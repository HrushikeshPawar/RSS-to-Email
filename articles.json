{"DeepMind Blog": {"Working together with YouTube": {"url": "https://www.deepmind.com/blog/working-together-with-youtube", "description": "", "pubdate": "Thu, 14 Jul 2022 00:00:00 GMT", "pubdate_parsed": 1657737000.0, "email_sent": true}, "DeepMind\u2019s latest research at ICML 2022": {"url": "https://www.deepmind.com/blog/deepminds-latest-research-at-icml-2022", "description": "Starting this weekend, the thirty-ninth International Conference on Machine Learning (ICML 2022) is meeting from 17-23 July, 2022 at the Baltimore Convention Center in Maryland, USA, and will be running as a hybrid event. Researchers working across artificial intelligence, data science, machine vision, computational biology, speech recognition, and more are presenting and publishing their cutting-edge work in machine learning.", "pubdate": "Fri, 15 Jul 2022 00:00:00 GMT", "pubdate_parsed": 1657823400.0, "email_sent": true}, "The virtuous cycle of AI research": {"url": "https://www.deepmind.com/blog/the-virtuous-cycle-of-ai-research", "description": "We recently caught up with Petar Veli\u010dkovi\u0107, a research scientist at DeepMind. Along with his co-authors, Petar is presenting his paper The CLRS Algorithmic Reasoning Benchmark at ICML 2022 in Baltimore, Maryland, USA.", "pubdate": "Tue, 19 Jul 2022 00:00:00 GMT", "pubdate_parsed": 1658169000.0, "email_sent": true}, "AlphaFold reveals the structure of the protein universe": {"url": "https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe", "description": "Today, in partnership with EMBL\u2019s European Bioinformatics Institute (EMBL-EBI), we\u2019re now releasing predicted structures for nearly all catalogued proteins known to science, which will expand the AlphaFold DB by over 200x - from nearly 1 million structures to over 200 million structures - with the potential to dramatically increase our understanding of biology.", "pubdate": "Thu, 28 Jul 2022 00:00:00 GMT", "pubdate_parsed": 1658946600.0, "email_sent": true}}, "Nvidia Blog": {"Living on the Edge: New Features for NVIDIA Fleet Command Deliver All-in-One Edge AI Management, Maintenance for Enterprises": {"url": "https://blogs.nvidia.com/blog/2022/07/18/fleet-command-all-in-one-edge-ai-management/", "description": "<p>NVIDIA Fleet Command \u2014 a cloud service for deploying, managing and scaling AI applications at the edge \u2014 now includes features that enhance the seamless management of edge AI deployments around the world. With the scale of edge AI deployments, organizations can have up to thousands of independent edge locations that must be managed by <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/18/fleet-command-all-in-one-edge-ai-management/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/18/fleet-command-all-in-one-edge-ai-management/\" rel=\"nofollow\">Living on the Edge: New Features for NVIDIA Fleet Command Deliver All-in-One Edge AI Management, Maintenance for Enterprises</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Mon, 18 Jul 2022 16:00:12 +0000", "pubdate_parsed": 1658140212.0, "email_sent": true}, "Lucid Motors\u2019 Mike Bell on Software-Defined Innovation for the Luxury EV Brand": {"url": "https://blogs.nvidia.com/blog/2022/07/20/lucid-motors-podcast/", "description": "<p>AI and electric vehicle technology breakthroughs are transforming the automotive industry. These developments pave the way for new innovators, attracting technical prowess and design philosophies from Silicon Valley. Mike Bell, senior vice president of digital at Lucid Motors, sees continuous innovation coupled with over-the-air updates as key to designing sustainable, award-winning intelligent vehicles that provide <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/20/lucid-motors-podcast/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/20/lucid-motors-podcast/\" rel=\"nofollow\">Lucid Motors&#8217; Mike Bell on Software-Defined Innovation for the Luxury EV Brand</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Wed, 20 Jul 2022 13:00:17 +0000", "pubdate_parsed": 1658302217.0, "email_sent": true}, "Shifting Into High Gear: Lunit, Maker of FDA-Cleared AI for Cancer Analysis, Goes Public in Seoul": {"url": "https://blogs.nvidia.com/blog/2022/07/21/lunit-healthcare-ai-ipo/", "description": "<p>South Korean startup Lunit, developer of two FDA-cleared AI models for healthcare, went public this week on the country\u2019s Kosdaq stock market. The move marks the maturity of the Seoul-based company \u2014 which was founded in 2013 and has for years been part of the NVIDIA Inception program that nurtures cutting-edge startups. Lunit\u2019s AI software <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/21/lunit-healthcare-ai-ipo/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/21/lunit-healthcare-ai-ipo/\" rel=\"nofollow\">Shifting Into High Gear: Lunit, Maker of FDA-Cleared AI for Cancer Analysis, Goes Public in Seoul</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 21 Jul 2022 14:34:50 +0000", "pubdate_parsed": 1658394290.0, "email_sent": true}, "Get Battle Ready With New GeForce NOW Fortnite Reward": {"url": "https://blogs.nvidia.com/blog/2022/07/21/geforce-now-thursday-july-21/", "description": "<p>&#60;Incoming Transmission&#62; Epic Games is bringing a new Fortnite reward to GeForce NOW, available to all members. Drop from the Battle Bus in Fortnite on GeForce NOW between today and Thursday, Aug. 4, to earn \u201cThe Dish-stroyer Pickaxe\u201d in game for free. &#60;Transmission continues&#62; Members can earn this item by streaming Fortnite on GeForce NOW <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/21/geforce-now-thursday-july-21/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/21/geforce-now-thursday-july-21/\" rel=\"nofollow\">Get Battle Ready With New GeForce NOW Fortnite Reward</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 21 Jul 2022 13:00:40 +0000", "pubdate_parsed": 1658388640.0, "email_sent": true}, "Researchers Use GPUs to Give Earbud Users a \u2018Mute Button\u2019 for Background Noise": {"url": "https://blogs.nvidia.com/blog/2022/07/21/mute-button-clearbuds/", "description": "<p>Thanks to earbuds you can have calls anywhere while doing anything. The problem: those on the other end of the call hear it all, too, from your roommate\u2019s vacuum cleaner to background conversations at the cafe you\u2019re working from. Now, work by a trio of graduate students at the University of Washington who spent the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/21/mute-button-clearbuds/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/21/mute-button-clearbuds/\" rel=\"nofollow\">Researchers Use GPUs to Give Earbud Users a \u2018Mute Button\u2019 for Background Noise</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 21 Jul 2022 13:00:03 +0000", "pubdate_parsed": 1658388603.0, "email_sent": true}, "Digital Sculptor Does Heavy Lifting With Lightweight Mobile Workstation": {"url": "https://blogs.nvidia.com/blog/2022/07/25/marlon-nunez-rtx/", "description": "<p>As a professional digital sculptor, Marlon Nu\u00f1ez is on a mission to make learning 3D art skills easier, smoother and more fun for all. And with the help of an NVIDIA RTX-powered Lenovo mobile workstation, he takes his 3D projects to the next level, wherever he goes. Nu\u00f1ez is the art director and co-founder of <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/25/marlon-nunez-rtx/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/25/marlon-nunez-rtx/\" rel=\"nofollow\">Digital Sculptor Does Heavy Lifting With Lightweight Mobile Workstation</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Mon, 25 Jul 2022 16:00:48 +0000", "pubdate_parsed": 1658745048.0, "email_sent": true}, "What Is an Exaflop?": {"url": "https://blogs.nvidia.com/blog/2022/07/26/what-is-an-exaflop/", "description": "<p>Computers are crunching more numbers than ever to crack the most complex problems of our time \u2014 how to cure diseases like COVID and cancer, mitigate climate change and more. These and other grand challenges ushered computing into today\u2019s exascale era when top performance is often measured in exaflops. So, What\u2019s an Exaflop? An exaflop <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/26/what-is-an-exaflop/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/26/what-is-an-exaflop/\" rel=\"nofollow\">What Is an Exaflop?</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Tue, 26 Jul 2022 15:00:29 +0000", "pubdate_parsed": 1658827829.0, "email_sent": true}, "July NVIDIA Studio Driver Improves Performance for Chaos V-Ray 6 for 3ds Max": {"url": "https://blogs.nvidia.com/blog/2022/07/26/in-the-nvidia-studio-july-26/", "description": "<p>Creativity heats up In the NVIDIA Studio as the July NVIDIA Studio Driver, available now, accelerates the recent Chaos V-Ray 6 for 3ds Max release.Plus, this week\u2019s In the NVIDIA Studio 3D artist, Brian Lai, showcases his development process for Afternoon Coffee and Waffle, a piece that went from concept to completion faster with NVIDIA RTX acceleration in Chaos V-Ray rendering software.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/26/in-the-nvidia-studio-july-26/\" rel=\"nofollow\">July NVIDIA Studio Driver Improves Performance for Chaos V-Ray 6 for 3ds Max</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Tue, 26 Jul 2022 13:00:29 +0000", "pubdate_parsed": 1658820629.0, "email_sent": true}, "1,650+ Global Interns Gleam With NVIDIA Green": {"url": "https://blogs.nvidia.com/blog/2022/07/28/internship-virtual-2022/", "description": "<p>A record number of interns calls for a record-sized celebration. In our largest contingent ever, over 1,650 interns from 350+ schools started with NVIDIA worldwide over the past year. Amidst busy work days tackling real-world projects across engineering, automation, robotics and more, the group\u2019s also finishing up a three-day celebration, culminating today with National Intern <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/28/internship-virtual-2022/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/internship-virtual-2022/\" rel=\"nofollow\">1,650+ Global Interns Gleam With NVIDIA Green</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 28 Jul 2022 18:10:00 +0000", "pubdate_parsed": 1659012000.0, "email_sent": true}, "Pony.ai Express: New Autonomous Trucking Collaboration Powered by NVIDIA DRIVE Orin": {"url": "https://blogs.nvidia.com/blog/2022/07/28/pony-ai-sany-autonomous-trucking-drive-orin/", "description": "<p>More than 160 years after the legendary Pony Express delivery service completed its first route, a new generation of \u201cPony\u201d-emblazoned vehicles are taking an AI-powered approach to long-haul delivery. Autonomous driving company Pony.ai announced today a partnership with SANY Heavy Truck (SANY), China\u2019s largest heavy equipment manufacturer, to jointly develop level 4 autonomous trucks. The <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/28/pony-ai-sany-autonomous-trucking-drive-orin/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/pony-ai-sany-autonomous-trucking-drive-orin/\" rel=\"nofollow\">Pony.ai Express: New Autonomous Trucking Collaboration Powered by NVIDIA DRIVE Orin</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 28 Jul 2022 15:51:22 +0000", "pubdate_parsed": 1659003682.0, "email_sent": true}, "Welcome Back, Commander: \u2018Command & Conquer Remastered Collection\u2019 Joins GeForce NOW": {"url": "https://blogs.nvidia.com/blog/2022/07/28/geforce-now-thursday-july-28/", "description": "<p>Take a trip down memory lane this week with an instantly recognizable classic, Command &#38; Conquer Remastered Collection, joining the nearly 20 Electronic Arts games streaming from the GeForce NOW library. Speaking of remastered, GeForce NOW members can enhance their gameplay further with improved resolution scaling in the 2.0.43 app update. When the feature is <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/28/geforce-now-thursday-july-28/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/geforce-now-thursday-july-28/\" rel=\"nofollow\">Welcome Back, Commander: \u2018Command &amp; Conquer Remastered Collection\u2019 Joins GeForce NOW</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 28 Jul 2022 13:00:47 +0000", "pubdate_parsed": 1658993447.0, "email_sent": true}, "NVIDIA Studio Laptops Offer Students AI, Creative Capabilities That Are Best in\u2026 Class": {"url": "https://blogs.nvidia.com/blog/2022/07/28/back-to-school-buying-guide/", "description": "<p>Selecting the right laptop is a lot like trying to pick the right major. Both can be challenging tasks where choosing wrongly costs countless hours. But pick the right one, and graduation is just around the corner. The tips below can help the next generation of artists select the ideal NVIDIA Studio laptop to maximize performance for the critical workload demands of their unique creative fields \u2014 all within budget.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/back-to-school-buying-guide/\" rel=\"nofollow\">NVIDIA Studio Laptops Offer Students AI, Creative Capabilities That Are Best in&#8230; Class</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 28 Jul 2022 13:00:18 +0000", "pubdate_parsed": 1658993418.0, "email_sent": true}, "How\u2019s That? Startup Ups Game for Cricket, Football and More With Vision AI": {"url": "https://blogs.nvidia.com/blog/2022/07/27/tvconal-sports-video-analytics/", "description": "<p>Sports produce a slew of data. In a game of cricket, for example, each play generates millions of video-frame data points for a sports analyst to scrutinize, according to Masoumeh Izadi, managing director of deep-tech startup TVConal. The Singapore-based company uses NVIDIA AI and computer vision to power its sports video analytics platform, which enables <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/27/tvconal-sports-video-analytics/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/27/tvconal-sports-video-analytics/\" rel=\"nofollow\">How\u2019s That? Startup Ups Game for Cricket, Football and More With Vision AI</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Thu, 28 Jul 2022 03:00:59 +0000", "pubdate_parsed": 1658957459.0, "email_sent": true}, "What Is a QPU?": {"url": "https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/", "description": "<p>Just as GPUs and DPUs enable accelerated computing today, they\u2019re also helping a new kind of chip, the QPU, boot up the promise of quantum computing. In your hand, a quantum processing unit might look and feel very similar to a graphics or a data processing unit. They\u2019re all typically chips, or modules with multiple <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/\" rel=\"nofollow\">What Is a QPU?</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Fri, 29 Jul 2022 15:00:49 +0000", "pubdate_parsed": 1659087049.0, "email_sent": true}, "Meet the Omnivore: Developer Builds Bots With NVIDIA Omniverse and Isaac Sim": {"url": "https://blogs.nvidia.com/blog/2022/08/01/omniverse-developer-antonio-serrano-munoz/", "description": "<p>While still in grad school, Antonio Serrano-Mu\u00f1oz has helped author papers spanning planetary gravities, AI-powered diagnosis of rheumatoid arthritis and robots that precisely track millimetric-sized walkers, like ants. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/01/omniverse-developer-antonio-serrano-munoz/\" rel=\"nofollow\">Meet the Omnivore: Developer Builds Bots With NVIDIA Omniverse and Isaac Sim</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Mon, 01 Aug 2022 16:01:47 +0000", "pubdate_parsed": 1659349907.0, "email_sent": true}, "Sensational Surrealism Astonishes This Week \u2018In the NVIDIA Studio\u2019": {"url": "https://blogs.nvidia.com/blog/2022/08/02/in-the-nvidia-studio-aug-02/", "description": "<p>3D phenom FESQ joins us 'In the NVIDIA Studio' this week to share his sensational and surreal animation 'Double/Sided' as well as an inside look into his creative workflow. 'Double/Sided' is deeply personal to FESQ, who said the piece \u201ctranslates really well to a certain period of my life when I was juggling both a programmer career and an artist career.\u201d</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/02/in-the-nvidia-studio-aug-02/\" rel=\"nofollow\">Sensational Surrealism Astonishes This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>", "pubdate": "Tue, 02 Aug 2022 13:00:23 +0000", "pubdate_parsed": 1659425423.0, "email_sent": true}}, "CMU Machine Learning Blog": {"Does AutoML work for diverse tasks?": {"url": "https://blog.ml.cmu.edu/2022/07/07/automl-for-diverse-tasks/", "description": "Over the past decade, machine learning (ML) has grown rapidly in both popularity and complexity. Driven by advances in deep neural networks, ML is now being applied far beyond its traditional domains like computer vision and text processing, with applications in areas as diverse as solving partial differential equations (PDEs), tracking credit card fraud, and predicting medical conditions from gene sequences. However, progress in such areas has often required expert-driven development of complex neural network architectures, expensive hyperparameter tuning, or both. Given that such resource intensive iteration is expensive and inaccessible to most practitioners, AutoML has emerged with an overarching goal of enabling any team of ML developers to deploy ML on arbitrary new tasks. Here we ask about the current status of AutoML, namely: can available AutoML tools quickly and painlessly attain near-expert performance on diverse learning tasks? This blog post is dedicated to two recent but related efforts that measure the field\u2019s current effectiveness at achieving this goal: NAS-Bench-360 and the AutoML Decathlon. The first is a benchmark suite focusing on the burgeoning field of neural architecture search (NAS), which seeks to automate the development of neural network models. With evaluations on ten diverse tasks\u2014including a precomputed tabular [&#8230;]", "pubdate": "Thu, 07 Jul 2022 18:16:30 +0000", "pubdate_parsed": 1657197990.0, "email_sent": true}}, "TensorFlow Blog": {"How Roboflow enables thousands of developers to use computer vision with TensorFlow.js": {"url": "https://blog.tensorflow.org/2022/07/how-roboflow-enables-thousands-of-developers-to-use-computer-vision-with-TensorFlow.js.html", "description": "<p><em>A guest post by <a href=\"https://twitter.com/braddwyer\" target=\"_blank\">Brad Dwyer</a>, co-founder and CTO, Roboflow</em></p><p> </p><a name=\"more\"></a><p></p> <p><a href=\"https://roboflow.com\" target=\"_blank\">Roboflow</a> lets developers build their own computer vision applications, from data preparation and model training to deployment and active learning. Through building <a href=\"https://twitter.com/braddwyer/status/910030265006923776\" target=\"_blank\">our own applications</a>, we learned firsthand how tedious it can be to train and deploy a computer vision model. That\u2019s why we launched Roboflow in January 2020 \u2013 we believe every developer should have computer vision available in their toolkit. Our mission is to remove any barriers that might prevent them from succeeding. </p><p>Our end-to-end computer vision platform simplifies the process of collecting images, creating datasets, training models, and deploying them to production. Over 100,000 developers build with Roboflow\u2019s tools. TensorFlow.js makes up a core part of<a href=\"https://docs.roboflow.com/inference\" target=\"_blank\"> Roboflow's deployment stack</a> that has<a href=\"https://blog.roboflow.com/computer-vision-datasets-and-apis/\" target=\"_blank\"> now powered over 10,000 projects</a> created by developers around the world. </p><p>As an early design decision, we decided that, in order to provide the best user experience, we needed to be able to run users' models directly in their web browser (along with our API, edge devices, and on-prem) instead of requiring a round-trip to our servers. The three primary concerns that motivated this decision were latency, bandwidth, and cost. </p><p>For example, Roboflow powers<a href=\"https://spelltable.wizards.com/\" target=\"_blank\"> SpellTable</a>'s<a href=\"https://twitter.com/SpellTable/status/1491877698293092352\" target=\"_blank\"> Codex</a> feature which uses a computer vision model to identify <em>Magic: The Gathering</em> cards. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRIq1GZCW_M4yiPxRQqUfY9TAGkxrRZ_s3peedpES5VyFHkMOK-eVumBaW-pwoE_A3Q9IX_ar4Zp9HzDoQdxX4W4SgCXjgcKYt3BHjmbWyteaS-GegM9ya8OyzUKIouFq9mqxJcXclzwfsNrQMfcnEBN5ScGfIQuSgka_7kJk9IlEeb4cjqCzrPv0d/s1600/Roboflow%20blog%202.gif\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>From <a href=\"https://twitter.com/SpellTable/status/1491877698293092352\" target=\"_blank\">Twitter</a></i></td></tr></tbody></table> <h3><strong>How Roboflow Uses TensorFlow.js</strong></h3>  <p>Whenever a user's model finishes<a href=\"https://docs.roboflow.com/train\" target=\"_blank\"> training on Roboflow's backend</a>, the model is converted and automatically converted to support sevel various deployment targets; one of those targets is TensorFlow.js. While TensorFlow.js is not the only way to <a href=\"https://roboflow.com/deploy\" target=\"_blank\">deploy a computer vision model</a> with Roboflow, some ways TensorFlow.js powers features within Roboflow include: </p><h4><strong>roboflow.js</strong></h4>  <p><a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\">roboflow.js</a> is a JavaScript SDK developers can use to integrate their trained model into a web app or Node.js app. Check this video for a quick introduction: </p> <div class=\"separator\" style=\"clear: both; text-align: left;\"></div><h4><strong>Inference Server</strong></h4><p><a href=\"https://github.com/roboflow-ai/inference-server\" target=\"_blank\">The Roboflow Inference Server</a> is a cross-platform microservice that enables developers to self-host and serve their model on-prem. (Note: while not all of Roboflow\u2019s inference servers are TFjs-based, it is one supported means of model deployment.) </p><p>The <a href=\"https://github.com/tensorflow/tfjs/tree/master/tfjs-node\" target=\"_blank\">tfjs-node</a> container runs via Docker and is GPU-accelerated on any machine with CUDA and a compatible NVIDIA graphics card, or using a CPU on any Linux, Mac, or Windows device. </p><h4><strong>Preview</strong></h4>  <p>Preview is an <a href=\"https://blog.roboflow.com/introducing-the-roboflow-inference-widget/\" target=\"_blank\">in-browser widget</a> that lets developers seamlessly test their models on images, video, and webcam streams. </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3fH2YX7U79s6s7RHZJuPlYJcqkc8PB1mGwD5wPlmom2yh3q-3y3vAoaopZ0U-a7RfCAZNCk7KBKt1RDq2refpSuF50oj6vcg6mtEuQP7UwwgodufA2HKB0czwHW1SMSt1uVcsIOH2dfa2Rc6cOqzSR6pmC4YXJW_tHD5LND9j2UszTUYCkn-6kjlH/s1600/Roboflow%20blog%203.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3fH2YX7U79s6s7RHZJuPlYJcqkc8PB1mGwD5wPlmom2yh3q-3y3vAoaopZ0U-a7RfCAZNCk7KBKt1RDq2refpSuF50oj6vcg6mtEuQP7UwwgodufA2HKB0czwHW1SMSt1uVcsIOH2dfa2Rc6cOqzSR6pmC4YXJW_tHD5LND9j2UszTUYCkn-6kjlH/s1600/Roboflow%20blog%203.png\" /></a></div><h4><strong>Label Assist</strong></h4>  <p>Label Assist is a<a href=\"https://roboflow.com/annotate\" target=\"_blank\"> model-assisted image labeling tool</a> that lets developers use their previous model's predictions as the starting point for annotating additional images. </p><p>One way users leverage Label Assist is in-browser predictions: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjHPQMr2knMeHlXX-bOFrx6XxXKKr-PzTZKVWqJ6ffj_VcuKY-CKta-3GjuXRQZx9MXAc-SHODMqnaNVRG4FcRRkBLgp2h6ZQ18AdE7x56poCzZaUfiJPN0hTuinPuC8nt8qcYMgNej1gjLwKkTm5oQJ52LOkBY0yr-cVXrN0CM4iXFRRXOVCIrfG/s1600/Roboflow%20blog%201.gif\" style=\"display: block; padding: 1em 0; text-align: center; clear: left; float: left;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjHPQMr2knMeHlXX-bOFrx6XxXKKr-PzTZKVWqJ6ffj_VcuKY-CKta-3GjuXRQZx9MXAc-SHODMqnaNVRG4FcRRkBLgp2h6ZQ18AdE7x56poCzZaUfiJPN0hTuinPuC8nt8qcYMgNej1gjLwKkTm5oQJ52LOkBY0yr-cVXrN0CM4iXFRRXOVCIrfG/s1600/Roboflow%20blog%201.gif\" /></a></div><h3><strong>Why We Chose TensorFlow.js</strong></h3>  <p>Once we had decided we needed to run in the browser, TensorFlow.js was a clear choice. </p><p>Because TFJS runs in our users' browsers and on their own compute, we are able to provide ML-powered features to our full user base of over 100,000 developers, including those on<a href=\"https://roboflow.com/pricing\" target=\"_blank\"> our free Public plan</a>. That simply wouldn't be feasible if we had to spin up a fleet of cloud-hosted GPUs. </p><h3><strong>Behind the Scenes</strong></h3>  <p>To implement<a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\"> roboflow.js</a> with TensorFlow.js was relatively straightforward. </p><p>We had to change a couple of layers in our neural network to<a href=\"https://docs.google.com/spreadsheets/d/1D25XtWaBrmUEErbGQB0QmNhH-xtwHo9LDl59w0TbxrI/edit#gid=0\" target=\"_blank\"> ensure all of our ops were supported</a> on the runtimes we wanted to use, integrate the<a href=\"https://www.npmjs.com/package/@tensorflow/tfjs-converter\" target=\"_blank\"> tfjs-converter</a> into our training pipeline, and port our pre-processing and post-processing code to JavaScript from Python. From there, it was smooth sailing. </p><p>Once we'd built roboflow.js for our customers, we utilized it internally to power features like Preview, <a href=\"https://blog.roboflow.com/announcing-label-assist/\" target=\"_blank\">Label Assist</a>, and one implementation of the Inference Server. </p><h3><strong>Try it Out</strong></h3>  <p>The easiest way to try roboflow.js is by using Preview on<a href=\"https://universe.roboflow.com\" target=\"_blank\"> Roboflow Universe</a>, where we host over 7,000 pre-trained models that our users have shared. Any of these models can be readily built into your applications for things like <a href=\"https://universe.roboflow.com/augmented-startups/playing-cards-ow27d/model/2\" target=\"_blank\">seeing playing cards</a>, <a href=\"https://universe.roboflow.com/surfline/surfer-spotting\" target=\"_blank\">counting surfers</a>, <a href=\"https://universe.roboflow.com/augmented-startups/vehicle-registration-plates-trudk\" target=\"_blank\">reading license plates</a>, and <a href=\"https://universe.roboflow.com/explo1-w7h8c/see-sci\" target=\"_blank\">spotting bacteria under microscope</a>, and more. </p><p>On the Deployment tab of<a href=\"https://universe.roboflow.com/search?q=trained%2520model\" target=\"_blank\"> any project with a trained model</a>, you can drop a video or use your webcam to run inference right in your browser. To see a live in-browser example, give this community created <a href=\"https://universe.roboflow.com/joseph-nelson/mask-wearing/model/11\" target=\"_blank\">mask detector</a> a try by clicking the \u201cWebcam\u201d icon: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSymprLcTpg7tM481QkcQ_gF3rXdwPyNmXehz3q_jq8dxR1_TE4dTi43ayquf9ngWPVEq7YLHJj61y_6BBN-DNreNMJpXAP9_J61FdZTa6haeL6cE-poQ2EwKBv7prPQByMJLZCxXVu4VMuo3bpkwE3F1qstHVKwVFf0CQjmL8VYixS_4a7nUSqLeE/s1600/Roboflow%20blog%205.gif\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSymprLcTpg7tM481QkcQ_gF3rXdwPyNmXehz3q_jq8dxR1_TE4dTi43ayquf9ngWPVEq7YLHJj61y_6BBN-DNreNMJpXAP9_J61FdZTa6haeL6cE-poQ2EwKBv7prPQByMJLZCxXVu4VMuo3bpkwE3F1qstHVKwVFf0CQjmL8VYixS_4a7nUSqLeE/s1600/Roboflow%20blog%205.gif\" /></a></div><p>To train your own model for a custom use case, you can<a href=\"https://app.roboflow.com\" target=\"_blank\"> create a free Roboflow account</a> to collect and label a dataset, then train and deploy it for use with roboflow.js in a single click. This enables you to use your model wherever you may need.  </p><h4 style=\"text-align: left;\"><strong>About Roboflow</strong></h4><p>Roboflow makes it easy for developers to use computer vision in their applications. Over 100,000 users have built with the company's end-to-end platform for image and video collection, organization, annotation, preprocessing, model training, and model deployment. Roboflow provides the tools for companies to improve their datasets and build more accurate computer vision models faster so their teams can focus on their domain problems without reinventing the wheel on vision infrastructure.  </p><p><a href=\"https://universe.roboflow.com/\" target=\"_blank\">Browse datasets on Roboflow Universe</a></p><p><a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\">Get started in the Roboflow documentation</a></p><p><a href=\"https://roboflow.com/features\" target=\"_blank\">View all available Roboflow features</a></p><p></p><p></p>", "pubdate": "Wed, 27 Jul 2022 17:00:00 +0000", "pubdate_parsed": 1658921400.0, "email_sent": true}, "Load-testing TensorFlow Serving\u2019s REST Interface": {"url": "https://blog.tensorflow.org/2022/07/load-testing-TensorFlow-Servings-REST-interface.html", "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\" style=\"display: none;\" /> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\" /></a> <p><em>Posted by <a href=\"https://github.com/deep-diver\" target=\"_blank\">Chansung Park</a> and <a href=\"https://github.com/sayakpaul\" target=\"_blank\">Sayak Paul</a> (ML-GDEs)</em></p> <a name=\"more\"></a><p></p> <p>In this post, we\u2019ll share the lessons and findings learned from conducting load tests for an image classification model across numerous deployment configurations. These configurations involve REST-based deployments with TensorFlow Serving. In this way, we aim to equip the readers with a holistic understanding of the differences between the configurations. </p><p>This post is less about code and more about the architectural decisions we had to make for performing the deployments. We\u2019ll first provide an overview of our setup including the technical specifications. We\u2019ll also share our commentaries on the design choices we made and their impact.  </p><h2>Technical Setup</h2>  <p><a href=\"https://www.tensorflow.org/tfx/guide/serving\" target=\"_blank\">TensorFlow Serving</a> is feature-rich and has targeted specifications embedded in its designs (more on this later). For <a href=\"https://cloud.google.com/ai-platform/prediction/docs/online-vs-batch-prediction\" target=\"_blank\">online prediction scenarios</a>, the model is usually exposed as some kind of service.  </p><p>To perform our testing we use a <a href=\"https://arxiv.org/abs/1512.03385\" target=\"_blank\">pre-trained ResNet50 model</a> which can classify a variety of images into different categories. We then serve this model in the following way: </p><ul><blockquote> <li><a href=\"https://www.docker.com/\" target=\"_blank\">Docker</a> to containerize the environment.  </li><li><a href=\"https://kubernetes.io/\" target=\"_blank\">Kubernetes</a> to orchestrate a cluster of container nodes for scalability. We use <a href=\"https://cloud.google.com/kubernetes-engine\" target=\"_blank\">Kubernetes Engine</a> (GKE) to manage this.   </li><li><a href=\"https://github.com/features/actions\" target=\"_blank\">GitHub Actions</a> to automatically roll out deployments on GKE.  </li>  </blockquote></ul><p>Our deployment platform (nodes on the Kubernetes Cluster) is CPU-based. We don\u2019t employ GPUs at any stage of our processes. For this purpose, we can build a CPU-optimized TensorFlow Serving image and take advantage of a few other options which can reduce the latency and boost the overall throughput of the system. We will discuss these later in the post.  </p><p>You can find all the code and learn how the deployments were performed in <a href=\"https://github.com/deep-diver/ml-deployment-k8s-tfserving\" target=\"_blank\">this repository</a>. Here, you\u2019ll find example notebooks and detailed setup instructions for playing around with the code. As such, we won\u2019t be discussing the code line by line but rather shed light on the most important parts when necessary. </p><p>Throughout the rest of this post, we\u2019ll discuss the key considerations for the deployment experiments respective to TensorFlow Serving including its motivation, limitations, and our experimental results.  </p><p><em>With the emergence of serverless offerings like <a href=\"https://cloud.google.com/vertex-ai\" target=\"_blank\">Vertex AI</a>, it has never been easier to deploy models and scale them securely and reliably. These services help reduce the time-to-market tremendously and increase overall developer productivity. That said,  there might still be instances where you\u2019d like more granular control over things. This is one of the reasons why we wanted to do these experiments in the first place. </em></p><h2>Considerations</h2>  <p>TensorFlow Serving has its own sets of constraints and design choices that can impact a deployment. In this section, we provide a concise overview of these considerations.  </p><p><strong>Deployment infrastructure:</strong> We chose GKE because Kubernetes is a standard deployment platform when using GCP, and GKE lets us focus on the ML parts without worrying about the infrastructure since it is a fully managed Google Cloud Platform service. Our main interest is in how to deploy models for CPU-based environments, so we have prepared a CPU-optimized TensorFlow Serving image.  </p><p><strong>Trade-off between more or fewer servers:</strong> We started experiments for TensorFlow Serving setups with the simplest possible VMs equipped with 2vCPU and 4GB RAM, then we gradually upgraded the specification up to 8vCPU and 64GB RAM. On the other hand, we decreased the number of nodes in the Kubernetes cluster from 8 to 2 because it is a trade-off between costs to deploy cheaper servers versus fewer expensive servers.  </p><p><strong>Options to benefit multi-core environments:</strong> We wanted to see if high-end VMs can outperform simple VMs with options to take advantage of the multi-core environment even though there are fewer nodes. To this end, we experimented with a different number <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads\" target=\"_blank\">inter_op_parallelism</a></code> and <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/config/threading/set_intra_op_parallelism_threads\" target=\"_blank\">intra_op_parallelism</a></code> threads for TensorFlow Serving deployment set according to the number of CPU cores.   </p><p><strong>Dynamic batching and other considerations:</strong> Modern ML frameworks such as TensorFlow Serving usually support dynamic batching, initial model warm-up, multiple deployments of multiple versions of different models, and more out of the box. For our purpose of online prediction, we have not tested these features carefully. However, dynamic batching capability is also worth exploring to enhance the performance according to the <a href=\"https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/batching/README.md#batch-scheduling-parameters-and-tuning\" target=\"_blank\">official document</a>. We have seen that the default batching configuration could reduce the latency a little even though the results of that are not included in this blog post. </p><h2>Experiments</h2>  <p>We have prepared the following environments. In TensorFlow Serving, the number of <code>intra_op_parallelism</code>_<code>threads</code> is set equal to the number of CPU cores while the number of <code>inter_op_parallelism_threads</code> is set from 2 to 8 for experimental purposes as it controls the number of threads to parallelize the execution of independent operations. Below we provide the details on the adjustments we performed on the number of vCPUs, RAM size, and the number of nodes for each Kubernetes cluster. Note that the number of vCPUs and the RAM size are applicable for the cluster nodes individually.  </p><p>The load tests are conducted using <a href=\"https://locust.io/\" target=\"_blank\">Locust</a>. We have run each load test for 5 minutes. The number of requests are controlled by the number of users, and it depends on the circumstances on the client side. We increased the number of users by one every second up to 150 which we found the handled number of requests reaches the plateau, and the requests are spawned every second to understand how TensorFlow Serving behaves. So you can assume that requests/second doesn't reflect the real-world situation where clients try to send requests at any time. </p><p>We experimented with the following node configurations on a Kubernetes cluster. The configurations are read like so: {num_vcpus_per_node}-{ram}_{num_nodes}: </p><ul style=\"text-align: left;\"> <li><strong>2vCPUs, 4GB RAM, 8 Nodes</strong></li><li><strong>4vCPUs, 8GB RAM, 4 Nodes</strong></li><li><strong>8vCPUs, 16GB RAM, 2 Nodes</strong></li><li><strong>8vCPUs, 64GB RAM, 2 Nodes</strong></li><ul></ul> </ul><p>You can find code for experimenting with these different configurations in the above-mentioned repositories. The deployment for each experiment is provisioned through <a href=\"https://kustomize.io/\" target=\"_blank\">Kustomize</a> to overlay the base configurations, and file-based configurations are injected through <a href=\"https://kubernetes.io/docs/concepts/configuration/configmap/\" target=\"_blank\">ConfigMap</a>. </p><h2>Results </h2>  <p>This section presents the results for each of the above configurations and suggests which configuration is the best based on the environments we considered. As per Figure 1, the best configuration and the environmental setup is observed as 2 nodes, 8 <code>intra_op_parallelism_threads</code>, 8 <code>inter_op_parallelism_threads</code>, 8vCPUs, 16GB RAM based on the result. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN73u2NKv-JzaPZ-NaGtIlNOTYrx_JiQeob2CB1lHbfOoLbjyYsi9GRiV76sxZEeX4M5_0HPjZlawduh1hWdbE5vYkXmmABQkteqKR26EoqJVh26A1K31RNXEV2fAjGUC6flIBDRWb7cZr8mkW4Wiqa3f1Y7cwi3Fb_QpUssA4wp2wGjdmY7kW-aRC/s1600/TF%20Blog%201.png\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN73u2NKv-JzaPZ-NaGtIlNOTYrx_JiQeob2CB1lHbfOoLbjyYsi9GRiV76sxZEeX4M5_0HPjZlawduh1hWdbE5vYkXmmABQkteqKR26EoqJVh26A1K31RNXEV2fAjGUC6flIBDRWb7cZr8mkW4Wiqa3f1Y7cwi3Fb_QpUssA4wp2wGjdmY7kW-aRC/s1600/TF%20Blog%201.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i><span style=\"text-align: start;\">Figure 1: Comparison between different configurations of TensorFlow Serving (</span><a href=\"https://i.ibb.co/wJ42g2Q/download-2.png\" style=\"text-align: start;\">original</a><span style=\"text-align: start;\">).<br /></span></i></td></tr></tbody></table><p>We have observed the following aspects by picking the best options. </p><ul> <li>TensorFlow Serving is more efficient when deployed on fewer, larger (more CPU and RAM) machines, but the RAM capacity doesn\u2019t have much impact on handling more requests. It is important to find the right number of <code>inter_op_parallelism_threads</code> with experimentation. With a higher number the better performance is not always guaranteed even when the nodes are equipped with high-capacity hardware. </li></ul><p>TensorFlow Serving focuses more on reliability than throughput performance. We believe it sacrifices some throughput performance to achieve reliability, but this is the expected behavior of TensorFlow Serving, as stated in the <a href=\"https://www.tensorflow.org/tfx/serving/performance#objectives\" target=\"_blank\">official document</a>. Even though handling as many requests as possible is important, keeping the server as reliable as possible is also substantially important when dealing with a production system.  </p><p>There is a trade-off between performance and reliability, so you must be careful to choose the right one. However, it seems like the throughput performance of TensorFlow Serving is close enough to <a href=\"https://github.com/sayakpaul/ml-deployment-k8s-fastapi\" target=\"_blank\">results from other frameworks such as FastAPI</a>, and if you want to factor in richer features such as dynamic batching and sharing GPU resources efficiently between models, we believe TensorFlow Serving is the right one to choose. </p><h2>Note on gRPC and TensorFlow Serving</h2>  <p>We are dealing with an image classification model for the deployments, and the input to the model will include images. Hence the size of the request payload can spiral up depending on the image resolution and fidelity. Therefore it\u2019s particularly important to ensure the message transmission is as lightweight as possible. Generally, message transmission is quite a bit faster in gRPC than REST. <a href=\"https://blog.dreamfactory.com/grpc-vs-rest-how-does-grpc-compare-with-traditional-rest-apis\" target=\"_blank\">This post</a> provides a good discussion on the main differences between REST and gRPC APIs. </p><p>TensorFlow Serving can <a href=\"https://www.tensorflow.org/tfx/serving/docker\" target=\"_blank\">serve a model with gRPC</a> seamlessly, but comparing the performance of a gRPC API and REST API is non-trivial. This is why we did not include that in this post. The interested readers can check out <a href=\"https://github.com/deep-diver/ml-deployment-k8s-tfserving\" target=\"_blank\">this repository</a> that follows a similar setup but uses a gRPC server instead.  </p><h2>Costs</h2>  <p>We used the <a href=\"https://cloud.google.com/products/calculator\" target=\"_blank\">GCP cost estimator</a> for this purpose. Pricing for each experiment configuration was assumed to be live for 24 hours per month (which was sufficient for our experiments).  </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border-collapse: collapse; border: none; width: 468pt;\">        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Machine Configuration (E2 series)</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Pricing (USD)</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">2vCPUs, 4GB RAM, 8 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4vCPUs, 8GB RAM, 4 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">8vCPUs, 16GB RAM, 2 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">8vCPUs, 64GB RAM, 2 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">18.21</span></p>                </td>            </tr>        </tbody>    </table></div><h2>Conclusion</h2>  <p>In this post, we discussed some critical lessons we learned from our experience of load-testing a standard image classification model. We considered the industry-grade framework for exposing the model to the end-users \u2013 TensorFlow Serving. While our setup for performing the load tests may not fully resemble what happens in the wild, we hope that our findings will at least act as a good starting point for the community. Even though the post demonstrated our approaches with an image classification model, the approaches should be fairly task-agnostic.  </p><p>In the interest of brevity, we didn\u2019t do much to push further the efficiency aspects of the model in both the APIs. With modern CPUs, software stack, and OS-level optimizations, it\u2019s possible to improve the latency and throughput of the model. We redirect the interested reader to the following resources that might be relevant: </p><ul> <li><a href=\"https://huggingface.co/blog/bert-cpu-scaling-part-1\" target=\"_blank\">Scaling up BERT-like model Inference on modern CPU - Part 1</a> </li><li><a href=\"https://huggingface.co/blog/bert-cpu-scaling-part-2\" target=\"_blank\">Scaling up BERT-like model Inference on modern CPU - Part 2</a> </li><li><a href=\"https://cloud.google.com/architecture/load-testing-and-monitoring-aiplatform-models\" target=\"_blank\">Load testing and monitoring AI Platform models </a> </li><li><a href=\"https://cloud.google.com/architecture/best-practices-for-ml-performance-cost\" target=\"_blank\">Best practices for performance and cost optimization for machine learning</a></li></ul><h2>Acknowledgements</h2>  <p>We are grateful to the <a href=\"https://developers.google.com/community/experts\" target=\"_blank\">ML Ecosystem team</a> that provided GCP credits for supporting our experiments. We also thank <a href=\"https://www.linkedin.com/in/hanneshapke\" target=\"_blank\">Hannes Hapke</a> and <a href=\"https://www.linkedin.com/in/robert-crowe\" target=\"_blank\">Robert Crowe</a> for providing us with helpful feedback and guidance.  </p>", "pubdate": "Thu, 28 Jul 2022 17:33:00 +0000", "pubdate_parsed": 1659009780.0, "email_sent": true}}, "Machine Learning Mastery Blog": {"Using Activation Functions in Neural Networks": {"url": "https://machinelearningmastery.com/using-activation-functions-in-neural-networks/", "description": "<p>Last Updated on July 6, 2022 Activation functions play an integral role in neural networks by introducing non-linearity. This nonlinearity allows neural networks to develop complex representations and functions based on the inputs that would not be possible with a simple linear regression model. There have been many different non-linear activation functions proposed throughout the [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-activation-functions-in-neural-networks/\" rel=\"nofollow\">Using Activation Functions in Neural Networks</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Mon, 04 Jul 2022 02:34:12 +0000", "pubdate_parsed": 1656882252.0, "email_sent": true}, "Binary Classification Tutorial with the Keras Deep Learning Library": {"url": "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/", "description": "<p>Last Updated on July 7, 2022 Keras is a Python library for deep learning that wraps the efficient numerical libraries TensorFlow and Theano. Keras allows you to quickly and simply design and train neural network and deep learning models. In this post you will discover how to effectively use the Keras library in your machine [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\" rel=\"nofollow\">Binary Classification Tutorial with the Keras Deep Learning Library</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Tue, 05 Jul 2022 19:00:56 +0000", "pubdate_parsed": 1657027856.0, "email_sent": true}, "Dropout Regularization in Deep Learning Models With Keras": {"url": "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/", "description": "<p>Last Updated on July 12, 2022 A simple and powerful regularization technique for neural networks and deep learning models is dropout. In this post you will discover the dropout regularization technique and how to apply it to your models in Python with Keras. After reading this post you will know: How the dropout regularization technique [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\" rel=\"nofollow\">Dropout Regularization in Deep Learning Models With Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Tue, 05 Jul 2022 19:00:37 +0000", "pubdate_parsed": 1657027837.0, "email_sent": true}, "Using Learning Rate Schedules for Deep Learning Models in Python with Keras": {"url": "https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/", "description": "<p>Last Updated on July 12, 2022 Training a neural network or large deep learning model is a difficult optimization task. The classical algorithm to train neural networks is called stochastic gradient descent. It has been well established that you can achieve increased performance and faster training on some problems by using a learning rate that [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\" rel=\"nofollow\">Using Learning Rate Schedules for Deep Learning Models in Python with Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Fri, 08 Jul 2022 19:00:40 +0000", "pubdate_parsed": 1657287040.0, "email_sent": true}, "A Gentle Introduction to tensorflow.data API": {"url": "https://machinelearningmastery.com/a-gentle-introduction-to-tensorflow-data-api/", "description": "<p>Last Updated on July 12, 2022 When we build and train a Keras deep learning model, the training data can be provided in several different ways. Presenting the data as a NumPy array or a TensorFlow tensor is a common one. Making a Python generator function and let the training loop to read data from [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/a-gentle-introduction-to-tensorflow-data-api/\" rel=\"nofollow\">A Gentle Introduction to tensorflow.data API</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Mon, 11 Jul 2022 18:05:36 +0000", "pubdate_parsed": 1657542936.0, "email_sent": true}, "Understanding the Design of a Convolutional Neural Network": {"url": "https://machinelearningmastery.com/understanding-the-design-of-a-convolutional-neural-network/", "description": "<p>Last Updated on July 13, 2022 Convolutional neural networks have been found successful in computer vision applications. Various network architectures are proposed and they are neither magical nor hard to understand. In this tutorial, we will make sense of the operation of convolutional layers and their role in a larger convolutional neural network. After finishing [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/understanding-the-design-of-a-convolutional-neural-network/\" rel=\"nofollow\">Understanding the Design of a Convolutional Neural Network</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Tue, 12 Jul 2022 14:50:02 +0000", "pubdate_parsed": 1657617602.0, "email_sent": true}, "High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike": {"url": "https://machinelearningmastery.com/high-fidelity-synthetic-data-for-data-engineers-and-data-scientists-alike/", "description": "<p>Last Updated on July 15, 2022 Sponsored Post If you&#8217;re a data engineer or data scientist, you know how hard it is to generate and maintain realistic data at scale. And to guarantee data privacy protection, in addition to all your day-to-day responsibilities? OOF. Talk about a heavy lift. But in today&#8217;s world, efficient data [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/high-fidelity-synthetic-data-for-data-engineers-and-data-scientists-alike/\" rel=\"nofollow\">High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Thu, 14 Jul 2022 20:03:59 +0000", "pubdate_parsed": 1657809239.0, "email_sent": true}, "Loss Functions in TensorFlow": {"url": "https://machinelearningmastery.com/loss-functions-in-tensorflow/", "description": "<p>Last Updated on July 15, 2022 Loss metric is very important for neural networks. As all machine learning model is a optimization problem or another, the loss is the objective function to minimize. In neural networks, the optimization is done with gradient descent and backpropagation. But what are loss functions and how are they affecting [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/loss-functions-in-tensorflow/\" rel=\"nofollow\">Loss Functions in TensorFlow</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Fri, 15 Jul 2022 02:52:11 +0000", "pubdate_parsed": 1657833731.0, "email_sent": true}, "Image Augmentation for Deep Learning with Keras": {"url": "https://machinelearningmastery.com/image-augmentation-deep-learning-keras/", "description": "<p>Last Updated on July 19, 2022 Data preparation is required when working with neural network and deep learning models. Increasingly data augmentation is also required on more complex object recognition tasks. In this post you will discover how to use data preparation and data augmentation with your image datasets when developing and evaluating deep learning [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\" rel=\"nofollow\">Image Augmentation for Deep Learning with Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Sat, 16 Jul 2022 19:00:09 +0000", "pubdate_parsed": 1657978209.0, "email_sent": true}, "Image Augmentation with Keras Preprocessing Layers and tf.image": {"url": "https://machinelearningmastery.com/image-augmentation-with-keras-preprocessing-layers-and-tf-image/", "description": "<p>Last Updated on July 20, 2022 When we work on a machine learning problem related to images, not only we need to collect some images as training data, but also need to employ augmentation to create variations in the image. It is especially true for more complex object recognition problems. There are many ways for [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/image-augmentation-with-keras-preprocessing-layers-and-tf-image/\" rel=\"nofollow\">Image Augmentation with Keras Preprocessing Layers and tf.image</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>", "pubdate": "Wed, 20 Jul 2022 02:10:31 +0000", "pubdate_parsed": 1658263231.0, "email_sent": true}}, "Colah's Blog": {}, "Amazon Science Blog": {"Better joint representations of image and text": {"url": "https://www.amazon.science/blog/better-joint-representations-of-image-and-text", "description": "Two methods presented at CVPR achieve state-of-the-art results by imposing additional structure on the representational space.", "pubdate": "Fri, 01 Jul 2022 15:30:39 GMT", "pubdate_parsed": 1656669639.0, "email_sent": true}, "Ten stories from the first half of 2022 that captivated readers": {"url": "https://www.amazon.science/latest-news/ten-stories-from-the-first-half-of-2022-that-captivated-readers", "description": "From Josh Miele's passion for making the world more accessible to improving forecasting by learning quantile functions, these stories resonated with our audience.", "pubdate": "Mon, 04 Jul 2022 04:01:00 GMT", "pubdate_parsed": 1656887460.0, "email_sent": true}, "My experience at Amazon while teaching at Stanford": {"url": "https://www.amazon.science/working-at-amazon/my-experience-at-amazon-while-teaching-at-stanford", "description": "Co-mingling industry experience and academic teaching.", "pubdate": "Tue, 05 Jul 2022 14:03:03 GMT", "pubdate_parsed": 1657009983.0, "email_sent": true}, "Second annual Machine Learning Summer School launches in India": {"url": "https://www.amazon.science/academic-engagements/second-annual-ml-summer-school-amazon-india", "description": "Expanded program aimed at engineering undergraduate and graduate students builds off the success of inaugural program.", "pubdate": "Wed, 06 Jul 2022 14:39:07 GMT", "pubdate_parsed": 1657098547.0, "email_sent": true}, "Anwar Walid receives 2022 IEEE INFOCOM Test of Time Paper Award": {"url": "https://www.amazon.science/latest-news/anwar-walid-receives-2022-ieee-infocom-test-of-time-paper-award", "description": "Walid\u2019s 2010 paper on distributed caching algorithms for content distribution networks cited for its \u201csignificant impact on the research community\u201d.", "pubdate": "Thu, 07 Jul 2022 19:00:00 GMT", "pubdate_parsed": 1657200600.0, "email_sent": true}, "A quick guide to Amazon\u2019s 45-plus NAACL papers": {"url": "https://www.amazon.science/blog/a-quick-guide-to-amazons-45-plus-naacl-papers", "description": "The breadth and originality of Amazon\u2019s natural-language-processing research are on display at the annual meeting of the North American chapter of the Association for Computational Linguistics.", "pubdate": "Thu, 07 Jul 2022 16:09:54 GMT", "pubdate_parsed": 1657190394.0, "email_sent": true}, "NAACL: Industry track offers reality checks, new directions": {"url": "https://www.amazon.science/blog/naacl-industry-track-offers-reality-checks-new-directions", "description": "Industry track chair and Amazon principal research scientist Rashmi Gangadharaiah on trends in industry papers and the challenges of building practical dialogue systems.", "pubdate": "Fri, 08 Jul 2022 17:19:26 GMT", "pubdate_parsed": 1657280966.0, "email_sent": true}, "Improving \u201centity linking\u201d between texts and knowledge bases": {"url": "https://www.amazon.science/blog/improving-entity-linking-between-texts-and-knowledge-bases", "description": "New model sets new standard in accuracy while enabling 60-fold speedups.", "pubdate": "Fri, 08 Jul 2022 14:15:01 GMT", "pubdate_parsed": 1657269901.0, "email_sent": true}, "How events like Prime Day helped Amazon navigate the pandemic": {"url": "https://www.amazon.science/latest-news/how-peak-events-like-prime-day-helped-amazon-navigate-the-pandemic", "description": "The SCOT science team used lessons from the past \u2014 and improved existing tools \u2014 to contend with \u201ca peak that lasted two years\u201d.", "pubdate": "Mon, 11 Jul 2022 13:12:35 GMT", "pubdate_parsed": 1657525355.0, "email_sent": true}, "Machine Learning University expands with MLU Explains": {"url": "https://www.amazon.science/latest-news/amazon-machine-learning-university-new-courses-mlu-explains", "description": "Fun visual essays explain key concepts of machine learning.", "pubdate": "Tue, 12 Jul 2022 13:43:35 GMT", "pubdate_parsed": 1657613615.0, "email_sent": true}, "Amazon and MIT announce Science Hub gift project awards": {"url": "https://www.amazon.science/academic-engagements/amazon-and-mit-announce-science-hub-gift-project-awards", "description": "Four MIT professors are the recipients of the inaugural call for research projects.", "pubdate": "Wed, 13 Jul 2022 18:00:00 GMT", "pubdate_parsed": 1657715400.0, "email_sent": true}, "Knowledge distillation for better convergence in multitask learning": {"url": "https://www.amazon.science/blog/knowledge-distillation-for-better-convergence-in-multitask-learning", "description": "Allowing separate tasks to converge on their own schedules and using knowledge distillation to maintain performance improves accuracy.", "pubdate": "Wed, 13 Jul 2022 15:28:28 GMT", "pubdate_parsed": 1657706308.0, "email_sent": true}, "Why ambient computing needs self-learning": {"url": "https://www.amazon.science/blog/why-ambient-computing-needs-self-learning", "description": "To become the interface for the Internet of things, conversational agents will need to learn on their own. Alexa has already started down that path.", "pubdate": "Thu, 14 Jul 2022 20:59:54 GMT", "pubdate_parsed": 1657812594.0, "email_sent": true}, "Joris Kinable wins IISE Transactions 2022 Best Application Award": {"url": "https://www.amazon.science/latest-news/amazon-scientist-joris-kinable-wins-iise-transactions-2022-best-application-award", "description": "Paper explains the use of constraint programming and mathematical optimization techniques in calculating the best routes for snowplows to clear Pittsburgh\u2019s roads.", "pubdate": "Thu, 14 Jul 2022 13:00:00 GMT", "pubdate_parsed": 1657783800.0, "email_sent": true}, "Filtering out \"forbidden\" documents during information retrieval": {"url": "https://www.amazon.science/blog/filtering-out-forbidden-documents-during-information-retrieval", "description": "New method optimizes the twin demands of retrieving relevant content and filtering out bad content.", "pubdate": "Fri, 15 Jul 2022 18:14:51 GMT", "pubdate_parsed": 1657889091.0, "email_sent": true}, "Amazon scientists Mike Hicks and Ren\u00e9 Vidal honored": {"url": "https://www.amazon.science/latest-news/amazon-scientists-mike-hicks-and-rene-vidal-honored", "description": "Hicks wins 2022 ACM SIGPLAN Distinguished Service Award for career contributions; Vidal wins IEEE Signal Processing Magazine Best Paper Award.", "pubdate": "Fri, 15 Jul 2022 16:32:31 GMT", "pubdate_parsed": 1657882951.0, "email_sent": true}, "74 Amazon Research Awards recipients announced": {"url": "https://www.amazon.science/research-awards/program-updates/74-amazon-research-awards-recipients-announced", "description": "The awardees represent 51 universities in 17 countries. Recipients have access to more than 300 Amazon public datasets, and can utilize AWS AI/ML services and tools.", "pubdate": "Mon, 18 Jul 2022 16:10:38 GMT", "pubdate_parsed": 1658140838.0, "email_sent": true}, "New method identifies the root causes of statistical outliers": {"url": "https://www.amazon.science/blog/new-method-identifies-the-root-causes-of-statistical-outliers", "description": "Amazon ICML paper proposes information-theoretic measurement of quantitative causal contribution.", "pubdate": "Tue, 19 Jul 2022 15:20:16 GMT", "pubdate_parsed": 1658224216.0, "email_sent": true}, "\"Among all sources of information, visual information may be the most interesting\"": {"url": "https://www.amazon.science/working-at-amazon/amazon-computer-vision-intern-to-applied-scientist-violetta-shevchenko", "description": "Violetta Shevchenko, an Amazon applied scientist and former intern, combines vision and language to create solutions to challenging problems.", "pubdate": "Wed, 20 Jul 2022 13:55:22 GMT", "pubdate_parsed": 1658305522.0, "email_sent": true}, "ICML: Where causality meets machine learning": {"url": "https://www.amazon.science/blog/icml-where-causality-meets-machine-learning", "description": "Amazon\u2019s Dominik Janzing on the history and promise of the young field of causal machine learning.", "pubdate": "Thu, 21 Jul 2022 13:43:23 GMT", "pubdate_parsed": 1658391203.0, "email_sent": true}, "Causal inference when treatments are continuous variables": {"url": "https://www.amazon.science/blog/causal-inference-when-treatments-are-continuous-variables", "description": "Combining a cutting-edge causal-inference technique and end-to-end machine learning reduces root-mean-square error by 27% to 38%.", "pubdate": "Fri, 22 Jul 2022 20:00:00 GMT", "pubdate_parsed": 1658500200.0, "email_sent": true}, "Massively Multilingual NLU 2022: Call for papers and shared-task entries": {"url": "https://www.amazon.science/blog/massively-multilingual-nlu-2022-call-for-papers-and-shared-task-entries", "description": "New EMNLP workshop will feature talks, papers, posters, and a competition built around the 50-plus-language, million-utterance MASSIVE dataset.", "pubdate": "Fri, 22 Jul 2022 16:39:17 GMT", "pubdate_parsed": 1658488157.0, "email_sent": true}, "Honorable mention to Amazon researchers for ICML test-of-time award": {"url": "https://www.amazon.science/blog/honorable-mention-to-amazon-researchers-for-icml-test-of-time-award", "description": "Amazon's Bernhard Sch\u00f6lkopf and Dominik Janzing are first and second authors on \"breakthrough 2012 paper\".", "pubdate": "Fri, 22 Jul 2022 14:21:28 GMT", "pubdate_parsed": 1658479888.0, "email_sent": true}, "Amazon-Columbia SURE students meet with Alexa AI VP": {"url": "https://www.amazon.science/academic-engagements/amazon-columbia-sure-students-meet-with-alexa-ai-vp", "description": "Prem Natarajan, Alexa AI vice president of natural understanding, visited the campus to engage with young STEM researchers from historically underrepresented backgrounds.", "pubdate": "Mon, 25 Jul 2022 19:00:00 GMT", "pubdate_parsed": 1658755800.0, "email_sent": true}, "How Amazon learned to cut its cardboard waste": {"url": "https://www.amazon.science/latest-news/amazon-cardboard-boxes-waste-reduction", "description": "Pioneering web-based PackOpt tool has resulted in an annual reduction in cardboard waste of 7% to 10% in North America, saving roughly 60,000 tons of cardboard annually.", "pubdate": "Mon, 25 Jul 2022 14:10:18 GMT", "pubdate_parsed": 1658738418.0, "email_sent": true}, "Preparing today for a post-quantum cryptographic future": {"url": "https://www.amazon.science/blog/preparing-today-for-a-post-quantum-cryptographic-future", "description": "Amazon is helping develop standards for post-quantum cryptography and deploying promising technologies for customers to experiment with.", "pubdate": "Tue, 26 Jul 2022 14:17:17 GMT", "pubdate_parsed": 1658825237.0, "email_sent": true}, "How silicon innovation became the \u2018secret sauce\u2019 behind AWS\u2019s success": {"url": "https://www.amazon.science/how-silicon-innovation-became-the-secret-sauce-behind-awss-success", "description": "Nafea Bshara, AWS vice president and distinguished engineer, discusses Annapurna Lab\u2019s path to silicon success; Annapurna co-founder will be a featured speaker in August 3 AWS Silicon Innovation Day virtual event.", "pubdate": "Wed, 27 Jul 2022 18:10:07 GMT", "pubdate_parsed": 1658925607.0, "email_sent": true}, "\u201cI didn\u2019t imagine I could grow and learn so much\u201d": {"url": "https://www.amazon.science/working-at-amazon/amazon-internships-summer-2022-experience-donato-crisostomi-science-intern", "description": "Donato Crisostomi talks about how his mother helped spark a love of knowledge that led him to two science internships at Amazon.", "pubdate": "Thu, 28 Jul 2022 18:00:00 GMT", "pubdate_parsed": 1659011400.0, "email_sent": true}, "Amazon hosts largest class of science interns": {"url": "https://www.amazon.science/working-at-amazon/amazon-hosts-largest-class-of-science-interns", "description": "This year\u2019s class includes applied science, research science, and data science interns.", "pubdate": "Thu, 28 Jul 2022 14:33:08 GMT", "pubdate_parsed": 1658998988.0, "email_sent": true}, "A hyperparameter optimization library for reproducible research": {"url": "https://www.amazon.science/blog/a-hyperparameter-optimization-library-for-reproducible-research", "description": "Syne Tune supports multiple backends, single-fidelity and multi-fidelity (early-exit) optimization algorithms, and hyperparameter transfer learning.", "pubdate": "Fri, 29 Jul 2022 14:16:25 GMT", "pubdate_parsed": 1659084385.0, "email_sent": true}, "Amazon Scholar Kathleen McKeown receives dual honors": {"url": "https://www.amazon.science/latest-news/amazon-scholar-kathleen-mckeown-receives-dual-honors", "description": "McKeown awarded IEEE Innovation in Societal Infrastructure Award and named a member of the American Philosophical Society.", "pubdate": "Mon, 01 Aug 2022 18:02:14 GMT", "pubdate_parsed": 1659357134.0, "email_sent": true}, "The path to carbon reductions in high-growth economic sectors": {"url": "https://www.amazon.science/blog/the-path-to-carbon-reductions-in-high-growth-economic-sectors", "description": "Confronting climate change requires the participation of governments, companies, academics, civil-society organizations, and the public.", "pubdate": "Mon, 01 Aug 2022 14:37:12 GMT", "pubdate_parsed": 1659344832.0, "email_sent": true}, "20B-parameter Alexa model sets new marks in few-shot learning": {"url": "https://www.amazon.science/blog/20b-parameter-alexa-model-sets-new-marks-in-few-shot-learning", "description": "With an encoder-decoder architecture \u2014 rather than decoder only \u2014 the Alexa Teacher Model excels other large language models on few-shot tasks such as summarization and machine translation.", "pubdate": "Tue, 02 Aug 2022 12:59:36 GMT", "pubdate_parsed": 1659425376.0, "email_sent": true}}, "The Berkeley Artificial Intelligence Research Blog": {"Why do Policy Gradient Methods work so well in Cooperative MARL? Evidence from Policy Representation": {"url": "http://bair.berkeley.edu/blog/2022/07/10/pg-ar/", "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p>In cooperative multi-agent reinforcement learning (MARL), due to its <em>on-policy</em> nature, policy gradient (PG) methods are typically believed to be less sample efficient than value decomposition (VD) methods, which are <em>off-policy</em>. However, some <a href=\"https://arxiv.org/abs/2103.01955\">recent</a> <a href=\"https://arxiv.org/abs/2011.09533\">empirical</a> <a href=\"https://arxiv.org/abs/2006.07869\">studies</a> demonstrate that with proper input representation and hyper-parameter tuning, multi-agent PG can achieve <a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">surprisingly strong performance</a> compared to off-policy VD methods.</p>\n\n<p><strong>Why could PG methods work so well?</strong> In this post, we will present concrete analysis to show that in certain scenarios, e.g., environments with a highly multi-modal reward landscape, VD can be problematic and lead to undesired outcomes. By contrast, PG methods with individual policies can converge to an optimal policy in these cases. In addition, PG methods with auto-regressive (AR) policies can learn multi-modal policies.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/ar.png\" width=\"80%\" />\n    <br />\n<i>\nFigure 1: different policy representation for the 4-player permutation game.\n</i>\n</p>\n\n<!--more-->\n\n<h2 id=\"ctde-in-cooperative-marl-vd-and-pg-methods\">CTDE in Cooperative MARL: VD and PG methods</h2>\n\n<p>Centralized training and decentralized execution (<a href=\"https://arxiv.org/abs/1706.02275\">CTDE</a>) is a popular framework in cooperative MARL. It leverages <em>global</em> information for more effective training while keeping the representation of individual policies for testing. CTDE can be implemented via value decomposition (VD) or policy gradient (PG), leading to two different types of algorithms.</p>\n\n<p>VD methods learn local Q networks and a mixing function that mixes the local Q networks to a global Q function. The mixing function is usually enforced to satisfy the Individual-Global-Max (<a href=\"https://arxiv.org/abs/1905.05408\">IGM</a>) principle, which guarantees the optimal joint action can be computed by greedily choosing the optimal action locally for each agent.</p>\n\n<p>By contrast, PG methods directly apply policy gradient to learn an individual policy and a centralized value function for each agent. The value function takes as its input the global state (e.g., <a href=\"https://arxiv.org/abs/2103.01955\">MAPPO</a>) or the concatenation of all the local observations (e.g., <a href=\"https://arxiv.org/abs/1706.02275\">MADDPG</a>), for an accurate global value estimate.</p>\n\n<h2 id=\"the-permutation-game-a-simple-counterexample-where-vd-fails\">The permutation game: a simple counterexample where VD fails</h2>\n\n<p>We start our analysis by considering a stateless cooperative game, namely the permutation game. In an $N$-player permutation game, each agent can output $N$ actions ${ 1,\\ldots, N }$. Agents receive $+1$ reward  if their actions are mutually different, i.e., the joint action is a permutation over $1, \\ldots, N$; otherwise, they receive $0$ reward. Note that there are $N!$ symmetric optimal strategies in this game.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/permutation_game.png\" width=\"70%\" />\n    <br />\n<i>\nFigure 2: the 4-player permutation game.\n</i>\n</p>\n\n<p>Let us focus on the 2-player permutation game for our discussion. In this setting, if we apply VD to the game, the global Q-value will factorize to</p>\n\n\\[Q_\\textrm{tot}(a^1,a^2)=f_\\textrm{mix}(Q_1(a^1),Q_2(a^2)),\\]\n\n<p>where $Q_1$ and $Q_2$ are local Q-functions, $Q_\\textrm{tot}$ is the global Q-function, and $f_\\textrm{mix}$ is the mixing function that, as required by VD methods, satisfies the IGM principle.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/vd_pg.png\" width=\"90%\" />\n    <br />\n    <i>\nFigure 3: high-level intuition on why VD fails in the 2-player permutation game.\n    </i>\n</p>\n<p>We formally prove that VD cannot represent the payoff of the 2-player permutation game by contradiction. If VD methods were able to represent the payoff, we would have</p>\n\n\\[Q_\\textrm{tot}(1, 2)=Q_\\textrm{tot}(2,1)=1 \\qquad \\textrm{and} \\qquad Q_\\textrm{tot}(1, 1)=Q_\\textrm{tot}(2,2)=0.\\]\n\n<p>However, if either of these two agents have different local Q values, e.g. $Q_1(1)&gt; Q_1(2)$, then according to the IGM principle, we must have</p>\n\n\\[1=Q_\\textrm{tot}(1,2)=\\arg\\max_{a^2}Q_\\textrm{tot}(1,a^2)&gt;\\arg\\max_{a^2}Q_\\textrm{tot}(2,a^2)=Q_\\textrm{tot}(2,1)=1.\\]\n\n<p>Otherwise, if $Q_1(1)=Q_1(2)$ and $Q_2(1)=Q_2(2)$, then</p>\n\n\\[Q_\\textrm{tot}(1, 1)=Q_\\textrm{tot}(2,2)=Q_\\textrm{tot}(1, 2)=Q_\\textrm{tot}(2,1).\\]\n\n<p>As a result, value decomposition cannot represent the payoff matrix of the 2-player permutation game.</p>\n\n<p>What about PG methods? Individual policies can indeed represent an optimal policy for the permutation game. Moreover, stochastic gradient descent can guarantee PG to converge to one of these optima <a href=\"https://arxiv.org/abs/1802.06175\">under mild assumptions</a>. This suggests that, even though PG methods are less popular in MARL compared with VD methods, they can be preferable in certain cases that are common in real-world applications, e.g., games with multiple strategy modalities.</p>\n\n<p>We also remark that in the permutation game, in order to represent an optimal joint policy, each agent must choose distinct actions. <strong>Consequently, a successful implementation of PG must ensure that the policies are agent-specific.</strong> This can be done by using either individual policies with unshared parameters (referred to as PG-Ind in our paper), or an agent-ID conditioned policy (<a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">PG-ID</a>).</p>\n\n<h2 id=\"pg-outperform-best-vd-methods-on-popular-marl-testbeds\">PG outperform best VD methods on popular MARL testbeds</h2>\n\n<p>Going beyond the simple illustrative example of the permutation game, we extend our study to popular and more realistic MARL benchmarks. In addition to StarCraft Multi-Agent Challenge (<a href=\"https://github.com/oxwhirl/smac\">SMAC</a>), where the effectiveness of PG and agent-conditioned policy input <a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">has been verified</a>, we show new results in Google Research Football (<a href=\"https://github.com/google-research/football\">GRF</a>) and multi-player <a href=\"https://github.com/deepmind/hanabi-learning-environment\">Hanabi Challenge</a>.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/football.png\" width=\"48%\" />\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/hanabi.png\" width=\"45%\" />\n    <br />\n<i>\nFigure 4: (left) winning rates of PG methods on GRF; (right) best and average evaluation scores on Hanabi-Full.\n</i>\n</p>\n\n<p>In GRF, PG methods outperform the state-of-the-art VD baseline (<a href=\"https://arxiv.org/abs/2106.02195\">CDS</a>) in 5 scenarios. Interestingly, we also notice that individual policies (PG-Ind) without parameter sharing achieve comparable, sometimes even higher winning rates, compared to agent-specific policies (PG-ID) in all 5 scenarios. We evaluate PG-ID in the full-scale Hanabi game with varying numbers of players (2-5 players) and compare them to <a href=\"https://arxiv.org/abs/1912.02288\">SAD</a>, a strong off-policy Q-learning variant in Hanabi, and Value Decomposition Networks (<a href=\"https://arxiv.org/abs/1706.05296\">VDN</a>). As demonstrated in the above table, PG-ID is able to produce results comparable to or better than the best and average rewards achieved by SAD and VDN with varying numbers of players using the same number of environment steps.</p>\n\n<h2 id=\"beyond-higher-rewards-learning-multi-modal-behavior-via-auto-regressive-policy-modeling\">Beyond higher rewards: learning multi-modal behavior via auto-regressive policy modeling</h2>\n\n<p>Besides learning higher rewards, we also study how to learn multi-modal policies in cooperative MARL. Let\u2019s go back to the permutation game. Although we have proved that PG can effectively learn an optimal policy, the strategy mode that it finally reaches can highly depend on the policy initialization. Thus, a natural question will be:</p>\n\n<p style=\"text-align: center;\">\n    <i>\nCan we learn a single policy that can cover all the optimal modes?\n    </i>\n</p>\n\n<p>In the decentralized PG formulation, the factorized representation of a joint policy can only represent one particular mode. Therefore, we propose an enhanced way to parameterize the policies for stronger expressiveness \u2014 the auto-regressive (AR) policies.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/pg-ar/permutation_ar.gif\" width=\"80%\" />\n<br />\n<i>\nFigure 5: comparison between individual policies (PG) and auto-regressive  policies (AR) in the 4-player permutation game.\n</i>\n</p>\n\n<p>Formally, we factorize the joint policy of $n$ agents into the form of</p>\n\n\\[\\pi(\\mathbf{a} \\mid \\mathbf{o}) \\approx \\prod_{i=1}^n \\pi_{\\theta^{i}} \\left( a^{i}\\mid o^{i},a^{1},\\ldots,a^{i-1} \\right),\\]\n\n<p>where the action produced by agent $i$ depends on its own observation $o_i$ and all the actions from previous agents $1,\\dots,i-1$. The auto-regressive factorization can represent <em>any</em> joint policy in a centralized MDP. The <em>only</em> modification to each agent\u2019s policy is the input dimension, which is slightly enlarged by including previous actions; and the output dimension of each agent\u2019s policy remains unchanged.</p>\n\n<p>With such a minimal parameterization overhead, AR policy substantially improves the representation power of PG methods. We remark that PG with AR policy (PG-AR) can simultaneously represent all optimal policy modes in the permutation game.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/heatmap.png\" width=\"70%\" />\n    <br />\n<i>\nFigure: the heatmaps of actions for policies learned by PG-Ind (left) and PG-AR (middle), and the heatmap for rewards (right); while PG-Ind only converge to a specific mode in the 4-player permutation game, PG-AR successfully discovers all the optimal modes.\n</i>\n</p>\n\n<p>In more complex environments, including SMAC and GRF, PG-AR can learn interesting emergent behaviors that require strong intra-agent coordination that may never be learned by PG-Ind.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/2m1z.gif\" width=\"45%\" />\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/3v1.gif\" width=\"45%\" />\n    <br />\n<i>\nFigure 6: (left) emergent behavior induced by PG-AR in SMAC and GRF. On the 2m_vs_1z map of SMAC, the marines keep standing and attack alternately while ensuring there is only one attacking marine at each timestep; (right) in the academy_3_vs_1_with_keeper scenario of GRF, agents learn a \"Tiki-Taka\" style behavior: each player keeps passing the ball to their teammates.\n</i>\n</p>\n\n<h2 id=\"discussions-and-takeaways\">Discussions and Takeaways</h2>\n\n<p>In this post, we provide a concrete analysis of VD and PG methods in cooperative MARL. First, we reveal the limitation on the expressiveness of popular VD methods, showing that they could not represent optimal policies even in a simple permutation game. By contrast, we show that PG methods are provably more expressive. We empirically verify the expressiveness advantage of PG on popular MARL testbeds, including SMAC, GRF, and Hanabi Challenge. We hope the insights from this work could benefit the community towards more general and more powerful cooperative MARL algorithms in the future.</p>\n\n<hr />\n\n<p><em>This post is based on our paper in joint with Zelai Xu: Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning (<a href=\"https://arxiv.org/abs/2206.07505\">paper</a>, <a href=\"https://sites.google.com/view/revisiting-marl\">website</a>).</em></p>", "pubdate": "Sun, 10 Jul 2022 02:00:00 -0700", "pubdate_parsed": 1657423800.0, "email_sent": true}}, "Google AI Blog": {"An update on our work in responsible innovation": {"url": "https://blog.google/technology/ai/an-update-on-our-work-in-responsible-innovation/", "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Over the last year, we\u2019ve seen artificial intelligence (AI) systems advance our work in areas like <a href=\"https://blog.google/products/pixel/image-equity-real-tone-pixel-6-photos/\">inclusive product development</a> and support for <a href=\"https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/\">small businesses</a> and <a href=\"https://grow.google/certificates/interview-warmup/\">job seekers</a>. We\u2019ve also seen its potential to be helpful in addressing major global needs \u2014 like <a href=\"https://blog.google/technology/ai/expanding-our-ml-based-flood-forecasting/\">forecasting</a> and planning <a href=\"https://blog.google/around-the-globe/google-africa/using-ai-to-map-africas-buildings/\">humanitarian responses</a> to natural disasters, <a href=\"https://blog.google/intl/en-au/company-news/outreach-initiatives/protecting-our-reef-with-csiro/\">addressing global environmental</a> challenges, and delivering groundbreaking <a href=\"https://www.nature.com/articles/d41586-021-02025-4\">scientific research</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI is exciting \u2014 both from a technical perspective and when considering its underlying social benefits. And yet, to fully realize AI\u2019s potential, it must be developed responsibly, thoughtfully and in a way that gives deep consideration to core ethical questions. After all, the promise of great reward inherently involves risk \u2014 and we\u2019re committed to ethically developing AI in a way that is socially beneficial.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our <a href=\"http://ai.google/principles\">AI Principles</a> guide how we integrate AI research into Google\u2019s products and services and engage with external partners. Internally, we implement the Principles, every day, through education programs, AI ethics reviews and technical tools. There are more than 200 Googlers across the company whose full-time roles are to operationalize responsible practices for developing AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re committed to sharing our lessons learned so others across the industry can learn, too (see our posts from <a href=\"https://www.blog.google/technology/ai/google-ai-principles-updates-six-months/\">2018,</a> <a href=\"https://www.blog.google/technology/ai/responsible-ai-principles/\">2019</a>, <a href=\"https://blog.google/technology/ai/update-work-ai-responsible-innovation/\">2020</a> and <a href=\"https://blog.google/technology/ai/update-our-progress-responsible-ai-innovation/#:~:text=Over%20the%20past%20year%2C%20responsibly,and%20protected%20wildlife%20after%20bushfires.\">2021</a>, and our in-depth annual <a href=\"https://ai.google/responsibilities/review-process/#:~:text=the%20current%20process.-,annual%20updates,-AI%20Principles%202021\">AI Principles Progress Updates</a>).</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Internal education</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s important to craft principles, but putting them into practice requires both training and constant dialogue.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Launched in late 2019, to date more than 32,000 employees across Google have engaged in AI Principles training. Given our growing understanding of effective hybrid and remote learning, we continue to expand and modify the courses. For example, this year we adapted our popular four-part Tech Ethics self-study course to a one-part deep dive based on Googler feedback. Similarly, we launched the <a href=\"https://blog.google/technology/ai/crossword-puzzle-big-purpose/\">Responsible Innovation Challenge</a> \u2014 taken by more than 13,000 employees \u2014 as a series of engaging online puzzles, quizzes and games to raise awareness of the AI Principles and measure employees' retention of ethical concepts, such as avoiding unfair bias.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We also piloted a new Moral Imagination workshop, a two-day, live-video immersive set of activities for product teams to walk through the ethical implications of potential AI products. To date, 248 Googlers across 23 Google product and research teams have taken the workshop, resulting in deeper, ongoing AI ethics consultations on product development.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As we develop internal training, we\u2019re committed to incorporating the input of both Googlers and outside experts. This year, when we launched a live workshop to educate our internal user experience and product teams on the concept of <a href=\"https://blog.google/inside-google/googlers/ask-techspert-how-do-machine-learning-models-explain-themselves/\">AI explainability</a>, we first piloted the workshop with outside experts at the international <a href=\"https://summit.ttclabs.net/\">Trust, Transparency and Control Labs</a> summit in May.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We believe this approach complements programs like our internal AI Principles Ethics Fellows program, a six-month fellowship that this year involved Googlers from 17 different global offices. We also just launched a version of the fellowship program tailored for senior leaders.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Putting the Principles into practice</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our approach to responsible AI innovation starts early, before teams plan a new AI application. When a team starts to build a machine learning (ML) model, dataset or product feature, they can attend office hours with experts to ask questions and engage in analyses using responsible AI <a href=\"https://www.tensorflow.org/responsible_ai?hl=en\">tools</a> that Google develops, or seek adversarial proactive fairness <a href=\"https://www.blog.google/inside-google/googlers/meet-3-women-who-test-google-products-fairness/\">(ProFair) testing.</a> Pre-launch, a team then can request an AI Principles review.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI Principles reviewers are in place to implement a structured assessment to identify, measure and analyze potential risk of harm. The risk rating focuses on the extent to which people and society may be impacted if solutions did not exist or were to fail. Reviewers also consider a growing body of lessons from thousands of previous AI Principles reviews conducted since 2019.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>When reviewers find medium- to high-risk issues, such as product exclusion or a potential privacy or security concern, they work with the teams to address these issues. Reviews either result in an approval, approval with conditions or recommendations, or non-approval. New AI applications that might affect multiple product areas are escalated to the Advanced Technology Review Council \u2014 a group of senior research, product and business leaders who make the final decision.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To supplement the expertise of our internal AI Principles group members, we often incorporate trusted external advisors. For example, a team was incorporating AI to help build a <a href=\"https://dynamicworld.app/\">near real-time dataset</a> to enable reliable measurement of global land cover for environmental and social benefit. They submitted for <a href=\"https://ai.google/static/documents/case-study-dynamic-world.pdf\">AI Principles review</a> and then collaborated with the review team to design several safeguards. The review team also worked with third-party experts at the <a href=\"https://www.wri.org/about\">World Resources Institute</a> and <a href=\"https://www.bsr.org/en/about\">BSR</a>. Following the example of the European Commission\u2019s <a href=\"https://www.copernicus.eu/en\">Copernicus mission\u2019s</a> open <a href=\"https://sentinel.esa.int/documents/247904/690755/sentinel_data_legal_notice\">data and services</a> terms, the product team applied open data principles, making the ML model\u2019s <a href=\"https://doi.pangaea.de/10.1594/PANGAEA.933475\">training</a> and <a href=\"https://doi.org/10.5281/zenodo.4766508\">test data</a> used to create the dataset, as well as the dataset itself, freely available under CC-BY-4.0, and the <a href=\"https://github.com/google/dynamicworld\">model available on Github</a> under an Apache 2.0 license. We recently released a <a href=\"https://ai.google/static/documents/case-study-dynamic-world.pdf\">Codelab</a> for developers to walk through the ethics review process and apply learnings to their own projects.</p></div></div><div class=\"block-video\"><div class=\"h-c-page h-c-page--mobile-full-bleed\"><div class=\"h-c-grid\"><div class=\"h-c-grid__col h-c-grid__col-l--10 h-c-grid__col-l--offset-1\"><div class=\"article-module uni-article-video uni-article-video--body\"><div class=\"uni-article-video__embed-container hidden\"><div id=\"uni-article-yt-player-S75NcDqbPbI\"></div></div><figure><a class=\"h-c-video h-c-video--marquee uni-article-video__custom-wrapper\" tabindex=\"0\"><div class=\"uni-article-video__aspect-image\"><img alt=\"A video explaining Google's AI Principles Review process\" src=\"https://img.youtube.com/vi/S75NcDqbPbI/maxresdefault.jpg\" /><div class=\"uni-article-video__dimmer\"></div><svg class=\"uni-article-video__play-button--active\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button_no_hole\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><svg class=\"uni-article-video__play-button\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><div class=\"uni-article-video__duration loading\"><svg class=\"uni-article-video__duration-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_duration\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><span class=\"uni-article-video__duration-time\">10:25</span></div></div></a><p>Google\u2019s AI Principles Review Process: How we assess new AI research and applications for alignment with our Principles</p></figure></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Projects such as research methods for evaluating misinformation and datasets that need more diverse representation tend to receive conditions to proceed toward a launch. A recurring condition given to teams is to engage in ProFair testing with people from a diversity of backgrounds, often in partnership with our central Product Inclusion and Equity team. This year, the number of ProFair consultations increased annually by 100%. A recurring approach is to create and release detailed documentation in the form of<a href=\"https://www.youtube.com/watch?v=IYK6fkODXNU\">data cards</a> and <a href=\"https://modelcards.withgoogle.com/about\">model cards</a> for transparency and accountability. The number of AI Principles reviews with model or data card mitigations increased 68% in the last year.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As we\u2019ve stated, we\u2019ve embedded customized AI governance and review committees within certain product areas (like Cloud and Health). As a result, both the Health Ethics Committee and Cloud make decisions with specialized expertise, such as establishing policies for potentially winding down the <a href=\"https://www.google.com/covid19/mobility/\">Covid-19 Community Mobility Reports</a> and the <a href=\"https://ai.googleblog.com/2021/10/an-ml-based-framework-for-covid-19.html\">Covid-19 Forecaster</a>, respectively, if situations arise that might cause the data quality to degrade. This year, we extended this specialized approach and created a dedicated consumer hardware AI Principles review process.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s important to note that product teams across Google engage in everyday responsible AI practices even if not in formal reviews. <a href=\"https://blog.youtube/inside-youtube/inside-responsibility-whats-next-on-our-misinfo-efforts/\">YouTube</a> is leveraging a more targeted mix of classifiers, keywords in additional languages, and information from regional analysts. This work is a result of collaboration with our researchers who focus on new tools for AI fairness. The Photos team participated in an <a href=\"https://blog.google/technology/ai/update-our-progress-responsible-ai-innovation/#:~:text=equitable%20ai%20research%20roundtables%20(earr)%2C\">Equitable AI Research Roundtable (EARR)</a> with a group of external advisors on potential fairness considerations. And the Gboard team deployed a new, <a href=\"https://ai.googleblog.com/2021/12/a-scalable-approach-for-partially-local.html\">privacy-by-design</a> approach to federated machine learning. These examples did not stem from AI Principles reviews, but reflect the adoption of the AI Principles across Google.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Tools and research</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In early 2022, to offer easier access to our publications on responsible AI, we curated an <a href=\"https://research.google/pubs/?collection=responsible-ai\">external collection</a> of more than 200 research papers focused on the topic. We continue to launch, refine and consolidate technical resources, including proactive tools like:</p><ul><li>The <a href=\"https://skintone.google/\">Monk Skin Tone Scale</a>, developed by Harvard University Sociology Professor Dr. Ellis Monk. The scale offers a spectrum of skin tones from all around the world for use in evaluating and addressing fairness considerations in AI.</li><li>The <a href=\"https://knowyourdata.withgoogle.com/\">Know Your Data</a> tool (KYD), which helps developers with tasks such as quickly identifying issues in fairness, and which has integrated the Monk Scale to help developers examine skin tone data for unfair bias.</li><li>The <a href=\"https://pair-code.github.io/lit/\">Language Interpretability Tool</a>, or LIT, to help developers probe an ML model, now with a <a href=\"https://arxiv.org/abs/1711.11279\">new method</a> to better understand, test and debug its behaviors.</li><li><a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview?hl=en\">Counterfactual Logit Pairing</a>, which helps ensure that a model\u2019s prediction doesn\u2019t change when sensitive attributes or identity terms referenced in an example are removed or replaced, now added to the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation\">TensorFlow Model Remediation Library</a> (see the <a href=\"https://arxiv.org/abs/1809.10610\">research paper</a> for more).</li><li>And to help teams measure their progress against the AI Principles, we\u2019re piloting an internal tool to help teams assess how ML models were developed in accordance with emerging smart practices, previous reviews, and our growing body of ethics, fairness, and human-rights work.</li></ul></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Many responsible AI tools developed by researchers are actively in use by product teams at Google. For example, Photos, Pixel and Image Search are leveraging the Monk Skin Tone Scale.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>External engagement</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Ensuring the responsible development and deployment of AI is an ongoing process. We believe it should be a collaborative one, too, so we remain deeply engaged with governments across Europe, the Middle East and Africa, Latin America, Asia Pacific, and the U.S. to advocate for AI regulation that supports innovation around the world for businesses of all sizes. We share our approach to responsible AI and <a href=\"https://ai.google/static/documents/google-response-to-nist-ai-risk-management-framework-rfi.pdf\">recommendations</a>, <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2662492_en\">comments</a> and <a href=\"https://ai.google/static/documents/google-ostp-biometrics-rfi.pdf\">responses</a> to open requests for information. We also initiated and are leading an effort with the <a href=\"https://www.iso.org/home.html\">International Standards Organization</a> (ISO/IEC PWI TS 17866) to share best practice guidance for the development of AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As these efforts look toward the future, Responsible AI needs to be supported across industries today. So for current Google Cloud Partners and customers seeking best practices to help with the responsible implementation and AI governance in their organization, we added responsible AI prerequisites to the Google Cloud Partner Advantage <a href=\"https://cloud.google.com/find-a-partner/?specializations=Machine%20Learning%20-%20Services\">ML Specialization</a>, including a newly-released training, \u201c<a href=\"https://www.cloudskillsboost.google/course_templates/388\">Applying AI Principles with Google Cloud</a>.\u201d</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To help nurture the next generation of responsible AI practitioners, we launched a free <a href=\"https://blog.google/technology/ai/discover-ai-in-daily-life/\">introduction</a> to AI and machine learning for K-12 students. And we continue to develop an external Responsible Innovation Fellowship program in the U.S. for students at Historically Black Colleges and Universities (HBCUs).</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our approach to responsible innovation also means keeping an eye on emerging markets where AI is being developed. We launched a new <a href=\"https://blog.google/technology/ai/investing-in-eastern-europes-ai-future/\">AI research center in Bulgaria</a> and expanded <a href=\"https://blog.google/around-the-globe/google-africa/supporting-growth-in-africa/\">support for African entrepreneurs</a> whose businesses use AI through our <a href=\"https://startup.google.com/accelerator/africa/\">Google for Startups Accelerator: Africa</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>The examples we\u2019re sharing today are a sampling of our ongoing commitment to responsible innovation. They also reflect our ability to change and keep setting a high bar for trustworthy AI standards for our company. We remain dedicated to sharing helpful information on Google\u2019s journey, as recommended practices for responsible AI continue to emerge and evolve.</p></div></div>", "pubdate": "Wed, 06 Jul 2022 18:00:00 +0000", "pubdate_parsed": 1657110600.0, "email_sent": true}}, "OpenAI Blog": {"DALL\u00b7E 2: Extending Creativity": {"url": "https://openai.com/blog/dall-e-2-extending-creativity/", "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>As part of our DALL&#xb7;E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL&#xb7;E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL&#xb7;E and have served as</p></div>", "pubdate": "Thu, 14 Jul 2022 16:30:22 GMT", "pubdate_parsed": 1657796422.0, "email_sent": true}, "Reducing Bias and Improving Safety in DALL\u00b7E 2": {"url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/", "description": "<!--kg-card-begin: markdown--><p>Today, we are implementing a new technique so that DALL&#xb7;E generates images of people that more accurately reflect the diversity of the world&#x2019;s population. This technique is applied at the system level when DALL&#xb7;E is given a prompt describing a person that does not</p>", "pubdate": "Mon, 18 Jul 2022 16:30:23 GMT", "pubdate_parsed": 1658142023.0, "email_sent": true}, "DALL\u00b7E Now Available in Beta": {"url": "https://openai.com/blog/dall-e-now-available-in-beta/", "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>We&#x2019;ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL&#xb7;E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.</p>\n<div class=\"btns mb-0.5\">\n<a class=\"btn btn-padded btn-dark btn-circle icon-external right\" href=\"https://labs.openai.com/waitlist\">Join DALL&#xb7;E 2 waitlist</a>\n</div>\n</div>\n<p><a href=\"https://openai.com/dall-e-2/\">DALL&#xb7;E</a>, the AI system that</p>", "pubdate": "Wed, 20 Jul 2022 16:29:05 GMT", "pubdate_parsed": 1658314745.0, "email_sent": true}}, "Apple Machine Learning Blog": {"Dynamic Memory for Interpretable Sequential Optimisation": {"url": "https://machinelearning.apple.com/research/dynamic-memory", "description": "Real-world applications of reinforcement learning for recommendation and experimentation faces a practical challenge: the relative reward of different bandit arms can evolve over the lifetime of the learning agent. To deal with these non-stationary cases, the agent must forget some historical knowledge, as it may no longer be relevant to minimise regret. We present a solution to handling non-stationarity that is suitable for deployment at scale, to provide business operators with automated adaptive optimisation. Our solution aims to provide interpretable learning that can be trusted by humans\u2026", "pubdate": "Fri, 01 Jul 2022 16:39:17 GMT", "pubdate_parsed": 1656673757.0, "email_sent": true}, "Style Equalization: Unsupervised Learning of Controllable Generative Sequence Models": {"url": "https://machinelearning.apple.com/research/unsupervised-learning", "description": "Controllable generative sequence models with the capability to extract and replicate the style of specific examples enable many applications, including narrating audiobooks in different voices, auto-completing and auto-correcting written handwriting, and generating missing training samples for downstream recognition tasks. However, under an unsupervised-style setting, typical training algorithms for controllable sequence generative models suffer from the training-inference mismatch, where the same sample is used as content and style input during training but unpaired samples are given during\u2026", "pubdate": "Fri, 01 Jul 2022 16:41:20 GMT", "pubdate_parsed": 1656673880.0, "email_sent": true}, "Speech Emotion: Investigating Model Representations, Multi-Task Learning and Knowledge Distillation": {"url": "https://machinelearning.apple.com/research/investigating-model-representations", "description": "Estimating dimensional emotions, such as activation, valence and dominance, from acoustic speech signals has been widely explored over the past few years. While accurate estimation of activation and dominance from speech seem to be possible, the same for valence remains challenging. Previous research has shown that the use of lexical information can improve valence estimation performance.\nLexical information can be obtained from pre-trained acoustic models, where the learned representations can improve valence estimation from speech. We investigate the use of pre-trained model representations\u2026", "pubdate": "Mon, 11 Jul 2022 20:59:50 GMT", "pubdate_parsed": 1657553390.0, "email_sent": true}, "ICML 2022": {"url": "https://machinelearning.apple.com/updates/apple-at-icml-2022", "description": "<p>Apple is sponsoring the International Conference on Machine Learning (ICML) which will be held in Baltimore, Maryland from July 17 to 23. ICML is a conference dedicated to the advancement of machine learning.</p>", "pubdate": "Mon, 11 Jul 2022 20:05:05 GMT", "pubdate_parsed": 1657550105.0, "email_sent": true}, "Private Frequency Estimation via Projective Geometry": {"url": "https://machinelearning.apple.com/research/private-frequency-estimation", "description": "In this work, we propose a new algorithm ProjectiveGeometryResponse (PGR) for locally differentially private (LDP) frequency estimation. For a universe size of  and with  users, our -LDP algorithm has communication cost  bits in the private coin setting and  in the public coin setting, and has computation cost  for the server to approximately reconstruct the frequency histogram, while achieving the state-of-the-art privacy-utility tradeoff. In many parameter settings used in practice this is a significant improvement over the  computation cost that is achieved by the recent PI-RAPPOR algorithm\u2026", "pubdate": "Mon, 11 Jul 2022 22:04:39 GMT", "pubdate_parsed": 1657557279.0, "email_sent": true}, "Efficient Representation Learning via Adaptive Context Pooling": {"url": "https://machinelearning.apple.com/research/efficient-representation", "description": "Self-attention mechanisms model long-range context by using pairwise attention between all input tokens. In doing so, they assume a fixed attention granularity defined by the individual tokens (e.g., text characters or image pixels), which may not be optimal for modeling complex dependencies at higher levels. In this paper, we propose ContextPool to address this problem by adapting the attention granularity for each token. Inspired by the success of ConvNets that are combined with pooling to capture long-range dependencies, we learn to pool neighboring features for each token before computing\u2026", "pubdate": "Mon, 11 Jul 2022 20:02:24 GMT", "pubdate_parsed": 1657549944.0, "email_sent": true}, "Self-Conditioning Pre-Trained Language Models": {"url": "https://machinelearning.apple.com/research/self-conditioning-pre-trained", "description": "In this paper we aim to investigate the mechanisms that guide text generation with pre-trained Transformer-based Language Models (TLMs). Grounded on the Product of Experts formulation by Hinton (1999), we describe a generative mechanism that exploits expert units which naturally exist in TLMs. Such units are responsible for detecting concepts in the input and conditioning text generation on such concepts. We describe how to identify expert units and how to activate them during inference in order to induce any desired concept in the generated output. We find that the activation of a\u2026", "pubdate": "Mon, 11 Jul 2022 21:19:31 GMT", "pubdate_parsed": 1657554571.0, "email_sent": true}, "Position Prediction as an Effective Pre-training Strategy": {"url": "https://machinelearning.apple.com/research/position-prediction", "description": "Transformers  have gained increasing popularity in a wide range of applications, including Natural Language Processing (NLP), Computer Vision and Speech Recognition, because of their powerful representational capacity. However, harnessing this representational capacity effectively requires a large amount of data, strong regularization, or both, to mitigate overfitting. Recently, the power of the Transformer has been unlocked by self-supervised pretraining strategies based on masked autoencoderswhich rely on reconstructing masked inputs, directly, or contrastively from unmasked content. This\u2026", "pubdate": "Mon, 11 Jul 2022 21:39:05 GMT", "pubdate_parsed": 1657555745.0, "email_sent": true}, "ARtonomous: Introducing Middle School Students to Reinforcement Learning Through Virtual Robotics": {"url": "https://machinelearning.apple.com/research/reinforcement-learning-robotics", "description": "Typical educational robotics approaches rely on imperative programming for robot navigation. However, with the increasing presence of AI in everyday life, these approaches miss an opportunity to introduce machine learning (ML) techniques grounded in an authentic and engaging learning context. Furthermore, the needs for costly specialized equipment and ample physical space are barriers that limit access to robotics experiences for all learners. We propose ARtonomous, a relatively low-cost, virtual alternative to physical, programming-only robotics kits. With ARtonomous, students employ\u2026", "pubdate": "Wed, 20 Jul 2022 17:23:26 GMT", "pubdate_parsed": 1658318006.0, "email_sent": true}, "KDD 2022": {"url": "https://machinelearning.apple.com/updates/apple-at-kdd-2022", "description": "<p>Apple is sponsoring the 28th annual ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). KDD will be held in Washington D.C. from August 14  to 18. It is an interdisciplinary conference bringing together researchers and practitioners from data science, data mining, knowledge discovery, large-scale data analytics, and big data.</p>", "pubdate": "Fri, 29 Jul 2022 02:34:27 GMT", "pubdate_parsed": 1659042267.0, "email_sent": true}}, "Towards AI Blog": {"Neural Entity Linking in JPMorgan Chase": {"url": "https://towardsai.net/p/l/neural-entity-linking-in-jpmorgan-chase", "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Harshit Sharma Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Neural Entity Linking at JPMorgan\u00a0Chase JPMC published a paper in 2021 highlighting their approach to Entity Linking. This article summarizes the problem statement, solution, and other key technical components of the\u00a0paper What is Entity\u00a0Linking? It&#039;s the task of assigning a unique identity to ambiguous mentions of named entities in a\u00a0text. An example of an entity linking from Wikipedia Here, \u201cParis\u201d from the text is given a unique identity via a URL (the most common type of URI) \u201cwikipedia.org/wiki/Paris\u201d. Note that the type of URI used to identify the mentioned entity depends on the domain uniquely. For eg, Instead of a web address, we could have used ISBNs if we were to identify books from a\u00a0text. JPMC was interested in\u00a0: Mapping mentions of financial institutions from news articles to the entities stored in their internal knowledge base (stored as a Knowledge Graph) An example is shown\u00a0below: Example of Entity Linking from the\u00a0paper There are two sub-problems that must be\u00a0defined: Recognition: Extraction of mentions from financial news articles. JPMC has used Spacy for\u00a0this. Linking:Choosing the correct entity from the internal Knowledge Graph to be linked to the extracted mentions in the previous step. The paper discusses this\u00a0step. A pictorial representation of this is shown\u00a0below: (Image by Author) Sub-problems as part of the overall\u00a0solution String MatchingThese approaches capture the \u201cmorphological\u201d structure of the entity names. The team experimented with (a) Jaccard(b) Levenshtein(c) Ratcliff-Obershelp (also known as Gestalt-Pattern-Matching)(d) Jaro Winkler(e) N-Gram Cosine Similarity The con of these approaches is that they focus just on the \u201csyntactics\u201d of the names and not the semantics. An example of a failure case would be the matching of \u201cLumier\u201d and \u201cLumier\u201d. Even though they are exactly the same, they refer to two different entities. 2. Context Similarity MethodsThese methods take the contexts around mentions and entities to give a similarity score.The Context for \u201cmention\u201d is text to the left and right of the mention, whereasthe Context for \u201centity\u201d is all the data that&#039;s stored in the KG for this entity.Finally, Cosine similarity / Jaccard similarity can be used on top of the context\u00a0vectors. 3. ML ClassificationNaive Bayes, Logistic Regression, and SVM are trained on (mention, entity) pairs to find the ones that should be\u00a0linked 4. Learn to Rank Methods (LTR)These models work in tandem with ML approaches, which might give us multiple (mention, entity) pairs as the solutions. LTR approaches just narrow down to the most probable solution. The idea is to capture both Semantic distance(the meaning that the mention or entity stands for) and Syntactic distance (character composition of the name) between the names and use a contrastive loss function to train a\u00a0model. We will see below how both of these distances are calculated step by\u00a0step. Step 1: Obtain embeddings for Entities and\u00a0Mentions To come up with both of the distances, the authors have proposed to use embeddings for mentions as well as entities in the\u00a0KG. To obtain Entity embeddings, the authors have used a Triplet Loss function (shown\u00a0below) Triplet Loss\u00a0Function For each entity, they used 10 positive and 10 negative samples, making 10 &#60;entity, positive word, negative word&#62; triplets. Model for Entity embedding Unlike Entity embeddings, which they had precomputed, the mention embeddings were trained using the on-the-go embeddings approach, where the embedding matrix is learned during the training\u00a0itself. Step 2: Calculate Syntactic Distance\u00a0score Before going further, it&#039;s worth mentioning \u201cWide &#38; Deep\u201d architecture which was introduced by Google in 2016. You can find their official blog here. We won\u2019t go into the details, but to give a summary, it&#039;s an architecture that has two components\u200a\u2014\u200aThe Wide component and the Deep component. Image from Google\u2019s paper &#124; Spectrum of Wide and Deep\u00a0Models Syntactic Distance score calculation is done using the WIDE part, which consists of a Linear Siamese\u00a0Network. Calculation of Syntax Distance\u00a0score The output of the siamese network is the vectors for both the entity and the mention, which are then compared to find the Euclidean distance. Step 3: Calculate Semantic Distance\u00a0score Semantic Distance score calculation is done using the DEEP\u00a0part Calculation of Semantic Distance\u00a0score e\u2096 is the pre-trained embedding for the \u201cApache Corp\u201d that was calculated in Step 1. To obtain the embedding for the mention, its left and right context words are fed into a Bi-LSTM network that trains the embeddings. The embedding vectors of mention (V\u2098) and the entity (V\u2091) are then used to find the Euclidean distance: Step 4: Compute Contrastive Loss Both Syntactic and Semantic distances are combined in a weighted fashion as\u00a0follows: The contrastive loss function is then combined as\u00a0follows: Contrastive Loss\u00a0Function where Y is the ground truth value, where a value of 1 indicates that mention m and entity e are matched, 0 otherwise. Combining all the pieces, the final model framework is shown\u00a0below: JEL Model Framework At the time of writing this paper, JPMC was still in the process of deploying the model, which, once done, will help support users across JPMC in discovering relevant and curated news that matters to their business. From the cost perspective, not all the mentions are fed through the JEL framework as that would be computationally expensive. JPMC has put another blocking layer to funnel out the mentions that share less than 2 bigrams with the entities from their internal\u00a0KGs. Once again, here is the paper link if you would like to read the full\u00a0paper. Follow Intuitive Shorts (my Substack newsletter), to read quick and intuitive summaries of ML/NLP/DS concepts. Neural Entity Linking in JPMorgan Chase was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. [&#8230;]", "pubdate": "Tue, 02 Aug 2022 20:18:56 +0000", "pubdate_parsed": 1659451736.0, "email_sent": true}, "GANs for Synthetic Data Generation": {"url": "https://towardsai.net/p/l/gans-for-synthetic-data-generation", "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Varatharajah Vaseekaran Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A practical guide to generating synthetic data using open-sourced GAN implementations The advancements in technology have paved the way for generating millions of gigabytes of real-world data in a single minute, which would be great for any organization or individual in utilizing the data. However, a large amount of time and resources would be consumed in cleaning, processing, and extracting vital information from the mounds of\u00a0data. The answer to handling such a problem is by generating synthetic data. Photo by Vackground on Unsplash. Contents What is Synthetic Data? A Brief Introduction to\u00a0GANs Mode Collapse Wasserstein GAN\u00a0(WGAN) Implementing a GAN for Synthetic Data Generation The Dataset Designing and Training the Synthesizer Final Words References What is Synthetic Data? Photo generated using DALL-E by\u00a0author. The definition for synthetic data is quite straightforward: artificially generated data that mimics real-world data. Organizations and individuals can leverage the use of synthetic data to their needs and would be able to generate data, according to their specifications, as much as they\u00a0require. The use of synthetic data is highly beneficial in preserving privacy in information-sensitive domains: the medical data of the patients and transactional details of banking customers are a few examples where synthetic data can be used to mask the real data, which would enable sharing of sensitive data among organizations. Few well-labeled data can be used to generate a large amount of synthetic data, which would fast-track the time and energy needed to process the massive real-world data. There are many ways of generating synthetic data: SMOTE, ADASYN, Variational AutoEncoders, and Generative Adversarial Networks are a few techniques for synthetic data generation. This article will focus on using Generative Adversarial Networks to generate synthetic data and a practical demonstration of generating synthetic data using open-sourced libraries. A Brief Introduction to\u00a0GANs Generating photorealistic faces using GANs based on StyleGAN3 research. Image from\u00a0[1]. Many machine learning and deep learning architectures are prone to adversarial manipulation, that is, the models fail when data that is different to the one that is used to train is fed. To solve the adversarial problem, Generative Adversarial Networks (GANs) were introduced by Ian Goodfellow [2], and currently, GANs are very popular in generating synthetic data. A typical GAN consists of two components: generator and discriminator, where both networks compete with each\u00a0other. The generator is the heart of the GAN, where it attempts to generate fake data that looks real by learning the features from the real\u00a0data. The discriminator evaluates the generated data with the real data and classifies whether the generated data looks real or not, and provides feedback to the generator to improve its data generation. The goal of the generator is to generate data that can trick the discriminator. A Vanilla GAN architecture. Image from\u00a0[3]. Mode Collapse Mode collapse is a common problem that GAN-based architectures face during adversarial training, where the generator repeatedly generates one specific type of data. This occurs when the generator identifies that it can fool the discriminator with one type of data, the generator would keep on generating that same\u00a0data. This problem can easily go undetected, as the metrics would indicate the model training is running smoothly, but the generated results would indicate otherwise. An example of mode collapse in image-based GANs. Image from\u00a0[4]. Wasserstein GAN\u00a0(WGAN) The main problem in a standard GAN is the difference in complexity of the outputs from the generator and the discriminator. A standard Vanilla GAN uses the Binary Cross Entropy (BCE)loss function [5] to evaluate whether the generated data looks real, where the output of the loss function is between 0 and 1. The task of the generator is to generate synthetic data that might have a lot of features and values, and the output from the discriminator is not sufficient for the generator to learn, and due to the lack of guidance, the generator can easily fall into mode collapse. WGAN [6] alleviates the problem by replacing the discriminator with a critic, where the critic would evaluate the distribution of the real data with the distribution of the generated data and outputs a score of how real the generated data looks when compared to the real data. The Wasserstein loss function utilized in WGAN measures the difference between the real distribution and the generated distribution based on the Earth Mover\u2019s Distance. Visualization of Earth Mover\u2019s Distance. Image from Coursera course\u00a0[8] Earth Mover\u2019s Distance measures the effort that is needed to make the distribution of the generated data look similar to the real data\u2019s distribution. Therefore, there is no limitation on the value that is output. That is, if both distributions are far apart, the Earth Mover\u2019s Distance will give a real positive value, whereas the BCE loss would output gradient values that are closer to zero. Therefore, the Wasserstein loss function enables solving the vanishing gradient problem during training. The expression of Wasserstein Loss. Image from Coursera course\u00a0[8]. The above picture denotes the equation for the Wasserstein loss, which is relatively simple compared to the BCE loss. The initial part of the equation is the expected value of the prediction that the critic provides on the real data. The second part of the equation is the expected value of the prediction that the critic provides on the generated data. The goal of the critic is to maximize the distance between the real and generated data, and the goal of the generator is to minimize that difference. Difference between BCE (left) and Wasserstein (right) losses. Image from Coursera course\u00a0[8]. WGANs are prone to exploding gradient problems, as the Wasserstein loss outputs any value that is positive and real; therefore, the value of the [&#8230;]", "pubdate": "Tue, 02 Aug 2022 17:03:39 +0000", "pubdate_parsed": 1659440019.0, "email_sent": true}, "Sports Analytics 101\u200a\u2014\u200aExpected Threats (xT)": {"url": "https://towardsai.net/p/l/sports-analytics-101%e2%80%8a-%e2%80%8aexpected-threats-xt", "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Nitin Chauhan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Sports Analytics 101\u200a\u2014\u200aExpected Threats\u00a0(xT) The threat of a goal being conceded or a threat of an opposition scoring a goal through play. Courtesy: Image via Omar\u00a0Ram As part of the introduction series on sports analytics for beginners, I am writing a series of articles examining the impact and benefits of machine learning and data analytics. Throughout my life as an aspiring data scientist, I have always sought out guides that would help me gain a deeper understanding of sports analytics. In the years that I have spent researching and attending courses, I have come up with the concept of a guide titled Sports Analytics 101. My hope is that this guide will assist people like myself in better understanding and appreciating sports + data analytics. Why Expected Threat\u00a0(xT)? From coaches to scouts to fans, one of the critical questions is how we evaluate the quality of a player based on data. We now understand that scoring many goals means they are good, and finding good scoring opportunities (having a high xG) is also essential. How do we value all those passes, dribbles, blocks, and interceptions? A concept called expected Threat has been adopted by Athletic when discussing player and team performance. An example of such a probability map is provided below, which assigns a value to every point on a football field based on the probability that having the ball there will result in a\u00a0goal. A zonal grid of football pitches with each zone being allocated an expected threat probability. What is the Expected Threat\u00a0(xT)? According to the expected threat model, matches are divided into possessions, which are periods in which the same team owns the ball. According to xT, (1) players act intentionally to increase the chances of scoring for their team, and (2) the chance of scoring can be adequately captured by considering only the ball\u2019s location. As a result of point (2), xT represents a game state solely by utilizing the current ball location. As a result, xT overlays a grid of M*N points over the pitch to divide it into zones. In the figure below, xT(z) is illustrated as a result of how threatening teams are at each zone\u00a0z. This chart shows the Expected Threat for different parts of the pitch. It shows how likely a goal will be scored, given that the team has possession at that location. Expected Threat (xT) is calculated from the middle of the pitch. The movement towards the goal is more likely than the shot being conceded from that position; Courtesy: Image via Karun\u00a0Singh Expected Threat (xT) is calculated near the penalty box. There\u2019s a higher chance of a goal being conceded by a team around that zone by the opposition; Courtesy: Image via Karun\u00a0Singh We evaluate actions based on their effect on the probability of scoring. The expected Threat (xT) is defined as the change in the likelihood of scoring. The player has increased the xT in favor of their team if they make a pass that moves the ball from a place where their team is unlikely to score to a place where they have a greater probability of scoring. There is a general rule that the closer you are to the goal, the more likely your team will score (although passes back to the goalkeeper can also be very valuable). Utilizing the Expected Threat (xT)\u00a0metric Spaces are of greater value than others. The same is true on the football pitch. If you have the ball in your half, it is less valuable than if it is near the edge of your opponent\u2019s box. We know those two things intuitively, but how do we measure them? The expected threat (xT, for short) is an effective solution for this problem for various reasons. Not all attacks are connected. https://medium.com/media/9acff157cbe3a398218aee2c12d52c90/href It was Sarah Rudd, who invented Expected Threat in 2011. She did not call it that. She did not call it anything at all, but she had the mathematical insight, using Markov chains, on which it was based, which you can see in this video. On this basis, she was recruited by StatDNA, which Arsenal acquired shortly after. Karun Singh first used the name xT in a blog post in 2018, and it was then repurposed in the public\u00a0sphere. When we see a clear example of a female scientist coming up with the idea that is now being used everywhere in a male-dominated area, it is added essential to pause and let others know where it came from. Science has a history of forgetting women\u2019s contributions, and it would be embarrassing if we made the same mistake in football, especially in the modern\u00a0era. We should remember, therefore, that when we hear that Liverpool used expected goals added in recruitment during 2018\u201319 or that Opta and Statsbomb have their versions of expected Threat, this all came about because one very determined young woman went to as many sports analytics conferences as possible over the past ten years and pestered everyone she met until she gained one of the first jobs ever in football analytics. With that clarified, I would like to make a more subtle point. There are many ways to measure expected Threats, as compared to expected goals. Our methodology at Twelve Football differs from that outlined above. Moreover, it is better\u2026 (I am not saying that it is better than what Rudd used at Arsenal, but there has been much progress since her talk in 2011) But if you have, for example, Opta, Statbomb, or Wyscout event data, this is the best method for implementing xT. This is our logic. Football is a [&#8230;]", "pubdate": "Tue, 02 Aug 2022 16:38:59 +0000", "pubdate_parsed": 1659438539.0, "email_sent": true}, "Non-Linear Models": {"url": "https://towardsai.net/p/l/non-linear-models", "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Dr. Marc Jacobs Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. When the formula looks nice but is hurting the\u00a0analysis This is not my first blog concerning non-linear models. In fact, if you sift through my lists of blogs, you can see I applied quite a couple of them. Personally, I like non-linear models since they have a biological basis, and if you have data that does not connect to that basis, it can become quite a challenge to move further. As always, the first steps are the hardest, and nothing suits that premise better than a non-linear model. I will not dive into a talk about non-linear models, but what I will do is show you briefly my struggle with a dataset handed to me by another researcher. This is nutritional commercial data, so I cannot share the data itself, but you can see what I did. Also, the formula given to me is beyond my comprehension, but what I will show is that a perfect-looking formula can be quite difficult to work with if it fits the data too perfectly. Let&#039;s start by loading the libraries and the data. It is data coming from piglets, measured across\u00a0time. rm(list = ls())library(readr)library(nlstools)library(nlme)library(ggplot2)library(nls2) ## new file from TheoOral_data_for_Marc &#60;- read_delim(\"Oral data for Marc.csv\", \";\", escape_double = FALSE, trim_ws = TRUE)data&#60;-Oral_data_for_Marcrm(Oral_data_for_Marc)data&#60;-data[, 1:3]data&#60;-data[complete.cases(data),]head(data);str(data)as.numeric(gsub(\",\", \".\", gsub(\"\\\\.\", \"\", data$D9std)))data$D9std &#60;- gsub(\",\", \"\", data$D9std)data$D9std &#60;- as.numeric(data$D9std) data$D9std&#60;-data$D9std/1000000000data$Big&#60;-as.factor(data$Big) The data for each piglet (Big), time, and the outcome of interest. Now, the data was not easy to work with from the start, especially the outcome. It was loaded as a character, but I could not make a numeric on the spot, forcing me to do some transformations first. Transforming the\u00a0data. ggplot(data, aes(x=time, y=D9std, group=Big, col=Big))+ geom_point()+ geom_line()+ theme_bw()+ labs(x=\"Time\", y=\"Value\", col=\"Pig\" ) Plotting the data. I have nine piglets, showing data across time (seconds). The majority follow a distinct pattern, but not all, and this will cause our non-linear model some\u00a0trouble. Not only will the pathway cause issues, but also the beginning, which is why I cut a couple of seconds from the data. Let&#039;s see how the data will look\u00a0then. datasub&#60;-data[data$time&#62;=30,];head(datasub)colnames(datasub)[2]&#60;-\"x\" # time called xcolnames(datasub)[3]&#60;-\"y\" # D9std called ydatasub$Big&#60;-NULL # not informative vectordatasub&#60;-as.data.frame(datasub)datasub$y &#60;- gsub(\",\", \"\", datasub$y) datasub$y&#60;-as.numeric(datasub$y)head(data)head(datasub);str(datasub)plot(datasub$x, datasub$y) Not much better to be\u00a0honest. Now, it is time to look at the formula. As I said, this was handed to me, and I have no idea how somebody ever came up with such an elaborate formula. It truly is massive, with several compartments included. Below you see ways to connect the formula and how I test it to make sure I translated it correctly in\u00a0R. formulaExp&#60;-as.formula(y~P*(I(1-(exp(-(Ks*x))))^B)*(Ka*((exp(-(Ke*x)))-(exp(-(Ka*x))))/(Ka-Ke))) f1&#60;-function(x, P, Ks,B, Ka, Ke){ P*(I(1-(exp(-(Ks*x))))^B)*(Ka*((exp(-(Ke*x)))-(exp(-(Ka*x))))/(Ka-Ke))} f1(20, P=2.48, Ks=0.014, B=1.52, Ka=0.00059, Ke=0.00690) Gives a decent\u00a0value. The biggest hurdle in non-linear regression modeling is finding the exact values. Since non-linear models are not closed, the search goes iterative. One way of taking a peak is by plotting the data and overlaying several gradations of the\u00a0curve. plot(datasub$x, datasub$y)curve(f1(x, P=2.48, Ks=0.014, B=1.52, Ka=0.00059, Ke=0.00690), add=T, col=\"red\") curve(f1(x, P=3.5, Ks=0.014, B=1.52, Ka=0.00059, Ke=0.00690), add=T, col=\"green\") curve(f1(x, P=3.5, Ks=0.010, B=1.52, Ka=0.00059, Ke=0.00690), add=T, col=\"yellow\") curve(f1(x, P=3.5, Ks=0.010, B=1.52, Ka=0.00050, Ke=0.00590), add=T, col=\"blue\") curve(f1(x, P=3.5, Ks=0.010, B=1.42, Ka=0.00059, Ke=0.00690), add=T, col=\"orange\") curve(f1(x, P=3.0, Ks=0.010, B=1.62, Ka=0.00080, Ke=0.0090), add=T, col=\"purple\") This actually looks very, very nice! The curves follow the data in a splendid fashion. The formula IS quite complex, though but it works\u00a0wonders. A simple way of checking if the coefficients for each of the parameters, as chosen, come close to the average value seen in the data. This exercise was an additional check but not really necessary anymore considering the curves fitted\u00a0above. In R, there is a very nice package called NLStools, which will help you look at the data and offer functions to preview the coefficients you deem to be a good fit. Like I said before, that process is quite difficult, and unlike simple linear regression or mixed modeling, decent starting values are key in finding the solution. If there is\u00a0one. Residual Sums of Squares are provided which does not mean that much without comparison. However, considering the scale, it is still more than you would\u00a0like. The picture that belongs to the preview process. The model looks good, but the high Residual Sum of Squares is to be explained for\u00a0sure. Up until now, I have fed the formula a single or just a couple of scenarios. That is good if you know where to look but often you do not, so it is better to conduct a grid search. What this simply means is that you create a matrix of combinations and then let the model sift to\u00a0that. Below is the command for the grid and how it\u00a0looks. grid.theo&#60;-expand.grid(list(P=seq(2, 4, by=0.1), Ks=seq(0.010, 0.020, by=0.01), B=seq(1.4, 1.6, by=0.01), Ka=seq(0.005,0.007,by=0.01), Ke=seq(0.006,0.008, by=0.01))) grid.theo Then, it is time to feed the model the\u00a0grid. mod1 &#60;- nls2(formulaExp, data=datasub, start = grid.theo, algorithm = \"brute-force\")plot(mod1)nls2(formulaExp, data=datasub, start = mod1) I am getting a lot of\u00a0errors. However, the model does produce. You can see the formula, the coefficients, and the residual sum of squares of the model chosen. It looks a lot higher than the value I obtained from the last\u00a0preview. Now, there ARE other ways of using grid searches by connecting them directly to the model. Here, you see me going at it\u00a0again. f1_nls_fit &#60;- nls.multstart::nls_multstart(y ~ f1(x, P, Ks,B, Ka, Ke),data = datasub,lower=c(P=2, Ks=0.01, B=1.4, Ka=0.005, Ke=0.006),upper=c(P=4, Ks=0.02, B=1.6, Ka=0.007, Ke=0.008),start_lower = c(P=2, Ks=0.01, B=1.4, Ka=0.005, Ke=0.006),start_upper = c(P=4, Ks=0.02, B=1.6, Ka=0.007, Ke=0.008),iter = 500,supp_errors = \"Y\") summary(f1_nls_fit)plot(f1_nls_fit) plot_nls &#60;- function(nls_object, data) { predframe &#60;- tibble(x=seq(from=min(datasub$x), to=max(datasub$x), length.out = 1024)) %&#62;% mutate(ypred = predict(nls_object, newdata = list(x=.$x))) ggplot(data, aes(x=x, y=y)) + [&#8230;]", "pubdate": "Tue, 02 Aug 2022 16:33:53 +0000", "pubdate_parsed": 1659438233.0, "email_sent": true}, "Sports Analytics 101\u200a\u2014\u200aExpected Goals (xG)": {"url": "https://towardsai.net/p/l/sports-analytics-101%e2%80%8a-%e2%80%8aexpected-goals-xg", "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Nitin Chauhan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Sports Analytics 101\u200a\u2014\u200aExpected Goals\u00a0(xG) Courtesy: Image via Sven\u00a0Kucinic As part of the introduction series on sports analytics for beginners, I am writing a series of articles examining the impact and benefits of machine learning and data analytics. Throughout my life as an aspiring data scientist, I have always sought out guides that would help me gain a deeper understanding of sports analytics. In the years that I have spent researching and attending courses, I have come up with the concept of a guide titled Sports Analytics 101. My hope is that this guide will assist people like myself in better understanding and appreciating sports + data analytics. Why Expected Goals\u00a0(xG)? Over the past few years, football has become increasingly dependent on data and statistics. One of the most widely used and insightful football analytics metrics is expected goals (or xG). It was introduced by Opta\u2019s Sam Green in 2012 and has since become one of the most widely used\u00a0metrics. It has now become a regular feature for mainstream broadcasters such as Sky Sports and BBC\u2019s Match of the Day, following the early adoption of expected goals in the betting and professional markets. From the laptops of analysts to the mouths of Premier League managers, xG has gained popularity. In recent interviews, Jurgen Klopp has compared Liverpool\u2019s expected goals output with Manchester City\u2019s, while Dean Smith has used the metric to discuss Aston Villa\u2019s performance this\u00a0season. Over the past few years, expected goals have inevitably been criticized by general football fans who have become increasingly aware of it (see Jeff Stelling in 2017)\u200a\u2014\u200atraditionally viewed games versus the upcoming world of data analytics. However, before judging the metric, it is vital to comprehend how the metric operates and how it should be utilized. Expected Goal (xG) ratio for top strikers in Bundesliga season 2019/20; Courtesy: Image via\u00a0twenty3 What Are Expected Goals\u00a0(xG)? By calculating the probability that a given opportunity will be scored from a particular location on a pitch during a specific phase of play, expected goals (xG) are calculated to determine the quality of a chance. As a result of these calculations, several factors were taken into account before the shot was taken. In terms of xG, zero represents the likelihood that a player is unlikely to score, while one represents the likelihood that they are likely to score consistently. In such a situation, a player is less likely to score a goal from the halfway line than from within the box. By quantifying xG, we can assess the probability of a player scoring from each of these situations. As an example, assume that the chance of a player scoring inside the box with a set of pre-shot characteristics is worth 0.1 xG. Thus, in this situation, a player will likely score one goal out of every ten shots, or 10% of the\u00a0time. Football fans and commentators had used these phrases for years before xG was introduced\u200a\u2014\u200a\u201che scores that nine out of ten times\u201d or \u201che should have had a hat-trick.\u201d Standard Misinterpretations about\u00a0xG Most criticisms of expected goals (xG) arise from an incorrect metric application. One example of this is the game level. Having the highest xG in a match does not necessarily imply the team should have won. xG is a measure of chance quality, not the expected outcome. Goals change games, and scorelines influence how teams play, just as the old saying goes. If a team takes an early lead, they do not necessarily \u2018need\u2019 to generate more chances. We typically expect the opposition to create more scoring chances during the remainder of the game to make a comeback. Secondly, there is a misconception regarding the literal interpretation of the metric name. We do not \u201cexpect\u201d goals to occur precisely as the likelihood predicts. Additionally, fractions of goals cannot be achieved. A measure of the probability of an outcome occurring is known as an \u201cexpected goal,\u201d derived from the mathematical concept of \u201cexpected value.\u201d The expected value of a fair coin toss is 50% on heads and 50% on tails (the probability of landing on heads is 0.5). Rather than expecting exactly half of our tosses to land on each outcome, we anticipate a regress to this balance over a more significant number of coin tosses. Expected goals are no different. Variances from the expected values are inevitable, and this is valuable information we can utilize to analyze football\u00a0scores. As the Gambler\u2019s Fallacy indicates, if a player or team has been overperforming their xG, they do not need to underperform to regress to expectation. Even though we expect them to revert to scoring as they expected with their future shots, they have already \u2018banked\u2019 this overperformance. As a result, we should expect them to still overperform by this amount in the aggregates throughout the season. In the same way, a coin toss that lands on heads ten times in a row is equally likely to land on heads as tails in the future, but the ten times it has already landed on heads are already behind\u00a0us. Calculating the Expected Goals\u00a0(xG) We can tell intuitively which chances were more or less likely to end in goals based on factors such as how close the shooter was to the goal, whether they shot from a good angle, whether it was one-on-one or whether it was a\u00a0header. As a result, we have to work out the probability for an average of 25 shots per game, all of which can be the result of unique circumstances. We can now quantify the effects of the variables above and others on the likelihood that a goal will be [&#8230;]", "pubdate": "Tue, 02 Aug 2022 16:33:50 +0000", "pubdate_parsed": 1659438230.0, "email_sent": true}, "This AI newsletter is all you need #6": {"url": "https://towardsai.net/p/newsletter/this-ai-newsletter-is-all-you-need-6", "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Towards AI Editorial Team &#160; Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. We are excited to announce that we will partner with the MineRL competition we shared a few weeks ago and host a Q&#38;A on the server with one of the organizers/deep mind researchers/Open AI VPG paper team involved in the MineRL competition. We created a Discord channel for you to ask any questions to someone working at DeepMind/OpenAI and we will select the most interesting questions to ask in our next podcast and/or interview. So if you are interested in OpenAI or DeepMind, but do not know much about what it\u2019s like to work there or even be hired there, join the conversation and ask your question! What happened this week in\u00a0AI Tons of exciting news this week\u200a\u2014\u200abut the one that stands out is DeepMind\u2019s new blog post where they announced that their AlphaFold 2 model predicted structures for nearly all proteins known to science. Yes, you read that right. DeepMind expanded its protein database by over 200x to over 200 million predicted structures that other scientists will use to better understand specific proteins, what they do and how they work, accelerating scientific research and discovery globally\u200a\u2014\u200aallowing to create further breakthroughs. This is a big deal for the scientific community as \u201cAlphaFold has been accessed by more than half a million researchers and used to accelerate progress on important real-world problems ranging from plastic pollution to antibiotic resistance,\u201d now expanding this knowledge base by 200x with the model\u2019s second\u00a0version. Hottest News DeepMind predicted structures for nearly all cataloged proteins known to science DeepMind predicted structures for nearly all cataloged proteins known to science. It will expand the AlphaFold database by over 200x\u200a\u2014\u200afrom nearly 1 million structures to over 200 million structures. DeepSpeed Compression: A composable library for extreme compression and zero-cost quantization Microsoft Research open-sourced DeepSpeed Compression, a framework for compression and system optimization in deep learning models, learn more\u00a0here. Building AI models on mobile? This may be for you! PyTorch open-sourced the PlayTorch app to streamline the development of mobile AI experiences. Most interesting papers of the\u00a0week Translating a Visual LEGO Manual to a Machine-Executable Plan A novel learning-based framework, the Manual-to-Executable Plan Network (MEPNet), which reconstructs the assembly steps from a sequence of manual images, taking a LEGO manual and creating a machine executable plan that can be executed to build the target shape (see image\u00a0above). Audio-driven Neural Gesture Reenactment with Video Motion Graphs A method that reenacts a high-quality video with gestures matching a target speech audio from a video &#38; audio source, splitting and re-assembling clips from a reference video through a novel video motion graph encoding valid transitions between\u00a0clips. Panoptic Scene Graph Generation They \u201cintroduce panoptic scene graph generation (PSG), a new problem task that requires the model to generate a more comprehensive scene graph representation (see image above) based on panoptic segmentations rather than rigid bounding boxes,\u201d which they say causes several problems that impede the progress of the field. They created a high-quality PSG dataset, containing 49k well annotated overlapping images from COCO and Visual Genome, for the community to keep track of its progress. Check out the\u00a0code Enjoy these papers and news summaries? Get a daily recap in your\u00a0inbox! The Learn AI Together Community section! Meme of the\u00a0week! Once again, a meme shared by one of our fantastic moderators, Ian Yu. Join the conversation and share your memes with\u00a0us! Featured Community post from the\u00a0Discord Another event was organized by a member of the community! Shared by @Zakrz#2739, Cohere AI Hackathon has workshops, keynotes, and mentoring sessions aiming to build with one of the world\u2019s most powerful artificial intelligence language\u00a0models. Join the event happening from August 19 through August\u00a021. AI poll of the\u00a0week! What do you think? Join the discussion on\u00a0Discord. TAI Curated\u00a0section Article of the\u00a0week Data Science Essentials\u200a\u2014\u200aMulticollinearity: This article explains multicollinearity. Multicollinearity may not seem like the most critical topic to grasp, but it is an important widespread concept for machine learning practitioners. The ability of an ML model to find independent variables that are statistically significant for prediction is diminished by high correlations between two or more independent variables. The author provides the most intuitive explanations of types of multicollinearity, causes of multicollinearity, and multicollinearity detection and management. This week we published 24 new articles and welcomed six new writers to our platform. If you are interested in writing for us at Towards AI, please sign up here and we will publish your blog to our network if it meets our editorial policies and standards. https://contribute.towardsai.net/ Lauren\u2019s Ethical Take on DeepMind\u2019s AlphaFold 2 Expansion What an incredible advancement! AlphaFold 2 has cataloged the structure of nearly every known protein. This freshly released dataset is open to anyone, and will soon be completely bulk downloadable through Google Cloud Public Datasets. This is incredibly exciting, and the ethical implications are vast and varied. There is, of course, the proven effects and massive potential of reducing some of the greatest causes of suffering we face today and in the future, such as understanding and treating unique genetic diseases, addressing ecosystem health and biodiversity loss, and improving food supply. While this is a cause for both celebration and optimism, there is also potential for abuse that should be considered and mitigated, such as the creation of targeted biological weaponry using the database. DeepMind will have to decide what that mitigation looks like, but so far, their partnerships and respective advancements demonstrate a trend towards positive outcomes. I want to highlight a passage from the conclusion of DeepMind\u2019s blog post on the\u00a0release: \u201cJust as maths is the perfect description language for physics, we believe AI might [&#8230;]", "pubdate": "Tue, 02 Aug 2022 16:28:39 +0000", "pubdate_parsed": 1659437919.0, "email_sent": true}}, "Louis Bouchard Blog": {"No Language Left\u00a0Behind": {"url": "https://www.louisbouchard.ai/no-language-left-behind/", "description": "Translating 200 languages with a single model\u200a-\u200aMeta\u00a0AI", "pubdate": "Wed, 06 Jul 2022 13:11:04 GMT", "pubdate_parsed": 1657093264.0, "email_sent": true}, "What is data-centric AI?": {"url": "https://www.louisbouchard.ai/data-centric-ai/", "description": "The beginning of data-centric AI with data programming", "pubdate": "Fri, 08 Jul 2022 00:11:13 GMT", "pubdate_parsed": 1657219273.0, "email_sent": true}, "CVPR 2022 Best Paper Honorable Mention: Dual-Shutter Optical Vibration Sensing": {"url": "https://www.louisbouchard.ai/cvpr-2022-best-paper/", "description": "They reconstruct sound using cameras and a laser beam on any vibrating surface, allowing them to isolate music instruments, focus on a specific speaker, remove ambient noises, and many more amazing applications.", "pubdate": "Wed, 13 Jul 2022 13:36:57 GMT", "pubdate_parsed": 1657699617.0, "email_sent": true}, "How OpenAI Reduces risks for DALL\u00b7E\u00a02": {"url": "https://www.louisbouchard.ai/how-openai-reduces-risks-for-dall-e-2/", "description": "DALL\u00b7E 2 Pre-Training Mitigations", "pubdate": "Sat, 16 Jul 2022 16:00:54 GMT", "pubdate_parsed": 1657967454.0, "email_sent": true}, "Produce Amazing Artworks with Text and Sketches!": {"url": "https://www.louisbouchard.ai/make-a-scene/", "description": "\"Make-A-Scene\": a fantastic blend between text and sketch-conditioned image generation.", "pubdate": "Tue, 19 Jul 2022 12:16:59 GMT", "pubdate_parsed": 1658213219.0, "email_sent": true}}, "Computational Intelligence Blog": {"IEEE Transactions on Fuzzy Systems, Volume 30, Issue 7": {"url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-fuzzy-systems.html", "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9419714/\">Novel Heterogeneous Mode-Dependent Impulsive Synchronization for Piecewise T-S Fuzzy Probabilistic Coupled Delayed Neural Networks</a></div><div><b>Author(s): </b>Xiangxiang Wang, Yongbin Yu, Shouming Zhong, Kaibo Shi, Nijing Yang, Dingfa Zhang, Jingye Cai, Nyima Tashi</div><div><b>Pages: </b>2142 - 2156</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9419710/\">Nonlinear Dimensionality Reduction for Data Visualization: An Unsupervised Fuzzy Rule-Based Approach</a></div><div><b>Author(s):&nbsp;</b>Suchismita Das, Nikhil R. Pal</div><div><b>Pages:&nbsp;</b>2157 - 2169</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9423589/\">An Efficient Self-Organizing Deep Fuzzy Neural Network for Nonlinear System Modeling</a></div><div><b>Author(s):&nbsp;</b>Gongming Wang, Junfei Qiao</div><div><b>Pages:&nbsp;</b>2170 - 2182</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9424990/\">Adaptive Event-Triggered Fuzzy Tracking Control of Uncertain Stochastic Nonlinear Systems With Unmeasurable States</a></div><div><b>Author(s):&nbsp;</b>Rui-Yan Zhang, Li-Bing Wu, Nan-Nan Zhao, Yan Yan</div><div><b>Pages:&nbsp;</b>2183 - 2196</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9425433/\">Membership Function, Time Delay-Dependent \u03b7-Exponential Stabilization of the Positive Discrete-Time Polynomial Fuzzy Model Control System</a></div><div><b>Author(s):&nbsp;</b>Xiaomiao Li, Kamyar Mehran, Zhiyong Bao</div><div><b>Pages:&nbsp;</b>2197 - 2209</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9425590/\">A Novel Three-Way Decision Model Based on Utility Theory in Incomplete Fuzzy Decision Systems</a></div><div><b>Author(s):&nbsp;</b>Jianming Zhan, Jin Ye, Weiping Ding, Peide Liu</div><div><b>Pages:&nbsp;</b>2210 - 2226</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9427360/\">Finite-Time Adaptive Fuzzy Prescribed Performance Control for High-Order Stochastic Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Shuai Sui, C. L. Philip Chen, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>2227 - 2240</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9427125/\">Maximum Number of Line Faults in a P2P Network System Based on the Addition-Min Fuzzy Relation Inequalities</a></div><div><b>Author(s):&nbsp;</b>Xiao-Peng Yang, Gengzhong Zheng</div><div><b>Pages:&nbsp;</b>2241 - 2253</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9427225/\">Sampled-Data-Based H\u221e Fuzzy Pinning Synchronization of Complex Networked Systems With Adaptive Event-Triggered Communications</a></div><div><b>Author(s):&nbsp;</b>Xin Wang, Ju H. Park, Huilan Yang, Zhiqi Yu</div><div><b>Pages:&nbsp;</b>2254 - 2265</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9428619/\">Analysis of Ranking Consistency in Linguistic Multiple Attribute Decision Making: The Roles of Granularity and Decision Rules</a></div><div><b>Author(s):&nbsp;</b>Sihai Zhao, Yucheng Dong, Luis Mart\u00edne, Witold Pedrycz</div><div><b>Pages:&nbsp;</b>2266 - 2278</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9428344/\">Adaptive Fast Finite-Time Fuzzy Control of Stochastic Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Zhaoyang You, Fang Wang</div><div><b>Pages:&nbsp;</b>2279 - 2288</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9428513/\">Model-Based Fuzzy l2\u2212l\u221e Filtering for Discrete-Time Semi-Markov Jump Nonlinear Systems Using Semi-Markov Kernel</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Yigang Zhang, Lei Su, Ju H. Park, Hao Shen</div><div><b>Pages:&nbsp;</b>2289 - 2299</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9430728/\">Adaptive Fuzzy SOSM Controller Design With Output Constraints</a></div><div><b>Author(s):&nbsp;</b>Shihong Ding, Binbin Zhang, Keqi Mei, Ju H. Park</div><div><b>Pages:&nbsp;</b>2300 - 2311</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9430676/\">Fault-Tolerant Quantized Sliding Mode Observers Design for a Class of Takagi-Sugeno Fuzzy System With Unmeasurable Premise Variable</a></div><div><b>Author(s):&nbsp;</b>Ang Li, Guangren Duan, Ming Liu, Jingbo Fu</div><div><b>Pages:&nbsp;</b>2312 - 2324</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9432713/\">Fuzzy Energy-to-Peak Filtering for Continuous-Time Nonlinear Singular System</a></div><div><b>Author(s):&nbsp;</b>Xiao-Heng Chang, Ming-Yang Qiao, Xudong Zhao</div><div><b>Pages:&nbsp;</b>2325 - 2336</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9435080/\">An Analytical Method to Compute the Approximate Inverses of a Fuzzy Matrix With Max-Product Composition</a></div><div><b>Author(s):&nbsp;</b>Yan-Kuen Wu, Yung-Yih Lur, Hsun-Chih Kuo, Ching-Feng Wen</div><div><b>Pages:&nbsp;</b>2337 - 2346</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9436023/\">Fuzzy Event-Triggered Integral Sliding Mode Control of Nonlinear Continuous-Time Systems</a></div><div><b>Author(s):&nbsp;</b>Zeinab Echreshavi, Mohsen Farbood, Mokhtar Shasadeghi</div><div><b>Pages:&nbsp;</b>2347 - 2359</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9435959/\">Fuzzy Measures and Choquet Integrals Based on Fuzzy Covering Rough Sets</a></div><div><b>Author(s):&nbsp;</b>Xiaohong Zhang, Jingqian Wang, Jianming Zhan, Jianhua Dai</div><div><b>Pages:&nbsp;</b>2360 - 2374</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9436033/\">Fast Fuzzy Clustering Based on Anchor Graph</a></div><div><b>Author(s):&nbsp;</b>Feiping Nie, Chaodie Liu, Rong Wang, Zhen Wang, Xuelong Li</div><div><b>Pages:&nbsp;</b>2375 - 2387</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9437688/\">Multilabel Feature Selection Based on Relative Discernibility Pair Matrix</a></div><div><b>Author(s):&nbsp;</b>Erliang Yao, Deyu Li, Yanhui Zhai, Chao Zhang</div><div><b>Pages:&nbsp;</b>2388 - 2401</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9439174/\">Quantized Guaranteed Cost Output Feedback Control for Nonlinear Networked Control Systems and Its Applications</a></div><div><b>Author(s):&nbsp;</b>Qunxian Zheng, Shengyuan Xu, Baozhu Du</div><div><b>Pages:&nbsp;</b>2402 - 2411</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9439896/\">Fuzzy Bayesian Knowledge Tracing</a></div><div><b>Author(s):&nbsp;</b>Fei Liu, Xuegang Hu, Chenyang Bu, Kui Yu</div><div><b>Pages:&nbsp;</b>2412 - 2425</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9440662/\">Dwell-Time-Dependent H\u221e Bumpless Transfer Control for Discrete-Time Switched Interval Type-2 Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Siyuan Zhang, Jun Zhao</div><div><b>Pages:&nbsp;</b>2426 - 2437</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9442351/\">Fuzzy Multioutput Transfer Learning for Regression</a></div><div><b>Author(s):&nbsp;</b>Xiaoya Che, Hua Zuo, Jie Lu, Degang Chen</div><div><b>Pages:&nbsp;</b>2438 - 2451</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9442297/\">Stability and Control of Fuzzy Semi-Markov Jump Systems Under Unknown Semi-Markov Kernel</a></div><div><b>Author(s):&nbsp;</b>Zepeng Ning, Bo Cai, Rui Weng, Lixian Zhang, Shun-Feng Su</div><div><b>Pages:&nbsp;</b>2452 - 2465</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9446576/\">New Results on Dissipative Control for a Class of Singular Takagi\u2013Sugeno Fuzzy Systems With Time Delay</a></div><div><b>Author(s):&nbsp;</b>Zhiguang Feng, Huayang Zhang, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>2466 - 2475</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9447197/\">Finite-Time Dynamic Event-Triggered Distributed H\u221e Filtering for T-S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaoyuan Zheng, Hao Zhang, Zhuping Wang, Changzhu Zhang, Huaicheng Yan</div><div><b>Pages:&nbsp;</b>2476 - 2486</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9447907/\">Asynchronous Fault Detection for Interval Type-2 Fuzzy Nonhomogeneous Higher Level Markov Jump Systems With Uncertain Transition Probabilities</a></div><div><b>Author(s):&nbsp;</b>Xiang Zhang, Hai Wang, Vladimir Stojanovic, Peng Cheng, Shuping He, Xiaoli Luan, Fei Liu</div><div><b>Pages:&nbsp;</b>2487 - 2499</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9448475/\">Fuzzy Community Detection Based on Elite Symbiotic Organisms Search and Node Neighborhood Information</a></div><div><b>Author(s):&nbsp;</b>Jing Xiao, Yan-Jiao Wang, Xiao-Ke Xu</div><div><b>Pages:&nbsp;</b>2500 - 2514</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9449989/\">Cooperative Target Enclosing of Ring-Networked Underactuated Autonomous Surface Vehicles Based on Data-Driven Fuzzy Predictors and Extended State Observers</a></div><div><b>Author(s):&nbsp;</b>Yue Jiang, Zhouhua Peng, Dan Wang, Yong Yin, Qing-Long Han</div><div><b>Pages:&nbsp;</b>2515 - 2528</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9454304/\">A Simplified Finite-Time Fuzzy Neural Controller With Prescribed Performance Applied to Waverider Aircraft</a></div><div><b>Author(s):&nbsp;</b>Xiangwei Bu, Qiang Qi, Baoxu Jiang</div><div><b>Pages:&nbsp;</b>2529 - 2537</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9454283/\">Stability Criteria for Fuzzy-Based Sampled-Data Control Systems via a Fractional Parameter-Based Refined Looped Lyapunov Functional</a></div><div><b>Author(s):&nbsp;</b>Lakshmanan Shanmugam, Young Hoon Joo</div><div><b>Pages:&nbsp;</b>2538 - 2549</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9454293/\">Distributed Kalman Filter With Fuzzy Noises Over Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Haoshen Lin, Chen Hu, Zhenhua Deng, Gang Liu</div><div><b>Pages:&nbsp;</b>2550 - 2562</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9454307/\">Self-Sustaining Oscillations With an Internal Two-Fuzzy Inference System Based on the Poincar\u00e9\u2013Bendixson Method</a></div><div><b>Author(s):&nbsp;</b>Jorge A. Lopez-Renteria, Lisdan Herrera-Garcia, Selene L. Cardenas-Maciel, Luis T. Aguilar, Nohe R. Cazarez-Castro</div><div><b>Pages:&nbsp;</b>2563 - 2573</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9454376/\">Admissibility and Design Issues for T-S Fuzzy Descriptor Systems With Perturbed Derivative Matrices in the Rules</a></div><div><b>Author(s):&nbsp;</b>Chih-Peng Huang</div><div><b>Pages:&nbsp;</b>2574 - 2582</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9454380/\">Guaranteed Cost Control for Interval Type-2 Fuzzy Semi-Markov Switching Systems Within a Finite-Time Interval</a></div><div><b>Author(s):&nbsp;</b>Linchuang Zhang, Yonghui Sun, Hak-Keung Lam, Hongyi Li, Jianxi Wang, Dongchen Hou</div><div><b>Pages:&nbsp;</b>2583 - 2594</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9457145/\">Finite-Frequency H\u2212/H\u221e Memory Fault Detection Filtering Design for Uncertain Takagi\u2013Sugeno Fuzzy Affine Systems</a></div><div><b>Author(s):&nbsp;</b>Rong Zhao, Lu Liu, Gang Feng</div><div><b>Pages:&nbsp;</b>2595 - 2609</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9457138/\">Event-Triggered Bipartite Consensus for Fuzzy Multiagent Systems Under Markovian Switching Signed Topology</a></div><div><b>Author(s):&nbsp;</b>Jiafeng Yu, Choon Ki Ahn, Peng Shi</div><div><b>Pages:&nbsp;</b>2610 - 2620</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9457143/\">Continuous Exp Strategy for Consumer Preference Analysis Based on Online Ratings</a></div><div><b>Author(s):&nbsp;</b>Long Ren, Bin Zhu, Zeshui Xu</div><div><b>Pages:&nbsp;</b>2621 - 2633</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9457170/\">Trust Cop-Kmeans Clustering Analysis and Minimum-Cost Consensus Model Considering Voluntary Trust Loss in Social Network Large-Scale Decision-Making</a></div><div><b>Author(s):&nbsp;</b>Su-Min Yu, Zhi-Jiao Du, Xue-Yang Zhang, Han-Yang Luo, Xu-Dong Lin</div><div><b>Pages:&nbsp;</b>2634 - 2648</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9462345/\">Statistically Evolving Fuzzy Inference System for Non-Gaussian Noises</a></div><div><b>Author(s):&nbsp;</b>Zhao-Xu Yang, Hai-Jun Rong, Plamen Angelov, Zhi-Xin Yang</div><div><b>Pages:&nbsp;</b>2649 - 2664</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9462321/\">A New Fuzzy Spiking Neural Network Based on Neuronal Contribution Degree</a></div><div><b>Author(s):&nbsp;</b>Fang Liu, Jie Yang, Witold Pedrycz, Wei Wu</div><div><b>Pages:&nbsp;</b>2665 - 2677</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9462470/\">Aperiodic Sampled-Data Takagi\u2013Sugeno Fuzzy Extended State Observer for a Class of Uncertain Nonlinear Systems With External Disturbance and Unmodeled Dynamics</a></div><div><b>Author(s):&nbsp;</b>Zhichen Li, Huaicheng Yan, Hao Zhang, Hak-Keung Lam, Congzhi Huang</div><div><b>Pages:&nbsp;</b>2678 - 2692</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9464680/\">Sampled-Data-Based Event-Triggered Fuzzy Control for PDE Systems Under Cyberattacks</a></div><div><b>Author(s):&nbsp;</b>Xiaona Song, Qiyuan Zhang, Shuai Song, Choon Ki Ahn</div><div><b>Pages:&nbsp;</b>2693 - 2705</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9466935/\">Interval-Valued Aggregation Functions Based on Moderate Deviations Applied to Motor-Imagery-Based Brain\u2013Computer Interface</a></div><div><b>Author(s):&nbsp;</b>Javier Fumanal-Idocin, Zdenko Tak\u00e1\u010d, Javier Fern\u00e1ndez, Jos\u00e9 Antonio Sanz, Harkaitz Goyena, Ching-Teng Lin, Yu-Kai Wang, Humberto Bustince</div><div><b>Pages:&nbsp;</b>2706 - 2720</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9468319/\">Noise-Tolerant Fuzzy-\u03b2-Covering-Based Multigranulation Rough Sets and Feature Subset Selection</a></div><div><b>Author(s):&nbsp;</b>Zhehuang Huang, Jinjin Li, Yuhua Qian</div><div><b>Pages:&nbsp;</b>2721 - 2735</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9470937/\">Expansive Errors-Based Fuzzy Adaptive Prescribed Performance Control by Residual Approximation</a></div><div><b>Author(s):&nbsp;</b>Shigen Gao, Mingjun Li, Yue Zheng, Hairong Dong</div><div><b>Pages:&nbsp;</b>2736 - 2746</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9477002/\">Fractional-Order Terminal Sliding-Mode Control Using Self-Evolving Recurrent Chebyshev Fuzzy Neural Network for MEMS Gyroscope</a></div><div><b>Author(s):&nbsp;</b>Zhe Wang, Juntao Fei</div><div><b>Pages:&nbsp;</b>2747 - 2758</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9477053/\">Relaxed Conditions of Observer Design of Discrete-Time Takagi\u2013Sugeno Fuzzy Systems via a New Multi-Instant Gain-Scheduling Scheme</a></div><div><b>Author(s):&nbsp;</b>Hongyu Lu, Xiangpeng Xie, Chen Peng</div><div><b>Pages:&nbsp;</b>2759 - 2768</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9426421/\">A Fuzzy Lyapunov Function Method to Stability Analysis of Fractional-Order T\u2013S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Fan, Zhanshan Wang</div><div><b>Pages:&nbsp;</b>2769 - 2776</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9454282/\">Multi-Instant Gain-Scheduling Stabilization of Discrete-Time Takagi\u2013Sugeno Fuzzy Systems Based on a Time-Variant Balanced Matrix Approach</a></div><div><b>Author(s):&nbsp;</b>Xiangpeng Xie, Chengjie Bu, Chen Peng</div><div><b>Pages:&nbsp;</b>2777 - 2782</div><div><br /></div>", "pubdate": "2022-07-08T10:36:00.000+12:00", "pubdate_parsed": 1657213560.0, "email_sent": true}, "Soft Computing, Volume 26, issue 14, July 2022": {"url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-14-july.html", "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07116-6\">Efficient data transfer supporting provable data deletion for secure cloud storage</a></div><div><b>Author(s): </b>Changsong Yang, Yueling Liu, Yong Ding</div><div><b>Pages: </b>6463 - 6479</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07119-3\">Green\u2019s relations in L-E-fuzzy skew lattices</a></div><div><b>Author(s):&nbsp;</b>Yuan Zhi, Xiangnan Zhou, Qingguo Li</div><div><b>Pages:&nbsp;</b>6481 - 6494</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07134-4\">Regular and strongly regular relations induced by fuzzy subhypermodules</a></div><div><b>Author(s):&nbsp;</b>N. Rakhsh Khorshid, S. Ostadhadi-Dehkordi</div><div><b>Pages:&nbsp;</b>6495 - 6506</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07127-3\">Another view on knowledge measures in atanassov intuitionistic fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>Muhammad Irfan Ali, Jianming Zhan...Haider Faizan</div><div><b>Pages:&nbsp;</b>6507 - 6517</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07128-2\">Effect of fuzziness in fuzzy rule-based classifiers defined by strong fuzzy partitions and winner-takes-all inference</a></div><div><b>Author(s):&nbsp;</b>Gabriella Casalino, Giovanna Castellano...Corrado Mencar</div><div><b>Pages:&nbsp;</b>6519 - 6527</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07168-8\">Nonlinear interval regression analysis with neural networks and grey prediction for energy demand forecasting</a></div><div><b>Author(s):&nbsp;</b>Yi-Chung Hu, Wen-Bao Wang</div><div><b>Pages:&nbsp;</b>6529 - 6545</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07178-6\">Knowledge transfer learning from multiple user activities to improve personalized recommendation</a></div><div><b>Author(s):&nbsp;</b>Mingxin Gan, Yingxue Ma</div><div><b>Pages:&nbsp;</b>6547 - 6566</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07179-5\">A quantum system control method based on enhanced reinforcement learning</a></div><div><b>Author(s):&nbsp;</b>Wenjie Liu, Bosi Wang...Mohammed Zidan</div><div><b>Pages:&nbsp;</b>6567 - 6575</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07181-x\">On-demand DWDM design using machine learning</a></div><div><b>Author(s):&nbsp;</b>K. Venkatesan, A. Chandrasekar, P. G. V. Ramesh</div><div><b>Pages:&nbsp;</b>6577 - 6589</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07040-9\">Ramp loss KNN-weighted multi-class twin support vector machine</a></div><div><b>Author(s):&nbsp;</b>Huiru Wang, Yitian Xu, Zhijian Zhou</div><div><b>Pages:&nbsp;</b>6591 - 6618</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07042-7\">A revisited fuzzy DEMATEL and optimization method for strategy map design under the BSC framework: selection of objectives and relationships</a></div><div><b>Author(s):&nbsp;</b>H\u00e9ctor L\u00f3pez-Ospina, Daniela Pardo...Luis Quezada</div><div><b>Pages:&nbsp;</b>6619 - 6644</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07043-6\">A novel linear representation for evolving matrices</a></div><div><b>Author(s):&nbsp;</b>Connor Gregor, Daniel Ashlock...David Kribs</div><div><b>Pages:&nbsp;</b>6645 - 6657</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07050-7\">MOTEO: a novel multi-objective thermal exchange optimization algorithm for engineering problems</a></div><div><b>Author(s):&nbsp;</b>Nima Khodadadi, Siamak Talatahari...Armin Dadras Eslamlou</div><div><b>Pages:&nbsp;</b>6659 - 6684</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07061-4\">A novel incremental cost consensus approach for distributed economic dispatch over directed communication topologies in a smart grid</a></div><div><b>Author(s):&nbsp;</b>Um-E-Habiba Alvi, Waqas Ahmed...Ijaz Ahmed</div><div><b>Pages:&nbsp;</b>6685 - 6700</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07065-0\">Intelligent computing technique for solving singular multi-pantograph delay differential equation</a></div><div><b>Author(s):&nbsp;</b>Zulqurnain Sabir, Hafiz Abdul Wahab...Mohamed R. Ali</div><div><b>Pages:&nbsp;</b>6701 - 6713</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07066-z\">Optimization on the multi-period empty container repositioning problem in regional port cluster based upon inventory control strategies</a></div><div><b>Author(s):&nbsp;</b>Jiaxin Cai, Yubo Li...Zhihong Jin</div><div><b>Pages:&nbsp;</b>6715 - 6738</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07072-1\">A simple solution to technician routing and scheduling problem using improved genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Engin Pekel</div><div><b>Pages:&nbsp;</b>6739 - 6748</div><div><br /></div><div><b>18) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07079-8\">Fusion of modern meta-heuristic optimization methods using arithmetic optimization algorithm for global optimization tasks</a></div><div><b>Author(s):&nbsp;</b>Shubham Mahajan, Laith Abualigah...Maryam Altalhi</div><div><b>Pages:&nbsp;</b>6749 - 6763</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07089-6\">Identification of nonlinear discrete systems using a new Hammerstein model with Volterra neural network</a></div><div><b>Author(s):&nbsp;</b>Wei-Der Chang</div><div><b>Pages:&nbsp;</b>6765 - 6775</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07103-x\">Environmental assisted cracking and strength attenuation effect computing on the mechanical properties of casing steel P110 for industrial revolution 5.0 applications in sour well environments</a></div><div><b>Author(s):&nbsp;</b>Duo Hou, Zhongling Xiao...Taihe Shi</div><div><b>Pages:&nbsp;</b>6777 - 6787</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06906-2\">Comparison of subsidy strategies on the green supply chain under a behaviour-based pricing model</a></div><div><b>Author(s):&nbsp;</b>Kanying Liu, Wei Li...Yong Lan</div><div><b>Pages:&nbsp;</b>6789 - 6809</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06921-3\">Attack detection and prevention in IoT-SCADA networks using NK-classifier</a></div><div><b>Author(s):&nbsp;</b>Y. JustindhasP. Jeyanthi</div><div><b>Pages:&nbsp;</b>6811 - 6823</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06926-y\">A method to determine the integrated weights of cross-efficiency aggregation</a></div><div><b>Author(s):&nbsp;</b>Mei-Juan LiJin-Cheng LuLei Chen</div><div><b>Pages:&nbsp;</b>6825 - 6837</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06628-x\">Load-settlement response of a footing over buried conduit in a sloping terrain: a numerical experiment-based artificial intelligent approach</a></div><div><b>Author(s):&nbsp;</b>Muhammad Umer Arif Khan, Sanjay Kumar Shukla, Muhammad Nouman Amjad Raja</div><div><b>Pages:&nbsp;</b>6839 - 6856</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06629-w\">Recognition of shed damage on 11-kV polymer insulator using Bayesian optimized convolution neural network</a></div><div><b>Author(s):&nbsp;</b>B. Vigneshwaran, M. Willjuice Iruthayarajan, R. V. Maheswari</div><div><b>Pages:&nbsp;</b>6857 - 6869</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06630-3\">Enhanced heat transfer search and enriched replicated coronary circulation system optimization algorithms for real power loss reduction</a></div><div><b>Author(s):&nbsp;</b>Lenin Kanagasabai</div><div><b>Pages:&nbsp;</b>6871 - 6888</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06636-x\">A novel quality evaluation method for standardized experiment teaching</a></div><div><b>Author(s):&nbsp;</b>Luxin Yang, Yutong Chun...Jing Yang</div><div><b>Pages:&nbsp;</b>6889 - 6906</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06639-8\">Feature extraction-based intelligent algorithm framework with neural network for solving conditional nonlinear optimal perturbation</a></div><div><b>Author(s):&nbsp;</b>Shijin Yuan,Huazhen Zhang...Bin Mu</div><div><b>Pages:&nbsp;</b>6907 - 6924</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06646-9\">Computational intelligence in software defects rules discovery</a></div><div><b>Author(s):&nbsp;</b>Andreea VescanCamelia \u015eerbanGloria Cerasela Cri\u015fan</div><div><b>Pages:&nbsp;</b>6925 - 6939</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06648-7\">Fuzzy transfer learning in time series forecasting for stock market prices</a></div><div><b>Author(s):&nbsp;</b>Shanoli Samui PalSamarjit Kar</div><div><b>Pages:&nbsp;</b>6941 - 6952</div><div><br /></div></div>", "pubdate": "2022-07-09T12:00:00.001+12:00", "pubdate_parsed": 1657305000.0, "email_sent": true}, "Evolving Systems, Volume 13, issue 4, August 2022": {"url": "https://computational-intelligence.blogspot.com/2022/07/evolving-systems-volume-13-issue-4.html", "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09385-2\">FocusCovid: automated COVID-19 detection using deep learning with chest X-ray images</a></div><div><b>Author(s): </b>Tarun Agrawal, Prakash Choudhary</div><div><b>Pages: </b>519 - 533</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09392-3\">Multichannel convolutional neural network-based fuzzy active contour model for medical image segmentation</a></div><div><b>Author(s):&nbsp;</b>Qingwu Shi, Shoulin Yin...Hang Li</div><div><b>Pages:&nbsp;</b>535 - 549</div><div><br /></div><div><b>3)</b> Cubic graph representation of concept lattice and its decomposition</div><div><b>Author(s):&nbsp;</b>Prem Kumar Singh</div><div><b>Pages:&nbsp;</b>551 - 562</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09401-5\">Battle royale optimizer for training multi-layer perceptron</a></div><div><b>Author(s):&nbsp;</b>Saeid Agahian, Taymaz Akan</div><div><b>Pages:&nbsp;</b>563 - 575</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09404-2\">Extreme gradient boosting model based on improved Jaya optimizer applied to forecasting energy consumption in residential buildings</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o Sauer, Viviana Cocco Mariani...Mirco Rampazzo</div><div><b>Pages:&nbsp;</b>577 - 588</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09407-z\">Optimization of FRP jacket by fractional\u2011order pathfinder algorithm to improve the reinforced concrete frames' seismic response</a></div><div><b>Author(s):&nbsp;</b>Chengliang Wang, Wenrui Li, Dragan Rodriguez</div><div><b>Pages:&nbsp;</b>589 - 601</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09408-y\">EvolveCluster: an evolutionary clustering algorithm for streaming data</a></div><div><b>Author(s):&nbsp;</b>Christian Nordahl, Veselka Boeva...Marie Persson Netz</div><div><b>Pages:&nbsp;</b>603 - 623</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09395-0\">Synthetic samples generator (SYSGEN), an approach to increase the size of incidence samples in coffee leaf rust modelling</a></div><div><b>Author(s):&nbsp;</b>Edwar Javier Gir\u00f3n, David Camilo Corrales...Juan Carlos Corrales</div><div><b>Pages:&nbsp;</b>625 - 636</div><div><br /></div></div>", "pubdate": "2022-07-11T21:35:00.001+12:00", "pubdate_parsed": 1657512300.0, "email_sent": true}, "Soft Computing, Volume 26, issue 15, August 2022": {"url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-15.html", "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07174-w\">Analytic hierarchy process-based regression test case prioritization technique enhancing the fault detection rate</a></div><div><b>Author(s): </b>Soumen Nayak, Chiranjeev Kumar, Sachin Tripathi</div><div><b>Pages: </b>6953 - 6968</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07193-7\">On Annihilators in Hoops</a></div><div><b>Author(s):&nbsp;</b>R. A. Borzooei, M. Aaly Kologani...Y. B. Jun</div><div><b>Pages:&nbsp;</b>6969 - 6980</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07216-3\">Properties of stabilizers in residuated lattices</a></div><div><b>Author(s):&nbsp;</b>Michiro Kondo</div><div><b>Pages:&nbsp;</b>6981 - 6988</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07217-2\">Independent domination polynomial of zero-divisor graphs of commutative rings</a></div><div><b>Author(s):&nbsp;</b>Necla K\u0131rcal\u0131 G\u00fcrsoy, Alper \u00dclker, Arif G\u00fcrsoy</div><div><b>Pages:&nbsp;</b>6989 - 6997</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07223-4\">Quasi-MV* algebras: a generalization of MV*-algebras</a></div><div><b>Author(s):&nbsp;</b>Yingying Jiang, Wenjuan Chen</div><div><b>Pages:&nbsp;</b>6999 - 7015</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06985-1\">Fuzzy filters of IL-algebras</a></div><div><b>Author(s):&nbsp;</b>Safiqul Islam, Arundhati Sanyal, Jayanta Sen</div><div><b>Pages:&nbsp;</b>7017 - 7027</div><div><br /></div><div><b>7) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07004-z\">Broad learning system based ensemble deep model</a></div><div><b>Author(s):&nbsp;</b>Chenglong Zhang, Shifei Ding...Jian Zhang</div><div><b>Pages:&nbsp;</b>7029 - 7041</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07101-z\">On differential lattices</a></div><div><b>Author(s):&nbsp;</b>Aiping Gan, Li Guo</div><div><b>Pages:&nbsp;</b>7043 - 7058</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07132-6\">A faster algorithm for identifying signals using complex fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>Madad Khan, Inamullah Khan...Sohail Iqbal</div><div><b>Pages:&nbsp;</b>7059 - 7079</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07172-y\">Trapezoidal approximation operators preserving the most indicators of fuzzy numbers-relationships and applications</a></div><div><b>Author(s):&nbsp;</b>M. Chehlabi</div><div><b>Pages:&nbsp;</b>7081 - 7105</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07150-4\">An introduction to single-valued neutrosophic soft topological structure</a></div><div><b>Author(s):&nbsp;</b>Yaser Saber, Fahad Alsharari, Florentin Smarandache</div><div><b>Pages:&nbsp;</b>7107 - 7122</div><div><br /></div><div><b>12) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07160-2\">An evidence combination rule based on a new weight assignment scheme</a></div><div><b>Author(s):&nbsp;</b>Yu-Cui Wang, Jian Wang...Ming-Hui Wang</div><div><b>Pages:&nbsp;</b>7123 - 7137</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07188-4\">A note on \u201cDealer using a new trapezoidal cubic hesitant fuzzy TOPSIS method and application to group decision-making program\u201d</a></div><div><b>Author(s):&nbsp;</b>S. S. Appadoo, Mohammadreza Makhan, Amit Kumar</div><div><b>Pages:&nbsp;</b>7139 - 7141</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07191-9\">Distributed energy-efficient clustering routing protocol for wireless sensor networks using affinity propagation and fuzzy logic</a></div><div><b>Author(s):&nbsp;</b>Chu-hang Wang, Huang-shui Hu...Jin-feng Zhang</div><div><b>Pages:&nbsp;</b>7143 - 7158</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07323-1\">Stability and admissibility analysis of T\u2013S descriptive systems and its applications</a></div><div><b>Author(s):&nbsp;</b>Muhammad Shamrooz Aslam, Ma Zhenhua...Abdul Majid</div><div><b>Pages:&nbsp;</b>7159 - 7166</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07190-w\">Quantum-enhanced filter: QFilter</a></div><div><b>Author(s):&nbsp;</b>Parfait Atchade-Adelomou, Guillermo Alonso-Linaje</div><div><b>Pages:&nbsp;</b>7167 - 7174</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07194-6\">Estimation of fault probability in medium voltage feeders through calibration techniques in classification models</a></div><div><b>Author(s):&nbsp;</b>Enrico De Santis, Francesco Arn\u00f2, Antonello Rizzi</div><div><b>Pages:&nbsp;</b>7175 - 7193</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07105-9\">Deep multiobjective design optimization of CFRP isogrid tubes using lichtenberg algorithm</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o Luiz Junho Pereira, Matheus Brendon Francisco...Guilherme Ferreira Gomes</div><div><b>Pages:&nbsp;</b>7195 - 7209</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07107-7\">An effective structure of multi-modal deep convolutional neural network with adaptive group teaching optimization</a></div><div><b>Author(s):&nbsp;</b>Vinit Gupta, Santosh Pawar</div><div><b>Pages:&nbsp;</b>7211 - 7232</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07109-5\">An enhanced Harris Hawk optimization algorithm for parameter estimation of single, double and triple diode photovoltaic models</a></div><div><b>Author(s):&nbsp;</b>Abdelhady Ramadan, Salah Kamel...Jose Luis Dom\u00ednguez-Garc\u00eda</div><div><b>Pages:&nbsp;</b>7233 - 7257</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07112-w\">A preference structure in multi-attribute decision making: an algorithmic approach based on hesitant fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>B. K. Mohanty, Eshika Aggarwal</div><div><b>Pages:&nbsp;</b>7259 - 7277</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07124-6\">Optimal autonomic management of service-based business processes in the cloud</a></div><div><b>Author(s):&nbsp;</b>Leila Hadded, Tarek Hamrouni</div><div><b>Pages:&nbsp;</b>7279 - 7291</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07139-z\">A novel hybrid gravitational and pattern search algorithm based MPPT controller with ANN and perturb and observe for photovoltaic system</a></div><div><b>Author(s):&nbsp;</b>Salem Alkhalaf, Ziad M. AliHitoshi Oikawa</div><div><b>Pages:&nbsp;</b>7293 - 7315</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06941-z\">Modeling stock market using new hybrid intelligent method based on MFNN and IBHA</a></div><div><b>Author(s):&nbsp;</b>Wei Gao</div><div><b>Pages:&nbsp;</b>7317 - 7337</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06964-6\">Evaluating and selecting agricultural insurance packages through an AHP-based fuzzy TOPSIS Method</a></div><div><b>Author(s):&nbsp;</b>Ta-Chung Chu, Thi Hong Phuong Le</div><div><b>Pages:&nbsp;</b>7339 - 7354</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07027-6\">Inclusion degree-based multigranulation rough fuzzy set over heterogeneous preference information and application to multiple attribute group decision making</a></div><div><b>Author(s):&nbsp;</b>Xinrui Zhang, Bingzhen Sun</div><div><b>Pages:&nbsp;</b>7355 - 7375</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07299-y\">Research on safety simulation model and algorithm of dynamic system based on artificial neural network</a></div><div><b>Author(s):&nbsp;</b>Guangna Zhang</div><div><b>Pages:&nbsp;</b>7377 - 7386</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07300-8\">Mobile robot path planning using multi-objective genetic algorithm in industrial automation</a></div><div><b>Author(s):&nbsp;</b>K. S. Suresh, R. Venkatesan, S. Venugopal</div><div><b>Pages:&nbsp;</b>7387 - 7400</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06677-2\">Toward in-flight Wi-Fi: a neuro-fuzzy based routing approach for Civil Aeronautical Ad hoc Network</a></div><div><b>Author(s):&nbsp;</b>T. Gurumekala, S. Indira Gandhi</div><div><b>Pages:&nbsp;</b>7401 - 7422</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06688-z\">CoupGAN: Chinese couplet generation via encoder\u2013decoder model and adversarial training under global control</a></div><div><b>Author(s):&nbsp;</b>Qian Qu, Jiancheng Lv...Kexin Yang</div><div><b>Pages:&nbsp;</b>7423 - 7433</div><div><br /></div><div><br /></div></div>", "pubdate": "2022-07-14T10:56:00.001+12:00", "pubdate_parsed": 1657733160.0, "email_sent": true}, "Soft Computing, Volume 26, issue 16, August 2022": {"url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-16.html", "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07213-6\">Special issue on advances in pattern recognition and computer vision, applications and systems</a></div><div><b>Author(s): </b>M. Irfan Uddin</div><div><b>Pages: </b>7435 - 7436</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06439-0\">Analysis of industry convergence based on improved neural network</a></div><div><b>Author(s):&nbsp;</b>Nan Ma</div><div><b>Pages:&nbsp;</b>7437 - 7448</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06449-y\">Nucleus image segmentation method based on GAN and FCN model</a></div><div><b>Author(s):&nbsp;</b>Kai Zhang, Yang Shi...Hang Yu</div><div><b>Pages:&nbsp;</b>7449 - 7460</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06459-w\">A new color image encryption technique using DNA computing and Chaos-based substitution box</a></div><div><b>Author(s):&nbsp;</b>Fawad Masood, Junaid Masood...Jawad Ahmad</div><div><b>Pages:&nbsp;</b>7461 - 7477</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06465-y\">An evolutionary trajectory planning algorithm for multi-UAV-assisted MEC system</a></div><div><b>Author(s):&nbsp;</b>Muhammad Asim, Wali Khan Mashwani...Samir Brahim Belhaouari</div><div><b>Pages:&nbsp;</b>7479 - 7492</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06478-7\">Research on modeling of government debt risk comprehensive evaluation based on multidimensional data mining</a></div><div><b>Author(s):&nbsp;</b>Li Chao Ying, Wu Xiang Da, Zhao En Hui</div><div><b>Pages:&nbsp;</b>7493 - 7500</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06479-6\">Research on trade data encryption of tobacco enterprises based on adversarial neural network</a></div><div><b>Author(s):&nbsp;</b>Zhang Yi</div><div><b>Pages:&nbsp;</b>7501 - 7508</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06480-z\">Research on intelligent language translation system based on deep learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Chunliu Shi</div><div><b>Pages:&nbsp;</b>7509 - 7518</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06519-1\">Analyzing fibrous tissue pattern in fibrous dysplasia bone images using deep R-CNN networks for segmentation</a></div><div><b>Author(s):&nbsp;</b>A. Saranya, Kottilingam Kottursamy...Ali Kashif Bashir</div><div><b>Pages:&nbsp;</b>7519 - 7533</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06569-5\">Deep learning-based election results prediction using Twitter activity</a></div><div><b>Author(s):&nbsp;</b>Haider Ali, Haleem Farman...Adel Ammar</div><div><b>Pages:&nbsp;</b>7535 - 7543</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06581-9\">Q-method optimization of tunnel surrounding rock classification by fuzzy reasoning model and support vector machine</a></div><div><b>Author(s):&nbsp;</b>Feng Jiang, Peng He...Zhihan Lv</div><div><b>Pages:&nbsp;</b>7545 - 7558</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06585-5\">Analysis of the change of artificial intelligence to online consumption patterns and consumption concepts</a></div><div><b>Author(s):&nbsp;</b>Longyue Bai</div><div><b>Pages:&nbsp;</b>7559 - 7569</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06587-3\">Sparse representation optimization of Gaussian mixed feature of image based on convolution neural network</a></div><div><b>Author(s):&nbsp;</b>Yuguang Ye</div><div><b>Pages:&nbsp;</b>7571 - 7580</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06603-6\">Task-specific image summaries using semantic information and self-supervision</a></div><div><b>Author(s):&nbsp;</b>Deepak Kumar Sharma, Anurag Singh...Jerry Chun-Wei Lin</div><div><b>Pages:&nbsp;</b>7581 - 7594</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06612-5\">The study on life model of MOV based on various parameters and surge history</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Ruan, Shaoyun Jin...Weidong Cheng</div><div><b>Pages:&nbsp;</b>7595 - 7600</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06662-9\">Deep ensembling for perceptual image quality assessment</a></div><div><b>Author(s):&nbsp;</b>Nisar Ahmed, H. M. Shahzad Asif...Atif Khan</div><div><b>Pages:&nbsp;</b>7601 - 7622</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06705-1\">ConTEXT: context-aware adaptive SMS client for drivers to reduce risky driving behaviors</a></div><div><b>Author(s):&nbsp;</b>Inayat Khan, Shah Khusro</div><div><b>Pages:&nbsp;</b>7623 - 7640</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06706-0\">Design of robust deep learning-based object detection and classification model for autonomous driving applications</a></div><div><b>Author(s):&nbsp;</b>Mesfer Al Duhayyim, Fahd N. Al-Wesabi...Ashish Khanna</div><div><b>Pages:&nbsp;</b>7641 - 7652</div><div><br /></div><div><b>19) </b><a href=\"https://link.springer.com/article/10.1007/s00500-021-06707-z\">Gene Ontology GAN (GOGAN): a novel architecture for protein function prediction</a></div><div><b>Author(s):&nbsp;</b>Musadaq Mansoor, Mohammad Nauman...Alfredo Benso</div><div><b>Pages:&nbsp;</b>7653 - 7667</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06715-z\">The control mode study of PPP project financing management information system</a></div><div><b>Author(s):&nbsp;</b>Junli Cao, Lin Li</div><div><b>Pages:&nbsp;</b>7669 - 7675</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06869-4\">Correction to: The control mode study of PPP project financing management information system</a></div><div><b>Author(s):&nbsp;</b>Junli Cao, Lin Li</div><div><b>Pages:&nbsp;</b>7677 - 7677</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06734-4\">A comprehensive overview of AI-enabled music classification and its influence in games</a></div><div><b>Author(s):&nbsp;</b>Tiancheng Yang, Shah Nazir</div><div><b>Pages:&nbsp;</b>7679 - 7693</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06739-z\">Classification of Gurumukhi month\u2019s name images using various convolutional neural network optimizers</a></div><div><b>Author(s):&nbsp;</b>Tajinder Pal Singh, Sheifali Gupta...Atef Zaguia</div><div><b>Pages:&nbsp;</b>7695 - 7707</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06742-4\">Novel semi-supervised learning approach for descriptor generation using artificial neural networks</a></div><div><b>Author(s):&nbsp;</b>Alla Fikrat Alwindawi, Osman Nuri U\u00e7an...Aminu Yusuf</div><div><b>Pages:&nbsp;</b>7709 - 7720</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06750-4\">Hybrid deep-learning model to detect botnet attacks over internet of things environments</a></div><div><b>Author(s):&nbsp;</b>Mohammed Y. Alzahrani, Alwi M. Bamhdi</div><div><b>Pages:&nbsp;</b>7721 - 7735</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06755-z\">Machine health surveillance system by using deep learning sparse autoencoder</a></div><div><b>Author(s):&nbsp;</b>Faizan Ullah, Abdu Salam...Wael Alosaimi</div><div><b>Pages:&nbsp;</b>7737 - 7750</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06762-0\">Diagnosis and classification of Alzheimer's disease by using a convolution neural network algorithm</a></div><div><b>Author(s):&nbsp;</b>Mosleh Hmoud Al-Adhaileh</div><div><b>Pages:&nbsp;</b>7751 - 7762</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06773-x\">Machine learning for fake news classification with optimal feature selection</a></div><div><b>Author(s):&nbsp;</b>Muhammad Fayaz, Atif Khan...Sana Ullah Khan</div><div><b>Pages:&nbsp;</b>7763 - 7771</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06775-9\">Application and Analysis of Computer Network Technology in Electronic Information Engineering</a></div><div><b>Author(s):&nbsp;</b>Wanjie Kang, Jie Xiao</div><div><b>Pages:&nbsp;</b>7773 - 7779</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06781-x\">Research and application of GIS and data mining technology in monitoring and assessment of natural geography environment</a></div><div><b>Author(s):&nbsp;</b>Fuheng Zhang, Guangbin Ji...Guihua Liu</div><div><b>Pages:&nbsp;</b>7781 - 7787</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06794-6\">Extracting built-up areas from spectro-textural information using machine learning</a></div><div><b>Author(s):&nbsp;</b>Ahsen Maqsoom, Bilal Aslam...Muhammad Imran</div><div><b>Pages:&nbsp;</b>7789 - 7808</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06796-4\">The traditional settlement planning and the renovation of residential buildings based on spatial syntax analysis</a></div><div><b>Author(s):&nbsp;</b>Kaifeng Chu, Mengyu Wu</div><div><b>Pages:&nbsp;</b>7809 - 7815</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06804-7\">Efficient facial emotion recognition model using deep convolutional neural network and modified joint trilateral filter</a></div><div><b>Author(s):&nbsp;</b>Naveen Kumari, Rekha Bhatia</div><div><b>Pages:&nbsp;</b>7817 - 7830</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06805-6\">Convolutional neural network based hurricane damage detection using satellite images</a></div><div><b>Author(s):&nbsp;</b>Swapandeep Kaur, Sheifali Gupta...Atef Zaguia</div><div><b>Pages:&nbsp;</b>7831 - 7845</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06806-5\">Fake opinion detection in an e-commerce business based on a long-short memory algorithm</a></div><div><b>Author(s):&nbsp;</b>Nizar Alsharif</div><div><b>Pages:&nbsp;</b>7847 - 7854</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06811-8\">Visual design elements based on digital visualization</a></div><div><b>Author(s):&nbsp;</b>Lei Jiang</div><div><b>Pages:&nbsp;</b>7855 - 7863</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06812-7\">Analysis of transmission line icing prediction based on CNN and data mining technology</a></div><div><b>Author(s):&nbsp;</b>Lixue Li, Da Luo, Wenhao Yao</div><div><b>Pages:&nbsp;</b>7865 - 7870</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06813-6\">Computer application under the management of network information security technology using genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xu Jian Qiang</div><div><b>Pages:&nbsp;</b>7871 - 7876</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06830-5\">Software defect prediction employing BiLSTM and BERT-based semantic feature</a></div><div><b>Author(s):&nbsp;</b>Md Nasir Uddin, Bixin Li...Islam Zada</div><div><b>Pages:&nbsp;</b>7877 - 7891</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06845-y\">An effective nonlocal means image denoising framework based on non-subsampled shearlet transform</a></div><div><b>Author(s):&nbsp;</b>Bhawna Goyal, Ayush Dogra, Arun Kumar Sangaiah</div><div><b>Pages:&nbsp;</b>7893 - 7915</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06849-8\">The study of physical education evaluation based on a fuzzy stochastic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xiuyan Su</div><div><b>Pages:&nbsp;</b>7917 - 7923</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06851-0\">Conceptual model construction of building information management system based on BIM architecture</a></div><div><b>Author(s):&nbsp;</b>Jiang Haiying</div><div><b>Pages:&nbsp;</b>7925 - 7931</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06853-y\">Perceptual adversarial non-residual learning for blind image denoising</a></div><div><b>Author(s):&nbsp;</b>Aamir Khan, Weidong Jin, Rizwan Ali Naqvi</div><div><b>Pages:&nbsp;</b>7933 - 7957</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06855-w\">Research on the optimization of communication protocol in network security protocol</a></div><div><b>Author(s):&nbsp;</b>Daoyuan Sun</div><div><b>Pages:&nbsp;</b>7959 - 7966</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06859-6\">Multi-scale local-global architecture for person re-identification</a></div><div><b>Author(s):&nbsp;</b>Jing Liu, Prayag Tiwari...Shahab S. Band</div><div><b>Pages:&nbsp;</b>7967 - 7977</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06900-8\">Optimal feature extraction and ulcer classification from WCE image data using deep learning</a></div><div><b>Author(s):&nbsp;</b>Youssef Masmoudi, Muhammad Ramzan...Mohammed Habib</div><div><b>Pages:&nbsp;</b>7979 - 7992</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06901-7\">A communication security anti-interference decision model using deep learning in intelligent industrial IoT environment</a></div><div><b>Author(s):&nbsp;</b>Lichao Yan, Juan Hu...Jinhong Di</div><div><b>Pages:&nbsp;</b>7993 - 8002</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06990-4\">Smoke removal and image enhancement of laparoscopic images by an artificial multi-exposure image fusion method</a></div><div><b>Author(s):&nbsp;</b>Muhammad Adeel Azam, Khan Bahadar Khan...Sana Ullah Khan</div><div><b>Pages:&nbsp;</b>8003 - 8015</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06996-y\">Predicting the spread of COVID-19 with a machine learning technique and multiplicative calculus</a></div><div><b>Author(s):&nbsp;</b>B\u00fclent Bilgehan, Ali \u00d6zyap\u0131c\u0131...Yusuf Gurefe</div><div><b>Pages:&nbsp;</b>8017 - 8024</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07047-2\">Fusion of multi-modality biomedical images using deep neural networks</a></div><div><b>Author(s):&nbsp;</b>Manish Gupta, Naresh Kumar...Atef Zaguia</div><div><b>Pages:&nbsp;</b>8025 - 8036</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07058-z\">Rotating object detection in remote-sensing environment</a></div><div><b>Author(s):&nbsp;</b>Sixian Chan, Jingcheng Zheng...Kai Fang</div><div><b>Pages:&nbsp;</b>8037 - 8045</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07062-3\">Analyzing the interactions among factors affecting cloud adoption for software testing: a two-stage ISM-ANN approach</a></div><div><b>Author(s):&nbsp;</b>Sikandar Ali, Samad Baseer...Jiwei Huang</div><div><b>Pages:&nbsp;</b>8047 - 8075</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07064-1\">A probabilistic approach toward evaluation of Internet rumor on COVID</a></div><div><b>Author(s):&nbsp;</b>Yancheng Yang, Shah Nazir, Wajeeha Khalil</div><div><b>Pages:&nbsp;</b>8077 - 8088</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07142-4\">Single-image reconstruction using novel super-resolution technique for large-scaled images</a></div><div><b>Author(s):&nbsp;</b>Ramanath Datta, Sekhar Mandal...Jazem Mutared Alanazi</div><div><b>Pages:&nbsp;</b>8089 - 8103</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07155-z\">Hybrid optimisation-based robust watermarking using denoising convolutional neural network</a></div><div><b>Author(s):&nbsp;</b>Dhiran Kumar Mahto, Ashima Anand, Amit Kumar Singh</div><div><b>Pages:&nbsp;</b>8105 - 8116</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07169-7\">Constrained optimization based on hybrid version of superiority of feasibility solution strategy</a></div><div><b>Author(s):&nbsp;</b>Asia Noureen, Wali Khan Mashwani...Muhammad Asim</div><div><b>Pages:&nbsp;</b>8117 - 8132</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07204-7\">An adaptive genetic algorithm-based background elimination model for English text</a></div><div><b>Author(s):&nbsp;</b>Tang Xiaohui</div><div><b>Pages:&nbsp;</b>8133 - 8143</div><div><br /></div><div><br /></div></div>", "pubdate": "2022-07-18T12:16:00.000+12:00", "pubdate_parsed": 1658083560.0, "email_sent": true}, "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 7, July 2022": {"url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-neural-networks.html", "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9311226/\">The Heidelberg Spiking Data Sets for the Systematic Evaluation of Spiking Neural Networks</a></div><div><b>Author(s): </b>Benjamin Cramer, Yannik Stradmann, Johannes Schemmel, Friedemann Zenke</div><div><b>Pages: </b>2744 - 2757</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9312438/\">Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding</a></div><div><b>Author(s):&nbsp;</b>Qingxing Cao, Bailin Li, Xiaodan Liang, Keze Wang, Liang Lin</div><div><b>Pages:&nbsp;</b>2758 - 2767</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9311244/\">Stabilizing Training of Generative Adversarial Nets via Langevin Stein Variational Gradient Descent</a></div><div><b>Author(s):&nbsp;</b>Dong Wang, Xiaoqian Qin, Fengyi Song, Li Cheng</div><div><b>Pages:&nbsp;</b>2768 - 2780</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9316912/\">Reinforcement Learning and Adaptive Optimal Control for Continuous-Time Nonlinear Systems: A Value Iteration Approach</a></div><div><b>Author(s):&nbsp;</b>Tao Bian, Zhong-Ping Jiang</div><div><b>Pages:&nbsp;</b>2781 - 2790</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9314928/\">Parameterized Luenberger-Type H\u221e State Estimator for Delayed Static Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Yongsik Jin, Wookyong Kwon, Sangmoon Lee</div><div><b>Pages:&nbsp;</b>2791 - 2800</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9319553/\">BiCoSS: Toward Large-Scale Cognition Brain With Multigranular Neuromorphic Architecture</a></div><div><b>Author(s):&nbsp;</b>Shuangming Yang, Jiang Wang, Xinyu Hao, Huiyan Li, Xile Wei, Bin Deng, Kenneth A. Loparo</div><div><b>Pages:&nbsp;</b>2801 - 2815</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9317707/\">Causal Discovery in Linear Non-Gaussian Acyclic Model With Multiple Latent Confounders</a></div><div><b>Author(s):&nbsp;</b>Wei Chen, Ruichu Cai, Kun Zhang, Zhifeng Hao</div><div><b>Pages:&nbsp;</b>2816 - 2827</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9319566/\">A Study on Truncated Newton Methods for Linear Classification</a></div><div><b>Author(s):&nbsp;</b>Leonardo Galli, Chih-Jen Lin</div><div><b>Pages:&nbsp;</b>2828 - 2841</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9324979/\">Agglomerative Neural Networks for Multiview Clustering</a></div><div><b>Author(s):&nbsp;</b>Zhe Liu, Yun Li, Lina Yao, Xianzhi Wang, Feiping Nie</div><div><b>Pages:&nbsp;</b>2842 - 2852</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9321210/\">Low-Latency <i>In Situ</i> Image Analytics With FPGA-Based Quantized Convolutional Neural Network</a></div><div><b>Author(s):&nbsp;</b>Maolin Wang, Kelvin C. M. Lee, Bob M. F. Chung, Sharatchandra Varma Bogaraju, Ho-Cheung Ng, Justin S. J. Wong, Ho Cheung Shum, Kevin K. Tsia, Hayden Kwok-Hay So</div><div><b>Pages:&nbsp;</b>2853 - 2866</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9325083/\">Adaptive Optimal Control for Unknown Constrained Nonlinear Systems With a Novel Quasi-Model Network</a></div><div><b>Author(s):&nbsp;</b>Xiumei Han, Xudong Zhao, Hamid Reza Karimi, Ding Wang, Guangdeng Zong</div><div><b>Pages:&nbsp;</b>2867 - 2878</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9316921/\">A Hybrid Residual Dilated LSTM and Exponential Smoothing Model for Midterm Electric Load Forecasting</a></div><div><b>Author(s):&nbsp;</b>Grzegorz Dudek, Pawe\u0142 Pe\u0142ka, Slawek Smyl</div><div><b>Pages:&nbsp;</b>2879 - 2891</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9344620/\">Observer-Based Fixed-Time Neural Control for a Class of Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Yan Zhang, Fang Wang</div><div><b>Pages:&nbsp;</b>2892 - 2902</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9335504/\">Generalized Zero-Shot Learning With Multiple Graph Adaptive Generative Networks</a></div><div><b>Author(s):&nbsp;</b>Guo-Sen Xie, Zheng Zhang, Guoshuai Liu, Fan Zhu, Li Liu, Ling Shao, Xuelong Li</div><div><b>Pages:&nbsp;</b>2903 - 2915</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9319541/\">mCRF and mRD: Two Classification Methods Based on a Novel Multiclass Label Noise Filtering Learning Framework</a></div><div><b>Author(s):&nbsp;</b>Shuyin Xia, Baiyun Chen, Guoyin Wang, Yong Zheng, Xinbo Gao, Elisabeth Giem, Zizhong Chen</div><div><b>Pages:&nbsp;</b>2916 - 2930</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9325091/\">Observer Design for Sampled-Data Systems via Deterministic Learning</a></div><div><b>Author(s):&nbsp;</b>Jingtao Hu, Weiming Wu, Bing Ji, Cong Wang</div><div><b>Pages:&nbsp;</b>2931 - 2939</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9324926/\">Dynamically Weighted Balanced Loss: Class Imbalanced Learning and Confidence Calibration of Deep Neural Networks</a></div><div><b>Author(s):&nbsp;</b>K. Ruwani M. Fernando, Chris P. Tsokos</div><div><b>Pages:&nbsp;</b>2940 - 2951</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9328160/\">Broad Learning With Reinforcement Learning Signal Feedback: Theory and Applications</a></div><div><b>Author(s):&nbsp;</b>Ruiqi Mao, Rongxin Cui, C. L. Philip Chen</div><div><b>Pages:&nbsp;</b>2952 - 2964</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9324947/\">Neural-Network-Based Distributed Asynchronous Event-Triggered Consensus Tracking of a Class of Uncertain Nonlinear Multi-Agent Systems</a></div><div><b>Author(s):&nbsp;</b>Yun Ho Choi, Sung Jin Yoo</div><div><b>Pages:&nbsp;</b>2965 - 2979</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9325069/\">Active Learning With Multiple Kernels</a></div><div><b>Author(s):&nbsp;</b>Songnam Hong, Jeongmin Chae</div><div><b>Pages:&nbsp;</b>2980 - 2994</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9325927/\">Dissipativity-Based Finite-Time Filtering for Uncertain Semi-Markovian Jump Random Systems With Multiple Time Delays and State Constraints</a></div><div><b>Author(s):&nbsp;</b>Shaoxin Sun, Huaguang Zhang, Jian Han, Juan Zhang</div><div><b>Pages:&nbsp;</b>2995 - 3009</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9325537/\">PID Controller-Guided Attention Neural Network Learning for Fast and Effective Real Photographs Denoising</a></div><div><b>Author(s):&nbsp;</b>Ruijun Ma, Bob Zhang, Yicong Zhou, Zhengming Li, Fangyuan Lei</div><div><b>Pages:&nbsp;</b>3010 - 3023</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9325549/\">A Novel Feature Selection Method for High-Dimensional Mixed Decision Tables</a></div><div><b>Author(s):&nbsp;</b>Nguyen Ngoc Thuy, Sartra Wongthanavasu</div><div><b>Pages:&nbsp;</b>3024 - 3037</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9325918/\">Spatio-Spectral Feature Representation for Motor Imagery Classification Using Convolutional Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Ji-Seon Bang, Min-Ho Lee, Siamac Fazli, Cuntai Guan, Seong-Whan Lee</div><div><b>Pages:&nbsp;</b>3038 - 3049</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9366422/\">MetaMixUp: Learning Adaptive Interpolation Policy of MixUp With Metalearning</a></div><div><b>Author(s):&nbsp;</b>Zhijun Mai, Guosheng Hu, Dexiong Chen, Fumin Shen, Heng Tao Shen</div><div><b>Pages:&nbsp;</b>3050 - 3064</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9334415/\">An Efficient Sparse Bayesian Learning Algorithm Based on Gaussian-Scale Mixtures</a></div><div><b>Author(s):&nbsp;</b>Wei Zhou, Hai-Tao Zhang, Jun Wang</div><div><b>Pages:&nbsp;</b>3065 - 3078</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9340559/\">Efficient Approximation of High-Dimensional Functions With Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Patrick Cheridito, Arnulf Jentzen, Florian Rossmannek</div><div><b>Pages:&nbsp;</b>3079 - 3093</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9337198/\">Synaptic Scaling\u2014An Artificial Neural Network Regularization Inspired by Nature</a></div><div><b>Author(s):&nbsp;</b>Martin Hofmann, Patrick M\u00e4der</div><div><b>Pages:&nbsp;</b>3094 - 3108</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9340575/\">Observer-Based Adaptive Synchronization of Multiagent Systems With Unknown Parameters Under Attacks</a></div><div><b>Author(s):&nbsp;</b>Shiping Wen, Xiaoze Ni, Huamin Wang, Song Zhu, Kaibo Shi, Tingwen Huang</div><div><b>Pages:&nbsp;</b>3109 - 3119</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9336287/\">Explicit Duration Recurrent Networks</a></div><div><b>Author(s):&nbsp;</b>Shun-Zheng Yu</div><div><b>Pages:&nbsp;</b>3120 - 3130</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9336267/\">Observer-Based Neuro-Adaptive Optimized Control of Strict-Feedback Nonlinear Systems With State Constraints</a></div><div><b>Author(s):&nbsp;</b>Yongming Li, Yanjun Liu, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>3131 - 3145</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9494037/\">Granger Causality Inference in EEG Source Connectivity Analysis: A State-Space Approach</a></div><div><b>Author(s):&nbsp;</b>Parinthorn Manomaisaowapak, Anawat Nartkulpat, Jitkomut Songsiri</div><div><b>Pages:&nbsp;</b>3146 - 3156</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9410428/\">Rank Consistency Induced Multiview Subspace Clustering via Low-Rank Matrix Factorization</a></div><div><b>Author(s):&nbsp;</b>Jipeng Guo, Yanfeng Sun, Junbin Gao, Yongli Hu, Baocai Yin</div><div><b>Pages:&nbsp;</b>3157 - 3170</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9316932/\">Data-Driven-Based Event-Triggered Control for Nonlinear CPSs Against Jamming Attacks</a></div><div><b>Author(s):&nbsp;</b>Yingchun Wang, Xiaojie Qiu, Huaguang Zhang, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3171 - 3177</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9333591/\">Sequence Learning in a Single Trial: A Spiking Neurons Model Based on Hippocampal Circuitry</a></div><div><b>Author(s):&nbsp;</b>Simone Coppolino, Giuseppe Giacopelli, Michele Migliore</div><div><b>Pages:&nbsp;</b>3178 - 3183</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9340604/\">DNN-kWTA With Bounded Random Offset Voltage Drifts in Threshold Logic Units</a></div><div><b>Author(s):&nbsp;</b>Wenhao Lu, Chi-Sing Leung, John Sum, Yi Xiao</div><div><b>Pages:&nbsp;</b>3184 - 3192</div><div><br /></div><div><br /></div></div>", "pubdate": "2022-07-20T15:09:00.000+12:00", "pubdate_parsed": 1658266740.0, "email_sent": true}, "Upcoming Special Issues": {"url": "https://computational-intelligence.blogspot.com/2022/07/upcoming-special-issues.html", "description": "<div style=\"text-align: left;\"><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><b>IEEE Computational Intelligence Magazine</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/cim/CIM-SI-MLEMO_CFP.pdf\">Machine Learning Assisted Evolutionary Multi-Objective Optimization</a> - <u>September 1, 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/TNNLS_SI_CFP.pdf\">Explainable and Generalizable Deep Learning for Medical Imaging</a> -&nbsp;<u>1 September 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/202202-Explainable_Representation_Learning-based_Intelligent_Inspection_and_Maintenance_of_Complex_Systems.pdf\">Explainable Representation Learning-based Intelligent Inspection and Maintenance of Complex Systems</a> -&nbsp;<u>1 September 2022</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Cognitive_Learning_of_Multi-Agent_Systems-IEEE_TCDS-CFP-20211210.pdf\">Cognitive Learning of Multi-Agent Systems</a> -&nbsp;<u>September 30, 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Publications/TNNLS/special-issues/proposal_TNNLS_2.27_new.pdf\">Information Theoretic Methods for the Generalization, Robustness and Interpretability of Machine Learning</a> -&nbsp;<u>1 October 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/New_SI.pdf\">Deep Learning for Intelligent Media Computing and Applications</a> -&nbsp;<u>30 October 2022</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Movement_Sciences_in_Cognitive_Systems_CFP_2022.pdf\">Movement Sciences in Cognitive Systems</a> -&nbsp;<u>6 January 2023</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Advancing_Machine_Intelligence_with_Neuromorphic_Computing-CFP2022.pdf\">Advancing Machine Intelligence with Neuromorphic Computing</a> -&nbsp;<u>31 January 2023</u></li><li><b>IEEE Transactions on Emerging Topics in Computational Intelligence</b> - <a href=\"https://cis.ieee.org/images/files/Publications/TETCI/SI26_CFP_RSCAI.pdf\">Resource Sustainable Computational and Artificial Intelligence</a> -&nbsp;<u>1 February 2023</u></li></ul></div><div><br /></div></div>", "pubdate": "2022-07-21T12:00:00.001+12:00", "pubdate_parsed": 1658341800.0, "email_sent": true}, "IEEE Transactions on Emerging Topics in Computational Intelligence, Volume 6, Issue 4": {"url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-emerging-topics-in.html", "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9834992/\">Guest Editorial Special Issue on Computational Intelligence for IoT-based Human Activity Recognition</a></div><div><b>Author(s): </b>Xiaoli Li, Huanhuan Chen, Thomas Ploetz, Min Wu, Zhenghua Chen</div><div><b>Pages: </b>725 - 727</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9546996/\">Evolutionary Dual-Ensemble Class Imbalance Learning for Human Activity Recognition</a></div><div><b>Author(s):&nbsp;</b>Yinan Guo, Yaoqi Chu, Botao Jiao, Jian Cheng, Zekuan Yu, Ning Cui, Lianbo Ma</div><div><b>Pages:&nbsp;</b>728 - 739</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9720134/\">Real-Time Activities of Daily Living Recognition Under Long-Tailed Class Distribution</a></div><div><b>Author(s):&nbsp;</b>Atul Chaudhary, Hari Prabhat Gupta, K. K. Shukla</div><div><b>Pages:&nbsp;</b>740 - 750</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9724169/\">MOCLoc: Emerging Online Collaborative Localization Enhanced by Multidimensional Scaling</a></div><div><b>Author(s):&nbsp;</b>Chanxin Zhou, Bang Wang, Yijun Mo, Zeng Zeng</div><div><b>Pages:&nbsp;</b>751 - 761</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9779097/\">Trends and Prospects of Techniques for Haze Removal From Degraded Images: A Survey</a></div><div><b>Author(s):&nbsp;</b>Geet Sahu, Ayan Seal, Debotosh Bhattacharjee, Mita Nasipuri, Peter Brida, Ondrej Krejcar</div><div><b>Pages:&nbsp;</b>762 - 782</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9686068/\">Evolutionary Architectural Search for Generative Adversarial Networks</a></div><div><b>Author(s):&nbsp;</b>Qiuzhen Lin, Zhixiong Fang, Yi Chen, Kay Chen Tan, Yun Li</div><div><b>Pages:&nbsp;</b>783 - 794</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9600838/\">Generating Black-Box Adversarial Examples in Sparse Domain</a></div><div><b>Author(s):&nbsp;</b>Hadi Zanddizari, Behnam Zeinali, J. Morris Chang</div><div><b>Pages:&nbsp;</b>795 - 804</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9472875/\">A Novel Evolutionary Algorithm Based on Judgment-Rule Evolution Strategy for Structural Balance in Signed Social Networks</a></div><div><b>Author(s):&nbsp;</b>Mingzhou Yang, Xingwei Wang, Min Huang, Lianbo Ma, Qiang He</div><div><b>Pages:&nbsp;</b>805 - 817</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9582815/\">Multiobjective Multitasking Optimization With Subspace Distribution Alignment and Decision Variable Transfer</a></div><div><b>Author(s):&nbsp;</b>Weifeng Gao, Jiangli Cheng, Maoguo Gong, Hong Li, Jin Xie</div><div><b>Pages:&nbsp;</b>818 - 827</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9564251/\">Transfer Clustering Using a Multiple Kernel Metric Learned Under Multi-Instance Weak Supervision</a></div><div><b>Author(s):&nbsp;</b>Avisek Gupta, Swagatam Das</div><div><b>Pages:&nbsp;</b>828 - 838</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9615029/\">Dynamic Path Planning for Unmanned Aerial Vehicles Under Deadline and Sector Capacity Constraints</a></div><div><b>Author(s):&nbsp;</b>Sudharsan Vaidhun, Zhishan Guo, Jiang Bian, Haoyi Xiong, Sajal K. Das</div><div><b>Pages:&nbsp;</b>839 - 851</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9586052/\">A Robust Non-Integer Controller Design for Load Frequency Control in Modern Marine Power Grids</a></div><div><b>Author(s):&nbsp;</b>B. Yildirim, M. Gheisarnejad, M. H. Khooban</div><div><b>Pages:&nbsp;</b>852 - 866</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9586057/\">A Weighted Portfolio Optimization Model Based on the Trend Ratio, Emotion Index, and ANGQTS</a></div><div><b>Author(s):&nbsp;</b>Yao-Hsin Chou, Yu-Chi Jiang, Yi-Rui Hsu, Shu-Yu Kuo, Sy-Yen Kuo</div><div><b>Pages:&nbsp;</b>867 - 882</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9671053/\">Do Models Learn the Directionality of Relations? A New Evaluation: Relation Direction Recognition</a></div><div><b>Author(s):&nbsp;</b>Shengfei Lyu, Xingyu Wu, Jinlong Li, Qiuju Chen, Huanhuan Chen</div><div><b>Pages:&nbsp;</b>883 - 892</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9628017/\">Quaternion Capsule Neural Network With Region Attention for Facial Expression Recognition in Color Images</a></div><div><b>Author(s):&nbsp;</b>Yu Zhou, Lianghai Jin, Guangzhi Ma, Xiangyang Xu</div><div><b>Pages:&nbsp;</b>893 - 912</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9475074/\">Unbalanced Incomplete Multi-View Clustering Via the Scheme of View Evolution: Weak Views are Meat,&nbsp; Strong Views Do Eat</a></div><div><b>Author(s):&nbsp;</b>Xiang Fang, Yuchong Hu, Pan Zhou, Dapeng Oliver Wu</div><div><b>Pages:&nbsp;</b>913 - 927</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9655256/\">EDITH : ECG Biometrics Aided by Deep Learning for Reliable Individual Authentication</a></div><div><b>Author(s):&nbsp;</b>Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, Tawsifur Rahman</div><div><b>Pages:&nbsp;</b>928 - 940</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9576096/\">Efficient Privacy Preserving Edge Intelligent Computing Framework for Image Classification in IoT</a></div><div><b>Author(s):&nbsp;</b>Omobayode Fagbohungbe, Sheikh Rufsan Reza, Xishuang Dong, Lijun Qian</div><div><b>Pages:&nbsp;</b>941 - 956</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9583676/\">APNet: Adversarial Learning Assistance and Perceived Importance Fusion Network for All-Day RGB-T Salient Object Detection</a></div><div><b>Author(s):&nbsp;</b>Wujie Zhou, Yun Zhu, Jingsheng Lei, Jian Wan, Lu Yu</div><div><b>Pages:&nbsp;</b>957 - 968</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9615378/\">A Novel Test Case Generation Approach for Adaptive Random Testing of Object-Oriented Software Using K-Means Clustering Technique</a></div><div><b>Author(s):&nbsp;</b>Jinfu Chen, Haibo Chen, Yuchi Guo, Minmin Zhou, Rubing Huang, Chengying Mao</div><div><b>Pages:&nbsp;</b>969 - 981</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9772749/\">Data Embedding Scheme for Efficient Program Behavior Modeling With Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Sunwoo Ahn, Hayoon Yi, Ho Bae, Sungroh Yoon, Yunheung Paek</div><div><b>Pages:&nbsp;</b>982 - 993</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9704877/\">Half Quadratic Dual Learning for Fuzzy Multiconcepts of Partially-Observed Images</a></div><div><b>Author(s):&nbsp;</b>Bo-Wei Chen, Kuan-Lin Hou</div><div><b>Pages:&nbsp;</b>994 - 1007</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9712322/\">Obtaining Fuzzy Membership Function of Clusters With the Memristor Hardware Implementation and On-Chip Learning</a></div><div><b>Author(s):&nbsp;</b>Mohammad Javadian, Arian Hejazi, Sajad Haghzad Klidbary</div><div><b>Pages:&nbsp;</b>1008 - 1025</div><div><br /></div>", "pubdate": "2022-07-29T12:00:00.001+12:00", "pubdate_parsed": 1659033000.0, "email_sent": true}, "IEEE Transactions on Artificial Intelligence, Volume 3, Issue 4": {"url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-artificial.html", "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9591342/\">Balanced Graph Cut With Exponential Inter-Cluster Compactness</a></div><div><b>Author(s): </b>Danyang Wu, Feiping Nie, Jitao Lu, Rong Wang, Xuelong Li</div><div><b>Pages: </b>498 - 505</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9695289/\">Efficient Temporal Piecewise-Linear Numeric Planning With Lazy Consistency Checking</a></div><div><b>Author(s):&nbsp;</b>Josef Bajada, Maria Fox, Derek Long</div><div><b>Pages:&nbsp;</b>506 - 517</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9612034/\">Ignorance is Bliss: Exploring Defenses Against Invariance-Based Attacks on Neural Machine Translation Systems</a></div><div><b>Author(s):&nbsp;</b>Akshay Chaturvedi, Abhisek Chakrabarty, Masao Utiyama, Eiichiro Sumita, Utpal Garain</div><div><b>Pages:&nbsp;</b>518 - 525</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9618852/\">ArcText: A Unified Text Approach to Describing Convolutional Neural Network Architectures</a></div><div><b>Author(s):&nbsp;</b>Yanan Sun, Gary G. Yen, Bing Xue, Mengjie Zhang, Jiancheng Lv</div><div><b>Pages:&nbsp;</b>526 - 540</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9652037/\">Histogram Layers for Texture Analysis</a></div><div><b>Author(s):&nbsp;</b>Joshua Peeples, Weihuang Xu, Alina Zare</div><div><b>Pages:&nbsp;</b>541 - 552</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9613742/\">Traded Control of Human\u2013Machine Systems for Sequential Decision-Making Based on Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Qianqian Zhang, Yu Kang, Yun-Bo Zhao, Pengfei Li, Shiyi You</div><div><b>Pages:&nbsp;</b>553 - 566</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9612040/\">Potential Impacts of Smart Homes on Human Behavior: A Reinforcement Learning Approach</a></div><div><b>Author(s):&nbsp;</b>Shashi Suman, Ali Etemad, Francois Rivest</div><div><b>Pages:&nbsp;</b>567 - 580</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9612064/\">Multiadvisor Reinforcement Learning for Multiagent Multiobjective Smart Home Energy Control</a></div><div><b>Author(s):&nbsp;</b>Andrew Tittaferrante, Abdulsalam Yassine</div><div><b>Pages:&nbsp;</b>581 - 594</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9614997/\">On a Sparse Shortcut Topology of Artificial Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Feng-Lei Fan, Dayang Wang, Hengtao Guo, Qikui Zhu, Pingkun Yan, Ge Wang, Hengyong Yu</div><div><b>Pages:&nbsp;</b>595 - 608</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9594655/\">CSNAS: Contrastive Self-Supervised Learning Neural Architecture Search Via Sequential Model-Based Optimization</a></div><div><b>Author(s):&nbsp;</b>Nam Nguyen, J. Morris Chang</div><div><b>Pages:&nbsp;</b>609 - 624</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9652108/\">Perturbed Composite Attention Model for Macular Optical Coherence Tomography Image Classification</a></div><div><b>Author(s):&nbsp;</b>Sapna S. Mishra, Bappaditya Mandal, Niladri B. Puhan</div><div><b>Pages:&nbsp;</b>625 - 635</div><div><br /></div>", "pubdate": "2022-07-30T12:00:00.041+12:00", "pubdate_parsed": 1659119400.0, "email_sent": true}}, "TopBots Blog": {}}