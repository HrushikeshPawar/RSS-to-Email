{
    "DeepMind Blog": {
        "Working together with YouTube": {
            "url": "https://www.deepmind.com/blog/working-together-with-youtube",
            "description": "",
            "pubdate": "Thu, 14 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": 1657737000.0,
            "email_sent": true
        },
        "DeepMind\u2019s latest research at ICML 2022": {
            "url": "https://www.deepmind.com/blog/deepminds-latest-research-at-icml-2022",
            "description": "Starting this weekend, the thirty-ninth International Conference on Machine Learning (ICML 2022) is meeting from 17-23 July, 2022 at the Baltimore Convention Center in Maryland, USA, and will be running as a hybrid event. Researchers working across artificial intelligence, data science, machine vision, computational biology, speech recognition, and more are presenting and publishing their cutting-edge work in machine learning.",
            "pubdate": "Fri, 15 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": 1657823400.0,
            "email_sent": true
        },
        "The virtuous cycle of AI research": {
            "url": "https://www.deepmind.com/blog/the-virtuous-cycle-of-ai-research",
            "description": "We recently caught up with Petar Veli\u010dkovi\u0107, a research scientist at DeepMind. Along with his co-authors, Petar is presenting his paper The CLRS Algorithmic Reasoning Benchmark at ICML 2022 in Baltimore, Maryland, USA.",
            "pubdate": "Tue, 19 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": 1658169000.0,
            "email_sent": true
        },
        "AlphaFold reveals the structure of the protein universe": {
            "url": "https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe",
            "description": "Today, in partnership with EMBL\u2019s European Bioinformatics Institute (EMBL-EBI), we\u2019re now releasing predicted structures for nearly all catalogued proteins known to science, which will expand the AlphaFold DB by over 200x - from nearly 1 million structures to over 200 million structures - with the potential to dramatically increase our understanding of biology.",
            "pubdate": "Thu, 28 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": 1658946600.0,
            "email_sent": true
        },
        "Discovering when an agent is present in a system": {
            "url": "https://www.deepmind.com/blog/discovering-when-an-agent-is-present-in-a-system",
            "description": "We want to build safe, aligned artificial general intelligence (AGI) systems that pursue the intended goals of its designers. Causal influence diagrams (CIDs) are a way to model decision-making situations that allow us to reason about agent incentives. By relating training setups to the incentives that shape agent behaviour, CIDs help illuminate potential risks before training an agent and can inspire better agent designs. But how do we know when a CID is an accurate model of a training setup?",
            "pubdate": "Thu, 18 Aug 2022 00:00:00 GMT",
            "pubdate_parsed": 1660780800.0,
            "email_sent": true
        },
        "Advancing conservation with AI-based facial recognition of turtles": {
            "url": "https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles",
            "description": "We came across Zindi \u2013 a dedicated partner with complementary goals \u2013 who are the largest community of African data scientists and host competitions that focus on solving Africa\u2019s most pressing problems. Our Science team\u2019s Diversity, Equity, and Inclusion (DE&amp;I) team worked with Zindi to identify a scientific challenge that could help advance conservation efforts and grow involvement in AI. Inspired by Zindi\u2019s bounding box turtle challenge, we landed on a project with the potential for real impact: turtle facial recognition.",
            "pubdate": "Thu, 25 Aug 2022 00:00:00 GMT",
            "pubdate_parsed": 1661385600.0,
            "email_sent": true
        }
    },
    "Nvidia Blog": {
        "Living on the Edge: New Features for NVIDIA Fleet Command Deliver All-in-One Edge AI Management, Maintenance for Enterprises": {
            "url": "https://blogs.nvidia.com/blog/2022/07/18/fleet-command-all-in-one-edge-ai-management/",
            "description": "<p>NVIDIA Fleet Command \u2014 a cloud service for deploying, managing and scaling AI applications at the edge \u2014 now includes features that enhance the seamless management of edge AI deployments around the world. With the scale of edge AI deployments, organizations can have up to thousands of independent edge locations that must be managed by <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/18/fleet-command-all-in-one-edge-ai-management/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/18/fleet-command-all-in-one-edge-ai-management/\" rel=\"nofollow\">Living on the Edge: New Features for NVIDIA Fleet Command Deliver All-in-One Edge AI Management, Maintenance for Enterprises</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 18 Jul 2022 16:00:12 +0000",
            "pubdate_parsed": 1658140212.0,
            "email_sent": true
        },
        "Lucid Motors\u2019 Mike Bell on Software-Defined Innovation for the Luxury EV Brand": {
            "url": "https://blogs.nvidia.com/blog/2022/07/20/lucid-motors-podcast/",
            "description": "<p>AI and electric vehicle technology breakthroughs are transforming the automotive industry. These developments pave the way for new innovators, attracting technical prowess and design philosophies from Silicon Valley. Mike Bell, senior vice president of digital at Lucid Motors, sees continuous innovation coupled with over-the-air updates as key to designing sustainable, award-winning intelligent vehicles that provide <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/20/lucid-motors-podcast/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/20/lucid-motors-podcast/\" rel=\"nofollow\">Lucid Motors&#8217; Mike Bell on Software-Defined Innovation for the Luxury EV Brand</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 20 Jul 2022 13:00:17 +0000",
            "pubdate_parsed": 1658302217.0,
            "email_sent": true
        },
        "Shifting Into High Gear: Lunit, Maker of FDA-Cleared AI for Cancer Analysis, Goes Public in Seoul": {
            "url": "https://blogs.nvidia.com/blog/2022/07/21/lunit-healthcare-ai-ipo/",
            "description": "<p>South Korean startup Lunit, developer of two FDA-cleared AI models for healthcare, went public this week on the country\u2019s Kosdaq stock market. The move marks the maturity of the Seoul-based company \u2014 which was founded in 2013 and has for years been part of the NVIDIA Inception program that nurtures cutting-edge startups. Lunit\u2019s AI software <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/21/lunit-healthcare-ai-ipo/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/21/lunit-healthcare-ai-ipo/\" rel=\"nofollow\">Shifting Into High Gear: Lunit, Maker of FDA-Cleared AI for Cancer Analysis, Goes Public in Seoul</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 21 Jul 2022 14:34:50 +0000",
            "pubdate_parsed": 1658394290.0,
            "email_sent": true
        },
        "Get Battle Ready With New GeForce NOW Fortnite Reward": {
            "url": "https://blogs.nvidia.com/blog/2022/07/21/geforce-now-thursday-july-21/",
            "description": "<p>&#60;Incoming Transmission&#62; Epic Games is bringing a new Fortnite reward to GeForce NOW, available to all members. Drop from the Battle Bus in Fortnite on GeForce NOW between today and Thursday, Aug. 4, to earn \u201cThe Dish-stroyer Pickaxe\u201d in game for free. &#60;Transmission continues&#62; Members can earn this item by streaming Fortnite on GeForce NOW <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/21/geforce-now-thursday-july-21/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/21/geforce-now-thursday-july-21/\" rel=\"nofollow\">Get Battle Ready With New GeForce NOW Fortnite Reward</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 21 Jul 2022 13:00:40 +0000",
            "pubdate_parsed": 1658388640.0,
            "email_sent": true
        },
        "Researchers Use GPUs to Give Earbud Users a \u2018Mute Button\u2019 for Background Noise": {
            "url": "https://blogs.nvidia.com/blog/2022/07/21/mute-button-clearbuds/",
            "description": "<p>Thanks to earbuds you can have calls anywhere while doing anything. The problem: those on the other end of the call hear it all, too, from your roommate\u2019s vacuum cleaner to background conversations at the cafe you\u2019re working from. Now, work by a trio of graduate students at the University of Washington who spent the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/21/mute-button-clearbuds/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/21/mute-button-clearbuds/\" rel=\"nofollow\">Researchers Use GPUs to Give Earbud Users a \u2018Mute Button\u2019 for Background Noise</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 21 Jul 2022 13:00:03 +0000",
            "pubdate_parsed": 1658388603.0,
            "email_sent": true
        },
        "Digital Sculptor Does Heavy Lifting With Lightweight Mobile Workstation": {
            "url": "https://blogs.nvidia.com/blog/2022/07/25/marlon-nunez-rtx/",
            "description": "<p>As a professional digital sculptor, Marlon Nu\u00f1ez is on a mission to make learning 3D art skills easier, smoother and more fun for all. And with the help of an NVIDIA RTX-powered Lenovo mobile workstation, he takes his 3D projects to the next level, wherever he goes. Nu\u00f1ez is the art director and co-founder of <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/25/marlon-nunez-rtx/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/25/marlon-nunez-rtx/\" rel=\"nofollow\">Digital Sculptor Does Heavy Lifting With Lightweight Mobile Workstation</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 25 Jul 2022 16:00:48 +0000",
            "pubdate_parsed": 1658745048.0,
            "email_sent": true
        },
        "What Is an Exaflop?": {
            "url": "https://blogs.nvidia.com/blog/2022/07/26/what-is-an-exaflop/",
            "description": "<p>Computers are crunching more numbers than ever to crack the most complex problems of our time \u2014 how to cure diseases like COVID and cancer, mitigate climate change and more. These and other grand challenges ushered computing into today\u2019s exascale era when top performance is often measured in exaflops. So, What\u2019s an Exaflop? An exaflop <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/26/what-is-an-exaflop/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/26/what-is-an-exaflop/\" rel=\"nofollow\">What Is an Exaflop?</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 26 Jul 2022 15:00:29 +0000",
            "pubdate_parsed": 1658827829.0,
            "email_sent": true
        },
        "July NVIDIA Studio Driver Improves Performance for Chaos V-Ray 6 for 3ds Max": {
            "url": "https://blogs.nvidia.com/blog/2022/07/26/in-the-nvidia-studio-july-26/",
            "description": "<p>Creativity heats up In the NVIDIA Studio as the July NVIDIA Studio Driver, available now, accelerates the recent Chaos V-Ray 6 for 3ds Max release.Plus, this week\u2019s In the NVIDIA Studio 3D artist, Brian Lai, showcases his development process for Afternoon Coffee and Waffle, a piece that went from concept to completion faster with NVIDIA RTX acceleration in Chaos V-Ray rendering software.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/26/in-the-nvidia-studio-july-26/\" rel=\"nofollow\">July NVIDIA Studio Driver Improves Performance for Chaos V-Ray 6 for 3ds Max</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 26 Jul 2022 13:00:29 +0000",
            "pubdate_parsed": 1658820629.0,
            "email_sent": true
        },
        "1,650+ Global Interns Gleam With NVIDIA Green": {
            "url": "https://blogs.nvidia.com/blog/2022/07/28/internship-virtual-2022/",
            "description": "<p>A record number of interns calls for a record-sized celebration. In our largest contingent ever, over 1,650 interns from 350+ schools started with NVIDIA worldwide over the past year. Amidst busy work days tackling real-world projects across engineering, automation, robotics and more, the group\u2019s also finishing up a three-day celebration, culminating today with National Intern <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/28/internship-virtual-2022/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/internship-virtual-2022/\" rel=\"nofollow\">1,650+ Global Interns Gleam With NVIDIA Green</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 28 Jul 2022 18:10:00 +0000",
            "pubdate_parsed": 1659012000.0,
            "email_sent": true
        },
        "Pony.ai Express: New Autonomous Trucking Collaboration Powered by NVIDIA DRIVE Orin": {
            "url": "https://blogs.nvidia.com/blog/2022/07/28/pony-ai-sany-autonomous-trucking-drive-orin/",
            "description": "<p>More than 160 years after the legendary Pony Express delivery service completed its first route, a new generation of \u201cPony\u201d-emblazoned vehicles are taking an AI-powered approach to long-haul delivery. Autonomous driving company Pony.ai announced today a partnership with SANY Heavy Truck (SANY), China\u2019s largest heavy equipment manufacturer, to jointly develop level 4 autonomous trucks. The <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/28/pony-ai-sany-autonomous-trucking-drive-orin/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/pony-ai-sany-autonomous-trucking-drive-orin/\" rel=\"nofollow\">Pony.ai Express: New Autonomous Trucking Collaboration Powered by NVIDIA DRIVE Orin</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 28 Jul 2022 15:51:22 +0000",
            "pubdate_parsed": 1659003682.0,
            "email_sent": true
        },
        "Welcome Back, Commander: \u2018Command & Conquer Remastered Collection\u2019 Joins GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2022/07/28/geforce-now-thursday-july-28/",
            "description": "<p>Take a trip down memory lane this week with an instantly recognizable classic, Command &#38; Conquer Remastered Collection, joining the nearly 20 Electronic Arts games streaming from the GeForce NOW library. Speaking of remastered, GeForce NOW members can enhance their gameplay further with improved resolution scaling in the 2.0.43 app update. When the feature is <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/28/geforce-now-thursday-july-28/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/geforce-now-thursday-july-28/\" rel=\"nofollow\">Welcome Back, Commander: \u2018Command &amp; Conquer Remastered Collection\u2019 Joins GeForce NOW</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 28 Jul 2022 13:00:47 +0000",
            "pubdate_parsed": 1658993447.0,
            "email_sent": true
        },
        "NVIDIA Studio Laptops Offer Students AI, Creative Capabilities That Are Best in\u2026 Class": {
            "url": "https://blogs.nvidia.com/blog/2022/07/28/back-to-school-buying-guide/",
            "description": "<p>Selecting the right laptop is a lot like trying to pick the right major. Both can be challenging tasks where choosing wrongly costs countless hours. But pick the right one, and graduation is just around the corner. The tips below can help the next generation of artists select the ideal NVIDIA Studio laptop to maximize performance for the critical workload demands of their unique creative fields \u2014 all within budget.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/28/back-to-school-buying-guide/\" rel=\"nofollow\">NVIDIA Studio Laptops Offer Students AI, Creative Capabilities That Are Best in&#8230; Class</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 28 Jul 2022 13:00:18 +0000",
            "pubdate_parsed": 1658993418.0,
            "email_sent": true
        },
        "How\u2019s That? Startup Ups Game for Cricket, Football and More With Vision AI": {
            "url": "https://blogs.nvidia.com/blog/2022/07/27/tvconal-sports-video-analytics/",
            "description": "<p>Sports produce a slew of data. In a game of cricket, for example, each play generates millions of video-frame data points for a sports analyst to scrutinize, according to Masoumeh Izadi, managing director of deep-tech startup TVConal. The Singapore-based company uses NVIDIA AI and computer vision to power its sports video analytics platform, which enables <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/27/tvconal-sports-video-analytics/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/27/tvconal-sports-video-analytics/\" rel=\"nofollow\">How\u2019s That? Startup Ups Game for Cricket, Football and More With Vision AI</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 28 Jul 2022 03:00:59 +0000",
            "pubdate_parsed": 1658957459.0,
            "email_sent": true
        },
        "What Is a QPU?": {
            "url": "https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/",
            "description": "<p>Just as GPUs and DPUs enable accelerated computing today, they\u2019re also helping a new kind of chip, the QPU, boot up the promise of quantum computing. In your hand, a quantum processing unit might look and feel very similar to a graphics or a data processing unit. They\u2019re all typically chips, or modules with multiple <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/07/29/what-is-a-qpu/\" rel=\"nofollow\">What Is a QPU?</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Fri, 29 Jul 2022 15:00:49 +0000",
            "pubdate_parsed": 1659087049.0,
            "email_sent": true
        },
        "Meet the Omnivore: Developer Builds Bots With NVIDIA Omniverse and Isaac Sim": {
            "url": "https://blogs.nvidia.com/blog/2022/08/01/omniverse-developer-antonio-serrano-munoz/",
            "description": "<p>While still in grad school, Antonio Serrano-Mu\u00f1oz has helped author papers spanning planetary gravities, AI-powered diagnosis of rheumatoid arthritis and robots that precisely track millimetric-sized walkers, like ants. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/01/omniverse-developer-antonio-serrano-munoz/\" rel=\"nofollow\">Meet the Omnivore: Developer Builds Bots With NVIDIA Omniverse and Isaac Sim</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 01 Aug 2022 16:01:47 +0000",
            "pubdate_parsed": 1659349907.0,
            "email_sent": true
        },
        "Sensational Surrealism Astonishes This Week \u2018In the NVIDIA Studio\u2019": {
            "url": "https://blogs.nvidia.com/blog/2022/08/02/in-the-nvidia-studio-aug-02/",
            "description": "<p>3D phenom FESQ joins us 'In the NVIDIA Studio' this week to share his sensational and surreal animation 'Double/Sided' as well as an inside look into his creative workflow. 'Double/Sided' is deeply personal to FESQ, who said the piece \u201ctranslates really well to a certain period of my life when I was juggling both a programmer career and an artist career.\u201d</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/02/in-the-nvidia-studio-aug-02/\" rel=\"nofollow\">Sensational Surrealism Astonishes This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 02 Aug 2022 13:00:23 +0000",
            "pubdate_parsed": 1659425423.0,
            "email_sent": true
        },
        "AI Flying Off the Shelves: Restocking Robot Rolls Out to Hundreds of Japanese Convenience Stores": {
            "url": "https://blogs.nvidia.com/blog/2022/08/10/telexistence-convenience-store-robotics/",
            "description": "<p>Tokyo-based startup Telexistence this week announced it will deploy NVIDIA AI-powered robots to restock shelves at hundreds of FamilyMart convenience stores in Japan. There are 56,000 convenience stores in Japan \u2014 the third-highest density worldwide. Around 16,000 of them are run by FamilyMart. Telexistence aims to save time for these stores by offloading repetitive tasks <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/10/telexistence-convenience-store-robotics/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/10/telexistence-convenience-store-robotics/\" rel=\"nofollow\">AI Flying Off the Shelves: Restocking Robot Rolls Out to Hundreds of Japanese Convenience Stores</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 10 Aug 2022 13:00:41 +0000",
            "pubdate_parsed": 1660136441.0,
            "email_sent": true
        },
        "GFN Thursday Brings Thunder to the Cloud With \u2018Rumbleverse\u2019 Arriving on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2022/08/11/geforce-now-thursday-august-11/",
            "description": "<p>It\u2019s time to rumble in Grapital City with Rumbleverse launching today on GeForce NOW. Punch your way into the all-new, free-to-play Brawler Royale from Iron Galaxy Studios and Epic Games Publishing, streaming from the cloud to nearly all devices. That means gamers can tackle, uppercut, body slam and more from any GeForce NOW-compatible device, including <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/11/geforce-now-thursday-august-11/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/11/geforce-now-thursday-august-11/\" rel=\"nofollow\">GFN Thursday Brings Thunder to the Cloud With \u2018Rumbleverse&#8217; Arriving on GeForce NOW</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 11 Aug 2022 13:00:32 +0000",
            "pubdate_parsed": 1660222832.0,
            "email_sent": true
        },
        "Digital Art Professor Kate Parsons Inspires Next Generation of Creators This Week \u2018In the NVIDIA Studio\u2019": {
            "url": "https://blogs.nvidia.com/blog/2022/08/16/in-the-nvidia-studio-august-16/",
            "description": "<p>Many artists can edit a video, paint a picture or build a model \u2014 but transforming one\u2019s imagination into stunning creations can now involve breakthrough design technologies. Kate Parsons, a digital art professor at Pepperdine University and this week\u2019s featured In the NVIDIA Studio artist, helped bring a music video for How Do I Get to Invincible to life using virtual reality and NVIDIA GeForce RTX GPUs. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/16/in-the-nvidia-studio-august-16/\" rel=\"nofollow\">Digital Art Professor Kate Parsons Inspires Next Generation of Creators This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 16 Aug 2022 13:00:48 +0000",
            "pubdate_parsed": 1660654848.0,
            "email_sent": true
        },
        "Easy A: GeForce NOW Brings Higher Resolution and Frame Rates for Browser Streaming on PC": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/geforce-now-thursday-august-18/",
            "description": "<p>Class is in session this GFN Thursday as GeForce NOW makes the up-grade with support for higher resolutions and frame rates in Chrome browser on PC. It\u2019s the easiest way to spice up a boring study session. When the lecture is over, dive into the six games joining the GeForce NOW library this week, where <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/geforce-now-thursday-august-18/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/geforce-now-thursday-august-18/\" rel=\"nofollow\">Easy A: GeForce NOW Brings Higher Resolution and Frame Rates for Browser Streaming on PC</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 13:00:55 +0000",
            "pubdate_parsed": 1660827655.0,
            "email_sent": true
        },
        "Startup Digs Into Public Filings With GPU-Driven Machine Learning to Serve Up Alternative Financial Data Services": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/gpu-driven-machine-learning-alternative-financial-data-services/",
            "description": "<p>When Rachel Carpenter and Joseph French founded Intrinio a decade ago, the fintech revolution had only just begun. But they saw an opportunity to apply machine learning to vast amounts of financial filings to create an alternative data provider among the giants. The startup, based in St. Petersburg, Fla., delivers financial data to hedge funds, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/gpu-driven-machine-learning-alternative-financial-data-services/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/gpu-driven-machine-learning-alternative-financial-data-services/\" rel=\"nofollow\">Startup Digs Into Public Filings With GPU-Driven Machine Learning to Serve Up Alternative Financial Data Services</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 16:06:46 +0000",
            "pubdate_parsed": 1660838806.0,
            "email_sent": true
        },
        "Boldly Go: Discover New Frontiers in AI-Powered Transportation at GTC": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/discover-frontiers-ai-autonomous-vehicles-gtc/",
            "description": "<p>AI and the metaverse are revolutionizing every aspect of the way we live, work and play \u2014 including how we move. Leaders in the automotive and technology industries will come together at NVIDIA GTC to discuss the newest breakthroughs driving intelligent vehicles, whether in the real world or in simulation. The virtual conference, which runs <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/discover-frontiers-ai-autonomous-vehicles-gtc/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/discover-frontiers-ai-autonomous-vehicles-gtc/\" rel=\"nofollow\">Boldly Go: Discover New Frontiers in AI-Powered Transportation at GTC</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 15:32:48 +0000",
            "pubdate_parsed": 1660836768.0,
            "email_sent": true
        },
        "Startup\u2019s Vision AI Software Trains Itself \u2014 in One Hour \u2014 to Detect Manufacturing Defects in Real Time": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/covision-visual-inspection-for-manufacturing/",
            "description": "<p>Cameras have been deployed in factories for over a decade \u2014 so why, Franz Tschimben wondered, hasn\u2019t automated visual inspection yet become the worldwide standard? This question motivated Tschimben and his colleagues to found Covision Quality, an AI-based visual-inspection software startup that uses NVIDIA technology to transform end-of-line defect detection for the manufacturing industry. \u201cThe <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/covision-visual-inspection-for-manufacturing/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/covision-visual-inspection-for-manufacturing/\" rel=\"nofollow\">Startup\u2019s Vision AI Software Trains Itself \u2014 in One Hour \u2014 to Detect Manufacturing Defects in Real Time</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 15:00:39 +0000",
            "pubdate_parsed": 1660834839.0,
            "email_sent": true
        },
        "An AI-Enabled Drone Could Soon Become Every Rhino Poacher\u2019s\u2026 Horn Enemy": {
            "url": "https://blogs.nvidia.com/blog/2022/08/22/ai-drone-rhino-poachers/",
            "description": "<p>Watching out for the nearly-extinct two-ton beasts may be the ultimate example of a job best done remotely.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/22/ai-drone-rhino-poachers/\" rel=\"nofollow\">An AI-Enabled Drone Could Soon Become Every Rhino Poacher&#8217;s\u2026 Horn Enemy</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 22 Aug 2022 13:00:59 +0000",
            "pubdate_parsed": 1661173259.0,
            "email_sent": true
        },
        "3D Artists Reimagine, Remaster Iconic European Architecture This Week \u2018In the NVIDIA Studio\u2019": {
            "url": "https://blogs.nvidia.com/blog/2022/08/23/in-the-nvidia-studio-august-23/",
            "description": "<p>A triple threat steps In the NVIDIA Studio this week: a tantalizing trio of talented 3D artists who each reimagined and remastered classic European buildings with individualistic flair. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/23/in-the-nvidia-studio-august-23/\" rel=\"nofollow\">3D Artists Reimagine, Remaster Iconic European Architecture This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 23 Aug 2022 13:00:35 +0000",
            "pubdate_parsed": 1661259635.0,
            "email_sent": true
        },
        "GFN Thursday Adds \u2018Saints Row,\u2019 \u2018Genshin Impact\u2019 on Mobile With Touch Controls": {
            "url": "https://blogs.nvidia.com/blog/2022/08/25/geforce-now-thursday-august-25/",
            "description": "<p>Some weeks, GFN Thursday reveals new or unique features. Other weeks, it\u2019s a cool reward. And every week, it offers its members new games. This week, it\u2019s all of the above. First, Saints Row marches into GeForce NOW. Be your own boss in the new reboot of the classic open-world criminal adventure series, now available <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/25/geforce-now-thursday-august-25/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/25/geforce-now-thursday-august-25/\" rel=\"nofollow\">GFN Thursday Adds \u2018Saints Row,\u2019 \u2018Genshin Impact\u2019 on Mobile With Touch Controls</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 25 Aug 2022 13:00:02 +0000",
            "pubdate_parsed": 1661432402.0,
            "email_sent": true
        }
    },
    "CMU Machine Learning Blog": {
        "Does AutoML work for diverse tasks?": {
            "url": "https://blog.ml.cmu.edu/2022/07/07/automl-for-diverse-tasks/",
            "description": "Over the past decade, machine learning (ML) has grown rapidly in both popularity and complexity. Driven by advances in deep neural networks, ML is now being applied far beyond its traditional domains like computer vision and text processing, with applications in areas as diverse as solving partial differential equations (PDEs), tracking credit card fraud, and predicting medical conditions from gene sequences. However, progress in such areas has often required expert-driven development of complex neural network architectures, expensive hyperparameter tuning, or both. Given that such resource intensive iteration is expensive and inaccessible to most practitioners, AutoML has emerged with an overarching goal of enabling any team of ML developers to deploy ML on arbitrary new tasks. Here we ask about the current status of AutoML, namely: can available AutoML tools quickly and painlessly attain near-expert performance on diverse learning tasks? This blog post is dedicated to two recent but related efforts that measure the field\u2019s current effectiveness at achieving this goal: NAS-Bench-360 and the AutoML Decathlon. The first is a benchmark suite focusing on the burgeoning field of neural architecture search (NAS), which seeks to automate the development of neural network models. With evaluations on ten diverse tasks\u2014including a precomputed tabular [&#8230;]",
            "pubdate": "Thu, 07 Jul 2022 18:16:30 +0000",
            "pubdate_parsed": 1657197990.0,
            "email_sent": true
        }
    },
    "TensorFlow Blog": {
        "How Roboflow enables thousands of developers to use computer vision with TensorFlow.js": {
            "url": "https://blog.tensorflow.org/2022/07/how-roboflow-enables-thousands-of-developers-to-use-computer-vision-with-TensorFlow.js.html",
            "description": "<p><em>A guest post by <a href=\"https://twitter.com/braddwyer\" target=\"_blank\">Brad Dwyer</a>, co-founder and CTO, Roboflow</em></p><p> </p><a name=\"more\"></a><p></p> <p><a href=\"https://roboflow.com\" target=\"_blank\">Roboflow</a> lets developers build their own computer vision applications, from data preparation and model training to deployment and active learning. Through building <a href=\"https://twitter.com/braddwyer/status/910030265006923776\" target=\"_blank\">our own applications</a>, we learned firsthand how tedious it can be to train and deploy a computer vision model. That\u2019s why we launched Roboflow in January 2020 \u2013 we believe every developer should have computer vision available in their toolkit. Our mission is to remove any barriers that might prevent them from succeeding. </p><p>Our end-to-end computer vision platform simplifies the process of collecting images, creating datasets, training models, and deploying them to production. Over 100,000 developers build with Roboflow\u2019s tools. TensorFlow.js makes up a core part of<a href=\"https://docs.roboflow.com/inference\" target=\"_blank\"> Roboflow's deployment stack</a> that has<a href=\"https://blog.roboflow.com/computer-vision-datasets-and-apis/\" target=\"_blank\"> now powered over 10,000 projects</a> created by developers around the world. </p><p>As an early design decision, we decided that, in order to provide the best user experience, we needed to be able to run users' models directly in their web browser (along with our API, edge devices, and on-prem) instead of requiring a round-trip to our servers. The three primary concerns that motivated this decision were latency, bandwidth, and cost. </p><p>For example, Roboflow powers<a href=\"https://spelltable.wizards.com/\" target=\"_blank\"> SpellTable</a>'s<a href=\"https://twitter.com/SpellTable/status/1491877698293092352\" target=\"_blank\"> Codex</a> feature which uses a computer vision model to identify <em>Magic: The Gathering</em> cards. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRIq1GZCW_M4yiPxRQqUfY9TAGkxrRZ_s3peedpES5VyFHkMOK-eVumBaW-pwoE_A3Q9IX_ar4Zp9HzDoQdxX4W4SgCXjgcKYt3BHjmbWyteaS-GegM9ya8OyzUKIouFq9mqxJcXclzwfsNrQMfcnEBN5ScGfIQuSgka_7kJk9IlEeb4cjqCzrPv0d/s1600/Roboflow%20blog%202.gif\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>From <a href=\"https://twitter.com/SpellTable/status/1491877698293092352\" target=\"_blank\">Twitter</a></i></td></tr></tbody></table> <h3><strong>How Roboflow Uses TensorFlow.js</strong></h3>  <p>Whenever a user's model finishes<a href=\"https://docs.roboflow.com/train\" target=\"_blank\"> training on Roboflow's backend</a>, the model is converted and automatically converted to support sevel various deployment targets; one of those targets is TensorFlow.js. While TensorFlow.js is not the only way to <a href=\"https://roboflow.com/deploy\" target=\"_blank\">deploy a computer vision model</a> with Roboflow, some ways TensorFlow.js powers features within Roboflow include: </p><h4><strong>roboflow.js</strong></h4>  <p><a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\">roboflow.js</a> is a JavaScript SDK developers can use to integrate their trained model into a web app or Node.js app. Check this video for a quick introduction: </p> <div class=\"separator\" style=\"clear: both; text-align: left;\"></div><h4><strong>Inference Server</strong></h4><p><a href=\"https://github.com/roboflow-ai/inference-server\" target=\"_blank\">The Roboflow Inference Server</a> is a cross-platform microservice that enables developers to self-host and serve their model on-prem. (Note: while not all of Roboflow\u2019s inference servers are TFjs-based, it is one supported means of model deployment.) </p><p>The <a href=\"https://github.com/tensorflow/tfjs/tree/master/tfjs-node\" target=\"_blank\">tfjs-node</a> container runs via Docker and is GPU-accelerated on any machine with CUDA and a compatible NVIDIA graphics card, or using a CPU on any Linux, Mac, or Windows device. </p><h4><strong>Preview</strong></h4>  <p>Preview is an <a href=\"https://blog.roboflow.com/introducing-the-roboflow-inference-widget/\" target=\"_blank\">in-browser widget</a> that lets developers seamlessly test their models on images, video, and webcam streams. </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3fH2YX7U79s6s7RHZJuPlYJcqkc8PB1mGwD5wPlmom2yh3q-3y3vAoaopZ0U-a7RfCAZNCk7KBKt1RDq2refpSuF50oj6vcg6mtEuQP7UwwgodufA2HKB0czwHW1SMSt1uVcsIOH2dfa2Rc6cOqzSR6pmC4YXJW_tHD5LND9j2UszTUYCkn-6kjlH/s1600/Roboflow%20blog%203.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3fH2YX7U79s6s7RHZJuPlYJcqkc8PB1mGwD5wPlmom2yh3q-3y3vAoaopZ0U-a7RfCAZNCk7KBKt1RDq2refpSuF50oj6vcg6mtEuQP7UwwgodufA2HKB0czwHW1SMSt1uVcsIOH2dfa2Rc6cOqzSR6pmC4YXJW_tHD5LND9j2UszTUYCkn-6kjlH/s1600/Roboflow%20blog%203.png\" /></a></div><h4><strong>Label Assist</strong></h4>  <p>Label Assist is a<a href=\"https://roboflow.com/annotate\" target=\"_blank\"> model-assisted image labeling tool</a> that lets developers use their previous model's predictions as the starting point for annotating additional images. </p><p>One way users leverage Label Assist is in-browser predictions: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjHPQMr2knMeHlXX-bOFrx6XxXKKr-PzTZKVWqJ6ffj_VcuKY-CKta-3GjuXRQZx9MXAc-SHODMqnaNVRG4FcRRkBLgp2h6ZQ18AdE7x56poCzZaUfiJPN0hTuinPuC8nt8qcYMgNej1gjLwKkTm5oQJ52LOkBY0yr-cVXrN0CM4iXFRRXOVCIrfG/s1600/Roboflow%20blog%201.gif\" style=\"display: block; padding: 1em 0; text-align: center; clear: left; float: left;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjHPQMr2knMeHlXX-bOFrx6XxXKKr-PzTZKVWqJ6ffj_VcuKY-CKta-3GjuXRQZx9MXAc-SHODMqnaNVRG4FcRRkBLgp2h6ZQ18AdE7x56poCzZaUfiJPN0hTuinPuC8nt8qcYMgNej1gjLwKkTm5oQJ52LOkBY0yr-cVXrN0CM4iXFRRXOVCIrfG/s1600/Roboflow%20blog%201.gif\" /></a></div><h3><strong>Why We Chose TensorFlow.js</strong></h3>  <p>Once we had decided we needed to run in the browser, TensorFlow.js was a clear choice. </p><p>Because TFJS runs in our users' browsers and on their own compute, we are able to provide ML-powered features to our full user base of over 100,000 developers, including those on<a href=\"https://roboflow.com/pricing\" target=\"_blank\"> our free Public plan</a>. That simply wouldn't be feasible if we had to spin up a fleet of cloud-hosted GPUs. </p><h3><strong>Behind the Scenes</strong></h3>  <p>To implement<a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\"> roboflow.js</a> with TensorFlow.js was relatively straightforward. </p><p>We had to change a couple of layers in our neural network to<a href=\"https://docs.google.com/spreadsheets/d/1D25XtWaBrmUEErbGQB0QmNhH-xtwHo9LDl59w0TbxrI/edit#gid=0\" target=\"_blank\"> ensure all of our ops were supported</a> on the runtimes we wanted to use, integrate the<a href=\"https://www.npmjs.com/package/@tensorflow/tfjs-converter\" target=\"_blank\"> tfjs-converter</a> into our training pipeline, and port our pre-processing and post-processing code to JavaScript from Python. From there, it was smooth sailing. </p><p>Once we'd built roboflow.js for our customers, we utilized it internally to power features like Preview, <a href=\"https://blog.roboflow.com/announcing-label-assist/\" target=\"_blank\">Label Assist</a>, and one implementation of the Inference Server. </p><h3><strong>Try it Out</strong></h3>  <p>The easiest way to try roboflow.js is by using Preview on<a href=\"https://universe.roboflow.com\" target=\"_blank\"> Roboflow Universe</a>, where we host over 7,000 pre-trained models that our users have shared. Any of these models can be readily built into your applications for things like <a href=\"https://universe.roboflow.com/augmented-startups/playing-cards-ow27d/model/2\" target=\"_blank\">seeing playing cards</a>, <a href=\"https://universe.roboflow.com/surfline/surfer-spotting\" target=\"_blank\">counting surfers</a>, <a href=\"https://universe.roboflow.com/augmented-startups/vehicle-registration-plates-trudk\" target=\"_blank\">reading license plates</a>, and <a href=\"https://universe.roboflow.com/explo1-w7h8c/see-sci\" target=\"_blank\">spotting bacteria under microscope</a>, and more. </p><p>On the Deployment tab of<a href=\"https://universe.roboflow.com/search?q=trained%2520model\" target=\"_blank\"> any project with a trained model</a>, you can drop a video or use your webcam to run inference right in your browser. To see a live in-browser example, give this community created <a href=\"https://universe.roboflow.com/joseph-nelson/mask-wearing/model/11\" target=\"_blank\">mask detector</a> a try by clicking the \u201cWebcam\u201d icon: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSymprLcTpg7tM481QkcQ_gF3rXdwPyNmXehz3q_jq8dxR1_TE4dTi43ayquf9ngWPVEq7YLHJj61y_6BBN-DNreNMJpXAP9_J61FdZTa6haeL6cE-poQ2EwKBv7prPQByMJLZCxXVu4VMuo3bpkwE3F1qstHVKwVFf0CQjmL8VYixS_4a7nUSqLeE/s1600/Roboflow%20blog%205.gif\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSymprLcTpg7tM481QkcQ_gF3rXdwPyNmXehz3q_jq8dxR1_TE4dTi43ayquf9ngWPVEq7YLHJj61y_6BBN-DNreNMJpXAP9_J61FdZTa6haeL6cE-poQ2EwKBv7prPQByMJLZCxXVu4VMuo3bpkwE3F1qstHVKwVFf0CQjmL8VYixS_4a7nUSqLeE/s1600/Roboflow%20blog%205.gif\" /></a></div><p>To train your own model for a custom use case, you can<a href=\"https://app.roboflow.com\" target=\"_blank\"> create a free Roboflow account</a> to collect and label a dataset, then train and deploy it for use with roboflow.js in a single click. This enables you to use your model wherever you may need.  </p><h4 style=\"text-align: left;\"><strong>About Roboflow</strong></h4><p>Roboflow makes it easy for developers to use computer vision in their applications. Over 100,000 users have built with the company's end-to-end platform for image and video collection, organization, annotation, preprocessing, model training, and model deployment. Roboflow provides the tools for companies to improve their datasets and build more accurate computer vision models faster so their teams can focus on their domain problems without reinventing the wheel on vision infrastructure.  </p><p><a href=\"https://universe.roboflow.com/\" target=\"_blank\">Browse datasets on Roboflow Universe</a></p><p><a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\">Get started in the Roboflow documentation</a></p><p><a href=\"https://roboflow.com/features\" target=\"_blank\">View all available Roboflow features</a></p><p></p><p></p>",
            "pubdate": "Wed, 27 Jul 2022 17:00:00 +0000",
            "pubdate_parsed": 1658921400.0,
            "email_sent": true
        },
        "Load-testing TensorFlow Serving\u2019s REST Interface": {
            "url": "https://blog.tensorflow.org/2022/07/load-testing-TensorFlow-Servings-REST-interface.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\" style=\"display: none;\" /> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\" /></a> <p><em>Posted by <a href=\"https://github.com/deep-diver\" target=\"_blank\">Chansung Park</a> and <a href=\"https://github.com/sayakpaul\" target=\"_blank\">Sayak Paul</a> (ML-GDEs)</em></p> <a name=\"more\"></a><p></p> <p>In this post, we\u2019ll share the lessons and findings learned from conducting load tests for an image classification model across numerous deployment configurations. These configurations involve REST-based deployments with TensorFlow Serving. In this way, we aim to equip the readers with a holistic understanding of the differences between the configurations. </p><p>This post is less about code and more about the architectural decisions we had to make for performing the deployments. We\u2019ll first provide an overview of our setup including the technical specifications. We\u2019ll also share our commentaries on the design choices we made and their impact.  </p><h2>Technical Setup</h2>  <p><a href=\"https://www.tensorflow.org/tfx/guide/serving\" target=\"_blank\">TensorFlow Serving</a> is feature-rich and has targeted specifications embedded in its designs (more on this later). For <a href=\"https://cloud.google.com/ai-platform/prediction/docs/online-vs-batch-prediction\" target=\"_blank\">online prediction scenarios</a>, the model is usually exposed as some kind of service.  </p><p>To perform our testing we use a <a href=\"https://arxiv.org/abs/1512.03385\" target=\"_blank\">pre-trained ResNet50 model</a> which can classify a variety of images into different categories. We then serve this model in the following way: </p><ul><blockquote> <li><a href=\"https://www.docker.com/\" target=\"_blank\">Docker</a> to containerize the environment.  </li><li><a href=\"https://kubernetes.io/\" target=\"_blank\">Kubernetes</a> to orchestrate a cluster of container nodes for scalability. We use <a href=\"https://cloud.google.com/kubernetes-engine\" target=\"_blank\">Kubernetes Engine</a> (GKE) to manage this.   </li><li><a href=\"https://github.com/features/actions\" target=\"_blank\">GitHub Actions</a> to automatically roll out deployments on GKE.  </li>  </blockquote></ul><p>Our deployment platform (nodes on the Kubernetes Cluster) is CPU-based. We don\u2019t employ GPUs at any stage of our processes. For this purpose, we can build a CPU-optimized TensorFlow Serving image and take advantage of a few other options which can reduce the latency and boost the overall throughput of the system. We will discuss these later in the post.  </p><p>You can find all the code and learn how the deployments were performed in <a href=\"https://github.com/deep-diver/ml-deployment-k8s-tfserving\" target=\"_blank\">this repository</a>. Here, you\u2019ll find example notebooks and detailed setup instructions for playing around with the code. As such, we won\u2019t be discussing the code line by line but rather shed light on the most important parts when necessary. </p><p>Throughout the rest of this post, we\u2019ll discuss the key considerations for the deployment experiments respective to TensorFlow Serving including its motivation, limitations, and our experimental results.  </p><p><em>With the emergence of serverless offerings like <a href=\"https://cloud.google.com/vertex-ai\" target=\"_blank\">Vertex AI</a>, it has never been easier to deploy models and scale them securely and reliably. These services help reduce the time-to-market tremendously and increase overall developer productivity. That said,  there might still be instances where you\u2019d like more granular control over things. This is one of the reasons why we wanted to do these experiments in the first place. </em></p><h2>Considerations</h2>  <p>TensorFlow Serving has its own sets of constraints and design choices that can impact a deployment. In this section, we provide a concise overview of these considerations.  </p><p><strong>Deployment infrastructure:</strong> We chose GKE because Kubernetes is a standard deployment platform when using GCP, and GKE lets us focus on the ML parts without worrying about the infrastructure since it is a fully managed Google Cloud Platform service. Our main interest is in how to deploy models for CPU-based environments, so we have prepared a CPU-optimized TensorFlow Serving image.  </p><p><strong>Trade-off between more or fewer servers:</strong> We started experiments for TensorFlow Serving setups with the simplest possible VMs equipped with 2vCPU and 4GB RAM, then we gradually upgraded the specification up to 8vCPU and 64GB RAM. On the other hand, we decreased the number of nodes in the Kubernetes cluster from 8 to 2 because it is a trade-off between costs to deploy cheaper servers versus fewer expensive servers.  </p><p><strong>Options to benefit multi-core environments:</strong> We wanted to see if high-end VMs can outperform simple VMs with options to take advantage of the multi-core environment even though there are fewer nodes. To this end, we experimented with a different number <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads\" target=\"_blank\">inter_op_parallelism</a></code> and <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/config/threading/set_intra_op_parallelism_threads\" target=\"_blank\">intra_op_parallelism</a></code> threads for TensorFlow Serving deployment set according to the number of CPU cores.   </p><p><strong>Dynamic batching and other considerations:</strong> Modern ML frameworks such as TensorFlow Serving usually support dynamic batching, initial model warm-up, multiple deployments of multiple versions of different models, and more out of the box. For our purpose of online prediction, we have not tested these features carefully. However, dynamic batching capability is also worth exploring to enhance the performance according to the <a href=\"https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/batching/README.md#batch-scheduling-parameters-and-tuning\" target=\"_blank\">official document</a>. We have seen that the default batching configuration could reduce the latency a little even though the results of that are not included in this blog post. </p><h2>Experiments</h2>  <p>We have prepared the following environments. In TensorFlow Serving, the number of <code>intra_op_parallelism</code>_<code>threads</code> is set equal to the number of CPU cores while the number of <code>inter_op_parallelism_threads</code> is set from 2 to 8 for experimental purposes as it controls the number of threads to parallelize the execution of independent operations. Below we provide the details on the adjustments we performed on the number of vCPUs, RAM size, and the number of nodes for each Kubernetes cluster. Note that the number of vCPUs and the RAM size are applicable for the cluster nodes individually.  </p><p>The load tests are conducted using <a href=\"https://locust.io/\" target=\"_blank\">Locust</a>. We have run each load test for 5 minutes. The number of requests are controlled by the number of users, and it depends on the circumstances on the client side. We increased the number of users by one every second up to 150 which we found the handled number of requests reaches the plateau, and the requests are spawned every second to understand how TensorFlow Serving behaves. So you can assume that requests/second doesn't reflect the real-world situation where clients try to send requests at any time. </p><p>We experimented with the following node configurations on a Kubernetes cluster. The configurations are read like so: {num_vcpus_per_node}-{ram}_{num_nodes}: </p><ul style=\"text-align: left;\"> <li><strong>2vCPUs, 4GB RAM, 8 Nodes</strong></li><li><strong>4vCPUs, 8GB RAM, 4 Nodes</strong></li><li><strong>8vCPUs, 16GB RAM, 2 Nodes</strong></li><li><strong>8vCPUs, 64GB RAM, 2 Nodes</strong></li><ul></ul> </ul><p>You can find code for experimenting with these different configurations in the above-mentioned repositories. The deployment for each experiment is provisioned through <a href=\"https://kustomize.io/\" target=\"_blank\">Kustomize</a> to overlay the base configurations, and file-based configurations are injected through <a href=\"https://kubernetes.io/docs/concepts/configuration/configmap/\" target=\"_blank\">ConfigMap</a>. </p><h2>Results </h2>  <p>This section presents the results for each of the above configurations and suggests which configuration is the best based on the environments we considered. As per Figure 1, the best configuration and the environmental setup is observed as 2 nodes, 8 <code>intra_op_parallelism_threads</code>, 8 <code>inter_op_parallelism_threads</code>, 8vCPUs, 16GB RAM based on the result. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN73u2NKv-JzaPZ-NaGtIlNOTYrx_JiQeob2CB1lHbfOoLbjyYsi9GRiV76sxZEeX4M5_0HPjZlawduh1hWdbE5vYkXmmABQkteqKR26EoqJVh26A1K31RNXEV2fAjGUC6flIBDRWb7cZr8mkW4Wiqa3f1Y7cwi3Fb_QpUssA4wp2wGjdmY7kW-aRC/s1600/TF%20Blog%201.png\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN73u2NKv-JzaPZ-NaGtIlNOTYrx_JiQeob2CB1lHbfOoLbjyYsi9GRiV76sxZEeX4M5_0HPjZlawduh1hWdbE5vYkXmmABQkteqKR26EoqJVh26A1K31RNXEV2fAjGUC6flIBDRWb7cZr8mkW4Wiqa3f1Y7cwi3Fb_QpUssA4wp2wGjdmY7kW-aRC/s1600/TF%20Blog%201.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i><span style=\"text-align: start;\">Figure 1: Comparison between different configurations of TensorFlow Serving (</span><a href=\"https://i.ibb.co/wJ42g2Q/download-2.png\" style=\"text-align: start;\">original</a><span style=\"text-align: start;\">).<br /></span></i></td></tr></tbody></table><p>We have observed the following aspects by picking the best options. </p><ul> <li>TensorFlow Serving is more efficient when deployed on fewer, larger (more CPU and RAM) machines, but the RAM capacity doesn\u2019t have much impact on handling more requests. It is important to find the right number of <code>inter_op_parallelism_threads</code> with experimentation. With a higher number the better performance is not always guaranteed even when the nodes are equipped with high-capacity hardware. </li></ul><p>TensorFlow Serving focuses more on reliability than throughput performance. We believe it sacrifices some throughput performance to achieve reliability, but this is the expected behavior of TensorFlow Serving, as stated in the <a href=\"https://www.tensorflow.org/tfx/serving/performance#objectives\" target=\"_blank\">official document</a>. Even though handling as many requests as possible is important, keeping the server as reliable as possible is also substantially important when dealing with a production system.  </p><p>There is a trade-off between performance and reliability, so you must be careful to choose the right one. However, it seems like the throughput performance of TensorFlow Serving is close enough to <a href=\"https://github.com/sayakpaul/ml-deployment-k8s-fastapi\" target=\"_blank\">results from other frameworks such as FastAPI</a>, and if you want to factor in richer features such as dynamic batching and sharing GPU resources efficiently between models, we believe TensorFlow Serving is the right one to choose. </p><h2>Note on gRPC and TensorFlow Serving</h2>  <p>We are dealing with an image classification model for the deployments, and the input to the model will include images. Hence the size of the request payload can spiral up depending on the image resolution and fidelity. Therefore it\u2019s particularly important to ensure the message transmission is as lightweight as possible. Generally, message transmission is quite a bit faster in gRPC than REST. <a href=\"https://blog.dreamfactory.com/grpc-vs-rest-how-does-grpc-compare-with-traditional-rest-apis\" target=\"_blank\">This post</a> provides a good discussion on the main differences between REST and gRPC APIs. </p><p>TensorFlow Serving can <a href=\"https://www.tensorflow.org/tfx/serving/docker\" target=\"_blank\">serve a model with gRPC</a> seamlessly, but comparing the performance of a gRPC API and REST API is non-trivial. This is why we did not include that in this post. The interested readers can check out <a href=\"https://github.com/deep-diver/ml-deployment-k8s-tfserving\" target=\"_blank\">this repository</a> that follows a similar setup but uses a gRPC server instead.  </p><h2>Costs</h2>  <p>We used the <a href=\"https://cloud.google.com/products/calculator\" target=\"_blank\">GCP cost estimator</a> for this purpose. Pricing for each experiment configuration was assumed to be live for 24 hours per month (which was sufficient for our experiments).  </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border-collapse: collapse; border: none; width: 468pt;\">        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Machine Configuration (E2 series)</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Pricing (USD)</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">2vCPUs, 4GB RAM, 8 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4vCPUs, 8GB RAM, 4 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">8vCPUs, 16GB RAM, 2 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">8vCPUs, 64GB RAM, 2 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">18.21</span></p>                </td>            </tr>        </tbody>    </table></div><h2>Conclusion</h2>  <p>In this post, we discussed some critical lessons we learned from our experience of load-testing a standard image classification model. We considered the industry-grade framework for exposing the model to the end-users \u2013 TensorFlow Serving. While our setup for performing the load tests may not fully resemble what happens in the wild, we hope that our findings will at least act as a good starting point for the community. Even though the post demonstrated our approaches with an image classification model, the approaches should be fairly task-agnostic.  </p><p>In the interest of brevity, we didn\u2019t do much to push further the efficiency aspects of the model in both the APIs. With modern CPUs, software stack, and OS-level optimizations, it\u2019s possible to improve the latency and throughput of the model. We redirect the interested reader to the following resources that might be relevant: </p><ul> <li><a href=\"https://huggingface.co/blog/bert-cpu-scaling-part-1\" target=\"_blank\">Scaling up BERT-like model Inference on modern CPU - Part 1</a> </li><li><a href=\"https://huggingface.co/blog/bert-cpu-scaling-part-2\" target=\"_blank\">Scaling up BERT-like model Inference on modern CPU - Part 2</a> </li><li><a href=\"https://cloud.google.com/architecture/load-testing-and-monitoring-aiplatform-models\" target=\"_blank\">Load testing and monitoring AI Platform models </a> </li><li><a href=\"https://cloud.google.com/architecture/best-practices-for-ml-performance-cost\" target=\"_blank\">Best practices for performance and cost optimization for machine learning</a></li></ul><h2>Acknowledgements</h2>  <p>We are grateful to the <a href=\"https://developers.google.com/community/experts\" target=\"_blank\">ML Ecosystem team</a> that provided GCP credits for supporting our experiments. We also thank <a href=\"https://www.linkedin.com/in/hanneshapke\" target=\"_blank\">Hannes Hapke</a> and <a href=\"https://www.linkedin.com/in/robert-crowe\" target=\"_blank\">Robert Crowe</a> for providing us with helpful feedback and guidance.  </p>",
            "pubdate": "Thu, 28 Jul 2022 17:33:00 +0000",
            "pubdate_parsed": 1659009780.0,
            "email_sent": true
        }
    },
    "Machine Learning Mastery Blog": {
        "Using Activation Functions in Neural Networks": {
            "url": "https://machinelearningmastery.com/using-activation-functions-in-neural-networks/",
            "description": "<p>Last Updated on July 6, 2022 Activation functions play an integral role in neural networks by introducing non-linearity. This nonlinearity allows neural networks to develop complex representations and functions based on the inputs that would not be possible with a simple linear regression model. There have been many different non-linear activation functions proposed throughout the [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-activation-functions-in-neural-networks/\" rel=\"nofollow\">Using Activation Functions in Neural Networks</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Mon, 04 Jul 2022 02:34:12 +0000",
            "pubdate_parsed": 1656882252.0,
            "email_sent": true
        },
        "Binary Classification Tutorial with the Keras Deep Learning Library": {
            "url": "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/",
            "description": "<p>Last Updated on July 7, 2022 Keras is a Python library for deep learning that wraps the efficient numerical libraries TensorFlow and Theano. Keras allows you to quickly and simply design and train neural network and deep learning models. In this post you will discover how to effectively use the Keras library in your machine [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/\" rel=\"nofollow\">Binary Classification Tutorial with the Keras Deep Learning Library</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Tue, 05 Jul 2022 19:00:56 +0000",
            "pubdate_parsed": 1657027856.0,
            "email_sent": true
        },
        "Dropout Regularization in Deep Learning Models With Keras": {
            "url": "https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/",
            "description": "<p>Last Updated on July 12, 2022 A simple and powerful regularization technique for neural networks and deep learning models is dropout. In this post you will discover the dropout regularization technique and how to apply it to your models in Python with Keras. After reading this post you will know: How the dropout regularization technique [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/dropout-regularization-deep-learning-models-keras/\" rel=\"nofollow\">Dropout Regularization in Deep Learning Models With Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Tue, 05 Jul 2022 19:00:37 +0000",
            "pubdate_parsed": 1657027837.0,
            "email_sent": true
        },
        "Using Learning Rate Schedules for Deep Learning Models in Python with Keras": {
            "url": "https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/",
            "description": "<p>Last Updated on July 12, 2022 Training a neural network or large deep learning model is a difficult optimization task. The classical algorithm to train neural networks is called stochastic gradient descent. It has been well established that you can achieve increased performance and faster training on some problems by using a learning rate that [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-learning-rate-schedules-deep-learning-models-python-keras/\" rel=\"nofollow\">Using Learning Rate Schedules for Deep Learning Models in Python with Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Fri, 08 Jul 2022 19:00:40 +0000",
            "pubdate_parsed": 1657287040.0,
            "email_sent": true
        },
        "A Gentle Introduction to tensorflow.data API": {
            "url": "https://machinelearningmastery.com/a-gentle-introduction-to-tensorflow-data-api/",
            "description": "<p>Last Updated on July 12, 2022 When we build and train a Keras deep learning model, the training data can be provided in several different ways. Presenting the data as a NumPy array or a TensorFlow tensor is a common one. Making a Python generator function and let the training loop to read data from [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/a-gentle-introduction-to-tensorflow-data-api/\" rel=\"nofollow\">A Gentle Introduction to tensorflow.data API</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Mon, 11 Jul 2022 18:05:36 +0000",
            "pubdate_parsed": 1657542936.0,
            "email_sent": true
        },
        "Understanding the Design of a Convolutional Neural Network": {
            "url": "https://machinelearningmastery.com/understanding-the-design-of-a-convolutional-neural-network/",
            "description": "<p>Last Updated on July 13, 2022 Convolutional neural networks have been found successful in computer vision applications. Various network architectures are proposed and they are neither magical nor hard to understand. In this tutorial, we will make sense of the operation of convolutional layers and their role in a larger convolutional neural network. After finishing [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/understanding-the-design-of-a-convolutional-neural-network/\" rel=\"nofollow\">Understanding the Design of a Convolutional Neural Network</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Tue, 12 Jul 2022 14:50:02 +0000",
            "pubdate_parsed": 1657617602.0,
            "email_sent": true
        },
        "High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike": {
            "url": "https://machinelearningmastery.com/high-fidelity-synthetic-data-for-data-engineers-and-data-scientists-alike/",
            "description": "<p>Last Updated on July 15, 2022 Sponsored Post If you&#8217;re a data engineer or data scientist, you know how hard it is to generate and maintain realistic data at scale. And to guarantee data privacy protection, in addition to all your day-to-day responsibilities? OOF. Talk about a heavy lift. But in today&#8217;s world, efficient data [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/high-fidelity-synthetic-data-for-data-engineers-and-data-scientists-alike/\" rel=\"nofollow\">High-Fidelity Synthetic Data for Data Engineers and Data Scientists Alike</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Thu, 14 Jul 2022 20:03:59 +0000",
            "pubdate_parsed": 1657809239.0,
            "email_sent": true
        },
        "Loss Functions in TensorFlow": {
            "url": "https://machinelearningmastery.com/loss-functions-in-tensorflow/",
            "description": "<p>Last Updated on July 15, 2022 Loss metric is very important for neural networks. As all machine learning model is a optimization problem or another, the loss is the objective function to minimize. In neural networks, the optimization is done with gradient descent and backpropagation. But what are loss functions and how are they affecting [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/loss-functions-in-tensorflow/\" rel=\"nofollow\">Loss Functions in TensorFlow</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Fri, 15 Jul 2022 02:52:11 +0000",
            "pubdate_parsed": 1657833731.0,
            "email_sent": true
        },
        "Image Augmentation for Deep Learning with Keras": {
            "url": "https://machinelearningmastery.com/image-augmentation-deep-learning-keras/",
            "description": "<p>Last Updated on July 19, 2022 Data preparation is required when working with neural network and deep learning models. Increasingly data augmentation is also required on more complex object recognition tasks. In this post you will discover how to use data preparation and data augmentation with your image datasets when developing and evaluating deep learning [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/image-augmentation-deep-learning-keras/\" rel=\"nofollow\">Image Augmentation for Deep Learning with Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Sat, 16 Jul 2022 19:00:09 +0000",
            "pubdate_parsed": 1657978209.0,
            "email_sent": true
        },
        "Image Augmentation with Keras Preprocessing Layers and tf.image": {
            "url": "https://machinelearningmastery.com/image-augmentation-with-keras-preprocessing-layers-and-tf-image/",
            "description": "<p>Last Updated on July 20, 2022 When we work on a machine learning problem related to images, not only we need to collect some images as training data, but also need to employ augmentation to create variations in the image. It is especially true for more complex object recognition problems. There are many ways for [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/image-augmentation-with-keras-preprocessing-layers-and-tf-image/\" rel=\"nofollow\">Image Augmentation with Keras Preprocessing Layers and tf.image</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Wed, 20 Jul 2022 02:10:31 +0000",
            "pubdate_parsed": 1658263231.0,
            "email_sent": true
        }
    },
    "Colah's Blog": {},
    "Amazon Science Blog": {
        "Better joint representations of image and text": {
            "url": "https://www.amazon.science/blog/better-joint-representations-of-image-and-text",
            "description": "Two methods presented at CVPR achieve state-of-the-art results by imposing additional structure on the representational space.",
            "pubdate": "Fri, 01 Jul 2022 15:30:39 GMT",
            "pubdate_parsed": 1656669639.0,
            "email_sent": true
        },
        "Ten stories from the first half of 2022 that captivated readers": {
            "url": "https://www.amazon.science/latest-news/ten-stories-from-the-first-half-of-2022-that-captivated-readers",
            "description": "From Josh Miele's passion for making the world more accessible to improving forecasting by learning quantile functions, these stories resonated with our audience.",
            "pubdate": "Mon, 04 Jul 2022 04:01:00 GMT",
            "pubdate_parsed": 1656887460.0,
            "email_sent": true
        },
        "My experience at Amazon while teaching at Stanford": {
            "url": "https://www.amazon.science/working-at-amazon/my-experience-at-amazon-while-teaching-at-stanford",
            "description": "Co-mingling industry experience and academic teaching.",
            "pubdate": "Tue, 05 Jul 2022 14:03:03 GMT",
            "pubdate_parsed": 1657009983.0,
            "email_sent": true
        },
        "Second annual Machine Learning Summer School launches in India": {
            "url": "https://www.amazon.science/academic-engagements/second-annual-ml-summer-school-amazon-india",
            "description": "Expanded program aimed at engineering undergraduate and graduate students builds off the success of inaugural program.",
            "pubdate": "Wed, 06 Jul 2022 14:39:07 GMT",
            "pubdate_parsed": 1657098547.0,
            "email_sent": true
        },
        "Anwar Walid receives 2022 IEEE INFOCOM Test of Time Paper Award": {
            "url": "https://www.amazon.science/latest-news/anwar-walid-receives-2022-ieee-infocom-test-of-time-paper-award",
            "description": "Walid\u2019s 2010 paper on distributed caching algorithms for content distribution networks cited for its \u201csignificant impact on the research community\u201d.",
            "pubdate": "Thu, 07 Jul 2022 19:00:00 GMT",
            "pubdate_parsed": 1657200600.0,
            "email_sent": true
        },
        "A quick guide to Amazon\u2019s 45-plus NAACL papers": {
            "url": "https://www.amazon.science/blog/a-quick-guide-to-amazons-45-plus-naacl-papers",
            "description": "The breadth and originality of Amazon\u2019s natural-language-processing research are on display at the annual meeting of the North American chapter of the Association for Computational Linguistics.",
            "pubdate": "Thu, 07 Jul 2022 16:09:54 GMT",
            "pubdate_parsed": 1657190394.0,
            "email_sent": true
        },
        "NAACL: Industry track offers reality checks, new directions": {
            "url": "https://www.amazon.science/blog/naacl-industry-track-offers-reality-checks-new-directions",
            "description": "Industry track chair and Amazon principal research scientist Rashmi Gangadharaiah on trends in industry papers and the challenges of building practical dialogue systems.",
            "pubdate": "Fri, 08 Jul 2022 17:19:26 GMT",
            "pubdate_parsed": 1657280966.0,
            "email_sent": true
        },
        "Improving \u201centity linking\u201d between texts and knowledge bases": {
            "url": "https://www.amazon.science/blog/improving-entity-linking-between-texts-and-knowledge-bases",
            "description": "New model sets new standard in accuracy while enabling 60-fold speedups.",
            "pubdate": "Fri, 08 Jul 2022 14:15:01 GMT",
            "pubdate_parsed": 1657269901.0,
            "email_sent": true
        },
        "How events like Prime Day helped Amazon navigate the pandemic": {
            "url": "https://www.amazon.science/latest-news/how-peak-events-like-prime-day-helped-amazon-navigate-the-pandemic",
            "description": "The SCOT science team used lessons from the past \u2014 and improved existing tools \u2014 to contend with \u201ca peak that lasted two years\u201d.",
            "pubdate": "Mon, 11 Jul 2022 13:12:35 GMT",
            "pubdate_parsed": 1657525355.0,
            "email_sent": true
        },
        "Machine Learning University expands with MLU Explains": {
            "url": "https://www.amazon.science/latest-news/amazon-machine-learning-university-new-courses-mlu-explains",
            "description": "Fun visual essays explain key concepts of machine learning.",
            "pubdate": "Tue, 12 Jul 2022 13:43:35 GMT",
            "pubdate_parsed": 1657613615.0,
            "email_sent": true
        },
        "Amazon and MIT announce Science Hub gift project awards": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-mit-announce-science-hub-gift-project-awards",
            "description": "Four MIT professors are the recipients of the inaugural call for research projects.",
            "pubdate": "Wed, 13 Jul 2022 18:00:00 GMT",
            "pubdate_parsed": 1657715400.0,
            "email_sent": true
        },
        "Knowledge distillation for better convergence in multitask learning": {
            "url": "https://www.amazon.science/blog/knowledge-distillation-for-better-convergence-in-multitask-learning",
            "description": "Allowing separate tasks to converge on their own schedules and using knowledge distillation to maintain performance improves accuracy.",
            "pubdate": "Wed, 13 Jul 2022 15:28:28 GMT",
            "pubdate_parsed": 1657706308.0,
            "email_sent": true
        },
        "Why ambient computing needs self-learning": {
            "url": "https://www.amazon.science/blog/why-ambient-computing-needs-self-learning",
            "description": "To become the interface for the Internet of things, conversational agents will need to learn on their own. Alexa has already started down that path.",
            "pubdate": "Thu, 14 Jul 2022 20:59:54 GMT",
            "pubdate_parsed": 1657812594.0,
            "email_sent": true
        },
        "Joris Kinable wins IISE Transactions 2022 Best Application Award": {
            "url": "https://www.amazon.science/latest-news/amazon-scientist-joris-kinable-wins-iise-transactions-2022-best-application-award",
            "description": "Paper explains the use of constraint programming and mathematical optimization techniques in calculating the best routes for snowplows to clear Pittsburgh\u2019s roads.",
            "pubdate": "Thu, 14 Jul 2022 13:00:00 GMT",
            "pubdate_parsed": 1657783800.0,
            "email_sent": true
        },
        "Filtering out \"forbidden\" documents during information retrieval": {
            "url": "https://www.amazon.science/blog/filtering-out-forbidden-documents-during-information-retrieval",
            "description": "New method optimizes the twin demands of retrieving relevant content and filtering out bad content.",
            "pubdate": "Fri, 15 Jul 2022 18:14:51 GMT",
            "pubdate_parsed": 1657889091.0,
            "email_sent": true
        },
        "Amazon scientists Mike Hicks and Ren\u00e9 Vidal honored": {
            "url": "https://www.amazon.science/latest-news/amazon-scientists-mike-hicks-and-rene-vidal-honored",
            "description": "Hicks wins 2022 ACM SIGPLAN Distinguished Service Award for career contributions; Vidal wins IEEE Signal Processing Magazine Best Paper Award.",
            "pubdate": "Fri, 15 Jul 2022 16:32:31 GMT",
            "pubdate_parsed": 1657882951.0,
            "email_sent": true
        },
        "74 Amazon Research Awards recipients announced": {
            "url": "https://www.amazon.science/research-awards/program-updates/74-amazon-research-awards-recipients-announced",
            "description": "The awardees represent 51 universities in 17 countries. Recipients have access to more than 300 Amazon public datasets, and can utilize AWS AI/ML services and tools.",
            "pubdate": "Mon, 18 Jul 2022 16:10:38 GMT",
            "pubdate_parsed": 1658140838.0,
            "email_sent": true
        },
        "New method identifies the root causes of statistical outliers": {
            "url": "https://www.amazon.science/blog/new-method-identifies-the-root-causes-of-statistical-outliers",
            "description": "Amazon ICML paper proposes information-theoretic measurement of quantitative causal contribution.",
            "pubdate": "Tue, 19 Jul 2022 15:20:16 GMT",
            "pubdate_parsed": 1658224216.0,
            "email_sent": true
        },
        "\"Among all sources of information, visual information may be the most interesting\"": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-computer-vision-intern-to-applied-scientist-violetta-shevchenko",
            "description": "Violetta Shevchenko, an Amazon applied scientist and former intern, combines vision and language to create solutions to challenging problems.",
            "pubdate": "Wed, 20 Jul 2022 13:55:22 GMT",
            "pubdate_parsed": 1658305522.0,
            "email_sent": true
        },
        "ICML: Where causality meets machine learning": {
            "url": "https://www.amazon.science/blog/icml-where-causality-meets-machine-learning",
            "description": "Amazon\u2019s Dominik Janzing on the history and promise of the young field of causal machine learning.",
            "pubdate": "Thu, 21 Jul 2022 13:43:23 GMT",
            "pubdate_parsed": 1658391203.0,
            "email_sent": true
        },
        "Causal inference when treatments are continuous variables": {
            "url": "https://www.amazon.science/blog/causal-inference-when-treatments-are-continuous-variables",
            "description": "Combining a cutting-edge causal-inference technique and end-to-end machine learning reduces root-mean-square error by 27% to 38%.",
            "pubdate": "Fri, 22 Jul 2022 20:00:00 GMT",
            "pubdate_parsed": 1658500200.0,
            "email_sent": true
        },
        "Massively Multilingual NLU 2022: Call for papers and shared-task entries": {
            "url": "https://www.amazon.science/blog/massively-multilingual-nlu-2022-call-for-papers-and-shared-task-entries",
            "description": "New EMNLP workshop will feature talks, papers, posters, and a competition built around the 50-plus-language, million-utterance MASSIVE dataset.",
            "pubdate": "Fri, 22 Jul 2022 16:39:17 GMT",
            "pubdate_parsed": 1658488157.0,
            "email_sent": true
        },
        "Honorable mention to Amazon researchers for ICML test-of-time award": {
            "url": "https://www.amazon.science/blog/honorable-mention-to-amazon-researchers-for-icml-test-of-time-award",
            "description": "Amazon's Bernhard Sch\u00f6lkopf and Dominik Janzing are first and second authors on \"breakthrough 2012 paper\".",
            "pubdate": "Fri, 22 Jul 2022 14:21:28 GMT",
            "pubdate_parsed": 1658479888.0,
            "email_sent": true
        },
        "Amazon-Columbia SURE students meet with Alexa AI VP": {
            "url": "https://www.amazon.science/academic-engagements/amazon-columbia-sure-students-meet-with-alexa-ai-vp",
            "description": "Prem Natarajan, Alexa AI vice president of natural understanding, visited the campus to engage with young STEM researchers from historically underrepresented backgrounds.",
            "pubdate": "Mon, 25 Jul 2022 19:00:00 GMT",
            "pubdate_parsed": 1658755800.0,
            "email_sent": true
        },
        "How Amazon learned to cut its cardboard waste": {
            "url": "https://www.amazon.science/latest-news/amazon-cardboard-boxes-waste-reduction",
            "description": "Pioneering web-based PackOpt tool has resulted in an annual reduction in cardboard waste of 7% to 10% in North America, saving roughly 60,000 tons of cardboard annually.",
            "pubdate": "Mon, 25 Jul 2022 14:10:18 GMT",
            "pubdate_parsed": 1658738418.0,
            "email_sent": true
        },
        "Preparing today for a post-quantum cryptographic future": {
            "url": "https://www.amazon.science/blog/preparing-today-for-a-post-quantum-cryptographic-future",
            "description": "Amazon is helping develop standards for post-quantum cryptography and deploying promising technologies for customers to experiment with.",
            "pubdate": "Tue, 26 Jul 2022 14:17:17 GMT",
            "pubdate_parsed": 1658825237.0,
            "email_sent": true
        },
        "How silicon innovation became the \u2018secret sauce\u2019 behind AWS\u2019s success": {
            "url": "https://www.amazon.science/how-silicon-innovation-became-the-secret-sauce-behind-awss-success",
            "description": "Nafea Bshara, AWS vice president and distinguished engineer, discusses Annapurna Lab\u2019s path to silicon success; Annapurna co-founder will be a featured speaker in August 3 AWS Silicon Innovation Day virtual event.",
            "pubdate": "Wed, 27 Jul 2022 18:10:07 GMT",
            "pubdate_parsed": 1658925607.0,
            "email_sent": true
        },
        "\u201cI didn\u2019t imagine I could grow and learn so much\u201d": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-internships-summer-2022-experience-donato-crisostomi-science-intern",
            "description": "Donato Crisostomi talks about how his mother helped spark a love of knowledge that led him to two science internships at Amazon.",
            "pubdate": "Thu, 28 Jul 2022 18:00:00 GMT",
            "pubdate_parsed": 1659011400.0,
            "email_sent": true
        },
        "Amazon hosts largest class of science interns": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-hosts-largest-class-of-science-interns",
            "description": "This year\u2019s class includes applied science, research science, and data science interns.",
            "pubdate": "Thu, 28 Jul 2022 14:33:08 GMT",
            "pubdate_parsed": 1658998988.0,
            "email_sent": true
        },
        "A hyperparameter optimization library for reproducible research": {
            "url": "https://www.amazon.science/blog/a-hyperparameter-optimization-library-for-reproducible-research",
            "description": "Syne Tune supports multiple backends, single-fidelity and multi-fidelity (early-exit) optimization algorithms, and hyperparameter transfer learning.",
            "pubdate": "Fri, 29 Jul 2022 14:16:25 GMT",
            "pubdate_parsed": 1659084385.0,
            "email_sent": true
        },
        "Amazon Scholar Kathleen McKeown receives dual honors": {
            "url": "https://www.amazon.science/latest-news/amazon-scholar-kathleen-mckeown-receives-dual-honors",
            "description": "McKeown awarded IEEE Innovation in Societal Infrastructure Award and named a member of the American Philosophical Society.",
            "pubdate": "Mon, 01 Aug 2022 18:02:14 GMT",
            "pubdate_parsed": 1659357134.0,
            "email_sent": true
        },
        "The path to carbon reductions in high-growth economic sectors": {
            "url": "https://www.amazon.science/blog/the-path-to-carbon-reductions-in-high-growth-economic-sectors",
            "description": "Confronting climate change requires the participation of governments, companies, academics, civil-society organizations, and the public.",
            "pubdate": "Mon, 01 Aug 2022 14:37:12 GMT",
            "pubdate_parsed": 1659344832.0,
            "email_sent": true
        },
        "20B-parameter Alexa model sets new marks in few-shot learning": {
            "url": "https://www.amazon.science/blog/20b-parameter-alexa-model-sets-new-marks-in-few-shot-learning",
            "description": "With an encoder-decoder architecture \u2014 rather than decoder only \u2014 the Alexa Teacher Model excels other large language models on few-shot tasks such as summarization and machine translation.",
            "pubdate": "Tue, 02 Aug 2022 12:59:36 GMT",
            "pubdate_parsed": 1659425376.0,
            "email_sent": true
        },
        "Identifying the sponsored-product ads most useful to customers": {
            "url": "https://www.amazon.science/blog/identifying-the-sponsored-product-ads-most-useful-to-customers",
            "description": "Large language models improve click-through-rate prediction for sponsored products on Amazon product pages.",
            "pubdate": "Thu, 25 Aug 2022 13:30:55 GMT",
            "pubdate_parsed": 1661434255.0,
            "email_sent": true
        },
        "I always knew that my main interest was in supply chain optimization": {
            "url": "https://www.amazon.science/working-at-amazon/alp-muharremoglu-columbia-university-of-texas-operations-professor-amazon-scot",
            "description": "After 15 years in academia, Alp Muharremoglu became a senior principal senior scientist within Amazon\u2019s Supply Chain Optimization Technologies organization, and says his teaching skills are indispensable.",
            "pubdate": "Mon, 29 Aug 2022 13:36:27 GMT",
            "pubdate_parsed": [
                2022,
                8,
                29
            ],
            "email_sent": true
        }
    },
    "The Berkeley Artificial Intelligence Research Blog": {
        "Why do Policy Gradient Methods work so well in Cooperative MARL? Evidence from Policy Representation": {
            "url": "http://bair.berkeley.edu/blog/2022/07/10/pg-ar/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p>In cooperative multi-agent reinforcement learning (MARL), due to its <em>on-policy</em> nature, policy gradient (PG) methods are typically believed to be less sample efficient than value decomposition (VD) methods, which are <em>off-policy</em>. However, some <a href=\"https://arxiv.org/abs/2103.01955\">recent</a> <a href=\"https://arxiv.org/abs/2011.09533\">empirical</a> <a href=\"https://arxiv.org/abs/2006.07869\">studies</a> demonstrate that with proper input representation and hyper-parameter tuning, multi-agent PG can achieve <a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">surprisingly strong performance</a> compared to off-policy VD methods.</p>\n\n<p><strong>Why could PG methods work so well?</strong> In this post, we will present concrete analysis to show that in certain scenarios, e.g., environments with a highly multi-modal reward landscape, VD can be problematic and lead to undesired outcomes. By contrast, PG methods with individual policies can converge to an optimal policy in these cases. In addition, PG methods with auto-regressive (AR) policies can learn multi-modal policies.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/ar.png\" width=\"80%\" />\n    <br />\n<i>\nFigure 1: different policy representation for the 4-player permutation game.\n</i>\n</p>\n\n<!--more-->\n\n<h2 id=\"ctde-in-cooperative-marl-vd-and-pg-methods\">CTDE in Cooperative MARL: VD and PG methods</h2>\n\n<p>Centralized training and decentralized execution (<a href=\"https://arxiv.org/abs/1706.02275\">CTDE</a>) is a popular framework in cooperative MARL. It leverages <em>global</em> information for more effective training while keeping the representation of individual policies for testing. CTDE can be implemented via value decomposition (VD) or policy gradient (PG), leading to two different types of algorithms.</p>\n\n<p>VD methods learn local Q networks and a mixing function that mixes the local Q networks to a global Q function. The mixing function is usually enforced to satisfy the Individual-Global-Max (<a href=\"https://arxiv.org/abs/1905.05408\">IGM</a>) principle, which guarantees the optimal joint action can be computed by greedily choosing the optimal action locally for each agent.</p>\n\n<p>By contrast, PG methods directly apply policy gradient to learn an individual policy and a centralized value function for each agent. The value function takes as its input the global state (e.g., <a href=\"https://arxiv.org/abs/2103.01955\">MAPPO</a>) or the concatenation of all the local observations (e.g., <a href=\"https://arxiv.org/abs/1706.02275\">MADDPG</a>), for an accurate global value estimate.</p>\n\n<h2 id=\"the-permutation-game-a-simple-counterexample-where-vd-fails\">The permutation game: a simple counterexample where VD fails</h2>\n\n<p>We start our analysis by considering a stateless cooperative game, namely the permutation game. In an $N$-player permutation game, each agent can output $N$ actions ${ 1,\\ldots, N }$. Agents receive $+1$ reward  if their actions are mutually different, i.e., the joint action is a permutation over $1, \\ldots, N$; otherwise, they receive $0$ reward. Note that there are $N!$ symmetric optimal strategies in this game.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/permutation_game.png\" width=\"70%\" />\n    <br />\n<i>\nFigure 2: the 4-player permutation game.\n</i>\n</p>\n\n<p>Let us focus on the 2-player permutation game for our discussion. In this setting, if we apply VD to the game, the global Q-value will factorize to</p>\n\n\\[Q_\\textrm{tot}(a^1,a^2)=f_\\textrm{mix}(Q_1(a^1),Q_2(a^2)),\\]\n\n<p>where $Q_1$ and $Q_2$ are local Q-functions, $Q_\\textrm{tot}$ is the global Q-function, and $f_\\textrm{mix}$ is the mixing function that, as required by VD methods, satisfies the IGM principle.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/vd_pg.png\" width=\"90%\" />\n    <br />\n    <i>\nFigure 3: high-level intuition on why VD fails in the 2-player permutation game.\n    </i>\n</p>\n<p>We formally prove that VD cannot represent the payoff of the 2-player permutation game by contradiction. If VD methods were able to represent the payoff, we would have</p>\n\n\\[Q_\\textrm{tot}(1, 2)=Q_\\textrm{tot}(2,1)=1 \\qquad \\textrm{and} \\qquad Q_\\textrm{tot}(1, 1)=Q_\\textrm{tot}(2,2)=0.\\]\n\n<p>However, if either of these two agents have different local Q values, e.g. $Q_1(1)&gt; Q_1(2)$, then according to the IGM principle, we must have</p>\n\n\\[1=Q_\\textrm{tot}(1,2)=\\arg\\max_{a^2}Q_\\textrm{tot}(1,a^2)&gt;\\arg\\max_{a^2}Q_\\textrm{tot}(2,a^2)=Q_\\textrm{tot}(2,1)=1.\\]\n\n<p>Otherwise, if $Q_1(1)=Q_1(2)$ and $Q_2(1)=Q_2(2)$, then</p>\n\n\\[Q_\\textrm{tot}(1, 1)=Q_\\textrm{tot}(2,2)=Q_\\textrm{tot}(1, 2)=Q_\\textrm{tot}(2,1).\\]\n\n<p>As a result, value decomposition cannot represent the payoff matrix of the 2-player permutation game.</p>\n\n<p>What about PG methods? Individual policies can indeed represent an optimal policy for the permutation game. Moreover, stochastic gradient descent can guarantee PG to converge to one of these optima <a href=\"https://arxiv.org/abs/1802.06175\">under mild assumptions</a>. This suggests that, even though PG methods are less popular in MARL compared with VD methods, they can be preferable in certain cases that are common in real-world applications, e.g., games with multiple strategy modalities.</p>\n\n<p>We also remark that in the permutation game, in order to represent an optimal joint policy, each agent must choose distinct actions. <strong>Consequently, a successful implementation of PG must ensure that the policies are agent-specific.</strong> This can be done by using either individual policies with unshared parameters (referred to as PG-Ind in our paper), or an agent-ID conditioned policy (<a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">PG-ID</a>).</p>\n\n<h2 id=\"pg-outperform-best-vd-methods-on-popular-marl-testbeds\">PG outperform best VD methods on popular MARL testbeds</h2>\n\n<p>Going beyond the simple illustrative example of the permutation game, we extend our study to popular and more realistic MARL benchmarks. In addition to StarCraft Multi-Agent Challenge (<a href=\"https://github.com/oxwhirl/smac\">SMAC</a>), where the effectiveness of PG and agent-conditioned policy input <a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">has been verified</a>, we show new results in Google Research Football (<a href=\"https://github.com/google-research/football\">GRF</a>) and multi-player <a href=\"https://github.com/deepmind/hanabi-learning-environment\">Hanabi Challenge</a>.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/football.png\" width=\"48%\" />\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/hanabi.png\" width=\"45%\" />\n    <br />\n<i>\nFigure 4: (left) winning rates of PG methods on GRF; (right) best and average evaluation scores on Hanabi-Full.\n</i>\n</p>\n\n<p>In GRF, PG methods outperform the state-of-the-art VD baseline (<a href=\"https://arxiv.org/abs/2106.02195\">CDS</a>) in 5 scenarios. Interestingly, we also notice that individual policies (PG-Ind) without parameter sharing achieve comparable, sometimes even higher winning rates, compared to agent-specific policies (PG-ID) in all 5 scenarios. We evaluate PG-ID in the full-scale Hanabi game with varying numbers of players (2-5 players) and compare them to <a href=\"https://arxiv.org/abs/1912.02288\">SAD</a>, a strong off-policy Q-learning variant in Hanabi, and Value Decomposition Networks (<a href=\"https://arxiv.org/abs/1706.05296\">VDN</a>). As demonstrated in the above table, PG-ID is able to produce results comparable to or better than the best and average rewards achieved by SAD and VDN with varying numbers of players using the same number of environment steps.</p>\n\n<h2 id=\"beyond-higher-rewards-learning-multi-modal-behavior-via-auto-regressive-policy-modeling\">Beyond higher rewards: learning multi-modal behavior via auto-regressive policy modeling</h2>\n\n<p>Besides learning higher rewards, we also study how to learn multi-modal policies in cooperative MARL. Let\u2019s go back to the permutation game. Although we have proved that PG can effectively learn an optimal policy, the strategy mode that it finally reaches can highly depend on the policy initialization. Thus, a natural question will be:</p>\n\n<p style=\"text-align: center;\">\n    <i>\nCan we learn a single policy that can cover all the optimal modes?\n    </i>\n</p>\n\n<p>In the decentralized PG formulation, the factorized representation of a joint policy can only represent one particular mode. Therefore, we propose an enhanced way to parameterize the policies for stronger expressiveness \u2014 the auto-regressive (AR) policies.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/pg-ar/permutation_ar.gif\" width=\"80%\" />\n<br />\n<i>\nFigure 5: comparison between individual policies (PG) and auto-regressive  policies (AR) in the 4-player permutation game.\n</i>\n</p>\n\n<p>Formally, we factorize the joint policy of $n$ agents into the form of</p>\n\n\\[\\pi(\\mathbf{a} \\mid \\mathbf{o}) \\approx \\prod_{i=1}^n \\pi_{\\theta^{i}} \\left( a^{i}\\mid o^{i},a^{1},\\ldots,a^{i-1} \\right),\\]\n\n<p>where the action produced by agent $i$ depends on its own observation $o_i$ and all the actions from previous agents $1,\\dots,i-1$. The auto-regressive factorization can represent <em>any</em> joint policy in a centralized MDP. The <em>only</em> modification to each agent\u2019s policy is the input dimension, which is slightly enlarged by including previous actions; and the output dimension of each agent\u2019s policy remains unchanged.</p>\n\n<p>With such a minimal parameterization overhead, AR policy substantially improves the representation power of PG methods. We remark that PG with AR policy (PG-AR) can simultaneously represent all optimal policy modes in the permutation game.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/heatmap.png\" width=\"70%\" />\n    <br />\n<i>\nFigure: the heatmaps of actions for policies learned by PG-Ind (left) and PG-AR (middle), and the heatmap for rewards (right); while PG-Ind only converge to a specific mode in the 4-player permutation game, PG-AR successfully discovers all the optimal modes.\n</i>\n</p>\n\n<p>In more complex environments, including SMAC and GRF, PG-AR can learn interesting emergent behaviors that require strong intra-agent coordination that may never be learned by PG-Ind.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/2m1z.gif\" width=\"45%\" />\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/3v1.gif\" width=\"45%\" />\n    <br />\n<i>\nFigure 6: (left) emergent behavior induced by PG-AR in SMAC and GRF. On the 2m_vs_1z map of SMAC, the marines keep standing and attack alternately while ensuring there is only one attacking marine at each timestep; (right) in the academy_3_vs_1_with_keeper scenario of GRF, agents learn a \"Tiki-Taka\" style behavior: each player keeps passing the ball to their teammates.\n</i>\n</p>\n\n<h2 id=\"discussions-and-takeaways\">Discussions and Takeaways</h2>\n\n<p>In this post, we provide a concrete analysis of VD and PG methods in cooperative MARL. First, we reveal the limitation on the expressiveness of popular VD methods, showing that they could not represent optimal policies even in a simple permutation game. By contrast, we show that PG methods are provably more expressive. We empirically verify the expressiveness advantage of PG on popular MARL testbeds, including SMAC, GRF, and Hanabi Challenge. We hope the insights from this work could benefit the community towards more general and more powerful cooperative MARL algorithms in the future.</p>\n\n<hr />\n\n<p><em>This post is based on our paper in joint with Zelai Xu: Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning (<a href=\"https://arxiv.org/abs/2206.07505\">paper</a>, <a href=\"https://sites.google.com/view/revisiting-marl\">website</a>).</em></p>",
            "pubdate": "Sun, 10 Jul 2022 02:00:00 -0700",
            "pubdate_parsed": 1657423800.0,
            "email_sent": true
        }
    },
    "Google AI Blog": {
        "An update on our work in responsible innovation": {
            "url": "https://blog.google/technology/ai/an-update-on-our-work-in-responsible-innovation/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Over the last year, we\u2019ve seen artificial intelligence (AI) systems advance our work in areas like <a href=\"https://blog.google/products/pixel/image-equity-real-tone-pixel-6-photos/\">inclusive product development</a> and support for <a href=\"https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/\">small businesses</a> and <a href=\"https://grow.google/certificates/interview-warmup/\">job seekers</a>. We\u2019ve also seen its potential to be helpful in addressing major global needs \u2014 like <a href=\"https://blog.google/technology/ai/expanding-our-ml-based-flood-forecasting/\">forecasting</a> and planning <a href=\"https://blog.google/around-the-globe/google-africa/using-ai-to-map-africas-buildings/\">humanitarian responses</a> to natural disasters, <a href=\"https://blog.google/intl/en-au/company-news/outreach-initiatives/protecting-our-reef-with-csiro/\">addressing global environmental</a> challenges, and delivering groundbreaking <a href=\"https://www.nature.com/articles/d41586-021-02025-4\">scientific research</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI is exciting \u2014 both from a technical perspective and when considering its underlying social benefits. And yet, to fully realize AI\u2019s potential, it must be developed responsibly, thoughtfully and in a way that gives deep consideration to core ethical questions. After all, the promise of great reward inherently involves risk \u2014 and we\u2019re committed to ethically developing AI in a way that is socially beneficial.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our <a href=\"http://ai.google/principles\">AI Principles</a> guide how we integrate AI research into Google\u2019s products and services and engage with external partners. Internally, we implement the Principles, every day, through education programs, AI ethics reviews and technical tools. There are more than 200 Googlers across the company whose full-time roles are to operationalize responsible practices for developing AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re committed to sharing our lessons learned so others across the industry can learn, too (see our posts from <a href=\"https://www.blog.google/technology/ai/google-ai-principles-updates-six-months/\">2018,</a> <a href=\"https://www.blog.google/technology/ai/responsible-ai-principles/\">2019</a>, <a href=\"https://blog.google/technology/ai/update-work-ai-responsible-innovation/\">2020</a> and <a href=\"https://blog.google/technology/ai/update-our-progress-responsible-ai-innovation/#:~:text=Over%20the%20past%20year%2C%20responsibly,and%20protected%20wildlife%20after%20bushfires.\">2021</a>, and our in-depth annual <a href=\"https://ai.google/responsibilities/review-process/#:~:text=the%20current%20process.-,annual%20updates,-AI%20Principles%202021\">AI Principles Progress Updates</a>).</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Internal education</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s important to craft principles, but putting them into practice requires both training and constant dialogue.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Launched in late 2019, to date more than 32,000 employees across Google have engaged in AI Principles training. Given our growing understanding of effective hybrid and remote learning, we continue to expand and modify the courses. For example, this year we adapted our popular four-part Tech Ethics self-study course to a one-part deep dive based on Googler feedback. Similarly, we launched the <a href=\"https://blog.google/technology/ai/crossword-puzzle-big-purpose/\">Responsible Innovation Challenge</a> \u2014 taken by more than 13,000 employees \u2014 as a series of engaging online puzzles, quizzes and games to raise awareness of the AI Principles and measure employees' retention of ethical concepts, such as avoiding unfair bias.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We also piloted a new Moral Imagination workshop, a two-day, live-video immersive set of activities for product teams to walk through the ethical implications of potential AI products. To date, 248 Googlers across 23 Google product and research teams have taken the workshop, resulting in deeper, ongoing AI ethics consultations on product development.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As we develop internal training, we\u2019re committed to incorporating the input of both Googlers and outside experts. This year, when we launched a live workshop to educate our internal user experience and product teams on the concept of <a href=\"https://blog.google/inside-google/googlers/ask-techspert-how-do-machine-learning-models-explain-themselves/\">AI explainability</a>, we first piloted the workshop with outside experts at the international <a href=\"https://summit.ttclabs.net/\">Trust, Transparency and Control Labs</a> summit in May.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We believe this approach complements programs like our internal AI Principles Ethics Fellows program, a six-month fellowship that this year involved Googlers from 17 different global offices. We also just launched a version of the fellowship program tailored for senior leaders.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Putting the Principles into practice</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our approach to responsible AI innovation starts early, before teams plan a new AI application. When a team starts to build a machine learning (ML) model, dataset or product feature, they can attend office hours with experts to ask questions and engage in analyses using responsible AI <a href=\"https://www.tensorflow.org/responsible_ai?hl=en\">tools</a> that Google develops, or seek adversarial proactive fairness <a href=\"https://www.blog.google/inside-google/googlers/meet-3-women-who-test-google-products-fairness/\">(ProFair) testing.</a> Pre-launch, a team then can request an AI Principles review.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI Principles reviewers are in place to implement a structured assessment to identify, measure and analyze potential risk of harm. The risk rating focuses on the extent to which people and society may be impacted if solutions did not exist or were to fail. Reviewers also consider a growing body of lessons from thousands of previous AI Principles reviews conducted since 2019.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>When reviewers find medium- to high-risk issues, such as product exclusion or a potential privacy or security concern, they work with the teams to address these issues. Reviews either result in an approval, approval with conditions or recommendations, or non-approval. New AI applications that might affect multiple product areas are escalated to the Advanced Technology Review Council \u2014 a group of senior research, product and business leaders who make the final decision.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To supplement the expertise of our internal AI Principles group members, we often incorporate trusted external advisors. For example, a team was incorporating AI to help build a <a href=\"https://dynamicworld.app/\">near real-time dataset</a> to enable reliable measurement of global land cover for environmental and social benefit. They submitted for <a href=\"https://ai.google/static/documents/case-study-dynamic-world.pdf\">AI Principles review</a> and then collaborated with the review team to design several safeguards. The review team also worked with third-party experts at the <a href=\"https://www.wri.org/about\">World Resources Institute</a> and <a href=\"https://www.bsr.org/en/about\">BSR</a>. Following the example of the European Commission\u2019s <a href=\"https://www.copernicus.eu/en\">Copernicus mission\u2019s</a> open <a href=\"https://sentinel.esa.int/documents/247904/690755/sentinel_data_legal_notice\">data and services</a> terms, the product team applied open data principles, making the ML model\u2019s <a href=\"https://doi.pangaea.de/10.1594/PANGAEA.933475\">training</a> and <a href=\"https://doi.org/10.5281/zenodo.4766508\">test data</a> used to create the dataset, as well as the dataset itself, freely available under CC-BY-4.0, and the <a href=\"https://github.com/google/dynamicworld\">model available on Github</a> under an Apache 2.0 license. We recently released a <a href=\"https://ai.google/static/documents/case-study-dynamic-world.pdf\">Codelab</a> for developers to walk through the ethics review process and apply learnings to their own projects.</p></div></div><div class=\"block-video\"><div class=\"h-c-page h-c-page--mobile-full-bleed\"><div class=\"h-c-grid\"><div class=\"h-c-grid__col h-c-grid__col-l--10 h-c-grid__col-l--offset-1\"><div class=\"article-module uni-article-video uni-article-video--body\"><div class=\"uni-article-video__embed-container hidden\"><div id=\"uni-article-yt-player-S75NcDqbPbI\"></div></div><figure><a class=\"h-c-video h-c-video--marquee uni-article-video__custom-wrapper\" tabindex=\"0\"><div class=\"uni-article-video__aspect-image\"><img alt=\"A video explaining Google's AI Principles Review process\" src=\"https://img.youtube.com/vi/S75NcDqbPbI/maxresdefault.jpg\" /><div class=\"uni-article-video__dimmer\"></div><svg class=\"uni-article-video__play-button--active\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button_no_hole\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><svg class=\"uni-article-video__play-button\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><div class=\"uni-article-video__duration loading\"><svg class=\"uni-article-video__duration-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_duration\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><span class=\"uni-article-video__duration-time\">10:25</span></div></div></a><p>Google\u2019s AI Principles Review Process: How we assess new AI research and applications for alignment with our Principles</p></figure></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Projects such as research methods for evaluating misinformation and datasets that need more diverse representation tend to receive conditions to proceed toward a launch. A recurring condition given to teams is to engage in ProFair testing with people from a diversity of backgrounds, often in partnership with our central Product Inclusion and Equity team. This year, the number of ProFair consultations increased annually by 100%. A recurring approach is to create and release detailed documentation in the form of<a href=\"https://www.youtube.com/watch?v=IYK6fkODXNU\">data cards</a> and <a href=\"https://modelcards.withgoogle.com/about\">model cards</a> for transparency and accountability. The number of AI Principles reviews with model or data card mitigations increased 68% in the last year.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As we\u2019ve stated, we\u2019ve embedded customized AI governance and review committees within certain product areas (like Cloud and Health). As a result, both the Health Ethics Committee and Cloud make decisions with specialized expertise, such as establishing policies for potentially winding down the <a href=\"https://www.google.com/covid19/mobility/\">Covid-19 Community Mobility Reports</a> and the <a href=\"https://ai.googleblog.com/2021/10/an-ml-based-framework-for-covid-19.html\">Covid-19 Forecaster</a>, respectively, if situations arise that might cause the data quality to degrade. This year, we extended this specialized approach and created a dedicated consumer hardware AI Principles review process.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s important to note that product teams across Google engage in everyday responsible AI practices even if not in formal reviews. <a href=\"https://blog.youtube/inside-youtube/inside-responsibility-whats-next-on-our-misinfo-efforts/\">YouTube</a> is leveraging a more targeted mix of classifiers, keywords in additional languages, and information from regional analysts. This work is a result of collaboration with our researchers who focus on new tools for AI fairness. The Photos team participated in an <a href=\"https://blog.google/technology/ai/update-our-progress-responsible-ai-innovation/#:~:text=equitable%20ai%20research%20roundtables%20(earr)%2C\">Equitable AI Research Roundtable (EARR)</a> with a group of external advisors on potential fairness considerations. And the Gboard team deployed a new, <a href=\"https://ai.googleblog.com/2021/12/a-scalable-approach-for-partially-local.html\">privacy-by-design</a> approach to federated machine learning. These examples did not stem from AI Principles reviews, but reflect the adoption of the AI Principles across Google.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Tools and research</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In early 2022, to offer easier access to our publications on responsible AI, we curated an <a href=\"https://research.google/pubs/?collection=responsible-ai\">external collection</a> of more than 200 research papers focused on the topic. We continue to launch, refine and consolidate technical resources, including proactive tools like:</p><ul><li>The <a href=\"https://skintone.google/\">Monk Skin Tone Scale</a>, developed by Harvard University Sociology Professor Dr. Ellis Monk. The scale offers a spectrum of skin tones from all around the world for use in evaluating and addressing fairness considerations in AI.</li><li>The <a href=\"https://knowyourdata.withgoogle.com/\">Know Your Data</a> tool (KYD), which helps developers with tasks such as quickly identifying issues in fairness, and which has integrated the Monk Scale to help developers examine skin tone data for unfair bias.</li><li>The <a href=\"https://pair-code.github.io/lit/\">Language Interpretability Tool</a>, or LIT, to help developers probe an ML model, now with a <a href=\"https://arxiv.org/abs/1711.11279\">new method</a> to better understand, test and debug its behaviors.</li><li><a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview?hl=en\">Counterfactual Logit Pairing</a>, which helps ensure that a model\u2019s prediction doesn\u2019t change when sensitive attributes or identity terms referenced in an example are removed or replaced, now added to the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation\">TensorFlow Model Remediation Library</a> (see the <a href=\"https://arxiv.org/abs/1809.10610\">research paper</a> for more).</li><li>And to help teams measure their progress against the AI Principles, we\u2019re piloting an internal tool to help teams assess how ML models were developed in accordance with emerging smart practices, previous reviews, and our growing body of ethics, fairness, and human-rights work.</li></ul></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Many responsible AI tools developed by researchers are actively in use by product teams at Google. For example, Photos, Pixel and Image Search are leveraging the Monk Skin Tone Scale.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>External engagement</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Ensuring the responsible development and deployment of AI is an ongoing process. We believe it should be a collaborative one, too, so we remain deeply engaged with governments across Europe, the Middle East and Africa, Latin America, Asia Pacific, and the U.S. to advocate for AI regulation that supports innovation around the world for businesses of all sizes. We share our approach to responsible AI and <a href=\"https://ai.google/static/documents/google-response-to-nist-ai-risk-management-framework-rfi.pdf\">recommendations</a>, <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2662492_en\">comments</a> and <a href=\"https://ai.google/static/documents/google-ostp-biometrics-rfi.pdf\">responses</a> to open requests for information. We also initiated and are leading an effort with the <a href=\"https://www.iso.org/home.html\">International Standards Organization</a> (ISO/IEC PWI TS 17866) to share best practice guidance for the development of AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As these efforts look toward the future, Responsible AI needs to be supported across industries today. So for current Google Cloud Partners and customers seeking best practices to help with the responsible implementation and AI governance in their organization, we added responsible AI prerequisites to the Google Cloud Partner Advantage <a href=\"https://cloud.google.com/find-a-partner/?specializations=Machine%20Learning%20-%20Services\">ML Specialization</a>, including a newly-released training, \u201c<a href=\"https://www.cloudskillsboost.google/course_templates/388\">Applying AI Principles with Google Cloud</a>.\u201d</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To help nurture the next generation of responsible AI practitioners, we launched a free <a href=\"https://blog.google/technology/ai/discover-ai-in-daily-life/\">introduction</a> to AI and machine learning for K-12 students. And we continue to develop an external Responsible Innovation Fellowship program in the U.S. for students at Historically Black Colleges and Universities (HBCUs).</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our approach to responsible innovation also means keeping an eye on emerging markets where AI is being developed. We launched a new <a href=\"https://blog.google/technology/ai/investing-in-eastern-europes-ai-future/\">AI research center in Bulgaria</a> and expanded <a href=\"https://blog.google/around-the-globe/google-africa/supporting-growth-in-africa/\">support for African entrepreneurs</a> whose businesses use AI through our <a href=\"https://startup.google.com/accelerator/africa/\">Google for Startups Accelerator: Africa</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>The examples we\u2019re sharing today are a sampling of our ongoing commitment to responsible innovation. They also reflect our ability to change and keep setting a high bar for trustworthy AI standards for our company. We remain dedicated to sharing helpful information on Google\u2019s journey, as recommended practices for responsible AI continue to emerge and evolve.</p></div></div>",
            "pubdate": "Wed, 06 Jul 2022 18:00:00 +0000",
            "pubdate_parsed": 1657110600.0,
            "email_sent": true
        },
        "Helping people understand AI": {
            "url": "https://blog.google/technology/ai/helping-people-understand-ai/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>If you\u2019re like me, you may have noticed that AI has become a part of daily life. I wake up each morning and ask my smart assistant about the weather. I recently applied for a new credit card and the credit limit was likely determined by a machine learning model. And while typing the previous sentence, I got a word choice suggestion that \u201cprobably\u201d might flow better than \u201clikely,\u201d a suggestion powered by AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As a member of <a href=\"https://ai.google/responsibilities/review-process/\">Google\u2019s Responsible Innovation team</a>, I think a lot about how AI works and how to develop it responsibly. Recently, I spoke with Patrick Gage Kelley, Head of Research Strategy on Google\u2019s Trust &amp; Safety team, to learn more about developing products that help people recognize and understand AI in their daily lives.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How do you help people navigate a world with so much AI?</b></p><p>My goal is to ensure that people, at a basic level, know how AI works and how it impacts their lives. AI systems can be really complicated, but the goal of explaining AI isn\u2019t to get everyone to become programmers and understand all of the technical details \u2014 it\u2019s to make sure people understand the parts that matter to them.</p><p>When AI makes a decision that affects people (whether it\u2019s recommending a video or qualifying for a loan), we want to explain how that decision was made. And we don\u2019t want to just provide a complicated technical explanation, but rather, information that is meaningful, helpful, and equips people to act if needed.</p><p>We also want to find the best times to explain AI. Our goal is to help people develop AI literacy early, including in primary and secondary education. And when people use products that rely on AI (everything from online services to medical devices), we want to include a lot of chances for people to learn about the role AI plays, as well as its benefits and limitations. For example, if people are told early on what kinds of mistakes AI-powered products are likely to make, then they are better prepared to understand and remedy situations that might arise.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>Do I need to be a mathematician or programmer to have a meaningful understanding of AI?</b></p><p>No! A good metaphor here is financial literacy. While we may not need to know every detail of what goes into interest rate hikes or the intricacies of financial markets, it\u2019s important to know how they impact us \u2014 from paying off credit cards, to buying a home, or paying for student loans. In the same way, AI explainability isn\u2019t about understanding every technical aspect of a machine learning algorithm \u2013 it\u2019s about knowing how to interact with it and how it impacts our daily lives.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How should AI practitioners \u2014 developers, designers, researchers, students, and others \u2014 think about AI explainability?</b></p><p>Lots of practitioners are doing important work on explainability. Some focus on interpretability, making it easier to identify specific factors that influence a decision. Others focus on providing \u201cin-the-moment explanations\u201d right when AI makes a decision. These can be helpful, especially when carefully designed. However, AI systems are often so complex that we can\u2019t rely on in-the-moment explanations entirely. It\u2019s just too much information to pack into a single moment. Instead, AI education and literacy should be incorporated into the entire user journey and built continuously throughout a person\u2019s life.</p><p>More generally, AI practitioners should think about AI explainability as fundamental to the design and development of the entire product experience. At Google, we use our <a href=\"https://ai.google/principles\">AI Principles</a> to guide responsible technology development. In accordance with AI Principle #4: \u201cBe accountable to people,\u201d we encourage AI practitioners to think about all the moments and ways they can help people understand how AI operates and makes decisions.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How are you and your collaborators working to improve explanations of AI?</b></p><p>We develop resources that help AI practitioners learn creative ways to incorporate AI explainability in product design. For example, in the <a href=\"https://pair.withgoogle.com/guidebook/\">PAIR Guidebook</a> we launched a series of <a href=\"https://arxiv.org/abs/2009.00246\">ethical case studies</a> to help AI practitioners think through tricky issues and hone their skills for explaining AI. We also do fundamental research like <a href=\"https://arxiv.org/abs/2012.00874\">this paper</a> to learn more about how people perceive AI as a decision-maker, and what values they would like AI-powered products to embody.</p><p>We\u2019ve learned that many AI practitioners want concrete examples of good explanations of AI that they can build on, so we\u2019re currently developing a story-driven visual design toolkit for explanations of a fictional AI app. The toolkit will be publicly available, so teams in startups and tech companies everywhere can prioritize explainability in their work.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"An illustration of a sailboat navigating the coast of Maine\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Inline_Image_--_Helping_People_Understand_.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The visual design toolkit provides story-driven examples of good explanations of AI.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>I want to learn more about AI explainability. Where should I start?</b></p><p>This February, we released an <a href=\"https://applieddigitalskills.withgoogle.com/en/teach?gclid=CjwKCAjwi8iXBhBeEiwAKbUofZfj4ve-ub1b5Y5ZW2qe1NbNX4OOvdXWsxZhumVAoAOe67Bld2LGBxoCPNAQAvD_BwE\">Applied Digital Skills</a> lesson, \u201c<a href=\"https://applieddigitalskills.withgoogle.com/c/middle-and-high-school/en/discover-ai-in-daily-life/overview.html\">Discover AI in Daily Life</a>.\u201d It\u2019s a great place to start for anyone who wants to learn more about how we interact with AI everyday.</p><p>We also hope to speak about AI explainability at the upcoming <a href=\"https://www.sxsw.com/conference/\">South by Southwest Conference</a>. Our proposed session would dive deeper into these topics, including our visual design toolkit for product designers. If you\u2019re interested in learning more about AI explainability and our work, you can vote for our proposal through the SXSW PanelPicker\u00ae <a href=\"https://panelpicker.sxsw.com/vote/129081\">here</a>.</p></div></div>",
            "pubdate": "Thu, 18 Aug 2022 15:00:00 +0000",
            "pubdate_parsed": 1660834800.0,
            "email_sent": true
        }
    },
    "OpenAI Blog": {
        "DALL\u00b7E 2: Extending Creativity": {
            "url": "https://openai.com/blog/dall-e-2-extending-creativity/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>As part of our DALL&#xb7;E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL&#xb7;E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL&#xb7;E and have served as</p></div>",
            "pubdate": "Thu, 14 Jul 2022 16:30:22 GMT",
            "pubdate_parsed": 1657796422.0,
            "email_sent": true
        },
        "Reducing Bias and Improving Safety in DALL\u00b7E 2": {
            "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/",
            "description": "<!--kg-card-begin: markdown--><p>Today, we are implementing a new technique so that DALL&#xb7;E generates images of people that more accurately reflect the diversity of the world&#x2019;s population. This technique is applied at the system level when DALL&#xb7;E is given a prompt describing a person that does not</p>",
            "pubdate": "Mon, 18 Jul 2022 16:30:23 GMT",
            "pubdate_parsed": 1658142023.0,
            "email_sent": true
        },
        "DALL\u00b7E Now Available in Beta": {
            "url": "https://openai.com/blog/dall-e-now-available-in-beta/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>We&#x2019;ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL&#xb7;E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.</p>\n<div class=\"btns mb-0.5\">\n<a class=\"btn btn-padded btn-dark btn-circle icon-external right\" href=\"https://labs.openai.com/waitlist\">Join DALL&#xb7;E 2 waitlist</a>\n</div>\n</div>\n<p><a href=\"https://openai.com/dall-e-2/\">DALL&#xb7;E</a>, the AI system that</p>",
            "pubdate": "Wed, 20 Jul 2022 16:29:05 GMT",
            "pubdate_parsed": 1658314745.0,
            "email_sent": true
        }
    },
    "Apple Machine Learning Blog": {
        "Dynamic Memory for Interpretable Sequential Optimisation": {
            "url": "https://machinelearning.apple.com/research/dynamic-memory",
            "description": "Real-world applications of reinforcement learning for recommendation and experimentation faces a practical challenge: the relative reward of different bandit arms can evolve over the lifetime of the learning agent. To deal with these non-stationary cases, the agent must forget some historical knowledge, as it may no longer be relevant to minimise regret. We present a solution to handling non-stationarity that is suitable for deployment at scale, to provide business operators with automated adaptive optimisation. Our solution aims to provide interpretable learning that can be trusted by humans\u2026",
            "pubdate": "Fri, 01 Jul 2022 16:39:17 GMT",
            "pubdate_parsed": 1656673757.0,
            "email_sent": true
        },
        "Style Equalization: Unsupervised Learning of Controllable Generative Sequence Models": {
            "url": "https://machinelearning.apple.com/research/unsupervised-learning",
            "description": "Controllable generative sequence models with the capability to extract and replicate the style of specific examples enable many applications, including narrating audiobooks in different voices, auto-completing and auto-correcting written handwriting, and generating missing training samples for downstream recognition tasks. However, under an unsupervised-style setting, typical training algorithms for controllable sequence generative models suffer from the training-inference mismatch, where the same sample is used as content and style input during training but unpaired samples are given during\u2026",
            "pubdate": "Fri, 01 Jul 2022 16:41:20 GMT",
            "pubdate_parsed": 1656673880.0,
            "email_sent": true
        },
        "Speech Emotion: Investigating Model Representations, Multi-Task Learning and Knowledge Distillation": {
            "url": "https://machinelearning.apple.com/research/investigating-model-representations",
            "description": "Estimating dimensional emotions, such as activation, valence and dominance, from acoustic speech signals has been widely explored over the past few years. While accurate estimation of activation and dominance from speech seem to be possible, the same for valence remains challenging. Previous research has shown that the use of lexical information can improve valence estimation performance.\nLexical information can be obtained from pre-trained acoustic models, where the learned representations can improve valence estimation from speech. We investigate the use of pre-trained model representations\u2026",
            "pubdate": "Mon, 11 Jul 2022 20:59:50 GMT",
            "pubdate_parsed": 1657553390.0,
            "email_sent": true
        },
        "ICML 2022": {
            "url": "https://machinelearning.apple.com/updates/apple-at-icml-2022",
            "description": "<p>Apple is sponsoring the International Conference on Machine Learning (ICML) which will be held in Baltimore, Maryland from July 17 to 23. ICML is a conference dedicated to the advancement of machine learning.</p>",
            "pubdate": "Mon, 11 Jul 2022 20:05:05 GMT",
            "pubdate_parsed": 1657550105.0,
            "email_sent": true
        },
        "Private Frequency Estimation via Projective Geometry": {
            "url": "https://machinelearning.apple.com/research/private-frequency-estimation",
            "description": "In this work, we propose a new algorithm ProjectiveGeometryResponse (PGR) for locally differentially private (LDP) frequency estimation. For a universe size of  and with  users, our -LDP algorithm has communication cost  bits in the private coin setting and  in the public coin setting, and has computation cost  for the server to approximately reconstruct the frequency histogram, while achieving the state-of-the-art privacy-utility tradeoff. In many parameter settings used in practice this is a significant improvement over the  computation cost that is achieved by the recent PI-RAPPOR algorithm\u2026",
            "pubdate": "Mon, 11 Jul 2022 22:04:39 GMT",
            "pubdate_parsed": 1657557279.0,
            "email_sent": true
        },
        "Efficient Representation Learning via Adaptive Context Pooling": {
            "url": "https://machinelearning.apple.com/research/efficient-representation",
            "description": "Self-attention mechanisms model long-range context by using pairwise attention between all input tokens. In doing so, they assume a fixed attention granularity defined by the individual tokens (e.g., text characters or image pixels), which may not be optimal for modeling complex dependencies at higher levels. In this paper, we propose ContextPool to address this problem by adapting the attention granularity for each token. Inspired by the success of ConvNets that are combined with pooling to capture long-range dependencies, we learn to pool neighboring features for each token before computing\u2026",
            "pubdate": "Mon, 11 Jul 2022 20:02:24 GMT",
            "pubdate_parsed": 1657549944.0,
            "email_sent": true
        },
        "Self-Conditioning Pre-Trained Language Models": {
            "url": "https://machinelearning.apple.com/research/self-conditioning-pre-trained",
            "description": "In this paper we aim to investigate the mechanisms that guide text generation with pre-trained Transformer-based Language Models (TLMs). Grounded on the Product of Experts formulation by Hinton (1999), we describe a generative mechanism that exploits expert units which naturally exist in TLMs. Such units are responsible for detecting concepts in the input and conditioning text generation on such concepts. We describe how to identify expert units and how to activate them during inference in order to induce any desired concept in the generated output. We find that the activation of a\u2026",
            "pubdate": "Mon, 11 Jul 2022 21:19:31 GMT",
            "pubdate_parsed": 1657554571.0,
            "email_sent": true
        },
        "Position Prediction as an Effective Pre-training Strategy": {
            "url": "https://machinelearning.apple.com/research/position-prediction",
            "description": "Transformers  have gained increasing popularity in a wide range of applications, including Natural Language Processing (NLP), Computer Vision and Speech Recognition, because of their powerful representational capacity. However, harnessing this representational capacity effectively requires a large amount of data, strong regularization, or both, to mitigate overfitting. Recently, the power of the Transformer has been unlocked by self-supervised pretraining strategies based on masked autoencoderswhich rely on reconstructing masked inputs, directly, or contrastively from unmasked content. This\u2026",
            "pubdate": "Mon, 11 Jul 2022 21:39:05 GMT",
            "pubdate_parsed": 1657555745.0,
            "email_sent": true
        },
        "ARtonomous: Introducing Middle School Students to Reinforcement Learning Through Virtual Robotics": {
            "url": "https://machinelearning.apple.com/research/reinforcement-learning-robotics",
            "description": "Typical educational robotics approaches rely on imperative programming for robot navigation. However, with the increasing presence of AI in everyday life, these approaches miss an opportunity to introduce machine learning (ML) techniques grounded in an authentic and engaging learning context. Furthermore, the needs for costly specialized equipment and ample physical space are barriers that limit access to robotics experiences for all learners. We propose ARtonomous, a relatively low-cost, virtual alternative to physical, programming-only robotics kits. With ARtonomous, students employ\u2026",
            "pubdate": "Wed, 20 Jul 2022 17:23:26 GMT",
            "pubdate_parsed": 1658318006.0,
            "email_sent": true
        },
        "KDD 2022": {
            "url": "https://machinelearning.apple.com/updates/apple-at-kdd-2022",
            "description": "<p>Apple is sponsoring the 28th annual ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). KDD will be held in Washington D.C. from August 14  to 18. It is an interdisciplinary conference bringing together researchers and practitioners from data science, data mining, knowledge discovery, large-scale data analytics, and big data.</p>",
            "pubdate": "Fri, 29 Jul 2022 02:34:27 GMT",
            "pubdate_parsed": 1659042267.0,
            "email_sent": true
        }
    },
    "Towards AI Blog": {
        "Neural Entity Linking in JPMorgan Chase": {
            "url": "https://towardsai.net/p/l/neural-entity-linking-in-jpmorgan-chase",
            "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Harshit Sharma Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Neural Entity Linking at JPMorgan\u00a0Chase JPMC published a paper in 2021 highlighting their approach to Entity Linking. This article summarizes the problem statement, solution, and other key technical components of the\u00a0paper What is Entity\u00a0Linking? It&#039;s the task of assigning a unique identity to ambiguous mentions of named entities in a\u00a0text. An example of an entity linking from Wikipedia Here, \u201cParis\u201d from the text is given a unique identity via a URL (the most common type of URI) \u201cwikipedia.org/wiki/Paris\u201d. Note that the type of URI used to identify the mentioned entity depends on the domain uniquely. For eg, Instead of a web address, we could have used ISBNs if we were to identify books from a\u00a0text. JPMC was interested in\u00a0: Mapping mentions of financial institutions from news articles to the entities stored in their internal knowledge base (stored as a Knowledge Graph) An example is shown\u00a0below: Example of Entity Linking from the\u00a0paper There are two sub-problems that must be\u00a0defined: Recognition: Extraction of mentions from financial news articles. JPMC has used Spacy for\u00a0this. Linking:Choosing the correct entity from the internal Knowledge Graph to be linked to the extracted mentions in the previous step. The paper discusses this\u00a0step. A pictorial representation of this is shown\u00a0below: (Image by Author) Sub-problems as part of the overall\u00a0solution String MatchingThese approaches capture the \u201cmorphological\u201d structure of the entity names. The team experimented with (a) Jaccard(b) Levenshtein(c) Ratcliff-Obershelp (also known as Gestalt-Pattern-Matching)(d) Jaro Winkler(e) N-Gram Cosine Similarity The con of these approaches is that they focus just on the \u201csyntactics\u201d of the names and not the semantics. An example of a failure case would be the matching of \u201cLumier\u201d and \u201cLumier\u201d. Even though they are exactly the same, they refer to two different entities. 2. Context Similarity MethodsThese methods take the contexts around mentions and entities to give a similarity score.The Context for \u201cmention\u201d is text to the left and right of the mention, whereasthe Context for \u201centity\u201d is all the data that&#039;s stored in the KG for this entity.Finally, Cosine similarity / Jaccard similarity can be used on top of the context\u00a0vectors. 3. ML ClassificationNaive Bayes, Logistic Regression, and SVM are trained on (mention, entity) pairs to find the ones that should be\u00a0linked 4. Learn to Rank Methods (LTR)These models work in tandem with ML approaches, which might give us multiple (mention, entity) pairs as the solutions. LTR approaches just narrow down to the most probable solution. The idea is to capture both Semantic distance(the meaning that the mention or entity stands for) and Syntactic distance (character composition of the name) between the names and use a contrastive loss function to train a\u00a0model. We will see below how both of these distances are calculated step by\u00a0step. Step 1: Obtain embeddings for Entities and\u00a0Mentions To come up with both of the distances, the authors have proposed to use embeddings for mentions as well as entities in the\u00a0KG. To obtain Entity embeddings, the authors have used a Triplet Loss function (shown\u00a0below) Triplet Loss\u00a0Function For each entity, they used 10 positive and 10 negative samples, making 10 &#60;entity, positive word, negative word&#62; triplets. Model for Entity embedding Unlike Entity embeddings, which they had precomputed, the mention embeddings were trained using the on-the-go embeddings approach, where the embedding matrix is learned during the training\u00a0itself. Step 2: Calculate Syntactic Distance\u00a0score Before going further, it&#039;s worth mentioning \u201cWide &#38; Deep\u201d architecture which was introduced by Google in 2016. You can find their official blog here. We won\u2019t go into the details, but to give a summary, it&#039;s an architecture that has two components\u200a\u2014\u200aThe Wide component and the Deep component. Image from Google\u2019s paper &#124; Spectrum of Wide and Deep\u00a0Models Syntactic Distance score calculation is done using the WIDE part, which consists of a Linear Siamese\u00a0Network. Calculation of Syntax Distance\u00a0score The output of the siamese network is the vectors for both the entity and the mention, which are then compared to find the Euclidean distance. Step 3: Calculate Semantic Distance\u00a0score Semantic Distance score calculation is done using the DEEP\u00a0part Calculation of Semantic Distance\u00a0score e\u2096 is the pre-trained embedding for the \u201cApache Corp\u201d that was calculated in Step 1. To obtain the embedding for the mention, its left and right context words are fed into a Bi-LSTM network that trains the embeddings. The embedding vectors of mention (V\u2098) and the entity (V\u2091) are then used to find the Euclidean distance: Step 4: Compute Contrastive Loss Both Syntactic and Semantic distances are combined in a weighted fashion as\u00a0follows: The contrastive loss function is then combined as\u00a0follows: Contrastive Loss\u00a0Function where Y is the ground truth value, where a value of 1 indicates that mention m and entity e are matched, 0 otherwise. Combining all the pieces, the final model framework is shown\u00a0below: JEL Model Framework At the time of writing this paper, JPMC was still in the process of deploying the model, which, once done, will help support users across JPMC in discovering relevant and curated news that matters to their business. From the cost perspective, not all the mentions are fed through the JEL framework as that would be computationally expensive. JPMC has put another blocking layer to funnel out the mentions that share less than 2 bigrams with the entities from their internal\u00a0KGs. Once again, here is the paper link if you would like to read the full\u00a0paper. Follow Intuitive Shorts (my Substack newsletter), to read quick and intuitive summaries of ML/NLP/DS concepts. Neural Entity Linking in JPMorgan Chase was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. [&#8230;]",
            "pubdate": "Tue, 02 Aug 2022 20:18:56 +0000",
            "pubdate_parsed": 1659451736.0,
            "email_sent": true
        },
        "GANs for Synthetic Data Generation": {
            "url": "https://towardsai.net/p/l/gans-for-synthetic-data-generation",
            "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Varatharajah Vaseekaran Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A practical guide to generating synthetic data using open-sourced GAN implementations The advancements in technology have paved the way for generating millions of gigabytes of real-world data in a single minute, which would be great for any organization or individual in utilizing the data. However, a large amount of time and resources would be consumed in cleaning, processing, and extracting vital information from the mounds of\u00a0data. The answer to handling such a problem is by generating synthetic data. Photo by Vackground on Unsplash. Contents What is Synthetic Data? A Brief Introduction to\u00a0GANs Mode Collapse Wasserstein GAN\u00a0(WGAN) Implementing a GAN for Synthetic Data Generation The Dataset Designing and Training the Synthesizer Final Words References What is Synthetic Data? Photo generated using DALL-E by\u00a0author. The definition for synthetic data is quite straightforward: artificially generated data that mimics real-world data. Organizations and individuals can leverage the use of synthetic data to their needs and would be able to generate data, according to their specifications, as much as they\u00a0require. The use of synthetic data is highly beneficial in preserving privacy in information-sensitive domains: the medical data of the patients and transactional details of banking customers are a few examples where synthetic data can be used to mask the real data, which would enable sharing of sensitive data among organizations. Few well-labeled data can be used to generate a large amount of synthetic data, which would fast-track the time and energy needed to process the massive real-world data. There are many ways of generating synthetic data: SMOTE, ADASYN, Variational AutoEncoders, and Generative Adversarial Networks are a few techniques for synthetic data generation. This article will focus on using Generative Adversarial Networks to generate synthetic data and a practical demonstration of generating synthetic data using open-sourced libraries. A Brief Introduction to\u00a0GANs Generating photorealistic faces using GANs based on StyleGAN3 research. Image from\u00a0[1]. Many machine learning and deep learning architectures are prone to adversarial manipulation, that is, the models fail when data that is different to the one that is used to train is fed. To solve the adversarial problem, Generative Adversarial Networks (GANs) were introduced by Ian Goodfellow [2], and currently, GANs are very popular in generating synthetic data. A typical GAN consists of two components: generator and discriminator, where both networks compete with each\u00a0other. The generator is the heart of the GAN, where it attempts to generate fake data that looks real by learning the features from the real\u00a0data. The discriminator evaluates the generated data with the real data and classifies whether the generated data looks real or not, and provides feedback to the generator to improve its data generation. The goal of the generator is to generate data that can trick the discriminator. A Vanilla GAN architecture. Image from\u00a0[3]. Mode Collapse Mode collapse is a common problem that GAN-based architectures face during adversarial training, where the generator repeatedly generates one specific type of data. This occurs when the generator identifies that it can fool the discriminator with one type of data, the generator would keep on generating that same\u00a0data. This problem can easily go undetected, as the metrics would indicate the model training is running smoothly, but the generated results would indicate otherwise. An example of mode collapse in image-based GANs. Image from\u00a0[4]. Wasserstein GAN\u00a0(WGAN) The main problem in a standard GAN is the difference in complexity of the outputs from the generator and the discriminator. A standard Vanilla GAN uses the Binary Cross Entropy (BCE)loss function [5] to evaluate whether the generated data looks real, where the output of the loss function is between 0 and 1. The task of the generator is to generate synthetic data that might have a lot of features and values, and the output from the discriminator is not sufficient for the generator to learn, and due to the lack of guidance, the generator can easily fall into mode collapse. WGAN [6] alleviates the problem by replacing the discriminator with a critic, where the critic would evaluate the distribution of the real data with the distribution of the generated data and outputs a score of how real the generated data looks when compared to the real data. The Wasserstein loss function utilized in WGAN measures the difference between the real distribution and the generated distribution based on the Earth Mover\u2019s Distance. Visualization of Earth Mover\u2019s Distance. Image from Coursera course\u00a0[8] Earth Mover\u2019s Distance measures the effort that is needed to make the distribution of the generated data look similar to the real data\u2019s distribution. Therefore, there is no limitation on the value that is output. That is, if both distributions are far apart, the Earth Mover\u2019s Distance will give a real positive value, whereas the BCE loss would output gradient values that are closer to zero. Therefore, the Wasserstein loss function enables solving the vanishing gradient problem during training. The expression of Wasserstein Loss. Image from Coursera course\u00a0[8]. The above picture denotes the equation for the Wasserstein loss, which is relatively simple compared to the BCE loss. The initial part of the equation is the expected value of the prediction that the critic provides on the real data. The second part of the equation is the expected value of the prediction that the critic provides on the generated data. The goal of the critic is to maximize the distance between the real and generated data, and the goal of the generator is to minimize that difference. Difference between BCE (left) and Wasserstein (right) losses. Image from Coursera course\u00a0[8]. WGANs are prone to exploding gradient problems, as the Wasserstein loss outputs any value that is positive and real; therefore, the value of the [&#8230;]",
            "pubdate": "Tue, 02 Aug 2022 17:03:39 +0000",
            "pubdate_parsed": 1659440019.0,
            "email_sent": true
        },
        "Sports Analytics 101\u200a\u2014\u200aExpected Threats (xT)": {
            "url": "https://towardsai.net/p/l/sports-analytics-101%e2%80%8a-%e2%80%8aexpected-threats-xt",
            "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Nitin Chauhan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Sports Analytics 101\u200a\u2014\u200aExpected Threats\u00a0(xT) The threat of a goal being conceded or a threat of an opposition scoring a goal through play. Courtesy: Image via Omar\u00a0Ram As part of the introduction series on sports analytics for beginners, I am writing a series of articles examining the impact and benefits of machine learning and data analytics. Throughout my life as an aspiring data scientist, I have always sought out guides that would help me gain a deeper understanding of sports analytics. In the years that I have spent researching and attending courses, I have come up with the concept of a guide titled Sports Analytics 101. My hope is that this guide will assist people like myself in better understanding and appreciating sports + data analytics. Why Expected Threat\u00a0(xT)? From coaches to scouts to fans, one of the critical questions is how we evaluate the quality of a player based on data. We now understand that scoring many goals means they are good, and finding good scoring opportunities (having a high xG) is also essential. How do we value all those passes, dribbles, blocks, and interceptions? A concept called expected Threat has been adopted by Athletic when discussing player and team performance. An example of such a probability map is provided below, which assigns a value to every point on a football field based on the probability that having the ball there will result in a\u00a0goal. A zonal grid of football pitches with each zone being allocated an expected threat probability. What is the Expected Threat\u00a0(xT)? According to the expected threat model, matches are divided into possessions, which are periods in which the same team owns the ball. According to xT, (1) players act intentionally to increase the chances of scoring for their team, and (2) the chance of scoring can be adequately captured by considering only the ball\u2019s location. As a result of point (2), xT represents a game state solely by utilizing the current ball location. As a result, xT overlays a grid of M*N points over the pitch to divide it into zones. In the figure below, xT(z) is illustrated as a result of how threatening teams are at each zone\u00a0z. This chart shows the Expected Threat for different parts of the pitch. It shows how likely a goal will be scored, given that the team has possession at that location. Expected Threat (xT) is calculated from the middle of the pitch. The movement towards the goal is more likely than the shot being conceded from that position; Courtesy: Image via Karun\u00a0Singh Expected Threat (xT) is calculated near the penalty box. There\u2019s a higher chance of a goal being conceded by a team around that zone by the opposition; Courtesy: Image via Karun\u00a0Singh We evaluate actions based on their effect on the probability of scoring. The expected Threat (xT) is defined as the change in the likelihood of scoring. The player has increased the xT in favor of their team if they make a pass that moves the ball from a place where their team is unlikely to score to a place where they have a greater probability of scoring. There is a general rule that the closer you are to the goal, the more likely your team will score (although passes back to the goalkeeper can also be very valuable). Utilizing the Expected Threat (xT)\u00a0metric Spaces are of greater value than others. The same is true on the football pitch. If you have the ball in your half, it is less valuable than if it is near the edge of your opponent\u2019s box. We know those two things intuitively, but how do we measure them? The expected threat (xT, for short) is an effective solution for this problem for various reasons. Not all attacks are connected. https://medium.com/media/9acff157cbe3a398218aee2c12d52c90/href It was Sarah Rudd, who invented Expected Threat in 2011. She did not call it that. She did not call it anything at all, but she had the mathematical insight, using Markov chains, on which it was based, which you can see in this video. On this basis, she was recruited by StatDNA, which Arsenal acquired shortly after. Karun Singh first used the name xT in a blog post in 2018, and it was then repurposed in the public\u00a0sphere. When we see a clear example of a female scientist coming up with the idea that is now being used everywhere in a male-dominated area, it is added essential to pause and let others know where it came from. Science has a history of forgetting women\u2019s contributions, and it would be embarrassing if we made the same mistake in football, especially in the modern\u00a0era. We should remember, therefore, that when we hear that Liverpool used expected goals added in recruitment during 2018\u201319 or that Opta and Statsbomb have their versions of expected Threat, this all came about because one very determined young woman went to as many sports analytics conferences as possible over the past ten years and pestered everyone she met until she gained one of the first jobs ever in football analytics. With that clarified, I would like to make a more subtle point. There are many ways to measure expected Threats, as compared to expected goals. Our methodology at Twelve Football differs from that outlined above. Moreover, it is better\u2026 (I am not saying that it is better than what Rudd used at Arsenal, but there has been much progress since her talk in 2011) But if you have, for example, Opta, Statbomb, or Wyscout event data, this is the best method for implementing xT. This is our logic. Football is a [&#8230;]",
            "pubdate": "Tue, 02 Aug 2022 16:38:59 +0000",
            "pubdate_parsed": 1659438539.0,
            "email_sent": true
        },
        "Non-Linear Models": {
            "url": "https://towardsai.net/p/l/non-linear-models",
            "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Dr. Marc Jacobs Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. When the formula looks nice but is hurting the\u00a0analysis This is not my first blog concerning non-linear models. In fact, if you sift through my lists of blogs, you can see I applied quite a couple of them. Personally, I like non-linear models since they have a biological basis, and if you have data that does not connect to that basis, it can become quite a challenge to move further. As always, the first steps are the hardest, and nothing suits that premise better than a non-linear model. I will not dive into a talk about non-linear models, but what I will do is show you briefly my struggle with a dataset handed to me by another researcher. This is nutritional commercial data, so I cannot share the data itself, but you can see what I did. Also, the formula given to me is beyond my comprehension, but what I will show is that a perfect-looking formula can be quite difficult to work with if it fits the data too perfectly. Let&#039;s start by loading the libraries and the data. It is data coming from piglets, measured across\u00a0time. rm(list = ls())library(readr)library(nlstools)library(nlme)library(ggplot2)library(nls2) ## new file from TheoOral_data_for_Marc &#60;- read_delim(\"Oral data for Marc.csv\", \";\", escape_double = FALSE, trim_ws = TRUE)data&#60;-Oral_data_for_Marcrm(Oral_data_for_Marc)data&#60;-data[, 1:3]data&#60;-data[complete.cases(data),]head(data);str(data)as.numeric(gsub(\",\", \".\", gsub(\"\\\\.\", \"\", data$D9std)))data$D9std &#60;- gsub(\",\", \"\", data$D9std)data$D9std &#60;- as.numeric(data$D9std) data$D9std&#60;-data$D9std/1000000000data$Big&#60;-as.factor(data$Big) The data for each piglet (Big), time, and the outcome of interest. Now, the data was not easy to work with from the start, especially the outcome. It was loaded as a character, but I could not make a numeric on the spot, forcing me to do some transformations first. Transforming the\u00a0data. ggplot(data, aes(x=time, y=D9std, group=Big, col=Big))+ geom_point()+ geom_line()+ theme_bw()+ labs(x=\"Time\", y=\"Value\", col=\"Pig\" ) Plotting the data. I have nine piglets, showing data across time (seconds). The majority follow a distinct pattern, but not all, and this will cause our non-linear model some\u00a0trouble. Not only will the pathway cause issues, but also the beginning, which is why I cut a couple of seconds from the data. Let&#039;s see how the data will look\u00a0then. datasub&#60;-data[data$time&#62;=30,];head(datasub)colnames(datasub)[2]&#60;-\"x\" # time called xcolnames(datasub)[3]&#60;-\"y\" # D9std called ydatasub$Big&#60;-NULL # not informative vectordatasub&#60;-as.data.frame(datasub)datasub$y &#60;- gsub(\",\", \"\", datasub$y) datasub$y&#60;-as.numeric(datasub$y)head(data)head(datasub);str(datasub)plot(datasub$x, datasub$y) Not much better to be\u00a0honest. Now, it is time to look at the formula. As I said, this was handed to me, and I have no idea how somebody ever came up with such an elaborate formula. It truly is massive, with several compartments included. Below you see ways to connect the formula and how I test it to make sure I translated it correctly in\u00a0R. formulaExp&#60;-as.formula(y~P*(I(1-(exp(-(Ks*x))))^B)*(Ka*((exp(-(Ke*x)))-(exp(-(Ka*x))))/(Ka-Ke))) f1&#60;-function(x, P, Ks,B, Ka, Ke){ P*(I(1-(exp(-(Ks*x))))^B)*(Ka*((exp(-(Ke*x)))-(exp(-(Ka*x))))/(Ka-Ke))} f1(20, P=2.48, Ks=0.014, B=1.52, Ka=0.00059, Ke=0.00690) Gives a decent\u00a0value. The biggest hurdle in non-linear regression modeling is finding the exact values. Since non-linear models are not closed, the search goes iterative. One way of taking a peak is by plotting the data and overlaying several gradations of the\u00a0curve. plot(datasub$x, datasub$y)curve(f1(x, P=2.48, Ks=0.014, B=1.52, Ka=0.00059, Ke=0.00690), add=T, col=\"red\") curve(f1(x, P=3.5, Ks=0.014, B=1.52, Ka=0.00059, Ke=0.00690), add=T, col=\"green\") curve(f1(x, P=3.5, Ks=0.010, B=1.52, Ka=0.00059, Ke=0.00690), add=T, col=\"yellow\") curve(f1(x, P=3.5, Ks=0.010, B=1.52, Ka=0.00050, Ke=0.00590), add=T, col=\"blue\") curve(f1(x, P=3.5, Ks=0.010, B=1.42, Ka=0.00059, Ke=0.00690), add=T, col=\"orange\") curve(f1(x, P=3.0, Ks=0.010, B=1.62, Ka=0.00080, Ke=0.0090), add=T, col=\"purple\") This actually looks very, very nice! The curves follow the data in a splendid fashion. The formula IS quite complex, though but it works\u00a0wonders. A simple way of checking if the coefficients for each of the parameters, as chosen, come close to the average value seen in the data. This exercise was an additional check but not really necessary anymore considering the curves fitted\u00a0above. In R, there is a very nice package called NLStools, which will help you look at the data and offer functions to preview the coefficients you deem to be a good fit. Like I said before, that process is quite difficult, and unlike simple linear regression or mixed modeling, decent starting values are key in finding the solution. If there is\u00a0one. Residual Sums of Squares are provided which does not mean that much without comparison. However, considering the scale, it is still more than you would\u00a0like. The picture that belongs to the preview process. The model looks good, but the high Residual Sum of Squares is to be explained for\u00a0sure. Up until now, I have fed the formula a single or just a couple of scenarios. That is good if you know where to look but often you do not, so it is better to conduct a grid search. What this simply means is that you create a matrix of combinations and then let the model sift to\u00a0that. Below is the command for the grid and how it\u00a0looks. grid.theo&#60;-expand.grid(list(P=seq(2, 4, by=0.1), Ks=seq(0.010, 0.020, by=0.01), B=seq(1.4, 1.6, by=0.01), Ka=seq(0.005,0.007,by=0.01), Ke=seq(0.006,0.008, by=0.01))) grid.theo Then, it is time to feed the model the\u00a0grid. mod1 &#60;- nls2(formulaExp, data=datasub, start = grid.theo, algorithm = \"brute-force\")plot(mod1)nls2(formulaExp, data=datasub, start = mod1) I am getting a lot of\u00a0errors. However, the model does produce. You can see the formula, the coefficients, and the residual sum of squares of the model chosen. It looks a lot higher than the value I obtained from the last\u00a0preview. Now, there ARE other ways of using grid searches by connecting them directly to the model. Here, you see me going at it\u00a0again. f1_nls_fit &#60;- nls.multstart::nls_multstart(y ~ f1(x, P, Ks,B, Ka, Ke),data = datasub,lower=c(P=2, Ks=0.01, B=1.4, Ka=0.005, Ke=0.006),upper=c(P=4, Ks=0.02, B=1.6, Ka=0.007, Ke=0.008),start_lower = c(P=2, Ks=0.01, B=1.4, Ka=0.005, Ke=0.006),start_upper = c(P=4, Ks=0.02, B=1.6, Ka=0.007, Ke=0.008),iter = 500,supp_errors = \"Y\") summary(f1_nls_fit)plot(f1_nls_fit) plot_nls &#60;- function(nls_object, data) { predframe &#60;- tibble(x=seq(from=min(datasub$x), to=max(datasub$x), length.out = 1024)) %&#62;% mutate(ypred = predict(nls_object, newdata = list(x=.$x))) ggplot(data, aes(x=x, y=y)) + [&#8230;]",
            "pubdate": "Tue, 02 Aug 2022 16:33:53 +0000",
            "pubdate_parsed": 1659438233.0,
            "email_sent": true
        },
        "Sports Analytics 101\u200a\u2014\u200aExpected Goals (xG)": {
            "url": "https://towardsai.net/p/l/sports-analytics-101%e2%80%8a-%e2%80%8aexpected-goals-xg",
            "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Nitin Chauhan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Sports Analytics 101\u200a\u2014\u200aExpected Goals\u00a0(xG) Courtesy: Image via Sven\u00a0Kucinic As part of the introduction series on sports analytics for beginners, I am writing a series of articles examining the impact and benefits of machine learning and data analytics. Throughout my life as an aspiring data scientist, I have always sought out guides that would help me gain a deeper understanding of sports analytics. In the years that I have spent researching and attending courses, I have come up with the concept of a guide titled Sports Analytics 101. My hope is that this guide will assist people like myself in better understanding and appreciating sports + data analytics. Why Expected Goals\u00a0(xG)? Over the past few years, football has become increasingly dependent on data and statistics. One of the most widely used and insightful football analytics metrics is expected goals (or xG). It was introduced by Opta\u2019s Sam Green in 2012 and has since become one of the most widely used\u00a0metrics. It has now become a regular feature for mainstream broadcasters such as Sky Sports and BBC\u2019s Match of the Day, following the early adoption of expected goals in the betting and professional markets. From the laptops of analysts to the mouths of Premier League managers, xG has gained popularity. In recent interviews, Jurgen Klopp has compared Liverpool\u2019s expected goals output with Manchester City\u2019s, while Dean Smith has used the metric to discuss Aston Villa\u2019s performance this\u00a0season. Over the past few years, expected goals have inevitably been criticized by general football fans who have become increasingly aware of it (see Jeff Stelling in 2017)\u200a\u2014\u200atraditionally viewed games versus the upcoming world of data analytics. However, before judging the metric, it is vital to comprehend how the metric operates and how it should be utilized. Expected Goal (xG) ratio for top strikers in Bundesliga season 2019/20; Courtesy: Image via\u00a0twenty3 What Are Expected Goals\u00a0(xG)? By calculating the probability that a given opportunity will be scored from a particular location on a pitch during a specific phase of play, expected goals (xG) are calculated to determine the quality of a chance. As a result of these calculations, several factors were taken into account before the shot was taken. In terms of xG, zero represents the likelihood that a player is unlikely to score, while one represents the likelihood that they are likely to score consistently. In such a situation, a player is less likely to score a goal from the halfway line than from within the box. By quantifying xG, we can assess the probability of a player scoring from each of these situations. As an example, assume that the chance of a player scoring inside the box with a set of pre-shot characteristics is worth 0.1 xG. Thus, in this situation, a player will likely score one goal out of every ten shots, or 10% of the\u00a0time. Football fans and commentators had used these phrases for years before xG was introduced\u200a\u2014\u200a\u201che scores that nine out of ten times\u201d or \u201che should have had a hat-trick.\u201d Standard Misinterpretations about\u00a0xG Most criticisms of expected goals (xG) arise from an incorrect metric application. One example of this is the game level. Having the highest xG in a match does not necessarily imply the team should have won. xG is a measure of chance quality, not the expected outcome. Goals change games, and scorelines influence how teams play, just as the old saying goes. If a team takes an early lead, they do not necessarily \u2018need\u2019 to generate more chances. We typically expect the opposition to create more scoring chances during the remainder of the game to make a comeback. Secondly, there is a misconception regarding the literal interpretation of the metric name. We do not \u201cexpect\u201d goals to occur precisely as the likelihood predicts. Additionally, fractions of goals cannot be achieved. A measure of the probability of an outcome occurring is known as an \u201cexpected goal,\u201d derived from the mathematical concept of \u201cexpected value.\u201d The expected value of a fair coin toss is 50% on heads and 50% on tails (the probability of landing on heads is 0.5). Rather than expecting exactly half of our tosses to land on each outcome, we anticipate a regress to this balance over a more significant number of coin tosses. Expected goals are no different. Variances from the expected values are inevitable, and this is valuable information we can utilize to analyze football\u00a0scores. As the Gambler\u2019s Fallacy indicates, if a player or team has been overperforming their xG, they do not need to underperform to regress to expectation. Even though we expect them to revert to scoring as they expected with their future shots, they have already \u2018banked\u2019 this overperformance. As a result, we should expect them to still overperform by this amount in the aggregates throughout the season. In the same way, a coin toss that lands on heads ten times in a row is equally likely to land on heads as tails in the future, but the ten times it has already landed on heads are already behind\u00a0us. Calculating the Expected Goals\u00a0(xG) We can tell intuitively which chances were more or less likely to end in goals based on factors such as how close the shooter was to the goal, whether they shot from a good angle, whether it was one-on-one or whether it was a\u00a0header. As a result, we have to work out the probability for an average of 25 shots per game, all of which can be the result of unique circumstances. We can now quantify the effects of the variables above and others on the likelihood that a goal will be [&#8230;]",
            "pubdate": "Tue, 02 Aug 2022 16:33:50 +0000",
            "pubdate_parsed": 1659438230.0,
            "email_sent": true
        },
        "This AI newsletter is all you need #6": {
            "url": "https://towardsai.net/p/newsletter/this-ai-newsletter-is-all-you-need-6",
            "description": "Last Updated on August 2, 2022 by Editorial Team Author(s): Towards AI Editorial Team &#160; Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. We are excited to announce that we will partner with the MineRL competition we shared a few weeks ago and host a Q&#38;A on the server with one of the organizers/deep mind researchers/Open AI VPG paper team involved in the MineRL competition. We created a Discord channel for you to ask any questions to someone working at DeepMind/OpenAI and we will select the most interesting questions to ask in our next podcast and/or interview. So if you are interested in OpenAI or DeepMind, but do not know much about what it\u2019s like to work there or even be hired there, join the conversation and ask your question! What happened this week in\u00a0AI Tons of exciting news this week\u200a\u2014\u200abut the one that stands out is DeepMind\u2019s new blog post where they announced that their AlphaFold 2 model predicted structures for nearly all proteins known to science. Yes, you read that right. DeepMind expanded its protein database by over 200x to over 200 million predicted structures that other scientists will use to better understand specific proteins, what they do and how they work, accelerating scientific research and discovery globally\u200a\u2014\u200aallowing to create further breakthroughs. This is a big deal for the scientific community as \u201cAlphaFold has been accessed by more than half a million researchers and used to accelerate progress on important real-world problems ranging from plastic pollution to antibiotic resistance,\u201d now expanding this knowledge base by 200x with the model\u2019s second\u00a0version. Hottest News DeepMind predicted structures for nearly all cataloged proteins known to science DeepMind predicted structures for nearly all cataloged proteins known to science. It will expand the AlphaFold database by over 200x\u200a\u2014\u200afrom nearly 1 million structures to over 200 million structures. DeepSpeed Compression: A composable library for extreme compression and zero-cost quantization Microsoft Research open-sourced DeepSpeed Compression, a framework for compression and system optimization in deep learning models, learn more\u00a0here. Building AI models on mobile? This may be for you! PyTorch open-sourced the PlayTorch app to streamline the development of mobile AI experiences. Most interesting papers of the\u00a0week Translating a Visual LEGO Manual to a Machine-Executable Plan A novel learning-based framework, the Manual-to-Executable Plan Network (MEPNet), which reconstructs the assembly steps from a sequence of manual images, taking a LEGO manual and creating a machine executable plan that can be executed to build the target shape (see image\u00a0above). Audio-driven Neural Gesture Reenactment with Video Motion Graphs A method that reenacts a high-quality video with gestures matching a target speech audio from a video &#38; audio source, splitting and re-assembling clips from a reference video through a novel video motion graph encoding valid transitions between\u00a0clips. Panoptic Scene Graph Generation They \u201cintroduce panoptic scene graph generation (PSG), a new problem task that requires the model to generate a more comprehensive scene graph representation (see image above) based on panoptic segmentations rather than rigid bounding boxes,\u201d which they say causes several problems that impede the progress of the field. They created a high-quality PSG dataset, containing 49k well annotated overlapping images from COCO and Visual Genome, for the community to keep track of its progress. Check out the\u00a0code Enjoy these papers and news summaries? Get a daily recap in your\u00a0inbox! The Learn AI Together Community section! Meme of the\u00a0week! Once again, a meme shared by one of our fantastic moderators, Ian Yu. Join the conversation and share your memes with\u00a0us! Featured Community post from the\u00a0Discord Another event was organized by a member of the community! Shared by @Zakrz#2739, Cohere AI Hackathon has workshops, keynotes, and mentoring sessions aiming to build with one of the world\u2019s most powerful artificial intelligence language\u00a0models. Join the event happening from August 19 through August\u00a021. AI poll of the\u00a0week! What do you think? Join the discussion on\u00a0Discord. TAI Curated\u00a0section Article of the\u00a0week Data Science Essentials\u200a\u2014\u200aMulticollinearity: This article explains multicollinearity. Multicollinearity may not seem like the most critical topic to grasp, but it is an important widespread concept for machine learning practitioners. The ability of an ML model to find independent variables that are statistically significant for prediction is diminished by high correlations between two or more independent variables. The author provides the most intuitive explanations of types of multicollinearity, causes of multicollinearity, and multicollinearity detection and management. This week we published 24 new articles and welcomed six new writers to our platform. If you are interested in writing for us at Towards AI, please sign up here and we will publish your blog to our network if it meets our editorial policies and standards. https://contribute.towardsai.net/ Lauren\u2019s Ethical Take on DeepMind\u2019s AlphaFold 2 Expansion What an incredible advancement! AlphaFold 2 has cataloged the structure of nearly every known protein. This freshly released dataset is open to anyone, and will soon be completely bulk downloadable through Google Cloud Public Datasets. This is incredibly exciting, and the ethical implications are vast and varied. There is, of course, the proven effects and massive potential of reducing some of the greatest causes of suffering we face today and in the future, such as understanding and treating unique genetic diseases, addressing ecosystem health and biodiversity loss, and improving food supply. While this is a cause for both celebration and optimism, there is also potential for abuse that should be considered and mitigated, such as the creation of targeted biological weaponry using the database. DeepMind will have to decide what that mitigation looks like, but so far, their partnerships and respective advancements demonstrate a trend towards positive outcomes. I want to highlight a passage from the conclusion of DeepMind\u2019s blog post on the\u00a0release: \u201cJust as maths is the perfect description language for physics, we believe AI might [&#8230;]",
            "pubdate": "Tue, 02 Aug 2022 16:28:39 +0000",
            "pubdate_parsed": 1659437919.0,
            "email_sent": true
        },
        "A guide to Predictive Lead Scoring using Machine Learning": {
            "url": "https://towardsai.net/p/l/a-guide-to-predictive-lead-scoring-using-machine-learning",
            "description": "Last Updated on August 7, 2022 by Editorial Team Author(s): Yashashri Shiral Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A Guide To Predictive Lead Scoring Using Machine\u00a0Learning Lead scoring is a valuable tool while implementing a marketing strategy, and in this article, you will understand how you can do it using Machine learning. In the article, I\u2019m covering\u00a0\u2192 What is lead scoring, and why it\u2019s important Types of lead\u00a0scoring Understanding Data Exploratory Data Analysis &#38; Observations One Hot\u00a0Encoding Feature Selection\u200a\u2014\u200aRFE Variance Inflation Factor SMOTE\u200a\u2014\u200aoversampling Model Implementation\u200a\u2014\u200aLogistic Regression, Hyperparameter Tuning Model Evaluation Refer to my GitHub repo here -&#62; https://github.com/YashashriShiral/LeadScoring 1. What is lead scoring, and why it\u2019s important? The purpose of marketing is to reach your target audience and communicate the benefits of your product and get people interested in the products and services. So you can successfully acquire, keep and grow. However, the more leads you generate, the more selective you have to be in your pursuits. Sales representatives don\u2019t want to waste time chasing a large list of leads. Since sales operation has high cost both in time and money, they should focus on nurturing only the most engaged and fitted leads in order to improve and maintain a profitable \u2018Return of Investment.\u2019 To consistently find strong potential customers, sales reps need a lead scoring model. In short, lead scoring is the process of qualifying prospects so salespeople can do their job more efficiently. Focus on lead generation would drive traffic from high-quality prospects(potential clients, someone who is in the market for your product has resources needed to buy it but has not purchased it). And high-quality prospects come with high-value customers that mean more revenue for your business. In other words, the idea is to assign scores to all prospects based on how their characteristics match with the pre-established profile of converted customers. The leads that score above a specific threshold are considered an ideal\u00a0target. Even though the companies recognize the importance of sales and marketing alignment, some still struggle with it. The sales team complains about marketing is spending money on campaigns that are not generating value, and marketing complains that the leads they are delivering aren\u2019t getting converted. So Lead Scoring gives your marketing and sales team a common valuation system they can use to determine which of those leads to follow\u00a0up. Using lead scoring, you can achieve the following: Increase Sales Efficiency Increase Marketing Effectiveness Improve sales and Marketing Alignment Increase Revenue Streamline your time and\u00a0impact 2. Types of Lead\u00a0Scoring: Rules-based lead\u00a0scoring- You take a look at common patterns and attributes among the customers that converted for your business and create a score based on interaction with Sales/Marketing teams. In this, whatever actions that customers are taking you are assigning values to them based on how important those actions are to the business. e.g. 5(points) Page view + 10(points) downloading content + 15(points) Attending webinar + 3(points) click on links\u00a0.As a user completes these actions, you can add up the point values for each of these actions and determine how likely someone is to be a good fit for your product. You can certainly use python and SQL to automate this process. Some companies rely on this method because they like the personal aspect of lead scoring. No one knows your customer better than one who spends time convincing them to become customers (sales) 2. Predictive Lead\u00a0Scoring- Predictive lead scoring is an algorithm-based machine learning approach to lead scoring. In this method, the algorithm learns patterns based on your customer purchases and behavioral data to predict what is the possibility that the customer will make a purchase. Predictive scoring identifies hidden buying signals that would have been impossible to find manually. In this article, we are taking a predictive lead scoring approach. 3. Input\u00a0Data: I\u2019m using a dataset from the UCI Machine learning repository. You can download it from\u00a0here. Dataset information: The data is related to direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact with the same client was required in order to access if the product (bank term deposit) would be (\u2018yes\u2019) or not (\u2018no\u2019) subscribed. So in the dataset, we have customers\u2019 personal information, their contact activity information, previous campaign information, and some social stats, and we also have information about which leads are converted and not converted yet. Our job is to help select the most promising leads. Build a model wherein you need to assign a lead score to each of the leads such that customers with higher scores have higher conversion chances and customers with lower lead scores have lower conversion chances. I\u2019m building a logistic regression model to assign a lead score between 0 and 100 to each of the leads, which can be used by the company to target potential leads. A higher score would mean that the lead is hot, i.e. is most likely to convert, whereas a lower score would mean that the lead is cold and will mostly not get converted. Attribute Information: You have three types of attributes in the\u00a0data: I\u2019m dropping the \u2018duration\u2019 attribute\u200a\u2014\u200abased on attribute information Important note: this attribute highly affects the output target (e.g., if duration=0, then y=\u2019no\u2019). Yet, the duration is not known before a call is performed. Also, after the end of the call, y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model. Customer information: age, job, marital, education, default, housing,\u00a0loan Contact activity information: contact, month, day_of_week Campaign activity information: campaign, pdays, previous, poutcome Social and economic context: emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m, nr.employed 4. Exploratory Data Analysis: Based [&#8230;]",
            "pubdate": "Mon, 08 Aug 2022 03:28:54 +0000",
            "pubdate_parsed": 1659929334.0,
            "email_sent": true
        },
        "The universe of \u201cData Science\u201d roles demystified": {
            "url": "https://towardsai.net/p/l/the-universe-of-data-science-roles-demystified",
            "description": "Last Updated on August 7, 2022 by Editorial Team Author(s): Shahrokh Barati Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. The Universe of \u201cData Science\u201d\u00a0Roles Data Scientist vs. Data Analyst vs. Data Engineer vs. ML Engineer vs. MLOps Engineer vs. [insert your fancy role title\u00a0here]\u2026 Visual overview of core &#38; supporting roles across the data science lifecycle\u200a\u2014\u200aimage by\u00a0author Let me start this blog by clarifying that I do not consider myself a data scientist nor a technical expert, but I have gained a pragmatic perspective on the various roles in this space through my experiences in leading AI &#38; data science projects and building up and managing teams of data scientists and analytics professionals. I believe in the power of visual illustrations, so if you only have 1 minute to spare, let it be on the image above, which is a visual summary of this blog, depicting core and supporting roles across the data science lifecycle. There are many different and sometimes contradicting views on the numerous roles in the data science space and their respective responsibilities. I don\u2019t claim to have THE right answer, but I have tried to highlight the most common roles in simple terms to demystify some of the hype that surrounds the \u201cloaded\u201d\u00a0titles. There is naturally a lot of overlap between these roles, and I will not pretend they are MECE (mutually exclusive and collectively exhaustive), but I\u2019ve tried to underline the key differentiating elements of each role to help with their positioning. Also, I believe as the industry matures, these roles will naturally become more standardized and commonly defined, especially considering some of them didn\u2019t even exist as recently as 3\u20134 years\u00a0ago. Overview of \u201cCore\u201d Data Science\u00a0roles I\u2019m only using the term \u201ccore\u201d to highlight the roles that are most often referred to when talking about data science. \u201cCore\u201d should certainly not be read as \u201cmore important,\u201d as each of these roles has its own place, without which the success of any data science project could be compromised. The common technical skills that span most data science roles are data modeling, machine learning theory &#38; statistics, software development, and data visualization. The main difference is in the extent to which each skill is important for one role versus another, as illustrated here: Common skills across data science roles\u200a\u2014\u200aimage by\u00a0author I\u2019m purposefully keeping the descriptions below fairly brief and succinct to help differentiate between each role more easily; writing an exhaustive list of responsibilities and full job descriptions goes beyond the scope of this\u00a0blog. Data Analyst (Analytics expert) Key focus: Data Analysts, sometimes also referred to as data analytics experts, spend the majority of their time exploring, wrangling, and preparing data, as well as creating reports, dashboards and visualizations with the main aim of providing actionable insights. Key tech stack: Microsoft Excel (for data exploration), Alteryx (or other similar visual data prep tool), Tableau/Power BI/Qlikview (and other similar dashboarding/visualization tools), Basic Python (e.g., Pandas, NumPy, and the\u00a0like) Data Engineer Key focus: Data Engineers are software engineers at their core who have specialized in the development of data (including Big Data) pipelines. They are primarily responsible for sourcing, transforming, and integrating large datasets from various systems and getting them into the required structure/data model for data analysts and data scientists to\u00a0consume. Key tech stack: Advanced Python (e.g., Pandas, NumPy), Advanced SQL, Big Data technologies/languages (e.g., Spark, PySpark, Scala, Hadoop, Hive), ETL platforms (e.g., Informatica, IBM InfoSphere) Data Scientist Key focus: The primary focus of data scientists is typically within the \u201cmodel development &#38; evaluation\u201d stage, where they are responsible for developing machine learning pipelines through an iterative and experimental process of feature engineering, model training, model evaluation, and performance optimization. In practice, however, many data scientists get involved across all stages of the data science lifecycle and are sometimes referred to as full-stack data scientists. Key tech stack: Advanced Python, including ML libraries (e.g., Pandas, NumPy, Tensorflow, Scikit-learn, PyTorch, Matplotlib, etc.), NLP libraries (e.g., NLTK, BERT, spaCy, etc.), working with SQL and NoSQL databases, Data Science Platforms (e.g., Dataiku, Azure ML, Databricks, Domino Data Lab, KNIME, RapidMiner, or simply Jupyter Notebook/JupyterLab) MLOps Engineer Key focus: Machine Learning Operations (MLOps) engineers are effectively DevOps engineers who have specialized in the deployment and CI/CD pipelines of machine learning models. MLOps practices differ from traditional DevOps practices in a number of ways. For example, they typically require production data in the development environment, scalable cloud-based infrastructure often including GPU-powered servers for model training, model version control with a model registry service, model containerization and deployment onto a scalable orchestration infrastructure, and pipelines that enable constant monitoring of outputs in production, mechanisms to feed outputs to automatically re-train and re-deploy models dynamically, etc.) Key tech stack: Docker Containers or similar, Kubernetes Services or similar, GitLab or similar, CI/CD pipelines, Linux/Unix, Fiddler, MLflow,\u00a0etc. ML Engineer Key focus: Machine Learning (ML) Engineer is one of the most contentious roles with often contradicting views about its scope. Some view it as almost synonymous with a data scientist, and others view it as a full-stack developer; however, in practice, they sit somewhere in between. ML Engineers are software engineers by training who also have intimate knowledge of machine learning concepts and pipelines. Their responsibilities span across integrating model outputs into downstream systems, re-factoring ML pipelines into production-ready code (sometimes in lower-level programming languages like Java or C++), developing APIs that wrap models and enable their decoupling as a microservice, developing applications that integrate the model outputs,\u00a0etc. Key tech stack: Advanced programming (Java, C++, Python), advanced microservices and API knowledge (e.g., Java Spring Boot, Flask, FastAPI, etc.), understanding of MLOps-related tech stack (e.g., Docker, Kubernetes, GitLab,\u00a0etc.) Overview of other supporting roles related to data science\u00a0projects Photo by John Schnobrich [&#8230;]",
            "pubdate": "Mon, 08 Aug 2022 00:13:42 +0000",
            "pubdate_parsed": 1659917622.0,
            "email_sent": true
        },
        "This AI newsletter is all you need #7": {
            "url": "https://towardsai.net/p/newsletter/this-ai-newsletter-is-all-you-need-7",
            "description": "Last Updated on August 9, 2022 by Editorial Team Author(s): Towards AI Editorial Team Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. This AI newsletter is all you need &#124; #1 What happened this week in\u00a0AI This week\u2019s newsletter iteration is all about how AI has been used to help society. As you know, there are many, many possible use cases of AI, and more are discovered daily. Fortunately, many of these use cases help take research forward in important fields like medicine or climate science to improve our quality of life. Last week, DeepMind announced that they predicted structures for nearly all cataloged proteins known to science. What does this mean? Researchers can already try new opportunities and use AlphaFold (DeepMind\u2019s model and database) to advance their work on important issues, including sustainability, food insecurity, and neglected diseases. This focus on high impact is becoming more and more common, as a new model called ProtGPT2 is now capable of designing new proteins capable of stable folding. This area of research is no longer only accessible to big and heavily financed organizations! This protein folding progress is mainly thanks to the similarity between proteins and language. As they mention, \u201cNatural languages and proteins are actually similar in structure. Amino acids arrange themselves in a multitude of combinations to form structures that have specific functions in the living organism\u200a\u2014\u200asimilar to the way words form sentences in different combinations that express certain\u00a0facts.\u201d So what\u2019s the moral of this story? Don\u2019t think too much about your research area and keep focusing on NLP models, as it generalizes to other important fields anyway!\u00a0\ud83d\ude09 Don\u2019t forget, if you are interested in the MineRL competition, or OpenAI/DeepMind, but do not know much about what it\u2019s like to work there, join the conversation and ask your question on our discord\u00a0channel! Hottest News DeepMind predicted structures for nearly all cataloged proteins known to scienceDeepMind predicted structures for nearly all cataloged proteins known to science. It will expand the AlphaFold database by over 200x\u200a\u2014\u200afrom nearly 1 million structures to over 200 million structures. Artificial intelligence enables the design of novel proteinsArtificial intelligence (AI) has created new possibilities for designing tailor-made proteins to solve everything from medical to ecological problems. The ProtGPT2 model designs new proteins that are capable of stable folding and could take over defined functions in larger molecular contexts. Louis\u2019 video was featured on PetaPixel and a couple of other news websites thanks to them!Louis, co-founder and Head of the Community at Toward\u2019s AI had his video \u201cImpressive restoration of memories by AI\u00a0!\u201d featured on PetaPixal, the largest news website for photographs. Read more on Toward\u2019s\u00a0AI. Most interesting papers of the\u00a0week A Fast Text-Driven Approach for Generating Artistic ContentYes, another image generative model! As shown in the image above, the image (a) can be stylized according to the user\u2019s requirements with a text prompt, a style image (b) and \u00a9, or a combination of style parameters. High Dynamic Range and Super-Resolution from Raw Image BurstsThis paper introduces the first approach to the reconstruction of high-resolution, high-dynamic range color images from raw photographic bursts captured by a handheld camera (phone) with exposure bracketing. 3D Cartoon Face Generation with Controllable Expressions from a Single GAN ImageFrom 2D human face images to 3D cartoon-styled avatars using a single GAN-generated human face image and without 3D annotations. Enjoy these papers and news summaries? Get a daily recap in your\u00a0inbox! The Learn AI Together Community section! Meme of the\u00a0week! Meme shared by 0wnlife#8511. Join the conversation and share your memes with\u00a0us! Featured Community post from the\u00a0Discord A member of the community, Tomi, has started a YouTube channel where he explains AI-related topics using shorts. If you enjoy quick information-dense videos, check out his channel and support a fellow member of this community giving him a little thumbs up and a subscription! Check out his video explaining ResNets in 60 seconds and let him know what you think of his video. Feedback is hard to have when you start a YouTube channel, blog, or similar adventure and we\u2019d be grateful if a handful of you guys click on his video and give honest feedback.\u00a0\ud83d\ude42 AI poll of the\u00a0week! Join the discussion on\u00a0Discord. TAI Curated\u00a0section Article of the\u00a0week How to Verify the Assumptions of Linear Regression: Linear regression is the most basic approach for getting started with ML, and it is frequently underrated. Every article discusses dealing with Linear Regression and ways for overcoming overfitting rather than preventing overfitting by adhering to a few fundamental Linear Regression assumptions. This article discusses the less-known and underestimated assumptions of Linear Regression, how to check them, and several approaches to adhere to\u00a0them. If you are interested in writing for us at Towards AI, please sign up here and we will publish your blog to our network if it meets our editorial policies and standards. https://contribute.towardsai.net/ Lauren\u2019s Ethical Take on Collaboration as a Tool for Innovation To match this issue\u2019s focus on improving society with AI, I wanted to wander off path a bit to highlight how collaboration provides the foundation for groundbreaking interdisciplinary work. Many of the improvements in society are the result of a collaboration of a complicated problem and a novel solution, for example, unique genetic conditions and targeted pharmaceuticals developed with AI tools. In AI contexts, AI ethics is the precursor to this: Complicated problems posed in AI, such as moral responsibility for a death caused by AI or how personal information should be used and treated, are met with a novel ethical solution to provide great societal\u00a0benefit. This benefit forms the foundation for more collaborations and advancements to happen, and our ability to work together and diversify our ways of thinking and working makes this possible. AI [&#8230;]",
            "pubdate": "Wed, 10 Aug 2022 00:24:32 +0000",
            "pubdate_parsed": 1660091072.0,
            "email_sent": true
        },
        "Using AI to Implement Vector-Based Technology in Topic Modeling": {
            "url": "https://towardsai.net/p/l/using-ai-to-implement-vector-based-technology-in-topic-modeling",
            "description": "Last Updated on August 11, 2022 by Editorial Team Author(s): Kirsten Jiayi Pan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Introduction In this article, we are going to analyze 50 thousand Covid-related tweets that we scraped from Twitter, using AI to extract the main topics argued by people around the\u00a0world. For this amount of unstructured data, we would require weeks to read and classify your data. This Gargantuan task, however, could be a piece of cake if we properly know how to use state-of-the-art NLP\u00a0models. To perform this task, we are going to use models called encoders and a method that allows us to group similar topics together in an automated fashion called topic modeling. Text Encoding Before starting to work on our code directly, we will first explain the logic behind it. The main technique we are going to use to execute this task is called encoding, or vectorization. By using models called embeddings, we are able to convert plain text into geometric coordinates belonging to a high-dimensional space (hundreds of dimensions). This image is retrieved from: https://openai.com/blog/introducing-text-and-code-embeddings/ Each dot in space represents a text. The value of encoders is that it can place text with a similar meaning closer in space. With this unique tool, we can then apply machine learning techniques to group data into common\u00a0trends. What is Topic Modeling, and why is it important? Topic modeling is an algorithm that, when applied to plain text, is able to extract the main topics discussed in the corpus. Once we have vectorized all our tweets and we have 50.000 dots in our high-dimensional cartesian plane, we can group them by using clustering techniques. Each group of dots will share a similar meanings, hence similar topics. We can group 50.000 samples into a few hundred separate groups. By extracting the most frequent keyword from each group, we will then be able to label each individual group with its corresponding topic. This image is retrieved from: https://nkoenig06.github.io/gd-tm-lda.html On Hand! In this project, we have 4 parts to\u00a0cover: Web Scraping: We will first scrape 50 thousand tweets about Covid-19 Vaccination in the span of 6 months as our sample corpus. The Python library we will be using is called snscrape. FYI: https://github.com/JustAnotherArchivist/snscrape https://medium.com/media/f451f2aadd1313c97914cfc692aff7c8/href Output from scraper.py In this sample corpus, we are only saving two pieces of information: the time of the tweet that was published and the text of the\u00a0tweets. 2. Encoding: Now we move on to the highlight of this project! We can also call this part encoding since we are converting text data to numerical data. The Python library that we will be using is called SentenceTransformerwhich can help us implement several pre-trained encoding models. The pre-trained model from SentenceTransformerthat we use is all-MiniLM-L6-v2which will create 768 dimensions for each tweet. This model is robust and fast. To see more details about pre-trained models for SentenceTransformer, please review https://www.sbert.net/docs/pretrained_models.html for more information. Note: Don\u2019t forget to add an additional column to store the text vector for our\u00a0dataset. https://medium.com/media/02ed3e0cf5e8ad543d0d93d101ca7f1e/href Output from encoder.py 3. Clustering: You might be familiar with clustering already. We are going to import KMeansfrom the scikit-learn Python library. Then we can define how many clusters we want for our corpus. As a rule of thumb, over 10,000 samples, we are going to group our data into 200 clusters. https://medium.com/media/f1047ae5a3f37f460684ec19c09069cd/href Output from clustering.py 4. Visualization: Once we have finished clustering our data. We want to visualize the outcome and see how our clustering model groups the tweets into different topics. However, we must reduce the dimension before visualization from 768 dimensions to 2 dimensions so we can understand our visualization of clustering as human beings. The dimensionality reduction algorithm we use for dimension reduction is\u00a0umap. FYI: https://umap-learn.readthedocs.io/en/latest/ Here is how we visualize our clustering by generating a 2-dimensional colorful graph by using matplotlib.plotly. FYI: https://www.activestate.com/blog/plotting-data-in-python-matplotlib-vs-plotly/ https://medium.com/media/3f5b30515e2f5463eaa1b85add9cbf8b/href Output from visualization.py As you can see in our beautiful graph draw, our 50 thousand tweets are grouped in 200 clusters with 200 colors on a 2-dimensional plane. The graph will represent the tweets that are grouped under the same topic using the same\u00a0color. Conclusion Since we have clustered the corpus by scanning the similarity, frequency of words, and patterns within the text, we can easily understand what are the most popular trends when people discussing about Covid-19 Vaccination. The insights that can be extracted using this algorithm will prove valuable to the Public Health Industry and Governments that need to monitor data constantly. Using AI to Implement Vector-Based Technology in Topic Modeling was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 11 Aug 2022 12:23:09 +0000",
            "pubdate_parsed": 1660220589.0,
            "email_sent": true
        },
        "Why Accuracy Is Not A Good Metric For Imbalanced Data": {
            "url": "https://towardsai.net/p/l/why-accuracy-is-not-a-good-metric-for-imbalanced-data",
            "description": "Last Updated on August 11, 2022 by Editorial Team Author(s): Rafay Qayyum Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Classification, In Machine Learning, is a supervised learning concept where data points are classified into different classes. For example, determining if an email is \u201cspam\u201d or \u201cnot spam\u201d and determining the blood type of a\u00a0patient. Machine Learning Classification is generally divided into three categories: Binary Classification Multi-class Classification Multi-label Classification What are Imbalanced classes or\u00a0data? Imbalanced data refers to a problem where the distribution of examples across the known classes is biased (One class has more instances than the other). For example, One class may have 10000 instances while the other class has just 100 instances. Class with majority instances is weighed more than the class with minority instances\u200a\u2014\u200aGoogle Data Imbalance can range from small to huge differences in the number of instances of the classes. Small data imbalances such as 4:1, 10:1, etc., won\u2019t harm your model much, but as the data imbalance starts to increase to 1000:1 and 5000: it can create problems for your machine learning\u00a0model. The class (or classes) in an imbalanced classification problem that has many instances is known as the Majority Class(es). The class (or classes) in an imbalanced classification problem that has few instances is known as the Minority Class(es). Why Imbalanced Classes can cause problems? When working with imbalanced data, The minority class is our interest most of the time. Like when detecting \u201cspam\u201d emails, they number quite a few compared to \u201cnot spam\u201d emails. So, the machine learning algorithms favor the larger class and sometimes even ignore the smaller class if the data is highly imbalanced. Machine learning algorithms are designed to learn from the training data to minimize the loss and maximize accuracy. Let\u2019s see how a machine learning algorithm works with highly imbalanced data. An Example Consider this example where there are 100 instances of Class \u201cA\u201d and 9900 instances of Class\u00a0\u201cB\u201d. x, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0) The count plot of the dataset can be created with the seaborn\u00a0library np.unique(y,return_counts=True)y=np.where(y==0,&#039;A&#039;,&#039;B&#039;)sns.countplot(x=y) count plot of the\u00a0dataset. xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.20, random_state=42)print(np.unique(ytrain,return_counts=True))print(np.unique(ytest,return_counts=True)) After splitting the dataset into training and test data using train_test_split with a test size of 20%, we are left with 7919 training examples for Class \u201cA\u201d and 81 training examples for Class \u201cB\u201d. Testing examples are 1981 for Class \u201cA\u201d and 19 for Class\u00a0\u201cB\u201d. Let\u2019s first train a Logistic Regression model with our training\u00a0data. lr=LogisticRegression()lr.fit(xtrain,ytrain)lr.score(xtest,ytest) Now, if we check the accuracy of the model using the scoring method, it is 0.992. 99.2% Accuracy? It\u2019s performing great, right? Let\u2019s check the confusion matrix. pred_lr=lr.predict(xtest)print(confusion_matrix(ytest,pred_lr)) Confusion matrix for Logistic Regression Although Class \u201cA\u201d has an accuracy of 100%, only 3 out of 19 test examples were classified correctly. It must be a mistake,\u00a0right? Let\u2019s use Random Forest Classifier on the same dataset and check what\u2019s happening. rfc=RandomForestClassifier()rfc.fit(xtrain,ytrain)rfc.score(xtest,ytest) The accuracy score is 0.991 this time, but what did we learn last time? The real results hide behind the accuracy. Let\u2019s check the confusion matrix for Random Forest Classifier\u2019s Predictions. pred_rfc=rfc.predict(xtest)print(confusion_matrix(ytest,pred_rfc)) Confusion matrix for Random Forest Classifier Only 1 out of 1981 testing examples for Class \u201cA\u201d was classified wrong, but only 2 out of 19 testing examples for Class \u201cB\u201d were classified correctly. What are our machine learning models doing\u00a0here? As we have discussed before, machine learning models try to maximize accuracy, that\u2019s what is happening here. Since the instances of Class \u201cA\u201d make up 99% of the data, machine learning models learn to classify them correctly and ignore or do not learn much about Class \u201cB\u201d because classifying all of the data to class \u201cA\u201d will get it 99% accuracy. You can match the accuracy of these models just by writing 1 statement in python.\u00a0Shocked? pred=[&#039;A&#039;]*len(ytest) This statement creates a list of length 2000 (since total testing data is 2000 or 20% for 10000) and fills it with \u201cA\u201d. Since 99% of the sample is just A class, so we get the accuracy of 99% using the accuracy\u00a0score. accuracy_score(ytest,pred) Confusion matrix for the \u201cpred\u201d\u00a0list How can you handle an imbalanced dataset? There are many ways through which you can handle an imbalanced dataset. Some require you to have field knowledge others use different algorithms to increase the instances of minority class (Over-sampling) and to decrease the instances of majority class (Under-sampling). Through field knowledge, you can either split a majority class into more than one class, or you can merge different minority classes to make one class with more instances. Imbalanced-learn is a python library that has different methods for under-sampling and over-sampling. Another way is to set weights for different classes when creating a machine learning model object. Check how class_weights work on StackOverflow. Some over-sampling methods in Imbalanced-learn are SMOTE, RandomOverSampler, BorderlineSMOTE, KMeansSMOTE, and\u00a0ADASYN. Some under-sampling methods in Imbalanced-learn are ClusterCentroids, CondensedNearestNeighbour, EditedNearestNeighbours, NearMiss, OneSidedSelection, RandomUnderSampler, TomekLinks, and NeighbourhoodCleaningRule Why Accuracy Is Not A Good Metric For Imbalanced Data was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 11 Aug 2022 05:13:32 +0000",
            "pubdate_parsed": 1660194812.0,
            "email_sent": true
        },
        "Biggest Problem With ML Systems Today": {
            "url": "https://towardsai.net/p/l/biggest-problem-with-ml-systems-today",
            "description": "Last Updated on August 11, 2022 by Editorial Team Author(s): Astha Puri Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Photo by Rain Bennett on\u00a0Unsplash So you built a machine learning model and deployed it in production. Most of the models built today do not make it to production. So in this scenario, we are the rare few whose ML system is actually out there in the world.\u00a0Hurray! Only to see that it is worsening in performance with time. Why!! Why is its performance degrading? We looked for everything. It performed great on all the model evaluation metrics there are. And still. Why? The Boss is annoyed, customers are complaining, and business is heading to\u00a0doom\u2026.. Welcome to the concept of\u00a0drift. Photo by Khamk\u00e9o Vilaysing on\u00a0Unsplash Drift happens when there are changes to the operational environment of your ML system. This was the kind of environment it was trained in. With time, if this changes inherently, your ML model no longer predicts correctly. Hence, the progression toward poorer and poorer performance. How many times have you heard this at your company\u200a\u2014\u200a\u2018yes, there was a data scientist before you who wanted to work on models and built this amazing model, which everyone was sold for. Then they left the company for more $$$. Their model no longer works, and well, now everyone is skeptical about using data science/ML altogether\u2019. If the model was never performing well, it could be a gazillion things that could be causing that. But if it was performing well at a point in time, and you notice the degradation over time, drift is something you might want to look at seriously. There are 2 types of drift that commonly\u00a0occur: Concept drift Data drift (also called covariate shift or feature\u00a0drift) 1. Concept\u00a0Drift This happens when something in the base environment changes in which the model was\u00a0built. Consider digital and online scams, for example. Fraudsters are constantly adapting to changing security and protection protocols online. The definition of what is considered spam has evolved over time. This is like a fundamental change in the environment. To fix a drift like this, we need to change the model design itself. We\u00a0can: add new\u00a0features change ML\u00a0model or do both of the\u00a0above 2. Data\u00a0Drift This affects the feature extraction part of ML modeling. It can usually be fixed by retraining the model on new\u00a0data. Anything that degrades the data quality could lead to a data drift, for example, badly calibrated sensors. Or, for example, an NLP model trained on millennial language but then not being able to predict because, with time, gen Z have grown up and entered the world where they are also generating a lot of gen Z lingo\u00a0data. It is a very real world problem and drift will happen. There is nothing you can do about it to prevent it like other problems in ML such as overfitting, data leaks\u00a0etc. Good news\u200a\u2014\u200awe can win the battle against\u00a0drift Photo by GR Stocks on\u00a0Unsplash Like blood is a very good sign that you\u2019ve been physically hurt, your model performing badly and accuracy going down is a very good indicator that drift has happened in some form. Is it a very good indicator? Yes. Is it the best timing?\u00a0No. You want to identify drift before things have blown up and customers are complaining or worse\u200a\u2014\u200achurning. An additional drawback with waiting till you see drift in model accuracy is that, even after identifying drift, we don\u2019t know which type of drift it is. So the problem here has a higher operational impact, and problem-solving takes\u00a0longer. A better approach might be to \u2018monitor\u2019 the model and identify early signs. This can be done by monitoring the intermediate stages of the model\u2019s outputs. This can be done\u00a0at: Feature extraction stage\u200a\u2014\u200aby comparing baseline distribution of features to current distributions. If the gap is large, there might be a potential drift. This analysis can be done using statistical tests for the Kolmogorov-Smirnov test (K-S\u00a0testing) Modeling stage\u200a\u2014\u200awe can compare basic patterns that appear in various layers of the model. An auxiliary model can be trained to compare these under normalcy vs outliers from training\u00a0data. Checking confidence\u200a\u2014\u200akeeping a tab on the confidence of the model in its results can be a good indicator. If the confidence starts going down, it could be a potential flag for\u00a0drift. Summary Drift is inevitable. Even though it is something we cannot prevent during our modeling, there are still ways to detect it and fix it. The key lies in early detection so that it can be solved before it affects business operations, customer experience, reviews, and\u00a0revenue. Biggest Problem With ML Systems Today was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 11 Aug 2022 05:13:30 +0000",
            "pubdate_parsed": 1660194810.0,
            "email_sent": true
        },
        "Is This the Way AI Gains Human Sight?": {
            "url": "https://towardsai.net/p/l/is-this-the-way-ai-gains-human-sight",
            "description": "Last Updated on August 11, 2022 by Editorial Team Author(s): Daniel Moriarty Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Blink and you&#x2019;ll miss it Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 11 Aug 2022 05:13:27 +0000",
            "pubdate_parsed": 1660194807.0,
            "email_sent": true
        },
        "Survival Analysis: Produce a Single Time-to-Event Prediction from Survival Functions": {
            "url": "https://towardsai.net/p/l/survival-analysis-produce-a-single-time-to-event-prediction-from-survival-functions",
            "description": "Last Updated on August 11, 2022 by Editorial Team Author(s): Yael Vilk Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Photo by Meritt Thomas on\u00a0Unsplash Survival analysis is a family of statistical methods for analyzing time-to-event data. Traditionally, this technique was used in the health and insurance domains, where the event of interest would be death, re-hospitalization, and similarly morbid events. However, survival analysis can be applied to model any time period, like the time it takes for a person to get a job, a system to fail, or a customer to\u00a0churn. Survival analysis is unique in its ability to handle censored data, that is, data where the time-to-event information is not fully disclosed for some of the subjects. This can happen for different reasons. For example, it is possible a subject dropped out of the study before its termination or that the trial ended before the event of interest occurred for some of the subjects. Applying different survival analysis techniques results in a single or multiple survival function. A survival function describes the probability of a subject, or a group, to survive past time T. In this context, \u2018survival\u2019 means avoiding the event of interest. The overall survival time, or lifespan, is the period of time between the \u2018birth\u2019 &#8211; trial onset, and \u2018death\u2019 &#8211; when the event of interest occurs. Naturally, the function is monotonically non-increasing, as survival only becomes less likely with\u00a0time. Here\u2019s a survival function, for\u00a0example: import pandas as pdpd.DataFrame({&#039;t&#039;: [1, 2, 5, 7, 9, 10, 12, 13], &#039;S(t)&#039;: [98, 95, 90, 80, 60, 50, 40, 0]}).set_index(&#039;t&#039;) According to this survival function, there is a 90% chance that the event of interest will not occur by time\u00a05. Survival functions are also useful for comparing survival times of several groups and for describing the effect of additional variables on survival time. It is a powerful function that holds a lot of information, but sometimes, you want to summarize it into a single time-to-event prediction. In this post, I will discuss the multiple ways to predict a lifespan from a survival function. If you wish to learn more about survival analysis in general or how to actually obtain a survival function(s) from your data, try the documentation of the python library \u2018lifelines\u2019, or this great blog\u00a0post. Let\u2019s get some survival functions. We\u2019ll start by creating a toy dataset in python. In this dataset, we have 5 subjects in a study that lasted over 20 days. The \u201cobserved\u201d column states whether the subjects have indeed experienced the recurrence of the symptoms during the study, and the \u201cduration\u201d column denotes the day on which the symptoms reappeared. As you can see, our data is not censored: the time of symptom recurrence was recorded for the entire sample. We have also documented a predictor variable. df = pd.DataFrame({\"predictor\": [5, 3.5, 20, 9, 15], \"observed\": [True, True, True, True, True], \"duration\": [0, 12, 13, 3, 20]}) We will use the lifelines library to fit the Cox Proportional-Hazards model to our data. This model is used to describe the effect of one or several covariates on survival. from lifelines import CoxPHFittercph = CoxPHFitter()cph.fit(df, \"duration\", \"observed\") &#60;lifelines.CoxPHFitter: fitted with 5 total observations, 0 right-censored observations&#62; Finally, we use the model to predict survival functions for a new sample of 2 subjects: X = pd.DataFrame({\"predictor\": [4, 18]}, index=[&#039;subject1&#039;, &#039;subject2&#039;])X survival_functions = cph.predict_survival_function(X)survival_functions We now have a survival function for each subject. But these subjects are interested in the bottom line: how long before their symptoms\u00a0return? Calculating the expected value of lifespan as the area under the survival\u00a0curve The most common measure of central tendency for a continuous random variable is the expected value. The expected value of a random variable is the mean of its possible outcomes, weighted by their probability. Survival time is a continuous variable (although our petite example can be considered discrete), so we would need to integrate the function over the given range. This means that the expected value of the subject\u2019s lifespan is the area under the survival\u00a0curve. Lifelines\u2019 regression fitter objects have a method for calculating the expected value of the subject\u2019s lifespan: predict_expectation(). It uses the trapezoidal rule to calculate the area under the\u00a0curve. cph.predict_expectation(X) subject1 4.648343subject2 13.456205dtype:\u00a0float64 The documentation warns that \u201cIf the survival function doesn\u2019t converge to 0, then the expectation is really infinity and the returned values are meaningless/too large\u201d. Why is that? Let\u2019s look at the survival function of subject no. 2, for example. Our predicted survival functions denote a probability for each of the durations the model trained on. For the latest time period, 20 days, subject 2 has a relatively high survival probability of\u00a00.25. import matplotlib.pyplot as pltsurvival_functions[&#039;subject2&#039;].plot()xlabel = plt.xlabel(\"time\")ylabel = plt.ylabel(\"probability\")ylim = plt.ylim([0, 1]) the area under this curve is\u00a013.456 Calculating the area under the survival curve actually creates a downward bias as it is probable that the curve goes on after the 20th day. However, we don\u2019t have enough information to determine how this function behaves for values larger than 20. There could be a substantial probability of a longer symptom-free period: the area under this curve is around\u00a014.7 But it\u2019s also possible that chances to \u2018survive\u2019 drop to zero straight after the 20th\u00a0day. The area under this curve is around\u00a013.58 Predicting the median\u00a0lifetime We\u2019ve established that using the expected value for the time of symptoms recurrence, while mathematically beautiful, can be problematic. Instead, we can use the time at which the probability hits the 50% threshold as our prediction. Upon hitting this threshold, the probability that the event has not occurred becomes lower than the probability that it has occurred for every following time point. Using the median, or other percentiles, is simple and direct and is not affected by extreme values. Lifelines [&#8230;]",
            "pubdate": "Thu, 11 Aug 2022 04:58:26 +0000",
            "pubdate_parsed": 1660193906.0,
            "email_sent": true
        },
        "The Top 3 Conferences For Data Science and Analytics": {
            "url": "https://towardsai.net/p/l/the-top-3-conferences-for-data-science-and-analytics",
            "description": "Last Updated on August 14, 2022 by Editorial Team Author(s): Rijul Singh Malik Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A blog post talking about which are the top data science and analytics conferences in the industry. Photo by Kane Reinholdtsen on\u00a0Unsplash Data is the new oil. This is a popular phrase being thrown around in the analytics industry these days. Data has become the new currency. Businesses are waking up to the value of data, and analytics is one of the top career choices in the industry. This blog talks about 3 of the top conferences in the\u00a0field. How to find the right conference If you\u2019re anything like me, you love to geek out on all things data science and analytics. I also love to hear new ideas and concepts and get inspired. I\u2019m also a firm believer in the power of networking, so I\u2019m always on the hunt for a great conference to attend. In this blog, I\u2019ll showcase my top three data science and analytics conferences. 1. Strata + Hadoop World I\u2019m a big fan of Strata Conferences. They offer a variety of analytics, data science, and big data conferences. Strata is a pioneer in the industry and is one of my favorites. I love to go to their events and learn new ways to solve problems. The conferences offer a unique opportunity to connect with data experts and learn from the best in the industry. Conferences can be a great way to advance your career. It\u2019s a chance to meet colleagues from all over the world and to learn from the experts. If you\u2019re new to the industry, it\u2019s a great chance to get a quick introduction to what\u2019s happening in the field. Even if you have been in the industry for a long time, a conference is a great way for you to learn about the latest developments in data science and analytics. There are a lot of conferences that focus on data science and analytics. In fact, there are so many that it can be hard to know which ones are really worth your time. Here are the three best conferences for data science and analytics: The three best data conferences Data science and analytics have become two of the hottest buzzwords in the past decade. And with the right skills, data science and analytics professionals can be some of the highest-paid professionals in the country. There are a lot of conferences that feature big data and analytics, and a lot of them are really important. But, there are a few that are just a cut above the rest. The three best conferences for data science and analytics are 1. ODSC East 2. Strata 3. KDD The best of these conferences have a lot of similarities and a lot of differences, but they all have a lot to offer. And, it\u2019s not always about data science and analytics. Sometimes, it\u2019s about the people. Sometimes, it\u2019s about the experience. And sometimes, it\u2019s about the location. Everybody in the industry knows that the best way to learn the latest and greatest in data science is to go to a conference. Conferences are the place to network and exchange ideas and learn about the newest trends and tools. Here are the top three conferences for data science and analytics, as voted by the data science community. If you have the opportunity to attend one of these, you should definitely take it. They are the best of the\u00a0best. Tips for attending a data conference Data science and analytics conferences are the best way to keep up with the latest trends and connect with your data peers. Data analysts and scientists are in high demand, but it can be hard to find an event that exactly fits your needs. Conference season is in full swing, so we\u2019ve compiled a list of the best conferences for data science and analytics. If you\u2019re just getting started with data science, we recommend checking out Strata + Hadoop World, where you can learn about the latest tools and technologies. If you\u2019re a seasoned data scientist, you might want to try out KDD or the Visual Analytics Summit, both of which focus on data science. If you\u2019re looking for something a little more niche, check out the Data Science Unconference or the Analytics Innovation Summit, two less-conventional analytics events. There are a lot of data analytics conferences. So many, in fact that it can be a little overwhelming to know where to start. You want to take advantage of the knowledge and experience that conference presenters have to offer, but you also want to make sure that you\u2019re getting your money\u2019s worth. You might have heard that it\u2019s possible to attend a conference without doing any networking, but we\u2019re here to tell you that this is a horrible idea. A data analytics conference is a great opportunity to network and discuss your current projects with people from all different industries. Photo by Alexas_Fotos on\u00a0Unsplash Conclusion: These conferences are the Defacto standard in the Data Science world, but there are so many other great Data science conferences. The Top 3 Conferences For Data Science and Analytics was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 15 Aug 2022 00:13:11 +0000",
            "pubdate_parsed": 1660522391.0,
            "email_sent": true
        },
        "Deep Learning: Forecasting of Confirmed Covid-19 Positive Cases Using LSTM": {
            "url": "https://towardsai.net/p/l/deep-learning-forecasting-of-confirmed-covid-19-positive-cases-using-lstm",
            "description": "Last Updated on August 15, 2022 by Editorial Team Author(s): Dede Kurniawan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Describing each step in the deep learning method for forecasting positive cases of Covid-19 in Indonesia Photo by Markus Spiske from\u00a0Pexels Introduction Almost all parts of the world have been shocked by the Covid-19 outbreak that has infected many people; even millions of people have died in this outbreak. The first case of Covid-19 was detected in Wuhan City, Hubei Province, China, in December 2019. On January 30, 2020, it was declared a health emergency for the whole world by the World Health Organization (WHO). Covid-19 spreads quickly because it can be transmitted directly through the air within a radius of 2 meters and in direct contact or when an infected person sneezes or coughs\u00a0[3]. The Covid-19 pandemic has significantly impacted people\u2019s lives in various fields such as economy, health, education, etc. Some examples of policies implemented by the Indonesian government are wearing masks when in public places, social restrictions on a microscale, Social distancing (2 meters), online learning, working from home, closing various places that invite crowds, etc. [2]. However, not all policies implemented by the Indonesian government effectively prevent the transmission of Covid-19. Having a reliable early warning method is very important to estimate how much this disease will affect the community, on this basis, it is hoped that the government can implement the right policies in dealing with the Covid-19 pandemic. How do we find a suitable early warning method in dealing with Covid-19? With machine learning or deep learning, we can estimate/predict/forecast the number of cases infected with the Covid-19 virus. After we know how big the estimated cases of being infected with the Covid-19 virus are, we can make a policy to deal with this pandemic by considering the\u00a0data. You can access the Google Colaboratory that we use\u00a0here Task We will analyze Covid-19 data in Indonesia and create a deep learning model to forecast the number of cases infected with Covid-19. Our processes include data cleaning and pre-processing, exploratory data analysis, modeling, and drawing conclusions. We use the dataset on the https://tiny.cc/Datacovidjakarta Import library Since we are using the python programming language, there are several libraries that we will use in this article. The first thing we have to do is import all the required libraries. https://medium.com/media/a7eb38cc25652e447d3abb6807a5e131/href We imported Numpy to perform computation. Pandas for data manipulation purposes. Matplotlib, Seaborn, and Plotly for data visualization. Scikit-learn for algorithms that are useful in data preprocessing, machine learning, etc. TensorFlow is used to build neural networks. Data cleaning and pre-processing Before preparing or cleaning the data, we must load the dataset into a data frame using pandas. To do so, we can use the pd.read_excel() function. https://medium.com/media/6017e539ca73a1d0c6e2b8049ceb558a/href We also display the first five rows of our dataset using\u00a0.head(). Just in case our data set gets corrupted during data cleaning, we use\u00a0.copy() method to duplicate our\u00a0dataset. df = data.copy() Well, here maybe there are some column names that cannot be understood because they use Bahasa, so we will rename the column names using English. Also, here we will only focus on analyzing the columns [&#039;Positif (Indonesia)&#039;, &#039;Sembuh (Indonesia)&#039;, Meninggal (Indonesia)&#039;]. Therefore, we will drop columns that are not\u00a0used. https://medium.com/media/8a518a844428ab318b0c9ea80a3db5e2/href To see information from the dataset, we can use df.info(). The dataset we use has 893 rows and 4 columns. In the date column, there is a datetime64 data type, and the other column has a float64 data type. However, the problem lies in the date column, which has more rows than the other 3 columns therefore we can assume that in 3 columns other than the date column, there are missing\u00a0values. https://medium.com/media/e4057996e8560cf81756ee10e54d5a42/href In the code df.dropna(inplace=True), we drop the column with missing values. Then, in the code df.drop(index=0, inplace=True), we drop the first line because it has an inconsistent time difference compared to the lines below. Next, we reset the index on our dataset df.reset_index(drop=True, inplace=True). The next thing we are going to do is check if there are any duplications and missing values in the data, if there are, we should drop\u00a0them. If it turns out that there is no duplication in our data, then our data cleaning process will end here. Next, we will go to the exploratory data analysis process, but before that, we will look at our data frame info once again to make sure our data cleaning process is completely complete. Finally, we should present an overview of our dataset once\u00a0again. Exploratory data\u00a0analysis At this stage, we will explore our dataset and try to understand more about it. We want to know a summary of the descriptive statistics of the dataset, to do that, we can use\u00a0.describe() and\u00a0.transpose() to convert rows into\u00a0columns. df.describe().transpose() Next, we want to know the comparison of the total number of positive confirmed cases, the number of death cases, and the number of recovered cases. To do this, we can visualize the data so that it is easier to understand. https://medium.com/media/69ee40d0214d665202af6f18be385688/href Image by the\u00a0author. According to the pie graph above, we can take insight that the comparison of recovered cases and positive cases are almost equal. This shows a high recovery rate due to being infected with the Covid-19 virus, but the spread rate is also high. Then, it can be seen that death cases have a small area when compared to cases of recovery and death, this shows a high survival rate due to the Covid-19\u00a0virus. Then, we also want to see the history of Covid-19 cases from some time ago using a line\u00a0chart. https://medium.com/media/0c169c6058ce200e33e307f1bde38bba/href Image by the\u00a0author. According to the line chart above, We can see that positive cases are occasionally rising quickly, but the recovery rate from Covid-19 is also [&#8230;]",
            "pubdate": "Mon, 15 Aug 2022 07:53:06 +0000",
            "pubdate_parsed": 1660549986.0,
            "email_sent": true
        },
        "Introduction To Pooling Layers In CNN": {
            "url": "https://towardsai.net/p/l/introduction-to-pooling-layers-in-cnn",
            "description": "Last Updated on August 16, 2022 by Editorial Team Author(s): Rafay Qayyum Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A Convolutional neural network(CNN) is a special type of Artificial Neural Network that is usually used for image recognition and processing due to its ability to recognize patterns in images. It eliminates the need to extract features from visual data manually. It learns images by sliding a filter of some size on them and learning not just the features from the data but also keeps Translation invariance. The typical structure of a CNN consists of three basic\u00a0layers Convolutional layer: These layers generate a feature map by sliding a filter over the input image and recognizing patterns in\u00a0images. Pooling layers: These layers downsample the feature map to introduce Translation invariance, which reduces the overfitting of the CNN\u00a0model. Fully Connected Dense Layer: This layer contains the same number of units as the number of classes and the output activation function such as \u201csoftmax\u201d or \u201csigmoid\u201d What are Pooling\u00a0layers? Pooling layers are one of the building blocks of Convolutional Neural Networks. Where Convolutional layers extract features from images, Pooling layers consolidate the features learned by CNNs. Its purpose is to gradually shrink the representation\u2019s spatial dimension to minimize the number of parameters and computations in the\u00a0network. Why are Pooling layers\u00a0needed? The feature map produced by the filters of Convolutional layers is location-dependent. For example, If an object in an image has shifted a bit it might not be recognizable by the Convolutional layer. So, it means that the feature map records the precise positions of features in the input. What pooling layers provide is \u201cTranslational Invariance\u201d which makes the CNN invariant to translations, i.e., even if the input of the CNN is translated, the CNN will still be able to recognize the features in the\u00a0input. In all cases, pooling helps to make the representation become approximately invariant to small translations of the input. Invariance to translation means that if we translate the input by a small amount, the values of most of the pooled outputs do not change\u200a\u2014\u200aPage 342, Deep Learning by Ian Goodfellow, 2016. How do Pooling layers achieve that? A Pooling layer is added after the Convolutional layer(s), as seen in the structure of a CNN above. It downsamples the output of the Convolutional layers by sliding the filter of some size with some stride size and calculating the maximum or average of the\u00a0input. There are two types of poolings that are\u00a0used: Max pooling: This works by selecting the maximum value from every pool. Max Pooling retains the most prominent features of the feature map, and the returned image is sharper than the original\u00a0image. Average pooling: This pooling layer works by getting the average of the pool. Average pooling retains the average values of features of the feature map. It smoothes the image while keeping the essence of the feature in an\u00a0image. Image source Let\u2019s explore the working of Pooling Layers using TensorFlow. Create a NumPy array and reshape\u00a0it. matrix=np.array([[3.,2.,0.,0.], [0.,7.,1.,3.], [5.,2.,3.,0.], [0.,9.,2.,3.]]).reshape(1,4,4,1) Max Pooling Create a MaxPool2D layer with pool_size=2 and strides=2. Apply the MaxPool2D layer to the matrix, and you will get the MaxPooled output in the tensor form. By applying it to the matrix, the Max pooling layer will go through the matrix by computing the max of each 2&#215;2 pool with a jump of 2. Print the shape of the tensor. Use tf.squeeze to remove dimensions of size 1 from the shape of a\u00a0tensor. max_pooling=tf.keras.layers.MaxPool2D(pool_size=2,strides=2)max_pooled_matrix=max_pooling(matrix)print(max_pooled_matrix.shape)print(tf.squeeze(max_pooled_matrix)) Average Pooling Create an AveragePooling2D layer with the same 2 pool_size and strides. Apply the AveragePooling2D layer to the matrix. By applying it to the matrix, the average pooling layer will go through the matrix by computing the average of 2&#215;2 for each pool with a jump of 2. Print the shape of the matrix and Use tf.squeeze to convert the output into a readable form by removing all 1 size dimensions. average_pooling=tf.keras.layers.AveragePooling2D(pool_size=2, strides=2)average_pooled_matrix=average_pooling(matrix)print(averge_pooled_matrix.shape)print(tf.squeeze(average_pooled_matrix)) The GIF here explains how these pooling layers go through the input matrix and computes the maximum or average for max pooling and average pooling, respectively. Max Pooling and Average Pooling being performed\u200a\u2014\u200aSource Global Pooling\u00a0Layers Global Pooling Layers often replace the classifier\u2019s fully connected or Flatten layer. The model instead ends with a convolutional layer that produces as many feature maps as there are target classes and performs global average pooling on each of the feature maps to combine each feature map into a single\u00a0value. Create the same NumPy array but with a different shape. By keeping the same shape as above, the Global Pooling layers will reduce them to one\u00a0value. matrix=np.array([[[3.,2.,0.,0.], [0.,7.,1.,3.]], [[5.,2.,3.,0.], [0.,9.,2.,3.]]]).reshape(1,2,2,4) Global Average\u00a0Pooling Considering a tensor of shape h*w*n, the output of the Global Average Pooling layer is a single value across h*w that summarizes the presence of the feature. Instead of downsizing the patches of the input feature map, the Global Average Pooling layer downsizes the whole h*w into 1 value by taking the\u00a0average. global_average_pooling=tf.keras.layers.GlobalAveragePooling2D()global_average_pooled_matrix=global_average_pooling(matrix)print(global_average_pooled_matrix) The output of the GlobalAveragePooled layer Global Max\u00a0Pooling With the tensor of shape h*w*n, the output of the Global Max Pooling layer is a single value across h*w that summarizes the presence of a feature. Instead of downsizing the patches of the input feature map, the Global Max Pooling layer downsizes the whole h*w into 1 value by taking the\u00a0maximum. global_max_pooling=tf.keras.layers.GlobalMaxPool2D()global_max_pooled_matrix=global_max_pooling(matrix)print(global_max_pooled_matrix) The output of the GlobalMaxPooled layer Conclusion In general, pooling layers are useful when you want to detect an object in an image regardless of its position in the image. The consequence of adding pooling layers is the reduction of overfitting, increased efficiency, and faster training times in a CNN model. While the max pooling layer draws out the most prominent features of an image, average pooling smoothes the image retaining [&#8230;]",
            "pubdate": "Tue, 16 Aug 2022 04:23:49 +0000",
            "pubdate_parsed": 1660623829.0,
            "email_sent": true
        },
        "Pull and Push\u200a\u2014\u200aHow Machines Deliver Text Data To Human": {
            "url": "https://towardsai.net/p/l/pull-and-push%e2%80%8a-%e2%80%8ahow-machines-deliver-text-data-to-human",
            "description": "Last Updated on August 21, 2022 by Editorial Team Author(s): Andrew D #datascience Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Pull and Push\u200a\u2014\u200aHow Machines Deliver Text Data To\u00a0Humans Learn how pull and push strategies define how relevant information is delivered to the end\u00a0user body[data-twttr-rendered=&#8221;true&#8221;] {background-color: transparent;}.twitter-tweet {margin: auto !important;} &#x200a;&#8212;&#x200a;@theDrewDag function notifyResize(height) {height = height ? height : document.documentElement.offsetHeight; var resized = false; if (window.donkey &#38;&#38; donkey.resize) {donkey.resize(height);resized = true;}if (parent &#38;&#38; parent._resizeIframe) {var obj = {iframe: window.frameElement, height: height}; parent._resizeIframe(obj); resized = true;}if (window.location &#38;&#38; window.location.hash === &#8220;#amp=1&#8221; &#38;&#38; window.parent &#38;&#38; window.parent.postMessage) {window.parent.postMessage({sentinel: &#8220;amp&#8221;, type: &#8220;embed-size&#8221;, height: height}, &#8220;*&#8221;);}if (window.webkit &#38;&#38; window.webkit.messageHandlers &#38;&#38; window.webkit.messageHandlers.resize) {window.webkit.messageHandlers.resize.postMessage(height); resized = true;}return resized;}twttr.events.bind(&#8216;rendered&#8217;, function (event) {notifyResize();}); twttr.events.bind(&#8216;resize&#8217;, function (event) {notifyResize();});if (parent &#38;&#38; parent._resizeIframe) {var maxWidth = parseInt(window.frameElement.getAttribute(&#8220;width&#8221;)); if ( 500 &#60; maxWidth) {window.frameElement.setAttribute(\"width\", \"500\");}} Information Retrieval (IR) is the process of gaining knowledge from a source of data from the environment. This environment can be explored in several ways to obtain such information, depending on its state and the state of the\u00a0user. The main goal of IR is to minimize the reduction of noise delivery and maximize the delivery of signal delivery. Think about Google\u200a\u2014\u200ait is safe to say that it is the main source of information retrieval in the world. Now think about Amazon\u200a\u2014\u200awe all know how powerful its recommendation systems are. But how do Google and Amazon work, and what strategies do they use to deliver relevant content to the end user? We won\u2019t look at how search engines and recommender systems work, but we\u2019ll see together the strategies that they employ to favor\u00a0IR. Strategies to deliver text\u00a0data We have mentioned Google and Amazon. The first because it is a search engine, and the second because of its recommender systems. They are the de-facto standard of the industry because they work so well. This is proven by how satisfied the users are with using their\u00a0product. But they are radically different in terms of how they deliver information to the user in some of their specific functionalities. While they both use search and recommendation systems (for instance, Google suggests related keywords, which can be interpreted as a recommendation, while Amazon delivers product info through the search bar), we can dissect how Google delivers information through search and how Amazon delivers information through recommendation. The user queries the system: the Pull\u00a0strategy It literally means that the user pulls the information from the system. An example is when users query a database or a search engine. In this context, the user takes the initiative and searches the environment for information. In tangible terms, whenever we search Google for something, we are pulling information from its database to do something with that information. Pulling involves two\u00a0aspects: QueryingWe query the search engine through a keyword, and the engine returns relevant documents. The ability of the engine to deliver relevant content dictates whether the search engine is doing a good job or not. Querying works very well when users know what they are looking\u00a0for. BrowsingThe user navigates the structure of the documents to find the information he\u2019s looking for. As you can intuitively understand, this strategy works well when the user doesn\u2019t know what to look for or can\u2019t conveniently query the\u00a0system. How Do Google and Amazon Use Pull Strategies? In search and in visualizing their results. Whenever Google returns a SERP (Search Engine Result Page), or whenever Amazon displays a list of products, they are moving the user from the querying space to the browsing space. This does not happen if the end-user lands directly on the result they looked for (Google\u2019s Are you feeling lucky feature for instance). Users query the system \u2192 \u201cwhere to buy sneakers in Milan,\u00a0Italy.\u201d Users browse the results \u2192 documents (items) match the intent of the\u00a0user The system guesses what info is relevant: the Push\u00a0strategy This strategy is used when systems take the initiative to deliver presumably relevant information to the end user. This strategy is employed by recommendation systems. The better these systems are at pushing information, the better their performance and\u00a0usage. Amazon is a perfect example of how these systems work on the professional level. Netflix\u2019s system is another one worth mentioning. We can all acknowledge how powerful these systems are in that they directly increase (or decrease) the user value for the business. But why are these systems so difficult to tune? Why is Amazon so good at suggesting items and some other engines fail when it comes to creating more complex associations? It\u2019s because these systems require stable, clean information coming in from the end user. In other words, it must access user behavior data. Of course, the more traffic you have on your website, the more data you can store and feed into the\u00a0system. The Problem of User\u00a0Intent Natural Language Processing is a very difficult domain. Having machines decode what humans imply during conversation is turning out to be quite the challenge. John saw a kid with a telescope. This sentence alone is sufficient to break any NLP algorithm of the past 20 years. The portion with a telescope can either refer to John (as if John saw the kind by looking through a telescope) or to the kid (as if the kid was holding a telescope when John saw him). Discerning ambiguity is one of the greatest challenges in NLP today. Google and Facebook have done great work in the field, together with many other big shots of the industry. It goes without saying that understanding user intent during the search is one tough task. Google, being the first search engine in the world whose job is literally to predict what users&#039; intention is, is still trying to figure out how to achieve this. Many updates are [&#8230;]",
            "pubdate": "Sun, 21 Aug 2022 04:48:30 +0000",
            "pubdate_parsed": 1661057310.0,
            "email_sent": true
        },
        "Practical Implementation of Content-Based Recommendation System": {
            "url": "https://towardsai.net/p/l/practical-implementation-of-content-based-recommendation-system",
            "description": "Last Updated on August 21, 2022 by Editorial Team Author(s): Gowtham S R Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A complete end-to-end Content-based recommendation system that recommends similar movies based on the user\u2019s\u00a0input. Image from Unsplash uploaded by Krists\u00a0Luhaers What is a recommendation system? Whenever we visit a shopping mall to buy a new pair of shoes or clothes, we find a dedicated person who helps us with the kind of products we should buy based on our preferences and makes our job simpler. In simple words, he is a recommendation system. But in this modern world, everything is online, and there is so much content on the internet, there are crores of videos on Youtube and crores of products on Amazon, which makes it difficult for the user to choose. There comes the recommendation system, which makes the user\u2019s life simple by recommending the next video to watch or a similar product to\u00a0buy. A recommendation system is a piece of code that is intelligent enough to understand the user\u2019s preferences and recommend things based on his/her interest, the goal is to increase profitability. For Eg, Youtube and NetFlix want you to spend more time on their platform, so they recommend the videos based on the user\u2019s preferences. Amazon wants you to buy products from their website so that they can make more\u00a0profit. What are the different types of Recommendation systems? Image by\u00a0author Popularity-based: Recommending the top products from their website to every user. This method will not consider the user\u2019s interest. E.g., the Trending section on Youtube, IMDB top 250\u00a0movies. Content-based: Image by\u00a0author This is based on the similarity between the products. E.g., If a user has watched a movie and liked it, he may like to watch similar movies in the future. This can be based on the genre, actor, actress, or director. Collaborative filtering: Image by\u00a0author This is based on the similarity of users. E.g., If person A and B had watched and liked the movie M, next if person A watched the movie Z and liked it, we can recommend the movie Z to person B since A and B are similar\u00a0users. If you are keen to know how we can build a popularity-based and collaborative-filtering-based recommendation system, consider reading the below\u00a0blog. A Complete end to end Machine Learning based Recommendation Project Hybrid filtering: This makes use of all or some of the above-mentioned methods to form a hybrid\u00a0model. Content-based Movie Recommendation System: Let us look at how we can build a content-based book recommendation system. Below is the image of the final model that we are going to build for this\u00a0project. Image by\u00a0author Following are the steps we will be performing. Let us import basic libraries, read the dataset and create the data frames. The dataset can be downloaded from the link\u200a\u2014\u200adataset https://medium.com/media/35aa1ec60ba259dafc3de90b678718d4/href Merge the data frames \u2018movies\u2019 and \u2018credits\u2019 to get the final data\u00a0frame. Consider only the required\u00a0columns. working on the column\u200a\u2014\u200agenres: The column \u2018genres\u2019 is the list of dictionaries, it has both keys and values, but we need only the genre values, so let us make a function to get only the required\u00a0data. https://medium.com/media/a5c51ca6957fac00fe16182adbb63934/href The \u2018genres\u2019 column now contains only the required\u00a0data. Let us apply the same function to column \u2018keywords.\u2019 Let us modify the above function to get only the first 3 cast\u00a0names. https://medium.com/media/2a330cfb16b5d1209c65363c4e5b321f/href Let us get the director\u2019s name from the column \u2018crew\u2019 by modifying the above function. https://medium.com/media/d4d56ec18fd7db28f3d1af5727b9a2a6/href Let us convert the column \u2018overview\u2019 from string to\u00a0list We need to modify the names of the crew and cast members in such a way that there should not be any space between the names because when we convert words into vectors, our machine learning model will get impacted. E.g., James Cameron should be converted to \u2018JamesCameron\u2019 and Johnny Depp to be converted to JohnnyDepp and Science Fiction to be converted to ScienceFiction. Let us make a new column called tags by concatenating the features \u2018keywords\u2019, \u2018overview\u2019, \u2018genres\u2019, \u2018cast\u2019, and\u00a0\u2018crew\u2019. Let us make a new data frame new_df by taking only the features \u2018movie_id\u2019, \u2018title\u2019, and\u00a0\u2018tags\u2019. Let us convert the feature \u2018tags\u2019 from a list to a\u00a0string. Convert the feature \u2018tags\u2019 into lowercase. Apply stemming for converting the words into their base\u00a0forms. Now let us convert the tags into a Bag of words while removing all the stop words, and now the movie vectors will be ready. Each movie is a vector with 5000 dimensions. Let us calculate the similarity score between each movie\u00a0vector. Let us make a function that takes a movie name as the input and recommends 5 movies based on the similarity scores. https://medium.com/media/a0243dbd8789ad40a3568a31bfc4c33a/href Take a look at some of the recommendations from the\u00a0model. Model Deployment: Let&#039;s make use of the \u2018streamlit\u2019 library to make a simple GUI and deploy the\u00a0model. https://medium.com/media/cec24aebcca8947ba2a1a51370e10021/href We have successfully completed the front end of the app, and you can deploy it to any of the cloud platforms. Take a look at some of the recommendations below. Image by\u00a0author Image by\u00a0author Image by\u00a0author We have successfully completed all the steps, and our model is ready. You can try and build a similar model. The complete code can be found on my Github\u00a0page. Practical Implementation of Content-Based Recommendation System was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 21 Aug 2022 04:48:27 +0000",
            "pubdate_parsed": 1661057307.0,
            "email_sent": true
        },
        "You\u2019re Missing The Point Behind PCA": {
            "url": "https://towardsai.net/p/l/youre-missing-the-point-behind-pca",
            "description": "Last Updated on August 21, 2022 by Editorial Team Author(s): Nandini Tengli Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Just as with most things in computer science, understanding what PCA (Principal Component Analysis) is or why it works takes hours of digging and sifting through complicated documentation. When trying to learn about PCA, most resources that I came across glossed over how/why PCA actually worked and didn\u2019t give me any intuition behind the algorithm\u2019s motives. My goal with this article is to compile an easy-to-understand account of what PCA actually is and why it works. I will provide links to resources for any further\u00a0study. Hello! I am Nandini Tengli, a college junior majoring in Computer Science. This is my CS blog, where I try to document what I learn in the most non-jargony way possible. If you are like me and love digging deep to get a good understanding of things but end up spending hours just trying to decrypt documentation, then you are in the right\u00a0place. Links to all resources are at the bottom of the\u00a0article! What you need to be familiar with before trying to understand the math behind\u00a0PCA: Eigendecomposition Linear Transformation If you\u2019ve never heard of these terms, then you should probably take a look at the resources at the bottom before reading this. If you have even a vague familiarity with what these terms mean, then you can start reading this article and revisit these topics as you need\u00a0to! Principal Component Analysis Despite PCA being commonly known as a dimensionality reduction technique, this is not entirely accurate. If there is one thing you take away from this article, it should be this: PCA is just a Linear transformation\u200a\u2014\u200aa change of perspective if you will\u200a\u2014\u200aof the data. The idea is to get a better understanding of the underlying patterns in your data by changing the perspective through which you view your\u00a0data. But what exactly is a linear transformation? Box of Marbles ordered by color (left), by size (right): transformation to the different coordinate system Let us say your data is a big box of colored marbles, with each color in its own separate box. Viewing your data (marbles) like this helps you understand certain things, like the number of colors the marbles are available in. But what if there were other patterns in your marbles that you were missing simply because you chose to organize your marbles by color? Applying the PCA algorithm on this box would be like shaking the box up and reordering it by the size of the marbles instead of the colors. In doing so, different patterns (one that concerns size in this case) come to the forefront. Of course, this is a simple analogy, and we should be careful not to extend its implications. The idea is to understand that PCA is a linear transformation technique\u200a\u2014\u200aa change of perspective\u200a\u2014\u200aof the\u00a0data. So all this algorithm really does is a cluster or order your data by a different feature/set of features (dimensions or axis\u200a\u2014\u200ahere, we changed the feature from color to size) in the hopes of getting a better understanding of the data and the trends in\u00a0it. The real use case of PCA actually lies in the way it constructs the transformation matrix\u200a\u2014\u200athe way it picks the \u2018features\u2019 or the \u2018dimensions\u2019 to organize your\u00a0data. The way PCA actually comes up with this new set of dimensions is by maximizing for \u2018spread\u2019 or variance in the data. The intuition behind this is that: given our dataset has good measurements (minimal noise), we assume that the directions of largest variances capture the most interesting patterns/dynamics (signals) in our data. So changing our reference frame\u200a\u2014\u200aour basis\u200a\u2014\u200a\u2014 to align with the directions of the largest variances allows us to analyze better/study these patterns in our\u00a0data. Another goal while working with massive datasets is to minimize redundancy in the dataset. For instance: given two features that are extremely correlated, we can reduce redundancy by recording just one of the features instead of both of them. This is because we can always use the relationship between the two features to produce the data for the second one. Since PCA also has this goal of reducing redundancy also built into the algorithm. PCA orders the new axes/dimensions/features from the most \u2018useful\u2019 to the least \u2018useful\u2019. This means that we can drop the less useful attributes easily and thus better optimize our learning algorithms. This \u2018getting rid of attributes\u2019 is what is referred to as projecting the data onto a lower dimensional subspace in linear algebra. Since these attributes are \u2018new\u2019\u200a\u2014\u200acompletely different\u200a\u2014\u200afrom the original attributes of our data, we can reduce the dimensionality of the data without having to explicitly \u2018delete\u2019 any of the original attributes. Since we have the transformation matrix, we can always re-derive the original ordering of the data by using the inverse of this matrix. This will become more clear when we apply this algorithm to compress a large image of a dying star later on in the article. This is what makes PCA a popular choice for dimensionality reduction in data\u00a0science. \u2018Usefulness\u2019 for the PCA algorithm is based on variance. It orders the dimensions\u200a\u2014\u200athe principal components\u200a\u2014\u200aby the amount of variance they capture. The first dimension\u200a\u2014\u200athe first principal component\u200a\u2014\u200ais going to be along the direction of the most varied data. The second principal component has to be orthogonal (perpendicular) to the first principal component and in the direction of the second highest variance. This is repeated to find the other principal components. We restrict each new principal component to being orthogonal to all the previous components since it allows us to take advantage of linear\u00a0algebra. There are a couple of avenues to perform PCA using\u00a0python: Sklearn\u2019s decomposition module. This is the [&#8230;]",
            "pubdate": "Sun, 21 Aug 2022 04:48:25 +0000",
            "pubdate_parsed": 1661057305.0,
            "email_sent": true
        },
        "Autoencoder Average Distance\u200a\u2014\u200aa classical way used internally at Microsoft to find out similarity\u2026": {
            "url": "https://towardsai.net/p/l/autoencoder-average-distance%e2%80%8a-%e2%80%8aa-classical-way-used-internally-at-microsoft-to-find-out-similarity",
            "description": "Last Updated on August 21, 2022 by Editorial Team Author(s): VARUN KUKRETI Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Autoencoder Average Distance\u200a\u2014\u200aA Classical Way Used Internally at Microsoft To Find Out Similarity Between the Given\u00a0Datasets The autoencoder average distance (AAD) uses a simpler approach to find out the distance between the two datasets. A neural autoencoder can convert any data item into a vector of numeric values. The idea of the AAD distance metric is to convert two source datasets into strictly numeric vectors with the same number of values and then compute the difference between the average of the vectors in each\u00a0dataset. This technique for computing dataset difference was developed by J. McCaffrey and S. Chen and has been used internally at Microsoft. Introduction The machine learning domain is often characterized by the fact that the data available from the application of interest is usually scarce. In other words, considerable data is available for general purpose implementations in contrast to the limited amount of data available for dedicated investigations. Because of this reason, there is vast interest in the development of methods that can combine, adapt and transfer knowledge across datasets and domains. Entire research areas are devoted to these, including domain adaptation, transfer-learning, and meta-learning. These also constitute some of the active areas of research in the field of machine learning. The Notion of\u00a0Distance A basic notion underlying all these domains is that of the distance (or similarity) between datasets. In order to determine the similarity between the two given datasets, we tend to figure out the distance between them. For instance, transferring knowledge across similar domains should intuitively be easier than across distant ones. Likewise, given a choice of various datasets to train a model on, it would seem natural to choose the one that is closest to the task of interest. This ultimately leads to an increment in the amount of data required for a particular task. However, this notion still poses certain problems. For instance, despite its usefulness and simpleness, the notion of distance between datasets is an elusive one, and quantifying it efficiently and in a principled manner remains largely an open problem. Doing so requires solving various challenges that commonly arise precisely in the settings for which this notion would be most useful, such as the ones mentioned above. For example, in supervised machine learning settings, the datasets consist of both features and labels, and while defining a distance between the former is often\u200a\u2014\u200athough not always\u200a\u2014\u200atrivial, doing so for the labels is far from it, particularly if the label sets across the two tasks are not identical (as is often the case for off-the-shelf pretrained models). Knowing the distance between two datasets can be useful for at least two reasons. Firstly, dataset distance can be used for transfer learning activities, such as using a prediction model trained on one dataset to train a second dataset quickly. Secondly, the distance between the datasets can be useful for augmenting training data\u200a\u2014\u200acreating additional synthetic training data which can be used to build a more accurate prediction model. Ways to determine Dataset\u00a0Distance There exist several ways to figure out similarities between the two given datasets. These do include a good level of mathematical calculations and rely on higher mathematical notions. Therefore, often these approaches appear to be heuristic and complex. The approaches in transfer learning that seek to quantify dataset similarity include various ways. A common approach is to compare the datasets using proxies. Most of these approaches lack guarantees, are highly dependent on the probe model used, and require training a model to completion (e. g., to find optimal parameters) on each dataset being compared. Dataset similarities can be measured using several available techniques. Various notions of similarity between data distributions have been proposed in the context of domain adaptation. These include using Discrepancy Distance, Dataset Distance via Parameter Sensitivity, Theory of Optimal Transport, Adversarial Validation, and Finding Distance Metrics between the two datasets. All these approaches are distinctive in their own sense, and each of them possesses its own advantages and disadvantages. Autoencoder Average Distance\u00a0(AAD) Although other techniques involve higher mathematics and often tend to get complex both in implementation and understanding, Autoencoder Average Distance(AAD) uses a relatively simple approach. In this approach, we use a neural autoencoder and use it to convert data items into a vector of numeric values. The idea involves converting two datasets to be compared into strictly numeric vectors with the same number of values using the autoencoder and then computing the difference between the average of the vectors in each dataset. The AAD distance metric then involves computing the average in each dataset and then comparing the two averages to compute a distance. This gives us a good idea about the similarity between the two datasets. For example, consider the MNIST dataset. We convert it into (0.3456, 0.9821,\u00a0.\u00a0.\u00a0. 0.5318) using an autoencoder. Take another dataset consisting of items like (\u201cmale\u201d, 31, $58,000.00, \u201csales\u201d) which converted into (0.1397, 0.7382,\u00a0.\u00a0.\u00a0. 0.0458). Once we have the numeric vectors of the respective datasets with the same number of values, our next task involves finding out the average of each dataset and then finding the difference between the two averages to get an appropriate idea of similarities between the MNIST and the other given\u00a0dataset. Advantages and Disadvantages of\u00a0AAD The other approaches often have a solid mathematical foundation and desirable mathematical properties, but they become too complex to be used in some scenarios. The autoencoder average distance (AAD) metric uses a simpler approach. Therefore, it becomes much easy to implement AAD. The advantages of AAD are that AAD is easier to compute, simpler to understand, and can be easily used with any type of data, including data with [&#8230;]",
            "pubdate": "Sun, 21 Aug 2022 04:28:55 +0000",
            "pubdate_parsed": 1661056135.0,
            "email_sent": true
        }
    },
    "Louis Bouchard Blog": {
        "No Language Left\u00a0Behind": {
            "url": "https://www.louisbouchard.ai/no-language-left-behind/",
            "description": "Translating 200 languages with a single model\u200a-\u200aMeta\u00a0AI",
            "pubdate": "Wed, 06 Jul 2022 13:11:04 GMT",
            "pubdate_parsed": 1657093264.0,
            "email_sent": true
        },
        "What is data-centric AI?": {
            "url": "https://www.louisbouchard.ai/data-centric-ai/",
            "description": "The beginning of data-centric AI with data programming",
            "pubdate": "Fri, 08 Jul 2022 00:11:13 GMT",
            "pubdate_parsed": 1657219273.0,
            "email_sent": true
        },
        "CVPR 2022 Best Paper Honorable Mention: Dual-Shutter Optical Vibration Sensing": {
            "url": "https://www.louisbouchard.ai/cvpr-2022-best-paper/",
            "description": "They reconstruct sound using cameras and a laser beam on any vibrating surface, allowing them to isolate music instruments, focus on a specific speaker, remove ambient noises, and many more amazing applications.",
            "pubdate": "Wed, 13 Jul 2022 13:36:57 GMT",
            "pubdate_parsed": 1657699617.0,
            "email_sent": true
        },
        "How OpenAI Reduces risks for DALL\u00b7E\u00a02": {
            "url": "https://www.louisbouchard.ai/how-openai-reduces-risks-for-dall-e-2/",
            "description": "DALL\u00b7E 2 Pre-Training Mitigations",
            "pubdate": "Sat, 16 Jul 2022 16:00:54 GMT",
            "pubdate_parsed": 1657967454.0,
            "email_sent": true
        },
        "Produce Amazing Artworks with Text and Sketches!": {
            "url": "https://www.louisbouchard.ai/make-a-scene/",
            "description": "\"Make-A-Scene\": a fantastic blend between text and sketch-conditioned image generation.",
            "pubdate": "Tue, 19 Jul 2022 12:16:59 GMT",
            "pubdate_parsed": 1658213219.0,
            "email_sent": true
        },
        "Build Animatable 3D Models with AI": {
            "url": "https://www.louisbouchard.ai/banmo/",
            "description": "Create deformable 3D models from pictures with\u00a0BANMo!",
            "pubdate": "Sat, 13 Aug 2022 13:39:19 GMT",
            "pubdate_parsed": 1660397959.0,
            "email_sent": true
        }
    },
    "Computational Intelligence Blog": {
        "IEEE Transactions on Fuzzy Systems, Volume 30, Issue 7": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9419714/\">Novel Heterogeneous Mode-Dependent Impulsive Synchronization for Piecewise T-S Fuzzy Probabilistic Coupled Delayed Neural Networks</a></div><div><b>Author(s): </b>Xiangxiang Wang, Yongbin Yu, Shouming Zhong, Kaibo Shi, Nijing Yang, Dingfa Zhang, Jingye Cai, Nyima Tashi</div><div><b>Pages: </b>2142 - 2156</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9419710/\">Nonlinear Dimensionality Reduction for Data Visualization: An Unsupervised Fuzzy Rule-Based Approach</a></div><div><b>Author(s):&nbsp;</b>Suchismita Das, Nikhil R. Pal</div><div><b>Pages:&nbsp;</b>2157 - 2169</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9423589/\">An Efficient Self-Organizing Deep Fuzzy Neural Network for Nonlinear System Modeling</a></div><div><b>Author(s):&nbsp;</b>Gongming Wang, Junfei Qiao</div><div><b>Pages:&nbsp;</b>2170 - 2182</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9424990/\">Adaptive Event-Triggered Fuzzy Tracking Control of Uncertain Stochastic Nonlinear Systems With Unmeasurable States</a></div><div><b>Author(s):&nbsp;</b>Rui-Yan Zhang, Li-Bing Wu, Nan-Nan Zhao, Yan Yan</div><div><b>Pages:&nbsp;</b>2183 - 2196</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9425433/\">Membership Function, Time Delay-Dependent \u03b7-Exponential Stabilization of the Positive Discrete-Time Polynomial Fuzzy Model Control System</a></div><div><b>Author(s):&nbsp;</b>Xiaomiao Li, Kamyar Mehran, Zhiyong Bao</div><div><b>Pages:&nbsp;</b>2197 - 2209</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9425590/\">A Novel Three-Way Decision Model Based on Utility Theory in Incomplete Fuzzy Decision Systems</a></div><div><b>Author(s):&nbsp;</b>Jianming Zhan, Jin Ye, Weiping Ding, Peide Liu</div><div><b>Pages:&nbsp;</b>2210 - 2226</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9427360/\">Finite-Time Adaptive Fuzzy Prescribed Performance Control for High-Order Stochastic Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Shuai Sui, C. L. Philip Chen, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>2227 - 2240</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9427125/\">Maximum Number of Line Faults in a P2P Network System Based on the Addition-Min Fuzzy Relation Inequalities</a></div><div><b>Author(s):&nbsp;</b>Xiao-Peng Yang, Gengzhong Zheng</div><div><b>Pages:&nbsp;</b>2241 - 2253</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9427225/\">Sampled-Data-Based H\u221e Fuzzy Pinning Synchronization of Complex Networked Systems With Adaptive Event-Triggered Communications</a></div><div><b>Author(s):&nbsp;</b>Xin Wang, Ju H. Park, Huilan Yang, Zhiqi Yu</div><div><b>Pages:&nbsp;</b>2254 - 2265</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9428619/\">Analysis of Ranking Consistency in Linguistic Multiple Attribute Decision Making: The Roles of Granularity and Decision Rules</a></div><div><b>Author(s):&nbsp;</b>Sihai Zhao, Yucheng Dong, Luis Mart\u00edne, Witold Pedrycz</div><div><b>Pages:&nbsp;</b>2266 - 2278</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9428344/\">Adaptive Fast Finite-Time Fuzzy Control of Stochastic Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Zhaoyang You, Fang Wang</div><div><b>Pages:&nbsp;</b>2279 - 2288</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9428513/\">Model-Based Fuzzy l2\u2212l\u221e Filtering for Discrete-Time Semi-Markov Jump Nonlinear Systems Using Semi-Markov Kernel</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Yigang Zhang, Lei Su, Ju H. Park, Hao Shen</div><div><b>Pages:&nbsp;</b>2289 - 2299</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9430728/\">Adaptive Fuzzy SOSM Controller Design With Output Constraints</a></div><div><b>Author(s):&nbsp;</b>Shihong Ding, Binbin Zhang, Keqi Mei, Ju H. Park</div><div><b>Pages:&nbsp;</b>2300 - 2311</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9430676/\">Fault-Tolerant Quantized Sliding Mode Observers Design for a Class of Takagi-Sugeno Fuzzy System With Unmeasurable Premise Variable</a></div><div><b>Author(s):&nbsp;</b>Ang Li, Guangren Duan, Ming Liu, Jingbo Fu</div><div><b>Pages:&nbsp;</b>2312 - 2324</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9432713/\">Fuzzy Energy-to-Peak Filtering for Continuous-Time Nonlinear Singular System</a></div><div><b>Author(s):&nbsp;</b>Xiao-Heng Chang, Ming-Yang Qiao, Xudong Zhao</div><div><b>Pages:&nbsp;</b>2325 - 2336</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9435080/\">An Analytical Method to Compute the Approximate Inverses of a Fuzzy Matrix With Max-Product Composition</a></div><div><b>Author(s):&nbsp;</b>Yan-Kuen Wu, Yung-Yih Lur, Hsun-Chih Kuo, Ching-Feng Wen</div><div><b>Pages:&nbsp;</b>2337 - 2346</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9436023/\">Fuzzy Event-Triggered Integral Sliding Mode Control of Nonlinear Continuous-Time Systems</a></div><div><b>Author(s):&nbsp;</b>Zeinab Echreshavi, Mohsen Farbood, Mokhtar Shasadeghi</div><div><b>Pages:&nbsp;</b>2347 - 2359</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9435959/\">Fuzzy Measures and Choquet Integrals Based on Fuzzy Covering Rough Sets</a></div><div><b>Author(s):&nbsp;</b>Xiaohong Zhang, Jingqian Wang, Jianming Zhan, Jianhua Dai</div><div><b>Pages:&nbsp;</b>2360 - 2374</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9436033/\">Fast Fuzzy Clustering Based on Anchor Graph</a></div><div><b>Author(s):&nbsp;</b>Feiping Nie, Chaodie Liu, Rong Wang, Zhen Wang, Xuelong Li</div><div><b>Pages:&nbsp;</b>2375 - 2387</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9437688/\">Multilabel Feature Selection Based on Relative Discernibility Pair Matrix</a></div><div><b>Author(s):&nbsp;</b>Erliang Yao, Deyu Li, Yanhui Zhai, Chao Zhang</div><div><b>Pages:&nbsp;</b>2388 - 2401</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9439174/\">Quantized Guaranteed Cost Output Feedback Control for Nonlinear Networked Control Systems and Its Applications</a></div><div><b>Author(s):&nbsp;</b>Qunxian Zheng, Shengyuan Xu, Baozhu Du</div><div><b>Pages:&nbsp;</b>2402 - 2411</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9439896/\">Fuzzy Bayesian Knowledge Tracing</a></div><div><b>Author(s):&nbsp;</b>Fei Liu, Xuegang Hu, Chenyang Bu, Kui Yu</div><div><b>Pages:&nbsp;</b>2412 - 2425</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9440662/\">Dwell-Time-Dependent H\u221e Bumpless Transfer Control for Discrete-Time Switched Interval Type-2 Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Siyuan Zhang, Jun Zhao</div><div><b>Pages:&nbsp;</b>2426 - 2437</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9442351/\">Fuzzy Multioutput Transfer Learning for Regression</a></div><div><b>Author(s):&nbsp;</b>Xiaoya Che, Hua Zuo, Jie Lu, Degang Chen</div><div><b>Pages:&nbsp;</b>2438 - 2451</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9442297/\">Stability and Control of Fuzzy Semi-Markov Jump Systems Under Unknown Semi-Markov Kernel</a></div><div><b>Author(s):&nbsp;</b>Zepeng Ning, Bo Cai, Rui Weng, Lixian Zhang, Shun-Feng Su</div><div><b>Pages:&nbsp;</b>2452 - 2465</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9446576/\">New Results on Dissipative Control for a Class of Singular Takagi\u2013Sugeno Fuzzy Systems With Time Delay</a></div><div><b>Author(s):&nbsp;</b>Zhiguang Feng, Huayang Zhang, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>2466 - 2475</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9447197/\">Finite-Time Dynamic Event-Triggered Distributed H\u221e Filtering for T-S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaoyuan Zheng, Hao Zhang, Zhuping Wang, Changzhu Zhang, Huaicheng Yan</div><div><b>Pages:&nbsp;</b>2476 - 2486</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9447907/\">Asynchronous Fault Detection for Interval Type-2 Fuzzy Nonhomogeneous Higher Level Markov Jump Systems With Uncertain Transition Probabilities</a></div><div><b>Author(s):&nbsp;</b>Xiang Zhang, Hai Wang, Vladimir Stojanovic, Peng Cheng, Shuping He, Xiaoli Luan, Fei Liu</div><div><b>Pages:&nbsp;</b>2487 - 2499</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9448475/\">Fuzzy Community Detection Based on Elite Symbiotic Organisms Search and Node Neighborhood Information</a></div><div><b>Author(s):&nbsp;</b>Jing Xiao, Yan-Jiao Wang, Xiao-Ke Xu</div><div><b>Pages:&nbsp;</b>2500 - 2514</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9449989/\">Cooperative Target Enclosing of Ring-Networked Underactuated Autonomous Surface Vehicles Based on Data-Driven Fuzzy Predictors and Extended State Observers</a></div><div><b>Author(s):&nbsp;</b>Yue Jiang, Zhouhua Peng, Dan Wang, Yong Yin, Qing-Long Han</div><div><b>Pages:&nbsp;</b>2515 - 2528</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9454304/\">A Simplified Finite-Time Fuzzy Neural Controller With Prescribed Performance Applied to Waverider Aircraft</a></div><div><b>Author(s):&nbsp;</b>Xiangwei Bu, Qiang Qi, Baoxu Jiang</div><div><b>Pages:&nbsp;</b>2529 - 2537</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9454283/\">Stability Criteria for Fuzzy-Based Sampled-Data Control Systems via a Fractional Parameter-Based Refined Looped Lyapunov Functional</a></div><div><b>Author(s):&nbsp;</b>Lakshmanan Shanmugam, Young Hoon Joo</div><div><b>Pages:&nbsp;</b>2538 - 2549</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9454293/\">Distributed Kalman Filter With Fuzzy Noises Over Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Haoshen Lin, Chen Hu, Zhenhua Deng, Gang Liu</div><div><b>Pages:&nbsp;</b>2550 - 2562</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9454307/\">Self-Sustaining Oscillations With an Internal Two-Fuzzy Inference System Based on the Poincar\u00e9\u2013Bendixson Method</a></div><div><b>Author(s):&nbsp;</b>Jorge A. Lopez-Renteria, Lisdan Herrera-Garcia, Selene L. Cardenas-Maciel, Luis T. Aguilar, Nohe R. Cazarez-Castro</div><div><b>Pages:&nbsp;</b>2563 - 2573</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9454376/\">Admissibility and Design Issues for T-S Fuzzy Descriptor Systems With Perturbed Derivative Matrices in the Rules</a></div><div><b>Author(s):&nbsp;</b>Chih-Peng Huang</div><div><b>Pages:&nbsp;</b>2574 - 2582</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9454380/\">Guaranteed Cost Control for Interval Type-2 Fuzzy Semi-Markov Switching Systems Within a Finite-Time Interval</a></div><div><b>Author(s):&nbsp;</b>Linchuang Zhang, Yonghui Sun, Hak-Keung Lam, Hongyi Li, Jianxi Wang, Dongchen Hou</div><div><b>Pages:&nbsp;</b>2583 - 2594</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9457145/\">Finite-Frequency H\u2212/H\u221e Memory Fault Detection Filtering Design for Uncertain Takagi\u2013Sugeno Fuzzy Affine Systems</a></div><div><b>Author(s):&nbsp;</b>Rong Zhao, Lu Liu, Gang Feng</div><div><b>Pages:&nbsp;</b>2595 - 2609</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9457138/\">Event-Triggered Bipartite Consensus for Fuzzy Multiagent Systems Under Markovian Switching Signed Topology</a></div><div><b>Author(s):&nbsp;</b>Jiafeng Yu, Choon Ki Ahn, Peng Shi</div><div><b>Pages:&nbsp;</b>2610 - 2620</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9457143/\">Continuous Exp Strategy for Consumer Preference Analysis Based on Online Ratings</a></div><div><b>Author(s):&nbsp;</b>Long Ren, Bin Zhu, Zeshui Xu</div><div><b>Pages:&nbsp;</b>2621 - 2633</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9457170/\">Trust Cop-Kmeans Clustering Analysis and Minimum-Cost Consensus Model Considering Voluntary Trust Loss in Social Network Large-Scale Decision-Making</a></div><div><b>Author(s):&nbsp;</b>Su-Min Yu, Zhi-Jiao Du, Xue-Yang Zhang, Han-Yang Luo, Xu-Dong Lin</div><div><b>Pages:&nbsp;</b>2634 - 2648</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9462345/\">Statistically Evolving Fuzzy Inference System for Non-Gaussian Noises</a></div><div><b>Author(s):&nbsp;</b>Zhao-Xu Yang, Hai-Jun Rong, Plamen Angelov, Zhi-Xin Yang</div><div><b>Pages:&nbsp;</b>2649 - 2664</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9462321/\">A New Fuzzy Spiking Neural Network Based on Neuronal Contribution Degree</a></div><div><b>Author(s):&nbsp;</b>Fang Liu, Jie Yang, Witold Pedrycz, Wei Wu</div><div><b>Pages:&nbsp;</b>2665 - 2677</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9462470/\">Aperiodic Sampled-Data Takagi\u2013Sugeno Fuzzy Extended State Observer for a Class of Uncertain Nonlinear Systems With External Disturbance and Unmodeled Dynamics</a></div><div><b>Author(s):&nbsp;</b>Zhichen Li, Huaicheng Yan, Hao Zhang, Hak-Keung Lam, Congzhi Huang</div><div><b>Pages:&nbsp;</b>2678 - 2692</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9464680/\">Sampled-Data-Based Event-Triggered Fuzzy Control for PDE Systems Under Cyberattacks</a></div><div><b>Author(s):&nbsp;</b>Xiaona Song, Qiyuan Zhang, Shuai Song, Choon Ki Ahn</div><div><b>Pages:&nbsp;</b>2693 - 2705</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9466935/\">Interval-Valued Aggregation Functions Based on Moderate Deviations Applied to Motor-Imagery-Based Brain\u2013Computer Interface</a></div><div><b>Author(s):&nbsp;</b>Javier Fumanal-Idocin, Zdenko Tak\u00e1\u010d, Javier Fern\u00e1ndez, Jos\u00e9 Antonio Sanz, Harkaitz Goyena, Ching-Teng Lin, Yu-Kai Wang, Humberto Bustince</div><div><b>Pages:&nbsp;</b>2706 - 2720</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9468319/\">Noise-Tolerant Fuzzy-\u03b2-Covering-Based Multigranulation Rough Sets and Feature Subset Selection</a></div><div><b>Author(s):&nbsp;</b>Zhehuang Huang, Jinjin Li, Yuhua Qian</div><div><b>Pages:&nbsp;</b>2721 - 2735</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9470937/\">Expansive Errors-Based Fuzzy Adaptive Prescribed Performance Control by Residual Approximation</a></div><div><b>Author(s):&nbsp;</b>Shigen Gao, Mingjun Li, Yue Zheng, Hairong Dong</div><div><b>Pages:&nbsp;</b>2736 - 2746</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9477002/\">Fractional-Order Terminal Sliding-Mode Control Using Self-Evolving Recurrent Chebyshev Fuzzy Neural Network for MEMS Gyroscope</a></div><div><b>Author(s):&nbsp;</b>Zhe Wang, Juntao Fei</div><div><b>Pages:&nbsp;</b>2747 - 2758</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9477053/\">Relaxed Conditions of Observer Design of Discrete-Time Takagi\u2013Sugeno Fuzzy Systems via a New Multi-Instant Gain-Scheduling Scheme</a></div><div><b>Author(s):&nbsp;</b>Hongyu Lu, Xiangpeng Xie, Chen Peng</div><div><b>Pages:&nbsp;</b>2759 - 2768</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9426421/\">A Fuzzy Lyapunov Function Method to Stability Analysis of Fractional-Order T\u2013S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Fan, Zhanshan Wang</div><div><b>Pages:&nbsp;</b>2769 - 2776</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9454282/\">Multi-Instant Gain-Scheduling Stabilization of Discrete-Time Takagi\u2013Sugeno Fuzzy Systems Based on a Time-Variant Balanced Matrix Approach</a></div><div><b>Author(s):&nbsp;</b>Xiangpeng Xie, Chengjie Bu, Chen Peng</div><div><b>Pages:&nbsp;</b>2777 - 2782</div><div><br /></div>",
            "pubdate": "2022-07-08T10:36:00.000+12:00",
            "pubdate_parsed": 1657213560.0,
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 14, July 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-14-july.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07116-6\">Efficient data transfer supporting provable data deletion for secure cloud storage</a></div><div><b>Author(s): </b>Changsong Yang, Yueling Liu, Yong Ding</div><div><b>Pages: </b>6463 - 6479</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07119-3\">Green\u2019s relations in L-E-fuzzy skew lattices</a></div><div><b>Author(s):&nbsp;</b>Yuan Zhi, Xiangnan Zhou, Qingguo Li</div><div><b>Pages:&nbsp;</b>6481 - 6494</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07134-4\">Regular and strongly regular relations induced by fuzzy subhypermodules</a></div><div><b>Author(s):&nbsp;</b>N. Rakhsh Khorshid, S. Ostadhadi-Dehkordi</div><div><b>Pages:&nbsp;</b>6495 - 6506</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07127-3\">Another view on knowledge measures in atanassov intuitionistic fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>Muhammad Irfan Ali, Jianming Zhan...Haider Faizan</div><div><b>Pages:&nbsp;</b>6507 - 6517</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07128-2\">Effect of fuzziness in fuzzy rule-based classifiers defined by strong fuzzy partitions and winner-takes-all inference</a></div><div><b>Author(s):&nbsp;</b>Gabriella Casalino, Giovanna Castellano...Corrado Mencar</div><div><b>Pages:&nbsp;</b>6519 - 6527</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07168-8\">Nonlinear interval regression analysis with neural networks and grey prediction for energy demand forecasting</a></div><div><b>Author(s):&nbsp;</b>Yi-Chung Hu, Wen-Bao Wang</div><div><b>Pages:&nbsp;</b>6529 - 6545</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07178-6\">Knowledge transfer learning from multiple user activities to improve personalized recommendation</a></div><div><b>Author(s):&nbsp;</b>Mingxin Gan, Yingxue Ma</div><div><b>Pages:&nbsp;</b>6547 - 6566</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07179-5\">A quantum system control method based on enhanced reinforcement learning</a></div><div><b>Author(s):&nbsp;</b>Wenjie Liu, Bosi Wang...Mohammed Zidan</div><div><b>Pages:&nbsp;</b>6567 - 6575</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07181-x\">On-demand DWDM design using machine learning</a></div><div><b>Author(s):&nbsp;</b>K. Venkatesan, A. Chandrasekar, P. G. V. Ramesh</div><div><b>Pages:&nbsp;</b>6577 - 6589</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07040-9\">Ramp loss KNN-weighted multi-class twin support vector machine</a></div><div><b>Author(s):&nbsp;</b>Huiru Wang, Yitian Xu, Zhijian Zhou</div><div><b>Pages:&nbsp;</b>6591 - 6618</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07042-7\">A revisited fuzzy DEMATEL and optimization method for strategy map design under the BSC framework: selection of objectives and relationships</a></div><div><b>Author(s):&nbsp;</b>H\u00e9ctor L\u00f3pez-Ospina, Daniela Pardo...Luis Quezada</div><div><b>Pages:&nbsp;</b>6619 - 6644</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07043-6\">A novel linear representation for evolving matrices</a></div><div><b>Author(s):&nbsp;</b>Connor Gregor, Daniel Ashlock...David Kribs</div><div><b>Pages:&nbsp;</b>6645 - 6657</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07050-7\">MOTEO: a novel multi-objective thermal exchange optimization algorithm for engineering problems</a></div><div><b>Author(s):&nbsp;</b>Nima Khodadadi, Siamak Talatahari...Armin Dadras Eslamlou</div><div><b>Pages:&nbsp;</b>6659 - 6684</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07061-4\">A novel incremental cost consensus approach for distributed economic dispatch over directed communication topologies in a smart grid</a></div><div><b>Author(s):&nbsp;</b>Um-E-Habiba Alvi, Waqas Ahmed...Ijaz Ahmed</div><div><b>Pages:&nbsp;</b>6685 - 6700</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07065-0\">Intelligent computing technique for solving singular multi-pantograph delay differential equation</a></div><div><b>Author(s):&nbsp;</b>Zulqurnain Sabir, Hafiz Abdul Wahab...Mohamed R. Ali</div><div><b>Pages:&nbsp;</b>6701 - 6713</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07066-z\">Optimization on the multi-period empty container repositioning problem in regional port cluster based upon inventory control strategies</a></div><div><b>Author(s):&nbsp;</b>Jiaxin Cai, Yubo Li...Zhihong Jin</div><div><b>Pages:&nbsp;</b>6715 - 6738</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07072-1\">A simple solution to technician routing and scheduling problem using improved genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Engin Pekel</div><div><b>Pages:&nbsp;</b>6739 - 6748</div><div><br /></div><div><b>18) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07079-8\">Fusion of modern meta-heuristic optimization methods using arithmetic optimization algorithm for global optimization tasks</a></div><div><b>Author(s):&nbsp;</b>Shubham Mahajan, Laith Abualigah...Maryam Altalhi</div><div><b>Pages:&nbsp;</b>6749 - 6763</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07089-6\">Identification of nonlinear discrete systems using a new Hammerstein model with Volterra neural network</a></div><div><b>Author(s):&nbsp;</b>Wei-Der Chang</div><div><b>Pages:&nbsp;</b>6765 - 6775</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07103-x\">Environmental assisted cracking and strength attenuation effect computing on the mechanical properties of casing steel P110 for industrial revolution 5.0 applications in sour well environments</a></div><div><b>Author(s):&nbsp;</b>Duo Hou, Zhongling Xiao...Taihe Shi</div><div><b>Pages:&nbsp;</b>6777 - 6787</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06906-2\">Comparison of subsidy strategies on the green supply chain under a behaviour-based pricing model</a></div><div><b>Author(s):&nbsp;</b>Kanying Liu, Wei Li...Yong Lan</div><div><b>Pages:&nbsp;</b>6789 - 6809</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06921-3\">Attack detection and prevention in IoT-SCADA networks using NK-classifier</a></div><div><b>Author(s):&nbsp;</b>Y. JustindhasP. Jeyanthi</div><div><b>Pages:&nbsp;</b>6811 - 6823</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06926-y\">A method to determine the integrated weights of cross-efficiency aggregation</a></div><div><b>Author(s):&nbsp;</b>Mei-Juan LiJin-Cheng LuLei Chen</div><div><b>Pages:&nbsp;</b>6825 - 6837</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06628-x\">Load-settlement response of a footing over buried conduit in a sloping terrain: a numerical experiment-based artificial intelligent approach</a></div><div><b>Author(s):&nbsp;</b>Muhammad Umer Arif Khan, Sanjay Kumar Shukla, Muhammad Nouman Amjad Raja</div><div><b>Pages:&nbsp;</b>6839 - 6856</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06629-w\">Recognition of shed damage on 11-kV polymer insulator using Bayesian optimized convolution neural network</a></div><div><b>Author(s):&nbsp;</b>B. Vigneshwaran, M. Willjuice Iruthayarajan, R. V. Maheswari</div><div><b>Pages:&nbsp;</b>6857 - 6869</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06630-3\">Enhanced heat transfer search and enriched replicated coronary circulation system optimization algorithms for real power loss reduction</a></div><div><b>Author(s):&nbsp;</b>Lenin Kanagasabai</div><div><b>Pages:&nbsp;</b>6871 - 6888</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06636-x\">A novel quality evaluation method for standardized experiment teaching</a></div><div><b>Author(s):&nbsp;</b>Luxin Yang, Yutong Chun...Jing Yang</div><div><b>Pages:&nbsp;</b>6889 - 6906</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06639-8\">Feature extraction-based intelligent algorithm framework with neural network for solving conditional nonlinear optimal perturbation</a></div><div><b>Author(s):&nbsp;</b>Shijin Yuan,Huazhen Zhang...Bin Mu</div><div><b>Pages:&nbsp;</b>6907 - 6924</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06646-9\">Computational intelligence in software defects rules discovery</a></div><div><b>Author(s):&nbsp;</b>Andreea VescanCamelia \u015eerbanGloria Cerasela Cri\u015fan</div><div><b>Pages:&nbsp;</b>6925 - 6939</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06648-7\">Fuzzy transfer learning in time series forecasting for stock market prices</a></div><div><b>Author(s):&nbsp;</b>Shanoli Samui PalSamarjit Kar</div><div><b>Pages:&nbsp;</b>6941 - 6952</div><div><br /></div></div>",
            "pubdate": "2022-07-09T12:00:00.001+12:00",
            "pubdate_parsed": 1657305000.0,
            "email_sent": true
        },
        "Evolving Systems, Volume 13, issue 4, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/evolving-systems-volume-13-issue-4.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09385-2\">FocusCovid: automated COVID-19 detection using deep learning with chest X-ray images</a></div><div><b>Author(s): </b>Tarun Agrawal, Prakash Choudhary</div><div><b>Pages: </b>519 - 533</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09392-3\">Multichannel convolutional neural network-based fuzzy active contour model for medical image segmentation</a></div><div><b>Author(s):&nbsp;</b>Qingwu Shi, Shoulin Yin...Hang Li</div><div><b>Pages:&nbsp;</b>535 - 549</div><div><br /></div><div><b>3)</b> Cubic graph representation of concept lattice and its decomposition</div><div><b>Author(s):&nbsp;</b>Prem Kumar Singh</div><div><b>Pages:&nbsp;</b>551 - 562</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09401-5\">Battle royale optimizer for training multi-layer perceptron</a></div><div><b>Author(s):&nbsp;</b>Saeid Agahian, Taymaz Akan</div><div><b>Pages:&nbsp;</b>563 - 575</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09404-2\">Extreme gradient boosting model based on improved Jaya optimizer applied to forecasting energy consumption in residential buildings</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o Sauer, Viviana Cocco Mariani...Mirco Rampazzo</div><div><b>Pages:&nbsp;</b>577 - 588</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09407-z\">Optimization of FRP jacket by fractional\u2011order pathfinder algorithm to improve the reinforced concrete frames' seismic response</a></div><div><b>Author(s):&nbsp;</b>Chengliang Wang, Wenrui Li, Dragan Rodriguez</div><div><b>Pages:&nbsp;</b>589 - 601</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09408-y\">EvolveCluster: an evolutionary clustering algorithm for streaming data</a></div><div><b>Author(s):&nbsp;</b>Christian Nordahl, Veselka Boeva...Marie Persson Netz</div><div><b>Pages:&nbsp;</b>603 - 623</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09395-0\">Synthetic samples generator (SYSGEN), an approach to increase the size of incidence samples in coffee leaf rust modelling</a></div><div><b>Author(s):&nbsp;</b>Edwar Javier Gir\u00f3n, David Camilo Corrales...Juan Carlos Corrales</div><div><b>Pages:&nbsp;</b>625 - 636</div><div><br /></div></div>",
            "pubdate": "2022-07-11T21:35:00.001+12:00",
            "pubdate_parsed": 1657512300.0,
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 15, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-15.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07174-w\">Analytic hierarchy process-based regression test case prioritization technique enhancing the fault detection rate</a></div><div><b>Author(s): </b>Soumen Nayak, Chiranjeev Kumar, Sachin Tripathi</div><div><b>Pages: </b>6953 - 6968</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07193-7\">On Annihilators in Hoops</a></div><div><b>Author(s):&nbsp;</b>R. A. Borzooei, M. Aaly Kologani...Y. B. Jun</div><div><b>Pages:&nbsp;</b>6969 - 6980</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07216-3\">Properties of stabilizers in residuated lattices</a></div><div><b>Author(s):&nbsp;</b>Michiro Kondo</div><div><b>Pages:&nbsp;</b>6981 - 6988</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07217-2\">Independent domination polynomial of zero-divisor graphs of commutative rings</a></div><div><b>Author(s):&nbsp;</b>Necla K\u0131rcal\u0131 G\u00fcrsoy, Alper \u00dclker, Arif G\u00fcrsoy</div><div><b>Pages:&nbsp;</b>6989 - 6997</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07223-4\">Quasi-MV* algebras: a generalization of MV*-algebras</a></div><div><b>Author(s):&nbsp;</b>Yingying Jiang, Wenjuan Chen</div><div><b>Pages:&nbsp;</b>6999 - 7015</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06985-1\">Fuzzy filters of IL-algebras</a></div><div><b>Author(s):&nbsp;</b>Safiqul Islam, Arundhati Sanyal, Jayanta Sen</div><div><b>Pages:&nbsp;</b>7017 - 7027</div><div><br /></div><div><b>7) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07004-z\">Broad learning system based ensemble deep model</a></div><div><b>Author(s):&nbsp;</b>Chenglong Zhang, Shifei Ding...Jian Zhang</div><div><b>Pages:&nbsp;</b>7029 - 7041</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07101-z\">On differential lattices</a></div><div><b>Author(s):&nbsp;</b>Aiping Gan, Li Guo</div><div><b>Pages:&nbsp;</b>7043 - 7058</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07132-6\">A faster algorithm for identifying signals using complex fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>Madad Khan, Inamullah Khan...Sohail Iqbal</div><div><b>Pages:&nbsp;</b>7059 - 7079</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07172-y\">Trapezoidal approximation operators preserving the most indicators of fuzzy numbers-relationships and applications</a></div><div><b>Author(s):&nbsp;</b>M. Chehlabi</div><div><b>Pages:&nbsp;</b>7081 - 7105</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07150-4\">An introduction to single-valued neutrosophic soft topological structure</a></div><div><b>Author(s):&nbsp;</b>Yaser Saber, Fahad Alsharari, Florentin Smarandache</div><div><b>Pages:&nbsp;</b>7107 - 7122</div><div><br /></div><div><b>12) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07160-2\">An evidence combination rule based on a new weight assignment scheme</a></div><div><b>Author(s):&nbsp;</b>Yu-Cui Wang, Jian Wang...Ming-Hui Wang</div><div><b>Pages:&nbsp;</b>7123 - 7137</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07188-4\">A note on \u201cDealer using a new trapezoidal cubic hesitant fuzzy TOPSIS method and application to group decision-making program\u201d</a></div><div><b>Author(s):&nbsp;</b>S. S. Appadoo, Mohammadreza Makhan, Amit Kumar</div><div><b>Pages:&nbsp;</b>7139 - 7141</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07191-9\">Distributed energy-efficient clustering routing protocol for wireless sensor networks using affinity propagation and fuzzy logic</a></div><div><b>Author(s):&nbsp;</b>Chu-hang Wang, Huang-shui Hu...Jin-feng Zhang</div><div><b>Pages:&nbsp;</b>7143 - 7158</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07323-1\">Stability and admissibility analysis of T\u2013S descriptive systems and its applications</a></div><div><b>Author(s):&nbsp;</b>Muhammad Shamrooz Aslam, Ma Zhenhua...Abdul Majid</div><div><b>Pages:&nbsp;</b>7159 - 7166</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07190-w\">Quantum-enhanced filter: QFilter</a></div><div><b>Author(s):&nbsp;</b>Parfait Atchade-Adelomou, Guillermo Alonso-Linaje</div><div><b>Pages:&nbsp;</b>7167 - 7174</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07194-6\">Estimation of fault probability in medium voltage feeders through calibration techniques in classification models</a></div><div><b>Author(s):&nbsp;</b>Enrico De Santis, Francesco Arn\u00f2, Antonello Rizzi</div><div><b>Pages:&nbsp;</b>7175 - 7193</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07105-9\">Deep multiobjective design optimization of CFRP isogrid tubes using lichtenberg algorithm</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o Luiz Junho Pereira, Matheus Brendon Francisco...Guilherme Ferreira Gomes</div><div><b>Pages:&nbsp;</b>7195 - 7209</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07107-7\">An effective structure of multi-modal deep convolutional neural network with adaptive group teaching optimization</a></div><div><b>Author(s):&nbsp;</b>Vinit Gupta, Santosh Pawar</div><div><b>Pages:&nbsp;</b>7211 - 7232</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07109-5\">An enhanced Harris Hawk optimization algorithm for parameter estimation of single, double and triple diode photovoltaic models</a></div><div><b>Author(s):&nbsp;</b>Abdelhady Ramadan, Salah Kamel...Jose Luis Dom\u00ednguez-Garc\u00eda</div><div><b>Pages:&nbsp;</b>7233 - 7257</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07112-w\">A preference structure in multi-attribute decision making: an algorithmic approach based on hesitant fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>B. K. Mohanty, Eshika Aggarwal</div><div><b>Pages:&nbsp;</b>7259 - 7277</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07124-6\">Optimal autonomic management of service-based business processes in the cloud</a></div><div><b>Author(s):&nbsp;</b>Leila Hadded, Tarek Hamrouni</div><div><b>Pages:&nbsp;</b>7279 - 7291</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07139-z\">A novel hybrid gravitational and pattern search algorithm based MPPT controller with ANN and perturb and observe for photovoltaic system</a></div><div><b>Author(s):&nbsp;</b>Salem Alkhalaf, Ziad M. AliHitoshi Oikawa</div><div><b>Pages:&nbsp;</b>7293 - 7315</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06941-z\">Modeling stock market using new hybrid intelligent method based on MFNN and IBHA</a></div><div><b>Author(s):&nbsp;</b>Wei Gao</div><div><b>Pages:&nbsp;</b>7317 - 7337</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06964-6\">Evaluating and selecting agricultural insurance packages through an AHP-based fuzzy TOPSIS Method</a></div><div><b>Author(s):&nbsp;</b>Ta-Chung Chu, Thi Hong Phuong Le</div><div><b>Pages:&nbsp;</b>7339 - 7354</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07027-6\">Inclusion degree-based multigranulation rough fuzzy set over heterogeneous preference information and application to multiple attribute group decision making</a></div><div><b>Author(s):&nbsp;</b>Xinrui Zhang, Bingzhen Sun</div><div><b>Pages:&nbsp;</b>7355 - 7375</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07299-y\">Research on safety simulation model and algorithm of dynamic system based on artificial neural network</a></div><div><b>Author(s):&nbsp;</b>Guangna Zhang</div><div><b>Pages:&nbsp;</b>7377 - 7386</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07300-8\">Mobile robot path planning using multi-objective genetic algorithm in industrial automation</a></div><div><b>Author(s):&nbsp;</b>K. S. Suresh, R. Venkatesan, S. Venugopal</div><div><b>Pages:&nbsp;</b>7387 - 7400</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06677-2\">Toward in-flight Wi-Fi: a neuro-fuzzy based routing approach for Civil Aeronautical Ad hoc Network</a></div><div><b>Author(s):&nbsp;</b>T. Gurumekala, S. Indira Gandhi</div><div><b>Pages:&nbsp;</b>7401 - 7422</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06688-z\">CoupGAN: Chinese couplet generation via encoder\u2013decoder model and adversarial training under global control</a></div><div><b>Author(s):&nbsp;</b>Qian Qu, Jiancheng Lv...Kexin Yang</div><div><b>Pages:&nbsp;</b>7423 - 7433</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-07-14T10:56:00.001+12:00",
            "pubdate_parsed": 1657733160.0,
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 16, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-16.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07213-6\">Special issue on advances in pattern recognition and computer vision, applications and systems</a></div><div><b>Author(s): </b>M. Irfan Uddin</div><div><b>Pages: </b>7435 - 7436</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06439-0\">Analysis of industry convergence based on improved neural network</a></div><div><b>Author(s):&nbsp;</b>Nan Ma</div><div><b>Pages:&nbsp;</b>7437 - 7448</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06449-y\">Nucleus image segmentation method based on GAN and FCN model</a></div><div><b>Author(s):&nbsp;</b>Kai Zhang, Yang Shi...Hang Yu</div><div><b>Pages:&nbsp;</b>7449 - 7460</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06459-w\">A new color image encryption technique using DNA computing and Chaos-based substitution box</a></div><div><b>Author(s):&nbsp;</b>Fawad Masood, Junaid Masood...Jawad Ahmad</div><div><b>Pages:&nbsp;</b>7461 - 7477</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06465-y\">An evolutionary trajectory planning algorithm for multi-UAV-assisted MEC system</a></div><div><b>Author(s):&nbsp;</b>Muhammad Asim, Wali Khan Mashwani...Samir Brahim Belhaouari</div><div><b>Pages:&nbsp;</b>7479 - 7492</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06478-7\">Research on modeling of government debt risk comprehensive evaluation based on multidimensional data mining</a></div><div><b>Author(s):&nbsp;</b>Li Chao Ying, Wu Xiang Da, Zhao En Hui</div><div><b>Pages:&nbsp;</b>7493 - 7500</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06479-6\">Research on trade data encryption of tobacco enterprises based on adversarial neural network</a></div><div><b>Author(s):&nbsp;</b>Zhang Yi</div><div><b>Pages:&nbsp;</b>7501 - 7508</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06480-z\">Research on intelligent language translation system based on deep learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Chunliu Shi</div><div><b>Pages:&nbsp;</b>7509 - 7518</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06519-1\">Analyzing fibrous tissue pattern in fibrous dysplasia bone images using deep R-CNN networks for segmentation</a></div><div><b>Author(s):&nbsp;</b>A. Saranya, Kottilingam Kottursamy...Ali Kashif Bashir</div><div><b>Pages:&nbsp;</b>7519 - 7533</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06569-5\">Deep learning-based election results prediction using Twitter activity</a></div><div><b>Author(s):&nbsp;</b>Haider Ali, Haleem Farman...Adel Ammar</div><div><b>Pages:&nbsp;</b>7535 - 7543</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06581-9\">Q-method optimization of tunnel surrounding rock classification by fuzzy reasoning model and support vector machine</a></div><div><b>Author(s):&nbsp;</b>Feng Jiang, Peng He...Zhihan Lv</div><div><b>Pages:&nbsp;</b>7545 - 7558</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06585-5\">Analysis of the change of artificial intelligence to online consumption patterns and consumption concepts</a></div><div><b>Author(s):&nbsp;</b>Longyue Bai</div><div><b>Pages:&nbsp;</b>7559 - 7569</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06587-3\">Sparse representation optimization of Gaussian mixed feature of image based on convolution neural network</a></div><div><b>Author(s):&nbsp;</b>Yuguang Ye</div><div><b>Pages:&nbsp;</b>7571 - 7580</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06603-6\">Task-specific image summaries using semantic information and self-supervision</a></div><div><b>Author(s):&nbsp;</b>Deepak Kumar Sharma, Anurag Singh...Jerry Chun-Wei Lin</div><div><b>Pages:&nbsp;</b>7581 - 7594</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06612-5\">The study on life model of MOV based on various parameters and surge history</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Ruan, Shaoyun Jin...Weidong Cheng</div><div><b>Pages:&nbsp;</b>7595 - 7600</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06662-9\">Deep ensembling for perceptual image quality assessment</a></div><div><b>Author(s):&nbsp;</b>Nisar Ahmed, H. M. Shahzad Asif...Atif Khan</div><div><b>Pages:&nbsp;</b>7601 - 7622</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06705-1\">ConTEXT: context-aware adaptive SMS client for drivers to reduce risky driving behaviors</a></div><div><b>Author(s):&nbsp;</b>Inayat Khan, Shah Khusro</div><div><b>Pages:&nbsp;</b>7623 - 7640</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06706-0\">Design of robust deep learning-based object detection and classification model for autonomous driving applications</a></div><div><b>Author(s):&nbsp;</b>Mesfer Al Duhayyim, Fahd N. Al-Wesabi...Ashish Khanna</div><div><b>Pages:&nbsp;</b>7641 - 7652</div><div><br /></div><div><b>19) </b><a href=\"https://link.springer.com/article/10.1007/s00500-021-06707-z\">Gene Ontology GAN (GOGAN): a novel architecture for protein function prediction</a></div><div><b>Author(s):&nbsp;</b>Musadaq Mansoor, Mohammad Nauman...Alfredo Benso</div><div><b>Pages:&nbsp;</b>7653 - 7667</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06715-z\">The control mode study of PPP project financing management information system</a></div><div><b>Author(s):&nbsp;</b>Junli Cao, Lin Li</div><div><b>Pages:&nbsp;</b>7669 - 7675</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06869-4\">Correction to: The control mode study of PPP project financing management information system</a></div><div><b>Author(s):&nbsp;</b>Junli Cao, Lin Li</div><div><b>Pages:&nbsp;</b>7677 - 7677</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06734-4\">A comprehensive overview of AI-enabled music classification and its influence in games</a></div><div><b>Author(s):&nbsp;</b>Tiancheng Yang, Shah Nazir</div><div><b>Pages:&nbsp;</b>7679 - 7693</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06739-z\">Classification of Gurumukhi month\u2019s name images using various convolutional neural network optimizers</a></div><div><b>Author(s):&nbsp;</b>Tajinder Pal Singh, Sheifali Gupta...Atef Zaguia</div><div><b>Pages:&nbsp;</b>7695 - 7707</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06742-4\">Novel semi-supervised learning approach for descriptor generation using artificial neural networks</a></div><div><b>Author(s):&nbsp;</b>Alla Fikrat Alwindawi, Osman Nuri U\u00e7an...Aminu Yusuf</div><div><b>Pages:&nbsp;</b>7709 - 7720</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06750-4\">Hybrid deep-learning model to detect botnet attacks over internet of things environments</a></div><div><b>Author(s):&nbsp;</b>Mohammed Y. Alzahrani, Alwi M. Bamhdi</div><div><b>Pages:&nbsp;</b>7721 - 7735</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06755-z\">Machine health surveillance system by using deep learning sparse autoencoder</a></div><div><b>Author(s):&nbsp;</b>Faizan Ullah, Abdu Salam...Wael Alosaimi</div><div><b>Pages:&nbsp;</b>7737 - 7750</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06762-0\">Diagnosis and classification of Alzheimer's disease by using a convolution neural network algorithm</a></div><div><b>Author(s):&nbsp;</b>Mosleh Hmoud Al-Adhaileh</div><div><b>Pages:&nbsp;</b>7751 - 7762</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06773-x\">Machine learning for fake news classification with optimal feature selection</a></div><div><b>Author(s):&nbsp;</b>Muhammad Fayaz, Atif Khan...Sana Ullah Khan</div><div><b>Pages:&nbsp;</b>7763 - 7771</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06775-9\">Application and Analysis of Computer Network Technology in Electronic Information Engineering</a></div><div><b>Author(s):&nbsp;</b>Wanjie Kang, Jie Xiao</div><div><b>Pages:&nbsp;</b>7773 - 7779</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06781-x\">Research and application of GIS and data mining technology in monitoring and assessment of natural geography environment</a></div><div><b>Author(s):&nbsp;</b>Fuheng Zhang, Guangbin Ji...Guihua Liu</div><div><b>Pages:&nbsp;</b>7781 - 7787</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06794-6\">Extracting built-up areas from spectro-textural information using machine learning</a></div><div><b>Author(s):&nbsp;</b>Ahsen Maqsoom, Bilal Aslam...Muhammad Imran</div><div><b>Pages:&nbsp;</b>7789 - 7808</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06796-4\">The traditional settlement planning and the renovation of residential buildings based on spatial syntax analysis</a></div><div><b>Author(s):&nbsp;</b>Kaifeng Chu, Mengyu Wu</div><div><b>Pages:&nbsp;</b>7809 - 7815</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06804-7\">Efficient facial emotion recognition model using deep convolutional neural network and modified joint trilateral filter</a></div><div><b>Author(s):&nbsp;</b>Naveen Kumari, Rekha Bhatia</div><div><b>Pages:&nbsp;</b>7817 - 7830</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06805-6\">Convolutional neural network based hurricane damage detection using satellite images</a></div><div><b>Author(s):&nbsp;</b>Swapandeep Kaur, Sheifali Gupta...Atef Zaguia</div><div><b>Pages:&nbsp;</b>7831 - 7845</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06806-5\">Fake opinion detection in an e-commerce business based on a long-short memory algorithm</a></div><div><b>Author(s):&nbsp;</b>Nizar Alsharif</div><div><b>Pages:&nbsp;</b>7847 - 7854</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06811-8\">Visual design elements based on digital visualization</a></div><div><b>Author(s):&nbsp;</b>Lei Jiang</div><div><b>Pages:&nbsp;</b>7855 - 7863</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06812-7\">Analysis of transmission line icing prediction based on CNN and data mining technology</a></div><div><b>Author(s):&nbsp;</b>Lixue Li, Da Luo, Wenhao Yao</div><div><b>Pages:&nbsp;</b>7865 - 7870</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06813-6\">Computer application under the management of network information security technology using genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xu Jian Qiang</div><div><b>Pages:&nbsp;</b>7871 - 7876</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06830-5\">Software defect prediction employing BiLSTM and BERT-based semantic feature</a></div><div><b>Author(s):&nbsp;</b>Md Nasir Uddin, Bixin Li...Islam Zada</div><div><b>Pages:&nbsp;</b>7877 - 7891</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06845-y\">An effective nonlocal means image denoising framework based on non-subsampled shearlet transform</a></div><div><b>Author(s):&nbsp;</b>Bhawna Goyal, Ayush Dogra, Arun Kumar Sangaiah</div><div><b>Pages:&nbsp;</b>7893 - 7915</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06849-8\">The study of physical education evaluation based on a fuzzy stochastic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xiuyan Su</div><div><b>Pages:&nbsp;</b>7917 - 7923</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06851-0\">Conceptual model construction of building information management system based on BIM architecture</a></div><div><b>Author(s):&nbsp;</b>Jiang Haiying</div><div><b>Pages:&nbsp;</b>7925 - 7931</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06853-y\">Perceptual adversarial non-residual learning for blind image denoising</a></div><div><b>Author(s):&nbsp;</b>Aamir Khan, Weidong Jin, Rizwan Ali Naqvi</div><div><b>Pages:&nbsp;</b>7933 - 7957</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06855-w\">Research on the optimization of communication protocol in network security protocol</a></div><div><b>Author(s):&nbsp;</b>Daoyuan Sun</div><div><b>Pages:&nbsp;</b>7959 - 7966</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06859-6\">Multi-scale local-global architecture for person re-identification</a></div><div><b>Author(s):&nbsp;</b>Jing Liu, Prayag Tiwari...Shahab S. Band</div><div><b>Pages:&nbsp;</b>7967 - 7977</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06900-8\">Optimal feature extraction and ulcer classification from WCE image data using deep learning</a></div><div><b>Author(s):&nbsp;</b>Youssef Masmoudi, Muhammad Ramzan...Mohammed Habib</div><div><b>Pages:&nbsp;</b>7979 - 7992</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06901-7\">A communication security anti-interference decision model using deep learning in intelligent industrial IoT environment</a></div><div><b>Author(s):&nbsp;</b>Lichao Yan, Juan Hu...Jinhong Di</div><div><b>Pages:&nbsp;</b>7993 - 8002</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06990-4\">Smoke removal and image enhancement of laparoscopic images by an artificial multi-exposure image fusion method</a></div><div><b>Author(s):&nbsp;</b>Muhammad Adeel Azam, Khan Bahadar Khan...Sana Ullah Khan</div><div><b>Pages:&nbsp;</b>8003 - 8015</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06996-y\">Predicting the spread of COVID-19 with a machine learning technique and multiplicative calculus</a></div><div><b>Author(s):&nbsp;</b>B\u00fclent Bilgehan, Ali \u00d6zyap\u0131c\u0131...Yusuf Gurefe</div><div><b>Pages:&nbsp;</b>8017 - 8024</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07047-2\">Fusion of multi-modality biomedical images using deep neural networks</a></div><div><b>Author(s):&nbsp;</b>Manish Gupta, Naresh Kumar...Atef Zaguia</div><div><b>Pages:&nbsp;</b>8025 - 8036</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07058-z\">Rotating object detection in remote-sensing environment</a></div><div><b>Author(s):&nbsp;</b>Sixian Chan, Jingcheng Zheng...Kai Fang</div><div><b>Pages:&nbsp;</b>8037 - 8045</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07062-3\">Analyzing the interactions among factors affecting cloud adoption for software testing: a two-stage ISM-ANN approach</a></div><div><b>Author(s):&nbsp;</b>Sikandar Ali, Samad Baseer...Jiwei Huang</div><div><b>Pages:&nbsp;</b>8047 - 8075</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07064-1\">A probabilistic approach toward evaluation of Internet rumor on COVID</a></div><div><b>Author(s):&nbsp;</b>Yancheng Yang, Shah Nazir, Wajeeha Khalil</div><div><b>Pages:&nbsp;</b>8077 - 8088</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07142-4\">Single-image reconstruction using novel super-resolution technique for large-scaled images</a></div><div><b>Author(s):&nbsp;</b>Ramanath Datta, Sekhar Mandal...Jazem Mutared Alanazi</div><div><b>Pages:&nbsp;</b>8089 - 8103</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07155-z\">Hybrid optimisation-based robust watermarking using denoising convolutional neural network</a></div><div><b>Author(s):&nbsp;</b>Dhiran Kumar Mahto, Ashima Anand, Amit Kumar Singh</div><div><b>Pages:&nbsp;</b>8105 - 8116</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07169-7\">Constrained optimization based on hybrid version of superiority of feasibility solution strategy</a></div><div><b>Author(s):&nbsp;</b>Asia Noureen, Wali Khan Mashwani...Muhammad Asim</div><div><b>Pages:&nbsp;</b>8117 - 8132</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07204-7\">An adaptive genetic algorithm-based background elimination model for English text</a></div><div><b>Author(s):&nbsp;</b>Tang Xiaohui</div><div><b>Pages:&nbsp;</b>8133 - 8143</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-07-18T12:16:00.000+12:00",
            "pubdate_parsed": 1658083560.0,
            "email_sent": true
        },
        "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 7, July 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-neural-networks.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9311226/\">The Heidelberg Spiking Data Sets for the Systematic Evaluation of Spiking Neural Networks</a></div><div><b>Author(s): </b>Benjamin Cramer, Yannik Stradmann, Johannes Schemmel, Friedemann Zenke</div><div><b>Pages: </b>2744 - 2757</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9312438/\">Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding</a></div><div><b>Author(s):&nbsp;</b>Qingxing Cao, Bailin Li, Xiaodan Liang, Keze Wang, Liang Lin</div><div><b>Pages:&nbsp;</b>2758 - 2767</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9311244/\">Stabilizing Training of Generative Adversarial Nets via Langevin Stein Variational Gradient Descent</a></div><div><b>Author(s):&nbsp;</b>Dong Wang, Xiaoqian Qin, Fengyi Song, Li Cheng</div><div><b>Pages:&nbsp;</b>2768 - 2780</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9316912/\">Reinforcement Learning and Adaptive Optimal Control for Continuous-Time Nonlinear Systems: A Value Iteration Approach</a></div><div><b>Author(s):&nbsp;</b>Tao Bian, Zhong-Ping Jiang</div><div><b>Pages:&nbsp;</b>2781 - 2790</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9314928/\">Parameterized Luenberger-Type H\u221e State Estimator for Delayed Static Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Yongsik Jin, Wookyong Kwon, Sangmoon Lee</div><div><b>Pages:&nbsp;</b>2791 - 2800</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9319553/\">BiCoSS: Toward Large-Scale Cognition Brain With Multigranular Neuromorphic Architecture</a></div><div><b>Author(s):&nbsp;</b>Shuangming Yang, Jiang Wang, Xinyu Hao, Huiyan Li, Xile Wei, Bin Deng, Kenneth A. Loparo</div><div><b>Pages:&nbsp;</b>2801 - 2815</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9317707/\">Causal Discovery in Linear Non-Gaussian Acyclic Model With Multiple Latent Confounders</a></div><div><b>Author(s):&nbsp;</b>Wei Chen, Ruichu Cai, Kun Zhang, Zhifeng Hao</div><div><b>Pages:&nbsp;</b>2816 - 2827</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9319566/\">A Study on Truncated Newton Methods for Linear Classification</a></div><div><b>Author(s):&nbsp;</b>Leonardo Galli, Chih-Jen Lin</div><div><b>Pages:&nbsp;</b>2828 - 2841</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9324979/\">Agglomerative Neural Networks for Multiview Clustering</a></div><div><b>Author(s):&nbsp;</b>Zhe Liu, Yun Li, Lina Yao, Xianzhi Wang, Feiping Nie</div><div><b>Pages:&nbsp;</b>2842 - 2852</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9321210/\">Low-Latency <i>In Situ</i> Image Analytics With FPGA-Based Quantized Convolutional Neural Network</a></div><div><b>Author(s):&nbsp;</b>Maolin Wang, Kelvin C. M. Lee, Bob M. F. Chung, Sharatchandra Varma Bogaraju, Ho-Cheung Ng, Justin S. J. Wong, Ho Cheung Shum, Kevin K. Tsia, Hayden Kwok-Hay So</div><div><b>Pages:&nbsp;</b>2853 - 2866</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9325083/\">Adaptive Optimal Control for Unknown Constrained Nonlinear Systems With a Novel Quasi-Model Network</a></div><div><b>Author(s):&nbsp;</b>Xiumei Han, Xudong Zhao, Hamid Reza Karimi, Ding Wang, Guangdeng Zong</div><div><b>Pages:&nbsp;</b>2867 - 2878</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9316921/\">A Hybrid Residual Dilated LSTM and Exponential Smoothing Model for Midterm Electric Load Forecasting</a></div><div><b>Author(s):&nbsp;</b>Grzegorz Dudek, Pawe\u0142 Pe\u0142ka, Slawek Smyl</div><div><b>Pages:&nbsp;</b>2879 - 2891</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9344620/\">Observer-Based Fixed-Time Neural Control for a Class of Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Yan Zhang, Fang Wang</div><div><b>Pages:&nbsp;</b>2892 - 2902</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9335504/\">Generalized Zero-Shot Learning With Multiple Graph Adaptive Generative Networks</a></div><div><b>Author(s):&nbsp;</b>Guo-Sen Xie, Zheng Zhang, Guoshuai Liu, Fan Zhu, Li Liu, Ling Shao, Xuelong Li</div><div><b>Pages:&nbsp;</b>2903 - 2915</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9319541/\">mCRF and mRD: Two Classification Methods Based on a Novel Multiclass Label Noise Filtering Learning Framework</a></div><div><b>Author(s):&nbsp;</b>Shuyin Xia, Baiyun Chen, Guoyin Wang, Yong Zheng, Xinbo Gao, Elisabeth Giem, Zizhong Chen</div><div><b>Pages:&nbsp;</b>2916 - 2930</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9325091/\">Observer Design for Sampled-Data Systems via Deterministic Learning</a></div><div><b>Author(s):&nbsp;</b>Jingtao Hu, Weiming Wu, Bing Ji, Cong Wang</div><div><b>Pages:&nbsp;</b>2931 - 2939</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9324926/\">Dynamically Weighted Balanced Loss: Class Imbalanced Learning and Confidence Calibration of Deep Neural Networks</a></div><div><b>Author(s):&nbsp;</b>K. Ruwani M. Fernando, Chris P. Tsokos</div><div><b>Pages:&nbsp;</b>2940 - 2951</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9328160/\">Broad Learning With Reinforcement Learning Signal Feedback: Theory and Applications</a></div><div><b>Author(s):&nbsp;</b>Ruiqi Mao, Rongxin Cui, C. L. Philip Chen</div><div><b>Pages:&nbsp;</b>2952 - 2964</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9324947/\">Neural-Network-Based Distributed Asynchronous Event-Triggered Consensus Tracking of a Class of Uncertain Nonlinear Multi-Agent Systems</a></div><div><b>Author(s):&nbsp;</b>Yun Ho Choi, Sung Jin Yoo</div><div><b>Pages:&nbsp;</b>2965 - 2979</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9325069/\">Active Learning With Multiple Kernels</a></div><div><b>Author(s):&nbsp;</b>Songnam Hong, Jeongmin Chae</div><div><b>Pages:&nbsp;</b>2980 - 2994</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9325927/\">Dissipativity-Based Finite-Time Filtering for Uncertain Semi-Markovian Jump Random Systems With Multiple Time Delays and State Constraints</a></div><div><b>Author(s):&nbsp;</b>Shaoxin Sun, Huaguang Zhang, Jian Han, Juan Zhang</div><div><b>Pages:&nbsp;</b>2995 - 3009</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9325537/\">PID Controller-Guided Attention Neural Network Learning for Fast and Effective Real Photographs Denoising</a></div><div><b>Author(s):&nbsp;</b>Ruijun Ma, Bob Zhang, Yicong Zhou, Zhengming Li, Fangyuan Lei</div><div><b>Pages:&nbsp;</b>3010 - 3023</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9325549/\">A Novel Feature Selection Method for High-Dimensional Mixed Decision Tables</a></div><div><b>Author(s):&nbsp;</b>Nguyen Ngoc Thuy, Sartra Wongthanavasu</div><div><b>Pages:&nbsp;</b>3024 - 3037</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9325918/\">Spatio-Spectral Feature Representation for Motor Imagery Classification Using Convolutional Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Ji-Seon Bang, Min-Ho Lee, Siamac Fazli, Cuntai Guan, Seong-Whan Lee</div><div><b>Pages:&nbsp;</b>3038 - 3049</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9366422/\">MetaMixUp: Learning Adaptive Interpolation Policy of MixUp With Metalearning</a></div><div><b>Author(s):&nbsp;</b>Zhijun Mai, Guosheng Hu, Dexiong Chen, Fumin Shen, Heng Tao Shen</div><div><b>Pages:&nbsp;</b>3050 - 3064</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9334415/\">An Efficient Sparse Bayesian Learning Algorithm Based on Gaussian-Scale Mixtures</a></div><div><b>Author(s):&nbsp;</b>Wei Zhou, Hai-Tao Zhang, Jun Wang</div><div><b>Pages:&nbsp;</b>3065 - 3078</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9340559/\">Efficient Approximation of High-Dimensional Functions With Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Patrick Cheridito, Arnulf Jentzen, Florian Rossmannek</div><div><b>Pages:&nbsp;</b>3079 - 3093</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9337198/\">Synaptic Scaling\u2014An Artificial Neural Network Regularization Inspired by Nature</a></div><div><b>Author(s):&nbsp;</b>Martin Hofmann, Patrick M\u00e4der</div><div><b>Pages:&nbsp;</b>3094 - 3108</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9340575/\">Observer-Based Adaptive Synchronization of Multiagent Systems With Unknown Parameters Under Attacks</a></div><div><b>Author(s):&nbsp;</b>Shiping Wen, Xiaoze Ni, Huamin Wang, Song Zhu, Kaibo Shi, Tingwen Huang</div><div><b>Pages:&nbsp;</b>3109 - 3119</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9336287/\">Explicit Duration Recurrent Networks</a></div><div><b>Author(s):&nbsp;</b>Shun-Zheng Yu</div><div><b>Pages:&nbsp;</b>3120 - 3130</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9336267/\">Observer-Based Neuro-Adaptive Optimized Control of Strict-Feedback Nonlinear Systems With State Constraints</a></div><div><b>Author(s):&nbsp;</b>Yongming Li, Yanjun Liu, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>3131 - 3145</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9494037/\">Granger Causality Inference in EEG Source Connectivity Analysis: A State-Space Approach</a></div><div><b>Author(s):&nbsp;</b>Parinthorn Manomaisaowapak, Anawat Nartkulpat, Jitkomut Songsiri</div><div><b>Pages:&nbsp;</b>3146 - 3156</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9410428/\">Rank Consistency Induced Multiview Subspace Clustering via Low-Rank Matrix Factorization</a></div><div><b>Author(s):&nbsp;</b>Jipeng Guo, Yanfeng Sun, Junbin Gao, Yongli Hu, Baocai Yin</div><div><b>Pages:&nbsp;</b>3157 - 3170</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9316932/\">Data-Driven-Based Event-Triggered Control for Nonlinear CPSs Against Jamming Attacks</a></div><div><b>Author(s):&nbsp;</b>Yingchun Wang, Xiaojie Qiu, Huaguang Zhang, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3171 - 3177</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9333591/\">Sequence Learning in a Single Trial: A Spiking Neurons Model Based on Hippocampal Circuitry</a></div><div><b>Author(s):&nbsp;</b>Simone Coppolino, Giuseppe Giacopelli, Michele Migliore</div><div><b>Pages:&nbsp;</b>3178 - 3183</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9340604/\">DNN-kWTA With Bounded Random Offset Voltage Drifts in Threshold Logic Units</a></div><div><b>Author(s):&nbsp;</b>Wenhao Lu, Chi-Sing Leung, John Sum, Yi Xiao</div><div><b>Pages:&nbsp;</b>3184 - 3192</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-07-20T15:09:00.000+12:00",
            "pubdate_parsed": 1658266740.0,
            "email_sent": true
        },
        "Upcoming Special Issues": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/upcoming-special-issues.html",
            "description": "<div style=\"text-align: left;\"><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><b>IEEE Computational Intelligence Magazine</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/cim/CIM-SI-MLEMO_CFP.pdf\">Machine Learning Assisted Evolutionary Multi-Objective Optimization</a> - <u>September 1, 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/TNNLS_SI_CFP.pdf\">Explainable and Generalizable Deep Learning for Medical Imaging</a> -&nbsp;<u>1 September 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/202202-Explainable_Representation_Learning-based_Intelligent_Inspection_and_Maintenance_of_Complex_Systems.pdf\">Explainable Representation Learning-based Intelligent Inspection and Maintenance of Complex Systems</a> -&nbsp;<u>1 September 2022</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Cognitive_Learning_of_Multi-Agent_Systems-IEEE_TCDS-CFP-20211210.pdf\">Cognitive Learning of Multi-Agent Systems</a> -&nbsp;<u>September 30, 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Publications/TNNLS/special-issues/proposal_TNNLS_2.27_new.pdf\">Information Theoretic Methods for the Generalization, Robustness and Interpretability of Machine Learning</a> -&nbsp;<u>1 October 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/New_SI.pdf\">Deep Learning for Intelligent Media Computing and Applications</a> -&nbsp;<u>30 October 2022</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Movement_Sciences_in_Cognitive_Systems_CFP_2022.pdf\">Movement Sciences in Cognitive Systems</a> -&nbsp;<u>6 January 2023</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Advancing_Machine_Intelligence_with_Neuromorphic_Computing-CFP2022.pdf\">Advancing Machine Intelligence with Neuromorphic Computing</a> -&nbsp;<u>31 January 2023</u></li><li><b>IEEE Transactions on Emerging Topics in Computational Intelligence</b> - <a href=\"https://cis.ieee.org/images/files/Publications/TETCI/SI26_CFP_RSCAI.pdf\">Resource Sustainable Computational and Artificial Intelligence</a> -&nbsp;<u>1 February 2023</u></li></ul></div><div><br /></div></div>",
            "pubdate": "2022-07-21T12:00:00.001+12:00",
            "pubdate_parsed": 1658341800.0,
            "email_sent": true
        },
        "IEEE Transactions on Emerging Topics in Computational Intelligence, Volume 6, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-emerging-topics-in.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9834992/\">Guest Editorial Special Issue on Computational Intelligence for IoT-based Human Activity Recognition</a></div><div><b>Author(s): </b>Xiaoli Li, Huanhuan Chen, Thomas Ploetz, Min Wu, Zhenghua Chen</div><div><b>Pages: </b>725 - 727</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9546996/\">Evolutionary Dual-Ensemble Class Imbalance Learning for Human Activity Recognition</a></div><div><b>Author(s):&nbsp;</b>Yinan Guo, Yaoqi Chu, Botao Jiao, Jian Cheng, Zekuan Yu, Ning Cui, Lianbo Ma</div><div><b>Pages:&nbsp;</b>728 - 739</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9720134/\">Real-Time Activities of Daily Living Recognition Under Long-Tailed Class Distribution</a></div><div><b>Author(s):&nbsp;</b>Atul Chaudhary, Hari Prabhat Gupta, K. K. Shukla</div><div><b>Pages:&nbsp;</b>740 - 750</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9724169/\">MOCLoc: Emerging Online Collaborative Localization Enhanced by Multidimensional Scaling</a></div><div><b>Author(s):&nbsp;</b>Chanxin Zhou, Bang Wang, Yijun Mo, Zeng Zeng</div><div><b>Pages:&nbsp;</b>751 - 761</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9779097/\">Trends and Prospects of Techniques for Haze Removal From Degraded Images: A Survey</a></div><div><b>Author(s):&nbsp;</b>Geet Sahu, Ayan Seal, Debotosh Bhattacharjee, Mita Nasipuri, Peter Brida, Ondrej Krejcar</div><div><b>Pages:&nbsp;</b>762 - 782</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9686068/\">Evolutionary Architectural Search for Generative Adversarial Networks</a></div><div><b>Author(s):&nbsp;</b>Qiuzhen Lin, Zhixiong Fang, Yi Chen, Kay Chen Tan, Yun Li</div><div><b>Pages:&nbsp;</b>783 - 794</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9600838/\">Generating Black-Box Adversarial Examples in Sparse Domain</a></div><div><b>Author(s):&nbsp;</b>Hadi Zanddizari, Behnam Zeinali, J. Morris Chang</div><div><b>Pages:&nbsp;</b>795 - 804</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9472875/\">A Novel Evolutionary Algorithm Based on Judgment-Rule Evolution Strategy for Structural Balance in Signed Social Networks</a></div><div><b>Author(s):&nbsp;</b>Mingzhou Yang, Xingwei Wang, Min Huang, Lianbo Ma, Qiang He</div><div><b>Pages:&nbsp;</b>805 - 817</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9582815/\">Multiobjective Multitasking Optimization With Subspace Distribution Alignment and Decision Variable Transfer</a></div><div><b>Author(s):&nbsp;</b>Weifeng Gao, Jiangli Cheng, Maoguo Gong, Hong Li, Jin Xie</div><div><b>Pages:&nbsp;</b>818 - 827</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9564251/\">Transfer Clustering Using a Multiple Kernel Metric Learned Under Multi-Instance Weak Supervision</a></div><div><b>Author(s):&nbsp;</b>Avisek Gupta, Swagatam Das</div><div><b>Pages:&nbsp;</b>828 - 838</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9615029/\">Dynamic Path Planning for Unmanned Aerial Vehicles Under Deadline and Sector Capacity Constraints</a></div><div><b>Author(s):&nbsp;</b>Sudharsan Vaidhun, Zhishan Guo, Jiang Bian, Haoyi Xiong, Sajal K. Das</div><div><b>Pages:&nbsp;</b>839 - 851</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9586052/\">A Robust Non-Integer Controller Design for Load Frequency Control in Modern Marine Power Grids</a></div><div><b>Author(s):&nbsp;</b>B. Yildirim, M. Gheisarnejad, M. H. Khooban</div><div><b>Pages:&nbsp;</b>852 - 866</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9586057/\">A Weighted Portfolio Optimization Model Based on the Trend Ratio, Emotion Index, and ANGQTS</a></div><div><b>Author(s):&nbsp;</b>Yao-Hsin Chou, Yu-Chi Jiang, Yi-Rui Hsu, Shu-Yu Kuo, Sy-Yen Kuo</div><div><b>Pages:&nbsp;</b>867 - 882</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9671053/\">Do Models Learn the Directionality of Relations? A New Evaluation: Relation Direction Recognition</a></div><div><b>Author(s):&nbsp;</b>Shengfei Lyu, Xingyu Wu, Jinlong Li, Qiuju Chen, Huanhuan Chen</div><div><b>Pages:&nbsp;</b>883 - 892</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9628017/\">Quaternion Capsule Neural Network With Region Attention for Facial Expression Recognition in Color Images</a></div><div><b>Author(s):&nbsp;</b>Yu Zhou, Lianghai Jin, Guangzhi Ma, Xiangyang Xu</div><div><b>Pages:&nbsp;</b>893 - 912</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9475074/\">Unbalanced Incomplete Multi-View Clustering Via the Scheme of View Evolution: Weak Views are Meat,&nbsp; Strong Views Do Eat</a></div><div><b>Author(s):&nbsp;</b>Xiang Fang, Yuchong Hu, Pan Zhou, Dapeng Oliver Wu</div><div><b>Pages:&nbsp;</b>913 - 927</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9655256/\">EDITH : ECG Biometrics Aided by Deep Learning for Reliable Individual Authentication</a></div><div><b>Author(s):&nbsp;</b>Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, Tawsifur Rahman</div><div><b>Pages:&nbsp;</b>928 - 940</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9576096/\">Efficient Privacy Preserving Edge Intelligent Computing Framework for Image Classification in IoT</a></div><div><b>Author(s):&nbsp;</b>Omobayode Fagbohungbe, Sheikh Rufsan Reza, Xishuang Dong, Lijun Qian</div><div><b>Pages:&nbsp;</b>941 - 956</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9583676/\">APNet: Adversarial Learning Assistance and Perceived Importance Fusion Network for All-Day RGB-T Salient Object Detection</a></div><div><b>Author(s):&nbsp;</b>Wujie Zhou, Yun Zhu, Jingsheng Lei, Jian Wan, Lu Yu</div><div><b>Pages:&nbsp;</b>957 - 968</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9615378/\">A Novel Test Case Generation Approach for Adaptive Random Testing of Object-Oriented Software Using K-Means Clustering Technique</a></div><div><b>Author(s):&nbsp;</b>Jinfu Chen, Haibo Chen, Yuchi Guo, Minmin Zhou, Rubing Huang, Chengying Mao</div><div><b>Pages:&nbsp;</b>969 - 981</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9772749/\">Data Embedding Scheme for Efficient Program Behavior Modeling With Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Sunwoo Ahn, Hayoon Yi, Ho Bae, Sungroh Yoon, Yunheung Paek</div><div><b>Pages:&nbsp;</b>982 - 993</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9704877/\">Half Quadratic Dual Learning for Fuzzy Multiconcepts of Partially-Observed Images</a></div><div><b>Author(s):&nbsp;</b>Bo-Wei Chen, Kuan-Lin Hou</div><div><b>Pages:&nbsp;</b>994 - 1007</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9712322/\">Obtaining Fuzzy Membership Function of Clusters With the Memristor Hardware Implementation and On-Chip Learning</a></div><div><b>Author(s):&nbsp;</b>Mohammad Javadian, Arian Hejazi, Sajad Haghzad Klidbary</div><div><b>Pages:&nbsp;</b>1008 - 1025</div><div><br /></div>",
            "pubdate": "2022-07-29T12:00:00.001+12:00",
            "pubdate_parsed": 1659033000.0,
            "email_sent": true
        },
        "IEEE Transactions on Artificial Intelligence, Volume 3, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-artificial.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9591342/\">Balanced Graph Cut With Exponential Inter-Cluster Compactness</a></div><div><b>Author(s): </b>Danyang Wu, Feiping Nie, Jitao Lu, Rong Wang, Xuelong Li</div><div><b>Pages: </b>498 - 505</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9695289/\">Efficient Temporal Piecewise-Linear Numeric Planning With Lazy Consistency Checking</a></div><div><b>Author(s):&nbsp;</b>Josef Bajada, Maria Fox, Derek Long</div><div><b>Pages:&nbsp;</b>506 - 517</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9612034/\">Ignorance is Bliss: Exploring Defenses Against Invariance-Based Attacks on Neural Machine Translation Systems</a></div><div><b>Author(s):&nbsp;</b>Akshay Chaturvedi, Abhisek Chakrabarty, Masao Utiyama, Eiichiro Sumita, Utpal Garain</div><div><b>Pages:&nbsp;</b>518 - 525</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9618852/\">ArcText: A Unified Text Approach to Describing Convolutional Neural Network Architectures</a></div><div><b>Author(s):&nbsp;</b>Yanan Sun, Gary G. Yen, Bing Xue, Mengjie Zhang, Jiancheng Lv</div><div><b>Pages:&nbsp;</b>526 - 540</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9652037/\">Histogram Layers for Texture Analysis</a></div><div><b>Author(s):&nbsp;</b>Joshua Peeples, Weihuang Xu, Alina Zare</div><div><b>Pages:&nbsp;</b>541 - 552</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9613742/\">Traded Control of Human\u2013Machine Systems for Sequential Decision-Making Based on Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Qianqian Zhang, Yu Kang, Yun-Bo Zhao, Pengfei Li, Shiyi You</div><div><b>Pages:&nbsp;</b>553 - 566</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9612040/\">Potential Impacts of Smart Homes on Human Behavior: A Reinforcement Learning Approach</a></div><div><b>Author(s):&nbsp;</b>Shashi Suman, Ali Etemad, Francois Rivest</div><div><b>Pages:&nbsp;</b>567 - 580</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9612064/\">Multiadvisor Reinforcement Learning for Multiagent Multiobjective Smart Home Energy Control</a></div><div><b>Author(s):&nbsp;</b>Andrew Tittaferrante, Abdulsalam Yassine</div><div><b>Pages:&nbsp;</b>581 - 594</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9614997/\">On a Sparse Shortcut Topology of Artificial Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Feng-Lei Fan, Dayang Wang, Hengtao Guo, Qikui Zhu, Pingkun Yan, Ge Wang, Hengyong Yu</div><div><b>Pages:&nbsp;</b>595 - 608</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9594655/\">CSNAS: Contrastive Self-Supervised Learning Neural Architecture Search Via Sequential Model-Based Optimization</a></div><div><b>Author(s):&nbsp;</b>Nam Nguyen, J. Morris Chang</div><div><b>Pages:&nbsp;</b>609 - 624</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9652108/\">Perturbed Composite Attention Model for Macular Optical Coherence Tomography Image Classification</a></div><div><b>Author(s):&nbsp;</b>Sapna S. Mishra, Bappaditya Mandal, Niladri B. Puhan</div><div><b>Pages:&nbsp;</b>625 - 635</div><div><br /></div>",
            "pubdate": "2022-07-30T12:00:00.041+12:00",
            "pubdate_parsed": 1659119400.0,
            "email_sent": true
        },
        "Complex and Intelligent Systems, Volume 8, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/complex-and-intelligent-systems-volume.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00766-x\">Evolutionary optimization of large complex problems</a></div><div><b>Author(s): </b>Handing Wang, Chaoli Sun...Yew-soon Ong</div><div><b>Pages: </b>2697 - 2698</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00249-x\">Surrogate-assisted evolutionary algorithm for expensive constrained multi-objective discrete optimization problems</a></div><div><b>Author(s):&nbsp;</b>Qinghua Gu, Qian Wang...Lu Chen</div><div><b>Pages:&nbsp;</b>2699 - 2718</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00352-7\">Accelerate the optimization of large-scale manufacturing planning using game theory</a></div><div><b>Author(s):&nbsp;</b>Hui-Ling Zhen, Zhenkun Wang...Jia Zeng</div><div><b>Pages:&nbsp;</b>2719 - 2730</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00374-1\">fSDE: efficient evolutionary optimisation for many-objective aero-engine calibration</a></div><div><b>Author(s):&nbsp;</b>Jialin Liu, Qingquan Zhang...Feng Wu</div><div><b>Pages:&nbsp;</b>2731 - 2747</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00402-0\">Simplified Phasmatodea population evolution algorithm for optimization</a></div><div><b>Author(s):&nbsp;</b>Pei-Cheng Song, Shu-Chuan Chu...Hongmei Yang</div><div><b>Pages:&nbsp;</b>2749 - 2767</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00452-4\">Two-stage improved Grey Wolf optimization algorithm for feature selection on high-dimensional classification</a></div><div><b>Author(s):&nbsp;</b>Chaonan Shen, Kai Zhang</div><div><b>Pages:&nbsp;</b>2769 - 2789</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00510-x\">A hybrid ant lion optimization chicken swarm optimization algorithm for charger placement problem</a></div><div><b>Author(s):&nbsp;</b>Sanchari Deb, Xiao-Zhi Gao</div><div><b>Pages:&nbsp;</b>2791 - 2808</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00773-y\">Robotic dexterous manipulation: from tele-operation to autonomous learning and adaptive control</a></div><div><b>Author(s):&nbsp;</b>Qiang Li, Chao Liu...Helge Ritter</div><div><b>Pages:&nbsp;</b>2809 - 2811</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00341-w\">Lower limb movement intention recognition for rehabilitation robot aided with projected recurrent neural network</a></div><div><b>Author(s):&nbsp;</b>Mei Liu, Bo Peng, Mingsheng Shang</div><div><b>Pages:&nbsp;</b>2813 - 2824</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00333-w\">Approach to hand posture recognition based on hand shape features for human\u2013robot interaction</a></div><div><b>Author(s):&nbsp;</b>Jing Qi, Kun Xu, Xilun Ding</div><div><b>Pages:&nbsp;</b>2825 - 2842</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00350-9\">Development and evaluation of demonstration information recording approach for wheelchair mounted robotic arm</a></div><div><b>Author(s):&nbsp;</b>Mingshan Chi, Yaxin Liu...Ming Zhong</div><div><b>Pages:&nbsp;</b>2843 - 2857</div><div><br /></div><div><b>12) </b><a href=\"https://link.springer.com/article/10.1007/s40747-021-00420-y\">Towards a balancing safety against performance approach in human\u2013robot co-manipulation for door-closing emergencies</a></div><div><b>Author(s):&nbsp;</b>Chuande Liu, Chuang Yu...Adriana Tapus</div><div><b>Pages:&nbsp;</b>2859 - 2871</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00429-3\">DMPs-based skill learning for redundant dual-arm robotic synchronized cooperative manipulation</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Lu, Ning Wang, Donghao Shi</div><div><b>Pages:&nbsp;</b>2873 - 2882</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00418-6\">Incorporating model predictive control with fuzzy approximation for robot manipulation under remote center of motion constraint</a></div><div><b>Author(s):&nbsp;</b>Hang Su, Junhao Zhang...Elena De Momi</div><div><b>Pages:&nbsp;</b>2883 - 2895</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00464-0\">A continuous switching contact model for virtual environment based teleoperation</a></div><div><b>Author(s):&nbsp;</b>Yongqing Fu, Baibo Wu, Weiyang Lin</div><div><b>Pages:&nbsp;</b>1 - 13</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00459-x\">GraspVDN: scene-oriented grasp estimation by learning vector representations of grasps</a></div><div><b>Author(s):&nbsp;</b>Zhipeng Dong, Hongkun Tian...Fei Chen</div><div><b>Pages:&nbsp;</b>2911 - 2922</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00485-9\">Monocular tissue reconstruction via remote center motion for robot-assisted minimally invasive surgery</a></div><div><b>Author(s):&nbsp;</b>Peng Li, Ming Tang...Yunhui Liu</div><div><b>Pages:&nbsp;</b>2923 - 2936</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00499-3\">Hybrid type multi-robot path planning of a serial manipulator and SwarmItFIX robots in sheet metal milling process</a></div><div><b>Author(s):&nbsp;</b>Satheeshkumar Veeramani, Sreekumar Muthuswamy</div><div><b>Pages:&nbsp;</b>2937 - 2954</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00522-7\">A peduncle detection method of tomato for autonomous harvesting</a></div><div>J<b>Author(s):&nbsp;</b>iacheng Rong, Guanglin Dai, Pengbo Wang</div><div><b>Pages:&nbsp;</b>2955 - 2969</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00533-4\">Intent inference in shared-control teleoperation system in consideration of user behavior</a></div><div><b>Author(s):&nbsp;</b>Liangliang Wang, Qiang Li...Zhengyou Zhang</div><div><b>Pages:&nbsp;</b>2971 - 2981</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00546-z\">Bilateral teleoperation with object-adaptive mapping</a></div><div><b>Author(s):&nbsp;</b>Xiao Gao, Jo\u00e3o Silv\u00e9rio...Xiaohui Xiao</div><div><b>Pages:&nbsp;</b>2983 - 2990</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00652-6\">Fault-tolerant motion planning and generation of quadruped robots synthesised by posture optimization and whole body control</a></div><div><b>Author(s):&nbsp;</b>Junwen Cui, Zhan Li...Tianxiao Li</div><div><b>Pages:&nbsp;</b>2991 - 3003</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00777-8\">Editorial of the Special Issue: Brain-like computing for medical applications</a></div><div><b>Author(s):&nbsp;</b>Yu-Dong Zhang, Hong Lin...Steven L. Fernandes</div><div><b>Pages:&nbsp;</b>3005 - 3006</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00321-0\">A decision support system for multimodal brain tumor classification using deep learning</a></div><div><b>Author(s):&nbsp;</b>Muhammad Imran Sharif, Muhammad Attique Khan...Mudassar Raza</div><div><b>Pages:&nbsp;</b>3007 - 3020</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00319-8\">Smart healthcare system-a brain-like computing approach for analyzing the performance of detectron2 and PoseNet models for anomalous action detection in aged people with movement impairments</a></div><div><b>Author(s):&nbsp;</b>R. Divya, J. Dinesh Peter</div><div><b>Pages:&nbsp;</b>3021 - 3040</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00328-7\">3D-semantic segmentation and classification of stomach infections using uncertainty aware deep neural networks</a></div><div><b>Author(s):&nbsp;</b>Javaria Amin, Muhammad Sharif...Ramesh Sunder Nayak</div><div><b>Pages:&nbsp;</b>3041 - 3057</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00336-7\">EEG data augmentation for emotion recognition with a multiple generator conditional Wasserstein GAN</a></div><div><b>Author(s):&nbsp;</b>Aiming Zhang, Lei Su...Shengjin Liang</div><div><b>Pages:&nbsp;</b>3059 - 3071</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00398-7\">Comparative performance analysis of quantum machine learning with deep learning for diabetes prediction</a></div><div><b>Author(s):&nbsp;</b>Himanshu Gupta, Hirdesh Varshney...Om Prakash Verma</div><div><b>Pages:&nbsp;</b>3073 - 3087</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00465-z\">A weighted least squares optimisation strategy for medical image super resolution via multiscale convolutional neural networks for healthcare applications</a></div><div><b>Author(s):&nbsp;</b>Bhawna Goyal, Dawa Chyophel Lepcha...Shui-Hua Wang</div><div><b>Pages:&nbsp;</b>3089 - 3104</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00473-z\">A deep network designed for segmentation and classification of leukemia using fusion of the transfer learning models</a></div><div><b>Author(s):&nbsp;</b>Saba Saleem, Javeria Amin...Shui-Hua Wang</div><div><b>Pages:&nbsp;</b>3105 - 3120</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00474-y\">A federated approach for detecting the chest diseases using DenseNet for multi-label classification</a></div><div><b>Author(s):&nbsp;</b>K. V. Priya, J. Dinesh Peter</div><div><b>Pages:&nbsp;</b>3121 - 3129</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00469-9\">Evolutionary multiple instance boosting framework for weakly supervised learning</a></div><div><b>Author(s):&nbsp;</b>Kamanasish Bhattacharjee, Millie Pant...Shilpa Srivastava</div><div><b>Pages:&nbsp;</b>3131 - 3141</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00564-x\">Categorizing white blood cells by utilizing deep features of proposed 4B-AdditionNet-based CNN network with ant colony optimization</a></div><div><b>Author(s):&nbsp;</b>Asim Shahzad, Mudassar Raza...Ramesh Sunder Nayak</div><div><b>Pages:&nbsp;</b>3143 - 3159</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00563-y\">Brain tumor detection and classification using machine learning: a comprehensive survey</a></div><div><b>Author(s):&nbsp;</b>Javaria Amin, Muhammad Sharif...Ramesh Sundar Nayak</div><div><b>Pages:&nbsp;</b>3161 - 3183</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00771-0\">Person identification from arm\u2019s hair patterns using CT-twofold Siamese network in forensic psychiatric hospitals</a></div><div><b>Author(s):&nbsp;</b>Rohan Don Salins, T. S. Ashwin...Chaitra K. Mallikarjun</div><div><b>Pages:&nbsp;</b>3185 - 3197</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00673-1\">Effective and scalable legal judgment recommendation using pre-learned word embedding</a></div><div><b>Author(s):&nbsp;</b>Jenish Dhanani, Rupa Mehta, Dipti Rana</div><div><b>Pages:&nbsp;</b>3199 - 3213</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00674-0\">An iterative approach to unsupervised outlier detection using ensemble method and distance-based data filtering</a></div><div><b>Author(s):&nbsp;</b>Bodhan Chakraborty, Agneet Chaterjee...Ram Sarkar</div><div><b>Pages:&nbsp;</b>3215 - 3230</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00675-z\">A consensus building model in group decision making with non-reciprocal fuzzy preference relations</a></div><div><b>Author(s):&nbsp;</b>Fang Liu, Tong Liu, Ya-Ru Chen</div><div><b>Pages:&nbsp;</b>3231 - 3245</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00663-3\">Two-factor-based RSA key generation from fingerprint biometrics and password for secure communication</a></div><div><b>Author(s):&nbsp;</b>K. SureshRajarshi Pal, S. R. Balasundaram</div><div><b>Pages:&nbsp;</b>3247 - 3261</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00662-4\">A novel multi-objective bi-level programming problem under intuitionistic fuzzy environment and its application in production planning problem</a></div><div><b>Author(s):&nbsp;</b>V. P. Singh, Kirti Sharma...Ali Ebrahimnejad</div><div><b>Pages:&nbsp;</b>3263 - 3278</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00669-x\">Hesitant T-spherical Dombi fuzzy aggregation operators and their applications in multiple criteria group decision-making</a></div><div><b>Author(s):&nbsp;</b>Faruk Karaaslan, Abdulrasool Hasan Sultan Al-Husseinawi</div><div><b>Pages:&nbsp;</b>3279 - 3297</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00670-4\">Cooperative multi-population Harris Hawks optimization for many-objective optimization</a></div><div><b>Author(s):&nbsp;</b>Na Yang, Zhenzhou Tang...Qian Hu</div><div><b>Pages:&nbsp;</b>3299 - 3332</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00676-y\">Software defect prediction based on nested-stacking and heterogeneous feature selection</a></div><div><b>Author(s):&nbsp;</b>Li-qiong Chen, Can Wang, Shi-long Song</div><div><b>Pages:&nbsp;</b>3333 - 3348</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00678-w\">Product selection based on sentiment analysis of online reviews: an intuitionistic fuzzy TODIM method</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Zhang, Jian Guo...Mengjiao Wang</div><div><b>Pages:&nbsp;</b>3349 - 3362</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00680-2\">Motion magnification multi-feature relation network for facial microexpression recognition</a></div><div><b>Author(s):&nbsp;</b>Jing Zhang, Boyun Yan...Yong Liu</div><div><b>Pages:&nbsp;</b>3363 - 3376</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00682-0\">A novel feature based algorithm for soil type classification</a></div><div><b>Author(s):&nbsp;</b>Machbah Uddin, Md. Rakib Hassan</div><div><b>Pages:&nbsp;</b>3377 - 3393</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00671-3\">Rethinking ResNets: improved stacking strategies with high-order schemes for image classification</a></div><div><b>Author(s):&nbsp;</b>Zhengbo Luo, Zitang Sun...Sei-ichiro Kamata</div><div><b>Pages:&nbsp;</b>3395 - 3407</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00684-y\">Stability analysis based parameter tuning of Social Group Optimization</a></div><div><b>Author(s):&nbsp;</b>Junali Jasmine Jena, Samarendra Chandan Bindu Dash, Suresh Chandra Satapathy</div><div><b>Pages:&nbsp;</b>3409 - 3435</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00677-x\">Control in the loop for synchronization of nonlinear chaotic systems via adaptive intuitionistic neuro-fuzzy: a comparative study</a></div><div><b>Author(s):&nbsp;</b>Salah Helmy, Mohamed Magdy, Mohamed Hamdy</div><div><b>Pages:&nbsp;</b>3437 - 3450</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00679-9\">Eigenvalue-based entropy and spectrum of bipartite digraph</a></div><div><b>Author(s):&nbsp;</b>Yan Sun, Haixing Zhao</div><div><b>Pages:&nbsp;</b>3451 - 3462</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00685-x\">The development trend of China\u2019s aging population: a forecast perspective</a></div><div><b>Author(s):&nbsp;</b>Xuchong Liu, Jianian Zhu, Kai Zou</div><div><b>Pages:&nbsp;</b>3463 - 3478</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00689-7\">Based on neutrosophic fuzzy environment: a new development of FWZIC and FDOSM for benchmarking smart e-tourism applications</a></div><div><b>Author(s):&nbsp;</b>A. H. Alamoodi, R. T. Mohammed...Ali Najm Jasim</div><div><b>Pages:&nbsp;</b>3479 - 3503</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00668-y\">1-Norm random vector functional link networks for classification problems</a></div><div><b>Author(s):&nbsp;</b>Barenya Bikash Hazarika, Deepak Gupta</div><div><b>Pages:&nbsp;</b>3505 - 3521</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00688-8\">Power Muirhead mean in spherical normal fuzzy environment and its applications to multi-attribute decision-making</a></div><div><b>Author(s):&nbsp;</b>Tansu Temel, Salih Berkan Aydemir, Ya\u015far Ho\u015fcan</div><div><b>Pages:&nbsp;</b>3523 - 3541</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00694-w\">Nerve optic segmentation in CT images using a deep learning model and a texture descriptor</a></div><div><b>Author(s):&nbsp;</b>Ramin Ranjbarzadeh, Shadi Dorosti...Malika Bendechache</div><div><b>Pages:&nbsp;</b>3543 - 3557</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00667-z\">Cyber-physical security for IoT networks: a comprehensive review on traditional, blockchain and artificial intelligence based key-security</a></div><div><b>Author(s):&nbsp;</b>Ankit Attkan, Virender Ranga</div><div><b>Pages:&nbsp;</b>3559 - 3591</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00801-x\">Correction to: Evolutionary optimization of large complex problems</a></div><div><b>Author(s):&nbsp;</b>Handing Wang, Chaoli Sun...Yew-soon Ong</div><div><b>Pages:&nbsp;</b>3593 - 3593</div><div><br /></div>",
            "pubdate": "2022-08-09T12:00:00.001+12:00",
            "pubdate_parsed": 1660003200.0,
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 17, September 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/soft-computing-volume-26-issue-17.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07201-w\">Copper price movement prediction using recurrent neural networks and ensemble averaging</a></div><div><b>Author(s): </b>Jian Ni, Yue Xu...Jun Zhao</div><div><b>Pages: </b>8145 - 8161</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07234-1\">Improving the classification accuracy of melanoma detection by performing feature selection using binary Harris hawks optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>Priti Bansal, Abhishek Vanjani...Sumit Kumar</div><div><b>Pages:&nbsp;</b>8163 - 8181</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07232-3\">Chaotic implanted opposition-based-quantum equipoise state and Ascidiacea algorithms for loss lessening and power permanence enrichment</a></div><div><b>Author(s):&nbsp;</b>Lenin Kanagasabai</div><div><b>Pages:&nbsp;</b>8183 - 8202</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07236-z\">Dominating set-based test prioritization algorithms for regression testing</a></div><div><b>Author(s):&nbsp;</b>Zafer Can Demir, \u015eahin Emrah Amrahov</div><div><b>Pages:&nbsp;</b>8203 - 8220</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07238-x\">(f, g)-derivation in residuated multilattices</a></div><div><b>Author(s):&nbsp;</b>Darline Laure Keubeng Yemene, Luc Emery Diekouam Fotso, Celestin Lele</div><div><b>Pages:&nbsp;</b>8221 - 8228</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07241-2\">RO-implications induced from CL-overlap functions on complete lattices</a></div><div><b>Author(s):&nbsp;</b>Junsheng Qiao</div><div><b>Pages:&nbsp;</b>8229 - 8243</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07256-9\">Partial orders induced by the smallest and greatest nullnorms on bounded lattices</a></div><div><b>Author(s):&nbsp;</b>Zhi-qiang Liu, Xue-ping Wang</div><div><b>Pages:&nbsp;</b>8245 - 8252</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07261-y\">A deep learning approaches and fastai text classification to predict 25 medical diseases from medical speech utterances, transcription and intent</a></div><div><b>Author(s):&nbsp;</b>Yogesh Kumar, Apeksha Koul, Seema Mahajan</div><div><b>Pages:&nbsp;</b>8253 - 8272</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07270-x\">Research on Chinese ancient characters image recognition method based on adaptive receptive field</a></div><div><b>Author(s):&nbsp;</b>Yalin Miao, Li Liang...Guodong Li</div><div><b>Pages:&nbsp;</b>8273 - 8282</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07284-5\">Some similarity measures of generalized trapezoidal cubic numbers with applications</a></div><div><b>Author(s):&nbsp;</b>Mohammed A. Al Shumrani, Muhammad Gulistan</div><div><b>Pages:&nbsp;</b>8283 - 8297</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07212-7\">Sliding window convergence in intuitionistic fuzzy normed spaces for measurable functions</a></div><div><b>Author(s):&nbsp;</b>Rabia Sava\u015f</div><div><b>Pages:&nbsp;</b>8299 - 8306</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07218-1\">Prediction of the lattice constants of pyrochlore compounds using machine learning</a></div><div><b>Author(s):&nbsp;</b>Ibrahim Olanrewaju Alade, Mojeed Opeyemi Oyedeji...Tawfik A. Saleh</div><div><b>Pages:&nbsp;</b>8307 - 8315</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07235-0\">Joint Transformer and Multi-scale CNN for DCE-MRI Breast Cancer Segmentation</a></div><div><b>Author(s):&nbsp;</b>Chuanbo Qin, Yujie Wu...Xiaozhi Zhang</div><div><b>Pages:&nbsp;</b>8317 - 8334</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07258-7\">Topological IL-algebras</a></div><div><b>Author(s):&nbsp;</b>Safiqul Islam, Arundhati Sanyal, Jayanta Sen</div><div><b>Pages:&nbsp;</b>8335 - 8349</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07271-w\">Pierce sheaves of pseudo EMV-algebras</a></div><div><b>Author(s):&nbsp;</b>Anatolij Dvure\u010denskij, Omid Zahiri</div><div><b>Pages:&nbsp;</b>8351 - 8369</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07207-4\">Finite-time dissipative synchronization of discrete-time semi-Markovian jump complex dynamical networks with actuator faults</a></div><div><b>Author(s):&nbsp;</b>N. Sakthivel, S. Pallavi...V. Vijayakumar</div><div><b>Pages:&nbsp;</b>8371 - 8386</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07208-3\">A multi-criteria group decision-making approach based on revised distance measures under dual hesitant fuzzy setting with unknown weight information</a></div><div><b>Author(s):&nbsp;</b>Jawad Ali, Zia Bashir, Tabasam Rashid</div><div><b>Pages:&nbsp;</b>8387 - 8401</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07221-6\">On the residuation principle of n-dimensional R-implications</a></div><div><b>Author(s):&nbsp;</b>Rosana Zanotelli, Bruno Moura...Benjamin Bedregal</div><div><b>Pages:&nbsp;</b>8403 - 8426</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07229-y\">Improvement of cross-efficiency based on TODIM method</a></div><div><b>Author(s):&nbsp;</b>Meiqin Wu, Xiaoqing Hou, Jianping Fan</div><div><b>Pages:&nbsp;</b>8427 - 8439</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07237-y\">Supervisory adaptive fuzzy sliding mode control with optimal Jaya based fuzzy PID sliding surface for a planer cable robot</a></div><div><b>Author(s):&nbsp;</b>Mohammadhossein Aghaseyedabdollah, Mostafa Abedi, Mahdi Pourgholi</div><div><b>Pages:&nbsp;</b>8441 - 8458</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07239-w\">Multi-attribute group decision-making method based on weighted partitioned Maclaurin symmetric mean operator and a novel score function under neutrosophic cubic environment</a></div><div><b>Author(s):&nbsp;</b>Jianping Fan, Shanshan Zha, Meiqin Wu</div><div><b>Pages:&nbsp;</b>8459 - 8477</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07242-1\">Mehar approach to solve neutrosophic linear programming problems using possibilistic mean</a></div><div><b>Author(s):&nbsp;</b>Tanveen Kaur Bhatia, Amit Kumar...S. S. Appadoo</div><div><b>Pages:&nbsp;</b>8479 - 8495</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07252-z\">An improved solution for the neutrosophic linear programming problems based on Mellin\u2019s transform</a></div><div><b>Author(s):&nbsp;</b>G. Tamilarasi, S. Paulraj</div><div><b>Pages:&nbsp;</b>8497 - 8507</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07151-3\">Low-voltage distribution network topology identification based on constrained least square and graph theory</a></div><div><b>Author(s):&nbsp;</b>Shijie Cui, Peng Zeng...Guangye Li</div><div><b>Pages:&nbsp;</b>8509 - 8519</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07251-0\">Evaluating appropriate communication technology for smart grid by using a comprehensive decision-making approach fuzzy TOPSIS</a></div><div><b>Author(s):&nbsp;</b>Daud Abdul, Jiang Wenqi</div><div><b>Pages:&nbsp;</b>8521 - 8536</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07276-5\">A CEEMD-ARIMA-SVM model with structural breaks to forecast the crude oil prices linked with extreme events</a></div><div><b>Author(s):&nbsp;</b>Yuxiang Cheng, Jiayu Yi...Luis Seco</div><div><b>Pages:&nbsp;</b>8537 - 8551</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07161-1\">Deep learning for volatility forecasting in asset management</a></div><div><b>Author(s):&nbsp;</b>Alessio Petrozziello, Luigi Troiano...Michele La Rocca</div><div><b>Pages:&nbsp;</b>8553 - 8574</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07195-5\">Relationship classification based on dependency parsing and the pretraining model</a></div><div><b>Author(s):&nbsp;</b>Baosheng Yin, Yifei Sun</div><div><b>Pages:&nbsp;</b>8575 - 8583</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07202-9\">A cooperative genetic algorithm based on extreme learning machine for data classification</a></div><div><b>Author(s):&nbsp;</b>Lixia Bai, Hong Li...Jin Xie</div><div><b>Pages:&nbsp;</b>8585 - 8601</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07226-1\">An intermittent fault diagnosis method of analog circuits based on variational modal decomposition and adaptive dynamic density peak clustering</a></div><div><b>Author(s):&nbsp;</b>Jianfeng Qu, Xiaoyu Fang...Jinzhuo Liu</div><div><b>Pages:&nbsp;</b>8603 - 8615</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07230-5\">Residual stacked gated recurrent unit with encoder\u2013decoder architecture and an attention mechanism for temporal traffic prediction</a></div><div><b>Author(s):&nbsp;</b>R. J. Kuo, D. A. Kunarsito</div><div><b>Pages:&nbsp;</b>8617 - 8633</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07244-z\">Code recommendation based on joint embedded attention network</a></div><div><b>Author(s):&nbsp;</b>Wanzhi Wen, Tian Zhao...Deepak Kumar Jain</div><div><b>Pages:&nbsp;</b>8635 - 8645</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07263-w\">Dark convolutional neural network for forest smoke detection and localization based on single image</a></div><div><b>Author(s):&nbsp;</b>Na Lu</div><div><b>Pages:&nbsp;</b>8647 - 8659</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07152-2\">Simulation\u2013optimization approach for the multi-objective production and distribution planning problem in the supply chain: using NSGA-II and Monte Carlo simulation</a></div><div><b>Author(s):&nbsp;</b>Niloofar Nadim Kabiri, Saeed Emami, Abdul Sattar Safaei</div><div><b>Pages:&nbsp;</b>8661 - 8687</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07154-0\">A method of real-temporal object tracking combined the temporal information and spatial information</a></div><div><b>Author(s):&nbsp;</b>Xiaoshuo Jia, Zhihui Li...Shangyou Zeng</div><div><b>Pages:&nbsp;</b>8689 - 8698</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07171-z\">Optimal solution of neutrosophic linear fractional programming problems with mixed constraints</a></div><div><b>Author(s):&nbsp;</b>Sapan Kumar Das, S. A. Edalatpanah</div><div><b>Pages:&nbsp;</b>8699 - 8707</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07182-w\">Software module clustering using grid-based large-scale many-objective particle swarm optimization</a></div><div><b>Author(s):&nbsp;</b>Amarjeet Prajapati</div><div><b>Pages:&nbsp;</b>8709 - 8730</div><div><br /></div><div><b>38) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07196-4\">Process optimization for post disaster reconstruction project based on industrial design structure matrix (DSM)</a></div><div><b>Author(s):&nbsp;</b>Hui Tang, Qingping Zhong, Chuan Chen</div><div><b>Pages:&nbsp;</b>8731 - 8743</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07198-2\">A dynamic space reduction ant colony optimization for capacitated vehicle routing problem</a></div><div><b>Author(s):&nbsp;</b>Jinsi Cai, Peng Wang...Huachao Dong</div><div><b>Pages:&nbsp;</b>8745 - 8756</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07203-8\">Fault location in distribution network by solving the optimization problem using genetic algorithm based on the calculating voltage changes</a></div><div><b>Author(s):&nbsp;</b>Masoud Dashtdar, Mohit Bajaj...H\u00e1m\u00e9d M\u00e9rsh\u00eak\u00e1\u00e9r</div><div><b>Pages:&nbsp;</b>8757 - 8783</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07227-0\">A Scatter Search Algorithm for Multi-Criteria Inventory Classification considering Multi-Objective Optimization</a></div><div><b>Author(s):&nbsp;</b>Ilkay Saracoglu</div><div><b>Pages:&nbsp;</b>8785 - 8806</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07153-1\">The research of innovation path of power monitoring and dispatching under the vision of carbon neutrality based on mobile edge computing</a></div><div><b>Author(s):&nbsp;</b>Jingxuan Dong, Jian Li</div><div><b>Pages:&nbsp;</b>8807 - 8820</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07192-8\">Sustainable supplier selection using HF-DEA-FOCUM-MABAC technique: a case study in the Auto-making industry</a></div><div><b>Author(s):&nbsp;</b>Arunodaya Raj Mishra, Abhijit Saha...Ibrahim M. Hezam</div><div><b>Pages:&nbsp;</b>8821 - 8840</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07225-2\">A note on \u201cPythagorean uncertain linguistic hesitant fuzzy weighted averaging operator and its application in financial group decision making\u201d</a></div><div>S. S. Appadoo, Mohammadreza Makhan, Amit Kumar</div><div><b>Pages:&nbsp;</b>8841 - 8843</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06652-x\">SECOI: an application based on fuzzy soft sets for producing selective-colored images</a></div><div><b>Author(s):&nbsp;</b>Petr Hurtik, Ji\u0159\u00ed Mo\u010dko\u0159</div><div><b>Pages:&nbsp;</b>8845 - 8855</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06661-w\">A novel model based on multiple input factors and variance reciprocal: application on wind speed forecasting</a></div><div><b>Author(s):&nbsp;</b>Zhihao Shang, Min Li...Lian Li</div><div><b>Pages:&nbsp;</b>8857 - 8877</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06692-3\">A variable neighborhood search algorithm with constraint relaxation for the two-echelon vehicle routing problem with simultaneous delivery and pickup demands</a></div><div><b>Author(s):&nbsp;</b>Ran Liu, Shan Jiang</div><div><b>Pages:&nbsp;</b>8879 - 8896</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07296-1\">Reservoir water level forecasting using wavelet support vector regression (WSVR) based on teaching learning-based optimization algorithm (TLBO)</a></div><div><b>Author(s):&nbsp;</b>Mohammad Mahdi Malekpour, Hossein Malekpoor</div><div><b>Pages:&nbsp;</b>8897 - 8909</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06697-y\">Multi-objective casting production scheduling problem by a neighborhood structure enhanced discrete NSGA-II: an application from real-world workshop</a></div><div><b>Author(s):&nbsp;</b>Weihua Tan, Xiaofang Yuan...Lianghong Wu</div><div><b>Pages:&nbsp;</b>8911 - 8928</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06701-5\">Weighted differential evolution-based heuristic computing for identification of Hammerstein systems in electrically stimulated muscle modeling</a></div><div><b>Author(s):&nbsp;</b>Ammara Mehmood, Muhammad Asif Zahoor Raja...Naveed Ishtiaq Chaudhary</div><div><b>Pages:&nbsp;</b>8929 - 8945</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07374-4\">Correction: G-optimal designs for hierarchical linear models: an equivalence theorem and a nature-inspired meta-heuristic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xin Liu, RongXian Yue...Weng Kee Wong</div><div><b>Pages:&nbsp;</b>8947 - 8947</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-08-18T12:00:00.001+12:00",
            "pubdate_parsed": 1660780800.0,
            "email_sent": true
        },
        "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 8, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/ieee-transactions-on-neural-networks.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9345705/\">New Generation Deep Learning for Video Object Detection: A Survey</a></div><div><b>Author(s): </b>Licheng Jiao, Ruohan Zhang, Fang Liu, Shuyuan Yang, Biao Hou, Lingling Li, Xu Tang</div><div><b>Pages: </b>3195 - 3215</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9334418/\">Synchronization of Complex Dynamical Networks Subject to Noisy Sampling Interval and Packet Loss</a></div><div><b>Author(s):&nbsp;</b>Zhipei Hu, Hongru Ren, Peng Shi</div><div><b>Pages:&nbsp;</b>3216 - 3226</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9334446/\">Boundary Stabilization of Stochastic Delayed Cohen\u2013Grossberg Neural Networks With Diffusion Terms</a></div><div><b>Author(s):&nbsp;</b>Xiao-Zhen Liu, Kai-Ning Wu, Xiaohua Ding, Weihai Zhang</div><div><b>Pages:&nbsp;</b>3227 - 3237</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9337191/\">Neuron Linear Transformation: Modeling the Domain Shift for Crowd Counting</a></div><div><b>Author(s):&nbsp;</b>Qi Wang, Tao Han, Junyu Gao, Yuan Yuan</div><div><b>Pages:&nbsp;</b>3238 - 3250</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9340584/\">A Hybrid System Based on Dynamic Selection for Time Series Forecasting</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o F. L. de Oliveira, Eraylson G. Silva, Paulo S. G. de Mattos Neto</div><div><b>Pages:&nbsp;</b>3251 - 3263</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9336312/\">Encoder-X: Solving Unknown Coefficients Automatically in Polynomial Fitting by Using an Autoencoder</a></div><div><b>Author(s):&nbsp;</b>Guojun Wang, Weijun Li, Liping Zhang, Linjun Sun, Peng Chen, Lina Yu, Xin Ning</div><div><b>Pages:&nbsp;</b>3264 - 3276</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9377649/\">DAMAD: Database, Attack, and Model Agnostic Adversarial Perturbation Detector</a></div><div><b>Author(s):&nbsp;</b>Akshay Agarwal, Gaurav Goswami, Mayank Vatsa, Richa Singh, Nalini K. Ratha</div><div><b>Pages:&nbsp;</b>3277 - 3289</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9336296/\">DQC-ADMM: Decentralized Dynamic ADMM With Quantized and Censored Communications</a></div><div><b>Author(s):&nbsp;</b>Yaohua Liu, Gang Wu, Zhi Tian, Qing Ling</div><div><b>Pages:&nbsp;</b>3290 - 3304</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9340243/\">Generalized Nonconvex Approach for Low-Tubal-Rank Tensor Recovery</a></div><div><b>Author(s):&nbsp;</b>Hailin Wang, Feng Zhang, Jianjun Wang, Tingwen Huang, Jianwen Huang, Xinling Liu</div><div><b>Pages:&nbsp;</b>3305 - 3319</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9339998/\">Deep Attention-Based Imbalanced Image Classification</a></div><div><b>Author(s):&nbsp;</b>Lituan Wang, Lei Zhang, Xiaofeng Qi, Zhang Yi</div><div><b>Pages:&nbsp;</b>3320 - 3330</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9337205/\">Adaptive Neural Network Control for Full-State Constrained Robotic Manipulator With Actuator Saturation and Time-Varying Delays</a></div><div><b>Author(s):&nbsp;</b>Weiwei Sun, You Wu, Xinyu Lv</div><div><b>Pages:&nbsp;</b>3331 - 3342</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9344656/\">Imbalanced Data Classification via Cooperative Interaction Between Classifier and Generator</a></div><div><b>Author(s):&nbsp;</b>Hyun-Soo Choi, Dahuin Jung, Siwon Kim, Sungroh Yoon</div><div><b>Pages:&nbsp;</b>3343 - 3356</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9345987/\">Parkinson\u2019s Disease Classification and Clinical Score Regression via United Embedding and Sparse Learning From Longitudinal Data</a></div><div><b>Author(s):&nbsp;</b>Zhongwei Huang, Haijun Lei, Guoliang Chen, Alejandro F. Frangi, Yanwu Xu, Ahmed Elazab, Jing Qin, Baiying Lei</div><div><b>Pages:&nbsp;</b>3357 - 3371</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9349201/\">Element-Wise Feature Relation Learning Network for Cross-Spectral Image Patch Matching</a></div><div><b>Author(s):&nbsp;</b>Dou Quan, Shuang Wang, Ning Huyan, Jocelyn Chanussot, Ruojing Wang, Xuefeng Liang, Biao Hou, Licheng Jiao</div><div><b>Pages:&nbsp;</b>3372 - 3386</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9344655/\">Temporal Encoding and Multispike Learning Framework for Efficient Recognition of Visual Patterns</a></div><div><b>Author(s):&nbsp;</b>Qiang Yu, Shiming Song, Chenxiang Ma, Jianguo Wei, Shengyong Chen, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>3387 - 3399</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9343714/\">Detachable Second-Order Pooling: Toward High-Performance First-Order Networks</a></div><div><b>Author(s):&nbsp;</b>Lida Li, Jiangtao Xie, Peihua Li, Lei Zhang</div><div><b>Pages:&nbsp;</b>3400 - 3414</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9340597/\">Solving Complex-Valued Time-Varying Linear Matrix Equations via QR Decomposition With Applications to Robotic Motion Tracking and on Angle-of-Arrival Localization</a></div><div><b>Author(s):&nbsp;</b>Vasilios N. Katsikis, Spyridon D. Mourtas, Predrag S. Stanimirovi\u0107, Yunong Zhang</div><div><b>Pages:&nbsp;</b>3415 - 3424</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9340611/\">Underexposed Image Correction via Hybrid Priors Navigated Deep Propagation</a></div><div><b>Author(s):&nbsp;</b>Risheng Liu, Long Ma, Yuxi Zhang, Xin Fan, Zhongxuan Luo</div><div><b>Pages:&nbsp;</b>3425 - 3436</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9352532/\">Theory-Inspired Deep Network for Instantaneous-Frequency Extraction and Subsignals Recovery From Discrete Blind-Source Data</a></div><div><b>Author(s):&nbsp;</b>Ningning Han, H. N. Mhaskar, Charles K. Chui</div><div><b>Pages:&nbsp;</b>3437 - 3447</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9343776/\">GenDet: Meta Learning to Generate Detectors From Few Shots</a></div><div><b>Author(s):&nbsp;</b>Liyang Liu, Bochao Wang, Zhanghui Kuang, Jing-Hao Xue, Yimin Chen, Wenming Yang, Qingmin Liao, Wayne Zhang</div><div><b>Pages:&nbsp;</b>3448 - 3460</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9344864/\">Distributed Group Coordination of Multiagent Systems in Cloud Computing Systems Using a Model-Free Adaptive Predictive Control Strategy</a></div><div><b>Author(s):&nbsp;</b>Haoran Tan, Yaonan Wang, Min Wu, Zhiwu Huang, Zhiqiang Miao</div><div><b>Pages:&nbsp;</b>3461 - 3473</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9343685/\">Adaptive NN-Based Consensus for a Class of Nonlinear Multiagent Systems With Actuator Faults and Faulty Networks</a></div><div><b>Author(s):&nbsp;</b>Xiaozheng Jin, Shaoyu L\u00fc, Jiguo Yu</div><div><b>Pages:&nbsp;</b>3474 - 3486</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9350111/\">Data-Driven Adaptive Consensus Learning From Network Topologies</a></div><div><b>Author(s):&nbsp;</b>Ronghu Chi, Yu Hui, Biao Huang, Zhongsheng Hou, Xuhui Bu</div><div><b>Pages:&nbsp;</b>3487 - 3497</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9344821/\">Adversarial Learning of Disentangled and Generalizable Representations of Visual Attributes</a></div><div><b>Author(s):&nbsp;</b>James Oldfield, Yannis Panagakis, Mihalis A. Nicolaou</div><div><b>Pages:&nbsp;</b>3498 - 3509</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9350110/\">Comparative Convolutional Dynamic Multi-Attention Recommendation Model</a></div><div><b>Author(s):&nbsp;</b>Juan Ni, Zhenhua Huang, Chang Yu, Dongdong Lv, Cheng Wang</div><div><b>Pages:&nbsp;</b>3510 - 3521</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9347827/\">Link Prediction Based on Stochastic Information Diffusion</a></div><div><b>Author(s):&nbsp;</b>Didier A. Vega-Oliveros, Liang Zhao, Anderson Rocha, Lilian Berton</div><div><b>Pages:&nbsp;</b>3522 - 3532</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9346019/\">A Convex Model for Support Vector Distance Metric Learning</a></div><div><b>Author(s):&nbsp;</b>Yibang Ruan, Yanshan Xiao, Zhifeng Hao, Bo Liu</div><div><b>Pages:&nbsp;</b>3533 - 3546</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9350205/\">RGB-D Point Cloud Registration Based on Salient Object Detection</a></div><div><b>Author(s):&nbsp;</b>Teng Wan, Shaoyi Du, Wenting Cui, Runzhao Yao, Yuyan Ge, Ce Li, Yue Gao, Nanning Zheng</div><div><b>Pages:&nbsp;</b>3547 - 3559</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9345932/\">Hierarchical-Bayesian-Based Sparse Stochastic Configuration Networks for Construction of Prediction Intervals</a></div><div><b>Author(s):&nbsp;</b>Jun Lu, Jinliang Ding, Changxin Liu, Tianyou Chai</div><div><b>Pages:&nbsp;</b>3560 - 3571</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9346050/\">Abnormal Event Detection and Localization via Adversarial Event Prediction</a></div><div><b>Author(s):&nbsp;</b>Jongmin Yu, Younkwan Lee, Kin Choong Yow, Moongu Jeon, Witold Pedrycz</div><div><b>Pages:&nbsp;</b>3572 - 3586</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9349966/\">Improving EEG Decoding via Clustering-Based Multitask Feature Learning</a></div><div><b>Author(s):&nbsp;</b>Yu Zhang, Tao Zhou, Wei Wu, Hua Xie, Hongru Zhu, Guoxu Zhou, Andrzej Cichocki</div><div><b>Pages:&nbsp;</b>3587 - 3597</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9350115/\">Neighborhood Geometric Structure-Preserving Variational Autoencoder for Smooth and Bounded Data Sources</a></div><div><b>Author(s):&nbsp;</b>Xingyu Chen, Chunyu Wang, Xuguang Lan, Nanning Zheng, Wenjun Zeng</div><div><b>Pages:&nbsp;</b>3598 - 3611</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9352534/\">Optimizing Attention for Sequence Modeling via Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Hao Fei, Yue Zhang, Yafeng Ren, Donghong Ji</div><div><b>Pages:&nbsp;</b>3612 - 3621</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9349207/\">Periodic Event-Triggered Synchronization for Discrete-Time Complex Dynamical Networks</a></div><div><b>Author(s):&nbsp;</b>Sanbo Ding, Zhanshan Wang, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3622 - 3633</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9350196/\">Fast Unsupervised Projection for Large-Scale Data</a></div><div><b>Author(s):&nbsp;</b>Jingyu Wang, Lin Wang, Feiping Nie, Xuelong Li</div><div><b>Pages:&nbsp;</b>3634 - 3644</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9386270/\">Relaxed Block-Diagonal Dictionary Pair Learning With Locality Constraint for Image Recognition</a></div><div><b>Author(s):&nbsp;</b>Zhe Chen, Xiao-Jun Wu, Josef Kittler</div><div><b>Pages:&nbsp;</b>3645 - 3659</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9351670/\">Multiperspective Progressive Structure Adaptation for JPEG Steganography Detection Across Domains</a></div><div><b>Author(s):&nbsp;</b>Ju Jia, Meng Luo, Jinshuo Liu, Weixiang Ren, Lina Wang</div><div><b>Pages:&nbsp;</b>3660 - 3674</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9364887/\">Optimal Scale Combination Selection Integrating Three-Way Decision With Hasse Diagram</a></div><div><b>Author(s):&nbsp;</b>Qinghua Zhang, Yunlong Cheng, Fan Zhao, Guoyin Wang, Shuyin Xia</div><div><b>Pages:&nbsp;</b>3675 - 3689</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9350116/\">Networked Multiagent Systems: Antagonistic Interaction, Constraint, and its Application</a></div><div><b>Author(s):&nbsp;</b>Wentao Zhang, Zhiqiang Zuo, Yijing Wang</div><div><b>Pages:&nbsp;</b>3690 - 3699</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9350109/\">Dynamic Learning From Adaptive Neural Control for Discrete-Time Strict-Feedback Systems</a></div><div><b>Author(s):&nbsp;</b>Min Wang, Haotian Shi, Cong Wang, Jun Fu</div><div><b>Pages:&nbsp;</b>3700 - 3712</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9349163/\">Transductive Semisupervised Deep Hashing</a></div><div><b>Author(s):&nbsp;</b>Weiwei Shi, Yihong Gong, Badong Chen, Xinhong Hei</div><div><b>Pages:&nbsp;</b>3713 - 3726</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9349967/\">Surrogate-Assisted Particle Swarm Optimization for Evolving Variable-Length Transferable Blocks for Image Classification</a></div><div><b>Author(s):&nbsp;</b>Bin Wang, Bing Xue, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>3727 - 3740</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9351698/\">Target Tracking Control of a Biomimetic Underwater Vehicle Through Deep Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Yu Wang, Chong Tang, Shuo Wang, Long Cheng, Rui Wang, Min Tan, Zengguang Hou</div><div><b>Pages:&nbsp;</b>3741 - 3752</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9353398/\">Variational Inference and Learning of Piecewise Linear Dynamical Systems</a></div><div><b>Author(s):&nbsp;</b>Xavier Alameda-Pineda, Vincent Drouard, Radu Patrice Horaud</div><div><b>Pages:&nbsp;</b>3753 - 3764</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9352557/\">CRL: Collaborative Representation Learning by Coordinating Topic Modeling and Network Embeddings</a></div><div><b>Author(s):&nbsp;</b>Junyang Chen, Zhiguo Gong, Wei Wang, Weiwen Liu, Xiao Dong</div><div><b>Pages:&nbsp;</b>3765 - 3777</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9356334/\">Beneficial Perturbation Network for Designing General Adaptive Artificial Intelligence Systems</a></div><div><b>Author(s):&nbsp;</b>Shixian Wen, Amanda Rios, Yunhao Ge, Laurent Itti</div><div><b>Pages:&nbsp;</b>3778 - 3791</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9352543/\">A Plug-in Method for Representation Factorization in Connectionist Models</a></div><div><b>Author(s):&nbsp;</b>Jee Seok Yoon, Myung-Cheol Roh, Heung-Il Suk</div><div><b>Pages:&nbsp;</b>3792 - 3803</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9354049/\">Event-Based Design of Finite-Time Adaptive Control of Uncertain Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Yuan-Xin Li, Zhongsheng Hou, Wei-Wei Che, Zheng-Guang Wu</div><div><b>Pages:&nbsp;</b>3804 - 3813</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9352495/\">Motion Planning and Adaptive Neural Tracking Control of an Uncertain Two-Link Rigid\u2013Flexible Manipulator With Vibration Amplitude Constraint</a></div><div><b>Author(s):&nbsp;</b>Qingxin Meng, Xuzhi Lai, Ze Yan, Chun-Yi Su, Min Wu</div><div><b>Pages:&nbsp;</b>3814 - 3828</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9349196/\">Sampled-Data Synchronization of Stochastic Markovian Jump Neural Networks With Time-Varying Delay</a></div><div><b>Author(s):&nbsp;</b>Guoliang Chen, Jianwei Xia, Ju H. Park, Hao Shen, Guangming Zhuang</div><div><b>Pages:&nbsp;</b>3829 - 3841</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9350193/\">A Novel Sparse Graph-Regularized Singular Value Decomposition Model and Its Application to Genomic Data Analysis</a></div><div><b>Author(s):&nbsp;</b>Wenwen Min, Xiang Wan, Tsung-Hui Chang, Shihua Zhang</div><div><b>Pages:&nbsp;</b>3842 - 3856</div><div><br /></div><div><b>52)</b> <a href=\"https://ieeexplore.ieee.org/document/9352556/\">Concept Drift-Tolerant Transfer Learning in Dynamic Environments</a></div><div><b>Author(s):&nbsp;</b>Cuie Yang, Yiu-Ming Cheung, Jinliang Ding, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>3857 - 3871</div><div><br /></div><div><b>53)</b> <a href=\"https://ieeexplore.ieee.org/document/9354489/\">Data-Based Optimal Consensus Control for Multiagent Systems With Policy Gradient Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Xindi Yang, Hao Zhang, Zhuping Wang</div><div><b>Pages:&nbsp;</b>3872 - 3883</div><div><br /></div><div><b>54)</b> <a href=\"https://ieeexplore.ieee.org/document/9354502/\">Directional Deep Embedding and Appearance Learning for Fast Video Object Segmentation</a></div><div><b>Author(s):&nbsp;</b>Yingjie Yin, De Xu, Xingang Wang, Lei Zhang</div><div><b>Pages:&nbsp;</b>3884 - 3894</div><div><br /></div><div><b>55) </b><a href=\"https://ieeexplore.ieee.org/document/9358980/\">Multi-Manifold Optimization for Multi-View Subspace Clustering</a></div><div><b>Author(s):&nbsp;</b>Aparajita Khan, Pradipta Maji</div><div><b>Pages:&nbsp;</b>3895 - 3907</div><div><br /></div><div><b>56)</b> <a href=\"https://ieeexplore.ieee.org/document/9352535/\">Remote State Estimation of Nonlinear Systems Over Fading Channels via Recurrent Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Songfu Cai, Vincent K. N. Lau</div><div><b>Pages:&nbsp;</b>3908 - 3922</div><div><br /></div><div><b>57)</b> <a href=\"https://ieeexplore.ieee.org/document/9352501/\">Convolutional Neural Network for Behavioral Modeling and Predistortion of Wideband Power Amplifiers</a></div><div><b>Author(s):&nbsp;</b>Xin Hu, Zhijun Liu, Xiaofei Yu, Yulong Zhao, Wenhua Chen, Biao Hu, Xuekun Du, Xiang Li, Mohamed Helaoui, Weidong Wang, Fadhel M. Ghannouchi</div><div><b>Pages:&nbsp;</b>3923 - 3937</div><div><br /></div><div><b>58)</b> <a href=\"https://ieeexplore.ieee.org/document/9352485/\">Finite-Time Synchronization of Complex-Valued Memristive-Based Neural Networks via Hybrid Control</a></div><div><b>Author(s):&nbsp;</b>Tianhu Yu, Jinde Cao, Leszek Rutkowski, Yi-Ping Luo</div><div><b>Pages:&nbsp;</b>3938 - 3947</div><div><br /></div><div><b>59)</b> <a href=\"https://ieeexplore.ieee.org/document/9360311/\">Margin Distribution Analysis</a></div><div><b>Author(s):&nbsp;</b>Jun Wang, Zhi-Hua Zhou</div><div><b>Pages:&nbsp;</b>3948 - 3960</div><div><br /></div><div><b>60)</b> <a href=\"https://ieeexplore.ieee.org/document/9359364/\">Learning Knowledge Graph Embedding With Heterogeneous Relation Attention Networks</a></div><div><b>Author(s):&nbsp;</b>Zhifei Li, Hai Liu, Zhaoli Zhang, Tingting Liu, Neal N. Xiong</div><div><b>Pages:&nbsp;</b>3961 - 3973</div><div><br /></div><div><b>61)</b> <a href=\"https://ieeexplore.ieee.org/document/9354062/\">Toward Full-Stack Acceleration of Deep Convolutional Neural Networks on FPGAs</a></div><div><b>Author(s):&nbsp;</b>Shuanglong Liu, Hongxiang Fan, Martin Ferianc, Xinyu Niu, Huifeng Shi, Wayne Luk</div><div><b>Pages:&nbsp;</b>3974 - 3987</div><div><br /></div><div><b>62)</b> <a href=\"https://ieeexplore.ieee.org/document/9353400/\">Toward the Optimal Design and FPGA Implementation of Spiking Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Wenzhe Guo, Hasan Erdem Yant\u0131r, Mohammed E. Fouda, Ahmed M. Eltawil, Khaled Nabil Salama</div><div><b>Pages:&nbsp;</b>3988 - 4002</div><div><br /></div><div><b>63)</b> <a href=\"https://ieeexplore.ieee.org/document/9353402/\">Lifelong Incremental Reinforcement Learning With Online Bayesian Inference</a></div><div><b>Author(s):&nbsp;</b>Zhi Wang, Chunlin Chen, Daoyi Dong</div><div><b>Pages:&nbsp;</b>4003 - 4016</div><div><br /></div><div><b>64)</b> <a href=\"https://ieeexplore.ieee.org/document/9354503/\">Massive-Scale Aerial Photo Categorization by Cross-Resolution Visual Perception Enhancement</a></div><div><b>Author(s):&nbsp;</b>Luming Zhang, Xiaoqin Zhang, Mingliang Xu, Ling Shao</div><div><b>Pages:&nbsp;</b>4017 - 4030</div><div><br /></div><div><b>65)</b> <a href=\"https://ieeexplore.ieee.org/document/9353404/\">Global Negative Correlation Learning: A Unified Framework for Global Optimization of Ensemble Models</a></div><div><b>Author(s):&nbsp;</b>Carlos Perales-Gonz\u00e1lez, Francisco Fern\u00e1ndez-Navarro, Mariano Carbonero-Ruz, Javier P\u00e9rez-Rodr\u00edguez</div><div><b>Pages:&nbsp;</b>4031 - 4042</div><div><br /></div><div><b>66)</b> <a href=\"https://ieeexplore.ieee.org/document/9354488/\">Optimal Tracking Control of Nonlinear Multiagent Systems Using Internal Reinforce Q-Learning</a></div><div><b>Author(s):&nbsp;</b>Zhinan Peng, Rui Luo, Jiangping Hu, Kaibo Shi, Sing Kiong Nguang, Bijoy Kumar Ghosh</div><div><b>Pages:&nbsp;</b>4043 - 4055</div><div><br /></div><div><b>67)</b> <a href=\"https://ieeexplore.ieee.org/document/9369104/\">Multi-Task Weakly-Supervised Attention Network for Dementia Status Estimation With Structural MRI</a></div><div><b>Author(s):&nbsp;</b>Chunfeng Lian, Mingxia Liu, Li Wang, Dinggang Shen</div><div><b>Pages:&nbsp;</b>4056 - 4068</div><div><br /></div><div><b>68)</b> <a href=\"https://ieeexplore.ieee.org/document/9354493/\">FPGA-Based High-Throughput CNN Hardware Accelerator With High Computing Resource Utilization Ratio</a></div><div><b>Author(s):&nbsp;</b>Wenjin Huang, Huangtao Wu, Qingkun Chen, Conghui Luo, Shihao Zeng, Tianrui Li, Yihua Huang</div><div><b>Pages:&nbsp;</b>4069 - 4083</div><div><br /></div><div><b>69)</b> <a href=\"https://ieeexplore.ieee.org/document/9357939/\">Convolutional Ordinal Regression Forest for Image Ordinal Estimation</a></div><div><b>Author(s):&nbsp;</b>Haiping Zhu, Hongming Shan, Yuheng Zhang, Lingfu Che, Xiaoyang Xu, Junping Zhang, Jianbo Shi, Fei-Yue Wang</div><div><b>Pages:&nbsp;</b>4084 - 4095</div><div><br /></div><div><b>70)</b> <a href=\"https://ieeexplore.ieee.org/document/9353392/\">Spiking Neural Network Regularization With Fixed and Adaptive Drop-Keep Probabilities</a></div><div><b>Author(s):&nbsp;</b>Junhong Zhao, Jie Yang, Jun Wang, Wei Wu</div><div><b>Pages:&nbsp;</b>4096 - 4109</div><div><br /></div><div><b>71)</b> <a href=\"https://ieeexplore.ieee.org/document/9372892/\">Adversarial Binary Mutual Learning for Semi-Supervised Deep Hashing</a></div><div><b>Author(s):&nbsp;</b>Guan\u2019An Wang, Qinghao Hu, Yang Yang, Jian Cheng, Zeng-Guang Hou</div><div><b>Pages:&nbsp;</b>4110 - 4124</div><div><br /></div><div><b>72)</b> <a href=\"https://ieeexplore.ieee.org/document/9334410/\">Scalable Inverse Reinforcement Learning Through Multifidelity Bayesian Optimization</a></div><div><b>Author(s):&nbsp;</b>Mahdi Imani, Seyede Fatemeh Ghoreishi</div><div><b>Pages:&nbsp;</b>4125 - 4132</div><div><br /></div><div><b>73)</b> <a href=\"https://ieeexplore.ieee.org/document/9350113/\">Fixed-Time Synchronization of Competitive Neural Networks With Multiple Time Scales</a></div><div><b>Author(s):&nbsp;</b>Wu Yang, Yan-Wu Wang, Irinel-Constantin Mor\u01cerescu, Xiao-Kang Liu, Yuehua Huang</div><div><b>Pages:&nbsp;</b>4133 - 4138</div><div><br /></div><div><b>74)</b> <a href=\"https://ieeexplore.ieee.org/document/9345983/\">Online Reinforcement Learning Control by Direct Heuristic Dynamic Programming: From Time-Driven to Event-Driven</a></div><div><b>Author(s):&nbsp;</b>Qingtao Zhao, Jennie Si, Jian Sun</div><div><b>Pages:&nbsp;</b>4139 - 4144</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-08-19T12:00:00.235+12:00",
            "pubdate_parsed": 1660867200.0,
            "email_sent": true
        }
    },
    "TopBots Blog": {},
    "Sebastian Raschka Blog": {},
    "Distill Machine Learning Blog": {},
    "Assembly AI Blog": {
        "How to Run Stable Diffusion Locally to Generate Images": {
            "url": "https://www.assemblyai.com/blog/how-to-run-stable-diffusion-locally-to-generate-images/",
            "description": "Stable Diffusion is a text-to-image model with recently-released open-sourced weights. Learn how to generate an image of a scene given only a description of it in this simple tutorial.",
            "pubdate": "Tue, 23 Aug 2022 12:57:39 GMT",
            "pubdate_parsed": 1661259459.0,
            "email_sent": true
        },
        "Why Product Teams at Top Call Tracking Solutions are Turning to AI": {
            "url": "https://www.assemblyai.com/blog/why-product-teams-at-top-call-tracking-solutions-are-turning-to-ai/",
            "description": "This article will look at some of the top AI models for product teams to integrate into Call Tracking Solutions, including what they are and how they work.",
            "pubdate": "Tue, 23 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": 1661234400.0,
            "email_sent": true
        },
        "Deep Learning Paper Recap - Diffusion and Transformer Models": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-diffusion-and-transformer-models/",
            "description": "This week\u2019s Deep Learning Paper Reviews is Diffusion-LM Improves Controllable Text Generation and Sparsifying Transformer Models with Trainable Representation Pooling.",
            "pubdate": "Wed, 24 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": 1661320800.0,
            "email_sent": true
        }
    },
    "Javier ML Blog": {},
    "Data School": {},
    "Lil'Log": {},
    "Hugging Face Blog": {}
}