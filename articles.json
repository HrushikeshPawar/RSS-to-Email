{
    "DeepMind Blog": {
        "Spurious normativity enhances learning of compliance and enforcement behavior in artificial agents": {
            "url": "https://www.deepmind.com/blog/spurious-normativity-enhances-learning-of-compliance-and-enforcement-behavior-in-artificial-agents",
            "description": "In our recent paper we explore how multi-agent deep reinforcement learning can serve as a model of complex social interactions, like the formation of social norms. This new class of models could provide a path to create richer, more detailed simulations of the world.",
            "pubdate": "Tue, 18 Jan 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                18
            ],
            "email_sent": true
        },
        "DeepMind: The Podcast returns for Season 2": {
            "url": "https://www.deepmind.com/blog/deepmind-the-podcast-returns-for-season-2",
            "description": "We believe artificial intelligence (AI) is one of the most significant technologies of our age and we want to help people understand its potential and how it\u2019s being created.",
            "pubdate": "Tue, 25 Jan 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                25
            ],
            "email_sent": true
        },
        "Competitive programming with AlphaCode": {
            "url": "https://www.deepmind.com/blog/competitive-programming-with-alphacode",
            "description": "Solving novel problems and setting a new milestone in competitive programming.",
            "pubdate": "Wed, 02 Feb 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                2
            ],
            "email_sent": true
        },
        "Red Teaming Language Models with Language Models": {
            "url": "https://www.deepmind.com/blog/red-teaming-language-models-with-language-models",
            "description": "In our recent paper, we show that it is possible to automatically find inputs that elicit harmful text from language models by generating inputs using language models themselves. Our approach provides one tool for finding harmful model behaviours before users are impacted, though we emphasize that it should be viewed as one component alongside many other techniques that will be needed to find harms and mitigate them once found.",
            "pubdate": "Mon, 07 Feb 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                7
            ],
            "email_sent": true
        },
        "MuZeros first step from research into the real world": {
            "url": "https://www.deepmind.com/blog/muzeros-first-step-from-research-into-the-real-world",
            "description": "Collaborating with YouTube to optimise video compression in the open source VP9 codec.",
            "pubdate": "Fri, 11 Feb 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                11
            ],
            "email_sent": true
        },
        "Accelerating fusion science through learned plasma control": {
            "url": "https://www.deepmind.com/blog/accelerating-fusion-science-through-learned-plasma-control",
            "description": "Successfully controlling the nuclear fusion plasma in a tokamak with deep reinforcement learning",
            "pubdate": "Wed, 16 Feb 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                16
            ],
            "email_sent": true
        },
        "Probing Image-Language Transformers for Verb Understanding": {
            "url": "https://www.deepmind.com/blog/probing-image-language-transformers-for-verb-understanding",
            "description": "Multimodal Image-Language transformers have achieved impressive results on a variety of tasks that rely on fine-tuning (e.g., visual question answering and image retrieval). We are interested in shedding light on the quality of their pretrained representations--in particular, if these models can distinguish verbs or they only use the nouns in a given sentence. To do so, we collect a dataset of image-sentence pairs consisting of 447 verbs that are either visual or commonly found in the pretraining data (i.e., the Conceptual Captions dataset). We use this dataset to evaluate the pretrained models in a zero-shot way.",
            "pubdate": "Wed, 23 Feb 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                23
            ],
            "email_sent": true
        },
        "Learning Robust Real-Time Cultural Transmission without Human Data": {
            "url": "https://www.deepmind.com/blog/learning-robust-real-time-cultural-transmission-without-human-data",
            "description": "In this work, we use deep reinforcement learning to generate artificial agents capable of test-time cultural transmission. Once trained, our agents can infer and recall navigational knowledge demonstrated by experts. This knowledge transfer happens in real time and generalises across a vast space of previously unseen tasks.",
            "pubdate": "Thu, 03 Mar 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                3
            ],
            "email_sent": true
        },
        "Predicting the past with Ithaca": {
            "url": "https://www.deepmind.com/blog/predicting-the-past-with-ithaca",
            "description": "The birth of human writing marked the dawn of History and is crucial to our understanding of past civilisations and the world we live in today. For example, more than 2,500 years ago, the Greeks began writing on stone, pottery, and metal to document everything from leases and laws to calendars and oracles, giving a detailed insight into the Mediterranean region. Unfortunately, it\u2019s an incomplete record. Many of the surviving inscriptions have been damaged over the centuries or moved from their original location. In addition, modern dating techniques, such as radiocarbon dating, cannot be used on these materials, making inscriptions difficult and time-consuming to interpret.",
            "pubdate": "Wed, 09 Mar 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                9
            ],
            "email_sent": true
        },
        "GopherCite: Teaching language models to support answers with verified quotes": {
            "url": "https://www.deepmind.com/blog/gophercite-teaching-language-models-to-support-answers-with-verified-quotes",
            "description": "Language models like Gopher can \u201challucinate\u201d facts that appear plausible but are actually fake. Those who are familiar with this problem know to do their own fact-checking, rather than trusting what language models say. Those who are not, may end up believing something that isn\u2019t true. This paper describes GopherCite, a model which aims to address the problem of language model hallucination. GopherCite attempts to back up all of its factual claims with evidence from the web.",
            "pubdate": "Wed, 16 Mar 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                16
            ],
            "email_sent": true
        },
        "An empirical analysis of compute-optimal large language model training": {
            "url": "https://www.deepmind.com/blog/an-empirical-analysis-of-compute-optimal-large-language-model-training",
            "description": "We ask the question: \u201cWhat is the optimal model size and number of training tokens for a given compute budget?\u201d To answer this question, we train models of various sizes and with various numbers of tokens, and estimate this trade-off empirically. Our main finding is that the current large language models are far too large for their compute budget and are not being trained on enough data.",
            "pubdate": "Tue, 12 Apr 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                12
            ],
            "email_sent": true
        },
        "DeepMinds latest research at ICLR 2022": {
            "url": "https://www.deepmind.com/blog/deepminds-latest-research-at-iclr-2022",
            "description": "Beyond supporting the event as sponsors and regular workshop organisers, our research teams are presenting 29 papers, including 10 collaborations this year. Here\u2019s a brief glimpse into our upcoming oral, spotlight, and poster presentations.",
            "pubdate": "Mon, 25 Apr 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                25
            ],
            "email_sent": true
        },
        "Tackling multiple tasks with a single visual language model": {
            "url": "https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model",
            "description": "We introduce Flamingo, a single visual language model (VLM) that sets a new state of the art in few-shot learning on a wide range of open-ended multimodal tasks.",
            "pubdate": "Thu, 28 Apr 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                28
            ],
            "email_sent": true
        },
        "When a passion for bass and brass help build better tools": {
            "url": "https://www.deepmind.com/blog/when-a-passion-for-bass-and-brass-help-build-better-tools",
            "description": "We caught up with Kevin Millikin, a software engineer on the DevTools team. He\u2019s in Salt Lake City this week to present at PyCon US, the largest annual gathering for those using and developing the open-source Python programming language.",
            "pubdate": "Thu, 28 Apr 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                28
            ],
            "email_sent": true
        },
        "Active offline policy selection": {
            "url": "https://www.deepmind.com/blog/active-offline-policy-selection",
            "description": "To make RL more applicable to real-world applications like robotics, we propose using an intelligent evaluation procedure to select the policy for deployment, called active offline policy selection (A-OPS). In A-OPS, we make use of the prerecorded dataset and allow limited interactions with the real environment to boost the selection quality.",
            "pubdate": "Fri, 06 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                6
            ],
            "email_sent": true
        },
        "A Generalist Agent": {
            "url": "https://www.deepmind.com/blog/a-generalist-agent",
            "description": "Inspired by progress in large-scale language modelling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi-modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens.",
            "pubdate": "Thu, 12 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                12
            ],
            "email_sent": true
        },
        "Emergent Bartering Behaviour in Multi-Agent Reinforcement Learning": {
            "url": "https://www.deepmind.com/blog/emergent-bartering-behaviour-in-multi-agent-reinforcement-learning",
            "description": "In our recent paper, we explore how populations of deep reinforcement learning (deep RL) agents can learn microeconomic behaviours, such as production, consumption, and trading of goods. We find that artificial agents learn to make economically rational decisions about production, consumption, and prices, and react appropriately to supply and demand changes.",
            "pubdate": "Mon, 16 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                16
            ],
            "email_sent": true
        },
        "From LEGO competitions to DeepMind's robotics lab": {
            "url": "https://www.deepmind.com/blog/from-lego-competitions-to-deepminds-robotics-lab",
            "description": "If you want to be at DeepMind, go for it. Apply, interview, and just try. You might not get it the first time but that doesn\u2019t mean you can\u2019t try again. I never thought DeepMind would accept me, and when they did, I thought it was a mistake. Everyone doubts themselves \u2013 I\u2019ve never felt like the smartest person in the room. I\u2019ve often felt the opposite. But I\u2019ve learned that, despite those feelings, I do belong and I do deserve to work at a place like this. And that journey, for me, started with just trying.",
            "pubdate": "Thu, 19 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                19
            ],
            "email_sent": true
        },
        "Open-sourcing MuJoCo": {
            "url": "https://www.deepmind.com/blog/open-sourcing-mujoco",
            "description": "In October 2021, we announced that we acquired the MuJoCo physics simulator, and made it freely available for everyone to support research everywhere. We also committed to developing and maintaining MuJoCo as a free, open-source, community-driven project with best-in-class capabilities. Today, we\u2019re thrilled to report that open sourcing is complete and the entire codebase is on GitHub!\u00a0Here, we explain why MuJoCo is a great platform for open-source collaboration and share a preview of our roadmap going forward.",
            "pubdate": "Mon, 23 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                23
            ],
            "email_sent": true
        },
        "Building a culture of pioneering responsibly": {
            "url": "https://www.deepmind.com/blog/building-a-culture-of-pioneering-responsibly",
            "description": "When I joined DeepMind as COO, I did so in large part because I could tell that the founders and team had the same focus on positive social impact. In fact, at DeepMind, we now champion a term that perfectly captures my own values and hopes for integrating technology into people\u2019s daily lives: pioneering responsibly. I believe pioneering responsibly should be a priority for anyone working in tech. But I also recognise that it\u2019s especially important when it comes to powerful, widespread technologies like artificial intelligence. AI is arguably the most impactful technology being developed today. It has the potential to benefit humanity in innumerable ways \u2013 from combating climate change to preventing and treating disease. But it\u2019s essential that we account for both its positive and negative downstream impacts.",
            "pubdate": "Tue, 24 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                24
            ],
            "email_sent": true
        },
        "Kyrgyzstan to Kings Cross: the star baker cooking up code": {
            "url": "https://www.deepmind.com/blog/kyrgyzstan-to-kings-cross-the-star-baker-cooking-up-code",
            "description": "My day can vary, it really depends on which phase of the project I'm on. Let\u2019s say we want to add a feature to our product \u2013 my tasks could range from designing solutions and working with the team to find the best one, to deploying new features into production and doing maintenance. Along the way, I\u2019ll communicate changes to our stakeholders, write docs, code and test solutions, build analytics dashboards, clean-up old code, and fix bugs.",
            "pubdate": "Thu, 26 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                26
            ],
            "email_sent": true
        },
        "Dynamic language understanding: adaptation to new knowledge in parametric and semi-parametric models": {
            "url": "https://www.deepmind.com/blog/dynamic-language-understanding-adaptation-to-new-knowledge-in-parametric-and-semi-parametric-models",
            "description": "To study how semi-parametric QA models and their underlying parametric language models (LMs) adapt to evolving knowledge, we construct a new large-scale dataset, StreamingQA, with human written and generated questions asked on a given date, to be answered from 14 years of time-stamped news articles. We evaluate our models quarterly as they read new articles not seen in pre-training. We show that parametric models can be updated without full retraining, while avoiding catastrophic forgetting.",
            "pubdate": "Thu, 26 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                26
            ],
            "email_sent": true
        },
        "Evaluating Multimodal Interactive Agents": {
            "url": "https://www.deepmind.com/blog/evaluating-multimodal-interactive-agents",
            "description": "In this paper, we assess the merits of these existing evaluation metrics and present a novel approach to evaluation called the Standardised Test Suite (STS). The STS uses behavioural scenarios mined from real human interaction data.",
            "pubdate": "Fri, 27 May 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                27
            ],
            "email_sent": true
        },
        "Advocating for the LGBTQ+ community in AI research": {
            "url": "https://www.deepmind.com/blog/advocating-for-the-lgbtq-community-in-ai-research",
            "description": "Research scientist, Kevin McKee, tells how his early love of science fiction and social psychology inspired his career, and how he\u2019s helping advance research in \u2018queer fairness\u2019, support human-AI collaboration, and study the effects of AI on the LGBTQ+ community.",
            "pubdate": "Wed, 01 Jun 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                1
            ],
            "email_sent": true
        },
        "Bridging DeepMind research with Alphabet products": {
            "url": "https://www.deepmind.com/blog/bridging-deepmind-research-with-alphabet-products",
            "description": "Today we caught up with Gemma Jennings, a product manager on the Applied team, who led a session on vision language models at the AI Summit, one of the world\u2019s largest AI events for business.",
            "pubdate": "Wed, 15 Jun 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                15
            ],
            "email_sent": true
        },
        "Unlocking High-Accuracy Differentially Private Image Classification through Scale": {
            "url": "https://www.deepmind.com/blog/unlocking-high-accuracy-differentially-private-image-classification-through-scale",
            "description": "According to empirical evidence from prior works, utility degradation in DP-SGD becomes more severe on larger neural network models \u2013 including the ones regularly used to achieve the best performance on challenging image classification benchmarks. Our work investigates this phenomenon and proposes a series of simple modifications to both the training procedure and model architecture, yielding a significant improvement on the accuracy of DP training on standard image classification benchmarks.",
            "pubdate": "Fri, 17 Jun 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                17
            ],
            "email_sent": true
        },
        "BYOL-Explore: Exploration with Bootstrapped Prediction": {
            "url": "https://www.deepmind.com/blog/byol-explore-exploration-with-bootstrapped-prediction",
            "description": "We present BYOL-Explore, a conceptually simple yet general approach for curiosity-driven exploration in visually-complex environments. BYOL-Explore learns a world representation, the world dynamics, and an exploration policy all-together by optimizing a single prediction loss in the latent space with no additional auxiliary objective. We show that BYOL-Explore is effective in DM-HARD-8, a challenging partially-observable continuous-action hard-exploration benchmark with visually-rich 3-D environments.",
            "pubdate": "Mon, 20 Jun 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                20
            ],
            "email_sent": true
        },
        "Leading a movement to strengthen machine learning in Africa": {
            "url": "https://www.deepmind.com/blog/leading-a-movement-to-strengthen-machine-learning-in-africa",
            "description": "",
            "pubdate": "Thu, 23 Jun 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                23
            ],
            "email_sent": true
        },
        "Human-centred mechanism design with Democratic AI": {
            "url": "https://www.deepmind.com/blog/human-centred-mechanism-design-with-democratic-ai",
            "description": "In our recent paper, published in Nature Human Behaviour, we provide a proof-of-concept demonstration that deep reinforcement learning (RL) can be used to find economic policies that people will vote for by majority in a simple game. The paper thus addresses a key challenge in AI research - how to train AI systems that align with human values.",
            "pubdate": "Mon, 04 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                4
            ],
            "email_sent": true
        },
        "Intuitive physics learning in a deep-learning model inspired by developmental psychology": {
            "url": "https://www.deepmind.com/blog/intuitive-physics-learning-in-a-deep-learning-model-inspired-by-developmental-psychology",
            "description": "Despite significant effort, current AI systems pale in their understanding of intuitive physics, in comparison to even very young children. In the present work, we address this AI problem, specifically by drawing on the field of developmental psychology.",
            "pubdate": "Mon, 11 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                11
            ],
            "email_sent": true
        },
        "Working together with YouTube": {
            "url": "https://www.deepmind.com/blog/working-together-with-youtube",
            "description": "",
            "pubdate": "Thu, 14 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                14
            ],
            "email_sent": true
        },
        "DeepMinds latest research at ICML 2022": {
            "url": "https://www.deepmind.com/blog/deepminds-latest-research-at-icml-2022",
            "description": "Starting this weekend, the thirty-ninth International Conference on Machine Learning (ICML 2022) is meeting from 17-23 July, 2022 at the Baltimore Convention Center in Maryland, USA, and will be running as a hybrid event. Researchers working across artificial intelligence, data science, machine vision, computational biology, speech recognition, and more are presenting and publishing their cutting-edge work in machine learning.",
            "pubdate": "Fri, 15 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                15
            ],
            "email_sent": true
        },
        "Perceiver AR: general-purpose, long-context autoregressive generation": {
            "url": "https://www.deepmind.com/blog/perceiver-ar-general-purpose-long-context-autoregressive-generation",
            "description": "We develop Perceiver AR, an autoregressive, modality-agnostic architecture which uses cross-attention to map long-range inputs to a small number of latents while also maintaining end-to-end causal masking. Perceiver AR can directly attend to over a hundred thousand tokens, enabling practical long-context density estimation without the need for hand-crafted sparsity patterns or memory mechanisms.",
            "pubdate": "Sat, 16 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                16
            ],
            "email_sent": true
        },
        "The virtuous cycle of AI research": {
            "url": "https://www.deepmind.com/blog/the-virtuous-cycle-of-ai-research",
            "description": "We recently caught up with Petar Veli\u010dkovi\u0107, a research scientist at DeepMind. Along with his co-authors, Petar is presenting his paper The CLRS Algorithmic Reasoning Benchmark at ICML 2022 in Baltimore, Maryland, USA.",
            "pubdate": "Tue, 19 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                19
            ],
            "email_sent": true
        },
        "AlphaFold reveals the structure of the protein universe": {
            "url": "https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe",
            "description": "Today, in partnership with EMBL\u2019s European Bioinformatics Institute (EMBL-EBI), we\u2019re now releasing predicted structures for nearly all catalogued proteins known to science, which will expand the AlphaFold DB by over 200x - from nearly 1 million structures to over 200 million structures - with the potential to dramatically increase our understanding of biology.",
            "pubdate": "Thu, 28 Jul 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                28
            ],
            "email_sent": true
        },
        "Realising scientists are the real superheroes": {
            "url": "https://www.deepmind.com/blog/realising-scientists-are-the-real-superheroes",
            "description": "Meet Edgar Du\u00e9\u00f1ez-Guzm\u00e1n, a research engineer on our Multi-Agent Research team who\u2019s drawing on knowledge of game theory, computer science, and social evolution to get AI agents working better together.",
            "pubdate": "Thu, 11 Aug 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                11
            ],
            "email_sent": true
        },
        "Discovering when an agent is present in a system": {
            "url": "https://www.deepmind.com/blog/discovering-when-an-agent-is-present-in-a-system",
            "description": "We want to build safe, aligned artificial general intelligence (AGI) systems that pursue the intended goals of its designers. Causal influence diagrams (CIDs) are a way to model decision-making situations that allow us to reason about agent incentives. By relating training setups to the incentives that shape agent behaviour, CIDs help illuminate potential risks before training an agent and can inspire better agent designs. But how do we know when a CID is an accurate model of a training setup?",
            "pubdate": "Thu, 18 Aug 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Advancing conservation with AI-based facial recognition of turtles": {
            "url": "https://www.deepmind.com/blog/advancing-conservation-with-ai-based-facial-recognition-of-turtles",
            "description": "We came across Zindi \u2013 a dedicated partner with complementary goals \u2013 who are the largest community of African data scientists and host competitions that focus on solving Africa\u2019s most pressing problems. Our Science team\u2019s Diversity, Equity, and Inclusion (DE&amp;I) team worked with Zindi to identify a scientific challenge that could help advance conservation efforts and grow involvement in AI. Inspired by Zindi\u2019s bounding box turtle challenge, we landed on a project with the potential for real impact: turtle facial recognition.",
            "pubdate": "Thu, 25 Aug 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "In conversation with artificial intelligence: aligning language models with human values": {
            "url": "https://www.deepmind.com/blog/in-conversation-with-artificial-intelligence-aligning-language-models-with-human-values",
            "description": "Our new paper, In conversation with AI: aligning language models with human values, explores a different approach, asking what successful communication between humans and an artificial conversational agent might look like and what values should guide conversation in these contexts.",
            "pubdate": "Tue, 06 Sep 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                9,
                6
            ],
            "email_sent": true
        },
        "How our principles helped define AlphaFolds release": {
            "url": "https://www.deepmind.com/blog/how-our-principles-helped-define-alphafolds-release",
            "description": "Our Operating Principles have come to define both our commitment to prioritising widespread benefit, as well as the areas of research and applications we refuse to pursue. These principles have been at the heart of our decision making since DeepMind was founded, and continue to be refined as the AI landscape changes and grows. They are designed for our role as a research-driven science company and consistent with Google\u2019s AI principles.",
            "pubdate": "Wed, 14 Sep 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                9,
                14
            ],
            "email_sent": true
        },
        "Building safer dialogue agents": {
            "url": "https://www.deepmind.com/blog/building-safer-dialogue-agents",
            "description": "In our latest paper, we introduce Sparrow \u2013 a dialogue agent that\u2019s useful and reduces the risk of unsafe and inappropriate answers. Our agent is designed to talk with a user, answer questions, and search the internet using Google when it\u2019s helpful to look up evidence to inform its responses.",
            "pubdate": "Thu, 22 Sep 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                9,
                22
            ],
            "email_sent": true
        },
        "How undesired goals can arise with correct rewards": {
            "url": "https://www.deepmind.com/blog/how-undesired-goals-can-arise-with-correct-rewards",
            "description": "As we build increasingly advanced artificial intelligence (AI) systems, we want to make sure they don\u2019t pursue undesired goals. Such behaviour in an AI agent is often the result of specification gaming \u2013 exploiting a poor choice of what they are rewarded for. In our latest paper, we explore a more subtle mechanism by which AI systems may unintentionally learn to pursue undesired goals: goal misgeneralisation (GMG).\u00a0GMG occurs when a system's capabilities generalise successfully but its goal does not generalise as desired, so the system competently pursues the wrong goal. Crucially, in contrast to specification gaming, GMG can occur even when the AI system is trained with a correct specification.",
            "pubdate": "Fri, 07 Oct 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                10,
                7
            ],
            "email_sent": true
        },
        "Measuring perception in AI models": {
            "url": "https://www.deepmind.com/blog/measuring-perception-in-ai-models",
            "description": "Perception \u2013 the process of experiencing the world through senses \u2013 is a significant part of intelligence. And building agents with human-level perceptual understanding of the world is a central but challenging task, which is becoming increasingly important in robotics, self-driving cars, personal assistants, medical imaging, and more. So today, we\u2019re introducing the Perception Test, a multimodal benchmark using real-world videos to help evaluate the perception capabilities of a model.",
            "pubdate": "Wed, 12 Oct 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                10,
                12
            ],
            "email_sent": true
        },
        "The pursuit of AI education - past, present and future": {
            "url": "https://www.deepmind.com/blog/the-pursuit-of-ai-education-past-present-and-future",
            "description": "Meet Sylvia Christie, our education partnerships manager who\u2019s played a leading role in expanding our scholarship programme, which is marking its five-year anniversary.",
            "pubdate": "Tue, 08 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                8
            ],
            "email_sent": true
        },
        "DeepMinds latest research at ICLR 2023": {
            "url": "https://www.deepmind.com/blog/deepminds-latest-research-at-iclr-2023",
            "description": "Next week marks the start of the 11th International Conference on Learning Representations (ICLR), taking place 1-5 May in Kigali, Rwanda. This will be the first major artificial intelligence (AI) conference to be hosted in Africa and the first in-person event since the start of the pandemic. Researchers from around the world will gather to share their cutting-edge work in deep learning spanning the fields of AI, statistics and data science, and applications including machine vision, gaming and robotics. We\u2019re proud to support the conference as a Diamond sponsor and DEI champion.",
            "pubdate": "Thu, 27 Apr 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                4,
                27
            ],
            "email_sent": true
        },
        "Using AI to fight climate change": {
            "url": "https://www.deepmind.com/blog/using-ai-to-fight-climate-change",
            "description": "AI is a powerful technology that will transform our future, so how can we best apply it to help combat climate change and find sustainable solutions? The effects of climate change on Earth\u2019s ecosystems are incredibly complex, and as part of our effort to use AI for solving some of the world\u2019s most challenging problems, here are some of the ways we\u2019re working to advance our understanding, optimise existing systems, and accelerate breakthrough science of climate and its effects.",
            "pubdate": "Fri, 21 Jul 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "RT-2: New model translates vision and language into action": {
            "url": "https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action",
            "description": "Introducing Robotic Transformer 2 (RT-2), a novel vision-language-action (VLA) model that learns from both web and robotics data, and translates this knowledge into generalised instructions for robotic control, while retaining web-scale capabilities. This work builds upon Robotic Transformer 1 (RT-1), a model trained on multi-task demonstrations which can learn combinations of tasks and objects seen in the robotic data. RT-2 shows improved generalisation capabilities and semantic and visual understanding, beyond the robotic data it was exposed to. This includes interpreting new commands and responding to user commands by performing rudimentary reasoning, such as reasoning about object categories or high-level descriptions.",
            "pubdate": "Fri, 28 Jul 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "Identifying AI-generated images with SynthID": {
            "url": "https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid",
            "description": "Today, in partnership with Google Cloud, we\u2019re beta launching SynthID, a new tool for watermarking and identifying AI-generated images. It\u2019s being released to a limited number of Vertex AI customers using Imagen, one of our latest text-to-image models that uses input text to create photorealistic images. This technology embeds a digital watermark directly into the pixels of an image, making it imperceptible to the human eye, but detectable for identification. While generative AI can unlock huge creative potential, it also presents new risks, like creators spreading false information \u2014 both intentionally or unintentionally. Being able to identify AI-generated content is critical to empowering people with knowledge of when they\u2019re interacting with generated media, and for helping prevent the spread of misinformation.",
            "pubdate": "Tue, 29 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        }
    },
    "Nvidia Blog": {
        "Smart Devices, Smart Manufacturing: Pegatron Taps AI, Digital Twins": {
            "url": "https://blogs.nvidia.com/blog/2022/08/16/pegatron-ai-omniverse/",
            "description": "<p>In the fast-paced field of making the world\u2019s tech devices, Pegatron Corp. initially harnessed AI to gain an edge. Now, it\u2019s on the cusp of creating digital twins to further streamline its efficiency. Whether or not they\u2019re familiar with the name, most people have probably used smartphones, tablets, Wi-Fi routers or other products that Taiwan-based <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/16/pegatron-ai-omniverse/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/16/pegatron-ai-omniverse/\" rel=\"nofollow\">Smart Devices, Smart Manufacturing: Pegatron Taps AI, Digital Twins</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 16 Aug 2022 15:00:59 +0000",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "AI Shows the Way: Seoul Robotics Helps Cars Move, Park on Their Own": {
            "url": "https://blogs.nvidia.com/blog/2022/08/16/seoul-robotics-autonomy-through-infrastructure/",
            "description": "<p>Imagine driving a car \u2014 one without self-driving capabilities \u2014 to a mall, airport or parking garage, and using an app to have the car drive off to park itself. Software company Seoul Robotics is using NVIDIA technology to make this possible \u2014 turning non-autonomous cars into self-driving vehicles. Headquartered in Korea, the company\u2019s initial <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/16/seoul-robotics-autonomy-through-infrastructure/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/16/seoul-robotics-autonomy-through-infrastructure/\" rel=\"nofollow\">AI Shows the Way: Seoul Robotics Helps Cars Move, Park on Their Own</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 16 Aug 2022 15:00:43 +0000",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "Digital Art Professor Kate Parsons Inspires Next Generation of Creators This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/08/16/in-the-nvidia-studio-august-16/",
            "description": "<p>Many artists can edit a video, paint a picture or build a model \u2014 but transforming one\u2019s imagination into stunning creations can now involve breakthrough design technologies. Kate Parsons, a digital art professor at Pepperdine University and this week\u2019s featured In the NVIDIA Studio artist, helped bring a music video for How Do I Get to Invincible to life using virtual reality and NVIDIA GeForce RTX GPUs. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/16/in-the-nvidia-studio-august-16/\" rel=\"nofollow\">Digital Art Professor Kate Parsons Inspires Next Generation of Creators This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 16 Aug 2022 13:00:48 +0000",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "Immunai Co-Founder Luis Voloch on Using Deep Learning to Develop New Drugs": {
            "url": "https://blogs.nvidia.com/blog/2022/08/17/immunai-luis-voloch/",
            "description": "<p>Mapping the immune system could lead to the creation of drugs that help our bodies win the fight against cancer and other diseases. That\u2019s the big idea behind immunotherapy. The problem: the immune system is incredibly complex. Enter Immunai, a biotech company that\u2019s using cutting-edge genomics &#38; ML technology to map the human immune system <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/17/immunai-luis-voloch/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/17/immunai-luis-voloch/\" rel=\"nofollow\">Immunai Co-Founder Luis Voloch on Using Deep Learning to Develop New Drugs</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 17 Aug 2022 13:00:41 +0000",
            "pubdate_parsed": [
                2022,
                8,
                17
            ],
            "email_sent": true
        },
        "Startup Digs Into Public Filings With GPU-Driven Machine Learning to Serve Up Alternative Financial Data Services": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/gpu-driven-machine-learning-alternative-financial-data-services/",
            "description": "<p>When Rachel Carpenter and Joseph French founded Intrinio a decade ago, the fintech revolution had only just begun. But they saw an opportunity to apply machine learning to vast amounts of financial filings to create an alternative data provider among the giants. The startup, based in St. Petersburg, Fla., delivers financial data to hedge funds, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/gpu-driven-machine-learning-alternative-financial-data-services/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/gpu-driven-machine-learning-alternative-financial-data-services/\" rel=\"nofollow\">Startup Digs Into Public Filings With GPU-Driven Machine Learning to Serve Up Alternative Financial Data Services</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 16:06:46 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Boldly Go: Discover New Frontiers in AI-Powered Transportation at GTC": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/discover-frontiers-ai-autonomous-vehicles-gtc/",
            "description": "<p>AI and the metaverse are revolutionizing every aspect of the way we live, work and play \u2014 including how we move. Leaders in the automotive and technology industries will come together at NVIDIA GTC to discuss the newest breakthroughs driving intelligent vehicles, whether in the real world or in simulation. The virtual conference, which runs <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/discover-frontiers-ai-autonomous-vehicles-gtc/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/discover-frontiers-ai-autonomous-vehicles-gtc/\" rel=\"nofollow\">Boldly Go: Discover New Frontiers in AI-Powered Transportation at GTC</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 15:32:48 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Startups Vision AI Software Trains Itself  in One Hour  to Detect Manufacturing Defects in Real Time": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/covision-visual-inspection-for-manufacturing/",
            "description": "<p>Cameras have been deployed in factories for over a decade \u2014 so why, Franz Tschimben wondered, hasn\u2019t automated visual inspection yet become the worldwide standard? This question motivated Tschimben and his colleagues to found Covision Quality, an AI-based visual-inspection software startup that uses NVIDIA technology to transform end-of-line defect detection for the manufacturing industry. \u201cThe <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/covision-visual-inspection-for-manufacturing/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/covision-visual-inspection-for-manufacturing/\" rel=\"nofollow\">Startup\u2019s Vision AI Software Trains Itself \u2014 in One Hour \u2014 to Detect Manufacturing Defects in Real Time</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 15:00:39 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Easy A: GeForce NOW Brings Higher Resolution and Frame Rates for Browser Streaming on PC": {
            "url": "https://blogs.nvidia.com/blog/2022/08/18/geforce-now-thursday-august-18/",
            "description": "<p>Class is in session this GFN Thursday as GeForce NOW makes the up-grade with support for higher resolutions and frame rates in Chrome browser on PC. It\u2019s the easiest way to spice up a boring study session. When the lecture is over, dive into the six games joining the GeForce NOW library this week, where <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/18/geforce-now-thursday-august-18/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/18/geforce-now-thursday-august-18/\" rel=\"nofollow\">Easy A: GeForce NOW Brings Higher Resolution and Frame Rates for Browser Streaming on PC</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 13:00:55 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "NVIDIA to Share New Details on Grace CPU, Hopper GPU, NVLink Switch, Jetson Orin Module at Hot Chips": {
            "url": "https://blogs.nvidia.com/blog/2022/08/19/grace-hopper-nvswitch-hot-chips/",
            "description": "<p>In four talks over two days, senior NVIDIA engineers will describe innovations in accelerated computing for modern data centers and systems at the edge of the network. Speaking at a virtual Hot Chips event, an annual gathering of processor and system architects, they\u2019ll disclose performance numbers and other technical details for NVIDIA\u2019s first server CPU, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/19/grace-hopper-nvswitch-hot-chips/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/19/grace-hopper-nvswitch-hot-chips/\" rel=\"nofollow\">NVIDIA to Share New Details on Grace CPU, Hopper GPU, NVLink Switch, Jetson Orin Module at Hot Chips</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Fri, 19 Aug 2022 15:00:33 +0000",
            "pubdate_parsed": [
                2022,
                8,
                19
            ],
            "email_sent": true
        },
        "Meet the Omnivore: Startup in3D Turns Selfies Into Talking, Dancing Avatars With NVIDIA Omniverse": {
            "url": "https://blogs.nvidia.com/blog/2022/08/19/omniverse-developer-in3d/",
            "description": "<p>Imagine taking a selfie and using it to get a moving, talking, customizable 3D avatar of yourself in just seconds.\u00a0</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/19/omniverse-developer-in3d/\" rel=\"nofollow\">Meet the Omnivore: Startup in3D Turns Selfies Into Talking, Dancing Avatars With NVIDIA Omniverse</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Fri, 19 Aug 2022 15:00:02 +0000",
            "pubdate_parsed": [
                2022,
                8,
                19
            ],
            "email_sent": true
        },
        "An AI-Enabled Drone Could Soon Become Every Rhino Poachers Horn Enemy": {
            "url": "https://blogs.nvidia.com/blog/2022/08/22/ai-drone-rhino-poachers/",
            "description": "<p>Watching out for the nearly-extinct two-ton beasts may be the ultimate example of a job best done remotely.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/22/ai-drone-rhino-poachers/\" rel=\"nofollow\">An AI-Enabled Drone Could Soon Become Every Rhino Poacher&#8217;s\u2026 Horn Enemy</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 22 Aug 2022 13:00:59 +0000",
            "pubdate_parsed": [
                2022,
                8,
                22
            ],
            "email_sent": true
        },
        "Learn How Leading Companies Are Building AI Centers of Excellence, at NVIDIA GTC": {
            "url": "https://blogs.nvidia.com/blog/2022/08/23/gtc-ai-centers-of-excellence/",
            "description": "<p>AI Centers of Excellence are organizational units dedicated to implementing a company-wide AI vision. They help identify business use cases, create an implementation roadmap, accelerate adoption, assess impact and more. NVIDIA GTC, a global conference on AI and the metaverse, brings together the world\u2019s top business and technology leaders who\u2019ve embraced artificial intelligence to transform <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/23/gtc-ai-centers-of-excellence/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/23/gtc-ai-centers-of-excellence/\" rel=\"nofollow\">Learn How Leading Companies Are Building AI Centers of Excellence, at NVIDIA GTC</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 23 Aug 2022 16:00:59 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Shelter From the Storm: AI Helps Gauge Catastrophe Risks": {
            "url": "https://blogs.nvidia.com/blog/2022/08/23/ai-catastrophe-risk-masterful/",
            "description": "<p>Floods in Kentucky and wildfires in California are the kinds of disasters companies of all sorts are trying to address with AI. Tom Rikert, co-founder and CEO of San Francisco-based startup Masterful AI, is one of many experts helping them manage catastrophe risk. In the U.S. alone, the National Association of Insurance Commissioners estimates that <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/23/ai-catastrophe-risk-masterful/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/23/ai-catastrophe-risk-masterful/\" rel=\"nofollow\">Shelter From the Storm: AI Helps Gauge Catastrophe Risks</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 23 Aug 2022 15:00:55 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Predict, Detect, Mitigate: AI for Climate Science Takes the Stage at NVIDIA GTC": {
            "url": "https://blogs.nvidia.com/blog/2022/08/23/ai-for-climate-science-gtc/",
            "description": "<p>Recent AI advances enable modeling of weather forecasting 4-5 magnitudes faster than traditional computing methods. The brightest leaders, researchers and developers in climate science, high performance computing and AI will discuss such technology breakthroughs \u2014 and how they can help foster a greener Earth \u2014 at NVIDIA GTC. The virtual conference, running Sept. 19-22, also <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/23/ai-for-climate-science-gtc/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/23/ai-for-climate-science-gtc/\" rel=\"nofollow\">Predict, Detect, Mitigate: AI for Climate Science Takes the Stage at NVIDIA GTC</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 23 Aug 2022 15:00:18 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "3D Artists Reimagine, Remaster Iconic European Architecture This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/08/23/in-the-nvidia-studio-august-23/",
            "description": "<p>A triple threat steps In the NVIDIA Studio this week: a tantalizing trio of talented 3D artists who each reimagined and remastered classic European buildings with individualistic flair. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/23/in-the-nvidia-studio-august-23/\" rel=\"nofollow\">3D Artists Reimagine, Remaster Iconic European Architecture This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 23 Aug 2022 13:00:35 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "3D Artist Creates Blooming, Generative Sculptures With NVIDIA RTX and AI": {
            "url": "https://blogs.nvidia.com/blog/2022/08/25/generative-art-rtx-ai/",
            "description": "<p>Looking for a change of art? Try using AI \u2014 that\u2019s what 3D artist Nikola Damjanov is doing. Based in Serbia, Damjanov has over 15 years of experience in the graphics industry, from making 3D models and animations to creating high-quality visual effects for music videos and movies. Now an artist at game developer company <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/25/generative-art-rtx-ai/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/25/generative-art-rtx-ai/\" rel=\"nofollow\">3D Artist Creates Blooming, Generative Sculptures With NVIDIA RTX and AI</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 25 Aug 2022 16:00:28 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "Fintech Company Blocks Fraud Attacks for Financial Institutions With AI and NVIDIA GPUs": {
            "url": "https://blogs.nvidia.com/blog/2022/08/25/featurespace-blocks-financial-fraud/",
            "description": "<p>E-commerce sales have skyrocketed as more people shop remotely, spurred by the pandemic. But this surge has also led fraudsters to use the opportunity to scam retailers and customers, according to David Sutton, director of analytical technology at fintech company Featurespace. The company, headquartered in the U.K., has developed AI-powered technology to increase the speed <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/25/featurespace-blocks-financial-fraud/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/25/featurespace-blocks-financial-fraud/\" rel=\"nofollow\">Fintech Company Blocks Fraud Attacks for Financial Institutions With AI and NVIDIA GPUs</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 25 Aug 2022 15:00:22 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "GFN Thursday Adds Saints Row, Genshin Impact on Mobile With Touch Controls": {
            "url": "https://blogs.nvidia.com/blog/2022/08/25/geforce-now-thursday-august-25/",
            "description": "<p>Some weeks, GFN Thursday reveals new or unique features. Other weeks, it\u2019s a cool reward. And every week, it offers its members new games. This week, it\u2019s all of the above. First, Saints Row marches into GeForce NOW. Be your own boss in the new reboot of the classic open-world criminal adventure series, now available <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/25/geforce-now-thursday-august-25/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/25/geforce-now-thursday-august-25/\" rel=\"nofollow\">GFN Thursday Adds \u2018Saints Row,\u2019 \u2018Genshin Impact\u2019 on Mobile With Touch Controls</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 25 Aug 2022 13:00:02 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "OBS Studio to Release Software Update 28.0 With NVIDIA Broadcast Features In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/08/31/in-the-nvidia-studio-august-31/",
            "description": "<p>In the NVIDIA Studio celebrates the Open Broadcaster Software (OBS) Studio\u2019s 10th anniversary and its 28.0 software release. Plus, popular streamer WATCHHOLLIE shares how she uses OBS and a GeForce RTX 3080 GPU in a single-PC setup to elevate her livestreams.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/31/in-the-nvidia-studio-august-31/\" rel=\"nofollow\">OBS Studio to Release Software Update 28.0 With NVIDIA Broadcast Features \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 31 Aug 2022 13:00:44 +0000",
            "pubdate_parsed": [
                2022,
                8,
                31
            ],
            "email_sent": true
        },
        "Rendered.ai Founder and CEO Nathan Kundtz on Using AI to Build Better AI": {
            "url": "https://blogs.nvidia.com/blog/2022/08/31/rendered-ai/",
            "description": "<p>Data is the fuel that makes artificial intelligence run. Training machine learning and AI systems requires data. And the quality of datasets has a big impact on the systems\u2019 results. But compiling quality real-world data for AI and ML can be difficult and expensive. That\u2019s where synthetic data comes in. The guest for this week\u2019s <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/08/31/rendered-ai/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/08/31/rendered-ai/\" rel=\"nofollow\">Rendered.ai Founder and CEO Nathan Kundtz on Using AI to Build Better AI</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 31 Aug 2022 13:00:41 +0000",
            "pubdate_parsed": [
                2022,
                8,
                31
            ],
            "email_sent": true
        },
        "GFN Thursday Slides Into September With 22 New Games": {
            "url": "https://blogs.nvidia.com/blog/2022/09/01/geforce-now-thursday-september-1/",
            "description": "<p>We\u2019d wake you up when September ends, but then you\u2019d miss out on a whole new set of games coming to GeForce NOW. Gear up for 22 games joining the GeForce NOW library, with 19 day-and-date releases including action role-playing game Steelrising. Playing them all will take some serious strategy. And build the perfect Minifigure <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/01/geforce-now-thursday-september-1/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/01/geforce-now-thursday-september-1/\" rel=\"nofollow\">GFN Thursday Slides Into September With 22 New Games</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 01 Sep 2022 13:00:47 +0000",
            "pubdate_parsed": [
                2022,
                9,
                1
            ],
            "email_sent": true
        },
        "Ridiculously Realistic Renders Rule This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/09/06/in-the-nvidia-studio-september-6/",
            "description": "<p>Viral creator turned NVIDIA 3D artist Lorenzo Drago takes viewers on a jaw-dropping journey through Toyama, Japan\u2019s Etch\u016b-Daimon Station this week In the NVIDIA Studio. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/06/in-the-nvidia-studio-september-6/\" rel=\"nofollow\">Ridiculously Realistic Renders Rule This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 06 Sep 2022 13:00:27 +0000",
            "pubdate_parsed": [
                2022,
                9,
                6
            ],
            "email_sent": true
        },
        "GeForce NOW Supports Over 1,400 Games Streaming Instantly": {
            "url": "https://blogs.nvidia.com/blog/2022/09/08/geforce-now-thursday-september-8/",
            "description": "<p>This GFN Thursday marks a milestone: With the addition of six new titles this week, more than 1,400 games are now available to stream from the GeForce NOW library. Plus, GeForce NOW members streaming to supported Smart TVs from Samsung and LG can get into their games faster with an improved user interface. Your Games, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/08/geforce-now-thursday-september-8/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/08/geforce-now-thursday-september-8/\" rel=\"nofollow\">GeForce NOW Supports Over 1,400 Games Streaming Instantly</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 08 Sep 2022 13:00:55 +0000",
            "pubdate_parsed": [
                2022,
                9,
                8
            ],
            "email_sent": true
        },
        "Concept Designer Ben Mauro Delivers Epic 3D Trailer Huxley This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/09/13/in-the-nvidia-studio-september-13/",
            "description": "<p>The gripping sci-fi comic Huxley was brought to life in an action-packed 3D trailer full of excitement and intrigue this week In the NVIDIA Studio.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/13/in-the-nvidia-studio-september-13/\" rel=\"nofollow\">Concept Designer Ben Mauro Delivers Epic 3D Trailer \u2018Huxley\u2019 This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 13 Sep 2022 13:00:23 +0000",
            "pubdate_parsed": [
                2022,
                9,
                13
            ],
            "email_sent": true
        },
        "GFN Thursday Delivers Seven New Games This Week": {
            "url": "https://blogs.nvidia.com/blog/2022/09/15/geforce-now-thursday-september-15/",
            "description": "<p>TGIGFNT: thank goodness it\u2019s GFN Thursday. Start your weekend early with seven new games joining the GeForce NOW library of over 1,400 titles. Whether it\u2019s streaming on an older-than-the-dinosaurs PC, a Mac that normally couldn\u2019t dream of playing PC titles, or mobile devices \u2013 it\u2019s all possible to play your way thanks to GeForce NOW. <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/15/geforce-now-thursday-september-15/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/15/geforce-now-thursday-september-15/\" rel=\"nofollow\">GFN Thursday Delivers Seven New Games This Week</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 15 Sep 2022 13:00:24 +0000",
            "pubdate_parsed": [
                2022,
                9,
                15
            ],
            "email_sent": true
        },
        "A Podcast With Teeth: How Overjet Brings AI to Dentists Offices": {
            "url": "https://blogs.nvidia.com/blog/2022/09/21/ai-podcast-overjet/",
            "description": "<p>Dentists get a bad rap. Dentists also get more people out of more aggravating pain than just about anyone. Which is why the more technology dentists have, the better. Overjet, a member of the NVIDIA Inception program for startups, is moving fast to bring AI to dentists\u2019 offices. On this episode of the NVIDIA AI <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/21/ai-podcast-overjet/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/21/ai-podcast-overjet/\" rel=\"nofollow\">A Podcast With Teeth: How Overjet Brings AI to Dentists\u2019 Offices</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 21 Sep 2022 13:00:46 +0000",
            "pubdate_parsed": [
                2022,
                9,
                21
            ],
            "email_sent": true
        },
        "Go Hands On: Logitech G CLOUD Launches With Support for GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2022/09/22/geforce-now-thursday-september-22/",
            "description": "<p>When it rains, it pours. And this GFN Thursday brings a downpour of news for GeForce NOW members. The Logitech G CLOUD is the latest gaming handheld device to support GeForce NOW, giving members a brand new way to keep the gaming going. But that\u2019s not all: Portal with RTX joins GeForce NOW in November, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/22/geforce-now-thursday-september-22/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/22/geforce-now-thursday-september-22/\" rel=\"nofollow\">Go Hands On: Logitech G CLOUD Launches With Support for GeForce NOW</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 22 Sep 2022 13:00:48 +0000",
            "pubdate_parsed": [
                2022,
                9,
                22
            ],
            "email_sent": true
        },
        "Continental and AEye Join NVIDIA DRIVE Sim Sensor Ecosystem, Providing Rich Capabilities for AV Development": {
            "url": "https://blogs.nvidia.com/blog/2022/09/22/continental-aeye-drive-sim-sensor-ecosystem/",
            "description": "<p>Autonomous vehicle sensors require the same rigorous testing and validation as the car itself, and one simulation platform is up to the task. Global tier-1 supplier Continental and software-defined lidar maker AEye announced this week at NVIDIA GTC that they will migrate their intelligent lidar sensor model into NVIDIA DRIVE Sim. The companies are the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/22/continental-aeye-drive-sim-sensor-ecosystem/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/22/continental-aeye-drive-sim-sensor-ecosystem/\" rel=\"nofollow\">Continental and AEye Join NVIDIA DRIVE Sim Sensor Ecosystem, Providing Rich Capabilities for AV Development</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 22 Sep 2022 12:41:01 +0000",
            "pubdate_parsed": [
                2022,
                9,
                22
            ],
            "email_sent": true
        },
        "World-Class: NVIDIA Research Builds AI Model to Populate Virtual Worlds With 3D Objects, Characters": {
            "url": "https://blogs.nvidia.com/blog/2022/09/23/3d-generative-ai-research-virtual-worlds/",
            "description": "<p>The massive virtual worlds created by growing numbers of companies and creators could be more easily populated with a diverse array of 3D buildings, vehicles, characters and more \u2014 thanks to a new AI model from NVIDIA Research. Trained using only 2D images, NVIDIA GET3D generates 3D shapes with high-fidelity textures and complex geometric details. <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/23/3d-generative-ai-research-virtual-worlds/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/23/3d-generative-ai-research-virtual-worlds/\" rel=\"nofollow\">World-Class: NVIDIA Research Builds AI Model to Populate Virtual Worlds With 3D Objects, Characters</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Fri, 23 Sep 2022 13:00:29 +0000",
            "pubdate_parsed": [
                2022,
                9,
                23
            ],
            "email_sent": true
        },
        "Video Virtuoso Sabour Amirazodi Shares AI-Powered Editing Tips This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/09/28/in-the-nvidia-studio-september-28/",
            "description": "<p>NVIDIA artist Sabour Amirazodi demonstrates his video editing workflows featuring AI this week in a special edition of In the NVIDIA Studio.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/28/in-the-nvidia-studio-september-28/\" rel=\"nofollow\">Video Virtuoso Sabour Amirazodi Shares AI-Powered Editing Tips This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 28 Sep 2022 13:00:28 +0000",
            "pubdate_parsed": [
                2022,
                9,
                28
            ],
            "email_sent": true
        },
        "All This and Mor-a Are Yours With Exclusive Genshin Impact GeForce NOW Membership Reward": {
            "url": "https://blogs.nvidia.com/blog/2022/09/29/geforce-now-thursday-september-29/",
            "description": "<p>It\u2019s good to be a GeForce NOW member. Genshin Impact\u2019s new Version 3.1 update launches this GFN Thursday, just in time for the game\u2019s second anniversary. Even better: GeForce NOW members can get an exclusive starter pack reward, perfect for their first steps in HoYoverse\u2019s open-world adventure, action role-playing game. And don\u2019t forget the nine <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/09/29/geforce-now-thursday-september-29/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/09/29/geforce-now-thursday-september-29/\" rel=\"nofollow\">All This and Mor-a Are Yours With Exclusive \u2018Genshin Impact\u2019 GeForce NOW Membership Reward</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 29 Sep 2022 13:00:51 +0000",
            "pubdate_parsed": [
                2022,
                9,
                29
            ],
            "email_sent": true
        },
        "Creator EposVox Shares Streaming Lessons, Successes This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/10/04/in-the-nvidia-studio-october-04/",
            "description": "<p>TwitchCon \u2014 the world\u2019s top gathering of live streamers \u2013 kicks off Friday with the new line of GeForce RTX 40 Series GPUs bringing incredible new technology \u2014 from AV1 to AI \u2014 to elevate live streams for aspiring and professional Twitch creators alike.  </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/04/in-the-nvidia-studio-october-04/\" rel=\"nofollow\">Creator EposVox Shares Streaming Lessons, Successes This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 04 Oct 2022 13:00:06 +0000",
            "pubdate_parsed": [
                2022,
                10,
                4
            ],
            "email_sent": true
        },
        "Fall Into October With 25 New Games Streaming on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2022/10/06/geforce-now-thursday-octobter-6/",
            "description": "<p>Cooler weather, the changing colors of the leaves, the needless addition of pumpkin spice to just about everything, and discount Halloween candy are just some things to look forward to in the fall. GeForce NOW members can add one more thing to the list \u2014 25 games joining the cloud gaming library in October, including <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/06/geforce-now-thursday-octobter-6/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/06/geforce-now-thursday-octobter-6/\" rel=\"nofollow\">Fall Into October With 25 New Games Streaming on GeForce NOW</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 06 Oct 2022 13:00:04 +0000",
            "pubdate_parsed": [
                2022,
                10,
                6
            ],
            "email_sent": true
        },
        "GeForce RTX 4090 GPU Arrives, Enabling New World-Building Possibilities for 3D Artists This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/10/12/in-the-nvidia-studio-october-12/",
            "description": "<p>This week 'In the NVIDIA Studio' creators can now pick up the GeForce RTX 4090 GPU, available from top add-in card providers including ASUS, Colorful, Gainward, Galaxy, GIGABYTE, INNO3D, MSI, Palit, PNY and ZOTAC, as well as from system integrators and builders worldwide. </p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/12/in-the-nvidia-studio-october-12/\" rel=\"nofollow\">GeForce RTX 4090 GPU Arrives, Enabling New World-Building Possibilities for 3D Artists This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 12 Oct 2022 13:00:24 +0000",
            "pubdate_parsed": [
                2022,
                10,
                12
            ],
            "email_sent": true
        },
        "GeForce NOW Streams High-Res, 120-FPS PC Gaming to Worlds First Cloud Gaming Chromebooks": {
            "url": "https://blogs.nvidia.com/blog/2022/10/13/geforce-now-thursday-oct-13/",
            "description": "<p>High-end PC gaming arrives on more devices this GFN Thursday. GeForce NOW RTX 3080 members can now stream their favorite PC games at up to 1600p and 120 frames per second in a Chrome browser. No downloads, no installs, just victory. Even better, NVIDIA has worked with Google to support the newest Chromebooks, which are <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/13/geforce-now-thursday-oct-13/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/13/geforce-now-thursday-oct-13/\" rel=\"nofollow\">GeForce NOW Streams High-Res, 120-FPS PC Gaming to World\u2019s First Cloud Gaming Chromebooks</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 13 Oct 2022 13:00:02 +0000",
            "pubdate_parsed": [
                2022,
                10,
                13
            ],
            "email_sent": true
        },
        "AI Supercomputer to Power $200 Million Oregon State University Innovation Complex": {
            "url": "https://blogs.nvidia.com/blog/2022/10/14/ai-supercomputer-oregon-state/",
            "description": "<p>As a civil engineer, Scott Ashford used explosives to make the ground under Japan\u2019s Sendai airport safer in an earthquake. Now, as the dean of the engineering college at Oregon State University, he\u2019s at ground zero of another seismic event. In its biggest fundraising celebration in nearly a decade, Oregon State announced plans today for <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/14/ai-supercomputer-oregon-state/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/14/ai-supercomputer-oregon-state/\" rel=\"nofollow\">AI Supercomputer to Power $200 Million Oregon State University Innovation Complex</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Sat, 15 Oct 2022 04:30:04 +0000",
            "pubdate_parsed": [
                2022,
                10,
                15
            ],
            "email_sent": true
        },
        "Souped-Up Auto Quotes: ProovStation Delivers GPU-Driven AI Appraisals": {
            "url": "https://blogs.nvidia.com/blog/2022/10/17/proovstation-gpu-ai-appraisals/",
            "description": "<p>Vehicle appraisals are getting souped up with a GPU-accelerated AI overhaul. ProovStation, a four-year-old startup based in Lyon, France, is taking on the ambitious computer-vision quest of automating vehicle inspection and repair estimates, aiming AI-driven super-high-resolution stations at businesses worldwide. It recently launched three of its state-of-the-art vehicle inspection scanners at French retail giant Carrefour\u2019s <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/17/proovstation-gpu-ai-appraisals/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/17/proovstation-gpu-ai-appraisals/\" rel=\"nofollow\">Souped-Up Auto Quotes: ProovStation Delivers GPU-Driven AI Appraisals</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 18 Oct 2022 03:00:22 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "Adobe MAX Kicks Off With Creative App Updates and 3D Artist Anna Natter Impresses This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/10/18/in-the-nvidia-studio-october-18/",
            "description": "<p>Editor\u2019s note: This post is part of our weekly In the NVIDIA Studio series, which celebrates featured artists, offers creative tips and tricks, and demonstrates how NVIDIA Studio technology improves creative workflows. In the coming weeks, we\u2019ll be deep diving on new GeForce RTX 40 Series GPU features, technologies and resources, and how they dramatically <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/18/in-the-nvidia-studio-october-18/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/18/in-the-nvidia-studio-october-18/\" rel=\"nofollow\">Adobe MAX Kicks Off With Creative App Updates and 3D Artist Anna Natter Impresses This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 18 Oct 2022 13:00:27 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "Get in Touch With New Mobile Gaming Controls on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2022/10/20/geforce-now-thursday-oct-20/",
            "description": "<p>GeForce NOW expands touch control support to 13 more games this GFN Thursday. That means it\u2019s easier than ever to take PC gaming on the go using mobile devices and tablets. The new \u201cMobile Touch Controls\u201d row in the GeForce NOW app is the easiest way for members to find which games put the action <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/20/geforce-now-thursday-oct-20/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/20/geforce-now-thursday-oct-20/\" rel=\"nofollow\">Get in Touch With New Mobile Gaming Controls on GeForce NOW</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 20 Oct 2022 13:00:43 +0000",
            "pubdate_parsed": [
                2022,
                10,
                20
            ],
            "email_sent": true
        },
        "3D Artist SouthernShotty Creates Wholesome Characters This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/10/25/in-the-nvidia-studio-october-25/",
            "description": "<p>This week 'In the NVIDIA Studio,' we\u2019re highlighting 3D and motion graphics artist SouthernShotty \u2014 and scenes from his soon-to-be released short film, Watermelon Girl.\u00a0</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/25/in-the-nvidia-studio-october-25/\" rel=\"nofollow\">3D Artist SouthernShotty Creates Wholesome Characters This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Tue, 25 Oct 2022 13:00:08 +0000",
            "pubdate_parsed": [
                2022,
                10,
                25
            ],
            "email_sent": true
        },
        "Make Gaming a Priority: Special Membership Discount Hits GeForce NOW for Limited Time": {
            "url": "https://blogs.nvidia.com/blog/2022/10/27/geforce-now-thursday-oct-27/",
            "description": "<p>This spook-tacular Halloween edition of GFN Thursday features a special treat: 40% off a six-month GeForce NOW Priority Membership \u2014 get it for just $29.99 for a limited time. Several sweet new games are also joining the GeForce NOW library. Creatures of the night can now stream vampire survival game V Rising from the cloud. <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/27/geforce-now-thursday-oct-27/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/27/geforce-now-thursday-oct-27/\" rel=\"nofollow\">Make Gaming a Priority: Special Membership Discount Hits GeForce NOW for Limited Time</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 27 Oct 2022 13:00:06 +0000",
            "pubdate_parsed": [
                2022,
                10,
                27
            ],
            "email_sent": true
        },
        "GeForce RTX 40 Series Receives Massive Creator App Benefits This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2022/10/31/in-the-nvidia-studio-october-31/",
            "description": "<p>Artists deploying the critically acclaimed GeForce RTX 4090 GPUs are primed to receive significant performance boosts in key creative apps. Plus, a special spook-tober edition of In the NVIDIA Studio features two talented 3D artists and their Halloween-themed creations this week.</p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/31/in-the-nvidia-studio-october-31/\" rel=\"nofollow\">GeForce RTX 40 Series Receives Massive Creator App Benefits This Week \u2018In the NVIDIA Studio\u2019</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 31 Oct 2022 13:00:03 +0000",
            "pubdate_parsed": [
                2022,
                10,
                31
            ],
            "email_sent": true
        },
        "Think Fast: Lotus Eletre Tops Charts in Driving and AI Compute Speeds, Powered by NVIDIA DRIVE Orin": {
            "url": "https://blogs.nvidia.com/blog/2022/10/31/lotus-eletre-ai-drive-orin/",
            "description": "<p>One of the biggest names in racing is going even bigger. Performance automaker Lotus launched its first SUV, the Eletre, earlier this week. The fully electric vehicle sacrifices little in terms of speed and outperforms when it comes to technology. It features an immersive digital cockpit, lengthy battery range of up to 370 miles and <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/10/31/lotus-eletre-ai-drive-orin/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/10/31/lotus-eletre-ai-drive-orin/\" rel=\"nofollow\">Think Fast: Lotus Eletre Tops Charts in Driving and AI Compute Speeds, Powered by NVIDIA DRIVE Orin</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Mon, 31 Oct 2022 12:38:05 +0000",
            "pubdate_parsed": [
                2022,
                10,
                31
            ],
            "email_sent": true
        },
        "Check Out 26 New Games Streaming on GeForce NOW in November": {
            "url": "https://blogs.nvidia.com/blog/2022/11/03/geforce-now-thursday-nov-3/",
            "description": "<p>It\u2019s a brand new month, which means this GFN Thursday is all about the new games streaming from the cloud. In November, 26 titles will join the GeForce NOW library. Kick off with 11 additions this week, like Total War: THREE KINGDOMS and new content updates for Genshin Impact and Apex Legends. Plus, leading 5G <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/11/03/geforce-now-thursday-nov-3/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/11/03/geforce-now-thursday-nov-3/\" rel=\"nofollow\">Check Out 26 New Games Streaming on GeForce NOW in November</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 03 Nov 2022 13:00:15 +0000",
            "pubdate_parsed": [
                2022,
                11,
                3
            ],
            "email_sent": true
        },
        "Give the Gift of Gaming With GeForce NOW Gift Cards": {
            "url": "https://blogs.nvidia.com/blog/2022/11/10/geforce-now-thursday-nov-10/",
            "description": "<p>The holiday season is approaching, and GeForce NOW has everyone covered. This GFN Thursday brings an easy way to give the gift of gaming with GeForce NOW gift cards, for yourself or for a gamer in your life. Plus, stream 10 new games from the cloud this week, including the first story downloadable content (DLC) <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/11/10/geforce-now-thursday-nov-10/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/11/10/geforce-now-thursday-nov-10/\" rel=\"nofollow\">Give the Gift of Gaming With GeForce NOW Gift Cards</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 10 Nov 2022 14:00:33 +0000",
            "pubdate_parsed": [
                2022,
                11,
                10
            ],
            "email_sent": true
        },
        "Qubit Pharmaceuticals Accelerates Drug Discovery With Hybrid Quantum Computing": {
            "url": "https://blogs.nvidia.com/blog/2022/11/30/qubit-pharmaceuticals-accelerates-drug-discovery-quantum-computing/",
            "description": "<p>The promise of quantum computing is to solve unsolvable problems. And companies are already making headway with hybrid approaches \u2014 those that combine classical and quantum computing \u2014 to tackle challenges like drug discovery for incurable diseases. By accelerating drug molecule simulation and modeling with hybrid quantum computing, startup Qubit Pharmaceuticals is significantly reducing the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/11/30/qubit-pharmaceuticals-accelerates-drug-discovery-quantum-computing/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/11/30/qubit-pharmaceuticals-accelerates-drug-discovery-quantum-computing/\" rel=\"nofollow\">Qubit Pharmaceuticals Accelerates Drug Discovery With Hybrid Quantum Computing</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 30 Nov 2022 08:01:00 +0000",
            "pubdate_parsed": [
                2022,
                11,
                30
            ],
            "email_sent": true
        },
        "Hittin the Sim: NVIDIAs Matt Cragun on Conditioning Autonomous Vehicles in Simulation": {
            "url": "https://blogs.nvidia.com/blog/2022/12/07/autonomous-vehicles-simulation/",
            "description": "<p>Training, testing and validating autonomous vehicles requires a continuous pipeline \u2014 or data factory \u2014 to introduce new scenarios and refine deep neural networks. A key component of this process is simulation. AV developers can test a virtually limitless number of scenarios, repeatably and at scale, with high-fidelity, physically based simulation. And like much of <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/12/07/autonomous-vehicles-simulation/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/12/07/autonomous-vehicles-simulation/\" rel=\"nofollow\">Hittin\u2019 the Sim: NVIDIA\u2019s Matt Cragun on Conditioning Autonomous Vehicles in Simulation</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Wed, 07 Dec 2022 13:00:03 +0000",
            "pubdate_parsed": [
                2022,
                12,
                7
            ],
            "email_sent": true
        },
        "23 and AV: Transportation Industry to Drive Into Metaverse, Cloud Technologies": {
            "url": "https://blogs.nvidia.com/blog/2022/12/08/2023-av-transportation-industry-metaverse-cloud/",
            "description": "<p>As the autonomous vehicle industry enters the next year, it will start navigating into even greater technology frontiers. Next-generation vehicles won\u2019t just be defined by autonomous driving capabilities. Everything from the design and production process to the in-vehicle experience is entering a new era of digitization, efficiency, safety and intelligence. These trends arrive after a <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2022/12/08/2023-av-transportation-industry-metaverse-cloud/\">Read article &#62;</a></p>\n<p>The post <a href=\"https://blogs.nvidia.com/blog/2022/12/08/2023-av-transportation-industry-metaverse-cloud/\" rel=\"nofollow\">\u201823 and AV: Transportation Industry to Drive Into Metaverse, Cloud Technologies</a> appeared first on <a href=\"https://blogs.nvidia.com\" rel=\"nofollow\">NVIDIA Blog</a>.</p>",
            "pubdate": "Thu, 08 Dec 2022 12:00:28 +0000",
            "pubdate_parsed": [
                2022,
                12,
                8
            ],
            "email_sent": true
        },
        "Booked for Brilliance: Swedens National Library Turns Page to AI to Parse Centuries of Data": {
            "url": "https://blogs.nvidia.com/blog/2023/01/23/sweden-library-ai-open-source/",
            "description": "For the past 500 years, the National Library of Sweden has collected virtually every word published in Swedish, from priceless medieval manuscripts to present-day pizza menus. Thanks to a centuries-old law that requires a copy of everything published in Swedish to be submitted to the library \u2014 also known as Kungliga biblioteket, or KB \u2014 <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/01/23/sweden-library-ai-open-source/\">Read article &#62;</a>",
            "pubdate": "Mon, 23 Jan 2023 08:01:40 +0000",
            "pubdate_parsed": [
                2023,
                1,
                23
            ],
            "email_sent": true
        },
        "NVIDIA CEO Ignites AI Conversation in Stockholm": {
            "url": "https://blogs.nvidia.com/blog/2023/01/24/nvidia-ceo-stockholm/",
            "description": "Jensen Huang headlines Stockholm AI confab, Berzelius supercomputer upgraded to 94 NVIDIA DGX A100 systems.",
            "pubdate": "Wed, 25 Jan 2023 00:36:49 +0000",
            "pubdate_parsed": [
                2023,
                1,
                25
            ],
            "email_sent": true
        },
        "NVIDIA Unveils GPU-Accelerated AI-on-5G System for Edge AI, 5G and Omniverse Digital Twins": {
            "url": "https://blogs.nvidia.com/blog/2023/02/27/mwc-ai-on-5g-system/",
            "description": "Telcos are seeking industry-standard solutions that can run 5G, AI applications and immersive graphics workloads on the same server \u2014 including for computer vision and the metaverse. To meet this need, NVIDIA is developing a new AI-on-5G solution that combines 5G vRAN, edge AI and digital twin workloads on an all-in-one, hyperconverged and GPU-accelerated system. <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/02/27/mwc-ai-on-5g-system/\">Read article &#62;</a>",
            "pubdate": "Mon, 27 Feb 2023 13:00:46 +0000",
            "pubdate_parsed": [
                2023,
                2,
                27
            ],
            "email_sent": true
        },
        "GeForce NOW Springs Into March With 19 New Games in the Cloud, Including Disney Dreamlight Valley": {
            "url": "https://blogs.nvidia.com/blog/2023/03/02/geforce-now-thursday-march-2/",
            "description": "March is already here and a new month always means new games, with a total of 19 joining the GeForce NOW library. Set off on a magical journey to restore Disney magic when Disney Dreamlight Valley joins the cloud later this month. Plus, the hunt is on with Capcom\u2019s Monster Hunter Rise now available for <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/03/02/geforce-now-thursday-march-2/\">Read article &#62;</a>",
            "pubdate": "Thu, 02 Mar 2023 14:00:43 +0000",
            "pubdate_parsed": [
                2023,
                3,
                2
            ],
            "email_sent": true
        },
        "NVIDIA Canvas 1.4 Available With Panorama Beta This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/03/16/in-the-nvidia-studio-march-16/",
            "description": "An update is now available for NVIDIA Canvas, the free beta app that harnesses the power of AI to help artists quickly turn simple brushstrokes into realistic landscapes.",
            "pubdate": "Thu, 16 Mar 2023 13:05:17 +0000",
            "pubdate_parsed": [
                2023,
                3,
                16
            ],
            "email_sent": true
        },
        "Game Like a PC: GeForce NOW Breaks Boundaries Transforming Macs Into Ultimate Gaming PCs": {
            "url": "https://blogs.nvidia.com/blog/2023/03/16/geforce-now-thursday-march-16/",
            "description": "Disney Dreamlight Valley is streaming from Steam and Epic Games Store on GeForce NOW starting today. It\u2019s one of two new games this week that members can stream with beyond-fast performance using a GeForce NOW Ultimate membership. Game as if using a PC on any device \u2014 at up to 4K resolution and 120 frames <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/03/16/geforce-now-thursday-march-16/\">Read article &#62;</a>",
            "pubdate": "Thu, 16 Mar 2023 13:00:56 +0000",
            "pubdate_parsed": [
                2023,
                3,
                16
            ],
            "email_sent": true
        },
        "Peter Ma on How Hes Using AI to Found 8 Promising Signals for Alien Life": {
            "url": "https://blogs.nvidia.com/blog/2023/03/16/peter-ma-podcast/",
            "description": "Peter Ma was bored in his high school computer science class. So he decided to teach himself something new: how to use artificial intelligence to find alien life. That\u2019s how he eventually became the lead author of a groundbreaking study published in Nature Astronomy. The study reveals how Ma and his co-authors used AI to <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/03/16/peter-ma-podcast/\">Read article &#62;</a>",
            "pubdate": "Thu, 16 Mar 2023 13:00:33 +0000",
            "pubdate_parsed": [
                2023,
                3,
                16
            ],
            "email_sent": true
        },
        "NVIDIA CEO to Reveal Whats Next for AI at GTC": {
            "url": "https://blogs.nvidia.com/blog/2023/03/16/next-ai-gtc/",
            "description": "The secret\u2019s out. Thanks to ChatGPT, everyone knows about the power of modern AI. To find out what\u2019s coming next, tune in to NVIDIA founder and CEO Jensen Huang\u2019s keynote address at NVIDIA GTC on Tuesday, March 21, at 8 a.m. Pacific. Huang will share his vision for the future of AI and how NVIDIA <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/03/16/next-ai-gtc/\">Read article &#62;</a>",
            "pubdate": "Fri, 17 Mar 2023 00:46:40 +0000",
            "pubdate_parsed": [
                2023,
                3,
                17
            ],
            "email_sent": true
        },
        "GFN Thursday Celebrates 1,500+ Games and Their Journey to GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/03/23/geforce-now-thursday-march-23/",
            "description": "Gamers love games \u2014 as do the people who make them. GeForce NOW streams over 1,500 games from the cloud, and with the Game Developers Conference in full swing this week, today\u2019s GFN Thursday celebrates all things games: the tech behind them, the tools that bring them to the cloud, the ways to play them <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/03/23/geforce-now-thursday-march-23/\">Read article &#62;</a>",
            "pubdate": "Thu, 23 Mar 2023 13:00:27 +0000",
            "pubdate_parsed": [
                2023,
                3,
                23
            ],
            "email_sent": true
        },
        "Blender Update 3.5 Fuels 3D Content Creation, Powered by NVIDIA GeForce RTX GPUs": {
            "url": "https://blogs.nvidia.com/blog/2023/03/29/blender-3-5-release/",
            "description": "Blender, the world\u2019s most popular 3D creation suite \u2014 free and open source \u2014 released its major version 3.5 update. Expected to have a profound impact on 3D creative workflows, this latest release features support for Open Shading Language (OSL) shaders with the NVIDIA OptiX ray-tracing engine.",
            "pubdate": "Wed, 29 Mar 2023 13:00:45 +0000",
            "pubdate_parsed": [
                2023,
                3,
                29
            ],
            "email_sent": true
        },
        "April Showers Bring 23 New GeForce NOW Games Including Have a Nice Death": {
            "url": "https://blogs.nvidia.com/blog/2023/03/30/geforce-now-thursday-march-30/",
            "description": "It\u2019s another rewarding GFN Thursday, with 23 new games for April on top of 11 joining the cloud this week and a new Marvel\u2019s Midnight Suns reward now available first for GeForce NOW Premium members. Newark, N.J., is next to complete its upgrade to RTX 4080 SuperPODs, making it the 12th region worldwide to bring <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/03/30/geforce-now-thursday-march-30/\">Read article &#62;</a>",
            "pubdate": "Thu, 30 Mar 2023 13:00:10 +0000",
            "pubdate_parsed": [
                2023,
                3,
                30
            ],
            "email_sent": true
        },
        "Video Editor Patrick Stirling Invents Custom Effect for DaVinci Resolve Software": {
            "url": "https://blogs.nvidia.com/blog/2023/04/04/davinci-resolve-fusion-ai-effects/",
            "description": "Video editor Patrick Stirling used the Magic Mask feature in Blackmagic Design\u2019s DaVinci Resolve software to create a custom effect that creates textured animations of people, this week In the NVIDIA Studio.",
            "pubdate": "Tue, 04 Apr 2023 13:00:31 +0000",
            "pubdate_parsed": [
                2023,
                4,
                4
            ],
            "email_sent": true
        },
        "Gaming on the Go: GeForce NOW Gives Members More Ways to Play": {
            "url": "https://blogs.nvidia.com/blog/2023/04/06/geforce-now-thursday-april-6/",
            "description": "This GFN Thursday explores the many ways GeForce NOW members can play their favorite PC games across the devices they know and love. Plus, seven new games join the GeForce NOW library this week. More Ways to Play GeForce NOW is the ultimate platform for gamers who want to play across more devices than their <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/06/geforce-now-thursday-april-6/\">Read article &#62;</a>",
            "pubdate": "Thu, 06 Apr 2023 13:00:12 +0000",
            "pubdate_parsed": [
                2023,
                4,
                6
            ],
            "email_sent": true
        },
        "The New Standard in Gaming: GeForce RTX Gamers Embrace Ray Tracing, DLSS in Record Numbers": {
            "url": "https://blogs.nvidia.com/blog/2023/04/12/ray-tracing-dlss/",
            "description": "Creating a map requires masterful geographical knowledge, artistic skill and evolving technologies that have taken people from using hand-drawn sketches to satellite imagery. Just as important, changes need to be navigated in the way people consume maps, from paper charts to GPS navigation and interactive online charts. The way people think about video games is <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/12/ray-tracing-dlss/\">Read article &#62;</a>",
            "pubdate": "Wed, 12 Apr 2023 13:00:33 +0000",
            "pubdate_parsed": [
                2023,
                4,
                12
            ],
            "email_sent": true
        },
        "New GeForce RTX 4070 GPU Dramatically Accelerates Creativity": {
            "url": "https://blogs.nvidia.com/blog/2023/04/13/geforce-rtx-4070-studio-creators/",
            "description": "The GeForce RTX 4070 GPU, the latest in the 40 Series lineup, is available today starting at $599. It comes backed by NVIDIA Studio technologies, including hardware acceleration for 3D, video and AI workflows; optimizations for RTX hardware in over 110 popular creative apps; and exclusive NVIDIA Studio apps like Omniverse, Broadcast, Canvas and RTX Remix.",
            "pubdate": "Thu, 13 Apr 2023 13:00:38 +0000",
            "pubdate_parsed": [
                2023,
                4,
                13
            ],
            "email_sent": true
        },
        "A Gripping New Adventure: GeForce NOW Brings Titles From Bandai Namco Europe to the Cloud, Including Little Nightmares Series": {
            "url": "https://blogs.nvidia.com/blog/2023/04/13/geforce-now-thursday-april-13/",
            "description": "A new adventure with publisher Bandai Namco Europe kicks off this GFN Thursday. Some of its popular titles lead seven new games joining the cloud this week. Plus, gamers can play them on more devices than ever, with native 4K streaming for GeForce NOW available on select LG Smart TVs. Better Together Bandai Namco is <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/13/geforce-now-thursday-april-13/\">Read article &#62;</a>",
            "pubdate": "Thu, 13 Apr 2023 13:00:25 +0000",
            "pubdate_parsed": [
                2023,
                4,
                13
            ],
            "email_sent": true
        },
        "NVIDIA Studio Creators Take Collaboration to Bone-Chilling New Heights": {
            "url": "https://blogs.nvidia.com/blog/2023/04/19/studio-omniverse-usd-composer-animation/",
            "description": "This week\u2019s In the NVIDIA Studio artists specializing in 3D, Gianluca Squillace and Pasquale Scionti, benefitted from just that \u2014 in their individual work and in collaborating to construct the final scene for their project, Cold Inside Diorama.",
            "pubdate": "Wed, 19 Apr 2023 13:00:53 +0000",
            "pubdate_parsed": [
                2023,
                4,
                19
            ],
            "email_sent": true
        },
        "Dont Wait: GeForce NOW Six-Month Priority Memberships on Sale for Limited Time": {
            "url": "https://blogs.nvidia.com/blog/2023/04/20/geforce-now-thursday-april-20/",
            "description": "GFN Thursday rolls up this week with a hot new deal for a GeForce NOW six-month Priority membership. Enjoy the cloud gaming service with seven new games to stream this week, including more favorites from Bandai Namco Europe and F1 2021 from Electronic Arts. Make Gaming a Priority\u00a0 Starting today, GeForce NOW is offering a <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/20/geforce-now-thursday-april-20/\">Read article &#62;</a>",
            "pubdate": "Thu, 20 Apr 2023 13:00:57 +0000",
            "pubdate_parsed": [
                2023,
                4,
                20
            ],
            "email_sent": true
        },
        "NVIDIA Announces Partners of the Year in Europe, Middle East": {
            "url": "https://blogs.nvidia.com/blog/2023/04/20/nvidia-partner-network-awards-emea/",
            "description": "NVIDIA today recognized a dozen partners for their work helping customers in Europe, the Middle East and Africa harness the power of AI across industries. At a virtual EMEA Partner Day event, which was hosted by the NVIDIA Partner Network (NPN) and drew more than 750 registrants, Partner of the Year awards were given to <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/20/nvidia-partner-network-awards-emea/\">Read article &#62;</a>",
            "pubdate": "Thu, 20 Apr 2023 11:00:55 +0000",
            "pubdate_parsed": [
                2023,
                4,
                20
            ],
            "email_sent": true
        },
        "Epic Benefits: Omniverse Connector for Unreal Engine Saves Content Creators Time and Effort": {
            "url": "https://blogs.nvidia.com/blog/2023/04/21/epic-benefits-omniverse-connector-unreal-engine/",
            "description": "Content creators using Epic Games\u2019 open, advanced real-time 3D creation tool, Unreal Engine, are now equipped with more features to bring their work to life with NVIDIA Omniverse, a platform for creating and operating metaverse applications. The Omniverse Connector for Unreal Engine\u2019s 201.0 update brings significant enhancements to creative workflows using both open platforms. Streamlining <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/21/epic-benefits-omniverse-connector-unreal-engine/\">Read article &#62;</a>",
            "pubdate": "Fri, 21 Apr 2023 13:00:43 +0000",
            "pubdate_parsed": [
                2023,
                4,
                21
            ],
            "email_sent": true
        },
        "Right on Track: NVIDIA Open-Source Software Helps Developers Add Guardrails to AI Chatbots": {
            "url": "https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/",
            "description": "Newly released open-source software can help developers guide generative AI applications to create impressive text responses that stay on track. NeMo Guardrails will help ensure smart applications powered by large language models (LLMs) are accurate, appropriate, on topic and secure. The software includes all the code, examples and documentation businesses need to add safety to <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/25/ai-chatbot-guardrails-nemo/\">Read article &#62;</a>",
            "pubdate": "Tue, 25 Apr 2023 13:00:55 +0000",
            "pubdate_parsed": [
                2023,
                4,
                25
            ],
            "email_sent": true
        },
        "Viral NVIDIA Broadcast Demo Drops Hammer on Imperfect Audio This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/04/26/broadcast-ai-effects-noise-echo-removal/",
            "description": "Spotlighted by this week\u2019s In the NVIDIA Studio featured artist Unmesh Dinda, NVIDIA Broadcast transforms the homes, apartments and dorm rooms of content creators, livestreamers and people working from home through the power of AI \u2014 all without the need for specialized equipment.",
            "pubdate": "Wed, 26 Apr 2023 13:00:23 +0000",
            "pubdate_parsed": [
                2023,
                4,
                26
            ],
            "email_sent": true
        },
        "The Future of Intelligent Vehicle Interiors: Building Trust with HMI & AI": {
            "url": "https://blogs.nvidia.com/blog/2023/04/26/intelligent-vehicle-interiors/",
            "description": "Imagine a future where your vehicle\u2019s interior offers personalized experiences and builds trust through human-machine interfaces (HMI) and AI. In this episode of the NVIDIA AI Podcast, Andreas Binner, chief technology officer at Rightware, delves into this fascinating topic with host Katie Burke Washabaugh. Rightware is a Helsinki-based company at the forefront of developing in-vehicle <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/26/intelligent-vehicle-interiors/\">Read article &#62;</a>",
            "pubdate": "Wed, 26 Apr 2023 13:00:18 +0000",
            "pubdate_parsed": [
                2023,
                4,
                26
            ],
            "email_sent": true
        },
        "Welcome to the Family: GeForce NOW, Capcom Bring Resident Evil Titles to the Cloud": {
            "url": "https://blogs.nvidia.com/blog/2023/04/27/geforce-now-thursday-april-27/",
            "description": "Horror descends from the cloud this GFN Thursday with the arrival of publisher Capcom\u2019s iconic Resident Evil series. They\u2019re part of nine new games expanding the GeForce NOW library of over 1,600 titles. RTX 4080 SuperPODs are now live in Miami, Portland, Ore., and Stockholm. Follow along with the server rollout process, and make the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/04/27/geforce-now-thursday-april-27/\">Read article &#62;</a>",
            "pubdate": "Thu, 27 Apr 2023 13:00:00 +0000",
            "pubdate_parsed": [
                2023,
                4,
                27
            ],
            "email_sent": true
        },
        "Now Shipping: DGX H100 Systems Bring Advanced AI Capabilities to Industries Worldwide": {
            "url": "https://blogs.nvidia.com/blog/2023/05/01/dgx-h100-systems-shipping/",
            "description": "Customers from Japan to Ecuador and Sweden are using NVIDIA DGX H100 systems like AI factories to manufacture intelligence. They\u2019re creating services that offer AI-driven insights in finance, healthcare, law, IT and telecom \u2014 and working to transform their industries in the process. Among the dozens of use cases, one aims to predict how factory <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/01/dgx-h100-systems-shipping/\">Read article &#62;</a>",
            "pubdate": "Mon, 01 May 2023 13:15:27 +0000",
            "pubdate_parsed": [
                2023,
                5,
                1
            ],
            "email_sent": true
        },
        "Renders and Dragons Rule Creative Kingdoms This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/05/02/blender-optix-ai/",
            "description": "Content creator Grant Abbitt embodies selflessness, one of the best qualities that a creative can possess. Passionate about giving back to the creative community, Abbitt offers inspiration, guidance and free education for others in his field through YouTube tutorials.",
            "pubdate": "Tue, 02 May 2023 13:00:51 +0000",
            "pubdate_parsed": [
                2023,
                5,
                2
            ],
            "email_sent": true
        },
        "GeForce NOW Makes May-hem With 16 New Games, Including The Lord of the Rings: Gollum": {
            "url": "https://blogs.nvidia.com/blog/2023/05/04/geforce-now-thursday-may-4/",
            "description": "What has it got in its pocketses? More games coming in May, that\u2019s what. GFN Thursday gets the summer started early with two newly supported games this week and 16 more coming later this month \u2014 including The Lord of the Rings: Gollum. Don\u2019t forget to take advantage of the limited-time discount on six-month Priority <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/04/geforce-now-thursday-may-4/\">Read article &#62;</a>",
            "pubdate": "Thu, 04 May 2023 13:00:01 +0000",
            "pubdate_parsed": [
                2023,
                5,
                4
            ],
            "email_sent": true
        },
        "Explore the Hidden Temple of Itzamn This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/05/09/unreal-engine-lumen-dlss/",
            "description": "3D artist Milan Dey finds inspiration in games, movies, comics and pop culture. He drew from all of the above when creating a stunning 3D scene of Mayan ruins, The Hidden Temple of Itzamn\u00e1, this week In the NVIDIA Studio.",
            "pubdate": "Tue, 09 May 2023 13:00:07 +0000",
            "pubdate_parsed": [
                2023,
                5,
                9
            ],
            "email_sent": true
        },
        "How AI and Crowdsourcing Can Advance mRNA Vaccine Distribution": {
            "url": "https://blogs.nvidia.com/blog/2023/05/10/vaccine-mrna/",
            "description": "Artificial intelligence is teaming up with crowdsourcing to improve the thermo-stability &#8211; the ability to avoid breaking down under heat stress &#8211;\u00a0 of mRNA vaccines, making distribution more accessible worldwide. In this episode of NVIDIA&#8217;s AI Podcast, host Noah Kravitz interviewed Bojan Tunguz, a physicist and senior system software engineer at NVIDIA, and Johnny Israeli, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/10/vaccine-mrna/\">Read article &#62;</a>",
            "pubdate": "Wed, 10 May 2023 13:00:18 +0000",
            "pubdate_parsed": [
                2023,
                5,
                10
            ],
            "email_sent": true
        },
        "Mammoth Mission: How Colossal Biosciences Aims to De-Extinct the Woolly Mammoth": {
            "url": "https://blogs.nvidia.com/blog/2023/05/16/colossal-biosciences-de-extinct-woolly-mammoth-parabricks/",
            "description": "Ten thousand years after the last woolly mammoths vanished with the last Ice Age, a team of computational biologists is on a mission to bring them back within five years. Led by synthetic biology pioneer George Church, Colossal Biosciences is also seeking to return the dodo bird and Tasmanian tiger, as well as help save <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/16/colossal-biosciences-de-extinct-woolly-mammoth-parabricks/\">Read article &#62;</a>",
            "pubdate": "Tue, 16 May 2023 13:00:35 +0000",
            "pubdate_parsed": [
                2023,
                5,
                16
            ],
            "email_sent": true
        },
        "Chip Manufacturing Ideal Application for AI, NVIDIA CEO Says": {
            "url": "https://blogs.nvidia.com/blog/2023/05/16/itf-world-2023/",
            "description": "Chip manufacturing is an \u201cideal application\u201d for NVIDIA accelerated and AI computing, NVIDIA founder and CEO Jensen Huang said Tuesday. Detailing how the latest advancements in computing are accelerating \u201cthe world\u2019s most important industry,\u201d Huang spoke at ITF World 2023 semiconductor conference in Antwerp, Belgium. Huang delivered his remarks via video to a gathering of <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/16/itf-world-2023/\">Read article &#62;</a>",
            "pubdate": "Tue, 16 May 2023 09:00:51 +0000",
            "pubdate_parsed": [
                2023,
                5,
                16
            ],
            "email_sent": true
        },
        "Into the Omniverse: Adobe Substance 3D, NVIDIA Omniverse Enhance Creative Freedom Within 3D Workflows": {
            "url": "https://blogs.nvidia.com/blog/2023/05/17/adobe-substance-3d-omniverse-enhance-creative-freedom/",
            "description": "An update to the Omniverse Connector for Adobe Substance 3D Painter will save 3D creators across industries significant time and effort.",
            "pubdate": "Wed, 17 May 2023 13:00:49 +0000",
            "pubdate_parsed": [
                2023,
                5,
                17
            ],
            "email_sent": true
        },
        "Beyond Fast: GeForce RTX 4060 GPU Family Gives Creators More Options to Accelerate Workflows, Starting at $299": {
            "url": "https://blogs.nvidia.com/blog/2023/05/18/geforce-rtx-4060-ti/",
            "description": "The GeForce RTX 4060 family will be available starting next week, bringing massive creator benefits to the popular 60-class GPUs.",
            "pubdate": "Thu, 18 May 2023 13:00:51 +0000",
            "pubdate_parsed": [
                2023,
                5,
                18
            ],
            "email_sent": true
        },
        "First Xbox Title Joins GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/05/18/geforce-now-thursday-may-18/",
            "description": "Get ready for action \u2014 the first Xbox game title is now streaming from GeForce GPUs in the cloud directly to GeForce NOW members, with more to come later this month. Gears 5 comes to the service this GFN Thursday. Keep reading to find out what other entries from the Xbox library will be streaming <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/18/geforce-now-thursday-may-18/\">Read article &#62;</a>",
            "pubdate": "Thu, 18 May 2023 13:00:46 +0000",
            "pubdate_parsed": [
                2023,
                5,
                18
            ],
            "email_sent": true
        },
        "Whats Up? Watts Down  More Science, Less Energy": {
            "url": "https://blogs.nvidia.com/blog/2023/05/21/gpu-energy-efficiency-nersc/",
            "description": "People agree: accelerated computing is energy-efficient computing. The National Energy Research Scientific Computing Center (NERSC), the U.S. Department of Energy\u2019s lead facility for open science, measured results across four of its key high performance computing and AI applications. They clocked how fast the applications ran and how much energy they consumed on CPU-only and GPU-accelerated <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/21/gpu-energy-efficiency-nersc/\">Read article &#62;</a>",
            "pubdate": "Mon, 22 May 2023 06:00:48 +0000",
            "pubdate_parsed": [
                2023,
                5,
                22
            ],
            "email_sent": true
        },
        "Privateer Space: The Final Frontier in AI Space Junk Management": {
            "url": "https://blogs.nvidia.com/blog/2023/05/23/privateer-space/",
            "description": "It\u2019s time to take out the space trash. In this episode of the NVIDIA AI Podcast, host Noah Kravitz dives into an illuminating conversation with Alex Fielding, co-founder and CEO of Privateer Space. Fielding is a tech industry veteran, having previously worked alongside Apple co-founder Steve Wozniak on several projects, and holds a deep expertise <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/23/privateer-space/\">Read article &#62;</a>",
            "pubdate": "Tue, 23 May 2023 13:00:10 +0000",
            "pubdate_parsed": [
                2023,
                5,
                23
            ],
            "email_sent": true
        },
        "Livestreaming Bliss: Wander Warwicks World This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/05/24/geforce-rtx-4060-vegas-pro/",
            "description": "The GeForce RTX 4060 Ti 8GB GPU is now available from top add-in card providers including ASUS, Colorful, Galax, GIGABYTE, INNO3D, MSI, Palit, PNY and ZOTAC, as well as from system integrators and builders worldwide.",
            "pubdate": "Wed, 24 May 2023 13:00:07 +0000",
            "pubdate_parsed": [
                2023,
                5,
                24
            ],
            "email_sent": true
        },
        "NVIDIA CEO Tells NTU Grads to Run, Not Walk  But Be Prepared to Stumble": {
            "url": "https://blogs.nvidia.com/blog/2023/05/26/huang-ntu-commencement/",
            "description": "\u201cYou are running for food, or you are running from becoming food. And often times, you can\u2019t tell which. Either way, run.\u201d NVIDIA founder and CEO Jensen Huang today urged graduates of National Taiwan University to run hard to seize the unprecedented opportunities that AI will present, but embrace the inevitable failures along the way. <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/26/huang-ntu-commencement/\">Read article &#62;</a>",
            "pubdate": "Sat, 27 May 2023 02:45:33 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "NVIDIA Brings New Generative AI Capabilities, Groundbreaking Performance to 100 Million Windows RTX PCs and Workstations": {
            "url": "https://blogs.nvidia.com/blog/2023/05/28/computex-generative-ai-rtx/",
            "description": "Generative AI is rapidly ushering in a new era of computing for productivity, content creation, gaming and more. Generative AI models and applications \u2014 like NVIDIA NeMo and DLSS 3 Frame Generation, Meta LLaMa, ChatGPT, Adobe Firefly and Stable Diffusion \u2014 use neural networks to identify patterns and structures within existing data to generate new <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/28/computex-generative-ai-rtx/\">Read article &#62;</a>",
            "pubdate": "Mon, 29 May 2023 03:14:19 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "MediaTek Partners With NVIDIA to Transform Automobiles With AI and Accelerated Computing": {
            "url": "https://blogs.nvidia.com/blog/2023/05/28/mediatek-intelligent-cabin-solutions/",
            "description": "MediaTek, a leading innovator in connectivity and multimedia, is teaming with NVIDIA to bring drivers and passengers new experiences inside the car. The partnership was announced today at a COMPUTEX press conference with MediaTek CEO Rick Tsai and NVIDIA founder and CEO Jensen Huang. \u201cNVIDIA is a world-renowned pioneer and industry leader in AI and <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/28/mediatek-intelligent-cabin-solutions/\">Read article &#62;</a>",
            "pubdate": "Mon, 29 May 2023 06:30:55 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Live From Taipei: NVIDIA CEO Unveils Gen AI Platforms for Every Industry": {
            "url": "https://blogs.nvidia.com/blog/2023/05/28/computex-keynote-generative-ai/",
            "description": "In his first live keynote since the pandemic, NVIDIA founder and CEO Jensen Huang today kicked off the COMPUTEX conference in Taipei, announcing platforms that companies can use to ride a historic wave of generative AI that\u2019s transforming industries from advertising to manufacturing to telecom. \u201cWe\u2019re back,\u201d Huang roared as he took the stage after <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/28/computex-keynote-generative-ai/\">Read article &#62;</a>",
            "pubdate": "Mon, 29 May 2023 05:02:48 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "NVIDIA Brings Advanced Autonomy to Mobile Robots With Isaac AMR": {
            "url": "https://blogs.nvidia.com/blog/2023/05/28/isaac-amr-nova-orin-autonomous-mobile-robots/",
            "description": "As mobile robot shipments surge to meet the growing demands of industries seeking operational efficiencies, NVIDIA is launching a new platform to enable the next generation of autonomous mobile robot (AMR) fleets. Isaac AMR brings advanced mapping, autonomy and simulation to mobile robots and will soon be available for early customers, NVIDIA founder and CEO <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/28/isaac-amr-nova-orin-autonomous-mobile-robots/\">Read article &#62;</a>",
            "pubdate": "Mon, 29 May 2023 04:51:58 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Techman Robot Selects NVIDIA Isaac Sim to Optimize Automated Optical Inspection": {
            "url": "https://blogs.nvidia.com/blog/2023/05/28/techman-robot-isaac-sim/",
            "description": "How do you help robots build better robots? By simulating even more robots. NVIDIA founder and CEO Jensen Huang today showcased how leading electronics manufacturer Quanta is using AI-enabled robots to inspect the quality of its products. In his keynote speech at this week\u2019s COMPUTEX trade show in Taipei, Huang presented on how electronics manufacturers <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/28/techman-robot-isaac-sim/\">Read article &#62;</a>",
            "pubdate": "Mon, 29 May 2023 04:51:36 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Electronics Giants Tap Into Industrial Automation With NVIDIA Metropolis for Factories": {
            "url": "https://blogs.nvidia.com/blog/2023/05/28/electronics-giants-industrial-automation-nvidia-metropolis-for-factories/",
            "description": "The $46 trillion global electronics manufacturing industry spans more than 10 million factories worldwide, where much is at stake in producing defect-free products. To drive product excellence, leading electronics manufacturers are adopting NVIDIA Metropolis for Factories. More than 50 manufacturing giants and industrial automation providers \u2014 including Foxconn Industrial Internet, Pegatron, Quanta, Siemens and Wistron <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/05/28/electronics-giants-industrial-automation-nvidia-metropolis-for-factories/\">Read article &#62;</a>",
            "pubdate": "Mon, 29 May 2023 04:50:41 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "NVIDIA RTX Transforming 14-Inch Laptops, Plus Simultaneous Screen Encoding and May Studio Driver Available Today": {
            "url": "https://blogs.nvidia.com/blog/2023/05/30/computex-studio-laptops-encoding-capcut/",
            "description": "New 14-inch NVIDIA Studio laptops, equipped with GeForce RTX 40 Series Laptop GPUs, give creators peak portability with a significant increase in performance over the last generation.",
            "pubdate": "Tue, 30 May 2023 13:00:21 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "A New Age: Age of Empires Series Joins GeForce NOW, Part of 20 Games Coming in June": {
            "url": "https://blogs.nvidia.com/blog/2023/06/01/geforce-now-thursday-june-1/",
            "description": "The season of hot sun and longer days is here, so stay inside this summer with 20 games joining GeForce NOW in June. Or stream across devices by the pool, from grandma\u2019s house or in the car \u2014 whichever way, GeForce NOW has you covered. Titles from the Age of Empires series are the next <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/01/geforce-now-thursday-june-1/\">Read article &#62;</a>",
            "pubdate": "Thu, 01 Jun 2023 13:00:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Digital Renaissance: NVIDIA Neuralangelo Research Reconstructs 3D Scenes": {
            "url": "https://blogs.nvidia.com/blog/2023/06/01/neuralangelo-ai-research-3d-reconstruction/",
            "description": "Neuralangelo, a new AI model by NVIDIA Research for 3D reconstruction using neural networks, turns 2D video clips into detailed 3D structures \u2014 generating lifelike virtual replicas of buildings, sculptures and other real-world objects. Like Michelangelo sculpting stunning, life-like visions from blocks of marble, Neuralangelo generates 3D structures with intricate details and textures. Creative professionals <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/01/neuralangelo-ai-research-3d-reconstruction/\">Read article &#62;</a>",
            "pubdate": "Thu, 01 Jun 2023 13:00:34 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Technical Artist Builds Great Woolly Mammoth With NVIDIA Omniverse USD Composer This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/06/06/omniverse-usd-marvelous-designer-connector/",
            "description": "Keerthan Sathya, a senior technical artist specializing in 3D, emerged trium-elephant In the NVIDIA Studio this week with the incredibly detailed, expertly constructed, jaw-droppingly beautiful animation Tiny Mammoth.",
            "pubdate": "Tue, 06 Jun 2023 13:00:17 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "Link-credible: Get in the Game Faster With Steam, Epic Games Store and Ubisoft Account Linking on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/06/08/geforce-now-thursday-june-8/",
            "description": "Get into your favorite games faster by linking GeForce NOW to Steam, Epic Games Store and Ubisoft accounts. And get a peek at more games coming to GeForce NOW later this year by tuning in to Ubisoft Forward on Monday, June 12, when the game publisher will reveal its latest news and announcements. Plus, two <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/08/geforce-now-thursday-june-8/\">Read article &#62;</a>",
            "pubdate": "Thu, 08 Jun 2023 13:00:19 +0000",
            "pubdate_parsed": [
                2023,
                6,
                8
            ],
            "email_sent": true
        },
        "NVIDIA and Hexagon Deliver Suite of Solutions for Accelerating Industrial Digitalization": {
            "url": "https://blogs.nvidia.com/blog/2023/06/12/omniverse-hexagon-industrial-digitalization/",
            "description": "For industrial businesses to reach the next level of digitalization, they need to create accurate, virtual representations of their physical systems. NVIDIA is working with Hexagon, the Stockholm-based global leader in digital reality solutions combining sensor, software and autonomous technologies, to equip enterprises with the tools and solutions they need to build physically accurate, perfectly <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/12/omniverse-hexagon-industrial-digitalization/\">Read article &#62;</a>",
            "pubdate": "Tue, 13 Jun 2023 02:05:11 +0000",
            "pubdate_parsed": [
                2023,
                6,
                13
            ],
            "email_sent": true
        },
        "Rendered.ai Integrates NVIDIA Omniverse for Synthetic Data Generation": {
            "url": "https://blogs.nvidia.com/blog/2023/06/13/rendered-ai-omniverse-replicator-integration/",
            "description": "Rendered.ai is easing AI training for developers, data scientists and others with its platform-as-a-service for synthetic data generation, or SDG. Training computer vision AI models requires massive, high-quality, diverse and unbiased datasets. These can be challenging and costly to obtain, especially with increasing demands both of and for AI. The Rendered.ai platform-as-a-service helps to solve <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/13/rendered-ai-omniverse-replicator-integration/\">Read article &#62;</a>",
            "pubdate": "Tue, 13 Jun 2023 11:05:28 +0000",
            "pubdate_parsed": [
                2023,
                6,
                13
            ],
            "email_sent": true
        },
        "Filmmaker Sara Dietschy Talks AI This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/06/14/sara-dietschy-davinci-resolve-ai/",
            "description": "With over 900,000 subscribers on her YouTube channel, editor and filmmaker Sara Dietschy creates docuseries, reviews and vlogs that explore the intersection of technology and creativity.",
            "pubdate": "Wed, 14 Jun 2023 13:00:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                14
            ],
            "email_sent": true
        },
        "Do Pass Go, Do Collect More Games: Xbox Game Pass Coming to GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/06/15/geforce-now-thursday-june-15/",
            "description": "Xbox Game Pass support is coming to GeForce NOW. Members will soon be able to play supported PC games from the Xbox Game Pass catalog through NVIDIA\u2019s cloud gaming servers. Learn more about how support for Game Pass and Microsoft Store will roll out in the coming months. Plus, Age of Empires IV: Anniversary Edition <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/15/geforce-now-thursday-june-15/\">Read article &#62;</a>",
            "pubdate": "Thu, 15 Jun 2023 13:00:44 +0000",
            "pubdate_parsed": [
                2023,
                6,
                15
            ],
            "email_sent": true
        },
        "Shell-e-brate Good Times in 3D With Kingsletter This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/06/21/blender-adobe-substance-3d-painter/",
            "description": "Amir Anbarestani, an accomplished 3D artist who goes by the moniker Kingsletter, had a \u201cshell of a good time\u201d creating his Space Turtle scene this week In the NVIDIA Studio.",
            "pubdate": "Wed, 21 Jun 2023 13:00:13 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Into the Omniverse: Universal Scene Description Support for Marvelous Designer Lets Users Tailor Digital Assets, Clothes for 3D Characters": {
            "url": "https://blogs.nvidia.com/blog/2023/06/21/usd-support-for-marvelous-designer/",
            "description": "Whether animating fish fins or fashioning chic outfits for digital characters, creators can tap Marvelous Designer software to compose and tailor assets, clothes and other materials for their 3D workflows.",
            "pubdate": "Wed, 21 Jun 2023 13:00:08 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "A Golden Age: Age of Empires III Joins GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/06/22/geforce-now-thursday-june-22/",
            "description": "Conquer the lands in Microsoft\u2019s award-winning Age of Empires III: Definitive Edition. It leads 10 new games supported today on GeForce NOW. At Your Command Age of Empires III: Definitive Edition is a remaster of one of the most beloved real-time strategy franchises featuring improved visuals, enhanced gameplay, cross-platform multiplayer and more. Command mighty civilizations <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/22/geforce-now-thursday-june-22/\">Read article &#62;</a>",
            "pubdate": "Thu, 22 Jun 2023 13:00:07 +0000",
            "pubdate_parsed": [
                2023,
                6,
                22
            ],
            "email_sent": true
        },
        "Quicker Cures: How Insilico Medicine Uses Generative AI to Accelerate Drug Discovery": {
            "url": "https://blogs.nvidia.com/blog/2023/06/27/insilico-medicine-uses-generative-ai-to-accelerate-drug-discovery/",
            "description": "While generative AI is a relatively new household term, drug discovery company Insilico Medicine has been using it for years to develop new therapies for debilitating diseases. The company\u2019s early bet on deep learning is bearing fruit \u2014 a drug candidate discovered using its AI platform is now entering Phase 2 clinical trials to treat <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/27/insilico-medicine-uses-generative-ai-to-accelerate-drug-discovery/\">Read article &#62;</a>",
            "pubdate": "Tue, 27 Jun 2023 13:01:25 +0000",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "Calm, Cool and Creative: MUE Studio Showcases 3D Scenes In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/06/29/mue-studio-chaos-vantage/",
            "description": "MUE Studio, founded by 3D artists Minjin Kang and Mijoo Kim, specializes in art direction, photography and 3D design for campaigns and installations.",
            "pubdate": "Thu, 29 Jun 2023 13:00:48 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "Remnant II Headlines 14 Games Joining GeForce NOW in July": {
            "url": "https://blogs.nvidia.com/blog/2023/06/29/geforce-now-thursday-june-29/",
            "description": "It\u2019s a jam-packed July with 14 newly supported titles in the GeForce NOW library, including Remnant II from Gunfire Games and Gearbox Publishing. Need a new adventure? Check out the nine additions streaming from the cloud this week. Plus, the Steam Summer Sale kicks off this week, and many supported titles in the GeForce NOW <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/06/29/geforce-now-thursday-june-29/\">Read article &#62;</a>",
            "pubdate": "Thu, 29 Jun 2023 13:00:01 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "My Favorite 3D App: Blender Fanatic Shares His Japanese-Inspired Scene This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/07/06/blendeered-blender-davinci-resolve/",
            "description": "A diverse range of artists, fashionistas, musicians and the cinematic arts inspired the creative journey of Pedro Soares, aka Blendeered, and helped him fall in love with using 3D to create art.",
            "pubdate": "Thu, 06 Jul 2023 13:00:39 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "Heres the Deal: Steam Summer Sale Games Streaming on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/07/06/geforce-now-thursday-july-6/",
            "description": "GFN Thursday arrives alongside the sweet Steam Summer Sale \u2014 with hundreds of PC games playable on GeForce NOW available during Valve\u2019s special event for PC gamers. Also on sale, OCTOPATH TRAVELER and OCTOPATH TRAVELER II join the GeForce NOW library as a part of five new games coming to the service this week. Saved <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/06/geforce-now-thursday-july-6/\">Read article &#62;</a>",
            "pubdate": "Thu, 06 Jul 2023 13:00:14 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "Sierra Division Studios Presents Three Epic Projects Built With NVIDIA Omniverse": {
            "url": "https://blogs.nvidia.com/blog/2023/07/11/sierra-division-omniverse-openusd-composer/",
            "description": "Jacob Norris is a 3D artist and the president, co-founder and creative director of Sierra Division Studios \u2014 an outsource studio specializing in digital 3D content creation.",
            "pubdate": "Tue, 11 Jul 2023 13:00:47 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "MosaicML Helps AI Users Boost Accuracy, Cut Costs and Save Time": {
            "url": "https://blogs.nvidia.com/blog/2023/07/12/mosaicml/",
            "description": "Startup MosaicML is on a mission to help the AI community improve prediction accuracy, decrease costs and save time by providing tools for easy training and deployment of large AI models. In this episode of NVIDIA\u2019s AI Podcast, host Noah Kravitz speaks with MosaicML CEO and co-founder Naveen Rao about how the company aims to <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/12/mosaicml/\">Read article &#62;</a>",
            "pubdate": "Wed, 12 Jul 2023 13:00:34 +0000",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Full-Scale Gaming: Dragons Dogma: Dark Arisen Comes to GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/07/13/geforce-now-thursday-july-13/",
            "description": "Arise, members! Capcom\u2019s legendary role-playing game Dragon\u2019s Dogma: Dark Arisen joins the GeForce NOW library today. The RPG and THQ Nordic\u2019s Jagged Alliance 3 are newly supported on GeForce NOW, playable on nearly any device. From Dusk Till Pawn Become the Arisen and take up the challenge in Capcom\u2019s critically acclaimed RPG. Set in a <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/13/geforce-now-thursday-july-13/\">Read article &#62;</a>",
            "pubdate": "Thu, 13 Jul 2023 13:00:27 +0000",
            "pubdate_parsed": [
                2023,
                7,
                13
            ],
            "email_sent": true
        },
        "Reborn, Remastered and Remixed: Portal: Prelude RTX Rejuvenates Legendary Gaming Mod": {
            "url": "https://blogs.nvidia.com/blog/2023/07/18/portal-prelude-rtx-remix-studio-driver/",
            "description": "The \u201cPortal: Prelude RTX\u201d gaming mod \u2014 a remastering of the popular unofficial \u201cPortal\u201d prequel \u2014 comes with full ray tracing, DLSS 3 and RTX IO technology for cutting-edge, AI-powered graphics that rejuvenate the legendary mod for gamers, creators, developers and others to experience it anew.",
            "pubdate": "Tue, 18 Jul 2023 13:00:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "So, So Fresh: Play the Newest Games in the Cloud on Day One": {
            "url": "https://blogs.nvidia.com/blog/2023/07/20/geforce-now-thursday-july-20/",
            "description": "It\u2019s a party this GFN Thursday with several newly launched titles streaming on GeForce NOW. Revel in gaming goodness with Xenonauts 2, Viewfinder and Techtonica, among the four new games joining the cloud this week. Portal fans, stay tuned \u2014 the Portal: Prelude RTX mod will be streaming on GeForce NOW to members soon. Plus, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/20/geforce-now-thursday-july-20/\">Read article &#62;</a>",
            "pubdate": "Thu, 20 Jul 2023 13:00:24 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "NVIDIA DGX Cloud Now Available to Supercharge Generative AI Training": {
            "url": "https://blogs.nvidia.com/blog/2023/07/25/dgx-generative-ai/",
            "description": "NVIDIA DGX Cloud \u2014 which delivers tools that can turn nearly any company into an AI company \u2014\u00a0 is now broadly available, with thousands of NVIDIA GPUs online on Oracle Cloud Infrastructure, as well as NVIDIA infrastructure located in the U.S. and U.K. Unveiled at NVIDIA\u2019s GTC conference in March, DGX Cloud is an AI <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/25/dgx-generative-ai/\">Read article &#62;</a>",
            "pubdate": "Tue, 25 Jul 2023 13:00:21 +0000",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "Fin-tastic: 3D Artist Dives Into AI-Powered Oceanic Work This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/07/25/alessandro-mastronardi-blender-omniverse-broadcast/",
            "description": "We\u2019re gonna need a bigger boat this week In the NVIDIA Studio as Alessandro Mastronardi, senior artist and programmer at BBC Studios, shares heart-stopping shark videos and renders.",
            "pubdate": "Tue, 25 Jul 2023 13:00:07 +0000",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "Codeiums Varun Mohan and Jeff Wang on Unleashing the Power of AI in Software Development": {
            "url": "https://blogs.nvidia.com/blog/2023/07/26/codeium/",
            "description": "The world increasingly runs on code. Accelerating the work of those who create that code will boost their productivity \u2014 and that\u2019s just what AI startup Codeium, a member of NVIDIA\u2019s Inception program for startups, aims to do. On the latest episode of NVIDIA\u2019s AI Podcast, host Noah Kravitz interviewed Codeium founder and CEO Varun <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/26/codeium/\">Read article &#62;</a>",
            "pubdate": "Wed, 26 Jul 2023 13:00:41 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "Gear Up and Game On: Gearboxs Remnant II Streaming on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/07/27/geforce-now-thursday-july-27/",
            "description": "Get ready for Gunfire Games and Gearbox Publishing\u2019s highly anticipated Remnant II, available for members to stream on GeForce NOW at launch. It leads eight new games coming to the cloud gaming platform. Ultimate and Priority members, make sure to grab the Guild Wars 2 rewards, available now through Thursday, Aug. 31. Visit the GeForce <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/07/27/geforce-now-thursday-july-27/\">Read article &#62;</a>",
            "pubdate": "Thu, 27 Jul 2023 13:00:59 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Cuddly 3D Creature Comes to Life in Father-Son Collaboration This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/08/01/johnson-autodesk-maya-adobe-3d-painter-photoshop/",
            "description": "Principal NVIDIA artist and 3D expert Michael Johnson creates highly detailed art that\u2019s both technically impressive and emotionally resonant.",
            "pubdate": "Tue, 01 Aug 2023 13:00:15 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "NVIDIA Helps Forge Forum to Set OpenUSD Standard for 3D Worlds": {
            "url": "https://blogs.nvidia.com/blog/2023/08/01/openusd-alliance-3d-standard/",
            "description": "NVIDIA joined Pixar, Adobe, Apple and Autodesk today to found the Alliance for OpenUSD, a major leap toward unlocking the next era of 3D graphics, design and simulation. The group will standardize and extend OpenUSD, the open-source Universal Scene Description framework that\u2019s the foundation of interoperable 3D applications and projects ranging from visual effects to <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/01/openusd-alliance-3d-standard/\">Read article &#62;</a>",
            "pubdate": "Tue, 01 Aug 2023 13:00:06 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "An Ultimate GFN Thursday: 41 New Games, Plus Baldurs Gate 3 Full Release and First Bethesda Titles to Join the Cloud in August": {
            "url": "https://blogs.nvidia.com/blog/2023/08/03/geforce-now-thursday-aug-03/",
            "description": "The Ultimate upgrade is complete \u2014 GeForce NOW Ultimate performance is now streaming all throughout North America and Europe, delivering RTX 4080-class power for gamers across these regions. Celebrate this month with 41 new games, on top of the full release of Baldur\u2019s Gate 3 and the first Bethesda titles coming to the cloud as <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/03/geforce-now-thursday-aug-03/\">Read article &#62;</a>",
            "pubdate": "Thu, 03 Aug 2023 13:00:26 +0000",
            "pubdate_parsed": [
                2023,
                8,
                3
            ],
            "email_sent": true
        },
        "The Proof Is in the Cloud: GeForce NOW Announces Ultimate KovaaKs Challenge Results": {
            "url": "https://blogs.nvidia.com/blog/2023/08/17/geforce-now-thursday-aug-17/",
            "description": "The verdict is in: A GeForce NOW Ultimate membership raises the bar on gaming. Members have been tackling the Ultimate KovvaK\u2019s challenge head-on and seeing for themselves how the power of Ultimate improves their gaming with 240 frames per second streaming. The popular training title that helps gamers improve their aim fully launches in the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/17/geforce-now-thursday-aug-17/\">Read article &#62;</a>",
            "pubdate": "Thu, 17 Aug 2023 13:00:57 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "Coming This Fall: NVIDIA DLSS 3.5 for Chaos Vantage, D5 Render, Omniverse and Popular Game Titles": {
            "url": "https://blogs.nvidia.com/blog/2023/08/22/dlss-ai-rtx-remix-half-life-d5-render-chaos-vantage/",
            "description": "On the eve of Gamescom, NVIDIA announced NVIDIA DLSS 3.5 featuring Ray Reconstruction \u2014 a new neural rendering AI model that creates more beautiful and realistic ray-traced visuals than traditional rendering methods \u2014 for real-time 3D creative apps and games.",
            "pubdate": "Tue, 22 Aug 2023 13:07:36 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "NVIDIA Debuts AI-Enhanced Real-Time Ray Tracing for Games and Apps With New DLSS 3.5": {
            "url": "https://blogs.nvidia.com/blog/2023/08/22/gamescom-dlss-ray-reconstruction/",
            "description": "The latest advancements in AI for gaming are in the spotlight today at Gamescom, the world\u2019s largest gaming conference, as NVIDIA introduced a host of technologies, starting with DLSS 3.5, the next step forward of its breakthrough AI neural rendering technology. DLSS 3.5, NVIDIA\u2019s latest innovation in AI-powered graphics is an image quality upgrade incorporated <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/22/gamescom-dlss-ray-reconstruction/\">Read article &#62;</a>",
            "pubdate": "Tue, 22 Aug 2023 13:00:13 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "Xbox PC Game Pass Comes to GeForce NOW, Along With 25 New Games": {
            "url": "https://blogs.nvidia.com/blog/2023/08/24/geforce-now-thursday-aug-24/",
            "description": "As part of NVIDIA and Microsoft\u2019s collaboration to bring more choice to gamers, new Microsoft Store integration has been added to GeForce NOW that lets gamers stream select titles from the Xbox PC Game Pass catalog on GeForce NOW, starting today. With the Microsoft Store integration, members will see a brand-new Xbox button on supported <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/24/geforce-now-thursday-aug-24/\">Read article &#62;</a>",
            "pubdate": "Thu, 24 Aug 2023 13:00:13 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Advantage AI: Elevated Creative Workflows in NVIDIA Canvas, Blender, TikTok and CapCut": {
            "url": "https://blogs.nvidia.com/blog/2023/08/29/janice-journal-canvas-blender-tiktok-capcut/",
            "description": "Janice K. Lee, a.k.a Janice.Journal \u2014 the subject of this week\u2019s In the NVIDIA Studio installment \u2014 is a TikTok sensation using AI to accelerate her creative process, find inspiration and automate repetitive tasks.",
            "pubdate": "Tue, 29 Aug 2023 13:00:34 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Deepdubs AI Redefining Dubbing from Hollywood to Bollywood": {
            "url": "https://blogs.nvidia.com/blog/2023/08/30/deepdub/",
            "description": "In the global entertainment landscape, TV show and film production stretches far beyond Hollywood or Bollywood \u2014 it&#8217;s a worldwide phenomenon. However, while streaming platforms have broadened the reach of content, dubbing and translation technology still has plenty of room for growth. Deepdub acts as a digital bridge, providing access to content by using generative <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/30/deepdub/\">Read article &#62;</a>",
            "pubdate": "Wed, 30 Aug 2023 13:00:50 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "GeForce NOW Gets Wild, With Party Animals Leading 24 New Games in September": {
            "url": "https://blogs.nvidia.com/blog/2023/08/31/geforce-now-thursday-aug-31/",
            "description": "Just like that, summer falls into September, and some of the most anticipated games of the year, like the Cyberpunk 2077: Phantom Liberty expansion, PAYDAY 3 and Party Animals, are dropping into the GeForce NOW library at launch this month. They\u2019re part of 24 new games hitting the cloud gaming service in September. And the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/08/31/geforce-now-thursday-aug-31/\">Read article &#62;</a>",
            "pubdate": "Thu, 31 Aug 2023 13:00:50 +0000",
            "pubdate_parsed": [
                2023,
                8,
                31
            ],
            "email_sent": true
        },
        "A Perfect Pair: adidas and Covision Media Use AI, NVIDIA RTX to Create Photorealistic 3D Content": {
            "url": "https://blogs.nvidia.com/blog/2023/09/05/covision-adidas-rtx-ai/",
            "description": "Creating 3D scans of physical products can be time consuming. Businesses often use traditional methods, like photogrammetry-based apps and scanners, but these can take hours or even days. They also don\u2019t always provide the 3D quality and level of detail needed to make models look realistic in all its applications. Italy-based startup Covision Media is <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/05/covision-adidas-rtx-ai/\">Read article &#62;</a>",
            "pubdate": "Tue, 05 Sep 2023 13:00:44 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "Arteanas Art Squad Assembles  Indie Showrunner Rafi Nizam Creates High-End Childrens Show on a Budget": {
            "url": "https://blogs.nvidia.com/blog/2023/09/06/asus-proart-studio-laptop-omniverse-openusd/",
            "description": "Rafi Nizam is an award-winning independent animator, director, character designer and more. He\u2019s developed feature films at Sony Pictures, children\u2019s series and comedies at BBC and global transmedia content at NBCUniversal.",
            "pubdate": "Wed, 06 Sep 2023 13:00:28 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "Attention, Please: Focus Entertainment Brings Game Pass Titles to GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/09/07/geforce-now-thursday-sep-07/",
            "description": "GeForce NOW brings expanded support for PC Game Pass to members this week. Members can stream eight more games from Microsoft\u2019s subscription service, including four titles from hit publisher Focus Entertainment. Play A Plague Tale: Requiem, Atomic Heart and more from the GeForce NOW library at up to 4K resolution and 120 frames per second <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/07/geforce-now-thursday-sep-07/\">Read article &#62;</a>",
            "pubdate": "Thu, 07 Sep 2023 13:00:18 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "One Small Step for Artists, One Giant Leap for Creative-Kind": {
            "url": "https://blogs.nvidia.com/blog/2023/09/12/aendom-blender-adobe-substance-3d-painter/",
            "description": "Editor\u2019s note: This post is part of our weekly In the NVIDIA Studio series, which celebrates featured artists, offers creative tips and tricks and demonstrates how NVIDIA Studio technology improves creative workflows.\u00a0 When it comes to converting 2D concepts into 3D masterpieces, self-taught visual development artist Alex Trevi\u00f1o has confidence in the potential of all <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/12/aendom-blender-adobe-substance-3d-painter/\">Read article &#62;</a>",
            "pubdate": "Tue, 12 Sep 2023 13:00:35 +0000",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "Unlocking the Language of Genomes and Climates: Anima Anandkumar on Using Generative AI to Tackle Global Challenges": {
            "url": "https://blogs.nvidia.com/blog/2023/09/13/anima-anandkumar-generative-ai/",
            "description": "Generative AI-based models can not only learn and understand natural languages \u2014 they can learn the very language of nature itself, presenting new possibilities for scientific research. Anima Anandkumar, Bren Professor at Caltech and senior director of AI research at NVIDIA, was recently invited to speak at the President\u2019s Council of Advisors on Science and <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/13/anima-anandkumar-generative-ai/\">Read article &#62;</a>",
            "pubdate": "Wed, 13 Sep 2023 13:00:11 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Shout at the Devil: Capcoms Devil May Cry 5 Joins GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/09/14/geforce-now-thursday-sep-14/",
            "description": "GFN Thursday is downright demonic, as Devil May Cry 5 comes to GeForce NOW. Capcom\u2019s action-packed third-person brawler leads 15 titles joining the GeForce NOW library this week, including Gears Tactics and The Crew Motorfest. It\u2019s also the last week to take on the Ultimate KovaaK\u2019s Challenge. Get on the leaderboard today for a chance <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/14/geforce-now-thursday-sep-14/\">Read article &#62;</a>",
            "pubdate": "Thu, 14 Sep 2023 13:00:20 +0000",
            "pubdate_parsed": [
                2023,
                9,
                14
            ],
            "email_sent": true
        },
        "Ray Shines with NVIDIA AI: Anyscale Collaboration to Help Developers Build, Tune, Train and Scale Production LLMs": {
            "url": "https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvaie/",
            "description": "Large language model development is about to reach supersonic speed thanks to a collaboration between NVIDIA and Anyscale. At its annual Ray Summit developers conference, Anyscale \u2014 the company behind the fast growing open-source unified compute framework for scalable computing \u2014 \u00a0announced today that it is bringing NVIDIA AI to Ray open source and the <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/18/llm-anyscale-nvaie/\">Read article &#62;</a>",
            "pubdate": "Mon, 18 Sep 2023 13:00:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                18
            ],
            "email_sent": true
        },
        "Into the Omniverse: Blender 4.0 Alpha Release Sets Stage for New Era of OpenUSD Artistry": {
            "url": "https://blogs.nvidia.com/blog/2023/09/21/omniverse-blender-release-openusd/",
            "description": "For seasoned 3D artists and budding digital creation enthusiasts alike, an alpha version of the popular 3D software Blender is elevating creative journeys.",
            "pubdate": "Thu, 21 Sep 2023 13:00:34 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "NVIDIA CEO Jensen Huang to Headline AI Summit in Tel Aviv": {
            "url": "https://blogs.nvidia.com/blog/2023/09/21/ai-summit/",
            "description": "NVIDIA founder and CEO Jensen Huang will highlight the newest in generative AI and cloud computing at the NVIDIA AI Summit in Tel Aviv from Oct. 15-16. The two-day summit is set to attract more than 2,500 developers, researchers and decision-makers from across one of the world\u2019s most vibrant technology hubs. With over 6,000 startups, <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/21/ai-summit/\">Read article &#62;</a>",
            "pubdate": "Thu, 21 Sep 2023 13:00:27 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "Cash In: PAYDAY 3 Streams on GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/",
            "description": "Time to get the gang back together \u2014 PAYDAY 3 streams on GeForce NOW this week. It\u2019s one of 11 titles joining the cloud this week, including Party Animals. The Perfect Heist PAYDAY 3 is the highly anticipated sequel to one of the world\u2019s most popular co-op shooters. Step out of retirement and back into <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/21/geforce-now-thursday-sep-21/\">Read article &#62;</a>",
            "pubdate": "Thu, 21 Sep 2023 13:00:19 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "AI Power Players: GeForce and NVIDIA RTX GPUs Supercharge Creativity, Gaming, Development, Productivity and More": {
            "url": "https://blogs.nvidia.com/blog/2023/09/26/itns-rtx-ai-windows/",
            "description": "From gaming to creating to everyday productivity, NVIDIA RTX graphics cards feature specialized Tensor Cores that deliver cutting-edge performance and transformative capabilities for AI.",
            "pubdate": "Tue, 26 Sep 2023 13:00:49 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "NVIDIA Works With NTT DOCOMO to Launch Worlds First GPU-Accelerated 5G Network": {
            "url": "https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/",
            "description": "As generative AI sweeps across corporate boardrooms around the world, global telecommunications companies are exploring how to cost-effectively deliver many of these new AI applications to the edge over 5G and upcoming 6G networks. Telcos plan to deploy over 17 million 5G microcells and towers worldwide by 2025. Building, managing and optimizing this new infrastructure <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/26/ntt-docomo-gpu-accelerated-5g-network/\">Read article &#62;</a>",
            "pubdate": "Wed, 27 Sep 2023 00:00:03 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "The Fastest Path: Healthcare Startup Uses AI to Analyze Cancer Cells in the Operating Room": {
            "url": "https://blogs.nvidia.com/blog/2023/09/27/healthcare-ai-startup-analyzes-cancer-cells-in-the-operating-room/",
            "description": "Medical-device company Invenio Imaging is developing technology that enables surgeons to evaluate tissue biopsies in the operating room, immediately after samples are collected \u2014 providing in just three minutes AI-accelerated insights that would otherwise take weeks to obtain from a pathology lab. In a surgical biopsy, a medical professional removes samples of cells or tissue <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/27/healthcare-ai-startup-analyzes-cancer-cells-in-the-operating-room/\">Read article &#62;</a>",
            "pubdate": "Wed, 27 Sep 2023 13:00:40 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "V for Victory: Cyberpunk 2077: Phantom Liberty Comes to GeForce NOW": {
            "url": "https://blogs.nvidia.com/blog/2023/09/28/geforce-now-thursday-sep-28/",
            "description": "The wait is over. GeForce NOW Ultimate members can experience Cyberpunk 2077: Phantom Liberty on GOG.com at full GeForce RTX 4080 quality, with support for NVIDIA DLSS 3.5 technology. It\u2019s part of an action-packed GFN Thursday, with 26 more games joining the cloud gaming platform\u2019s library, including Quake II from id Software. A New Look <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/09/28/geforce-now-thursday-sep-28/\">Read article &#62;</a>",
            "pubdate": "Thu, 28 Sep 2023 13:00:45 +0000",
            "pubdate_parsed": [
                2023,
                9,
                28
            ],
            "email_sent": true
        },
        "CG Geek Makes VFX Look Easy This Week In the NVIDIA Studio": {
            "url": "https://blogs.nvidia.com/blog/2023/10/03/cg-geek-blender/",
            "description": "Releasing a 3D tutorial dubbed The Easiest VFX Tutorial Ever takes supreme confidence and the skills to back it up. Steve Lund a.k.a. CG Geek \u2014 the featured artist of this week\u2019s In the NVIDIA Studio installment \u2014 has both in spades.",
            "pubdate": "Tue, 03 Oct 2023 13:00:33 +0000",
            "pubdate_parsed": [
                2023,
                10,
                3
            ],
            "email_sent": true
        },
        "Brains of the Operation: Atlas Meditech Maps Future of Surgery With AI, Digital Twins": {
            "url": "https://blogs.nvidia.com/blog/2023/10/05/atlas-meditech-brain-surgery-ai-digital-twins/",
            "description": "Just as athletes train for a game or actors rehearse for a performance, surgeons prepare ahead of an operation. Now, Atlas Meditech is letting brain surgeons experience a new level of realism in their pre-surgery preparation with AI and physically accurate simulations. Atlas Meditech, a brain-surgery intelligence platform, is adopting tools \u2014 including the MONAI <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/10/05/atlas-meditech-brain-surgery-ai-digital-twins/\">Read article &#62;</a>",
            "pubdate": "Thu, 05 Oct 2023 13:00:43 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Fall in Line for October With Nearly 60 New Games, Including Latest Game Pass Titles to Join the Cloud": {
            "url": "https://blogs.nvidia.com/blog/2023/10/05/geforce-now-thursday-oct-5/",
            "description": "October brings more than falling leaves and pumpkin spice lattes for GeForce NOW members. Get ready for nearly 60 new games to stream, including Forza Motorsport and 16 more PC Game Pass titles. Assassin\u2019s Creed Mirage leads 29 new games to hit the GeForce NOW library this week. In addition, catch a challenge to earn <a class=\"read-more\" href=\"https://blogs.nvidia.com/blog/2023/10/05/geforce-now-thursday-oct-5/\">Read article &#62;</a>",
            "pubdate": "Thu, 05 Oct 2023 13:00:25 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        }
    },
    "CMU Machine Learning Blog": {
        "Recurrent Model-Free RL Can Be a Strong Baseline for Many POMDPs": {
            "url": "https://blog.ml.cmu.edu/2022/08/26/recurrent-model-free-rl-can-be-a-strong-baseline-for-many-pomdps-2/",
            "description": "Figure 1. Our implementation of recurrent model-free RL outperforms the on-policy version (PPO/A2C-GRU), and a recent model-based POMDP algorithm (VRM) on most tasks of a POMDP benchmark where VRM was evaluated in their paper. While algorithms for decision-making typically focus on relatively easy problems where everything is known, most realistic problems involve noise and incomplete information. Complex algorithms have been proposed to tackle these complex problems, but there&#8217;s a simple approach that (in theory) works on both the easy and the complex problems. We show how to make this simple approach work in practice. Why POMDPs? Decision-making tasks in the real world are messy, with noise, occlusions, and uncertainty that are typically missing from their canonical problem formulation as a Markov decision process (MDP; Bellman, 1957). In contrast, Partially Observable MDPs (POMDPs; \u00c5str\u00f6m, 1965) can capture the uncertainty in the states, rewards, and dynamics. Such uncertainty arises in applications such as robotics, healthcare, NLP and finance. Apart from being realistic, POMDPs are a general framework that contains many subareas in RL, including: Meta-RL (Schmidhuber, 1987, Thrun and Pratt, 2012, Duan et al., 2016, Wang et al., 2017): assume the hidden states (task variables) of a POMDP do not vary through [&#8230;]",
            "pubdate": "Fri, 26 Aug 2022 17:38:40 +0000",
            "pubdate_parsed": [
                2022,
                8,
                26
            ],
            "email_sent": true
        },
        "Tracking Any Pixel in a Video": {
            "url": "https://blog.ml.cmu.edu/2022/09/09/tracking-any-pixel-in-a-video/",
            "description": "We upgrade pixels into PIPs: &#8220;Persistent Independent Particles&#8221;. With this representation, we track any pixel over time, and overcome visibility issues with a learned temporal prior. Motion estimation is a fundamental task of computer vision, with extremely broad applications. By tracking something, you can build models of its various properties: shape, texture, articulation, dynamics, affordances, and so on. More fine-grained tracking allows more fine-grained understanding. For robots, fine-grained tracking also enables fine-grained manipulation. Even setting aside downstream AI-related applications, motion tracks are directly useful for video editing applications &#8212; making realistic edits to a person or object in a video demands precise-as-possible tracking of the pixels, across an indefinite timespan. There are a variety of methods for tracking objects (at the level of segmentation masks or bounding boxes), or for tracking certain points in certain categories (e.g., the joints of a person), but there are actually very few options for general-purpose fine-grained tracking. In this domain, the dominant approaches are feature matching and optical flow. The feature matching approach is: compute a feature for the target on the first frame, then compute features for pixels in other frames, and then compute &#8220;matches&#8221; using feature similarity (i.e., nearest neighbors). This often [&#8230;]",
            "pubdate": "Sat, 10 Sep 2022 00:54:53 +0000",
            "pubdate_parsed": [
                2022,
                9,
                10
            ],
            "email_sent": true
        },
        "Are Model Explanations Useful in Practice? Rethinking How to Support Human-ML Interactions.": {
            "url": "https://blog.ml.cmu.edu/2023/03/30/are-model-explanations-useful-in-practice-rethinking-how-to-support-human-ml-interactions/",
            "description": "Model explanations have been touted as crucial information to facilitate human-ML interactions in many real-world applications where end users make decisions informed by ML predictions. For example, explanations are thought to assist model developers in identifying when models rely on spurious artifacts and to aid domain experts in determining whether to follow a model\u2019s prediction. However, while numerous explainable AI (XAI) methods have been developed, XAI has yet to deliver on this promise. XAI methods are typically optimized for diverse but narrow technical objectives disconnected from their claimed use cases. To connect methods to concrete use cases, we argued in our Communications of ACM paper [1] for researchers to rigorously evaluate how well proposed methods can help real users in their real-world applications.&#160; Towards bridging this gap, our group has since completed two collaborative projects where we worked with domain experts in e-commerce fraud detection and paper matching for peer review. Through these efforts, we\u2019ve gleaned the following two insights: Existing XAI methods are not useful for decision-making. Presenting humans with popular, general-purpose XAI methods does not improve their performance on real-world use cases that motivated the development of these methods. Our negative findings align with those of contemporaneous works. [&#8230;]",
            "pubdate": "Fri, 31 Mar 2023 03:32:01 +0000",
            "pubdate_parsed": [
                2023,
                3,
                31
            ],
            "email_sent": true
        }
    },
    "TensorFlow Blog": {
        "Highlights from TensorFlows 2021 exploreCSR awards": {
            "url": "https://blog.tensorflow.org/2022/02/exploreCSR-awards-highlights.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/a/AVvXsEjDPu7hWKseCInuSNKBkdkHEmHMRHIv2WoQjqs8fVMrvtglukxO4hKtDOAnMKFpLn1VslC37Y4qf-mDzO13fQHkwZoYf_fT7cL4cb0E_6XZHtm_VkuLesY83xdyli9zNoiPg79DbPZi97zCMVb4J9Logkm5O7UxG3IY2mYpKXm9Z5lWskPAAnyu86Kb\" style=\"display: none;\" /> <p><em>Posted by <a href=\"https://twitter.com/random_forests\">Josh Gordon</a>, Jocelyn Becker, and Sloan Davis for the TensorFlow team</em></p><a name=\"more\"></a> <p>Increasing the number of students pursuing computer science research is a priority at Google, especially for students from historically marginalized groups in the field. Since 2018, Google\u2019s <a href=\"https://research.google/outreach/explore-csr/\">exploreCSR</a> awards have aided higher education efforts that support students interested in pursuing graduate studies and research careers in computing.  </p><p>The TensorFlow team is proud to provide additional funding to support this important program. To date, we have awarded more than 20 professors with funding to support their education and outreach work in machine learning.  </p><p>We\u2019d like to highlight examples of the many (and often, unique) outreach programs the 2021 award recipients have created so far. These range from research experiences with robotics, aquatic vehicles, federated learning, and offline digital libraries to mentored small group workshops on data science and programming skills. They\u2019re sorted alphabetically by university below. </p><p>If you\u2019re interested in creating your own programs like these with support from Google, keep an eye on the <a href=\"https://research.google/outreach/explore-csr/\">exploreCSR</a> website for the next round of applications opening in June 2022. </p><p><strong><em>Laura Hosman and Courtney Finkbeiner, Arizona State University</em></strong></p><p>The <a href=\"https://solarspell.org/\">SolarSPELL</a> initiative at Arizona State University will host a workshop series thanks to support from exploreCSR to encourage students underrepresented in computer science research in their academic journey. The SolarSPELL initiative produces an offline, solar-powered digital library designed to bring educational content to resource-constrained locations that may lack electricity, internet connectivity, and/or traditional libraries.  </p><p>The exploreCSR workshop series, titled \u201cSolarSPELL exploreCSR: Computing for Good\u201d, involves 6 weeks of sessions using SolarSPELL as a case study for how students can apply machine learning to tackle real-world problems and develop solutions for social good. Students will meet SolarSPELL\u2019s co-director and learn about the history of the SolarSPELL initiative; learn about graduate programs available at ASU; and hear from guest panelists from industry.  </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgUvY3hc5BkaB57WmKy-mVerTCQ9rHSD03STkw8TfUKR81xxJDAgyj90w7QC6FxH80J5-BvWdb979RL91fjHQuNihJ_2lhrXpClFCnAFRQJIhVE2PGA7DEebEyLv6pCQRRpCXyciF-xJsES6_5UsQq9DUZCOcnIn57qtTFPcNatd4GwY0xmoCa-_liY\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A solar-powered, offline digital library.</td></tr></tbody></table> <p>Aside from the information sessions, students will also gain hands-on experience working in teams and problem solving for real-world topics. The SolarSPELL team will present the students with three different challenges for student teams to develop a proposed solution using machine learning. Students will then be eligible to apply for paid summer fellowship positions with SolarSPELL to develop and integrate one of the proposed machine learning models into SolarSPELL\u2019s technology.  </p><p>SolarSPELL is a student-driven initiative, so the solutions that the exploreCSR students develop will be implemented in our digital libraries to improve hundreds of library users\u2019 experiences around the world. With libraries in 10 countries in the Pacific Islands and East Africa, and plans to expand to Latin America and the Middle East, these students will have a far-reaching impact. </p><p><strong><em>Daehan Kwak, Kean University</em></strong></p><p>My colleague Xudong Zhang and I created an undergraduate research study group centered on computer vision, with projects underway on student attention detection, mask and social distancing detection, and pill recognition for healthcare scenarios. As one example, a student created a pill detection application using data from the National Library of Medicine pillbox. This can be used, for example, by high-volume distribution pharmacies to be more efficient and accurate, or by retirement homes to verify the pills a resident is taking. We\u2019re pleased to share that the pill recognition project won third place in the Kean Business Plan Competition and was accepted to be presented at <a href=\"https://www.cur.org/what/events/students/poh/\">Posters on the Hill 2022</a>. </p><p><strong><em>Matthew Roberts, Macquarie University</em></strong></p><p>The School of Computing at Macquarie University is working to lower the barrier to entry for students who are new to experimenting with ML by employing real-world examples. This month, around fifty students will spend the week testing their ideas for solving autonomous aquatic vehicles challenges (for example, navigation) under guidance from Macquarie University researchers. They will be developing their ideas with a sophisticated simulation environment, and the best solutions will be ready for deployment to real hardware testing in the water later in the year. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiAeBoCCXY-rZSeoQLS3OcukXLsZzTz2-yjz3YwvFFTUJiFpcTPl4WKHIAWQB7I_bJwaT2R6-j6VJ3JxSF-adjRYGchmd352jmUqPKbqFJbqyhNMG4oYTLVxD1oFobbn30Qjn5nfd2vDpJbAANAeoO6EoVnuQ46yM32O0CaK-A-KQO84vzMQ3d5RzxC\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A MacSim simulation of the Sydney Regatta Center (created by VRX), a placeholder for a machine learning model, is making random predictions, ready for improvements the students come up with.</td></tr></tbody></table> <p>Accurately simulated sensors like cameras and LIDAR can be subjected to various models, allowing people to experiment with even more sophisticated ideas to solve complex problems. After our first year in exploreCSR, the adjustments we made to our simulator and the workshop will generate new ideas and light a spark for machine learning research early in students' careers. </p><p><strong><em>Pooyan Fazli, San Francisco State University</em></strong></p><p>60+ students from 10 universities and colleges attended our<a href=\"https://democratizeai.org/\"> 2-day virtual exploreCSR workshop</a>. Participants were from San Francisco State University, CSU East Bay, CSU San Marcos, CSU Stanislaus, Foothill College, Northwestern University, San Diego State University, Sonoma State University, UC San Diego, and the University of San Francisco. </p><p>We had two invited speakers and two panels on mentorship and career pathways with 10 panelists from Google Research, Stanford, Emory University, Virginia Tech, and the University of Copenhagen. </p><p>As part of this workshop, we organized hands-on activities to introduce students to different aspects of AI and its applications for social good, such as with climate change. We also had mini-presentations and discussions on AI fairness, accountability, transparency and ethics in different areas, such as robotics, educational data mining, and impacts on underserved communities. </p><p>Following the workshop, selected students will participate in a research project under the guidance of graduate students and faculty during the spring semester. Through the research projects, we have a two-fold aim: to help students develop a sense of belonging in the AI and machine learning research community, and to illuminate a pathway for them to pursue graduate studies in AI/ML that explores the potential of developing responsible AI toward social good. </p><p>The research projects will begin with eight weekly meetups and hands-on training on Python programming with open-source publicly available materials. Then, students will engage in applied research projects that focus on AI applications for social good, such as health, environment, safety, education, climate change, and accessibility. </p><p><strong><em>Farzana Rahman, Syracuse University</em></strong></p><p>Earlier this year, the Electrical Engineering and Computer Science department of Syracuse University hosted RESORC (REsearch Exposure in Socially Relevant Computing), an exploreCSR program, for the second time. This program provided research exposure to 78 undergraduate students from SU and nearby institutions targeting populations historically underrepresented in computing. The goal of these two workshops was to give students an opportunity to learn machine learning using open-source tools, and to gain experience with data science workflows including collecting and labeling data, training a model, and carefully evaluating it. The ML workshops were the mostly highly rated sessions of the RESORC program. </p><p><strong><em>Erin Hestir and Leigh Bernacchi, University of California, Merced</em></strong></p><p>  </p><p>Since 2019, University of California, Merced has partnered with Merced College and California State University Stanislaus on the Google exploreCSR program <a href=\"https://citris.ucmerced.edu/valle\">\u00a1Valle! Get Your Start in Tech!</a>, serving 32 Central Valley of California undergraduates in STEM annually to build a sense of belonging, practice professional networking, and develop technical skills. Participants convene on Zoom and in-person this semester. Valle students typically come from historically underrepresented groups, and the program is designed to support their pursuits of computational research, graduate school and computer science related careers. Many have gone on to achieve just that! </p><p>  </p><p>This year we added additional training thanks to Google Research to support machine learning applications for social good. This program is open to all Valle participants as well as partner schools, inclusive of graduate and undergraduate students in all STEM fields, and will be taught by creative graduate students in computer science from UC Merced. Each workshop will be taught by a near-peer mentor\u2014a practice that supports mutual success in academics\u2014and the mentor will coach teams to develop ML projects for social good. </p><p>  </p><p>The goal of the program is to overcome some of the trepidation scientists and students may have about computational science and machine learning through teamwork, fun and a higher purpose. Students will be able to develop their skills and interest, focusing on ML applications to climate, sustainability, agriculture and food, and diversity in tech and aviation. </p><p><strong><em>Basak Guler, University of California, Riverside</em></strong></p><p>At the University of California, Riverside, we created an undergraduate research study group focused on federated and distributed machine learning. Federated learning has become widely popular in recent years due to its communication efficiency and on-device learning architecture. Our study group meets on a weekly basis, and students learn about the principles of federated and distributed learning, state-of-the-art federated learning algorithms, recent applications from financial services to healthcare, as well as recent challenges and advances in privacy, security, and fairness. Student projects provide opportunities for undergraduate students to be involved in machine learning research, and learn from the experiences of both faculty and graduate students. This program can facilitate their transition from undergraduate to graduate degrees, and prepare them for positions of leadership in industry, government, public service, and academia. </p><p><strong><em>Gonzalo A. Bello, University of Illinois at Chicago</em></strong></p><p>The computer science department is hosting a series of exploreCSR workshops, including <a href=\"https://engineering.uic.edu/news-stories/workshop-allows-students-to-explore-data-science/\">exploreCSR: Exploring Data Science Research</a>, to introduce students to data science and machine learning research. These workshops aim to encourage students from historically underrepresented groups to pursue graduate studies and careers in research in the field of computer science. UIC students from all majors were encouraged to apply, including those who haven\u2019t taken any computer science courses. Each semester, 60 students were selected out of more than 120 who applied, and 10 teaching assistants and a professor mentored students. In addition to lectures, students work on hands-on projects together where they explore, visualize, and build models using real-world data from the city of Chicago. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhve9mJivIXHkAKKR1QTY9fYuYNlaLlkDNxMCDZ26NHr-ARueVqF7NvA_JmcRdSfEMZxcnzkkzL5bGT5cbpiyVB-ZReaOa966J_XZxF8Hn6fj7sQjX9WX_rA8KKr3dyjWcAJTYVbpWULd_VqikMgLOk-CGnapkOphlzNvpt94928-2NHoo7xVctJ67r\" style=\"width: 50%;\" /></center></td></tr>  </tbody></table>  <p><strong><em>Melanie Moses and Humayra Tasnim, The University of New Mexico</em></strong></p><p>The UNM Google exploreCSR activity for 2021-2022 is a semester-long course called Swarmathon: The Next Generation. The students will learn technical skills like developing machine learning models for object recognition in robots, and soft skills including team building, research skills, and discussions with faculty and external speakers. The UNM exploreCSR program builds on 5 years of training students in a NASA-sponsored robotics competition called the Swarmathon (2014-2019). In 2019/2020 we developed a series of exploreCSR Swarmathon: TNG workshops which included a faculty panel, an industry mentor, an open-source tutorial, and a day-long workshop to enable \u201cSwarmie\u201d robots to classify and automatically retrieve objects.  </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEgn4do72xEklUYQADYsXZM277ifC9VmM83kaQmSpIM7C4cKJlFdeW9t2XPMWSooDLJkElGH5qg13B82CvNqVjiO2jxsp1HNXffOwu0ZCocGR0kXi8KiETUwnRlaqTNJZZdQQeQPuxuO06LHXzhTnq27ViMzJZg4PBaFOayFN4G4DRot0q0X5VNljbJx\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A glimpse of our robots in action.</td></tr></tbody></table> <p>  This year, in our exploreCSR Swarmathon: TNG course, students will have additional time to actively engage in developing and tuning their own machine learning models to test in the Swarmie robots. They will develop object detection models using convolutional neural networks (CNNs). They will be provided with a dataset of images of objects (shown below) taken from the robot camera and a simple model. The students will further develop the model and training data and then test their models on actual robots in real-time to see how much they can improve object recognition models to classify and retrieve the proper specified objects.</p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEhoBYEZIk106bijUo1_u5hWOQyW9VM8YKy6kznxXK1UX3jpwJr5k1vi12kncOEj5XSL3E1WgWcOFDVvZr5-wcuYbhToBZ9ZoeVxruzQ0IMzhMop0toDFfqWxcvhvW0UrELxm5tY1F7kWc7VOO7nGsejmJuOW0ZuEfpk_I6q0B9Oz5fZtHlDegZcTOBK\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Different shaped cubes for detection.</td></tr></tbody></table> <p>  Students will learn first-hand the reality gap between simulations and real-world experiments. This will encourage them to develop their own mini-research projects to enhance their model performance to resolve that gap. The exploreCSR-funded Swarmathon: TNG course will provide students with the opportunity to actively engage in hands-on robotics research. We hope the experience of defining a research objective, conducting a set of experiments, testing a model, and seeing results play out in our robotics arena will motivate students to attend graduate school and consider research careers.</p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEiM_aKpMKE40fa0ALpPQ-_oWDZByNX_noVuneLKmYQtyjQYsNMzAtOxEox6PKgzVpxy7hxbpiZEj0v6Kq4qQtB585VasDWVc-7_P2rZT7Q9qf0a7b9zfBHofVFfcUvpSPcC90lEDlbEnVYWmknGmkm_fC-BTurl-RwmhWoCjz6K7lz4Sv04gqEQ2RP_\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Swarmie with a cube in its gripper.</td></tr></tbody></table> <p><strong><em>Daniel Mej\u00eda, The University of Texas at El Paso</em></strong></p><p>We\u2019re building a series of workshops open to undergraduate students of all majors to introduce them to applied machine learning and research topics, starting with foundational concepts in math and a newfound way of approaching a problem through the eyes of a data scientist. These workshops are open to all students, including those who do not have any prior experience. We hope to encourage students to consider pursuing graduate studies, especially those who may have not previously considered it. I believe that the earlier students are exposed, the more likely that they will pursue a graduate degree. </p><p><strong><em>Henry Griffith, The University of Texas at San Antonio</em></strong></p><p>At the University of Texas at San Antonio, we\u2019re creating a portfolio of programs to enhance the persistence of first year Electrical and Computer Engineering students into research computing pathways. By integrating our programming with our Introduction to Electrical and Computer Engineering course, which has a total annual enrollment of approximately 200 students, we have the opportunity to achieve tremendous scale with our efforts. Our programs include an undergraduate research experience, a near-peer mentoring program, and group study projects - all designed to develop students' professional and technical skills and to accelerate their progression into research opportunities. </p><p><strong><em>John Akers, University of Washington</em></strong></p><p>Our exploreCSR workshop, <a href=\"https://realitylab.uw.edu/components/graduate-prep-workshop.html\">CSNext</a>, is scheduled to begin this April. It\u2019s a 4-week online program of workshops, seminars, and project work designed to encourage undergraduate students - particularly those from historically underrepresented groups - to consider and successfully apply to graduate schools in computer science. Participants will hear presentations from several University of Washington labs, such as Computer Vision/Graphics (GRAIL), Security and Privacy, and Human-Computer Interaction. There will be presentations on deep learning and on current graduate-level research, a panel discussion from current UW CSE grad students from varying backgrounds, opportunities to meet current graduate students from several UW CSE labs, and participants will be led through small-group exercises learning about active research from graduate student mentors. Participants will also learn about graduate school application processes and resources, led by staff from UW CSE Graduate Student Services. </p><h3>Learning more</h3>  <p>If you\u2019re interested in creating your own programs like these with support from Google, keep an eye on the <a href=\"https://research.google/outreach/explore-csr/\">exploreCSR</a> website for the next round of applications opening in June 2022.  </p>",
            "pubdate": "Wed, 23 Feb 2022 16:58:00 +0000",
            "pubdate_parsed": [
                2022,
                2,
                23
            ],
            "email_sent": true
        },
        "Accelerating TensorFlow Lite Micro on Cadence Audio Digital Signal Processors": {
            "url": "https://blog.tensorflow.org/2022/03/Accelerating-TFLite-Micro-On-Cadence.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmewLNKzKRZm7tPlPsm3AzC8g47bwqeo7EsJwCruRRi9s1gY2gRhfdNUPU6-SZhGq-AGTEW3FrcQpVWgF48w3OaAxZ7If3kYHuROVuqdWN1x5J3AJx43WVorfIsYsb2ulFJIJGjOfP4zR0P1KQ8cp1ajaHsGB1w5vfrvZrsfubTIh9Ju13vo4p1ry/s1600/image1.jpg\" style=\"display: none;\" />  <p><em>Posted by Raj Pawate (Cadence) and Advait Jain (Google)</em></p><a name=\"more\"></a><p>Digital Signal Processors (DSPs) are a key part of any battery-powered device offering a way to process audio data with a very low power consumption. These chips run signal processing algorithms such as audio codecs, noise canceling and beam forming. </p><p>Increasingly these DSPs are also being used to run neural networks such as wake-word detection, speech recognition, and noise suppression. A key part of enabling such applications is the ability to execute these neural networks as efficiently as possible. </p> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmewLNKzKRZm7tPlPsm3AzC8g47bwqeo7EsJwCruRRi9s1gY2gRhfdNUPU6-SZhGq-AGTEW3FrcQpVWgF48w3OaAxZ7If3kYHuROVuqdWN1x5J3AJx43WVorfIsYsb2ulFJIJGjOfP4zR0P1KQ8cp1ajaHsGB1w5vfrvZrsfubTIh9Ju13vo4p1ry/s1600/image1.jpg\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgtmewLNKzKRZm7tPlPsm3AzC8g47bwqeo7EsJwCruRRi9s1gY2gRhfdNUPU6-SZhGq-AGTEW3FrcQpVWgF48w3OaAxZ7If3kYHuROVuqdWN1x5J3AJx43WVorfIsYsb2ulFJIJGjOfP4zR0P1KQ8cp1ajaHsGB1w5vfrvZrsfubTIh9Ju13vo4p1ry/s1600/image1.jpg\" /></a></div>  <p>However, productization paths for machine learning on DSPs can often be ad-hoc.\u00a0In contrast, speech, audio, and video codecs have\u00a0worldwide standards bodies such as ITU and 3GPP creating algorithms for compression and decompression addressing several aspects of quality measurement, fixed point arithmetic considerations and interoperability. </p><p>TensorFlow Lite Micro (TFLM) is a generic open-sourced inference framework that runs machine learning models on embedded targets, including DSPs.\u00a0Similarly, <a href=\"https://www.cadence.com/en_US/home.html\">Cadence</a> has invested heavily in PPA-optimized hardware-software platforms such as Cadence Tensilica HiFi DSP family for audio and Cadence Tensilica Vision DSP family for vision. </p><h3>Google and Cadence \u2013 A Multi-Year Partnership for Enabling AI at the Edge</h3>  <p>This was the genesis of the collaboration between the TFLM team and the Audio DSP teams at Cadence, starting in 2019.\u00a0The TFLM team is focusing on leveraging the broad TensorFlow framework and developing a smooth path from training to embedded and DSP deployment via an interpreter and reference kernels.\u00a0Cadence is developing a highly optimized software library, called NeuralNet library (NNLIB), that leverages the SIMD and VLIW capabilities of their low-power HiFi DSPs. This collaboration started with three optimized kernels for one Xtensa DSP, and now encompasses over 50 kernels across a variety of platforms such as HiFi 5, HiFi 4, HiFi 3z, Fusion F1 as well as Vision DSPs such as P6, and includes the ability to offload to an accelerator, if available. </p><p>Additionally, we have collaborated to add continuous integration for all the optimized code targeted for the Cadence DSPs. This includes infrastructure that tests that every pull request to the TFLM repository passes all the unit tests for the Tensilica toolchain with various HiFix and Vision P6 cores. As such, we ensure that the combined TFLM and NNLIB open source software is both tightly integrated and has good <a href=\"https://github.com/tensorflow/tflite-micro/actions/workflows/xtensa.yml?query=event%3Aschedule\">automated test coverage</a>. </p><h3>Performance Improvements</h3>  <p>Most recently, we have collaborated on adding optimizations for models that are <a href=\"https://www.tensorflow.org/lite/performance/post_training_integer_quant_16x8\">quantized with int16 activations</a>. Specifically in the domain of audio, int16 activations can be critical for the quality of quantized generative models. We expect that these optimized kernels will enable a new class of ML-powered audio signal processing.  The table below shows a few operators that are required for implementing a noise suppression neural net.  We show a 267x improvement in cycle count for a variant of <a href=\"https://arxiv.org/abs/2008.02027\">SEANet</a>, an example noise suppression neural net. </p><p>The following table shows the improvement with the optimized kernels relative to the reference implementations as measured with the Xtensa instruction set simulation tool. </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 11.5pt;\">    <table>        <tbody>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; background-color: rgb(67, 67, 67); padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #ffffff; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Operator</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; background-color: rgb(67, 67, 67); padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #ffffff; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Improvement</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Transpose Conv</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">458x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Conv2D</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">287x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Sub</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">39x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Add</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">24x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Leaky ReLU</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">18x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Srided_Slice</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">10x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Pad</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">6x</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; background-color: rgb(204, 204, 204); padding: 5pt; overflow: hidden; width: 49.74%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Overall Network</span></p>                </td>                <td style=\"border-width: 1pt; border-style: solid; border-color: rgb(0, 0, 0); vertical-align: top; background-color: rgb(204, 204, 204); padding: 5pt; overflow: hidden; width: 50.0849%;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">267x</span></p>                </td>            </tr>        </tbody>    </table></div> <h3>How to use these optimizations</h3>  <p>All of the code can be used from the <a href=\"https://github.com/tensorflow/tflite-micro\">TFLite Micro</a> GitHub repository. </p><p>To use HiFi 3z targeted TFLM optimizations, the following conditions need to be met: </p><ul> <li>the TensorFlow Lite (TFLite) flatbuffer model is quantized with int16 activations and int8 weights  <li>it uses one or more of the operators listed in the table above  <li>TFLM is compiled with <code>OPTIMIZED_KERNEL_DIR=xtensa</code></li></ul><p>For example, you can run Conv2D kernel integration tests with reference C++ code with: </p>   <pre><code class=\"\">make -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa TARGET_ARCH=hifi4 XTENSA_CORE= test_integration_tests_seanet_conv</code></pre>  <p>And compare that to the optimized kernels by adding <code>OPTIMIZED_KERNEL_DIR=xtensa</code>: </p>   <pre><code class=\"\">make -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa TARGET_ARCH=hifi4 OPTIMIZED_KERNEL_DIR=xtensa XTENSA_CORE= test_integration_tests_seanet_conv</code></pre>  <h3>Looking Ahead</h3>  <p>While the work thus far has been primarily focused on convolutional neural networks, Google and Cadence are also working together to develop an optimized LSTM operator and have released a <a href=\"https://github.com/tensorflow/tflite-micro/tree/1c6b50ef8b9dac1bb31dfe79679aec781666a86b/third_party/xtensa/examples/micro_speech_lstm\">first example</a> of an LSTM-based key-word recognizer. We expect to expand on this and continue to bring optimized and production-ready implementations of the latest developments in AI/ML to Tensilica Xtensa DSPs. </p><h3>Acknowledgements</h3>  <p>We would like to acknowledge a number of our colleagues who have contributed to making this collaboration successful. </p><p>Cadence: Int16 optimizations: Manjunath CP, Bhanu Prakash Venkata, Anirban Mandal LSTM implementation: Niranjan Yadla, Lukman Rahumathulla, Manjunath CP, Pramodkumar Surana, Arjun Medinakere NNLIB optimizations: Vijay Pawar, Prasad Nikam, Harshavardhan, Mayur Jagtap, Raj Pawate </p><p>Google: Advait Jain, Deqiang Chen, Lawrence Chan, Marco Tagliasacchi, Nat Jeffries, Nick Kreeger, Pete Warden, Rocky Rhodes, Ting Yan, Yunpeng Li, Victor Ungureanu </p>",
            "pubdate": "Thu, 24 Mar 2022 16:18:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                24
            ],
            "email_sent": true
        },
        "Intro mPOD DxTrack: A low-cost healthcare device using TensorFlow Lite Micro": {
            "url": "https://blog.tensorflow.org/2022/03/intro-mpod-dxtrack-low-cost-healthcare.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOzl4x5OR9H0hf81VYobIMLILeu81Y_BEP5KWbveG3Evh5ieqO2NioYqa4hRTgFGp-IymRrZ4ioBKDCj_vaz0j_oWdS_34OteYZSXbGro0WBB7mQDqKsdqkw9ELVL7HdApsm06Lf-JKRnLNNYOcebEH0XbRauiZWhYLago3T1zwaJeubDmkj1Fp7k3/s1600/image2.png\" style=\"display: none;\" />  <p><em>A guest post by <a href=\"https://www.linkedin.com/in/jeffreyly/\">Jeffrey Ly</a>, CEO &amp; <a href=\"https://www.linkedin.com/in/joannaashby\">Joanna Ashby</a>, CMO of mPOD, Inc.</em></p><p>mPOD is a NIH-funded pre-seed startup headquartered out of Johnson &amp; Johnson\u2019s Innovation (JLABS) in New York City. In this article, we\u2019d like to share with you a hardware device we have developed independently at mPOD leveraging TensorFlow Lite Micro (TFLM) as a core technology, called DxTrack.  </p><a name=\"more\"></a><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEim0Z2oe1rhtzURFByHCs2DPyzak4ogcVGGqw7EugzlBzgQl5TuUVM-mOEdYf2ifS4g8zdN0iUSO4VSRpRFeUBnUAI-dqmieMEQHoiAUhDgIHsN1Nl6Y5AMgaogDOqp_TW3pZevgSOg3ZaNPYDPtoMFk-u1gU98wFpOXAs9Nr87BLERUPD0yDbLWf8h/s1600/image8.gif\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEim0Z2oe1rhtzURFByHCs2DPyzak4ogcVGGqw7EugzlBzgQl5TuUVM-mOEdYf2ifS4g8zdN0iUSO4VSRpRFeUBnUAI-dqmieMEQHoiAUhDgIHsN1Nl6Y5AMgaogDOqp_TW3pZevgSOg3ZaNPYDPtoMFk-u1gU98wFpOXAs9Nr87BLERUPD0yDbLWf8h/s1600/image8.gif\" /></a></div>  <p>mPOD DxTrack leverages TFLM and low cost hardware to enable accurate, rapid and objective interpretation of currently available lateral flow assays (LFAs) in less than 10 seconds. LFAs serve as diagnostic tools because they are low-cost and simple to use without specialized skills or equipment. Most recently popularized by COVID-19 rapid antigen tests, LFAs are also used extensively testing for pregnancy, disease tracking, STDs, food intolerances, and therapeutic drugs along with an extensive array of biomarkers totaling billions of tests sold each year. The mPOD Dxtrack is applicable to use with any type of visually read lateral flow assay, demonstrating a healthcare use case for TFLM that can directly impact our everyday lives.  </p><p>The LFA begins with a sample (nasal swab,  saliva, urine, blood, etc) loaded at (1) in the figure below. Once the sample has flowed to the green conjugate zone (2), it is labeled with a signaling moiety. Through capillary action, the sample will continue flowing until it is immobilized at (3), with these LFA tests, two lines indicate a positive result, one line indicates a negative result.  </p>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhOzl4x5OR9H0hf81VYobIMLILeu81Y_BEP5KWbveG3Evh5ieqO2NioYqa4hRTgFGp-IymRrZ4ioBKDCj_vaz0j_oWdS_34OteYZSXbGro0WBB7mQDqKsdqkw9ELVL7HdApsm06Lf-JKRnLNNYOcebEH0XbRauiZWhYLago3T1zwaJeubDmkj1Fp7k3/s1600/image2.png\" style=\"width: 50%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 1. Side (A) &amp; Top (B) view of a lateral flow assay (LFA) sample where at (1) the sample (nasal swab,  saliva, urine, blood, etc) is loaded before flowing to the green zone (2), where the target is labeled with a signaling moiety. Through capillary action, the sample will continue flowing until it is immobilized at (3) to form the test line. Excess material is absorbed at (4).</td></tr>  </tbody></table>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjXj0FI77LgORp7QhzSI07oqN26vCBLQDPnJDd88IEY0Wp92rhluonloN5KkaSHT9EJmwbQdA_7_Or6FeAB9Z4wciBa0VxtBrdaSuIMZTJ08IOow85id8m-bRQI_zfNIMKDCRk5S40FmWVmkYnoCaanKmexvEbTsxWkHM6ChW5cHmoneYgEESvKyAok/s1600/image9.png\" style=\"width: 50%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 2. These are the 3 possible classes results for a lateral flow assay (LFA) test. </td></tr>  </tbody></table>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5BdMrQvgGHkPNqTtBaw4a3CUzPr23uReiYl0mUoV0Og4TSmRy7jhv8xmkZoknkvbRwjuxwZ5RrlbqoVBe8xAgXDLejTO6yczSIjDdTwuRqenlUCFUGi4I_mZV3zrPSulDmACckWn4sb30PyLyEinBO9Zrb1X3ZdlHmlJFq1C_CqM3x55_KV7CLx1K/s1600/image5.png\" style=\"width: 50%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 3. This is a diagram NOWDiagnostics ADEXUSDx lateral flow assay (LFA) designed to collect and run saliva sample in point-of-care (POC) and over-the-counter (OTC) settings.</td></tr>  </tbody></table> <p>When used correctly, these tests are very effective; however self-testing presents challenges for the lay user to interpret. Significant variability is present between devices, making it difficult to tell if the test line you see is negative \u2026or a faint positive? </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiW41dgw5CN-QxeG6F4a4KEeXPDEjCOt5dFo7Sr_LMvofWnmgbcH7h-HLu_fLyuOjZZoJqnISvKkLKm6eW31vzK_rk_oXx9dtHiuQCweRw8zHFTvPhrTuozm7jtV-grpx5aYSqBRn80HotRUBYCfoYCl-IkBwamFkCEMotPgcbupr589V3lufpRpEin/s1600/image1.gif\" style=\"width: 50%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 4. A visualization of how the TinyML model on the mPOD DxTrack break interprets and classifies different lateral flow assay (LFA) results.</td></tr>  </tbody></table> <p>To address this challenge, we developed mPOD DxTrack, an over-the-counter (OTC) LFA reader that improves the utility of lateral flow assays by enabling rapid and objective readings with a simple, under $5 (Cost-of-Goods) globally-deployable device. The mPOD DxTrack aims to read lateral flow assay  tests using ML to accomplish two goals: 1) enable rapid and objective readings of LFAs and 2) streamline digital reporting.  Critically, TinyML allows for the software on the mPOD DxTrack to be deployed on low-cost (less-than $5) hardware that can be widely distributed - which is difficult with existing LFA readers which rely on high-cost/high complexity hardware that cost hundreds to thousands of dollars per unit.  Ultimately, we believe that TinyML will enable the mPOD DxTrack to catch missed positive test results by removing human bias and increasing confidence in lateral flow device testing, reducing user error, and increasing overall result accuracy. </p>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiwdPvQ1s9GmXPqK0chIpdJ4DjRqTYM4jRf_dS8G19aDvRajapFKwt0oIREC-IWXM9mJhNZOtV5yxafLrRQjZFPrmhkDpWVHGY3cv0fh-8xuz5Dyq6YHA2LuXohoQeglfzbiVj9_u_kKhyBq11NSu4aO9vd-UvF4Ap0HaInsWa1DLayUCSTVLLm7-nO/s1600/image6.png\" style=\"width: 50%;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 5. Assembly view of the mPOD DxTrack with lateral flow assay (LFA) cassette.</td></tr>  </tbody></table>  <p>Technical Dive </p><p><span style=\"text-decoration: underline;\">Key Considerations</span></p><ul> <li>Achieving high accuracy 99% overall accuracy, (99% sensitivity, 99% specificity) for model performance when interpreting live-run LFA strips.  <li>Ensuring the model can maintain that level of performance while fitting the hardware constraints. </li></ul><p><strong><span style=\"text-decoration: underline;\">Model size constraints for TinyML</span></strong></p><p>Deployment of the DxTrack TinyML model on the Pico4ML Dev kit is constrained by 2 pieces of hardware: Flash memory and SRAM. The Pico4ML Dev kit has 2MB of flash memory to host the .uf2 file and 264kb of SRAM that accommodate the intermediate arrays (among other things) of the model. Ensuring the model size stays within these bounds is critical because while the code can successfully compile, run on the host machine and even successfully flash on the Pico4Ml Dev Kit, it will hang during set-up and not execute the main loop. </p><p>Rather than guess and check the size of intermediate arrays (a process we initially took with little reproducible success), we ended up developing a workflow that enabled us to quantify the model\u2019s arena size by first using the interpreter function. See below, where this function was called during setup: </p> <pre><code class=\"\">TfLiteStatus setup_status = ScreenInit(error_reporter);<br />if (setup_status != kTfLiteOk){<br />while(1){TF_LITE_REPORT_ERROR(error_reporter, \"Set up failed\\n\");};<br /> }<br />arena_size = interpreter->arena_used_bytes();<br />printf(\"Arena_Size Used: %zu \\n\", arena_size);</code></pre> <p>When printed out, this is what the value from the interpreter function should look during Pico4ML Dev kit boot-up:</p> <pre><code class=\"\">DEV_Module_Init OK                                                              <br />Arena_Size Used: 93500                                                         <br /> sd_spi_go_low_frequency: Actual frequency: 122070                               <br />V2-Version Card                                                                 <br />R3/R7: 0x1aa                                                                    <br />R3/R7: 0xff8000                                                                 <br />R3/R7: 0xc0ff8000                                                               <br />Card Initialized: High Capacity Card                                           <br />SD card initialized<br />SDHC/SDXC Card: hc_c_size: 15237                                                <br />Sectors: 15603712                                                               <br />Capacity: 7619 MB                                                           <br />sd_spi_go_high_frequency: Actual frequency: 12500000<br /></code></pre> <p>With this value available to us, we are then able to set the appropriate TensorArenaSize. As you can see from above, the model uses 93500 bytes of SRAM. By setting the TensorArenaSize to just above that amount 99x1024 = 101376 bytes, we are able to allocate enough memory to host the model without going over the hardware limits (which also causes the Pico4ML Dev Kit to freeze).</p> <pre><code class=\"\">// An area of memory to use for input, output, and intermediate arrays.<br />constexpr int  kTensorArenaSize =  99* 1024; // 136 * 1024; //81 * 1024;<br />static uint8_t tensor_arena[kTensorArenaSize];</code></pre>  <p><span style=\"text-decoration: underline;\">Transforming from Unquantized to Quantized Models</span></p><p>Now that we have a reproducible methodology to quantify and deploy the model onto the Pico4ML Dev Kit, our next challenge is ensuring that the model can achieve the accuracy we require while still fitting with the size constrained by the hardware. For reference, the mPOD DxTrack platform is designed to interpret a 96x96 image. In the original model design, we were able to achieve > 99.999% accuracy with our model, but  the intermediate layer is 96x96x32 at fp32 which requires over 1 MB of memory - it would never fit on the Pico4ML Dev Kit\u2019s 264KB of SRAM. In order to achieve the size requirement for the model, we needed to take the model from unquantized to quantized; our best option was to utilize full int8 quantization. In essence, instead of treating the tensor values as floating points (float32), we correlate those values to integers (int8). Unfortunately,  this decreased the model size 4-fold, allowing it to fit onto the Pico4ML Dev Kit's rounding error from fp32 to int8 compounded, resulting in dramatically reduced model performance.  </p>  <p><img alt=\"ALT TEXT\" height=\"300\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgUFYKQMeyius4mZLk8qm7rVEYDGnle51G1rOtdwFtmNaVOS2HdFwFl8jTt40bCzBAYHjYsXNPASjnYnZ3E_QHYWuh-mVcvzhpm5gQjfMMz40guMzPcH2AGpYu8R_RQEyEyHF0HZaH1-4kLVXvClukEID5xyKvVx1b04LewRCn1uwVQy8p0wWvhope3/s1600/image7.png\" style=\"float: right; margin-bottom: 0.3px; margin-right: 10px;\" width=\"300px\" /></p><p>To combat this drop in model performance, we examined the effect of two different quantization strategies to improve performance: Post-training quantization (PTQ) and Quantization-aware training (QAT).  </p><p>Below, we compare 3 different models to understand which quantization strategy is best. For reference:  </p><ul> <li>Model 1:  2-layer convolutional network  <li>Model 2:  3-layer convolutional network   <li>Model 3:  4-layer convolutional network </li></ul><p>As we can see, Quantization-aware training (QAT) uniformly beats the post-training quantization (PTQ) method and it became part of our workflow moving forward. </p><p><strong><span style=\"text-decoration: underline;\">What performance can we achieve now?</span></strong></p><p>Tested across over 800 real-world test runs, the mPOD DxTrack can preliminary achieve an overall accuracy of 98.7%. This version of the model is currently being evaluated by our network of manufacturing partners who we work closely with. Currently we are assembling a unique dataset of images as part of a patient-focused data pipeline to learn from each manufacturing partnership and building bespoke models. </p> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnlX3AOb4V8qMOt9UfNU-izH4eIh_XOtEbYOkk9YRh-TlZdlKBaJEwb36-zV9tM93UMJOUlWN6ib3QdtO1ndAvMiQTpIWp1PgrbKLsydmFeJ92bFVULkwXRpksuyJRQEoV2-NIm63dmCgug2MinW5Dx_4GjpOdrWa9MEOKSxLD-QI_JAJHOh2laoY-/s1600/image4.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgnlX3AOb4V8qMOt9UfNU-izH4eIh_XOtEbYOkk9YRh-TlZdlKBaJEwb36-zV9tM93UMJOUlWN6ib3QdtO1ndAvMiQTpIWp1PgrbKLsydmFeJ92bFVULkwXRpksuyJRQEoV2-NIm63dmCgug2MinW5Dx_4GjpOdrWa9MEOKSxLD-QI_JAJHOh2laoY-/s1600/image4.png\" /></a></div> <p>Our preliminary work has also helped us correlate model performance with appropriately large dataset size to achieve the performance high enough accuracy for our healthcare application. Per the figure attached, the model needs to be trained on a quality dataset of at least 15,000 images. Our commercial-ready target is likely to require datasets that are greater than 100,000 images.</p> <p><img alt=\"ALT TEXT\" height=\"300\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiHP5hy5z6OchM1Xs8QoXV_KWccZoff2z6HYraEQcoZ3OWxtOIjtm112_qIeH0uf4w7jw5QK0MiPaRh21Cfetp5OpO4TG2QXnZglPiXz6tn_5HZQHz23Z_AHrMRISvIw5bsRQUtDkVdDWK2oox8utNIKktzQ304hXNrN5pp9Faa-N8q9FiBXtm6Q4W6/s1600/image3.png\" style=\"float: right; margin-bottom: 0.3px; margin-right: 10px;\" width=\"300px\" /></p> <p>To learn more about mPOD Inc, please visit our website at <a href=\"http://www.mpod.io\">www.mpod.io</a>. If you\u2019re interested in learning more about TinyML, we recommend checking out this <a href=\"https://www.amazon.com/TinyML-Learning-TensorFlow-Ultra-Low-Power-Microcontrollers/dp/1492052043\">book</a> and this <a href=\"https://www.edx.org/professional-certificate/harvardx-tiny-machine-learning\">course</a>. </p>",
            "pubdate": "Mon, 28 Mar 2022 18:01:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                28
            ],
            "email_sent": true
        },
        "How LinkedIn Personalized Performance for Millions of Members using TensorFlow.js": {
            "url": "https://blog.tensorflow.org/2022/03/how-linkedin-personalized-performance.html",
            "description": "<p><em>A guest post by LinkedIn</em></p><p><a href=\"https://www.linkedin.com/in/markepascual/\">Mark Pascual</a>, Sr. Staff Engineer </p><p><a href=\"https://www.linkedin.com/in/nitinpasumarthy/\">Nitin Pasumarthy</a>, Staff Engineer </p><a name=\"more\"></a><h3>Introduction</h3>  <p>The Performance team at LinkedIn optimizes latency to load web and mobile pages. Faster sites improve customer engagement and eventually revenue to LinkedIn. This concept is <a href=\"https://wpostats.com/\">well documented by many other companies too</a> who have had similar experiences but how do you define the optimal trade off between page load times and engagement? </p><p>The relationship between speed and engagement is non-linear. Fast loading sites, after a point, may not increase engagement by further reducing their load times. At LinkedIn we have used this relationship between engagement and speed to selectively customize the features on <a href=\"https://engineering.linkedin.com/blog/2018/03/linkedin-lite--a-lightweight-mobile-web-experience\">LinkedIn Lite</a> - a lighter, faster version of LinkedIn, specifically built for mobile web browsers.  </p> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMAEQ2KGrdiRdXqw46tw3E2as7NaxLPfJK_mKjqMOwpn47Hz0hjvMUefZXvzV4KdtJ-ndPH_wDw8Y0v4gQ0Cgu3gnPo8MZL7MbK9-4p2G6ore_NT9U3e3dhsmisHWBdBFoSqrAK1PcpExiSFfy10jeeA7emPKBsmoIezLMNBIDyWFC2On5JuAtSaEw/s1600/image1.gif\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiMAEQ2KGrdiRdXqw46tw3E2as7NaxLPfJK_mKjqMOwpn47Hz0hjvMUefZXvzV4KdtJ-ndPH_wDw8Y0v4gQ0Cgu3gnPo8MZL7MbK9-4p2G6ore_NT9U3e3dhsmisHWBdBFoSqrAK1PcpExiSFfy10jeeA7emPKBsmoIezLMNBIDyWFC2On5JuAtSaEw/s1600/image1.gif\" /></a></div>  <p>To do this, we trained a deep neural network to identify if a request to LinkedIn would result in a fast page load in real time. Based on the performance quality result predicted by this model we change the resolution of all images on a given user\u2019s news feed before the resulting webpage was sent to the client. This led to an increase in the magnitude of billions for extra Feed Viral Actions (<strong>+0.23%</strong>) taken, millions more Engaged Feed Users (<strong>+0.16%</strong>) and Sponsored Revenue increased significantly for us too (<strong>+0.76%</strong>). </p>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg6ZVoFb8j7Iwy5AP_g_06WzvABGAxkh9pGj-KMlQdYljjwxKNnJVZsGsgCosn-kuAD2AcJgHdPrMWGQUdnvZ9zb6vjnTXtajv-3V5Ah5XD4bKVkXW5kK7-D1SOeb72gQkIHJEbUv5SHyolNGImBJRpGzLnCVWSguFO54VaM0cRtmmYDpM7FCvA9-bu/s1600/image2.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><strong><em>Image Quality Comparison:  Image on the left uses 4x more memory than the one on the right which is less than ideal to send to users on slow network connections or when the device may be low on resources. Prior to using an ML model, we only showed the low resolution image which was not great for users that had capacity for higher quality images on newer devices.</em></strong></td></tr></tbody></table>   <p>We described in great detail why many of our performance optimization experiments failed back in 2017 and how we used those learnings to build a Performance Quality Model (PQM) in our <a href=\"https://www.linkedin.com/pulse/personalizing-performance-adapting-application-real-time-pasumarthy\">Personalizing Performance: Adapting Application in real time to member environments</a> blog. <br /><br />PQM\u2019s bold goal is to predict various performance metrics (e.g. page load time) of any web / mobile page using both device and network characteristics of end users to empower (web) developers to build impactful application features that are otherwise tricky to implement (like the one we described above). <br /></p><p><center><em>We are happy to announce that we are open sourcing our first performance quality model  that is trained on millions of <a href=\"https://en.wikipedia.org/wiki/Real_user_monitoring\">RUM</a> data samples from around the world free to use for your own website performance optimizations! <a href=\"https://github.com/linkedin/performance-quality-models/tree/main/ssr-mobile-web/mweb-jan-2022-v1\">Learn more and get started here</a>.</em>  </center></p><p>In the rest of this blog, we will go over how our team of full stack developers deployed this PQM in production that works at Linkedin scale! We wish to prove that deploying TensorFlow.js ML models today is both easy and beneficial for those working on the Node.js stack. </p><h3>TensorFlow.js: Model Deployment in Node.js</h3>  <p>At the time of our production deployment, LinkedIn\u2019s TensorFlow model deployment machinery was still being developed. Furthermore, using TensorFlow Serving was not yet a feasible option for us. So even though we had a model ready for use, we needed to figure out a way to deploy it.  </p><p>As LinkedIn is primarily a Java/JVM stack for serving external traffic, it might seem like TensorFlow Java would be ideal, but it was still experimental and didn\u2019t have the API stability guarantees that we require. </p><p>We looked at our options and realized that we already use Node.js (behind the JVM) as part of our frontend web serving stack in order to perform server side optimizations when serving HTML pages. The architecture for this is unique in that we use the JVM to manage an external pool of Node.js processes to perform \u201cwork,\u201d e.g., the previously mentioned server side optimizations. The \u201cwork\u201d can really be anything that Node.js can perform. In our use case, this enables us to use TensorFlow.js in an architecture that was already proven. </p><p>We repurposed our frontend stack to use Node.js to deploy our custom model and ended up with great results. In terms of performance, our mixed stack of Java and Node.js easily met our SLAs. The 50th and 90th percentile production latencies as measured (a) from a client (within the datacenter), (b) from on host instrumentation, and (c) in terms of only Node.js performing inference using TensorFlow.js are shown in the table below. </p>  <div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border: none; border-collapse: collapse; width: 468pt;\">        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\"><br /></td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">50th Percentile</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">90th Percentile</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">From client (within datacenter)</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">10 ms</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">12 ms</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">On host</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">8 ms</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">10 ms</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Inference in Node.js</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">2 ms</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">3 ms</span></p>                </td>            </tr>        </tbody>    </table></div> <p>The resulting architecture is shown above in Figure 1 below.</p>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3ARPZvycGXHKTn7Cz3RjtGR0cOE1inKHoe-91xNOq8eONMkoi8gLg2yJkVgV7h-eIUtRBnp4ohPlvlvo5td3uElKQHTAgTUcFIgLyFM95VmQhYhrd5poAQCAEkR1Uuoq2mizh5li_qJkZGHS91B4VSYSNTqelazUsWmS_I6SWC6Wq-bv5Se9G7yyg/s1600/image4.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"></td></tr></tbody></table>   <p>The API request that requires a prediction is received by the JVM server and is routed to our <a href=\"https://linkedin.github.io/rest.li/\">Rest.li</a> infrastructure which in turn routes the request to our performance prediction resource. To handle the request, the PaaS resource performs some feature generation based on the inputs and then makes an RPC call out to the Node.js process for the prediction. </p><p>The N Node.js processes are long-lived. They are started upon JVM startup and have already loaded the desired model using <code>tf.node.loadSavedModel()</code>. When a process receives a request for a prediction, it simply takes the input features, calls <code>tf_model.predict()</code>, and returns the result. Here is a simplified version of the Node.js code: </p> <pre><code class=\"\">const tf = require(\u2018@tensorflow/tfjs-node\u2019);<br /><br />async function main() {<br />  // load the model when the process starts so it\u2019s always ready<br />  const model = await tf.node.loadSavedModel(\u2018model_dir\u2019);<br /><br />  function predict(rawInput) {<br />    return tf.tidy(() => {<br />      // prepare the inputs as tensor arrays<br />      const x = {}<br />      for (const feature of Object.keys(predictionInput)) {<br />        x[feature] = tf.tensor([input[feature]], [1, 1]);<br />      }<br /><br />      const output = model.predict(x, {});<br />      const probs = Array.from(output.probabilities.dataSync());<br />      const classes = Array.from(output.all_class_ids.dataSync());<br />      const result = Object.fromEntries(classes.map((classId, i) => [classId, probs[i]]));<br />      return result; // {0: 0.8, 1: 0.15, 2: 0.05} probability of each performance quality<br />    });<br />  }<br /><br />  // Register our \u2018predict\u2019 RPC handler (pseudo-code)<br />  // process is an abstraction of the Node.js side of the communication channel<br />  // with the JVM<br />  process.registerHandler(\u2018predict\u2019, input => {    <br />    const result = predict(input);<br />    return Promise.resolve(result);<br />  });<br />}<br /><br />main();<br /><br /></code></pre>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh_LSM44GUKmnol9a7PawWI7jtkqcrll8eeU35Ms0_wU0FZ913ecCHkyfBI1AHY9ZIqGoxIkIzp6NwumZSsKBmW3hlUPPbfy1cxFVZDCLhxavQ4FBMX970sLpzO5qmPZ7zvcHDiDAIM3GmPUT3ojcZE1HzU7g5BAkBEmJ8Idw6nga8bb-9r7LxztMiK/s1600/image3.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"></td></tr></tbody></table>  <p><a href=\"https://expressjs.com/\">Express</a> could replace Rest.li\u2019s role and the feature generation pieces would need to be ported to Node.js, but everything else remains the same. As you can see, the architecture is cleaner and requires less mental hoops to manage both Java and Node.js in the same stack. </p><h3>An Unexpected Win</h3>  <p>In the architecture we described above, the external processes do not have to be Node.js.  The library that we use to manage the external process is pretty straightforward to implement in most technologies. In fact, we could have chosen Python for the external processes as it\u2019s popular for this ML use case. So what are the reasons we stuck with Node.js? Well, there\u2019s two: (1) we already had a Node.js implementation for the external process infrastructure and would have had to develop a new one for Python, and (2) it turns out that Node.js is also slightly faster at making the predictions due to the pre/post processing benefitting from the JIT compiler of JavaScript. </p><p>In order to prove this to ourselves, we took samples (~100k) from our real world prediction inputs and ran them against both Node.js and Python. The test bed was not exactly our production stack (we didn\u2019t include the JVM side), but it was close enough for our purposes. The results are shown below: </p> <div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border: none; border-collapse: collapse; width: 468pt;\">        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Stack</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">50th percentile</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Delta (from Python)</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Python</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">1.872 ms</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">0%</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 11pt; font-family: 'Proxima Nova',sans-serif; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Node.js</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">1.713 ms</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">-8.47%</span></p>                </td>            </tr>        </tbody>    </table></div>  <p><br />The results show that Node.js is almost 10% faster at performing inference for our specific model. Of course, performance may vary based on model architectures and the amount of pre and post processing being performed in Node. These results were from our model running on a typical production machine. Results may also vary due to model complexity, machine differences, and so on. <br /></p><p><a href=\"https://github.com/linkedin/performance-quality-models\">Checkout our README in the open source repo</a> to find out how we tested the model in Python and Node.js. </p><h3>Looking to the future</h3>  <p>Our current unique architecture does have some areas for improvement.  Probably the biggest opportunity is to address the uniqueness of this multi stack architecture itself. The mix of both Java and Node.js technologies adds additional cognitive overhead and complexity during design, development, debugging, operations, maintenance - however as previously stated you could move the whole stack to Node to simplify matters, so this is a solvable problem. </p><p>Another potential area for improvement comes from currently using a single threaded architecture on the Node.js side. Because of this, only a single prediction currently occurs at a time so latency sometimes includes some amount of queueing time. This can potentially be worked around by using Node <a href=\"https://nodejs.org/api/worker_threads.html\">worker threads</a> for parallel execution that may be considered in future versions of this implementation. In our particular case, however, prediction is very fast even as it stands, so we do not feel the need to explore this right now.  </p><h3>Summary</h3>  <p>The availability of TensorFlow.js gave us an easy option to deploy our model to serve production use cases when other options were not quite suitable or available to us. While our unique requirements resulted in using non-standard architecture (the mixture of the JVM and Node.js), TensorFlow.js can be used to an even greater effect in a homogeneous Node.js serving stack resulting in a very clean and performant architecture. With our open source performance quality model, a full stack JS engineer can personalize performance and improve their user engagement and we look forward to seeing how others use our open sourced model to do just that on their own websites.<br /></p><h3>Acknowledgements</h3>  <p>This success would not be possible without the tremendous work by <a href=\"https://www.linkedin.com/in/pvijayanathan/\">Prasanna Vijayanathan</a> and <a href=\"https://www.linkedin.com/in/niranjan-sharma-4a235850/\">Niranjan Sharma</a>. A huge thank you to <a href=\"https://www.linkedin.com/in/ACoAAABvvfsBDUf12dGVDTAEKoH8Q-SmA9DgvI8/\">Ritesh Maheshwari</a> and <a href=\"https://www.linkedin.com/in/rahulkumar14/\">Rahul Kumar</a> for their support and encouragement. Special thanks to <a href=\"https://www.linkedin.com/in/pyu10055/\">Ping Yu</a> (Google) and <a href=\"https://www.linkedin.com/in/creativetech/\">Jason Mayes</a> (Google) for their continued support and feedback. </p>",
            "pubdate": "Tue, 29 Mar 2022 18:01:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                29
            ],
            "email_sent": true
        },
        "How to migrate from BoostedTrees Estimators to TensorFlow Decision Forests": {
            "url": "https://blog.tensorflow.org/2022/04/how-to-migrate-from-boostedtrees.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiW0Cq5zZzPAlNtIN1Fmb_Xxw-r_0c5_60QzOrJYVTJcvFxKjte2zA6kwQxgWbXOBKizFIWVneiaa2KnpP0cNdTWHxy5d3OApFMIO2WnojCRgrdnqVihqZW5DqztA3GkKuY-fv7Anwn8PpDfwPuCaNYjbaRwASdviQT2eei2jAf6xlF2xOEYohCaYEJ/s1600/image1.gif\" style=\"display: none;\" />  <p><em>Posted by <a href=\"https://twitter.com/mat_gb\">Mathieu Guillame-Bert</a> and <a href=\"https://twitter.com/random_forests\">Josh Gordon</a> for the TensorFlow team</em></p><a name=\"more\"></a><p>Decision forest models like <a href=\"https://developers.google.com/machine-learning/glossary#random-forest\">random forests</a> and <a href=\"https://developers.google.com/machine-learning/glossary#gradient-boosted-decision-trees-gbt\">gradient boosted trees</a> are often the most effective tools available for working with tabular data. They provide many advantages over neural networks, including being easier to configure, and faster to train. Using trees greatly reduces the amount of code required to prepare your dataset, as they natively handle numeric, categorical, and missing features. And they often give good results out-of-the-box, with interpretable properties.  </p><p>Although we usually think of TensorFlow as a library to train neural networks, a popular use case at Google is to use TensorFlow to create decision forests.  </p>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiW0Cq5zZzPAlNtIN1Fmb_Xxw-r_0c5_60QzOrJYVTJcvFxKjte2zA6kwQxgWbXOBKizFIWVneiaa2KnpP0cNdTWHxy5d3OApFMIO2WnojCRgrdnqVihqZW5DqztA3GkKuY-fv7Anwn8PpDfwPuCaNYjbaRwASdviQT2eei2jAf6xlF2xOEYohCaYEJ/s1600/image1.gif\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">An animation of a decision tree classifying data.</td></tr></tbody></table>   <p>This article provides a migration guide if you were previously creating tree-based models using <a href=\"https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier\">tf.estimator.BoostedTrees</a>, which was <a href=\"https://blog.tensorflow.org/2019/03/how-to-train-boosted-trees-models-in-tensorflow.html\">introduced</a> in 2019. The Estimator API took care of much of the complexity of working with models in production, including distributed training and serialization. However, it is no longer recommended for new code. </p><p>If you are starting a new project, we recommend that you use <a href=\"https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\">TensorFlow Decision Forests</a> (TF-DF). This library provides state-of-the-art algorithms for training, serving and interpreting decision forest models, with many benefits over the previous approach, notably regarding quality, speed, and ease of use.  </p><p>To start, here are equivalent examples using the Estimator API and TF-DF to create a boosted tree model. </p><p><strong>Previously, this is how you would train a gradient boosted tree models with tf.estimator.BoostedTrees (no longer recommended)</strong></p> <pre><code class=\"\"><br />import tensorflow as tf<br /><br /># Dataset generators<br />def make_dataset_fn(dataset_path):<br />    def make_dataset():<br />        data = ... # read dataset<br />        return tf.data.Dataset.from_tensor_slices(...data...).repeat(10).batch(64)<br />    return make_dataset<br /><br /># List the possible values for the feature \"f_2\".<br />f_2_dictionary = [\"NA\", \"red\", \"blue\", \"green\"]<br /><br /># The feature columns define the input features of the model.<br />feature_columns = [<br />    tf.feature_column.numeric_column(\"f_1\"),<br />    tf.feature_column.indicator_column(<br />       tf.feature_column.categorical_column_with_vocabulary_list(\"f_2\",<br />         f_2_dictionary,<br />         # A special value \"missing\" is used to represent missing values.<br />         default_value=0)<br />       ),<br />    ]<br /><br /># Configure the estimator<br />estimator = boosted_trees.BoostedTreesClassifier(<br />          n_trees=1000,<br />          feature_columns=feature_columns,<br />          n_classes=3,<br />          # Rule of thumb proposed in the BoostedTreesClassifier documentation.<br />          n_batches_per_layer=max(2, int(len(train_df) / 2 / FLAGS.batch_size)),<br />      )<br /><br /># Stop the training is the validation loss stop decreasing.<br />early_stopping_hook = early_stopping.stop_if_no_decrease_hook(<br />      estimator,<br />      metric_name=\"loss\",<br />      max_steps_without_decrease=100,<br />      min_steps=50)<br /><br />tf.estimator.train_and_evaluate(<br />      estimator,<br />      train_spec=tf.estimator.TrainSpec(<br />          make_dataset_fn(train_path),<br />          hooks=[<br />              # Early stopping needs a CheckpointSaverHook.<br />              tf.train.CheckpointSaverHook(<br />                  checkpoint_dir=input_config.raw.temp_dir, save_steps=500),<br />              early_stopping_hook,<br />          ]),<br />      eval_spec=tf.estimator.EvalSpec(make_dataset_fn(valid_path)))<br /></code></pre>   <p><strong>How to train the same model using TensorFlow Decision Forests</strong></p> <pre><code class=\"\"><br />import tensorflow_decision_forests as tfdf<br /><br /># Load the datasets<br /># This code is similar to the estimator.<br />def make_dataset(dataset_path):<br />    data = ... # read dataset<br />    return tf.data.Dataset.from_tensor_slices(...data...).batch(64)<br /><br />train_dataset = make_dataset(train_path)<br />valid_dataset = make_dataset(valid_path)<br /><br /># List the input features of the model.<br />features = [<br />  tfdf.keras.FeatureUsage(\"f_1\", keras.FeatureSemantic.NUMERICAL),<br />  tfdf.keras.FeatureUsage(\"f_2\", keras.FeatureSemantic.CATEGORICAL),<br />]<br /><br />model = tfdf.keras.GradientBoostedTreesModel(<br />  task = tfdf.keras.Task.CLASSIFICATION,<br />  num_trees=1000,<br />  features=features,<br />  exclude_non_specified_features=True)<br /><br />model.fit(train_dataset, valid_dataset)<br /><br /># Export the model to a SavedModel.<br />model.save(\"project/model\")<br /></code></pre>   <p><strong>Remarks</strong></p><ul> <li>While not explicit in this example, early stopping is automatically enabled and configured.  <li>The dictionary of the \"f_2\" features is automatically built and optimized (e.g. rare values are merged into an out-of-vocabulary item).  <li>The number of classes (3 in this example) is automatically determined from the dataset.  <li>The batch size (64 in this example), has no impact on the model training. Larger values are often preferable as it makes reading the dataset more efficient. </li></ul><p>TF-DF is all about ease of use, and the previous example can be further simplified and improved, as shown next. </p><p><strong>How to train a TensorFlow Decision Forests (recommended solution)</strong></p> <pre><code class=\"\">import tensorflow_decision_forests as tfdf<br />import pandas as pd<br /><br /># Pandas dataset can be used easily with pd_dataframe_to_tf_dataset.<br />train_df = pd.read_csv(\"project/train.csv\")<br /><br /># Convert the Pandas dataframe into a TensorFlow dataset.<br />train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_df, label=\"my_label\")<br /><br />model = tfdf.keras.GradientBoostedTreeModel(num_trees=1000)<br />model.fit(train_dataset)<br /></code></pre>  <p><strong>Remarks</strong></p><ul> <li>We did not specify the semantics (e.g. numerical, or categorical) of the features. In this case, the semantics will be automatically inferred.  <li>We also didn\u2019t list which input features to use. In this case, all the columns (except for the label) will be used. The list and semantics of the input feature is visible in the training logs, or with the model inspector API.  <li>We did not specify any validation dataset. Each algorithm will optionally extract a validation dataset from the training examples as best for the algorithm. For example, by default, GradientBoostedTreeModel uses 10% of the training data for validation if no validation dataset is provided. </li></ul><p>Now, let\u2019s look at a couple differences between the Estimator API and TF-DF. </p><h3>Differences between the Estimator API and TF-DF</h3>  <p><strong>Type of algorithms</strong></p><p>TF-DF is a collection of decision forest algorithms. This includes (but is not limited to) the Gradient Boosted Trees available with the Estimator API. Notably, TF-DF also supports <a href=\"https://www.tensorflow.org/decision_forests/api_docs/python/tfdf/keras/RandomForestModel\">Random Forest</a> (great for nosy datasets) and a <a href=\"https://g3doc.corp.google.com/third_party/tensorflow/google/g3doc/use_tensorflow/migration_decision_forests.md?cl=432890187#:~:text=nosy%20datasets)%20and%20a-,CART,-implementation%20(great%20for\">CART</a> implementation (great for model interpretation). </p><p>In addition, for each of those algorithms, TF-DF includes many variations found in the literature and validated experimentally [<a href=\"https://arxiv.org/abs/2009.09991\">1</a>, <a href=\"https://arxiv.org/abs/1603.02754\">2</a>, <a href=\"https://proceedings.neurips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf\">3</a>]. </p><p><strong>Exact vs approximate splits</strong></p><p>The TF1 GBT Estimator is an approximated tree learning algorithm. Informally, the Estimator <a href=\"http://ecmlpkdd2017.ijs.si/papers/paperID705.pdf\">builds</a> trees by only considering a random subset of examples and a random subset of the conditions at each step. </p><p>By default, TF-DF is an exact tree training algorithm. Informally, TF-DF considers all the training examples and all the possible splits at each step. This is a more common and often better performing solution. </p><p>While sometimes faster on larger datasets (>10B examples x features), the estimator approximation are often less accurate (as more trees need to be grown to reach the same quality). In a small dataset (&lt;100M examples x features), the form of approximated training implemented in the Estimator can even be slower than exact training. </p><p>TF-DF also supports various types of \"approximated\" tree training. The recommended approach is to use exact training, and optionally test approximated training on large datasets. </p><p><strong>Inference</strong></p><p>The Estimator runs model inference using the <a href=\"https://developers.google.com/machine-learning/decision-forests/decision-trees\">top-down tree routing algorithm</a>. TF-DF uses an extension of the <a href=\"http://ecmlpkdd2017.ijs.si/papers/paperID718.pdf\">QuickScorer</a> algorithm. </p><p>While both algorithms return the exact same results, the top-down algorithm is less efficient because of exceeding branching predictions and cache misses. TF-DF inference is generally 10x faster on the same model. </p><p>For latency critical applications TF-DF offers a <a href=\"https://g3doc.corp.google.com/third_party/tensorflow/google/g3doc/use_tensorflow/migration_decision_forests.md?cl=432890187#:~:text=TF%2DDF%20offers%20a-,C%2B%2B%20API,-.%20It%20provides%20often\">C++ API</a>. It provides often ~1\u00b5s/example/core inference time. This is often a 50x-1000x speed-up over TF SavedModel inference (especially on small batches). </p><p><strong>Multi-head models</strong></p><p>The Estimator supports multi-head models (a model that outputs multiple predictions). TF-DF (currently) does not support multi-head models directly, however, using the Keras Functional API, multiple TF-DF models trained in parallel can be assembled into a multi-head model. </p><h2>Learning more</h2>  <p>You can learn more about TensorFlow Decision Forests by visiting the <a href=\"https://www.tensorflow.org/decision_forests/\">website</a>. If you\u2019re new to this library, the <a href=\"https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\">beginner example</a> is a good place to start. Experienced TensorFlow users can visit this <a href=\"https://github.com/tensorflow/decision-forests/blob/main/documentation/migration.md\">guide</a> for important details about the difference between using decision forests and neural networks in TensorFlow, including how to configure your training pipeline, and tips on Dataset I/O. You can also see <a href=\"https://www.tensorflow.org/guide/migrate/migrating_estimator\">Migrate from Estimator to Keras APIs</a> for more info on migrating from Estimators to Keras in general.  </p>",
            "pubdate": "Mon, 04 Apr 2022 16:02:00 +0000",
            "pubdate_parsed": [
                2022,
                4,
                4
            ],
            "email_sent": true
        },
        "Video Classification on Edge Devices with TensorFlow Lite and MoViNet": {
            "url": "https://blog.tensorflow.org/2022/04/video-classification-on-edge-devices.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiZEUGTtz5pQ1Oz86fmupeAjEoXcDZ9Ar4I4F5YhL6aNJbyAbz-AIJl9LRb-mzQ4Yh80VgEUM1HFhQaLWHeArM39HlOAwuVxHQw4lczTLqP0sSVloprJTx-blhannqi5tnsJksAQv7PpRQqj5IwgUdoxcrMpDjBNiwUJ32ljMMSPl9djYefKqpmnhWF/s1600/image3.gif\" style=\"display: none;\" /> <p><em>Posted by <a href=\"https://twitter.com/hyperparticle\">Dan Kondratyuk</a>, <a href=\"https://scholar.google.com/citations?user=1H9CkZgAAAAJ&amp;hl=en\">Liangzhe Yuan</a>, Google Research and <a href=\"https://twitter.com/khanhlvg\">Khanh LeViet</a>, TensorFlow Developer Relations</em></p><a name=\"more\"></a> <p>We are excited to announce <a href=\"https://github.com/tensorflow/models/tree/master/official/projects/movinet\">MoViNets</a> (pronounced \u201cmovie nets\u201d), a family of new mobile-optimized model architectures for video classification. The models are trained on the <a href=\"https://deepmind.com/research/open-source/kinetics\">Kinetics-600 dataset</a> to be able to recognize <a href=\"https://github.com/tensorflow/models/blob/e0ed507504b4efa6780e244677ded563b36b0ee7/official/projects/movinet/files/kinetics_600_labels.txt\">600</a> different human actions (such as playing trumpet, robot dancing, bowling, and more) and can classify video streams captured on a modern smartphone in real time. You can download the pre-trained TensorFlow Lite models from <a href=\"https://tfhub.dev/s?deployment-format=lite&amp;q=movinet\">TensorFlow Hub</a> or try it out using our <a href=\"https://github.com/tensorflow/examples/tree/master/lite/examples/video_classification/raspberry_pi\">Android</a> and <a href=\"https://github.com/tensorflow/examples/tree/master/lite/examples/video_classification/raspberry_pi\">Raspberry Pi</a> demo apps, as well as fine-tune your own MoViNets with the <a href=\"https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb\">Colab demo</a> and the <a href=\"https://github.com/tensorflow/models/tree/master/official/projects/movinet\">code in the TensorFlow Model Garden</a>. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td><center><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiZEUGTtz5pQ1Oz86fmupeAjEoXcDZ9Ar4I4F5YhL6aNJbyAbz-AIJl9LRb-mzQ4Yh80VgEUM1HFhQaLWHeArM39HlOAwuVxHQw4lczTLqP0sSVloprJTx-blhannqi5tnsJksAQv7PpRQqj5IwgUdoxcrMpDjBNiwUJ32ljMMSPl9djYefKqpmnhWF/s1600/image3.gif\" style=\"width: 400px;\" /></center></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Demo from the TensorFlow Lite video classification reference app</td></tr></tbody></table> <p>Video classification is a machine learning task that takes video frames as input and predicts a single class from a larger set of classes. Video action recognition is a type of video classification where the set of predicted classes consists of human actions that happened in the frames. Video action recognition is similar to image recognition in that both take input images and output the probabilities of the images belonging to each of the predefined classes. However, a video action recognition model has to look at both the content of each frame and the spatial relationships between adjacent frames to understand the actions in the video. For example, if you look at these still images, it\u2019s difficult to tell what the person is doing. </p> <table width=\"99%\">  <tr>    <td><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiFmymdyfpjdWPYjs8kD-D_MV2WUZ3JCDWv9OHYFEuDW_jQNuGVjpJRAVP3EUoy_vYIcreeSuds0VAnxRi6XiU0fEDn0evaM2JyUtcKLDaNkit8YYMpTBgx71NEBwO0wM6vrsWFpb08Ea-31gUKSbazy4FTIe2pWs-Iw7jPxHa_HCsyxfoME4sfGem-/s1600/image1.jpg\" /></td>    <td> <p> <img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3pwXcRtZKm2p2rj-f4xQxZ3ZPP8_1Prp7lsvzvsrFLLRdTHQytxvxmS5UWF6RsN8qbKQik4zHu12ubEw8iE5wVPbfDf7P1ODkFd-hhUaf1kg0krVhzP1SlqJq1sFAcIh_pqy046KsdAMSZs2srGLPKQgo6tsrW-LR-86YOyXzNnUdK34I9SoltDTt/s1600/image2.jpg\" /></td>    <td align=\"right\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjp2vkqwPGn8Ge8eSM8ZYFOWde-e__ckXSdsnk9oQB98a1JyOLJiWAU_1Vv0NwXc7Z0baJXNSoz8WU-UqF_IKiWdgoXSLek-IoYg8HL057_nNhucvhC90Z4Qrqg_w-TjDLwoAkMnzXFI4NQP5Keh6kCgEdd0THMhiX4gpGclCZcQhLF7gEVBgjYpTzo/s1600/image8.jpg\" /></td></table> <p>But if you look at the full video, it becomes clear that the person is performing jumping jacks.</p> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhn0aKRhnGGZ0f7RafLO82vGefPVFDBbKT0oHXTL1esoaMFMUMnaiDW8Jt2aEXFK2rweNAeYVeKeu1failQaa99xOE0V1Uoj7XgmR_BFxXvsGaFR-lKXi06ZTxNdFhYBtSDUZbHVw7DaRXYC4dRL1lvu1rjXzZRjDs1WxevTXx_ay2SbmVULn5nykg0/s1600/image6.gif\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhn0aKRhnGGZ0f7RafLO82vGefPVFDBbKT0oHXTL1esoaMFMUMnaiDW8Jt2aEXFK2rweNAeYVeKeu1failQaa99xOE0V1Uoj7XgmR_BFxXvsGaFR-lKXi06ZTxNdFhYBtSDUZbHVw7DaRXYC4dRL1lvu1rjXzZRjDs1WxevTXx_ay2SbmVULn5nykg0/s1600/image6.gif\" /></a></div>  <h4>MoViNet Model Architecture</h4>  <p><strong>MoViNets</strong> are a family of convolutional neural networks which efficiently process video streams, outputting accurate predictions with a fraction of the latency of convolutional video classifiers like <a href=\"https://paperswithcode.com/model/resnet-3d?variant=resnet-3d-18\">3D ResNets</a> or transformer-based classifiers like <a href=\"https://arxiv.org/abs/2010.11929\">ViT</a>. </p><p>Frame-based classifiers output predictions on each 2D frame independently, resulting in sub-optimal performance due to their lack of temporal reasoning. On the other hand, 3D video classifiers offer high accuracy predictions by processing all frames in a video clip simultaneously, at a cost of significant memory and latency penalties as the number of input frames increases. MoViNets offer key advantages from both 2D frame-based classifiers and 3D video classifiers while mitigating their disadvantages.  </p><p>The following figure shows a typical approach to using 3D networks with multi-clip evaluation, where the predictions of multiple overlapping subclips are averaged together. Shorter subclips result in lower latency, but reduce the overall accuracy. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiZ73NcVJRnzVrcQs5DZpMho4F9Xg0SyoLCd6IgFWQ9iGxW3G_-fRGqY_O-wHPDrqjLW8oSAnOkM9ZynHIiWKYAwDNjOFekHzpvfuJ_0jZEm8adKNk0Z8eiC1KzvK0XXxO-xY8PK492OQ49FNUDoepuxUYe3CYGrGBSIovz3gGiIOiyS3SvDvAxnloc/s1600/image5.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Diagram illustrating Multi-Clip Evaluation for 3D Video Networks </td></tr></tbody></table>  <p>MoViNets take a hybrid approach, which proposes the use of <a href=\"https://paperswithcode.com/method/causal-convolution\">causal convolutions</a> in place of 3D convolutions, allowing intermediate activations to be cached across frames with a Stream Buffer. The Stream Buffer copies the input activations of all 3D operations, which is output by the model and then input back into the model on the next clip input. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQNM1sRHmOVQfExxkKVjiF81UcbtUpbw8phofsuuRa9x0Y5cvUks5qwODh6rbpHBq-0uQ-zsrOds7gBSfl0l65wulIjX9znqjzJbzAu2Zq5ROmgV2NKQEvkEF3_V3F_D2keZJ8yqJdxZws1Lr7NdlYRzRxtlyvAAMF3al0E7fac3cY6rvb6yzAl5rJ/s1600/image7.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Diagram illustrating Streaming Evaluation for MoViNets</td></tr></tbody></table>  <p>The result is that MoViNets can receive one frame input at a time, reducing peak memory usage while resulting in no loss of accuracy, with predictions equivalent to inputting all frames at once like a 3D video classifier. MoViNets additionally leverage <a href=\"https://paperswithcode.com/task/architecture-search\">Neural Architecture Search (NAS)</a> by searching for efficient configurations of models on video datasets (specifically Kinetics 600) across network width, depth, and resolution. </p><p>The result is a set of action classifiers that can output temporally-stable predictions that smoothly transition based on frame content. Below is an example plot of MoViNet-A2 making predictions on each frame on a video clip of skateboarding. Notice how the initial scene with a small amount of motion has relatively constant predictions, while the next scene with much larger motion causes a dramatic shift in predicted classes. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiX_uoXPIJrekwRHmlnPgVZSckNBwz5B1cBB-oeWPXIc-19jpLjyL9lRcL1ZETHtjdD15AkWR4PsOAyDUCsvJyQ_jBfMfQ3Y6aEX5rMn0mdmonRHKBpWG0QdZRIL3ZHOJrm2zDOK_c3hg5iZLElZUw2tn2yROi_ASL8oRwC3-B7pL_3MZW5nVALvJxJ/s1600/image4.gif\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A video plotting the top-5 predictions of MoViNet-A2 over time on an example 8-second (25 fps) skateboarding video clip. Create your own plots with <a href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/official/projects/movinet/tools/plot_movinet_video_stream_predictions.ipynb\">this Colab notebook</a>.</td></tr>    </tbody></table>   <p>MoViNets need a few modifications to be able to run effectively on edge devices. We start with <a href=\"https://tfhub.dev/tensorflow/movinet/a0/stream/kinetics-600/classification\">MoViNet-A0-Stream</a>, <a href=\"https://tfhub.dev/tensorflow/movinet/a1/stream/kinetics-600/classification\">MoViNet-A1-Stream</a>, and <a href=\"https://tfhub.dev/tensorflow/movinet/a2/stream/kinetics-600/classification\">MoViNet-A2-Stream</a>, which represent the smaller models that can feasibly run in real time (20 fps or higher). To effectively quantize MoViNet, we adapt a few modifications to the model architecture - the <a href=\"https://paperswithcode.com/method/hard-swish\">hard swish</a> activation is replaced by <a href=\"https://paperswithcode.com/method/relu6\">ReLU6</a>, and <a href=\"https://paperswithcode.com/method/squeeze-and-excitation-block\">Squeeze-and-Excitation</a> layers are removed in the original architectures, which results in 3-4 p.p accuracy drop on Kinetics-600. We then convert the models to <a href=\"https://www.tensorflow.org/lite\">TensorFlow Lite</a> and use <a href=\"https://www.tensorflow.org/lite/performance/post_training_quantization\">integer-based post-training quantization</a> (as well as <a href=\"https://www.tensorflow.org/lite/performance/post_training_float16_quant\">float16 quantization</a>) to reduce the model sizes and make them run faster on mobile CPUs. The integer-based post-training quantization process further introduces 2-3 p.p. accuracy loss. Compared to the original MoViNets, quantized MoViNets lag behind in accuracy on full 10-second Kinetics 600 clips (5-7 p.p. accuracy reduction in total), but in practice they are able to provide very accurate predictions on daily human actions, e.g., push ups, dancing, and playing piano. In the future, we plan to train with <a href=\"https://www.tensorflow.org/model_optimization/guide/quantization/training\">quantization-aware training</a> to bridge this accuracy gap.  </p>     <p>We benchmark quantized A0, A1, and A2 on real hardware and the model inference time achieves 200, 120, and 60 fps respectively on Pixel 4 CPU. In practice, due to the input pipeline overhead, we see increased latency closer to 20-60 fps when running on Android with a camera as input. </p>  <div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border: none; border-collapse: collapse;\">        <tbody>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Model</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Quantization</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Top-1 Accuracy (%)</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Latency&nbsp;</span><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\"><br /></span><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">(ms, Pixel 4 CPU)</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Model Size (MB)</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Recommended Input</span></p>                </td>            </tr>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">A0-Stream</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">int8</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">65.0</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">4.80</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">3.1</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">172 x 172, 5 fps</span></p>                </td>            </tr>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">A1-Stream</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">int8</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">70.1</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">8.35</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">4.5</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">172 x 172, 5 fps</span></p>                </td>            </tr>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">A2-Stream</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">int8</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">72.2</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">15.76</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">5.1</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">224 x 224, 5 fps</span></p>                </td>            </tr>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">A0-Stream</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">float16</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">71.5</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">17.47</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">7.6</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">172 x 172, 5 fps</span></p>                </td>            </tr>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">A1-Stream</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">float16</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">76.0</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">34.82</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">13</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">172 x 172, 5 fps</span></p>                </td>            </tr>            <tr style=\"height: 26.25pt;\">                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 14.3891%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">A2-Stream</span></p>                </td>                <td style=\"border-width: 0.75pt; border-style: solid; border-color: rgb(204, 204, 204); vertical-align: bottom; padding: 2pt; overflow: hidden; width: 9.8874%;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">float16</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">77.5</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">76.31</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">15</span></p>                </td>                <td style=\"border-left: solid #cccccc 0.75pt; border-right: solid #cccccc 0.75pt; border-bottom: solid #cccccc 0.75pt; border-top: solid #cccccc 0.75pt; vertical-align: bottom; padding: 2pt 2pt 2pt 2pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">224 x 224, 5 fps</span></p>                </td>            </tr>        </tbody>    </table></div>  <p><strong>Train a Custom Model</strong></p><p>You can train your own video classifier model using the <a href=\"https://github.com/tensorflow/models/tree/master/official/projects/movinet\">MoViNet codebase</a> in the TensorFlow Model Garden. The provided <a href=\"https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/movinet/movinet_tutorial.ipynb\">Colab notebook</a> provides specific steps on how to fine-tune a pretrained video classifier on another dataset. </p><p><strong>Future Steps</strong></p><p>We are excited to see on-device online video action recognition powered by MoViNets, which demonstrate highly efficient performance. In the future, we plan to support quantize-aware training for MoViNets to mitigate the quantization accuracy loss. We also are interested in extending MoViNets as the backbone for more on-device video tasks, e.g. video object detection, video object segmentation, visual tracking, pose estimation, and more. </p><p><strong>Acknowledgement</strong></p><p>We would like to extend a big thanks to Yeqing Li for supporting MoViNets in TensorFlow Model Garden, Boqing Gong, Huisheng Wang, and Ting Liu for project guidance, Lu Wang for code reviews, and the TensorFlow Hub team for hosting our models. </p>",
            "pubdate": "Thu, 14 Apr 2022 16:04:00 +0000",
            "pubdate_parsed": [
                2022,
                4,
                14
            ],
            "email_sent": true
        },
        "Why Karrot Uses TFX, and How to Improve Productivity on ML Pipeline Development": {
            "url": "https://blog.tensorflow.org/2022/05/why-karrot-uses-tfx.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhL6IR5tPygfQ1vGwPYF8w9W5TjhAGUwNULyl8-laV4IzLH9iOYx5B8xk70btanduPLdpp8Oox5PKj5lXHAnBZUNICsPQqS04cggdRn6TUmaM6lYlaEOgRl5bX4ZSkzLZcJvPX_fYyTdiKKSWJTxHNJcc6v4UPH6SPz2_VnxhV88E3dQZ55kRAVVuIn/s1600/karrot.jpeg\" style=\"display: none;\" /><i>Posted by Ukjae Jeong, Gyoung-yoon Yoo, and Myeonghyeon Song from Karrot</i><a name=\"more\"></a><p></p> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhL6IR5tPygfQ1vGwPYF8w9W5TjhAGUwNULyl8-laV4IzLH9iOYx5B8xk70btanduPLdpp8Oox5PKj5lXHAnBZUNICsPQqS04cggdRn6TUmaM6lYlaEOgRl5bX4ZSkzLZcJvPX_fYyTdiKKSWJTxHNJcc6v4UPH6SPz2_VnxhV88E3dQZ55kRAVVuIn/s1600/karrot.jpeg\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhL6IR5tPygfQ1vGwPYF8w9W5TjhAGUwNULyl8-laV4IzLH9iOYx5B8xk70btanduPLdpp8Oox5PKj5lXHAnBZUNICsPQqS04cggdRn6TUmaM6lYlaEOgRl5bX4ZSkzLZcJvPX_fYyTdiKKSWJTxHNJcc6v4UPH6SPz2_VnxhV88E3dQZ55kRAVVuIn/s1600/karrot.jpeg\" /></a></div><p><a href=\"https://us.karrotmarket.com\">Karrot</a> (the global service of <a href=\"https://www.daangn.com\">Danggeun Market</a> in Korea) is a local community service app that connects neighbors based on a secondhand marketplace. Danggeun Market was launched in 2015, and over 23 million people in Korea are using Danggeun Market in their local communities. Currently, Karrot is operated in 440 local communities in four countries: the U.K., the U.S., Canada, and Japan. In our service, scrolling through feeds to find inexpensive and useful items has become a daily pleasure for users. For better user experiences, we\u2019ve been applying several machine learning models such as recommendation models. </p><p>We are also working on ways to effectively and efficiently apply ML models. In particular, we\u2019re putting lots of effort into building machine learning pipelines for periodic deployment, rapid experiments, and continuous model improvement. </p><p>For the ML pipelines, we\u2019ve been using TFX (TensorFlow Extended) for production. So in this article, we will briefly introduce why we use TFX, and how we utilize TFX to improve productivity. </p><h4><strong>Machine Learning in Karrot</strong></h4>  <p>There are many ML projects inside Karrot. ML models are running inside the services. For example, we use automation models to detect fraud, and there are recommendation models to improve the user experience on our app feed. If you are interested in detailed descriptions of the models, please refer to <a href=\"https://medium.com/daangn\">our team blogs</a>, which are written in Korean. </p><p>As we\u2019ve been using Kubeflow for our ML models, we were able to periodically train, experiment, and deploy models but still, we had some pain points. As we started to use TFX with Kubeflow last year, TFX pushed this line further and let the team easily use our production pipelines. </p><h4><strong>How TFX helps us with production ML</strong></h4>   <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg4t-wkbET2oIO6sJtP8Ig5R59tJRn28hF9wcSuelwOIddtZYLuDEiP7kKZNHl_azrtxaNDnkAio97duVXNAhn-H0SNkGPlUHT2H739AZS1Jh3LdywZMBw2p5Y0E9I8cEpCC9g8Jh6r2OqBemoKSNp9MvjsWVZYQ4MCj5D6ACNrVR_JKAN95WZ-clD5/s1600/productionMLtfx.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">TFX helps build and deploy production ML pipelines easily with open and extendable design.</td></tr></tbody></table> <p>TFX, completely open-sourced in 2019, is an end-to-end platform for production ML pipelines. It supports writing ML workflows in component units, which then can be run in multiple environments - <a href=\"https://beam.apache.org\">Apache Beam</a>, <a href=\"https://cloud.google.com/dataflow\">Dataflow</a>, <a href=\"https://www.kubeflow.org\">Kubeflow</a>, and <a href=\"https://airflow.apache.org\">Airflow</a>. It also comes with well-written standard components for data ingestion/transformation, training, and deployment. </p><h5>Standard Components</h5>  <p>TFX provides several standard components. If you are looking for components for data ingestion, there are <a href=\"https://www.tensorflow.org/tfx/api_docs/python/tfx/v1/components/CsvExampleGen\">CsvExampleGen</a> based on local CSV files, <a href=\"https://github.com/tensorflow/tfx/tree/master/tfx/examples/custom_components/presto_example_gen/presto_component\">PrestoExampleGen</a>, and <a href=\"http://PrestoExampleGen\">BigQueryExampleGen</a> which can ingest data directly from Presto, BigQuery, and many other sources with some customization. So you can easily process data from multiple sources just by connecting pre-built components to your TFX pipelines. </p><p>It can also handle large-scale data processing smoothly. Since the <a href=\"https://www.tensorflow.org/tfx/api_docs/python/tfx/v1/components/Transform\">Transform</a> component that performs feature engineering is implemented on <a href=\"https://beam.apache.org\">Apache Beam</a>, you can execute it on GCP <a href=\"https://cloud.google.com/dataflow\">Dataflow</a> or another compute cluster in a distributed manner. </p><p>Of course, many other convenient components exist and are added constantly. </p><h5>Component Reusability</h5>  <p>In order to adapt TFX to our product, there is a need for custom components. TFX has a well-structured component design that enables us to create custom components naturally and easily connect them to existing TFX pipelines. A simple Python function or container can be transformed into a TFX component, or you can write the whole component in the exact same way as standard components are written. For more details, check out <a href=\"https://www.tensorflow.org/tfx/guide/understanding_custom_components\">the custom component guide</a>. </p><p>To enhance our productivity by delivering these advantages, we share custom components that have similar use cases among our ML pipelines as an internal library of Karrot Market. </p><h5>Various Runners are Supported</h5>  <p>TFX is compatible with a variety of environments. It can be run locally on your laptop or run on DataFlow, GCP\u2019s batch data processing service compatible with Apache Beam. You can visualize the output by manually running each component in a Jupyter Notebook. TFX also supports KubeFlow and Vertex AI, which have recently been released with new features as well. Therefore, the pipeline code is written once, and can then be run almost anywhere. We can simply create development, experiment, and deployment environments at once. For that reason, the burden of deploying models to production was significantly reduced by using TFX for our services. </p><h4><strong>Technical lessons</strong></h4>  <p>As we set up our ML pipelines with TFX, code qualities and our experiences in model development have increased. </p><p>However, there were difficulties. We didn't have a uniform project structure or best practices among our team. Maybe this is because TFX itself is relatively new and we've been using it before version 1. It became harder to understand codes and start to contribute. As the pipelines are becoming larger and more complex, it\u2019s getting harder to understand the meaning of custom components, corresponding config values, and dependencies. In addition, it was difficult to introduce some of the latest features to the team. </p><h4><strong>Improving the Development Experience</strong></h4>  <p>We decided to create and use a template for TFX pipelines to make it easier to understand each other's code, implement pipelines with the same pattern, and share know-how with each other. We merged components frequently used in Karrot and put them in a shared library so that ML pipelines can be developed very quickly. </p><p>It was expected that the template would accelerate the development of new projects. In addition, as mentioned above, we expected that each project would have a similar structure, making it easier to understand each other's projects. </p><p>So far, we have briefly introduced the template project. Here are some of our considerations to make better use of TFX in this project. </p><h5>Configuration first</h5>  <p>We prioritize our configuration first. It should be enough to understand how pipelines work by reading their configuration. If we can understand specific settings very easily, we can set up various experiments and proceed with them to AB testing. </p><p><code>example_gen_config.proto</code> written in Protocol Buffer(Protobuf), denotes the specification of config. <code>config.pbtxt</code> holds the values, and <code>pipeline.py</code> builds up the pipeline. </p>  <pre><code class=\"\">// config.pbtxt<br />example_gen_config {<br />    big_query_example_gen_config {<br />        query: \"# query for example gen\"<br />    }<br /><br /><br />    ...<br />}<br /><br />...<br /></code></pre>  <pre><code class=\"\">// example_gen_config.proto<br />message ExampleGenConfig {<br />    oneof config {<br />        BigQueryExampleGenConfig big_query_example_gen_config = 1;<br />        CsvExampleGenConfig csv_example_gen_config = 2;<br />    }<br /><br />    ...<br />}<br /><br />// When BigQueryExampleGen is used<br />message BigQueryExampleGenConfig {<br />    optional string query = 1;<br />}<br /><br />// When CsvExampleGenConfig is used<br />message CsvExampleGenConfig {<br />    optional string input_base = 1;<br />}<br /></code></pre>  <pre><code class=\"\"># pipeline.py<br />def create_pipeline(config):<br />   ...<br />   example_gen = _create_example_gen(config.example_gen_config)<br />   ...<br /><br /><br /><br /><br />def _create_example_gen(config: example_gen_config_pb2.ExampleGenConfig):<br />    ...<br /><br />    if config.HasField(\"big_query_example_gen_config\"):<br />        ...<br />        return ...<br /><br /><br />    if config.HasField(\"csv_example_gen_config\"):<br />        ...<br />        return ...<br /><br /><br />    raise ...<br /></code></pre> <p>All configurations of ExampleGen are determined by a single <code>ExampleGenConfig</code> message. Similarly, all pipeline components only depend on their configs and are created from them. This way, you can understand the structure of the pipeline just by looking at the configuration file. There is also the intention to make customization and code understanding easier by separating the part that defines each component. </p><p>For example, let's assume the following situation: In order to test the data transformation later, the Transform component needs to support various data processing methods. You might want to add a data augmentation process in the transform component. Then it should be done by adding a config related to the data augmentation function. Similarly, you can extend the predefined Protobuf specification to easily support multiple processing methods and make it easy to see which processing method to use. </p><h5>Managing Configs with Protobuf</h5>  <p>About the example code above, some people may wonder why they use Protobuf as a configuration tool. There are several reasons for this, and we will compare advantages with YAML, which is one of the common practices for configuration. </p><p>First, Protobuf has a robust interface, and validation such as type checking is convenient. There is no need to check whether any field is defined, as Protobuf defines the object structure in advance. In addition, it is useful to support backward/forward compatibility in a project under active development. </p><p>Also, you can easily check the pipeline structure. YAML has a hierarchical structure, but in the case of hydra, which is often used in the machine learning ecosystem, the stage (e.g. production, dev, alpha) settings are divided into several files, so we thought that Protobuf has better stability and visibility. </p><p>If you use Protobuf as your project setup tool, many of the Protobuf definitions defined in TFX can be reused. </p><h5>TensorFlow Ecosystem with Bazel</h5>  <p>Bazel is a language-independent build system that is easy to extend and supports a variety of languages and tools. From simple projects to large projects using multiple languages and tools, it can be used quickly and concisely in most situations. For more information, please refer to <a href=\"https://bazel.build/start/bazel-vision\">Bazel Vision</a> on the Bazel documentation page. </p><p>Using Bazel in a Python project is an uncommon setting, but we used Bazel as the project build system of the TFX template project. A brief introduction to the reason is as follows. </p><p>First of all, it works really well with Protobuf. Because Bazel is a language-independent build system, you can easily tie your Protobuf build artifacts as dependencies with other builds without worry. In addition, the Protocol Buffer repository itself uses Bazel, so it is easy to integrate it into the Bazel-based project. </p><p>The second reason is the special environment of the TensorFlow ecosystem. Many projects in the TensorFlow ecosystem use Bazel, and TFX also uses Bazel, so you can easily link builds with other projects (TensorFlow, TFX) using Bazel. </p><h5>Internal Custom TFX Modules</h5>  <p>As mentioned before, we\u2019ve been building an internal library for the custom TFX modules (especially the custom components) that are frequently used across multiple projects. Anyone in Karrot can add their components and share them with the team. </p><p>For example, we are using ArgoCD to manage applications(e.g. TF Serving) in Kubernetes clusters, so if someone develops a component for deploying with ArgoCD, we can easily share it via an internal library. The library now contains several custom modules for our team for productivity. </p><p>The reason why we can share our custom features as an internal shared library is probably thanks to the modular structure of TFX. Through this, we were able to improve the overall productivity of the team easily. We can reuse most of the components that were developed from several projects, and develop new projects very easily. </p><h4>Conclusion</h4>  <p>TFX provides lots of great features to develop production ML pipelines. We\u2019re using TFX on Kubeflow for ML pipelines to develop, experiment, and deploy in a better way, and it brings us many benefits. So we decided to introduce how we are using TFX in this blog post. </p><p>To learn more about Karrot, check out our website (<a href=\"https://www.daangn.com/\">Korea</a>, <a href=\"https://us.karrotmarket.com/\">US</a>, and <a href=\"https://ca.karrotmarket.com/\">Canada</a>). For the TFX, check out the <a href=\"https://www.tensorflow.org/tfx\">TFX documentation page</a>. </p>",
            "pubdate": "Fri, 06 May 2022 18:30:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                6
            ],
            "email_sent": true
        },
        "Portrait Depth API: Turning a Single Image into a 3D Photo with TensorFlow.js": {
            "url": "https://blog.tensorflow.org/2022/05/portrait-depth-api-turning-single-image.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEie8HBDNHcne_-2GHUqKFG0g2XmniU0vGySZRc3NPDEoqPqvK36cP-4vgvIawOJWNQzrLo90Xx7WAAOvY3V4HjFpXMGMcyWRvuI8e3JCzBEoyZv2P--8ldmF3_q3o2YgfjlCMZXOL_0YhWIOAKPCUTn4X3a5zkL9PMgctqPvGqJUohOFkjkmBMRbkiG/s1600/ezgif.com-gif-maker%20%2844%29.gif\" style=\"display: none;\" /> <p><em>Posted by <a href=\"https://www.duruofei.com\">Ruofei Du</a>, <a href=\"https://www.zhangyinda.com\">Yinda Zhang</a>, <a href=\"https://github.com/ahmedsabie\">Ahmed Sabie</a>, <a href=\"https://www.linkedin.com/in/creativetech\">Jason Mayes</a>, Google.</em><a name=\"more\"></a><p></p> <p>A <a href=\"https://en.wikipedia.org/wiki/Depth_map\">depth map</a> is essentially an image (or image channel) that contains information relating to the distance of the surfaces of objects in the scene from a given viewpoint (in this case, the camera itself) for every pixel in that image. Depth maps are a fundamental building block for a variety of computer graphics and computer vision applications, such as <a href=\"https://augmentedperception.github.io/depthlab/\">augmented reality</a>, <a href=\"https://ai.googleblog.com/2019/12/improvements-to-portrait-mode-on-google.html\">portrait mode</a>, and <a href=\"https://ai.googleblog.com/2020/02/learning-to-see-transparent-objects.html\">3D reconstruction</a>. Despite the recent advances in depth sensing capabilities with <a href=\"https://developers.google.com/ar/develop/depth\">ARCore Depth API</a>, the majority of photographs on the web are still missing  associated depth maps. This, combined with users from the web community expressing a growing interest in having depth capabilities within JavaScript to enhance existing web apps such as to bring images to live, apply real time AR effects to a human face and body, or even reconstruct items for use in VR environments, helped shape the path for what you see today. </p><p>Today we are introducing the <a href=\"https://github.com/tensorflow/tfjs-models/blob/master/depth-estimation/README.md\">Depth API</a>, the first depth estimation API from TensorFlow.js. With this new API, we are also introducing the first depth model for portrait, ARPortraitDepth, which estimates a depth map for a single portrait image. To demonstrate one of many possible usages of depth information, we also present a computational photography application, <strong><a href=\"https://storage.googleapis.com/tfjs-models/demos/3dphoto/index.html\">3D photo</a></strong>, which utilizes the predicted depth and enables a 3D parallax effect on the given portrait image. Try the live demo below, everyone can easily make their social media profile photo 3D as shown below. </p>  <p><strong><center><a href=\"https://storage.googleapis.com/tfjs-models/demos/3dphoto/index.html\">Try out the 3D portrait demo for yourself</a>!</center></strong></p>  <a href=\"https://storage.googleapis.com/tfjs-models/demos/3dphoto/index.html\"><img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEie8HBDNHcne_-2GHUqKFG0g2XmniU0vGySZRc3NPDEoqPqvK36cP-4vgvIawOJWNQzrLo90Xx7WAAOvY3V4HjFpXMGMcyWRvuI8e3JCzBEoyZv2P--8ldmF3_q3o2YgfjlCMZXOL_0YhWIOAKPCUTn4X3a5zkL9PMgctqPvGqJUohOFkjkmBMRbkiG/s1600/ezgif.com-gif-maker%20%2844%29.gif\" /></a> <h3>ARPortraitDepth: Single Image Depth Estimation</h3>  <p>At the core of the Portrait Depth API is a deep learning model, named ARPortraitDepth, that takes a single color portrait image as the input and produces a depth map. For the sake of computational efficiency, we adopt a light-weight U-Net architecture. As shown below, the encoder gradually downscales the image or feature map resolution by half, and the decoder increases the feature resolution to the same as the input. Deep learning features from the encoder are concatenated to the corresponding layers with the same spatial resolution in the decoders to bring high resolution signals for depth estimation. During training, we force the decoder to produce depth predictions with increasing resolutions at each layer, and add a loss for each of them with the ground truth. This empirically helps the decoder to predict accurate depth by gradually adding details. </p><p>Abundant and diverse training data is critical for the machine learning model to achieve overall decent performance, e.g. accuracy and robustness. We synthetically render pairs of color and depth images with various camera configurations, e.g. focal length, camera pose, from 3D digital humans captured by <a href=\"https://augmentedperception.github.io/therelightables/\">a high quality performance capture system</a>, and run <a href=\"https://augmentedperception.github.io/total_relighting/\">relighting augmentation</a> with High Dynamic Range environment illumination maps to increase the realism and diversity of the color images, e.g. shadows on the face. We also collect real data using mobile phones equipped with a front facing depth sensor, e.g. <a href=\"https://ai.googleblog.com/2020/04/udepth-real-time-3d-depth-sensing-on.html\">Google Pixel 4</a>, where the depth quality, as the training ground truth, is not as accurate and complete as that in our synthetic data, but the color images are effective in improving the performance of our model when running on images in the wild. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglwEQ44QOMuts9Z8dfnSFs6Ebs0VcDNrG4FOQq7mg5-jRsVrlhvNgVd624Uv6g1GlCaBfyxPhSm9ej7bubbooVvBw_WojUi2FlqAaUFrwTAscojrNXSBH__TZ5kAFEu3fcDMbvYOcIzGhm83mLPdWMVr1Tl9pFqPxsKu9ZiYpnUhs9tRYjSKmxg1vj/s1600/image5.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglwEQ44QOMuts9Z8dfnSFs6Ebs0VcDNrG4FOQq7mg5-jRsVrlhvNgVd624Uv6g1GlCaBfyxPhSm9ej7bubbooVvBw_WojUi2FlqAaUFrwTAscojrNXSBH__TZ5kAFEu3fcDMbvYOcIzGhm83mLPdWMVr1Tl9pFqPxsKu9ZiYpnUhs9tRYjSKmxg1vj/s1600/image5.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Single image depth estimation pipeline.</td></tr></tbody></table>   <p>To enhance the robustness against background variation, in practice, we run an off-the-shelf <a href=\"https://blog.tensorflow.org/2022/01/body-segmentation.html\">body segmentation model</a> with MediaPipe and TensorFlow.js before sending the image into the neural network of depth estimation. </p><p>The portrait depth model could enable a whole host of creative applications orientated around the human body that could drive next generation web apps. We refer readers to <a href=\"https://augmentedperception.github.io/depthlab/\">ARCore Depth Lab</a> for more inspirations.  </p><p>For the 3D photo application, we created a high-performance rendering pipeline. It first generates a segmented mask using the TensorFlow.js existing <a href=\"https://github.com/tensorflow/tfjs-models/tree/master/body-segmentation\">body segmentation API</a>. Next, we pass the masked portrait into the Portrait Depth API and obtain a depth map on the GPU. Eventually, we generate a depth mesh in <a href=\"https://threejs.org/\">three.js</a>, with vertices arranged in a regular grid and displaced by re-projecting corresponding depth values (see the figure below for generating the depth mesh). Finally, we apply texture projection to the depth mesh and rotate the camera around the z axis in a circle. Users can download the animations in GIF or WebM format.  </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEju3TSCS6xv5jRleKw6kGGwKZ9jgInpgr2T-M0CcvDor1x0JKuozsqD9mDew-dPADY17US8lzLXx0FEwdOTvkO6ADJM4va33KBZa5QGeTZPQ_nXPy3EEGn5xTdfwtBeX8O9sepuWuJ5f9iNAtI-crx3l7cmOV2zrRos-K28X-qbHOdNg69cdTQ2tM3L/s1600/image11.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEju3TSCS6xv5jRleKw6kGGwKZ9jgInpgr2T-M0CcvDor1x0JKuozsqD9mDew-dPADY17US8lzLXx0FEwdOTvkO6ADJM4va33KBZa5QGeTZPQ_nXPy3EEGn5xTdfwtBeX8O9sepuWuJ5f9iNAtI-crx3l7cmOV2zrRos-K28X-qbHOdNg69cdTQ2tM3L/s1600/image11.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Generating the depth mesh from the depth map for the 3D photo application.</td></tr></tbody></table> <h3>Portrait Depth API Installation</h3>  <p>The portrait depth API is currently offered as one variant of the new depth API. </p><p>To install the API and runtime library, you can either use the &lt;script> tag in your html file or use NPM.  </p><p>Through script tag: </p> <pre><code class=\"\">&lt;script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core\">&lt;/script><br />&lt;script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl\">&lt;/script><br />&lt;script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter\">&lt;/script><br />&lt;script src=\"https://cdn.jsdelivr.net/npm/@tensorflow-models/body-segmentation\">&lt;/script><br />&lt;script src=\"https://cdn.jsdelivr.net/npm/@tensorflow-models/depth-estimation\">&lt;/script></code></pre> <p>Through NPM: </p> <pre><code class=\"\">yarn add @tensorflow/tfjs-core @tensorflow/tfjs-backend-webgl<br />yarn add @tensorflow/tfjs-converter<br />yarn add @tensorflow-models/body-segmentation<br />yarn add @tensorflow-models/depth-estimation</code></pre>  <p>To reference the API in your JS code, it depends on how you installed the library. </p><p>If installed through script tag, you can reference the library through the global namespace <code>depthEstimation</code>. </p><p>If installed through NPM, you need to import the libraries first:<br /></p> <pre><code class=\"\">import '@tensorflow/tfjs-backend-core';<br />import '@tensorflow/tfjs-backend-webgl';<br />import '@tensorflow/tfjs-converter';<br />import '@tensorflow-models/body-segmentation;<br />import * as depthEstimation from '@tensorflow-models/depth-estimation;</code></pre>   <h3>Try it yourself!</h3>  <p>First, you need to create an estimator:<br /></p> <pre><code class=\"\">const model = depthEstimation.SupportedModels.ARPortraitDepth;<br />    estimator = await depthEstimation.createEstimator(model);<br /><br /><br />    const video = document.getElementById('video');<br />    const depthMap = await estimator.estimateDepth(video);</code></pre> <p>Once you have an estimator, you can pass in a video stream, static image, or TensorFlow.js tensors to estimate depth: </p> <pre><code class=\"\">const video = document.getElementById('video');<br /><br />    const estimationConfig = {<br />      minDepth: 0, // The minimum depth value outputted by the estimator.<br />      maxDepth: 1, // The maximum depth value outputted by the estimator.<br />    };<br /><br />   const depthMap = await estimator.estimateDepth(video, estimationConfig);</code></pre>  <p><strong>How to use the output?</strong></p><p>The <code>depthMap</code> result above contains depth values for each pixel in the image. </p><p>The <code>depthMap</code> is an object which stores the underlying depth values. You can then utilize the provided asynchronous conversion functions such as <code>toCanvasImageSource</code>, <code>toArray</code>, and <code>toTensor</code> depending on the desired output type that you want for efficiency.  </p><p>It should be noted that different models have different internal representations of data. Therefore converting from one form to another may be expensive. In the name of efficiency, you can call <code>getUnderlyingType</code> to determine what form the depth map is in already so you may choose to keep it in the same form for faster results. </p><p>The semantics of the depthMap are as follows: the depth map is the same size as the input image. For array and tensor representations, there is one depth value per pixel. For <code>CanvasImageSource</code>, the green and blue channels are always set to 0, whereas the red channel stores the depth value.<br /><br />See below output snippet for example: </p>  <pre><code class=\"\">  {<br />    toCanvasImageSource(): ...<br />    toArray(): ...<br />    toTensor(): ...<br />    getUnderlyingType(): ...<br />  }</code></pre>  <h3>Browser Performance</h3>  <p><strong>Portrait Depth model</strong></p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border: none; border-collapse: collapse;\">        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\"><br /></td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #202124; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">MacBook M1 Pro 2021.&nbsp;</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 9pt; font-family: Arial; color: #3c4043; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">(FPS)</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #202124; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">iPhone 13 Pro</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 9pt; font-family: Arial; color: #3c4043; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">(FPS)</span></p>                </td>                                 <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #202124; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Desktop PC&nbsp;</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 9pt; font-family: Arial; color: #3c4043; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">Intel i9-10900K. Nvidia GTX 1070 GPU.</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 9pt; font-family: Arial; color: #3c4043; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">(FPS)</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #000000; background-color: transparent; font-weight: 700; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">TFJS Runtime</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 9pt; font-family: Arial; color: #3c4043; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">With WebGL backend.</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #202124; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">51</span></p>                </td>                <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #202124; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">22</span></p>                                 <td style=\"border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-bottom: solid #000000 1pt; border-top: solid #000000 1pt; vertical-align: top; padding: 5pt 5pt 5pt 5pt; overflow: hidden;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; text-align: center; margin-top: 0pt; margin-bottom: 0pt;\"><span style=\"font-size: 10pt; font-family: Arial; color: #202124; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre; white-space: pre-wrap;\">47</span></p>                </td>            </tr>        </tbody>    </table></div><p><br /></p><h3>Acknowledgements</h3>  <p>We would like to acknowledge our colleagues who participated in or sponsored creating Portrait Depth API in TensorFlow.js: <a href=\"https://www.linkedin.com/in/na-li-02a39315\">Na Li</a>, <a href=\"https://www.linkedin.com/in/xiuxiuyuan/\">Xiuxiu Yuan</a>, <a href=\"https://research.google/people/106687/\">Rohit Pandey</a>, <a href=\"http://abhishekkar.info\">Abhishek Kar</a>, <a href=\"https://scholar.google.es/citations?user=dznX1DMAAAAJ&amp;hl=es\">Sergio Orts Escolano</a>, <a href=\"https://scholar.google.com/citations?user=5D0_pjcAAAAJ&amp;hl=en\">Christoph Rhemann</a>, <a href=\"https://www.linkedin.com/in/idrisaleem/\">Idris Aleem</a>, <a href=\"https://research.google/people/SeanFanello/\">Sean Fanello</a>, <a href=\"https://research.google/people/AdarshKowdle/\">Adarsh Kowdle</a>, <a href=\"https://www.linkedin.com/in/pyu10055\">Ping Yu</a>, <a href=\"https://www.olwal.com\">Alex Olwal</a>\u200e, <a href=\"https://www.linkedin.com/in/sarahheimlich/\">Sarah Heimlich</a>, <a href=\"https://www.linkedin.com/in/ceciliaabadie//\">Cecilia Abadie</a>. We would also like to acknowledge the <a href=\"https://blog.tensorflow.org/2022/01/body-segmentation.html\">body segmentation model</a> provided by MediaPipe, and <a href=\"https://augmentedperception.github.io/therelightables/\">The Relightables</a> for high quality synthetic data. </p>",
            "pubdate": "Tue, 10 May 2022 18:51:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                10
            ],
            "email_sent": true
        },
        "Using Machine Learning to Help Protect the Great Barrier Reef in Partnership with Australias CSIRO": {
            "url": "https://blog.tensorflow.org/2022/05/Kaggle-Great-Barrier-Reef-ML.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht3pf-aqNMrbwqRsqQ98eSfwAi-cpyPUTHKoYJgoeGMhB1uhw8Rt42TcbTkjhDF6v6f0fwiL6YfnMNp9ppOEBU6uw-Tt_PpP0akjV9vkZbNczEKo9XTxKQb0TLdtCX8UvMR-eVVKMdJKMvojlXv1Bv2nQsPohAl_-DpCfIv3FAJM_hWLLx1k9-RrhV/s1600/Screen%20Shot%202022-05-09%20at%201.06.30%20PM.png\" style=\"display: none;\" />  <p><em>Posted by Megha Malpani, Google Product Manager and Ard Oerlemans, Google Software Engineer</em><p> <a name=\"more\"></a><p></p> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht3pf-aqNMrbwqRsqQ98eSfwAi-cpyPUTHKoYJgoeGMhB1uhw8Rt42TcbTkjhDF6v6f0fwiL6YfnMNp9ppOEBU6uw-Tt_PpP0akjV9vkZbNczEKo9XTxKQb0TLdtCX8UvMR-eVVKMdJKMvojlXv1Bv2nQsPohAl_-DpCfIv3FAJM_hWLLx1k9-RrhV/s1600/Screen%20Shot%202022-05-09%20at%201.06.30%20PM.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht3pf-aqNMrbwqRsqQ98eSfwAi-cpyPUTHKoYJgoeGMhB1uhw8Rt42TcbTkjhDF6v6f0fwiL6YfnMNp9ppOEBU6uw-Tt_PpP0akjV9vkZbNczEKo9XTxKQb0TLdtCX8UvMR-eVVKMdJKMvojlXv1Bv2nQsPohAl_-DpCfIv3FAJM_hWLLx1k9-RrhV/s1600/Screen%20Shot%202022-05-09%20at%201.06.30%20PM.png\" /></a>    <p>Coral reefs are some of the most diverse and important ecosystems in the world, both for marine life and society more broadly. Not only are healthy reefs critical to fisheries and food security, they also protect coastlines from storm surge, support tourism-based economies, and advance drug discovery research, among other countless benefits. </p><p>Reefs face a number of rising threats, most notably climate change, pollution, and overfishing. In the past 30 years alone, there have been dramatic losses in coral cover and habitat in the Great Barrier Reef (GBR), with other reefs experiencing similar declines. In Australia, outbreaks of the coral-eating crown of thorns starfish (COTS) have been shown to cause major coral loss. While COTS naturally exist in the Indo-Pacific, reductions in the abundance of natural predators and excess run-off nutrients have led to massive outbreaks that are devastating already vulnerable coral communities. Controlling COTS populations is critical to promoting coral growth and resilience. </p><p>The <a href=\"https://www.barrierreef.org/\">Great Barrier Reef Foundation</a> established an <a href=\"https://www.barrierreef.org/what-we-do/reef-trust-partnership/crown-of-thorns-starfish-control\">innovation program</a> to develop new survey and intervention methods that radically improve COTS control. Google teamed up with <a href=\"https://www.csiro.au/en/about\">CSIRO</a>, Australia\u2019s national science agency, to develop innovative machine learning technology that can analyze video sequences accurately, efficiently, and in near real-time. The goal is to transform the underwater survey, monitoring and mapping reefs at scale to help rapidly identify and prioritize COTS outbreaks. This project is part of a broader partnership with CSIRO under Google\u2019s <a href=\"https://blog.google/intl/en-au/company-news/outreach-initiatives/digital-future-initiative/\">Digital Future Initiative</a> in Australia. </p><p>CSIRO developed an edge ML platform (built on top of the <a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-agx-xavier/\">NVIDIA Jetson AGX Xavier</a>) that can analyze underwater image sequences and map out detections in near real-time. Our goal was to use the annotated dataset CSIRO had built over multiple field trips to develop the most accurate object detection model (across a variety of environments, weather conditions, and COTS populations) within a set of performance constraints, most notably, processing more than 10 frames per second (FPS) on a &lt;30 watt device. </p><p>We hosted a <a href=\"https://www.kaggle.com/c/tensorflow-great-barrier-reef\">Kaggle competition</a>, leveraging insights from the open source community to drive our experimentation plan. With over 2,000 teams and 61,000 submissions, we were able to learn from the successes and failures of far more experiments than we could hope to execute on our own. We used these insights to define our experimentation roadmap and ended up running hundreds of experiments on Google TPUs. </p><p>We used TensorFlow 2\u2019s <a href=\"https://github.com/tensorflow/models/tree/master/official\">Model Garden library</a> as our foundation, making use of its <a href=\"https://github.com/tensorflow/models/tree/master/official/vision/beta/projects/yolo\">scaled YOLOv4</a> model and corresponding training pipeline implementations. Our team of modeling experts then got to work, modifying the pipeline, experimenting with different image resolutions and model sizes, and applying various data augmentation and quantization techniques to create the most accurate model within our performance constraints. </p><p>Due to the limited amount of annotated data, a key part of this problem was figuring out the most effective data augmentation techniques. We ran hundreds of experiments based on what we learned from the Kaggle submissions to determine which techniques in combination were most effective in increasing our model\u2019s accuracy. </p><p>In parallel with our modeling workstream, we experimented with batching, XLA, and auto mixed precision (which converts parts of the model to fp16) to try and improve our performance, all of which resulted in increasing our FPS by 3x. We found however, that on the Jetson module, using <a href=\"https://blog.tensorflow.org/2021/01/leveraging-tensorflow-tensorrt-integration.html\">TensorFlow-TensorRT </a>(converting the entire model to fp16) by itself actually resulted in a 4x total speed up, so we used TF-TRT exclusively moving forward. </p><p>After the starfish are detected in specific frames, a tracker is applied that links detections over time. This means that every detected starfish will be assigned a unique ID that it keeps as long as it stays visible in the video. We link detections in subsequent frames to each other by first using optical flow to predict where the starfish will be in the next frame, and then matching detections to predictions based on their Intersection over Union (IoU) score. </p><p>In a task like this where recall is more important than precision (i.e. we care more about not missing COTS than false positives), it is useful to consider the <a href=\"https://en.wikipedia.org/wiki/F-score#F%CE%B2\">F2 metric</a> to assess model accuracy. This metric can be used to evaluate a model's performance on individual frames. However, our ultimate goal was to determine the total number of COTS present in the video stream. Thus, we cared more about evaluating the entire pipeline\u2019s accuracy (model + tracker) than frame-by-frame performance (i.e. it\u2019s okay if the model has inaccurate predictions on a frame or two as long as the pipeline correctly identifies the starfish\u2019s overall existence and location). We ended up using a sequence-based F<sub>2</sub> metric that determines how many \u201ctracks\u201d are found at a certain average IoU threshold. </p><p>Our current 1080p model using TensorFlow TensorRT runs at 11 FPS on the Jetson AGX Xavier, reaching a sequence-based F<sub>2</sub> score of 0.80! We additionally trained a 720p model that runs at 22 FPS on the Jetson module, with a sequence-based F<sub>2</sub> score of 0.78. </p><p>Google & CSIRO are thrilled to announce that we are <strong>open-sourcing both COTS Object Detection models and have created a <a href=\"https://colab.sandbox.google.com/github/tensorflow/models/blob/master/official/projects/cots_detector/crown_of_thorns_starfish_detection_pipeline.ipynb\">Colab notebook</a> to demonstrate the server-side inference workflow</strong>. Our Colab tutorial allows students, marine researchers, or data scientists to evaluate our COTS ML models on image sequences with zero configuration/ML knowledge. Additionally, it provides a blueprint for implementing an optimized inference pipeline for edge ML platforms, such as the Jetson module. Please stay tuned as we plan to continue updating our models & trackers, ultimately open-sourcing a full TFX pipeline and dataset so that conservation organizations and other governments around the world can retrain and modify our model with their own datasets. Please reach out to us if you have a specific use case you\u2019d like to collaborate on! </p><p><strong>Acknowledgements</strong></p><p><em>A huge thank you to everyone who\u2019s hard work made this project possible!</em></p><p><em>We couldn\u2019t have done this without our partners at CSIRO \u2013 Brano Kusy, Jiajun Liu, Yang Li, Lachlan Tychsen-Smith, David Ahmedt-Aristizabal, Ross Marchant, Russ Babcock, Mick Haywood, Brendan Do, Jeremy Oorloff, Lars Andersson, and Joey Crosswell, the amazing Kaggle community, and last but not least, the team at Google \u2013 Glenn Cameron, Scott Riddle, Di Zhu, Abdullah Rashwan, Rebecca Borgo, Evan Rosen, Wolff Dobson, Tei Jeong, Addison Howard, Will Cukierski, Sohier Dane, Mark McDonald, Phil Culliton, Ryan Holbrook, Khanh LeViet, Mark Daoust, George Karpenkov, and Swati Singh.</em></p>",
            "pubdate": "Wed, 11 May 2022 20:19:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "On-device Text-to-Image Search with TensorFlow Lite Searcher Library": {
            "url": "https://blog.tensorflow.org/2022/05/on-device-text-to-image-search-with.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRKSVzRJ89LQ4GppKujCFnXR1F-8kmxpQwb7shUiaIPBPOvf3axOqEsZO54J4uzlYP0RVQ9VNlyeLMSIk8M_npJc70n7o0LqnfBQBzvxphU1vZmjwDCs47cpYMbd27Sh9VYKI9expP8lrpaxOJAmJrCgeRR5eQzTVxEcT5lfW1CMIKcEesUDJUGIuJ/s1600/image3.png\" style=\"display: none;\" />  <p><em>Posted by Zonglin Li, Lu Wang, Maxime Br\u00e9non, and Yuqi Li, Software Engineers</em></p><a name=\"more\"></a><p></p>  <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjw4uZh_Pvl7hamimWYoFo2moCBXww7L_J7wdunVVxNDj3dFpGU4u2klFvFfRPnvfe-jYIRUQup8bBSt0ZjWp5wRYc6YHMd3eLebmBWqscNeW4KsINcLH1XJhLLvOikkz_26_qwHjGqZhps3DnvaXyHfvwRT20XTqXIHiIetXoCpweZjcnVX6DE0yY7/s1600/Copy%20of%20I_O22_BlogBanners_RB_v09.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjw4uZh_Pvl7hamimWYoFo2moCBXww7L_J7wdunVVxNDj3dFpGU4u2klFvFfRPnvfe-jYIRUQup8bBSt0ZjWp5wRYc6YHMd3eLebmBWqscNeW4KsINcLH1XJhLLvOikkz_26_qwHjGqZhps3DnvaXyHfvwRT20XTqXIHiIetXoCpweZjcnVX6DE0yY7/s1600/Copy%20of%20I_O22_BlogBanners_RB_v09.png\" /></a></div>   <p>Today, we're excited to announce a new on-device embedding-based search library that allows you to quickly find similar images, text or audio from millions of data samples in a few milliseconds.  </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaTXZDmasMaRs-z9tIu6R9a7zddIdDLv1IxyOI2OiAzgH0o6wHQVmRAJZfTdirnWYUbRE-5_G-rGk7SDXuFE4NnLuWgJco-tXvcZS39GI0Nk0hhSp-x3fH4V1B61alL8F9n8RV937GcLTGphNbwni8L_4tuWjeg5zriN1rPhox3O9XhvwVYpUuTiqe/s1600/image4.gif\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaTXZDmasMaRs-z9tIu6R9a7zddIdDLv1IxyOI2OiAzgH0o6wHQVmRAJZfTdirnWYUbRE-5_G-rGk7SDXuFE4NnLuWgJco-tXvcZS39GI0Nk0hhSp-x3fH4V1B61alL8F9n8RV937GcLTGphNbwni8L_4tuWjeg5zriN1rPhox3O9XhvwVYpUuTiqe/s1600/image4.gif\" /></a></div><p>It works by using a model to embed the search query into a high-dimensional vector representing the semantic meaning of the query. Then it uses <a href=\"https://github.com/google-research/google-research/tree/master/scann\">ScaNN</a> (Scalable Nearest Neighbors) to search for similar items from a predefined database. In order to apply it to your dataset, you need to use Model Maker Searcher API (<a href=\"https://www.tensorflow.org/lite/tutorials/model_maker_text_searcher\">tutorial</a><a href=\"https://www.tensorflow.org/lite/tutorials/model_maker_text_searcher\"></a>) to build a custom TFLite Searcher model, and then deploy it onto devices using Task Library Searcher API (<a href=\"https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_searcher\">vision</a>/<a href=\"https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher\">text</a>). </p><p>For example, with the Searcher model trained on <a href=\"https://cocodataset.org/#home\">COCO</a>, searching the query, <code>A passenger plane on the runway</code>, will return the following images: </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhooOxW8DRyg0f6TLCFjJJs1L1gWy7ic9vhDJSAomVaZQdxE_3-xlKsMcWi2b2bVwilK2ivmJPK7w3Q2jMwJvuRahVoO5WYlA9X4X0H111dReGI4Z7ckHel-Oux2bu--dfHw1-yKXcUzjl1h_TZxR2nbKH_csjQHfZtqUzxm4Ogc4aPP65NcaaNWCDa/s1600/image2.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhooOxW8DRyg0f6TLCFjJJs1L1gWy7ic9vhDJSAomVaZQdxE_3-xlKsMcWi2b2bVwilK2ivmJPK7w3Q2jMwJvuRahVoO5WYlA9X4X0H111dReGI4Z7ckHel-Oux2bu--dfHw1-yKXcUzjl1h_TZxR2nbKH_csjQHfZtqUzxm4Ogc4aPP65NcaaNWCDa/s1600/image2.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 1: All images are from COCO 2014 train and validation datasets. <a href=\"https://www.flickr.com/photos/multiplyleadership/6832329918/\">Image 1</a> by Mark Jones Jr. under <a href=\"http://creativecommons.org/licenses/by/2.0/\">Attribution License</a>. <a href=\"https://www.flickr.com/photos/bluehillranch/8613487675/\">Image 2</a> by 305 Seahill under <a href=\"http://creativecommons.org/licenses/by-nd/2.0/\">Attribution-NoDerivs License</a>. <a href=\"https://www.flickr.com/photos/25451699@N04/5942171839/\">Image 3</a> by tataquax under <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Attribution-ShareAlike License</a>. </td></tr></tbody></table><p>In this post, we will walk you through an end-to-end example of building a text-to-image search feature (retrieve the images given textual queries) using the new TensorFlow Lite Searcher Library. Here are the major steps: </p><ol> <li>Train a dual encoder model for image and text query encoding using the <a href=\"https://cocodataset.org/#home\">COCO</a> dataset.  <li>Create a text-to-image Searcher model using the Model Maker Searcher API.  <li>Retrieve images with text queries using the Task Library Searcher API.  </li></ol><h3>Train a Dual Encoder Model</h3> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRKSVzRJ89LQ4GppKujCFnXR1F-8kmxpQwb7shUiaIPBPOvf3axOqEsZO54J4uzlYP0RVQ9VNlyeLMSIk8M_npJc70n7o0LqnfBQBzvxphU1vZmjwDCs47cpYMbd27Sh9VYKI9expP8lrpaxOJAmJrCgeRR5eQzTVxEcT5lfW1CMIKcEesUDJUGIuJ/s1600/image3.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRKSVzRJ89LQ4GppKujCFnXR1F-8kmxpQwb7shUiaIPBPOvf3axOqEsZO54J4uzlYP0RVQ9VNlyeLMSIk8M_npJc70n7o0LqnfBQBzvxphU1vZmjwDCs47cpYMbd27Sh9VYKI9expP8lrpaxOJAmJrCgeRR5eQzTVxEcT5lfW1CMIKcEesUDJUGIuJ/s1600/image3.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 2: Train the dual encoder model with dot product similarity distance. The loss encourages related images and text to have larger dot products (the shaded green squares).</td></tr></tbody></table> <!-----  Yay, no errors, warnings, or alerts!  Conversion time: 0.579 seconds.   Using this HTML file:  1. Paste this output into your source file. 2. See the notes and action items below regarding this conversion run. 3. Check the rendered output (headings, lists, code blocks, tables) for proper    formatting and use a linkchecker before you publish this page.  Conversion notes:  * Docs to Markdown version 1.0\u03b233 * Tue May 10 2022 12:44:24 GMT-0700 (PDT) * Source doc: TensorFlow blog-On-device Text-to-Image Search with TensorFlow Lite Searcher Library * This is a partial selection. Check to make sure intra-doc links work. ----->  <p>The dual encoder model consists of an image encoder and a text encoder. The two encoders map the images and text, respectively, to embeddings in a high-dimensional space. The model computes the dot product between the image and text embeddings, and the loss encourages relevant image and text to have larger dot product (closer), and unrelated ones to have smaller dot product (farther apart).  </p><p>The training procedure is inspired by the <a href=\"https://arxiv.org/abs/2103.00020\">CLIP</a> paper and this <a href=\"https://keras.io/examples/nlp/nl_image_search/\">Keras example</a>. The image encoder is based on a pre-trained <a href=\"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/feature_vector/2\">EfficientNet</a> model and the text encoder is based on a pre-trained <a href=\"https://tfhub.dev/google/universal-sentence-encoder-lite/2\">Universal Sentence Encoder</a> model. The outputs from both encoders are then projected to a 128 dimensional space and are L2 normalized. For the dataset, we chose to use <a href=\"https://cocodataset.org/#home\">COCO</a>, as its train and validation splits have human generated captions for each image. Please take a look at the companion <a href=\"https://colab.sandbox.google.com/github/tensorflow/tflite-support/blob/master/tensorflow_lite_support/examples/colab/on_device_text_to_image_search_tflite.ipynb\">Colab notebook</a> for the details of the training process. </p><p>The dual encoder model makes it possible to retrieve images from a database without captions because once trained, the image embedder can directly extract the semantic meaning from the image without any need for human-generated captions. </p><h3>Create the text-to-image Searcher model using Model Maker</h3>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhImt-tBGiK8Z1W_JOAsuu3qlnDHrfko5bQ38e-njB3TAjxXk2lBtw_t2xxNMMrNt0BCu7uBarZtuMg0eCwNFkn7CoWEaKsUfl9f94b1EAICHmz2vXfMCDFhKpzK8tzsTv-KhS0l7AR3hC1RLQB4Fg5w2LAv0qYTrO7ea18j8Bnb0RhNItKqOK3oR8r/s1600/image1.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhImt-tBGiK8Z1W_JOAsuu3qlnDHrfko5bQ38e-njB3TAjxXk2lBtw_t2xxNMMrNt0BCu7uBarZtuMg0eCwNFkn7CoWEaKsUfl9f94b1EAICHmz2vXfMCDFhKpzK8tzsTv-KhS0l7AR3hC1RLQB4Fg5w2LAv0qYTrO7ea18j8Bnb0RhNItKqOK3oR8r/s1600/image1.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 3: Generate image embeddings using the image encoder and use Model Maker to create the TFLite Searcher model.</td></tr></tbody></table>  <p>Once the dual encoder model is trained, we can use it to create the TFLite Searcher model that searches for the most relevant images from an image dataset based on the text queries. This can be done by the following three steps: </p><ol> <li>Generate the embeddings of the image dataset using the TensorFlow image encoder. ScaNN is capable of searching through a very large dataset, hence we combined the train and validation splits of  COCO 2014 totaling 123K+ images to demonstrate its capabilities. See the code <a href=\"https://colab.sandbox.google.com/github/tensorflow/tflite-support/blob/master/tensorflow_lite_support/examples/colab/on_device_text_to_image_search_tflite.ipynb#scrollTo=Bp0qBKkyu4jA\">here</a>.  <li>Convert the TensorFlow text encoder model into TFLite format. See the code <a href=\"https://colab.research.google.com/github/tensorflow/tflite-support/blob/master/tensorflow_lite_support/examples/colab/on_device_text_to_image_search_tflite.ipynb#scrollTo=6Dzye66Xc8vE\">here</a>.  <li>Use <a href=\"https://www.tensorflow.org/lite/tutorials/model_maker_text_searcher\">Model Maker</a> to create the TFLite Searcher model from the TFLite text encoder and the image embeddings using the code below:</ol> <pre><code class=\"\"><br />#Configure ScaNN options. See the <a href=\"https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/searcher/ScaNNOptions\" target=\"_blank\">API doc</a> for how to configure ScaNN. <br />scann_options = searcher.ScaNNOptions(<br />      distance_measure='dot_product',<br />      tree=searcher.Tree(num_leaves=351, num_leaves_to_search=4),<br />      score_ah=searcher.ScoreAH(1, anisotropic_quantization_threshold=0.2))<br /><br /># Load the image embeddings and corresponding metadata if any.<br />data = searcher.DataLoader(tflite_embedder_path, image_embeddings, metadata)<br /><br /># Create the TFLite Searcher model.<br />model = searcher.Searcher.create_from_data(data, scann_options)<br /><br /># Export the TFLite Searcher model.<br />model.export(<br />      export_filename='searcher.tflite',<br />      userinfo='',<br />      export_format=searcher.ExportFormat.TFLITE)<br />     </code></pre>  <center><p id=\"imgCaption\"><a href=\"https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/searcher/ScaNNOptions\">API doc can be found here.</a></p></center> <p>When creating the Searcher model, Model Maker leverages ScaNN to index the embedding vectors. The embedding dataset is first partitioned into multiple subsets. In each of the subsets, ScaNN stores the quantized representation of the embedding vectors. At retrieval time, ScaNN selects a few most relevant partitions and scores the quantized representations with fast, approximate distances. This procedure saves both the model size (through quantization) and achieves speed up (through partition selection). See the <a href=\"https://ai.googleblog.com/2020/07/announcing-scann-efficient-vector.html\">in-depth examination</a> to learn more about the ScaNN algorithm. </p><p>In the above example, we divide the dataset into 351 partitions (roughly the square root of the number of embeddings we have), and search 4 of them during retrieval, which is roughly 1% of the dataset. We also quantize the 128 dimensional float embeddings to 128 int8 values to save space.  </p><h3>Run inference using Task Library</h3>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjhRfPCu6QCkMxXTJVV0Y7A2kWaHpImHFEuPIEHZTwgsxJ27JYvcI7ThzNCqLiVBB9u2P67F00FvGzdZzHvBBv0UO9PSyj4BmsUCjXjYAO4PSOUogKR4WNgBfLudNppCbNrnQgSWh6a3v-lWrFHiFUYBSmYd2A2LE9e9jNqsvk67XMvsicgOeJwYIcz/s1600/image1.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjhRfPCu6QCkMxXTJVV0Y7A2kWaHpImHFEuPIEHZTwgsxJ27JYvcI7ThzNCqLiVBB9u2P67F00FvGzdZzHvBBv0UO9PSyj4BmsUCjXjYAO4PSOUogKR4WNgBfLudNppCbNrnQgSWh6a3v-lWrFHiFUYBSmYd2A2LE9e9jNqsvk67XMvsicgOeJwYIcz/s1600/image1.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 4: Run inference using Task Library with the TFLite Searcher model. It takes the query text and returns the top neighbor\u2019s metadata. From there we can find the corresponding images.</td></tr></tbody></table>   <p>To query images using the Searcher model, you only need a couple of lines of code like the following using <a href=\"https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher\">Task Library</a>: </p> <pre><code class=\"\">from tflite_support.task import text<br /><br /># Initialize a TextSearcher object<br />searcher = text.TextSearcher.create_from_file('searcher.tflite')<br /><br /># Search the input query<br />results = searcher.search(query_text)<br /><br /># Show the results<br />for rank in range(len(results.nearest_neighbors)):<br />  print('Rank #', rank, ':')<br />  image_id = results.nearest_neighbors[rank].metadata<br />  print('image_id: ', image_id)<br />  print('distance: ', results.nearest_neighbors[rank].distance)<br />  show_image_by_id(image_id)</code></pre>  <p>Try the code from the <a href=\"https://colab.sandbox.google.com/github/tensorflow/tflite-support/blob/master/tensorflow_lite_support/examples/colab/on_device_text_to_image_search_tflite.ipynb\">Colab</a>. Also, see <a href=\"https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher\">more information</a> on how to integrate the model using the Task Library Java and C++ API, especially on Android. Each query in general takes only 6 milliseconds on Pixel 6.  </p><p>Here are some example results: </p><p>Query: <code>A man riding a bike</code></p><p>Results are ranked according to the approximate similarity distance. Here is a sample of retrieved images. Note that we are only showing images if their licenses allow. </p> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdVewBVwxQOAORYm4Jvd0W6g2lLEtvFbLs-qwCctuYT1KKOKYeZwbDhL08E7Kz2YPdIl4Ts6zmo0hqr8L6zatbdnMThSLesESxv6AnfFP_-gmHU6covHOSdOFHKhmP6KNRmadEt1yGS-LCWJH6MWIyu3v8MPwWqCdymNkmzFIgs_BbIJSG7y6tdrOH/s1600/image6.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjdVewBVwxQOAORYm4Jvd0W6g2lLEtvFbLs-qwCctuYT1KKOKYeZwbDhL08E7Kz2YPdIl4Ts6zmo0hqr8L6zatbdnMThSLesESxv6AnfFP_-gmHU6covHOSdOFHKhmP6KNRmadEt1yGS-LCWJH6MWIyu3v8MPwWqCdymNkmzFIgs_BbIJSG7y6tdrOH/s1600/image6.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Figure 5: All images are from COCO 2014 train and validation datasets. <a href=\"https://www.flickr.com/photos/kamalayan/4945223078/\">Image 1</a> by Reuel Mark Delez under <a href=\"http://creativecommons.org/licenses/by/2.0/\">Attribution License</a>. <a href=\"https://www.flickr.com/photos/bike/300626852/\">Image 2</a> by Richard Masoner / Cyclelicious under <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Attribution-ShareAlike License</a>. <a href=\"https://www.flickr.com/photos/jula_julz/3599983065/\">Image 3</a> by Julia under <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Attribution-ShareAlike License</a>. <a href=\"https://www.flickr.com/photos/roebot/3322126404/\">Image 4</a> by Aaron Fulkerson under <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Attribution-ShareAlike License</a>. <a href=\"https://www.flickr.com/photos/bike/2927188293/\">Image 5</a> by Richard Masoner / Cyclelicious under <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Attribution-ShareAlike License</a>. <a href=\"https://www.flickr.com/photos/bike/3018725318/\">Image 6</a> by Richard Masoner / Cyclelicious under <a href=\"http://creativecommons.org/licenses/by-sa/2.0/\">Attribution-ShareAlike License</a>. </td></tr></tbody></table> <h3>Future work</h3>  <p>We\u2019ll be working on enabling more search types beyond image and text, such as audio clips. </p><p>Contact odml-pipelines-team@google.com if you want to leave any feedback. Our goal is to make on-device ML even easier for you and we value your input! </p>  <h3>Acknowledgements</h3>  <p><em>We would like to thank Khanh LeViet, Chuo-Ling Chang, Ruiqi Guo, Lawrence Chan, Laurence Moroney, Yu-Cheng Ling, Matthias Grundmann, as well as Robby Neale, Chung-Ching Chang\u200e, Tom Small and Khalid Salama for their active support of this work. We would also like to thank the entire ScaNN team: David Simcha, Erik Lindgren, Felix Chern, Phil Sun and Sanjiv Kumar. </em></p>",
            "pubdate": "Wed, 11 May 2022 17:44:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "AI and Machine Learning @ I/O Recap": {
            "url": "https://blog.tensorflow.org/2022/05/ai-and-machine-learning-io-recap.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPVjGNKa1ihfr9scYARP3XU6-ZaDpyLfXU-drCOWhp_EwNqtywdPEl36uMxZdJHl7DcuK2njFEq3NZ4WEV13yK86S1OKsbkUzLr0D8WMeW1Rqf5Od1QQv7ehJXYNjFQ_wTNUU197M14C2cazmYACz3PA_h8Ir3vFMp-C67OzAPqz3S-JNRFm3COR2n/s1600/recapml.jpeg\" style=\"display: none;\" /> <p><em>Posted by TensorFlow Team</em><a name=\"more\"></a><p></p>  <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5QgVznRcilVS55FVhwRrp3-NPi-PWOorlfhPzIm439ioiu-adRlL83c8HpqffiDu3uIwYp0FUBl0C55uCemSnxIchSyCQpObDiElEoruuCTTslG3xn2V0xqrXYq7hTQDbgteDLcTBy_y8nRUhtuoBQhPTBpAdxW2crFq4XbzPCWT3JHfo3PZtPGBS/s1600/Copy%20of%20Copy%20of%20I_O22_BlogBanners_RB_v09.png\" style=\"display: block; padding: 1em 0; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5QgVznRcilVS55FVhwRrp3-NPi-PWOorlfhPzIm439ioiu-adRlL83c8HpqffiDu3uIwYp0FUBl0C55uCemSnxIchSyCQpObDiElEoruuCTTslG3xn2V0xqrXYq7hTQDbgteDLcTBy_y8nRUhtuoBQhPTBpAdxW2crFq4XbzPCWT3JHfo3PZtPGBS/s1600/Copy%20of%20Copy%20of%20I_O22_BlogBanners_RB_v09.png\" /></a></div> <p>Google I/O 2022 was a major milestone in the evolution of AI and Machine Learning for developers. We\u2019re really excited about the potential for developers using our technologies and Machine Learning to build intelligent solutions, and we believe that 2022 is the year when AI and ML become part of every developer\u2019s toolbox. </p><p>At the I/O keynotes we showed our fully open source ecosystem that takes you from end to end with Machine Learning. There are developer tools for managing data, training your models, and deploying them to a variety of surfaces from global scale cloud all the way down to tiny microcontrollers\u2026and of course ways to monitor and maintain your systems with MLOps. All of this comes with a common set of accelerated hardware for training and inference, along with open source tooling for responsible AI end-to-end. </p><p>You can get a tour through this ecosystem in the Keynote \u201cAI and Machine Learning updates for Developers\u201d </p> <center></center>   <p><h2><strong>Responsible AI review processes: From a developer\u2019s point of view<br /></strong></h2></p><p>We can all agree that responsible and ethical AI is important, but when you want to <em>build</em> responsibly, you need tooling. We could, and will, create a whole video series about these tools, but the great content to watch right now is the talk on the Responsible AI review process. Googlers who worked on projects like the Covid-19 public forecasts or the Celebrity Recognition APIs will take you step-by-step through their thought process and how the tools lined up to help them build more responsibly and thoughtfully. You\u2019ll also learn about some of the new releases in Responsible AI tools, such as the <a href=\"https://tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview\">Counterfactual Logit Pairing library</a>.   </p>   <p>   <center></center></p> <p><h2><strong>Adding machine learning to your developer toolbox<br /></strong></h2></p><p>If you\u2019re just getting started on your journey and you want ML to be a part of your toolbox, you probably have a million questions. Follow a developer's journey through the best offerings, from a turnkey API that can solve basic problems fast, to custom models that can be tuned and deployed.    </p> <p>  <center></center></p> <p><h2><strong>TensorFlow.js: From prototype to production, what's new in 2022?</strong></h2></p><p>If you\u2019re a web developer there\u2019s a whole bunch of new updates, from the announcement of a new set of courses that will take you from first principles through a deep dive of what\u2019s possible to lots of new models available to web devs. These include a selfie depth estimation model that can be used for cool things like a 3D effect in your pictures without needing any kind of extra sensor. You\u2019ll also see 3D pose estimation that allows you to run at a high FPS to get real time results, allowing you to do things like having a full animated character following your body motion. All in the browser!  </p> <p>  <center></center></p> <p><h2><strong>Deploy a custom ML model to mobile</strong></h2></p><p>If you want to build better mobile apps with AI and Machine Learning, you probably need to understand the ins and outs of getting models to execute on Android or iOS devices, including shrinking them and optimizing them to be power friendly.  Supercharge your model with new releases from the TensorFlow Lite team that let you quantize, debug, and accelerate your model on CPU or delegated GPUs, and a whole lot more.  </p> <p>  <center></center></p> <p><h2><strong>Further on the edge with Coral Dev Board Micro</strong></h2></p><p>Speaking of acceleration, this year at I/O we introduced the Coral Dev Board Micro. This is a new microcontroller class device with an on-board Edge TPU that\u2019s powerful enough to run multiple models in tandem. The Coral team has also updated their catalog of pre-trained models, now including over 40 models now available for you to use on embedded systems out of the box! </p> <p><center></center></p> <p><h2><strong>Tips and tricks for distributed large model training</strong></h2></p><p>On the other side of the spectrum, if you want to train large models, you\u2019ll need to understand how to shard training and data across multiple processors or cores. We\u2019ve released lots of new guidance and updates for model and data parallelism. You can learn all about them in this talk, including lessons learned from Google researchers in building language models. </p> <p>  <center></center></p> <p><h2><strong>Easier data preprocessing with Keras</strong></h2></p><p>Of course, not all data is big data, and if you\u2019re not building giant models, you still need to be able to manage your data. Often this is where devs will write the most code for ML, so we want to highlight some ways of making this easier, in particular with Keras. Keras's new preprocessing layers that not only make vectorization and augmentation much easier, but also allow for precomputation to make your training more efficient by reducing idle time. Learn about data preprocessing from the creator of Keras! </p> <p>  <center></center></p> <p><h2><strong>An introduction to MLOps with TFX</strong></h2></p><p>Finally, let\u2019s not forget MLOps and TFX, the open source, end-to-end pipeline management tool. Check out the talk from Robert Crowe who will help you understand everything, from why you need MLOps to managing your process through managing change. You\u2019ll see the component model in TFX, and get an introduction to the new TFX-Addons community that\u2019s focussed on building new ones. Check it all out in this talk!! </p> <p>  <center></center></p> <p>I/O wasn\u2019t just about new releases and talks! If you are inspired by any of what you saw, we also have workshops and learning paths you can dig into to learn in more detail.  </p> <p>  <center></center></p> <p>  <center></center></p> <p>  <center></center></p> <p>  <center></center></p> <p><a href=\"https://www.youtube.com/playlist?list=PLQY2H8rRoyvyY0AsvPIkb7rg7ogc5dgXW\">Full playlist</a> to all AI/ML talks and workshops. </p><p>That\u2019s it for this roundup of AI and ML at Google I/O 2022. We hope you\u2019ve enjoyed it, and we\u2019d love to hear your feedback when you explore the content.  Please drop by the <a href=\"https://discuss.tensorflow.org/\">TensorFlow Forum</a> and let us know what you think! </p>",
            "pubdate": "Thu, 12 May 2022 16:16:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                12
            ],
            "email_sent": true
        },
        "TensorFlow Lite for education and makers": {
            "url": "https://blog.tensorflow.org/2022/05/tensorflow-lite-for-education-and-makers.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqEDXa1_eLG5p2UEpcB9lncW024b695qrPeQyjNx15n_rnSQ68lV4VOPTWZKDm6S6l1OcXIcxkAp_-MQc906pOCYd8kvAaHLQF_0TrRIOGKG-MHRMKalvZWqmWFiWASghlbFQNOgjYQ1DbBwkw8echZ7u4Pre844E-ASgSIbr1UV5oQg4kM2DPsFvb/s1600/image1.jpg\" style=\"display: none;\" /> <p><em>Posted by Scott Main, AIY Projects and Coral</em></p><p> <a name=\"more\"></a><p></p> Back in 2017, we began AIY Projects to make do-it-yourself artificial intelligence projects accessible to anybody. Our first project was the <a href=\"https://aiyprojects.withgoogle.com/voice/\">AIY Voice Kit</a>, which allows you to build your own intelligent device that responds to voice commands. Then we released the <a href=\"https://aiyprojects.withgoogle.com/vision\">AIY Vision Kit</a>, which can recognize objects seen by its camera using on-device TensorFlow models. We were amazed by the projects people built with these kits and thrilled to see educational programs use them to introduce young engineers to the possibilities of computer science and machine learning (ML). So I'm excited to continue our mission to bring machine learning to everyone with the more powerful and more customizable AIY Maker Kit. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqEDXa1_eLG5p2UEpcB9lncW024b695qrPeQyjNx15n_rnSQ68lV4VOPTWZKDm6S6l1OcXIcxkAp_-MQc906pOCYd8kvAaHLQF_0TrRIOGKG-MHRMKalvZWqmWFiWASghlbFQNOgjYQ1DbBwkw8echZ7u4Pre844E-ASgSIbr1UV5oQg4kM2DPsFvb/s1600/image1.jpg\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqEDXa1_eLG5p2UEpcB9lncW024b695qrPeQyjNx15n_rnSQ68lV4VOPTWZKDm6S6l1OcXIcxkAp_-MQc906pOCYd8kvAaHLQF_0TrRIOGKG-MHRMKalvZWqmWFiWASghlbFQNOgjYQ1DbBwkw8echZ7u4Pre844E-ASgSIbr1UV5oQg4kM2DPsFvb/s1600/image1.jpg\" /></a> <p><strong>Making ML accessible to all</strong></p><p>The Voice Kit and Vision Kit are a lot of fun to put together and they include great programs that demonstrate the possibilities of ML on a small device. However, they don't provide the tools or procedures to help beginners achieve their own ML project ideas. When we released those kits in 2017, it was actually quite difficult to train an ML model, and getting a model to run on a device like a Raspberry Pi was even more challenging. Nowadays, if you have some experience with ML and know where to look for help, it's not so surprising that you can train an object detection model in your web browser in less than an hour, or that you can run a pose detection model on a battery-powered device. But if you don't have any experience, it can be difficult to discover the latest ML tools, let alone get started with them. </p><p>We intend to solve that with the Maker Kit. With this kit, we're not offering any new hardware or ML tools; we're offering a simplified workflow and a series of tutorials that use the latest tools to train TensorFlow Lite models and execute them on small devices. So it's all existing technology, but better packaged so beginners can stop searching and start building incredible things right away. </p><p><strong>Simplified tools for success</strong></p><p>The material we've collected and created for the Maker Kit offers an end-to-end experience that's ideal for educational programs and users who just want to make something with ML as fast as possible. </p><p>The hardware setup requires a Raspberry Pi, a Pi Camera, a USB microphone, and a <a href=\"https://coral.ai/products/accelerator\">Coral USB Accelerator</a> so you can execute advanced vision models at high speed on the Coral Edge TPU. If you want your hardware in a case, we offer two DIY options: a 3D-printed case design or a cardboard case you can build using materials at home. </p><p>Once it's booted up with our Maker Kit system image, just run some of our code examples and follow our coding tutorials. You'll quickly discover how easy it is to accomplish amazing things with ML that were recently considered accessible only to experts, including object detection, pose classification, and speech recognition. </p> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5nc5Cgt8SUJFEeLKzRprsr-7lKqY1zXrce3T2NxIRlw0PDSxYey65ucFGWeufPKc4K5qAMsM3KsBnRIRfyrdmnX2xgxEvyRkT0sHNJmnT-UFY5NBlae6def8ej_Tg8oR_gJfZEu2Xg46RykNQlb23Q8hfllvtf62Jiw4nZE9dcm3cAu1yt4f-jFmi/s1600/image2.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5nc5Cgt8SUJFEeLKzRprsr-7lKqY1zXrce3T2NxIRlw0PDSxYey65ucFGWeufPKc4K5qAMsM3KsBnRIRfyrdmnX2xgxEvyRkT0sHNJmnT-UFY5NBlae6def8ej_Tg8oR_gJfZEu2Xg46RykNQlb23Q8hfllvtf62Jiw4nZE9dcm3cAu1yt4f-jFmi/s1600/image2.png\" /></a> <p>Our code examples use some pre-trained models and you can get more models that are accelerated on the Edge TPU from the <a href=\"https://coral.ai/models\">Coral models library</a>. However, training your own models allows you to explore all new project ideas. So the Maker Kit also offers step-by-step tutorials that show you how to collect your own datasets and train your own vision and audio models. </p><p>Last but not least, we want you to spend nearly all your time writing the code that's unique to your project. So we created a Python library that reduces the amount of code needed to perform an inference down to a tiny part of your project. For example, this is how you can run an object detection model and draw labeled bounding boxes on a live camera feed: </p> <pre><code class=\"\">from aiymakerkit import vision<br />from aiymakerkit import utils<br />import models<br /><br />detector = vision.Detector(models.OBJECT_DETECTION_MODEL)<br />labels = utils.read_labels_from_metadata(models.OBJECT_DETECTION_MODEL)<br /><br />for frame in vision.get_frames():<br />    objects = detector.get_objects(frame, threshold=0.4)<br />    vision.draw_objects(frame, objects, labels)<br /></code></pre> <p>Our intent is to hide the code you don't absolutely need. You still have access to structured inference results and program flow, but without any boilerplate code to handle the model. </p><p>This aiymakerkit library is built upon TensorFlow Lite and it's <a href=\"https://github.com/google-coral/aiy-maker-kit\">available on GitHub</a>, so we invite you to explore the innards and extend the Maker Kit API for your projects. </p><p><strong>Getting started</strong></p><p>We created the Maker Kit to be fully customizable for your projects. So rather than provide all the materials in a box with a predetermined design, we designed it with hardware that's already available in stores (listed on our website) and with optional instructions to build your own case. </p><p>To get started, visit our website at <a href=\"https://g.co/aiy/maker\">g.co/aiy/maker</a>, gather the required materials, flash our system image, and follow our programming tutorials to start exploring the possibilities. With this head start toward building smart applications that run entirely on an embedded system, we can't wait to see what you will create. </p>",
            "pubdate": "Tue, 17 May 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                17
            ],
            "email_sent": true
        },
        "What's new in TensorFlow 2.9?": {
            "url": "https://blog.tensorflow.org/2022/05/whats-new-in-tensorflow-29.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYIMKKNGUkhWyF3gL1qLpn7cQ3iQu5GleP-36OHbTJwn90YdRUk8vGTefc9ctjwPcJhyBbFlprd581nDsWEKfMAeAo9xuX8zKfxti8Fvl2f2v69Qmvt695cCJY1dfVPbMIlfWqMFKMEyBCgIaRLXypYCrHlob-OiAb0mvVbhmBEt65-agfmRWDMuaI/s1600/image1.png\" style=\"display: none;\" /> <p><em>Posted by Goldie Gadde and Douglas Yarrington for the TensorFlow team</em><p> <a name=\"more\"></a><p></p> <p>TensorFlow 2.9 has been released! Highlights include performance improvements with oneDNN, and the release of DTensor, a new API for model distribution that can be used to seamlessly move from data parallelism to model parallelism  </p><p>We\u2019ve also made improvements to the core library, including Eigen and <code>tf.function</code> unification, deterministic behavior, and new support for Windows' <a href=\"https://docs.microsoft.com/en-us/windows/wsl/install\">WSL2</a>. Finally, we\u2019re releasing new experimental APIs for tf.function retracing and Keras Optimizers. Let's take a look at these new and improved features. </p><h3>Improved CPU performance: oneDNN by default</h3>  <p>We have worked with Intel to integrate the <a href=\"https://github.com/oneapi-src/oneDNN\">oneDNN</a> performance library with TensorFlow to achieve top performance on Intel CPUs. Since TensorFlow 2.5, TensorFlow has had <a href=\"https://github.com/tensorflow/community/blob/master/rfcs/20210930-enable-onednn-ops.md\">experimental support</a> for oneDNN, which could provide up to a 4x <a href=\"https://medium.com/intel-analytics-software/leverage-intel-deep-learning-optimizations-in-tensorflow-129faa80ee07\">performance improvement</a>. In TensorFlow 2.9, we are turning on oneDNN optimizations by default on Linux x86 packages and for CPUs with neural-network-focused hardware features such as AVX512_VNNI, AVX512_BF16, AMX, and others, which are found on <a href=\"https://www.intel.com/content/www/us/en/products/platforms/details/cascade-lake.html\">Intel Cascade Lake</a> and newer CPUs.  </p><p>Users running TensorFlow with oneDNN optimizations enabled might observe slightly different numerical results from when the optimizations are off. This is because floating-point round-off approaches and order differ, and can create slight errors. If this causes issues for you, turn the optimizations off by setting <code>TF_ENABLE_ONEDNN_OPTS=0</code> before running your TensorFlow programs. To enable or re-enable them, set  <code>TF_ENABLE_ONEDNN_OPTS=1</code> before running your TensorFlow program. To verify that the optimizations are on, look for a message beginning with <code>\"oneDNN custom operations are on\"</code> in your program log. We welcome feedback on <a href=\"https://github.com/tensorflow/tensorflow\">GitHub</a> and the <a href=\"https://discuss.tensorflow.org/\">TensorFlow Forum</a>. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYIMKKNGUkhWyF3gL1qLpn7cQ3iQu5GleP-36OHbTJwn90YdRUk8vGTefc9ctjwPcJhyBbFlprd581nDsWEKfMAeAo9xuX8zKfxti8Fvl2f2v69Qmvt695cCJY1dfVPbMIlfWqMFKMEyBCgIaRLXypYCrHlob-OiAb0mvVbhmBEt65-agfmRWDMuaI/s1600/image1.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgYIMKKNGUkhWyF3gL1qLpn7cQ3iQu5GleP-36OHbTJwn90YdRUk8vGTefc9ctjwPcJhyBbFlprd581nDsWEKfMAeAo9xuX8zKfxti8Fvl2f2v69Qmvt695cCJY1dfVPbMIlfWqMFKMEyBCgIaRLXypYCrHlob-OiAb0mvVbhmBEt65-agfmRWDMuaI/s1600/image1.png\" /></a>   <h3>Model parallelism with DTensor</h3>  <p>DTensor is a new TensorFlow API for distributed model processing that allows models to seamlessly move from data parallelism to single program multiple data (<a href=\"https://www.tensorflow.org/guide/dtensor_overview\">SPMD</a>) based model parallelism, including <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/train-ml-models-on-large-images-and-3d-volumes-with-spatial-partitioning-on-cloud-tpus\">spatial partitioning</a>. This means you have tools to easily train models where the model weights or inputs are so large they don\u2019t fit on a single device. (If you are familiar with <a href=\"https://github.com/tensorflow/mesh\">Mesh TensorFlow</a> in TF1, DTensor serves a similar purpose.) </p><p>DTensor is designed with the following principles at its core: </p><ul> <li><strong>A device-agnostic API</strong>:  This allows the same model code to be used on CPU, GPU, or TPU, including models partitioned across device types.  <li><strong>Multi-client execution</strong>: Removes the coordinator and leaves each task to drive its locally attached devices, allowing scaling a model with no impact to startup time.  <li><strong>A global perspective vs. per-replica: </strong>Traditionally with TensorFlow, distributed model code is written around replicas, but with DTensor, model code is written from the global perspective and per replica code is generated and run by the DTensor runtime. Among other things, this means no uncertainty about whether  batch normalization is happening at the global level or the per replica level. </li></ul><p>We have developed several introductory tutorials on DTensor, from DTensor concepts to training DTensor ML models with Keras: </p><ul> <li><a href=\"https://www.tensorflow.org/guide/dtensor_overview\">DTensor Concepts</a> <li><a href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_ml_tutorial\">Distributed ML with DTensors</a> <li><a href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial\">Using DTensors with Keras</a></li></ul><h3> TraceType for tf.function</h3>  <p>We have revamped the way tf.function retraces to make it simpler, predictable, and configurable. </p><p>All arguments of <code>tf.function</code> are assigned a <code>tf.types.experimental.TraceType. </code>Custom user classes can declare a <code>TraceType</code>  using the Tracing Protocol (<code>tf.types.experimental.SupportsTracingProtocol</code>). </p><p>The <code>TraceType</code> system makes it easy to understand retracing rules. For example, <a href=\"https://en.wikipedia.org/wiki/Subtyping\">subtyping</a> rules indicate what type of arguments can be used with particular function traces. Subtyping also explains how different specific shapes are joined into a generic shape that is their supertype, to reduce the number of traces for a function.  </p><p>To learn more, see the new APIs for <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/types/experimental/TraceType\">tf.types.experimental.TraceType</a></code>, <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/types/experimental/SupportsTracingProtocol\">tf.types.experimental.SupportsTracingProtocol</a></code>, and the <code>reduce_retracing</code> parameter of <code>tf.function</code>.  <h3>Support for WSL2</h3>  <p>The <a href=\"https://docs.microsoft.com/en-us/windows/wsl/about\">Windows Subsystem for Linux</a> lets developers run a Linux environment directly on Windows, without the overhead of a traditional virtual machine or dual boot setup. TensorFlow now supports WSL2 out of the box, including GPU acceleration. Please see the documentation for more details about the requirements and how to install WSL2 on Windows. </p><h3>Deterministic behavior</h3>  <p>The API <code>tf.config.experimental.enable_op_determinism</code> makes TensorFlow ops deterministic. </p><p>Determinism means that if you run an op multiple times with the same inputs, the op returns the exact same outputs every time. This is useful for debugging models, and if you train your model from scratch several times with determinism, your model weights will be the same every time. Normally, many ops are non-deterministic due to the use of threads within ops which can add floating-point numbers in a nondeterministic order. </p><p>TensorFlow 2.8 introduced <a href=\"https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism\">an API</a> to make ops deterministic, and TensorFlow 2.9 improved determinism performance in <code>tf.data</code> in some cases. If you want your TensorFlow models to run deterministically, just add the following to the start of your program: </p><p>``` </p><p>tf.keras.utils.set_random_seed(1) </p><p>tf.config.experimental.enable_op_determinism() </p><p>``` </p><p>The first line sets the random seed for Python, NumPy, and TensorFlow, which is necessary for determinism. The second line makes each TensorFlow op deterministic. Note that determinism in general comes at the expense of lower performance and so your model may run slower when op determinism is enabled. </p><h3>Optimized Training with Keras</h3>  <p>In TensorFlow 2.9, we are releasing a new experimental version of the Keras Optimizer API, <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental\">tf.keras.optimizers.experimental</a>. The API provides a more unified and expanded catalog of built-in optimizers which can be more easily customized and extended.  </p><p>In a future release, <code>tf.keras.optimizers.experimental.Optimizer</code> (and subclasses) will replace <code>tf.keras.optimizers.Optimizer</code> (and subclasses), which means that workflows using the legacy Keras optimizer will automatically switch to the new optimizer. The current (legacy) tf.keras.optimizers.* API will still be accessible via tf.keras.optimizers.legacy.*, such as tf.keras.optimizers.legacy.Adam. </p><p>Here are some highlights of the new optimizer class: </p><ul> <li>Incrementally faster training for some models.  <li>Easier to write customized optimizers.  <li>Built-in support for moving average of model weights (\"Polyak averaging\"). </li></ul><p>For most users, you will need to take no action. But, if you have an advanced workflow falling into the following cases, please make corresponding changes: </p><p><strong>Use Case 1: You implement a customized optimizer based on the Keras optimizer</strong></p><p>For these works, please first check if it is possible to change your dependency to <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental\">tf.keras.optimizers.experimental.Optimizer. </a></code>If for any reason you decide to stay with the old optimizer (we discourage it), then you can change your optimizer to <code>tf.keras.optimizers.legacy.Optimizer</code> to avoid being automatically switched to the new optimizer in a later TensorFlow version.  <p><strong>Use Case 2: Your work depends on third-party Keras-based optimizers (such as tensorflow_addons)</strong></p><p>Your work should run successfully as long as the library continues to support the specific optimizer. However, if the library maintainers fail to take actions to accommodate the Keras optimizer change, your work would error out. So please stay tuned with the third-party library\u2019s announcement, and<a href=\"https://github.com/keras-team/keras/issues\"> file a bug to Keras team</a> if your work is broken due to optimizer malfunction.  </p><p><strong>Use Case 3: Your work is based on TF1</strong></p><p>First of all, please try <a href=\"https://www.tensorflow.org/guide/migrate\">migrating to TF2</a>. It is worth it, and may be easier than you think! If for any reason migration is not going to happen soon, then please replace your <code>tf.keras.optimizers.XXX</code> to <code>tf.keras.optimizers.legacy.XXX</code> to avoid being automatically switched to the new optimizer. </p><p><strong>Use Case 4: Your work has customized gradient aggregation logic</strong></p><p>Usually this means you are doing gradients aggregation outside the optimizer, and calling <code>apply_gradients()</code> with <code>experimental_aggregate_gradients=False</code>. We changed the argument name, so please change your optimizer to <code>tf.keras.optimizers.experimental.Optimizer</code> and set <code>skip_gradients_aggregation=True</code>. If it errors out after making this change, please <a href=\"https://github.com/keras-team/keras/issues\">file a bug</a> to Keras team. </p><p><strong>Use Case 5: Your work has direct calls to deprecated optimizer public APIs</strong></p><p>Please check if your method call has a match <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental\">here</a>. change your optimizer to <code>tf.keras.optimizers.experimental.Optimizer</code>.  If for any reason you want to keep using the old optimizer, change your optimizer to <code>tf.keras.optimizers.legacy.Optimizer</code>. </p><p><strong>Next steps</strong></p><p>Check out the <a href=\"https://github.com/tensorflow/tensorflow/releases\">release notes</a> for more information. To stay up to date, you can read the TensorFlow <a href=\"https://blog.tensorflow.org/\">blog</a>, follow <a href=\"http://twitter.com/tensorflow\">twitter.com/tensorflow</a>, or subscribe to <a href=\"https://youtube.com/tensorflow\">youtube.com/tensorflow</a>. If you\u2019ve built something you\u2019d like to share, please submit it for our Community Spotlight at <a href=\"http://goo.gle/TFCS\">goo.gle/TFCS</a>. For feedback, please file an issue on <a href=\"https://github.com/tensorflow/tensorflow/issues\">GitHub</a> or post to the <a href=\"https://discuss.tensorflow.org/\">TensorFlow Forum</a>. Thank you! </p>",
            "pubdate": "Wed, 18 May 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                18
            ],
            "email_sent": true
        },
        "Real-time SKU detection in the browser using TensorFlow.js": {
            "url": "https://blog.tensorflow.org/2022/05/real-time-sku-detection-in-browser.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXJKi_ujdUUveIPpH2BeriYxl3K7TzTUfsocSRD1xKulteBDQZkZYmQBB1z_yW4C6orHg825mRAhFCJTEuOrtHjpMFpVUVcBUCQ33OYwkmPRDKdTs9oH4RBHrb2Ay9p_j3bDhsIfjwzukA1Sr-uT0uSXA_kpXnJSi62XSi0bHPDsaPMlQZZyGReTiB/s1600/image7.png\" style=\"display: none;\" />  <p><em>Posted by <a href=\"https://www.linkedin.com/in/hugozanini/?locale=en_US\">Hugo Zanini</a>, Data Product Manager</em><p> <a name=\"more\"></a><p></p> <p>Last year, I published an article on<a href=\"https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html\"> how to train custom object detection in the browser using TensorFlow.js</a>. This received lots of  interest from developers from all over the world who tried to apply the solution to their personal or business projects.While answering reader\u2019s questions on my first article, I noticed a few difficulties in adapting our solution to large datasets, and deploying the resulting model in production using the new version of TensorFlow.js. </p><p>Therefore, the goal of this article is to share a solution for a well-known problem in the consumer packaged goods (CPG) industry: real-time and offline <a href=\"https://en.wikipedia.org/wiki/Stock_keeping_unit\">SKU</a> detection using TensorFlow.js. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-RgZkEm4Rb9QERMU7H4wVyk5Z6KdeiCKoyGOOlOnyEiefkPXnDbFlVAW-ORzatYYq2bgkEc9XXXux_WzoPzlT3u-13WyNL8p8-dNo73C1k-ywKzuAAe207cSvaMx84_MrcqrT-qaVE-yL39_BbFX6ba3G9PepBjusD3M_wS0gsSVcIBALq6XjHpiy/s1600/ezgif.com-gif-maker.gif\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-RgZkEm4Rb9QERMU7H4wVyk5Z6KdeiCKoyGOOlOnyEiefkPXnDbFlVAW-ORzatYYq2bgkEc9XXXux_WzoPzlT3u-13WyNL8p8-dNo73C1k-ywKzuAAe207cSvaMx84_MrcqrT-qaVE-yL39_BbFX6ba3G9PepBjusD3M_wS0gsSVcIBALq6XjHpiy/s1600/ezgif.com-gif-maker.gif\" /></a> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh-RgZkEm4Rb9QERMU7H4wVyk5Z6KdeiCKoyGOOlOnyEiefkPXnDbFlVAW-ORzatYYq2bgkEc9XXXux_WzoPzlT3u-13WyNL8p8-dNo73C1k-ywKzuAAe207cSvaMx84_MrcqrT-qaVE-yL39_BbFX6ba3G9PepBjusD3M_wS0gsSVcIBALq6XjHpiy/s1600/ezgif.com-gif-maker.gif\"></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Offline SKU detection running in real time on a smartphone using TensorFlow.js  </td></tr></tbody></table>  <p><strong>The problem</strong></p><p>Items consumed frequently by consumers (foods, beverages, household products, etc) require an extensive routine of replenishment and placement of those products at their point of sale (supermarkets, convenience stores, etc).  </p><p>Over the past few years, researchers have shown repeatedly that about two-thirds of purchase decisions are made after customers enter the store. One of the biggest challenges for consumer goods companies is to guarantee the availability and correct placement of their product in-stores.   </p><p>At stores, teams organize the shelves based on marketing strategies, and manage the level of products in the stores. The people working on these activities may count the number of SKUs of each brand in a store to estimate product stocks and market share, and help to shape marketing strategies. </p><p>These estimations though are very time-consuming. Taking a photo and using an algorithm to count the SKUs on the shelves to calculate a brand\u2019s market share could be a good solution. </p><p>To use an approach like that, the detection should run in real-time such that as soon as you point a phone camera to the shelf, the algorithm recognizes the brands and calculates the market shares. And, as the internet inside the stores is generally limited, the detection should work offline. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXJKi_ujdUUveIPpH2BeriYxl3K7TzTUfsocSRD1xKulteBDQZkZYmQBB1z_yW4C6orHg825mRAhFCJTEuOrtHjpMFpVUVcBUCQ33OYwkmPRDKdTs9oH4RBHrb2Ay9p_j3bDhsIfjwzukA1Sr-uT0uSXA_kpXnJSi62XSi0bHPDsaPMlQZZyGReTiB/s1600/image7.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXJKi_ujdUUveIPpH2BeriYxl3K7TzTUfsocSRD1xKulteBDQZkZYmQBB1z_yW4C6orHg825mRAhFCJTEuOrtHjpMFpVUVcBUCQ33OYwkmPRDKdTs9oH4RBHrb2Ay9p_j3bDhsIfjwzukA1Sr-uT0uSXA_kpXnJSi62XSi0bHPDsaPMlQZZyGReTiB/s1600/image7.png\" /></a> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXJKi_ujdUUveIPpH2BeriYxl3K7TzTUfsocSRD1xKulteBDQZkZYmQBB1z_yW4C6orHg825mRAhFCJTEuOrtHjpMFpVUVcBUCQ33OYwkmPRDKdTs9oH4RBHrb2Ay9p_j3bDhsIfjwzukA1Sr-uT0uSXA_kpXnJSi62XSi0bHPDsaPMlQZZyGReTiB/s1600/image7.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"> Example workflow</td></tr></tbody></table>   <p>This post is going to show how to implement the real-time and offline image recognition solution to identify generic SKUs using the<a href=\"https://github.com/eg4000/SKU110K_CVPR19\"> SKU110K dataset</a> and the<a href=\"https://arxiv.org/abs/1801.04381\"> MobileNetV2</a> network. </p><p>Due to the lack of a public dataset with labeled SKUs of different brands, we\u2019re going to create a generic algorithm, but all the instructions can be applied in a multiclass problem. </p><p>As with every machine learning flow, the project will be divided into four steps, as follows: </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsTYleef2QUeRdcScNczV1XV50dtvAvS3M9jh47bAwfMEG0zJIOt0VJvlteFAaoPvA7D2U21L1zxmo_41WG6QVf46l4hnIsbCPn63EWCw4Dp_qSTEL2O9FIUOzPMElANPmlkMFd64ZFzD7eOrtkDqpu8_-CM4R5OM-v8VPtd9606_i1dzTjjD8NvSC/s1600/image3.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsTYleef2QUeRdcScNczV1XV50dtvAvS3M9jh47bAwfMEG0zJIOt0VJvlteFAaoPvA7D2U21L1zxmo_41WG6QVf46l4hnIsbCPn63EWCw4Dp_qSTEL2O9FIUOzPMElANPmlkMFd64ZFzD7eOrtkDqpu8_-CM4R5OM-v8VPtd9606_i1dzTjjD8NvSC/s1600/image3.png\" /></a>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsTYleef2QUeRdcScNczV1XV50dtvAvS3M9jh47bAwfMEG0zJIOt0VJvlteFAaoPvA7D2U21L1zxmo_41WG6QVf46l4hnIsbCPn63EWCw4Dp_qSTEL2O9FIUOzPMElANPmlkMFd64ZFzD7eOrtkDqpu8_-CM4R5OM-v8VPtd9606_i1dzTjjD8NvSC/s1600/image3.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Object Detection Model Production Pipeline</td></tr></tbody></table>    <p><strong>Preparing the data</strong></p><p>The first step to training a good model is to gather good data. As mentioned before, this solution is going to use a dataset of SKUs in different scenarios. The purpose of SKU110K was to create a benchmark for models capable of recognizing objects in densely packed scenes. </p><p>The dataset is provided in the <a href=\"https://towardsdatascience.com/coco-data-format-for-object-detection-a4c5eaf518c5\">Pascal VOC</a> format and has to be converted to <em><a href=\"https://keras.io/examples/keras_recipes/creating_tfrecords/\">tf.record</a></em>. The script to do the conversion is<a href=\"https://github.com/hugozanini/realtime-sku-detection/blob/main/pascal-to-tfrecord.py\"> available here</a> and the<em> tf.record</em> version of the dataset is also available in my <a href=\"https://github.com/hugozanini/realtime-sku-detection\">project repository</a>. As mentioned before, SKU110K is a large and very challenging dataset to work with. It contains many objects, often looking similar or even identical, positioned in close proximity. </p>  <center>  </center>  <p>To work with this dataset, the neural network chosen has to be very effective in recognizing patterns and be small enough to run in real-time in TensorFlow.js. </p><p><strong>Choosing the model</strong></p><p>There are a variety of neural networks capable of solving the SKU detection problem. But, the architectures that easily achieve a high level of precision are very dense and don't have reasonable inference times when converted to TensorFlow.js to run in real-time. </p><p>Because of that, the approach here is going to be to focus on optimizing a mid-level neural network to achieve reasonable precision working on densely packed scenes and run the inferences in real-time. Analyzing the<a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\"> TensorFlow 2.0 Detection Model Zoo</a>, the challenge will be to try to solve the problem using the lighter single-shot model available: SSD MobileNet v2 320x320 which seems to fit the criteria required. The architecture is proven to be able to recognize up to 90 classes and can be trained to identify different SKUs. </p><p><strong>Training the model</strong></p><p>With a good dataset and the model selected, it\u2019s time to think about the training process. TensorFlow 2.0 provides an<a href=\"https://github.com/tensorflow/models/tree/master/research/object_detection\"> Object Detection API</a> that makes it easy to construct, train, and deploy object detection models. In this project, we\u2019re going to use this API and train the model using a<a href=\"https://colab.research.google.com/drive/1dyuGpeLh1K4rqOkxELLTTlSqhfbTnFac?usp=sharing\"> Google Colaboratory Notebook</a>. The remainder of this section explains how to set up the environment, the model selection, and training. If you want to jump straight to the Colab Notebook,<a href=\"https://colab.research.google.com/drive/1WDXd1IzyQRw1oDmcapAM1PyZxgw2UVJM?usp=sharing\"> click here</a>. </p><p><strong>Setting up the environment</strong></p><p><a href=\"https://colab.research.google.com/\">Create</a> a new Google Colab notebook and select a GPU as the hardware accelerator: </p>   <pre class=\"prettyprint\">Runtime &gt; Change runtime type &gt; Hardware accelerator: GPU<br /></pre>  <p>Clone, install, and test the TensorFlow Object Detection API: </p> <center>  </center> <p>Next, download and extract the dataset using the following commands: </p>  <center>  </center>  <p><strong>Setting up the training pipeline</strong></p><p>We\u2019re ready to configure the training pipeline. TensorFlow 2.0 provides pre-trained weights for the SSD Mobilenet v2 320x320 on the<a href=\"https://cocodataset.org/#home\"> COCO 2017 Dataset</a>, and they are going to be downloaded using the following commands: </p>  <center>  </center> <p>The downloaded weights were pre-trained on the<a href=\"https://cocodataset.org/#home\"> COCO 2017 Dataset</a>, but the focus here is to train the model to recognize one class so these weights are going to be used only to initialize the network\u200a\u2014\u200athis technique is known as<a href=\"https://www.tensorflow.org/tutorials/images/transfer_learning\"> transfer learning</a>, and it\u2019s commonly used to speed up the learning process. </p><p>The last step is to set up the hyperparameters on the configuration file that is going to be used during the training. Choosing the best hyperparameters is a task that requires some experimentation and, consequently, computational resources. </p><p>I took a standard configuration of MobileNetV2 parameters from the TensorFlow <a href=\"https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2\">Models Config Repository</a> and performed a sequence of experiments (thanks Google Developers for the free resources) to optimize the model to work with densely packed scenes on the SKU110K dataset. Download the configuration and check the parameters using the code below. </p>  <center>  </center>  <center>  </center> <p>With the parameters set, start the training by executing the following command: </p>  <center>  </center><p>To identify how well the training is going, we use the loss value. Loss is a number indicating how bad the model\u2019s prediction was on the training samples. If the model\u2019s prediction is perfect, the loss is zero; otherwise, the loss is greater. The goal of training a model is to find a set of weights and biases that have low loss, on average, across all examples (<a href=\"https://developers.google.com/machine-learning/crash-course/descending-into-ml/training-and-loss\">Descending into ML: Training and Loss | Machine Learning Crash Course</a>). </p><p>The training process was monitored through Tensorboard and took around 22h to finish on a 60GB machine using an NVIDIA Tesla P4. The final losses can be checked below </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4k_zpucjpl8y6HA_I4lB-wH41VY_Eg9awRHYD9kZCE7sPDJpAareh0sOhzi0Mbaeae1cxSK2vuR_zn3ZAHrat0_r5Dk3ttFUXIPoBopVPJCefHsj_3DyhVqsBM4F9aCvAauEjwfQ9s_aG0asu8k9JGCZf4D6W6DlgKAIbLAjCgZgVLnLRZutj8etf/s1600/image9.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4k_zpucjpl8y6HA_I4lB-wH41VY_Eg9awRHYD9kZCE7sPDJpAareh0sOhzi0Mbaeae1cxSK2vuR_zn3ZAHrat0_r5Dk3ttFUXIPoBopVPJCefHsj_3DyhVqsBM4F9aCvAauEjwfQ9s_aG0asu8k9JGCZf4D6W6DlgKAIbLAjCgZgVLnLRZutj8etf/s1600/image9.png\" style=\"display: block; padding: 1em 0px; text-align: center;\" /></a> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi4k_zpucjpl8y6HA_I4lB-wH41VY_Eg9awRHYD9kZCE7sPDJpAareh0sOhzi0Mbaeae1cxSK2vuR_zn3ZAHrat0_r5Dk3ttFUXIPoBopVPJCefHsj_3DyhVqsBM4F9aCvAauEjwfQ9s_aG0asu8k9JGCZf4D6W6DlgKAIbLAjCgZgVLnLRZutj8etf/s1600/image9.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Total training loss </td></tr></tbody></table>   <p><strong>Validate the model</strong></p><p>Now let\u2019s evaluate the trained model using the test data: </p> <center>  </center> <p>The evaluation was done across 2740 images and provides three metrics based on the<a href=\"https://cocodataset.org/#detection-eval\"> COCO detection evaluation metrics</a>: precision, recall, and loss (<a href=\"https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall\">Classification: Precision and Recall | Machine Learning Crash Course</a>). The same metrics are available via Tensorboard and can be analyzed in an easier way </p>   <pre class=\"prettyprint\">%load_ext tensorboard<br />%tensorboard --logdir '/content/training/'<br /></pre>  <p>You can then explore all training and evaluation metrics. </p>    <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIuzWSK8B52q9FIJJ0ARUu4Y--esT101VSCIkUEg9JMTm5H0zy1r9PmkOkLTHl9ve-3DWWKa09876MB0TGYkzJXgRGMpSgriZZmOivA7fK4FJ7z_hXkEsiMkiGJBSgpfrD-MYBUlowijEKqECWHUEKxGxon9JDwqIllWlFuOD0qbEwBrblrnWDuToP/s1600/image8.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIuzWSK8B52q9FIJJ0ARUu4Y--esT101VSCIkUEg9JMTm5H0zy1r9PmkOkLTHl9ve-3DWWKa09876MB0TGYkzJXgRGMpSgriZZmOivA7fK4FJ7z_hXkEsiMkiGJBSgpfrD-MYBUlowijEKqECWHUEKxGxon9JDwqIllWlFuOD0qbEwBrblrnWDuToP/s1600/image8.png\" /></a> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIuzWSK8B52q9FIJJ0ARUu4Y--esT101VSCIkUEg9JMTm5H0zy1r9PmkOkLTHl9ve-3DWWKa09876MB0TGYkzJXgRGMpSgriZZmOivA7fK4FJ7z_hXkEsiMkiGJBSgpfrD-MYBUlowijEKqECWHUEKxGxon9JDwqIllWlFuOD0qbEwBrblrnWDuToP/s1600/image8.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Main evaluation metrics </td></tr></tbody></table>   <p><strong>Exporting the model</strong></p><p>Now that the training is validated, it\u2019s time to export the model. We\u2019re going to convert the training checkpoints to a <em><a href=\"https://developers.google.com/protocol-buffers/docs/proto3\">protobuf </a></em>(pb) file. This file is going to have the graph definition and the weights of the model. </p><center>  </center>  <p>As we\u2019re going to deploy the model using TensorFlow.js and Google Colab has a maximum lifetime limit of 12 hours, let\u2019s download the trained weights and save them locally. When running the command <code>files.download(\"/content/saved_model.zip\")</code>, the Colab will prompt the file download automatically. </p> <center> </center>   <p><strong>Deploying the model</strong></p><p>The model is going to be deployed in a way that anyone can open a PC or mobile camera and perform inference in real-time through a web browser. To do that, we\u2019re going to convert the saved model to the TensorFlow.js layers format, load the model in a JavaScript application and make everything available on<a href=\"https://codesandbox.io/\"> CodeSandbox</a>. </p><p><strong>Converting the model</strong></p><p>At this point, you should have something similar to this structure saved locally: </p><p>%MD </p><p>\u251c\u2500\u2500 inference-graph </p><p>\u2502 \u251c\u2500\u2500 saved_model </p><p>\u2502 \u2502 \u251c\u2500\u2500 assets </p><p>\u2502 \u2502 \u251c\u2500\u2500 saved_model.pb </p><p>\u2502 \u2502 \u251c\u2500\u2500 variables </p><p>\u2502 \u2502 \u251c\u2500\u2500 variables.data-00000-of-00001 </p><p>\u2502 \u2502 \u2514\u2500\u2500 variables.index </p><p>Before we start, let\u2019s create an isolated Python environment to work in an empty workspace and avoid any library conflict.<a href=\"https://virtualenv.pypa.io/en/latest/installation.html\"> Install virtualenv</a> and then open a terminal in the inference-graph folder and create and activate a new virtual environment: </p>   <pre class=\"prettyprint\">virtualenv -p python3 venv<br />source venv/bin/activate<br /></pre>  <p>Install the<a href=\"https://github.com/tensorflow/tfjs/tree/master/tfjs-converter\"> TensorFlow.js converter</a>: </p>   <pre class=\"prettyprint\">pip install tensorflowjs[wizard]<br /></pre>  <p>Start the conversion wizard: </p>   <pre class=\"prettyprint\">tensorflowjs_wizard<br /></pre>  <p>Now, the tool will guide you through the conversion, providing explanations for each choice you need to make. The image below shows all the choices that were made to convert the model. Most of them are the standard ones, but options like the shard sizes and compression can be changed according to your needs. </p><p>To enable the browser to cache the weights automatically, it\u2019s recommended to split them into shard files of around 4MB. To guarantee that the conversion is going to work, don\u2019t skip the op validation as well, not all TensorFlow operations are supported so some models can be incompatible with TensorFlow.js\u200a\u2014\u200aSee<a href=\"https://github.com/tensorflow/tfjs/blob/master/tfjs-converter/docs/supported_ops.md\"> this list for</a> which ops are currently supported on the various backends that TensorFlow.js executes on such as WebGL, WebAssembly, or plain JavaScript. </p>    <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMqCki32tUqEILujT0zrG-28wt9CxxQP1IQBwpWYi0hAQfix9TLFHcz9otuK_-kFn1KZbx068Z44cNtzfZ0zr-N6gev0SHhpQbDLt-PE5LeIInTphf9KN1FPPMUaTa14uRREpwhFJQuwy6mZd9oS7ZC5YT2yjrHGTTotKVt5vx6vJ0uGuFQtM9zdt9/s1600/image10.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMqCki32tUqEILujT0zrG-28wt9CxxQP1IQBwpWYi0hAQfix9TLFHcz9otuK_-kFn1KZbx068Z44cNtzfZ0zr-N6gev0SHhpQbDLt-PE5LeIInTphf9KN1FPPMUaTa14uRREpwhFJQuwy6mZd9oS7ZC5YT2yjrHGTTotKVt5vx6vJ0uGuFQtM9zdt9/s1600/image10.png\" style=\"display: block; padding: 1em 0px; text-align: center;\" /></a> <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjMqCki32tUqEILujT0zrG-28wt9CxxQP1IQBwpWYi0hAQfix9TLFHcz9otuK_-kFn1KZbx068Z44cNtzfZ0zr-N6gev0SHhpQbDLt-PE5LeIInTphf9KN1FPPMUaTa14uRREpwhFJQuwy6mZd9oS7ZC5YT2yjrHGTTotKVt5vx6vJ0uGuFQtM9zdt9/s1600/image10.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><p><em>Model conversion using TensorFlow.js Converter (Full resolution image <a href=\"https://drive.google.com/file/d/1G-8uRdLeP6FpCtMeDNZ9yxHyygoKUSc2/view?usp=sharing\">here</a>)</em></p></td></tr></tbody></table>  <p>If everything works well, you\u2019re going to have the model converted to the TensorFlow.js layers format in the web_model directory. The folder contains a model.json file and a set of sharded weights files in a binary format. The model.json has both the model topology (aka \u201carchitecture\u201d or \u201cgraph\u201d: a description of the layers and how they are connected) and a manifest of the weight files (<a href=\"https://cocodataset.org/#detection-eval\">Lin, Tsung-Yi, et al</a>). The contents of the web_model folder currently contains the files shown below: </p>   <pre class=\"prettyprint\">\u2514 web_model<br />  \u251c\u2500\u2500 group1-shard1of5.bin<br />  \u251c\u2500\u2500 group1-shard2of5.bin<br />  \u251c\u2500\u2500 group1-shard3of5.bin<br />  \u251c\u2500\u2500 group1-shard4of5.bin<br />  \u251c\u2500\u2500 group1-shard5of5.bin<br />  \u2514\u2500\u2500 model.json<br /></pre>  <p><strong>Configuring the application</strong></p><p>The model is ready to be loaded in JavaScript. I\u2019ve created an application to perform inference directly from the browser. Let\u2019s<a href=\"https://github.com/hugozanini/realtime-sku-detection/tree/web\"> clone the repository</a> to figure out how to use the converted model in real-time. This is the project structure: </p>   <pre class=\"prettyprint\">\u251c\u2500\u2500 models<br />\u2502\t\u251c\u2500\u2500 group1-shard1of5.bin<br />\u2502\t\u251c\u2500\u2500 group1-shard2of5.bin<br />\u2502\t\u251c\u2500\u2500 group1-shard3of5.bin<br />\u2502\t\u251c\u2500\u2500 group1-shard4of5.bin<br />\u2502\t\u251c\u2500\u2500 group1-shard5of5.bin<br />\u2502\t\u2514\u2500\u2500 model.json<br />\u251c\u2500\u2500 package.json<br />\u251c\u2500\u2500 package-lock.json<br />\u251c\u2500\u2500 public<br />\u2502   \u2514\u2500\u2500 index.html<br />\u251c\u2500\u2500 README.MD<br />\u2514\u2500\u2500 src<br />\t\u251c\u2500\u2500 index.js<br />\t\u2514\u2500\u2500 styles.css<br /></pre>  <p>For the sake of simplicity, I have already provided a converted SKU-detector model in the model's folder. However, let\u2019s put the web_model generated in the previous section in the models folder and test it. </p><p>Next, install the<a href=\"https://www.npmjs.com/package/http-server\"> http-server</a>: </p>   <pre class=\"prettyprint\">npm install http-server -g<br /></pre>  <p>Go to the <em>models</em> folder and run the command below to make the model available at http://127.0.0.1:8080 . This is a good choice when you want to keep the model weights in a safe place and control who can request inferences to it. The -c1 parameter is added to disable caching, and the --cors flag enables<a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS\"> cross-origin resource sharing</a> allowing the hosted files to be used by the client-side JavaScript for a given domain. </p>   <pre class=\"prettyprint\">http-server -c1 --cors .<br /></pre>  <p>Alternatively, you can upload the model files somewhere else - even on a different domain if needed. In my case, I chose my own Github repo and referenced the model.json folder URL in the load_model function as shown below: </p>   <pre class=\"prettyprint\">async function load_model() {<br />\t// It's possible to load the model locally or from a repo.<br />\t// Load from localhost locally:<br />      const model = await loadGraphModel(\"http://127.0.0.1:8080/model.json\");<br />\t// Or Load from another domain using a folder that contains model.json.<br />      // const model = await loadGraphModel(\"https://github.com/hugozanini/realtime-sku-detection/tree/web\");<br />\treturn model;<br />}<br /></pre>  <p>This is a good option because it gives more flexibility to the application and makes it easier to run on public web servers. </p><p>Pick one of the methods to load the model files in the function load_model <a href=\"https://github.com/hugozanini/realtime-sku-detection/blob/79f7414de797abcc6681ecef582790c33e96369d/src/index.js#L10\">(lines 10\u201315 in the file src&gt;index.js</a>).  </p><p>When loading the model, TensorFlow.js will perform the following requests: </p>   <pre class=\"prettyprint\">GET /model.json<br />GET /group1-shard1of5.bin<br />GET /group1-shard2of5.bin<br />GET /group1-shard3of5.bin<br />GET /group1-shardo4f5.bin<br />GET /group1-shardo5f5.bin<br /></pre>  <p><strong>Publishing in CodeSandbox</strong></p><p><a href=\"https://codesandbox.io/\">CodeSandbox</a> is a simple tool for creating web apps where we can upload the code and make the application available for everyone on the web. By uploading the model files in a GitHub repo and referencing them in the load_model function, we can simply log into <em>CodeSandbox</em>, click on New project &gt; Import from Github, and select the app repository. </p><p>Wait some minutes to install the packages and your app will be available at a public URL that you can share with others. Click on Show &gt; In a new window and a tab will open with a live preview. Copy this URL and paste it in any web browser (PC or Mobile) and your object detection will be ready to run. A ready to use project can be found <a href=\"https://codesandbox.io/s/sku-detection-mobilenet-wtvbj?file=/src/index.js\">here</a> as well if you prefer.  </p><strong>Conclusion</strong><p>Besides the precision, an interesting part of these experiments is the inference time\u200a\u2014\u200aeverything runs in real-time in the browser via JavaScript. SKU detection models running in the browser, <a href=\"https://www.tensorflow.org/js/guide/save_load#local_storage_browser_only\">even offline</a>, and using few computational resources is a must in many consumer packaged goods company applications, along with other industries too. </p><p>Enabling a Machine Learning solution to run on the client-side is a key step to guarantee that the models are being used effectively at the point of interaction with minimal latency and solve the problems when they happen: right in the user's hand. </p><p>Deep learning should not be costly and should be used beyond just research, for real world use cases, which JavaScript is great for production deployments. I hope this article will serve as a basis for new projects involving Computer Vision, TensorFlow, and create an easier flow between Python and Javascript. </p><p>If you have any questions or suggestions you can reach me on<a href=\"https://twitter.com/hugoznn\"> Twitter</a>. </p><p>Thanks for reading! </p><p><strong>Acknowledgments</strong></p><p>I\u2019d like to thank the<a href=\"https://developers.google.com/community/gdg\"> Google Developers Group</a>, for providing all the computational resources for training the models, and the authors of the<a href=\"https://arxiv.org/abs/1904.00853\"> SKU 110K Dataset</a>, for creating and open-sourcing the dataset used in this project. </p>",
            "pubdate": "Mon, 23 May 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                23
            ],
            "email_sent": true
        },
        "5 steps to go from a notebook to a deployed model": {
            "url": "https://blog.tensorflow.org/2022/05/5-steps-to-go-from-notebook-to-deployed.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaEGCozhmfcLBv-hG8Uath2-SdRoNrWtVDfNvE_7RrmqB-fGoHWgkwQTU-Rxep9Z32WX3edWj0SgYf8fWsRrky04ezcAaqFfuJaW64E1uWcKMDiETB5HzGBuC9XZEkr4eaabS863ez4v1C_TdK37TJH-pF31Bjd4ofwLsUhcd1aB2267iJ265hQGoS/s1600/image9.png\" style=\"display: none;\" /> <p><em>Posted by Nikita Namjoshi, Google Cloud Developer Advocate </em><p> <a name=\"more\"></a><p></p>  <p>When you start working on a new machine learning problem, I\u2019m guessing the first environment you use is a notebook. Maybe you like running <a href=\"https://jupyter.org/\">Jupyter</a> in a local environment, using a <a href=\"https://www.kaggle.com/code\">Kaggle Kernel</a>, or my personal favorite, <a href=\"https://colab.research.google.com/\">Colab</a>. With tools like these, creating and experimenting with machine learning is becoming increasingly accessible. But while experimentation in notebooks is great, it\u2019s easy to hit a wall when it comes time to elevate your experiments up to production scale. Suddenly, your concerns are more than just getting the highest accuracy score. </p><p>  </p><p>What if you have a long running job, want to do distributed training, or host a model for online predictions? Or maybe your use case requires more granular permissions around security and data privacy. What is your data going to look like at serving time, how will you handle code changes, or monitor the performance of your model overtime? </p><p>  </p><p>Making production applications or training large models requires additional tooling to help you scale beyond just code in a notebook, and using a cloud service provider can help. But that process can feel a bit daunting. Take a look at the full list of <a href=\"https://googlecloudcheatsheet.withgoogle.com/\">Google Cloud products</a>, and you might be completely unsure where to start. </p><p>So to make your journey a little easier, I\u2019ll show you a fast path from experimental notebook code to a deployed model in the cloud. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaEGCozhmfcLBv-hG8Uath2-SdRoNrWtVDfNvE_7RrmqB-fGoHWgkwQTU-Rxep9Z32WX3edWj0SgYf8fWsRrky04ezcAaqFfuJaW64E1uWcKMDiETB5HzGBuC9XZEkr4eaabS863ez4v1C_TdK37TJH-pF31Bjd4ofwLsUhcd1aB2267iJ265hQGoS/s1600/image9.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiaEGCozhmfcLBv-hG8Uath2-SdRoNrWtVDfNvE_7RrmqB-fGoHWgkwQTU-Rxep9Z32WX3edWj0SgYf8fWsRrky04ezcAaqFfuJaW64E1uWcKMDiETB5HzGBuC9XZEkr4eaabS863ez4v1C_TdK37TJH-pF31Bjd4ofwLsUhcd1aB2267iJ265hQGoS/s1600/image9.png\" /></a>  <p>The code used in this sample can be <a href=\"https://github.com/nikitamaia/tensorflow-examples/blob/main/prod_in_5_steps.ipynb\">found here</a>. This notebook trains an image classification model on the <a href=\"https://www.tensorflow.org/datasets/catalog/tf_flowers\">TF Flowers dataset.</a> You\u2019ll see how to deploy this model in the cloud and get predictions on a new flower image via a REST endpoint. </p><p>Note that you\u2019ll need a Google Cloud project with billing enabled to follow this tutorial. If you\u2019ve never used Google Cloud before, you can <a href=\"https://cloud.google.com/free/docs/gcp-free-tier\">follow these instructions</a> to set up a project and get $300 in free credits to experiment with. </p><p>Here are the five steps you\u2019ll take: </p><ol> <li>Create a Vertex AI Workbench managed notebook  <li>Upload .ipynb file  <li>Launch notebook execution  <li>Deploy model  <li>Get predictions </li></ol><h3>Create a Vertex AI Workbench managed notebook</h3>  <p>To train and deploy the model, you\u2019ll use <a href=\"https://cloud.google.com/vertex-ai\">Vertex AI</a>, which is Google Cloud\u2019s managed machine learning platform. Vertex AI contains lots of different products that help you across the entire lifecycle of an ML workflow. You\u2019ll use a few of these products today, starting with <a href=\"https://cloud.google.com/vertex-ai-workbench\">Workbench</a>, which is the managed notebook offering. </p><p>Under the Vertex AI section of the <a href=\"https://console.cloud.google.com/\">cloud console</a>, select \u201cWorkbench\u201d.  Note that if this is the first time you\u2019re using Vertex AI in a project, you\u2019ll be prompted to enable the Vertex API and the Notebooks API. So be sure to click the button in the UI to do so. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghh2FVADiuk_W08IMOyrpwm4TvUq8zCnUjGuw_-pd0U02NLUhHUk6E7BXstgdsVNPJNuW5I_QCzdx7PDDEUUMc2um3N76-1qSgBgvD1Q7vZE1iEb0Hov64MtlL1ZD4wKZ6BVZ7lyPSW-GwmovnlXxYZd8_1hBltrx5LQE-GeZn5LCZ1QIG3_vhZvas/s1600/image13.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEghh2FVADiuk_W08IMOyrpwm4TvUq8zCnUjGuw_-pd0U02NLUhHUk6E7BXstgdsVNPJNuW5I_QCzdx7PDDEUUMc2um3N76-1qSgBgvD1Q7vZE1iEb0Hov64MtlL1ZD4wKZ6BVZ7lyPSW-GwmovnlXxYZd8_1hBltrx5LQE-GeZn5LCZ1QIG3_vhZvas/s1600/image13.png\" /></a>  <p>Next, select <strong>MANAGED NOTEBOOKS</strong>, and then <strong>NEW NOTEBOOK</strong>. </p>    <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihGUgeiCGozEfcrQ6fyHxY1To62hgwD6j0q_2EYQ9NJFz8sblOLVOLzqE0pjNt0kGIW1nxpAi5F00pVNh-w-CD-gYstBUHc1_pQh7IahDOJfs7Lm5FedjrmXvcQg_R2fneHIykWx3rUXRaKUGHa1yQI6fMan1HDaQuHTzq3aDF2oMq1_1JaYHhdlIg/s1600/image16.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEihGUgeiCGozEfcrQ6fyHxY1To62hgwD6j0q_2EYQ9NJFz8sblOLVOLzqE0pjNt0kGIW1nxpAi5F00pVNh-w-CD-gYstBUHc1_pQh7IahDOJfs7Lm5FedjrmXvcQg_R2fneHIykWx3rUXRaKUGHa1yQI6fMan1HDaQuHTzq3aDF2oMq1_1JaYHhdlIg/s1600/image16.png\" /></a>  <p>Under <strong>Advanced Settings </strong>you can customize your notebook by specifying the machine type and location, adding GPUs, providing custom containers, and enabling terminal access. For now, keep the default settings and just provide a name for your notebook. Then click CREATE. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKANmUL-SL7BdnReszium05E8nZx_-16hHGaosCxKW1xs_H8cIW7arNAz03Ic9BOOfhzVFrp4PUIjG7Kg8K5C7CwBf47OA98xs2jSydxzceqNRZwrrKwbpjm4QPvNT63b01nHuDtfDeq8aYboOCYYulgl4r61Rp1THibDhkffUYp-3-oXUu8Y1ZXrx/s1600/image3.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhKANmUL-SL7BdnReszium05E8nZx_-16hHGaosCxKW1xs_H8cIW7arNAz03Ic9BOOfhzVFrp4PUIjG7Kg8K5C7CwBf47OA98xs2jSydxzceqNRZwrrKwbpjm4QPvNT63b01nHuDtfDeq8aYboOCYYulgl4r61Rp1THibDhkffUYp-3-oXUu8Y1ZXrx/s1600/image3.png\" /></a>  <p>You\u2019ll know your notebook is ready when you see the <strong>OPEN JUPYTERLAB</strong> text turn blue. The first time you open the notebook, you\u2019ll be prompted to authenticate and you can follow the steps in the UI to do so. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHGQfxOqMSyvo29b2cBzZnuxUdID42F1HzMruez6tjId58A48C4XHSxOY0gQkFJLrTCaOOYzH3t_5D2XNFp9Ltxv5q4LYW1uKg1ENbTH4lQBZuF69y_HfTWqDmUeAwVmQWdKtQrN3qn0ZK20KcOHifAqQASzKbSuCtJD7cYXPskB9F5Jxdks_X6YmQ/s1600/image8.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHGQfxOqMSyvo29b2cBzZnuxUdID42F1HzMruez6tjId58A48C4XHSxOY0gQkFJLrTCaOOYzH3t_5D2XNFp9Ltxv5q4LYW1uKg1ENbTH4lQBZuF69y_HfTWqDmUeAwVmQWdKtQrN3qn0ZK20KcOHifAqQASzKbSuCtJD7cYXPskB9F5Jxdks_X6YmQ/s1600/image8.png\" /></a>  <p>When you open the JupyterLab instance, you\u2019ll see a few different notebook options. Vertex AI Workbench provides different kernels (TensorFlow, R, XGBoost, etc), which are managed environments preinstalled with common libraries for data science. If you need to add additional libraries to a kernel, you can use pip install from a notebook cell, just like you would in Colab. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqRGpn0jG-3ZAawJVolo4v0AnRlvfUn9UP9e4iHI6vJtaAUubWdT3Wpha-NuyRB2Z89YFUccZnb1XIA7ZFcQDRf-XWfe4uKuOJMCOWwwfAyjFv9lPROyJqUHBRIFsFiGN6L4teuOGiDxAXFcs30haIuIO1ax56ZU3CKJQpMfoPBt82aKuSwPx4Ug9X/s1600/image17.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiqRGpn0jG-3ZAawJVolo4v0AnRlvfUn9UP9e4iHI6vJtaAUubWdT3Wpha-NuyRB2Z89YFUccZnb1XIA7ZFcQDRf-XWfe4uKuOJMCOWwwfAyjFv9lPROyJqUHBRIFsFiGN6L4teuOGiDxAXFcs30haIuIO1ax56ZU3CKJQpMfoPBt82aKuSwPx4Ug9X/s1600/image17.png\" /></a>     <p>Step one is complete! You\u2019ve created your managed JupyterLab environment. </p><h3>Upload .ipynb file</h3>  <p>Now it\u2019s time to get our TensorFlow code into Google Cloud. If you\u2019ve been working in a different environment (Colab, local, etc), you can upload any code artifacts you need to your Vertex AI Workbench managed notebook, and you can even integrate with GitHub. In the future, you can do all of your development right in Workbench, but for now let\u2019s assume you\u2019ve been using Colab. </p><p>Colab notebooks can be exported as .ipynb files. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5bW86zwVwwlMwJ0vYV_ECnnUj-TWgo70WdxTlob_ozUfYHOind4gZE6kaE6Etz3Phn3Pdk6yGrspi3etzdIXSQLUVK8suEZfqU3BFJCV73peLUSqWKNGDoIP0jaMGW6eTUssRQ12k8KGEhb1cOb3jIv_IJdLoJDLr-eit-A_c_0cSm4hGAK9bk6aa/s1600/image10.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh5bW86zwVwwlMwJ0vYV_ECnnUj-TWgo70WdxTlob_ozUfYHOind4gZE6kaE6Etz3Phn3Pdk6yGrspi3etzdIXSQLUVK8suEZfqU3BFJCV73peLUSqWKNGDoIP0jaMGW6eTUssRQ12k8KGEhb1cOb3jIv_IJdLoJDLr-eit-A_c_0cSm4hGAK9bk6aa/s1600/image10.png\" /></a>  <p>You can upload the file to Workbench by clicking the \u201cupload files\u201d icon. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheg17QjgbIMjvXL62woZRNxGDqQ0IB_yPxiTYL0sOxM73No7rOGspTqg8K5k4SbRAp1Vx1pg7zExC-g1D3sU1dZ9yvvoaBA2XDsJqj2CdQkcv3LfCMZWHbKhYY6niKRdw6q2-e0P7DJun6WTEylNFVRqdXe0qoEtyPcKu1hSCIDQ5BrZYYXRYU3kek/s1600/image6.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEheg17QjgbIMjvXL62woZRNxGDqQ0IB_yPxiTYL0sOxM73No7rOGspTqg8K5k4SbRAp1Vx1pg7zExC-g1D3sU1dZ9yvvoaBA2XDsJqj2CdQkcv3LfCMZWHbKhYY6niKRdw6q2-e0P7DJun6WTEylNFVRqdXe0qoEtyPcKu1hSCIDQ5BrZYYXRYU3kek/s1600/image6.png\" /></a>  <p>When you open the notebook in Workbench, you\u2019ll be prompted to select the kernel, which is the environment where your notebook is run. There are a few different kernels you can choose from, but since this code sample uses TensorFlow, you\u2019ll want to select the TensorFlow 2 kernel.  </p> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbrVCgkT_e1X-tBsCB9MwegaFuxqZx8E91MYC8GRU596yMNkDSG48FjmpPp1W3sZMeeX2NBvUw-0qMO9wfSlnV9gGDkbaqOW1F8tgEzhHLgnxNbvug_0ii1_CC4RnlmgctX9dbpuB_9Y9Do5l9TNsdYnwaBdnnw-ddkRdVc_tdcBk6X5Pdc6BFwLyc/s1600/image14.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhbrVCgkT_e1X-tBsCB9MwegaFuxqZx8E91MYC8GRU596yMNkDSG48FjmpPp1W3sZMeeX2NBvUw-0qMO9wfSlnV9gGDkbaqOW1F8tgEzhHLgnxNbvug_0ii1_CC4RnlmgctX9dbpuB_9Y9Do5l9TNsdYnwaBdnnw-ddkRdVc_tdcBk6X5Pdc6BFwLyc/s1600/image14.png\" /></a>   <p>After you select the kernel, any cells you execute in your notebook will run in this managed TensorFlow environment. For example, if you execute the import cell, you\u2019ll see that you can import TensorFlow, TensorFlow Datasets, and NumPy. This is because all of these libraries are included in the Vertex AI Workbench TensorFlow 2 kernel. Unsurprisingly, if you try to execute that same notebook cell in the XGBoost kernel, you\u2019ll see an error message since TensorFlow is not installed there. </p><h3>Launch a notebook execution</h3>  <p>While we could run the rest of the notebook cells manually, for models that take a long time to train, a notebook isn\u2019t always the most convenient option. And if you\u2019re building an application with ML, it\u2019s unlikely that you\u2019ll only need to train your model once. Over time, you\u2019ll want to retrain your model to make sure it stays fresh and keeps producing valuable results.  </p><p>Manually executing the cells of your notebook might be the right option when you\u2019re getting started with a new machine learning problem. But when you want to automate experimentation at a large scale, or retrain models for a production application, a managed ML training option will make things much easier.  </p><p>The quickest way to launch a training job is through the <a href=\"https://cloud.google.com/blog/products/ai-machine-learning/schedule-and-execute-notebooks-with-vertex-ai-workbench\">notebook execution feature</a>, which will run the notebook cell by cell on the Vertex AI managed training service.  </p><p>When you launch the training job, it\u2019s going to run on a machine you won\u2019t have access to after the job completes. So you don\u2019t want to save the TensorFlow model artifacts to a local path. Instead, you\u2019ll want to save to <a href=\"https://cloud.google.com/storage\">Cloud Storage</a>, which is Google Cloud\u2019s object storage, meaning you can store images, csv files, txt files, saved model artifacts. Just about anything.  </p><p>Cloud storage has the concept of a \u201cbucket\u201d which is what holds your data. You can <a href=\"https://console.cloud.google.com/storage/create-bucket\">create them via the UI</a>. Everything you store in Cloud Storage must be contained in a bucket. And within a bucket, you can create folders to organize your data.  </p><p>Each file in Cloud Storage has a path, just like a file on your local filesystem. Except that Cloud Storage paths always start with <strong><code>gs://</code></strong> <p>You\u2019ll want to update your training code so that you\u2019re saving to a Cloud Storage bucket instead of a local path.  </p><p>For example, here I\u2019ve updated the last cell of the notebook from <code>model.save('model_ouput\").</code>Instead of saving locally, I\u2019m now saving the artifacts to a bucket called <code>nikita-flower-demo-bucket</code> that I\u2019ve created in my project. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj016o6cNcn4wgdZCSRHNk-NXMco53VVl1znMI_KLd8vk7cx9dKB_qXVdKNWn1Vl0xFvXkKaRFkr7r1epgWKshfr_distsHx3kpDXEmhaORIWp7kIhtbek8JbZCcr0ifq9R1xLtoTmU58q8SjJMgCsg5BdRktraQz-lMSAiEB5NUSGAjVD0oCbslQkJ/s1600/image5.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj016o6cNcn4wgdZCSRHNk-NXMco53VVl1znMI_KLd8vk7cx9dKB_qXVdKNWn1Vl0xFvXkKaRFkr7r1epgWKshfr_distsHx3kpDXEmhaORIWp7kIhtbek8JbZCcr0ifq9R1xLtoTmU58q8SjJMgCsg5BdRktraQz-lMSAiEB5NUSGAjVD0oCbslQkJ/s1600/image5.png\" /></a>  <p>Now we\u2019re ready to launch the execution.</p>   <p>Select the Execute button, give your execution a name, then add a GPU. Under Environment, select the TensorFlow 2.7 GPU image. This container comes preinstalled with TensorFlow and many other data science libraries.</p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5I4758rM0cTwHQaF3rvHyvLxTNrmFFmiDBEho2mnHINBanIyVGSkle1ByQaPH6oil_sI-bdAbMNRr_BtaQK3AUXOLFJK9D1Lj5b7GgL9qRpEZSKFybARXLhBzYT6UQZaT56_3r46ocYuobhbNwmXiQ45V2capSE2U3TVaeMwO5H4PtPanBaBSBG_L/s1600/image18.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5I4758rM0cTwHQaF3rvHyvLxTNrmFFmiDBEho2mnHINBanIyVGSkle1ByQaPH6oil_sI-bdAbMNRr_BtaQK3AUXOLFJK9D1Lj5b7GgL9qRpEZSKFybARXLhBzYT6UQZaT56_3r46ocYuobhbNwmXiQ45V2capSE2U3TVaeMwO5H4PtPanBaBSBG_L/s1600/image18.png\" /></a>  <p>Then click <strong>SUBMIT</strong>. </p><p>You can track the status of your training job in the <strong>EXECUTIONS</strong> tab. The notebook and the output of each cell will be visible under <strong>VIEW RESULT</strong> when the job finishes and is stored in a GCS bucket. This means you can always tie a model run back to the code that was executed. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgF8l2FGcd8AORAsZgsVBh4OYTAbLWNK_69Pv2xGrpkUEbvo5no0-uN0X2bVCauEKL2mQNzWw3PyLbf-gN_k--DkGp29cCzRJBEdvuVKK7zdQH2xpBNBN8pm4z6Quo6kh96EztPtUX0BFdHPEvAgFx_jY13PbBBovtU6_Lv9YNi4kgHkx1Rl2Zk0-xw/s1600/image7.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgF8l2FGcd8AORAsZgsVBh4OYTAbLWNK_69Pv2xGrpkUEbvo5no0-uN0X2bVCauEKL2mQNzWw3PyLbf-gN_k--DkGp29cCzRJBEdvuVKK7zdQH2xpBNBN8pm4z6Quo6kh96EztPtUX0BFdHPEvAgFx_jY13PbBBovtU6_Lv9YNi4kgHkx1Rl2Zk0-xw/s1600/image7.png\" /></a>    <p>When the training completes you\u2019ll be able to see the TensorFlow saved model artifacts in your bucket. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBaxFQRaan-EMhe42E7f5vpmhOjW5OesLHf1DfEs9MWf4UMhW_xA7voHpwgTLxditmg8OWty183UzuS7T1cmVRKEiWsVxy_-n8iXRbmRrvzHX2YZAQbSURSuF5-Tg0ytFNBJgs19ltLr5HLEya_eHS9nSU6RxGua6U_6mdmrF5BZ0RMToR4oIKLJ77/s1600/image2.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBaxFQRaan-EMhe42E7f5vpmhOjW5OesLHf1DfEs9MWf4UMhW_xA7voHpwgTLxditmg8OWty183UzuS7T1cmVRKEiWsVxy_-n8iXRbmRrvzHX2YZAQbSURSuF5-Tg0ytFNBJgs19ltLr5HLEya_eHS9nSU6RxGua6U_6mdmrF5BZ0RMToR4oIKLJ77/s1600/image2.png\" /></a>  <h3>Deploy to endpoint</h3>  <p>Now you know how to quickly launch serverless training jobs on Google Cloud. But ML is not just about training. What\u2019s the point of all this effort if we don\u2019t actually use the model to do something, right? </p><p>Just like with training, we could execute predictions directly from our notebook by calling <code>model.predict</code>. But when we want to get predictions for lots of data, or get low latency predictions on the fly, we\u2019re going to need something more powerful than a notebook. </p><p>Back in your Vertex AI Workbench managed notebook, you can paste the code below in a cell, which will use the Vertex AI Python SDK to deploy the model you just trained to the Vertex AI Prediction service. Deploying the model to an endpoint associates the saved model artifacts with physical resources for low latency predictions. </p><p>First, import the <a href=\"https://googleapis.dev/python/aiplatform/latest/index.html\">Vertex AI Python SDK</a>. </p>   <pre class=\"prettyprint\">from google.cloud import aiplatform<br /></pre>  <p>Then, upload your model to the <a href=\"https://cloud.google.com/vertex-ai/docs/model-registry/introduction\">Vertex AI Model Registry</a>. You\u2019ll need to give your model a name, and provide a serving container image, which is the environment where your predictions will run. Vertex AI provides <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\">pre-built containers</a> for serving, and in this example we\u2019re using the TensorFlow 2.8 image.  </p><p> <p>You\u2019ll also need to replace <code>artifact_uri</code> with the path to the bucket where you stored your saved model artifacts. For me, that was \u201cnikita-flower-demo-bucket\u201d. You\u2019ll also need to replace <code>project </code>with your project ID. </p>   <pre class=\"prettyprint\">my_model = aiplatform.Model.upload(display_name='flower-model',<br />                                  artifact_uri='gs://{YOUR_BUCKET}',<br />                                  serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-8:latest',<br />                                  project={YOUR_PROJECT})</pre> <p>Then deploy the model to an endpoint. I\u2019m using default values for now, but if you\u2019d like to learn more about <a href=\"https://cloud.google.com/vertex-ai/docs/general/deployment\">traffic splitting</a>, and <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/configure-compute\">autoscaling</a>, be sure to check out the docs. Note that if your use case does not require low latency predictions, you don\u2019t need to deploy the model to an endpoint and can use the <a href=\"https://cloud.google.com/vertex-ai/docs/predictions/batch-predictions\">batch prediction feature instead</a>. </p>    <pre class=\"prettyprint\">endpoint = my_model.deploy(<br />     deployed_model_display_name='my-endpoint',<br />     traffic_split={\"0\": 100},<br />     machine_type=\"n1-standard-4\",<br />     accelerator_count=0,<br />     min_replica_count=1,<br />     max_replica_count=1,<br />   )<br /></pre>  <p>Once the deployment has completed, you can see your model and endpoint in the console </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_Ui0U3ZY1f9JrgGtsLgpdyJUZF9hk-ZEPsoZcHI5tkEyNEzx5dAA-Kupme8hMu5cWClhY4C3IJE3lrrWQNPtdySFoUXt2_tJUHC6dl6prVDfTFRnIHm1D3YR_l3WQv6iut8N17Pf8tgPI3YMVy1R7IMhD88_yKGjXu-JKCjfDaHl1j8TmLqrG9x0R/s1600/image4.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi_Ui0U3ZY1f9JrgGtsLgpdyJUZF9hk-ZEPsoZcHI5tkEyNEzx5dAA-Kupme8hMu5cWClhY4C3IJE3lrrWQNPtdySFoUXt2_tJUHC6dl6prVDfTFRnIHm1D3YR_l3WQv6iut8N17Pf8tgPI3YMVy1R7IMhD88_yKGjXu-JKCjfDaHl1j8TmLqrG9x0R/s1600/image4.png\" /></a>   <h3>Get predictions</h3>  <p>Now that this model is deployed to an endpoint, you can hit it like any other REST endpoint. This means you can integrate your model and get predictions into a downstream application. </p><p>For now, let\u2019s just test it out directly within Workbench. </p><p>First, open a new TensorFlow notebook. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqGeHRbU8l4f8ebG6ditY8RYgIJz7CmVb5JFySpyps8ErdwDwze3SXwy7XL5FaINc6cvpe3Qr4EnlpxjcWaCfD1Y64n-vN7khhGnNd2zd3_j3Eqa_qb9csHEHElRjaq-5JN6_7sfvHF4tQzHcC-RwF7TrSNTxMvK4xrikJaP9sN7sbDK8dn3Y5kv-b/s1600/image15.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhqGeHRbU8l4f8ebG6ditY8RYgIJz7CmVb5JFySpyps8ErdwDwze3SXwy7XL5FaINc6cvpe3Qr4EnlpxjcWaCfD1Y64n-vN7khhGnNd2zd3_j3Eqa_qb9csHEHElRjaq-5JN6_7sfvHF4tQzHcC-RwF7TrSNTxMvK4xrikJaP9sN7sbDK8dn3Y5kv-b/s1600/image15.png\" /></a>   <p>In the notebook, import the Vertex AI Python SDK. </p>   <pre class=\"prettyprint\">from google.cloud import aiplatform<br /></pre>  <p>Then, create your endpoint, replacing <code>project_number</code> and <code>endpoint_id</code>. </p>   <pre class=\"prettyprint\">endpoint = aiplatform.Endpoint(<br />    endpoint_name=\"projects/{project_number}/locations/us-central1/endpoints/{endpoint_id}\")<br /></pre>  <p>You can find your endpoint_id in the Endpoints section of the cloud Console. </p>  <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgwmebEfdn-7ylHSL4m3u5L6uf2jG3J8cBxGkv1bvKVXkkJIKOovR17otfuXD40mKbYnWoo2pDuZRyvJVnONhsWNUPYdA_a1WmTEjT_mmP3R5g7eVFNFLPJOrVBJaWtDlma7l-nlVhOl8g3Ikhp-CpzWHHVaJ0o5vm_VPXCfXeeOy5ztXrNMHVs9_u4/s1600/image1.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgwmebEfdn-7ylHSL4m3u5L6uf2jG3J8cBxGkv1bvKVXkkJIKOovR17otfuXD40mKbYnWoo2pDuZRyvJVnONhsWNUPYdA_a1WmTEjT_mmP3R5g7eVFNFLPJOrVBJaWtDlma7l-nlVhOl8g3Ikhp-CpzWHHVaJ0o5vm_VPXCfXeeOy5ztXrNMHVs9_u4/s1600/image1.png\" /></a>    <p>You can find your Project Number on the home page of the console. Note that this is different from the Project ID. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhCzHklYkMfdNGMXUqAdyd4S4vA3MVj6fnDO5TqTtDboT54__tHTUXQ0mPZoby54ml34CMDDH6qD5FJLLAczlZuKm9DP17L4EB-lDgUOBRw1al0yf5p0JbV4jmtZ9pSDNmy5_i0J7nR2N-Sp3lUJ8ZeCGo4TY73ZrN8R5agNLQkGLZAgzjsnusiMxls/s1600/image19.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhCzHklYkMfdNGMXUqAdyd4S4vA3MVj6fnDO5TqTtDboT54__tHTUXQ0mPZoby54ml34CMDDH6qD5FJLLAczlZuKm9DP17L4EB-lDgUOBRw1al0yf5p0JbV4jmtZ9pSDNmy5_i0J7nR2N-Sp3lUJ8ZeCGo4TY73ZrN8R5agNLQkGLZAgzjsnusiMxls/s1600/image19.png\" /></a>  <p>When you send a request to an online prediction server, the request is received by an HTTP server. The HTTP server extracts the prediction request from the HTTP request content body. The extracted prediction request is forwarded to the serving function. The basic format for online prediction is a list of data instances. These can be either plain lists of values or members of a JSON object, depending on how you configured your inputs in your training application. </p><p>To test the endpoint, I first uploaded an image of a flower to my workbench instance. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgO_nfBF4Wa-7o472Juo5vpaJn9bA-kEVXSndD4toP4xDdCOudnsOlQ9_VCYpO0PA3zcaHXDvz_zHa4A2H-ObvKboyuCB6OxcMp-HAyD9S5eiovzzAWwv3xfP_f6nkCEUOV1Ilv-tfJdjnCcm1N9SmgiGaFk_bUXkF7DmSOAljgXc4WwrUBL1-3O0a4/s1600/image11.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgO_nfBF4Wa-7o472Juo5vpaJn9bA-kEVXSndD4toP4xDdCOudnsOlQ9_VCYpO0PA3zcaHXDvz_zHa4A2H-ObvKboyuCB6OxcMp-HAyD9S5eiovzzAWwv3xfP_f6nkCEUOV1Ilv-tfJdjnCcm1N9SmgiGaFk_bUXkF7DmSOAljgXc4WwrUBL1-3O0a4/s1600/image11.png\" /></a>  <p>The code below opens and resizes the image with PIL, and converts it into a numpy array.  </p>   <pre class=\"prettyprint\">import numpy as np<br />from PIL import Image<br /><br />IMAGE_PATH = 'test_image.jpg'<br /><br />im = Image.open(IMAGE_PATH)<br />im = im.resize((150, 150))<br /></pre>  <p>Then, we convert our numpy data to type float32 and to a list. We convert to a list because numpy data is not JSON serializable so we can\u2019t send it in the body of our request. Note that we <em>don\u2019t</em> need to scale the data by 255 because that step was included as part of our model architecture using <code>tf.keras.layers.Rescaling(1./255). </code>To avoid having to resizing our image, we could have added<code> tf.keras.layers.Resizing</code> to our model, instead of making it part of the <code>tf.data </code>pipeline. </p>   <pre class=\"prettyprint\"># convert to float32 list<br />x_test = [np.asarray(im).astype(np.float32).tolist()]<br /></pre>  <p>Then, we call call predict </p>   <pre class=\"prettyprint\">endpoint.predict(instances=x_test).predictions<br /></pre>  <p>The result you get is the output of the model, which is a softmax layer with 5 units.  Looks like class at index 2 (tulips) scored the highest. </p>   <pre class=\"prettyprint\">[[0.0, 0.0, 1.0, 0.0, 0.0]]<br /></pre>  <p>Tip: to save costs, be sure to undeploy your endpoint if you\u2019re not planning to use it!  You can undeploy by going to the Endpoints section of the console, selecting the endpoint and then the <strong>Undeploy model form endpoint</strong> option. You can always redeploy in the future if needed. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg6NzTUpvH0NXX8GnSuN0fmgnOSKkBUhCVDhZ02_JHwvBbzVz0gKdwVjHS_MT6-UlMpt8tpj0DwSmUOt2IUxbAEgIuCNa24_DISvI274gMiDM6oCIvBI9t1joLh7whUyqHzTFO3Mbzf8nrUMrHcKTx2M7i5D6lfys2HuBfJNTWyqtCScPiHO6qEt9mo/s1600/image12.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg6NzTUpvH0NXX8GnSuN0fmgnOSKkBUhCVDhZ02_JHwvBbzVz0gKdwVjHS_MT6-UlMpt8tpj0DwSmUOt2IUxbAEgIuCNa24_DISvI274gMiDM6oCIvBI9t1joLh7whUyqHzTFO3Mbzf8nrUMrHcKTx2M7i5D6lfys2HuBfJNTWyqtCScPiHO6qEt9mo/s1600/image12.png\" /></a>  <p>For more realistic examples, you\u2019ll probably want to directly send the image itself to the endpoint, instead of loading it in NumPy first. If you\u2019d like to see an example, <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_tf_serving_function.ipynb\">check out this notebook.</a></p><h3>What\u2019s Next</h3>  <p>You now know how to get from notebook experimentation to deployment in the cloud. With this framework in mind, I hope you start thinking about how you can build new ML applications with notebooks and Vertex AI. <br /><br />If you\u2019re interested in learning even more about how to use Google Cloud to get your TensorFlow models into production, be sure to register for the upcoming Google Cloud <a href=\"https://cloudonair.withgoogle.com/events/summit-applied-ml-2022?utm_source=cgc-blog&amp;utm_medium=blog&amp;utm_campaign=FY22-Q2-global-EXPMKT14-onlineevent-er-applied-ml-summit-2022-main&amp;utm_content=tensorflow_blog&amp;utm_term=-\">Applied ML Summit. </a> This virtual event is scheduled for 9th June and brings together the world\u2019s leading professional machine learning engineers and data scientists. Connect with other ML engineers and data scientists and discover new ways to speed up experimentation, quickly get into production, scale and manage models, and automate pipelines to deliver impact. <a href=\"https://cloudonair.withgoogle.com/events/summit-applied-ml-2022\">Reserve your seat today!</a></p>",
            "pubdate": "Wed, 25 May 2022 16:04:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                25
            ],
            "email_sent": true
        },
        "New documentation on tensorflow.org": {
            "url": "https://blog.tensorflow.org/2022/06/new-documentation-on-tensorfloworg.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgAojM5Hs8D3sh_arXYrTDG6wOCUAJeF3atUeHVLyoHRh5GTBxaSimWiMmRc2-ot6rfY5R7aE-_axl51X9CyCqQDst4FyW55HlZ7MR6SG3qjpET9KaZdOz0hhii5li4l1CtgeoSQ7uGrzXVAJ98ZZ7uBt-PZ71fzCKI3FNKgUuE7iR1-fk8ohnZnzbI/s1600/output_1iFcAD0WF78p_3.png\" style=\"display: none;\" />  <p><em>Posted by the TensorFlow team</em></p><p>     <a name=\"more\"></a><p></p>   <p>As <a href=\"https://blog.tensorflow.org/2022/05/ai-and-machine-learning-io-recap.html\">Google I/O</a> took place, we published a lot of exciting new docs on <a href=\"https://www.tensorflow.org/\">tensorflow.org</a>, including updates to model parallelism and model remediation, <a href=\"https://www.tensorflow.org/lite\">TensorFlow Lite</a>, and the <a href=\"https://github.com/tensorflow/models\">TensorFlow Model Garden</a>. Let's take a look at what new things you can learn about! </p><h4>Counterfactual Logit Pairing</h4>  <p>The Responsible AI team added a new model remediation technique as part of their <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation\">Model Remediation</a> library. The TensorFlow Model Remediation library provides training-time techniques to intervene on the model such as  changing the model itself by introducing or altering model objectives.  Originally, model remediation launched with its first technique, <a href=\"https://blog.tensorflow.org/2020/11/applying-mindiff-to-improve-model.html\">MinDiff</a>, which minimizes the difference in performance between two slices of data. </p><p>New at I/O is <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview\">Counterfactual Logit Pairing (CLP)</a>.  This is a technique that seeks to ensure that a model\u2019s prediction doesn\u2019t change when a sensitive attribute referenced in an example is either removed or replaced. For example, in a toxicity classifier, examples such as \"I am a man\" and \"I am a lesbian\" should be equal and not classified as toxic. </p><p>Check out the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_usage_steps\">basic tutorial</a>, the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_keras\">Keras tutorial</a>, and the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/api_docs/python/model_remediation/counterfactual\">API reference</a>. </p><h4>Model parallelism: DTensor</h4>  <p>DTensor provides a global programming model that allows developers to operate on tensors globally while managing distribution across devices. DTensor distributes the program and tensors according to the sharding directives through a procedure called <em><a href=\"https://en.wikipedia.org/wiki/SPMD\">Single program, multiple data (SPMD)</a> expansion</em>.   </p><p>By decoupling the overall application from sharding directives, DTensor enables running the same application on a single device, multiple devices, or even multiple clients, while preserving its global semantics.  If you remember Mesh TensorFlow from TF1, DTensor can address the same issue that Mesh addressed:  training models that may be larger than a single core. </p><p>With TensorFlow 2.9, we made DTensor, that had been in nightly builds, visible on <a href=\"https://www.tensorflow.org/\">tensorflow.org</a>.  Although DTensor is experimental, you're welcome to try it out. Check out the <a href=\"https://www.tensorflow.org/guide/dtensor_overview\">DTensor Guide</a>, the <a href=\"https://www.tensorflow.org/tutorials/distribute/dtensor_keras_tutorial\">DTensor Keras Tutorial</a>, and the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/dtensor\">API reference</a>. </p><h4>New in TensorFlow Lite</h4>  <p>We made some big changes to the TensorFlow Lite site, including to the getting started docs. </p><h5>Developer Journeys</h5>  <p>First off, we now organize the developer journeys by platform (Android, iOS, and other edge devices) to make it easier to get started with your platform.  Android gained a new <a href=\"https://www.tensorflow.org/lite/android\">learning roadmap</a> and <a href=\"https://www.tensorflow.org/lite/android/quickstart\">quickstart</a>.  We also earlier added a guide to the new beta for <a href=\"https://www.tensorflow.org/lite/android/play_services\">TensorFlow Lite in Google Play services</a>.  These quickstarts include examples in both Kotlin and Java, and upgrade our example code to <a href=\"https://developer.android.com/training/camerax\">CameraX</a>, as recommended by our colleagues in Android developer relations! </p><p>If you want to immediately run an Android sample, one can now be imported directly from Android studio.  When starting a new project, choose: <strong>New Project > Import Sample...</strong> and look for <strong>Artificial Intelligence > TensorFlow Lite in Play Services</strong> image classification example application.  This is the sample that can help you find your mug...or other objects: </p>    <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitL9xenSIzgEVUPOUhPMlczODfKKR08sF-icqlPfB4QmCD5dMaP4aQifb18ZDU5E2PtkuU6yonEbTXVIurMmGCWIJjyw0Upz_UD6rKeBB0tygva8DoOVCKuOSUAnImPbpoz8r114ew1Ejhuk-mFfDZNSZXkbfMWuMF3rgr-qiNIjjEdM2kcUy0Cho6/s1600/app_gif.gif\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEitL9xenSIzgEVUPOUhPMlczODfKKR08sF-icqlPfB4QmCD5dMaP4aQifb18ZDU5E2PtkuU6yonEbTXVIurMmGCWIJjyw0Upz_UD6rKeBB0tygva8DoOVCKuOSUAnImPbpoz8r114ew1Ejhuk-mFfDZNSZXkbfMWuMF3rgr-qiNIjjEdM2kcUy0Cho6/s1600/app_gif.gif\" /></a>     <h4>Model Maker</h4>  <p>The <a href=\"https://www.tensorflow.org/lite/guide/model_maker\">TensorFlow Lite Model Maker</a> library simplifies the process of training a TensorFlow Lite model using custom datasets. It uses transfer learning to reduce the amount of training data required and reduce training time, and comes pre-built with seven common tasks including image classification, object detection, and text search. </p><p>We added a new tutorial for <a href=\"https://www.tensorflow.org/lite/tutorials/model_maker_text_searcher\">text search</a>.  This type of model lets you take a text query and search for the most related entries in a text dataset, such as a database of web pages.  On mobile, you might use this for auto reply or semantic document search. </p><p>We also published the full <a href=\"https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker\">Python library reference</a>.   </p><h4>TF Lite model page</h4>  <p>Finding the right model for your use case can sometimes be confusing. We've written <a href=\"https://www.tensorflow.org/lite/models\">more guidance</a> on how to choose the right model for your task, and what to consider to make that decision.You can also find links to models for common use cases. </p><h3>Model Garden: State of the art models ready to go</h3>  <p>The <a href=\"https://www.tensorflow.org/guide/model_garden\">TensorFlow Model Garden</a> provides implementations of many state-of-the-art machine learning (ML) models for vision and natural language processing (NLP), as well as workflow tools to let you quickly configure and run those models on standard datasets.  The Model Garden covers both vision and text tasks, and a flexible training loop library called Orbit. Models come with pre-built configs to train to state-of-the-art, as well as many useful specialized ops.  </p><p>We're just getting started documenting all the great things you can do with the Model Garden.  Your first stops should be the <a href=\"https://www.tensorflow.org/guide/model_garden\">overview</a>,  <a href=\"https://github.com/tensorflow/models/tree/master/official\">lists of available models</a>, and <a href=\"https://www.tensorflow.org/tutorials/images/classification_with_model_garden\">the image classification tutorial</a>.  </p><h3>Other exciting things!</h3>  <p>Don't miss the crown-of-thorns starfish detector!  Find your own COTS on real images from the Great Barrier reef.  See the <a href=\"https://www.youtube.com/watch?v=5OuHe_skk0M\">video</a>, read the <a href=\"https://blog.tensorflow.org/2022/05/Kaggle-Great-Barrier-Reef-ML.html\">blog post</a>, and <a href=\"https://colab.research.google.com/github/tensorflow/models/blob/master/official/projects/cots_detector/crown_of_thorns_starfish_detection_pipeline.ipynb\">try out the model</a> in Colab yourself. </p><p>Also, there is a new tutorial on <a href=\"https://www.tensorflow.org/tutorials/generative/data_compression\">TensorFlow compression</a>, which does lossy compression using neural networks.  This example uses something like an autoencoder to compress and decompress MNIST. </p><p>    <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgAojM5Hs8D3sh_arXYrTDG6wOCUAJeF3atUeHVLyoHRh5GTBxaSimWiMmRc2-ot6rfY5R7aE-_axl51X9CyCqQDst4FyW55HlZ7MR6SG3qjpET9KaZdOz0hhii5li4l1CtgeoSQ7uGrzXVAJ98ZZ7uBt-PZ71fzCKI3FNKgUuE7iR1-fk8ohnZnzbI/s1600/output_1iFcAD0WF78p_3.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgAojM5Hs8D3sh_arXYrTDG6wOCUAJeF3atUeHVLyoHRh5GTBxaSimWiMmRc2-ot6rfY5R7aE-_axl51X9CyCqQDst4FyW55HlZ7MR6SG3qjpET9KaZdOz0hhii5li4l1CtgeoSQ7uGrzXVAJ98ZZ7uBt-PZ71fzCKI3FNKgUuE7iR1-fk8ohnZnzbI/s1600/output_1iFcAD0WF78p_3.png\" /></a>               </p><p>And, of course, don't miss all the <a href=\"https://blog.tensorflow.org/2022/05/ai-and-machine-learning-io-recap.html\">great I/O</a> talks you can <a href=\"https://www.youtube.com/watch?v=OMFdgzeZGqU&amp;list=PLQY2H8rRoyvyY0AsvPIkb7rg7ogc5dgXW\">watch on YouTube</a>.  Thank you! </p>",
            "pubdate": "Wed, 01 Jun 2022 20:23:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                1
            ],
            "email_sent": true
        },
        "Memory-efficient inference with XNNPack weights cache": {
            "url": "https://blog.tensorflow.org/2022/06/memory-efficient-inference-with-xnnpack.html",
            "description": "<img src=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\" style=\"display: none;\" /> <p><em>Posted by Zhi An Ng and Marat Dukhan, Google</em><p> <a name=\"more\"></a><p></p> <p><a href=\"https://github.com/google/XNNPACK\">XNNPack</a> is the default TensorFlow Lite CPU inference engine for floating-point models, and <a href=\"https://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html\">delivers meaningful speedups across mobile, desktop, and Web platforms</a>. One of the optimizations employed in XNNPack is repacking the static weights of the Convolution, Depthwise Convolution, Transposed Convolution, and Fully Connected operators into an internal layout optimized for inference computations. During inference, the repacked weights are accessed in a sequential pattern that is friendly to the processors\u2019 pipelines. </p><p>The inference latency reduction comes at a cost: repacking essentially creates an extra copy of the weights inside XNNPack. When the TensorFlow Lite model is memory-mapped, the operating system eventually releases the original copy of the weights and makes the overhead disappear. However, some use-cases require creating multiple copies of a TensorFlow Lite interpreter, each with its own XNNPack delegate, for the same model. As the XNNPack delegates belonging to different TensorFlow Lite interpreters are unaware of each other, every one of them creates its own copy of repacked weights, and the memory overhead grows linearly with the number of delegate instances. Furthermore, since the original weights in the model are static, the repacked weights in XNNPack are also the same across all instances, making these copies wasteful and unnecessary. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0_1yuRglS2gJE3vbjfqhRa7iFDORvqKjNBDG82MoqnFqMIw6CIF7j39LNNVYInCKRWrWJUmbHajUwncM2ZSfN6X4OJSbRFfdySrGSyte2Z9K-cUzMfvRbqXN20J_ZmZQwMRnHdcFL474AJB_-WGjTYumA2K87uIPQeRN30kgKADAT9gqSAWLxNMEm/s1600/image2.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj0_1yuRglS2gJE3vbjfqhRa7iFDORvqKjNBDG82MoqnFqMIw6CIF7j39LNNVYInCKRWrWJUmbHajUwncM2ZSfN6X4OJSbRFfdySrGSyte2Z9K-cUzMfvRbqXN20J_ZmZQwMRnHdcFL474AJB_-WGjTYumA2K87uIPQeRN30kgKADAT9gqSAWLxNMEm/s1600/image2.png\" /></a>   <p>Weights cache is a mechanism that allows multiple instances of the XNNPack delegate accelerating the same model to optimize their memory usage for repacked weights. With a weights cache, all instances use the same underlying repacked weights, resulting in a constant memory usage, no matter how many interpreter instances are created. Moreover, elimination of duplicates due to weights cache may improve performance through increased efficiency of a processor\u2019s cache hierarchy. Note: the weights cache is an opt-in feature available only via the C++ API. </p>    <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNOdfLIzlJZY9Oo8ivGTWLpVNTPiKgDrRkPR3pBo_0pqmpeuyd1Pm-K2F0wRvgzELx-vKyyI-sgYTddVL14L1YyhcJ59hm9dB4DgrlTm0qrOcUsW1fiH5zCXdbFB_NEnX7tVD59LxfibNH702Z59EHY6jTEn-blXwYqlEOqqb6xQwkc3O_lXaCHcJ6/s1600/image3.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiNOdfLIzlJZY9Oo8ivGTWLpVNTPiKgDrRkPR3pBo_0pqmpeuyd1Pm-K2F0wRvgzELx-vKyyI-sgYTddVL14L1YyhcJ59hm9dB4DgrlTm0qrOcUsW1fiH5zCXdbFB_NEnX7tVD59LxfibNH702Z59EHY6jTEn-blXwYqlEOqqb6xQwkc3O_lXaCHcJ6/s1600/image3.png\" /></a>   <p>The chart below shows the high water mark memory usage (vertical axis) of creating multiple instances (horizontal axis). It compares the baseline, which does not use weights cache, with using weights cache with soft finalization. The peak memory usage when using weights cache grows much slower with respect to the number of instances created. For this example, using weights cache allows you to double the number of instances created with the same peak memory budget. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXNXKTze0EiLb2O_RS1jkeDy8k5u5ksYVdJYOndYstPacET-lfeNU_9wyxS9UcMqpHUoiFqxePad3MPXXDRHcXDOYbmA5vAya-aGK5OUS_kS5LTQmqvoPF-eeQ4MInpHHLg0Y4EXJbxPTDAwtnJuN_ioOohKdyp8Ngu8dtQVYgjyM0N8sFrn_fTrfE/s1600/image1.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXNXKTze0EiLb2O_RS1jkeDy8k5u5ksYVdJYOndYstPacET-lfeNU_9wyxS9UcMqpHUoiFqxePad3MPXXDRHcXDOYbmA5vAya-aGK5OUS_kS5LTQmqvoPF-eeQ4MInpHHLg0Y4EXJbxPTDAwtnJuN_ioOohKdyp8Ngu8dtQVYgjyM0N8sFrn_fTrfE/s1600/image1.png\" /></a>  <p>The weights cache object is created by the <code>TfLiteXNNPackDelegateWeightsCacheCreate</code> function, and passed to the XNNPack delegate via the delegate options. XNNPack delegate will then use the weights cache to store repacked weights. Importantly, the weights cache must be finalized before any inference invocation. </p>   <pre class=\"prettyprint\">// Example demonstrating how to create and finalize a weights cache.<br />std::unique_ptr&lt;tflite::Interpreter> interpreter;<br />TfLiteXNNPackDelegateWeightsCache* weights_cache =<br />    TfLiteXNNPackDelegateWeightsCacheCreate();<br />TfLiteXNNPackDelegateOptions xnnpack_options =<br />    TfLiteXNNPackDelegateOptionsDefault();<br />xnnpack_options.weights_cache = weights_cache;<br />TfLiteDelegate* delegate =<br />    TfLiteXNNPackDelegateCreate(&amp;xnnpack_options);<br />if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {<br />    // Static weights will be packed and written into weights_cache.<br />}<br />TfLiteXNNPackDelegateWeightsCacheFinalizeHard(weights_cache);<br /><br />// Calls to interpreter->Invoke and interpreter->AllocateTensors must<br />// be made here, between finalization and deletion of the cache.<br />// After the hard finalization any attempts to create a new XNNPack<br />// delegate instance using the same weights cache object will fail.<br /><br />TfLiteXNNPackWeightsCacheDelete(weights_cache);<br /></pre>  <p>There are two ways to finalize a weights cache, and in the example above we use <code>TfLiteXNNPackDelegateWeightsCacheFinalizeHard</code> which performs <em>hard</em> finalization. The <em>hard</em> finalization has the least memory overhead, as it will trim the memory used by the weights cache to the absolute minimum. However, no new delegates can be created with this weights cache object after the hard finalization - the number of XNNPack delegate instances using this cache is fixed in advance. The other kind of finalization is a <em>soft</em> finalization. Soft finalization has higher memory overhead, as it leaves sufficient space in the weights cache for some internal bookkeeping. The advantage of the soft finalization is that the same weights cache can be used to create new XNNPack delegate instances, provided that the delegate instances use exactly the same model. This is useful if the number of delegate instances is not fixed or known beforehand. </p>   <pre class=\"prettyprint\">// Example demonstrating soft finalization and creating multiple<br />// XNNPack delegate instances using the same weights cache.<br />std::unique_ptr&lt;tflite::Interpreter> interpreter;<br />TfLiteXNNPackDelegateWeightsCache* weights_cache =<br />    TfLiteXNNPackDelegateWeightsCacheCreate();<br />TfLiteXNNPackDelegateOptions xnnpack_options =<br />    TfLiteXNNPackDelegateOptionsDefault();<br />xnnpack_options.weights_cache = weights_cache;<br />TfLiteDelegate* delegate =<br />    TfLiteXNNPackDelegateCreate(&amp;xnnpack_options);<br />if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {<br />    // Static weights will be packed and written into weights_cache.<br />}<br />TfLiteXNNPackDelegateWeightsCacheFinalizeSoft(weights_cache);<br /><br />// Calls to interpreter->Invoke and interpreter->AllocateTensors can<br />// be made here, between finalization and deletion of the cache.<br />// Notably, new XNNPack delegate instances using the same cache can<br />// still be created, so long as they are used for the same model.<br /><br />std::unique_ptr&lt;tflite::Interpreter> new_interpreter;<br />TfLiteDelegate* new_delegate =<br />    TfLiteXNNPackDelegateCreate(&amp;xnnpack_options);<br />if (new_interpreter->ModifyGraphWithDelegate(new_delegate) !=<br />    kTfLiteOk)<br />{<br />    // Repacked weights inside of the weights cache will be reused,<br />    // no growth in memory usage<br />}<br /><br />// Calls to new_interpreter->Invoke and<br />// new_interpreter->AllocateTensors can be made here.<br />// More interpreters with XNNPack delegates can be created as needed.<br /><br />TfLiteXNNPackWeightsCacheDelete(weights_cache);<br /></pre>  <h3>Next steps</h3>  <p>With the weights cache, using XNNPack for batch inference will reduce memory usage, leading to better performance. Read more about how to use weights cache with XNNPack at the <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md\">README</a> and report any issues at <a href=\"https://github.com/google/XNNPACK/issues\">XNNPack's GitHub page</a>. </p><p>To stay up to date, you can read the TensorFlow blog, follow twitter.com/tensorflow, or subscribe to youtube.com/tensorflow. If you\u2019ve built something you\u2019d like to share, please submit it for our Community Spotlight at goo.gle/TFCS. For feedback, please file an issue on GitHub or post to the TensorFlow Forum. Thank you! </p>",
            "pubdate": "Mon, 06 Jun 2022 16:13:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                6
            ],
            "email_sent": true
        },
        "OCR in the browser using TensorFlow.js": {
            "url": "https://blog.tensorflow.org/2022/06/ocr-in-browser-using-tensorflowjs.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhUZjFVuG9BSKB8i2rF2n83tL9sVWXegW2Lu7ia6nSt-L8FWcpzEkP2rBFKMcRCkz5vXW7Ma4dvqgB6xL-AWhFP6HCPZ11Kj_rXyMj7KvARsj2T4POi5RlNuMn7XrhleBAww-TeLdoF3uvv0KSt32TqKaJfP8-gkl3HWLioEYI9jZrjsqlfjjWwrecq/s1600/image3.png\" style=\"display: none;\" /> <p><em>A guest post by <a href=\"https://www.linkedin.com/in/charles-gaillard-1738a614a/\">Charles Gaillard</a>, <a href=\"https://mindee.com/\">Mindee</a></em></p> <a name=\"more\"></a><p></p>  <h3>Introduction</h3>  <p>Optical Character Recognition (OCR) refers to technologies capable of capturing text elements from images or documents and converting them into a machine-readable text format. If you want to learn more on that topic, <a href=\"https://blog.mindee.com/ocr-explained/\">this article</a> is a good introduction. </p><p>At <a href=\"https://mindee.com/\">Mindee</a>, we have developed an open-source Python-based OCR called <a href=\"https://github.com/mindee/doctr\">DocTR</a>, however we also wanted to deploy it in the browser to ensure that it was accessible to all developers - especially as <a href=\"https://insights.stackoverflow.com/survey/2021#most-popular-technologies-language-prof\">~70% developers choose to use JavaScript</a>. <br /><br />We managed to achieve this using the <a href=\"https://js.tensorflow.org/api/latest/\">TensorFlow.js API</a>, which resulted in <a href=\"https://demo-doctr-tensorflowjs.mindee.com/\">a web demo</a> that you can now try for yourself using images of your own. </p>   <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhMI_POfn1KTijChup8uEzoTHu_f-Iej0qEkVEt-HXSo68zYZbDwK3HpO-y1uVk5Oqd0xzzX6fvR4xsYQ3zRsLAo4JdgbywdDqLCfcJyL_GtNmDT4Vx0jceb34a9BrkCmBa9y6_uKhUwPZBaLLyRYqIaalYRdoSPI4GhK3sHV13-Mp2MDm7g15_gnkw/s1600/image3.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">The demo interface with a picture of 2 receipts being parsed by the OCR: 89 words were found here </td></tr></tbody></table> <p>This demo is designed to be very simple to use and run quickly on most computers, therefore we provided a single pretrained model that we trained with a small (512 x 512) input size to save memory. Images are resized to be squares, so it generalizes well to most of the documents which have an aspect ratio close to 1: cards, smaller receipts, tickets, A4, etc. For rectangles with a very high aspect ratio, segmentation results might not be as good because we don\u2019t preserve the aspect ratio (with padding) at the text detection step. It is optimized to work on documents with a significant word size (for example receipts, cards, etc). Keep in mind that these models have been designed to offer performance while running in the browser. Hence, performance might not be optimal on documents that have a very small writing size vs the size of the document or images with a very high aspect ratio. </p><h3>Dive into the architecture</h3>  <p>OCR models can be divided into 2 parts: A detection model and a text recognition model. In DocTR, the detection model is a CNN (convolutional neural network) which segments the input image to find text areas, then text boxes are cropped around each detected word and sent to a recognition model. The second model is a convolutional recurrent neural network (CRNN), which extracts features from word-images and then decodes the sequence of letters on the image with recurrent layers (LSTM). </p>    <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh3BTkF3r714C-R0T3mok-qCUgGYjbVTe896k2TGPc11BGFmi0IX2NSvYnXR8YIpo2ipJrmgWQCf_lB1vpjHqnmsrqtnZKY5OmK-rBq0mUEdv5mnn01yqF8WbueGwybfVpCkcTQH5DbW2iPJqyWVPVZGxTNpkEdSPaRpDZ4kSGdqedJCzpe6-ArkCuu/s1600/image2.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">Global architecture of the OCR model used in this Demo </td></tr></tbody></table>  <h4>Detection model</h4>  <p>We have different architectures implemented in DocTR, but we chose a very light one for use on the client side as device hardware can change from person to person. Here we used a mobilenetV2 backbone with a <a href=\"https://arxiv.org/pdf/1911.08947.pdf\">DB (Differentiable Binarization) head</a>. The implementation details can be found in the <a href=\"https://github.com/mindee/doctr\">DocTR</a> Github. We trained this model with an input size of (512, 512, 3) to decrease latency and memory usage. We have a private dataset composed of 130,000 annotated documents that was used to train this model. </p><h4>Recognition model</h4>  <p>The recognition model we used is also our lighter architecture: a CRNN (convolutional recurrent neural network) with a mobilenetV2 backbone. More information on this architecture can be found <a href=\"https://arxiv.org/pdf/1507.05717.pdf\">here</a>. It is basically composed of the first half of the mobilenetV2 layers to extract features and it is followed by 2 <a href=\"https://medium.com/@raghavaggarwal0089/bi-lstm-bc3d68da8bd0\">bi-LSTMs</a> to decode visual features as character sequences (words). It uses the <a href=\"https://www.cs.toronto.edu/~graves/icml_2006.pdf\">CTC loss</a>, introduced by Alex Graves, to decode a sequence efficiently. We have an input size of (32, 128, 3) for word images in this model, and we use padding to preserve the aspect ratio of crops. It is trained on our private dataset, composed of 11 millions text boxes extracted from different documents. This dataset has a wide variety of fonts, since it is composed of documents which come from many different data sources. We used data augmentation so that it generalizes well on different fonts, backgrounds, and renderings. It should also give decent results on handwritten text as long as it is human-readable. </p><h3>Model conversion & code implementation</h3>  <p>As our model was originally implemented using TensorFlow, Python conversion was required to run the resulting models in the web browser at scale. To do this we exported a tensorflow <code>SavedModel</code> for each Python model trained and used the <code><a href=\"https://www.tensorflow.org/js/guide/conversion\">tensorflowjs_converter command line tool</a></code> to quickly convert our saved models to the TensorFlow.js JSON format required for execution in the browser.  <p>The resulting converted models were then integrated into our <a href=\"https://reactjs.org\">React.js</a> front end application that powered the user interface of the <a href=\"https://demo-doctr-tensorflowjs.mindee.com/\">demo</a>. More precisely, we used <a href=\"https://mui.com/\">MUI</a> to design the components of the interface for our in-house front-end SDK <a href=\"https://react-mindee-js.netlify.app/\">react-mindee-js</a> (which provides computer vision tools) and <a href=\"https://opencv.org/\">OpenCV.js</a> for the detection model post processing. This post processing step took the raw binarized segmentation map and converted it to a list of polygons with OpenCV.js functions.  We could then crop those boxes from the source image to finally obtain word images ready to be sent to the recognition model. </p><h3>Speed & performance</h3>  <p>We had to manage the tradeoff between speed and performance efficiently. OCR models are quite slow because you have 2 tasks (text areas segmentation + words recognition) that can't be parallelized, so we had to use lightweight models to ensure speedy execution on most devices. <br /><br />On an modern computer with an RTX 2060 and an i7 9th Gen, the detection task takes around 750 milliseconds per image, and the recognition model around 170 milliseconds per batch of 32 crops (words) with the WebGL backend, benchmarked with the <a href=\"https://github.com/tensorflow/tfjs/blob/master/e2e/benchmarks/local-benchmark/README.md\">TensorFlow.js benchmarking tool</a>. </p><p>Wrapping up the 2 models and the vision operations (detection post processing), the end-to-end OCR runs in less than 2 seconds on small documents (less than 100 words) and the prediction time can only take a few seconds more to run on very dense documents with a lot of words. </p>   <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjYe67hhAS-6v1JTtluOekvu72YGChcu0wc3OQlAIFlhSIOZrSWS_vqYMppePEWeuEi5q4xOBLoO3BqSar4PA0dvY9NWCDTY90S0jDhM5CbECshmTlUBjOT8SA_1m4CFxXTM048bbh1FGEa_2eSffkbBEo3GW2pAUdaN0qHcEWeOvH6NRi39_ZDhzZ-/s1600/image1.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjYe67hhAS-6v1JTtluOekvu72YGChcu0wc3OQlAIFlhSIOZrSWS_vqYMppePEWeuEi5q4xOBLoO3BqSar4PA0dvY9NWCDTY90S0jDhM5CbECshmTlUBjOT8SA_1m4CFxXTM048bbh1FGEa_2eSffkbBEo3GW2pAUdaN0qHcEWeOvH6NRi39_ZDhzZ-/s1600/image1.png\" /></a>  <table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjYe67hhAS-6v1JTtluOekvu72YGChcu0wc3OQlAIFlhSIOZrSWS_vqYMppePEWeuEi5q4xOBLoO3BqSar4PA0dvY9NWCDTY90S0jDhM5CbECshmTlUBjOT8SA_1m4CFxXTM048bbh1FGEa_2eSffkbBEo3GW2pAUdaN0qHcEWeOvH6NRi39_ZDhzZ-/s1600/image1.png\" /></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\">A screenshot of the demo interface with a very dense old A4 document being parsed by the OCR: 738 words are identified. </td></tr></tbody></table> <h3>Conclusion</h3>  <p><a href=\"https://demo-doctr-tensorflowjs.mindee.com/\">This demo</a> powered by <a href=\"https://www.tensorflow.org/js\">TensorFlow.js</a> is a way to give access to an online, relatively quick and robust document OCR to almost everyone, which is one of the first of its kind powered by TensorFlow.js entirely in the browser.<br /><br />As we are executing the model on the client side, exact performance will vary depending on the hardware of the device it is run on. However the goal here is more to demonstrate that even complex and state-of-the-art deep learning models can be deployed in the browser and run on almost every machine in an efficient manner that can be very useful, especially for potentially sensitive document information, where you do not want to send the document to the cloud for analysis. </p><p>We are excited to offer this solution for all to use, and keen to follow the future of the Web ML industry, where things will no doubt get faster with time as new web standards like <a href=\"https://www.w3.org/TR/webgpu/\">WebGPU</a> become mainstream and enabled by default on modern web browsers. </p>",
            "pubdate": "Tue, 07 Jun 2022 15:44:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                7
            ],
            "email_sent": true
        },
        "Adding Quantization-aware Training and Pruning to the TensorFlow Model Garden": {
            "url": "https://blog.tensorflow.org/2022/06/Adding-Quantization-aware-Training-and-Pruning-to-the-TensorFlow-Model-Garden.html",
            "description": "<p><em>Posted by Jaehong Kim, Rino Lee, and Fan Yang, Software Engineers</em></p><p>   </p><a name=\"more\"></a><p></p> <p>The <a href=\"https://www.tensorflow.org/model_optimization\" target=\"_blank\">TensorFlow model optimization toolkit</a> (TFMOT) provides modern optimization techniques such as quantization aware training (QAT) and pruning. Since the <a href=\"https://blog.tensorflow.org/2018/09/introducing-model-optimization-toolkit.html\" target=\"_blank\">introduction</a> of TFMOT, we have been continuously improving its usability and coverage. Today, we are excited to announce that we are extending the TFMOT model coverage to popular computer vision models in the TensorFlow <a href=\"https://github.com/tensorflow/models\" target=\"_blank\">Model Garden</a>. </p><p>To do so, we added <a href=\"https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/quantization/keras/default_8bit\" target=\"_blank\">8-bit QAT API support</a> for subclassed models and custom layers, and <a href=\"https://www.tensorflow.org/model_optimization/api_docs/python/tfmot/sparsity/keras/PrunableLayer#get_prunable_weights\" target=\"_blank\">Pruning API support</a>. You can use these new features in the model garden, and when developing your own models as well. With this, we have showcased applying QAT and pruning to several canonical computer vision models, while accelerating the model development cycle significantly. </p><p>In this article, we will describe the technical challenges we encountered to apply QAT and pruning to the subclass models and custom layers. And show the optimized results to show the benefits from optimization techniques. </p><h3>New support for Model Garden models</h3>  <h4>Quantization</h4>  <p>We have resolved a few technical challenges to support subclassed models and simplified the process of applying QAT API. All the new changes have already been taken care of by TFMOT and Model Garden to save users from knowing all technical details. The final user-facing API to apply QAT on a computer vision model in Model Garden is quite straightforward. By applying <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/configs/experiments/image_classification/imagenet_mobilenetv2_qat_gpu.yaml#L30-L31\" target=\"_blank\">a few configuration changes</a>, you can enable QAT to finetune a pre-trained model and obtain a deployable on-device model in just a few hours. There is minimal to no code change at all. Here we will talk about those challenges and how we addressed them. </p><p>The previous QAT API assumed that the model only contained built-in layers. To support nested functional models, we apply the QAT method to different parts of the model individually. For example, to apply QAT to an image classification model (M) in the Model Garden that consists of two sub modules: the backbone network (B) and the classification head (C). Here B is a nested model within M, and C is a layer. Both B and C only contain built-in layers. Instead of directly quantizing the entire classification model M, we quantize the backbone B and classification head C individually. First, we apply QAT to backbone B only. Then we connect the quantized backbone B to its corresponding classification head C to form a new classification model, and annotate C to be quantized. Finally, we quantize the entire new model, which effectively applies QAT to the annotated classification head C.  </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto; text-align: center;\"><tbody><tr><td style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiUG8GI1S4QmJU2L4Ei5QG_ByJZD2eZsU86h7yfmsjoRqpXrekX6lDsUHsx5_JiilOLk8RgOBRSDuabwUgFmzx5VXRelmk1HWurMgjTu_hSorImB71bdN-wbMIebYjdC_YSDl7CAKeKoWQIq5E9Km-a7dbbjZ-OgFCFOs6_gF_QA_RFQ-l8w_53JPu/s1600/image1.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiiUG8GI1S4QmJU2L4Ei5QG_ByJZD2eZsU86h7yfmsjoRqpXrekX6lDsUHsx5_JiilOLk8RgOBRSDuabwUgFmzx5VXRelmk1HWurMgjTu_hSorImB71bdN-wbMIebYjdC_YSDl7CAKeKoWQIq5E9Km-a7dbbjZ-OgFCFOs6_gF_QA_RFQ-l8w_53JPu/s1600/image1.png\" /></a></div></td></tr></tbody></table> <p>When the backbone network also contains custom layers rather than built-in layers, we add quantized versions of those custom layers first. For example, if the backbone network (B) or the classification head (C) of the classification model (M) also contain a custom layer called <span style=\"color: #38761d; font-family: courier;\">MyLayer</span>, we create its QAT counterpart called <span style=\"color: #38761d; font-family: courier;\">MyLayerQuantized</span> and wrap any built-in layers within it by a quantize wrapper API. We do this recursively if there are any nested custom layers, until all built-in layers are properly wrapped. </p><p>The remaining part after applying quantize is loading the weights from the original model because the QAT-applied model contains more parameters due to additional quantization parameters. Our current solution is variable name filtering. We have added a logic to load the weights from the original model to filtered weight from the QAT-applied model to support fine-tuning from pre-trained models. </p><h4>Pruning</h4>  <p>Along with QAT, we provide two Model garden models with pruning, which is another in-training model optimization technique of MOT. Pruning sparsifies (forces a fixed portion of elements to zero) the given model\u2019s weights during training for computation and storage efficiency.  </p><p>Users can easily <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/pruning/configs/experiments/image_classification/imagenet_mobilenetv2_pruning_gpu.yaml#L31-L38\" target=\"_blank\">set pruning parameters in Model Garden configs</a>. For better pruned model quality, starting pruning from a pre-trained dense model and careful tuning pruning schedule over training steps are well-known techniques. Both are available in Model Garden Pruning configs.  </p><p>This work also provides an example of nested functional layer support in pruning. The way we used here using <span style=\"color: #38761d; font-family: courier;\">get_prunable_weight</span><span style=\"color: #38761d; font-family: courier;\">()</span> is also applicable to any other Keras models with custom layers.  </p><p>With the provided two Model Garden Pruning configs, users can quickly demonstrate pruning to ResNet50 and MobileNetV2 models for image classification. Understanding the practical usage of Pruning API and the pruning process by monitoring tensorboard are also another takeaways of this work. </p><h3>Examples and Results</h3>  <p>We support two tasks, image classification and semantic segmentation. Specifically, for QAT in image classification, we support the common MobileNet family, including <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/configs/image_classification.py#L42\" target=\"_blank\">MobileNetV2</a>, <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/configs/image_classification.py#L42\" target=\"_blank\">MobileNetV3</a> (large), <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/configs/image_classification.py#L42\" target=\"_blank\">Multi-Hardware MobileNet</a> (AVG), and <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/configs/image_classification.py#L31\" target=\"_blank\">ResNet</a> (through quantization on common building blocks such as <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/modeling/layers/nn_blocks.py#L425\" target=\"_blank\">InvertedBottleneckBlockQuantized</a> and <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/modeling/layers/nn_blocks.py#L34\" target=\"_blank\">BottleneckBlockQuantized</a>). For QAT in semantic segmentation, we support MobileNetV2 backbone with <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/modeling/layers/nn_layers.py#L676\" target=\"_blank\">DeepLab V3/V3+</a>. For Pruning in image classification we support <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/pruning/configs/image_classification.py#L72\" target=\"_blank\">MobileNetV2</a> and <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/pruning/configs/image_classification.py#L59\" target=\"_blank\">ResNet</a>. Please refer to the documentations of <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/qat/vision/README.md\" target=\"_blank\">QAT</a> and <a href=\"https://github.com/tensorflow/models/blob/master/official/projects/pruning/README.md\" target=\"_blank\">pruning</a> for more details. </p><h4>Create QAT Models using Model Garden</h4>  <p>Using QAT with Model Garden is simple and straightforward. First, we train a floating point model following the standard process of training models using Model Garden. After training converges, we take the best checkpoint as our starting point to apply QAT, analogous to a finetuning stage. Soon, we will obtain a model that is more quantization friendly. Such model then can be converted to a TFLite model for on-device deployment.   </p><p>For image classification, we evaluate the top-1 accuracy on the ImageNet validation set. As shown in Table 1, QAT model consistently outperforms PTQ model by a large margin, which achieves comparable latency. Notably, on models where PTQ fails to produce reasonable results (MobileNetV3), QAT is still capable of generating a strong quantized model with negligible accuracy drop.  </p><p><em>Table 1. Accuracy and latency comparison of supported models for ImageNet classification. Latency is measured on a Samsung Galaxy S21 using 1-thread CPU. FP32 refers to the unquantized floating point TFLite  model. PTQ INT8 refers to full integer post-training quantization. QAT INT8 refers to the quantized QAT model.</em></p><div align=\"center\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border-collapse: collapse; border: none;\">        <tbody>            <tr style=\"height: 49.5pt;\">                <td rowspan=\"2\" style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">model</span></p>                </td>                <td rowspan=\"2\" style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: xx-small; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">reso-</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: xx-small; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">lution</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\"><br /></td>                <td colspan=\"6\" style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">TFLite Model</span></p>                </td>            </tr>            <tr style=\"height: 49.5pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 7.5pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 accuracy</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 accuracy (FP32)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 accuracy (PTQ INT8)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 accuracy (QAT INT8)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Latency (FP32, ms/img)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Latency (PTQ</span><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">INT8, ms/img)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: black; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Latency (QAT INT8, ms/img)</span></p>                </td>            </tr>            <tr style=\"height: 49.5pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">ResNet50</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">224x224</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">76.7</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">76.7</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">76.4</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">77.2</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">184.01</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">48.73</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">64.49</span></p>                </td>            </tr>            <tr style=\"height: 48.75pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">MobileNet V2</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">224x224</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">72.8</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">72.8</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">72.4</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">72.8</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">16.74</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">6.85</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">6.84</span></p>                </td>            </tr>            <tr style=\"height: 48.75pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: white; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">MobileNet V3 Large</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">224x224</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.1</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.1</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">34.5*</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">74.4</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">13.32</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">6.43</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">6.85</span></p>                </td>            </tr>            <tr style=\"height: 49.5pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">MobileNet Multi-HW AVG</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">224x224</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.3</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.2</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">73.5</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.1</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">20.97</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">7.73</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">7.73</span></p></td></tr></tbody></table></div><p><em>* PTQ fails to quantize MobileNet V3 properly due to hard-swish activation, thus leading to low accuracy.</em></p><p>We have a similar observation on semantic segmentation: PTQ introduces 1.3 mIoU drop, compared to FP32 model, while QAT model minimizes the drop to just 0.7 and maintains comparable latency. On average, we expect QAT will only introduce 0.5 top-1 accuracy drop for image classification and less than 1 mIoU drop for semantic segmentation. </p><p><em>Table 2. Accuracy and latency comparison of a MobileNet v2 + DeepLab v3 on Pascal VOC segmentation. Latency is measured on a Samsung Galaxy S21 using 1-thread CPU. FP32 refers to the unquantized floating point TFLite  model. PTQ INT8 refers to full integer post-training quantization. QAT INT8 refers to the quantized QAT model.</em></p><div align=\"center\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border-collapse: collapse; border: none;\">        <tbody>            <tr style=\"height: 49.5pt;\">                <td rowspan=\"2\" style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">model</span></p>                </td>                <td rowspan=\"2\" style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 8pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">reso-</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 8pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">lution</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\"><br /></td>                <td colspan=\"6\" style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">TFLite Model</span></p>                </td>            </tr>            <tr style=\"height: 49.5pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 7pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">mIoU</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">mIoU (FP32)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">mIoU (PTQ</span><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">INT8)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">mIoU (QAT INT8)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Latency (FP32, ms/img)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Latency (PTQ</span><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\"><br /></span><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">INT8, ms/img)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Latency (QAT INT8, ms/img)</span></p>                </td>            </tr>            <tr style=\"height: 49.5pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">MobileNet v2 + DeepLab v3</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">512x512</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.27</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.30</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">73.95</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">74.68</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">136.60</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">60.94</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: middle;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">55.53</span></p></td></tr></tbody></table></div><h4>Pruning Models in Model Garden</h4>  <p>We support ResNet50 and MobileNet V2 for image classification. Pretrained dense models for each task are generated using the Model Garden training configs. The pruned model can be converted to the TFLite model. By simply setting a flag for sparsity in TFLite conversion, one can get a benefit of model size reduction through sparse data format.  </p><p>For image classification, we again evaluate the top-1 accuracy on the ImageNet validation set, as well as the size of converted TFLite models. As sparsity level increases, the model size becomes more compact but accuracy degrades. The accuracy impact in high sparsity is more severe in parameter-efficient models like MobileNetV2.  </p><p><em>Table 3. Accuracy and model size comparison of ResNet-50 and MobileNet v2 for ImageNet classification. Model size is measured by disk usage of saved TFLite models. Dense refers to the unpruned TFLite model, and 50% sparsity refers to the TFLite model with all prunable layers\u2019 weights randomly pruned 50% of their elements. </em></p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border-collapse: collapse; border: none;\">        <tbody>            <tr style=\"height: 41.25pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Model</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto, sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10px; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Reso</span><span face=\"Roboto, sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 10px; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">lution</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 Accuracy (Dense)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 Accuracy (50% sparsity)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Top-1 Accuracy (80% sparsity)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">TFLite Model size (Dense)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">TFLite Model size (Mb, 50% sparsity)</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">TFLite Model size (Mb, 80% sparsity)</span></p>                </td>            </tr>            <tr style=\"height: 30pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">MobileNet V2</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 8pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">224x224</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">72.768%</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">71.334%</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">61.378%</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">13.36 Mb</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">9.74 Mb</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4.00 Mb</span></p>                </td>            </tr>            <tr style=\"height: 30pt;\">                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">ResNet50</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 8pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">224x224</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">76.704%</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">76.61%</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">75.508%</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">97.44 Mb</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">70.34 Mb</span></p>                </td>                <td style=\"background-color: white; border-color: rgb(32, 33, 36); border-style: solid; overflow: hidden; padding: 3pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span face=\"Roboto,sans-serif\" style=\"background-color: transparent; color: #202124; font-size: 9pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">28.35 Mb</span></p>                </td>            </tr>        </tbody>    </table></div><h3 style=\"text-align: left;\">Conclusions</h3><p>We have presented an extension to TFMOT that offers QAT and pruning support for computer vision models in Model Garden. We highlight the ease of use and outstanding trade-offs about maintaining accuracy while keeping low latency or small model size. </p><p>While we believe this is a simple and user-friendly solution to enable QAT and pruning, we know this is just the beginning of streamlined works to provide even better usability.  </p><p>Currently, supported tasks are limited to image classification and semantic segmentation. We will continue to add more support to other tasks, such as object detection and instance segmentation. We will also add more models, such as transformer based models, and improve the usability of TFMOT and Model Garden\u2019s API. Thanks for your interest in this work.  </p><h3>Acknowledgements </h3>  <p>We would like to thank everyone who contributed to this work, including Model Garden, Model Optimization, and our collaborators from Research. Special thanks to David Rim (emeritus), Ethan Kim (emeritus) from the Model Optimization team; Abdullah Rashwan, Xianzhi Du, Yeqing Li, Jaeyoun Kim, Jing Li from the Model Garden team; Yuqi Li from the on-device ML team. </p><p></p><p></p><p></p>",
            "pubdate": "Thu, 09 Jun 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        },
        "Profiling XNNPACK with TFLite": {
            "url": "https://blog.tensorflow.org/2022/06/Profiling-XNNPACK-with-TFLite.html",
            "description": "<p><em>Posted by Alan Kelly, Software Engineer</em></p><p> </p><a name=\"more\"></a><p></p> <p>We are happy to share that detailed <a href=\"https://www.tensorflow.org/lite/performance/measurement\" target=\"_blank\">profiling information</a> for XNNPACK is now available in TensorFlow 2.9.1 and later. <a href=\"https://github.com/google/XNNPACK\" target=\"_blank\">XNNPACK</a> is a highly optimized library of floating-point neural network inference operators for ARM, WebAssembly, and x86 platforms, and it is the default TensorFlow Lite CPU inference engine for floating-point models. </p><p>The most common and expensive neural network operators, such as fully connected layers and convolutions, are executed by XNNPACK so that you get the best performance possible from your model. Historically the profiler would measure the runtime for the entire section of delegated graph, meaning that the runtime of all delegated operators was accumulated in one result, making it difficult to identify the individual operations that were slow.  </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiGaMOZjmmcdeCHArC2JZGpTO3nsFS6Pdv4_mR7Krfqjyw5hbMWoy1TBJkDg5h9P62LPDIXoaPvj8NdwcszzXK_IhsS3Z39jx-q25Ud-Os7ShQkm2YjIhNX0Bn8R3Cfa-hcz_jZXvF_a8W9tpE2PDiX9A5d32qkAgfNpled0X_1DJuxHfoFOOtMdC4b/s1600/image6.png\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiGaMOZjmmcdeCHArC2JZGpTO3nsFS6Pdv4_mR7Krfqjyw5hbMWoy1TBJkDg5h9P62LPDIXoaPvj8NdwcszzXK_IhsS3Z39jx-q25Ud-Os7ShQkm2YjIhNX0Bn8R3Cfa-hcz_jZXvF_a8W9tpE2PDiX9A5d32qkAgfNpled0X_1DJuxHfoFOOtMdC4b/s1600/image6.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: left;\"><i>Previous TFLite profiling results when XNNPACK was used. The runtime of all delegated operators was accumulated in one row.</i></span></td></tr></tbody></table><p></p><p></p><p>If you are using TensorFlow Lite 2.9.1 or later, it gives the per operator profile even for the section that is delegated to XNNPACK so that you no longer need to decide between fast inference and detailed performance information. The operator name, data layout (NHWC for example), datatype (FP32) and microkernel type (if applicable) are shown.  </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjC4hVKqTuz3ZI3BDW-N9XFOthfw0GAmJrCuh0QCjgXglrO69vef8Nzj8-o9NZjF5sW9_mvqg3fQa8PuQO1b14ITkAcMx2cjqfcXKAnU3CpF7L_JE7qyjt8F-SmVXS-Foug7IKB7bYpknoYu1GWhyJqey-ZLL44YtitJyBrGYbYLCLU8p1VyqKjecm_/s1563/image2.png\" style=\"margin-left: auto; margin-right: auto;\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjC4hVKqTuz3ZI3BDW-N9XFOthfw0GAmJrCuh0QCjgXglrO69vef8Nzj8-o9NZjF5sW9_mvqg3fQa8PuQO1b14ITkAcMx2cjqfcXKAnU3CpF7L_JE7qyjt8F-SmVXS-Foug7IKB7bYpknoYu1GWhyJqey-ZLL44YtitJyBrGYbYLCLU8p1VyqKjecm_/s16000/image2.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: start;\"><i>New detailed per-operator profiling information is now shown. The operator name, data layout, data type and microkernel type are visible.</i></span></td></tr></tbody></table><div style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both; text-align: left;\">Now, you get lots of helpful information, such as the runtime per operator and the percentage of the total runtime that it accounts for. The runtime of each node is given in the order in which they were executed. The most expensive operators are also listed.</div></div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjszotPDs2GEy4drnKKcO1gPTCmmEYpf60Yk3iTA2MCogHpXF-pBWUYsH__DIoFkWhJisBBTP6uebX3MAyC0XFthmV5vcGFBndJF0L1EodeESG4tMJ9uY9z0IjotVNySAjcghi40WGRLZOFyneNB2J96pXlMEMXijMxRikoT68yzL1j1jgBMygupjWV/s1600/image3.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjszotPDs2GEy4drnKKcO1gPTCmmEYpf60Yk3iTA2MCogHpXF-pBWUYsH__DIoFkWhJisBBTP6uebX3MAyC0XFthmV5vcGFBndJF0L1EodeESG4tMJ9uY9z0IjotVNySAjcghi40WGRLZOFyneNB2J96pXlMEMXijMxRikoT68yzL1j1jgBMygupjWV/s1600/image3.png\" /></a></div></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: left;\"><i>The most expensive operators are listed. In this example, you can see that a deconvolution accounted for 33.91% of the total runtime.</i></span></td></tr></tbody></table><p></p><p></p><p> XNNPACK can also perform inference in half-precision (16 bit) floating point format if the hardware supports these operations natively, and IEEE16 inference is supported for every floating-point operator in the model, and the model\u2019s `reduced_precision_support` metadata indicates that it is compatible with FP16 inference. FP16 inference can also be forced. More information is available <a href=\"https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/xnnpack/README.md#floating-point-ieee-fp16-operators-experimental\" target=\"_blank\">here</a>. If half precision has been used, then F16 will be present in the Name column:</p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxQNnx-7gGV730igjxQLFBYhj8EH9B7FXaiRmJ61E2bD5lDfpwJ_6UFC0ViXc_EdjX4bpuxJkSDfhrRuHvu9UB0-GRYsyF9co3aqIpYBDyh2wQVq0_7yKDaFGwSN2om7c18piUo_6SYD5uU6N4J1yzzjiBbeM4u1krWhzTOTkiuHlNCi1NUUSxp3a6/s1600/image5.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxQNnx-7gGV730igjxQLFBYhj8EH9B7FXaiRmJ61E2bD5lDfpwJ_6UFC0ViXc_EdjX4bpuxJkSDfhrRuHvu9UB0-GRYsyF9co3aqIpYBDyh2wQVq0_7yKDaFGwSN2om7c18piUo_6SYD5uU6N4J1yzzjiBbeM4u1krWhzTOTkiuHlNCi1NUUSxp3a6/s1600/image5.png\" /></a></div></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: left;\"><i>FP16 inference has been used.</i></span></td></tr></tbody></table><p></p><p></p><p> Here, unsigned quantized inference has been used (QU8).</p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5mSDtQ3FzM_t0tuazFhgIEOdjRhbZG_ReGkegnKKmqfIeEXAzVwS3Xcl-SPFz6EoBFsgx2SlZWWOJ5wMOg-Jra8_hvZjAE_9eAB-3XVgDcv2qOHYDPqMzk7XIynvAA2qMWAEwPWgjwh5uaWpVePcHG4UyxXU7kjPI7VqaLBf0zh5WOlugtT7boDdN/s1600/TF%20Blog.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj5mSDtQ3FzM_t0tuazFhgIEOdjRhbZG_ReGkegnKKmqfIeEXAzVwS3Xcl-SPFz6EoBFsgx2SlZWWOJ5wMOg-Jra8_hvZjAE_9eAB-3XVgDcv2qOHYDPqMzk7XIynvAA2qMWAEwPWgjwh5uaWpVePcHG4UyxXU7kjPI7VqaLBf0zh5WOlugtT7boDdN/s1600/TF%20Blog.png\" /></a></div></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: left;\"><i>QU8 indicates that unsigned quantized inference has been used</i></span></td></tr></tbody></table><p></p><p></p><p>  And finally, sparse inference has been used. Sparse operators require that the data layout change from NHWC to NCHW as this is more efficient. This can be seen in the operator name.</p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhJW-1poK1ASuATN0IjayI53Hj6OYeyWvsuQdPOitXVjNbtdJiMpOK6jQVAK5QBTyeoCvsiZqMG93SrA9NZNyk2hVHEWWgF_7PILtAIdgBIAni-UWivl07GhDxYqYzMt8hDsO1PbjVMsaBgGIet5oTcbe0kijN9t-QIqtdIYVStmIExc_RaSZoOCng1/s1600/image1.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhJW-1poK1ASuATN0IjayI53Hj6OYeyWvsuQdPOitXVjNbtdJiMpOK6jQVAK5QBTyeoCvsiZqMG93SrA9NZNyk2hVHEWWgF_7PILtAIdgBIAni-UWivl07GhDxYqYzMt8hDsO1PbjVMsaBgGIet5oTcbe0kijN9t-QIqtdIYVStmIExc_RaSZoOCng1/s1600/image1.png\" /></a></div></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: left;\"><i>SPMM microkernel indicates that the operator is evaluated via SParse matrix-dense Matrix Multiplication. Note that sparse inference use NCHW layout (vs the typical NHWC) for the operators.</i></span></td></tr></tbody></table><p></p><p></p><p>Note that when some operators are delegated to XNNPACK, and others aren\u2019t, two sets of profile information are shown. This happens when not all operators in the model are supported by XNNPACK. The next step in this project is to merge profile information from XNNPACK operators and TensorFlow Lite into one profile.</p><h2><strong>Next Steps</strong></h2>  <p>You can learn more about performance measurement and profiling in TensorFlow Lite by visiting this <a href=\"https://www.tensorflow.org/lite/performance/measurement\" target=\"_blank\">guide</a>. Thanks for reading!</p><br />",
            "pubdate": "Wed, 15 Jun 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                15
            ],
            "email_sent": true
        },
        "Bringing Machine Learning to every developers toolbox": {
            "url": "https://blog.tensorflow.org/2022/06/ bringing-machine-learning-to-every-developers-toolbox.html",
            "description": "<p><em>Posted by Laurence Moroney and <a href=\"https://twitter.com/random_forests\">Josh Gordon</a> for the TensorFlow team</em></p><p> </p><a name=\"more\"></a><p></p> <p style=\"text-align: left;\">With the release of the recent <a href=\"https://survey.stackoverflow.co/2022/#most-loved-dreaded-and-wanted-misc-tech-want\" target=\"_blank\">Stack Overflow Developer Survey</a>, we\u2019re delighted to see the growth of TensorFlow as <a href=\"https://survey.stackoverflow.co/2022/#most-popular-technologies-misc-tech\" target=\"_blank\">the most-used ML tool</a>, being adopted by 3 million software developers to enhance their products and solutions using Machine Learning. And we\u2019re only getting started \u2013 the survey showed that TensorFlow was the <a href=\"https://survey.stackoverflow.co/2022/#most-loved-dreaded-and-wanted-misc-tech-want\" target=\"_blank\">most wanted</a> framework amongst developers, with an estimated 4 million developers wanting to adopt it in the near future.</p><p style=\"text-align: left;\"></p>TensorFlow is now being downloaded over 18M times per month and has amassed 166k stars on GitHub \u2013 more than any other ML framework. Within Google, it powers virtually all AI production workflows, including Search, Ads, YouTube, GMail, Maps, Play, Photos, and many more. It also powers production systems at many of the largest companies in the world \u2013 Apple, Netflix, Stripe, Tencent, Uber, Roche, LinkedIn, Twitter, Baidu, Orange, LVMH, and countless others. And every month, over 3,000 new scientific publications that mention TensorFlow or Keras are being indexed by Google Scholar, including important applied science like the <a href=\"https://candle.cels.anl.gov/\">CANDLE</a> research into understanding cancer.<div><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglKMff39bQMNWFnXhr8C3F8ICwnNyKup_rQBU6X5v9fAtlyfFQ8GdltFJ1yvkx-alW7fRBwUrQIBPWNYQwRnQt6DmA-GHJAIDIPmLrqUZuMtZHGqiTklYbKPCzFkYGKUi0vqJDSsZH4xYqL2g4uPYsCZhk4JQuepVbMV60Q93VeHiP38ELbOEKgAfh/s1080/TF%20Logo%20(1080%20%C3%97%20400%20px).png\" style=\"margin-left: 1em; margin-right: 1em; text-align: center;\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEglKMff39bQMNWFnXhr8C3F8ICwnNyKup_rQBU6X5v9fAtlyfFQ8GdltFJ1yvkx-alW7fRBwUrQIBPWNYQwRnQt6DmA-GHJAIDIPmLrqUZuMtZHGqiTklYbKPCzFkYGKUi0vqJDSsZH4xYqL2g4uPYsCZhk4JQuepVbMV60Q93VeHiP38ELbOEKgAfh/s16000/TF%20Logo%20(1080%20%C3%97%20400%20px).png\" /></a>We continue to grow the family of products and open source services that make up the Google AI/ML ecosystem. In recent years, we learned that a single universal framework could not work for all scenarios \u2013 in particular, the needs of production and cutting edge research are often in conflict. So we created JAX, a minimalistic API for distributed numerical computing to power the next era of scientific computing research. JAX is excellent for pushing new frontiers: reaching new scales of parallelism, advancing new algorithms and architectures, and developing new compilers and systems. The adoption of JAX by researchers has been exciting, and advances such as <a href=\"https://www.deepmind.com/research/highlighted-research/alphafold\" target=\"_blank\">AlphaFold</a> and <a href=\"https://imagen.research.google/\" target=\"_blank\">Imagen</a> underscore this. <p>In this new multi-framework world, TensorFlow is our answer to the needs of applied ML developers \u2013 engineers who need to build and deploy reliable, stable, performant ML systems, at any scale, and for any platform.&nbsp;Our vision is to create a cohesive ecosystem where researchers and engineers can leverage components that work together regardless of the framework where they originated. We've already made strides towards JAX and TensorFlow interoperability, in particular via <a href=\"https://github.com/google/jax/tree/main/jax/experimental/jax2tf\">jax2tf</a>. Researchers who develop JAX models will be able to bring them to production via the tools of the TensorFlow platform.</p><p>Going forward, we intend to continue to develop TensorFlow as the best-in-class platform for applied ML, side-by-side with JAX to push the boundaries of ML research. We will continue to invest in both ML frameworks to drive forward research and applications for our millions of users. </p><p>There\u2019s lots of great stuff baking that we can\u2019t wait to share with you, so watch this blog for more details! </p><p>PS: Interested in working on any of our AI and ML frameworks? We're <a href=\"https://careers.google.com/\" target=\"_blank\">hiring</a>.  </p></div>",
            "pubdate": "Mon, 27 Jun 2022 19:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                27
            ],
            "email_sent": true
        },
        "How Roboflow enables thousands of developers to use computer vision with TensorFlow.js": {
            "url": "https://blog.tensorflow.org/2022/07/how-roboflow-enables-thousands-of-developers-to-use-computer-vision-with-TensorFlow.js.html",
            "description": "<p><em>A guest post by <a href=\"https://twitter.com/braddwyer\" target=\"_blank\">Brad Dwyer</a>, co-founder and CTO, Roboflow</em></p><p> </p><a name=\"more\"></a><p></p> <p><a href=\"https://roboflow.com\" target=\"_blank\">Roboflow</a> lets developers build their own computer vision applications, from data preparation and model training to deployment and active learning. Through building <a href=\"https://twitter.com/braddwyer/status/910030265006923776\" target=\"_blank\">our own applications</a>, we learned firsthand how tedious it can be to train and deploy a computer vision model. That\u2019s why we launched Roboflow in January 2020 \u2013 we believe every developer should have computer vision available in their toolkit. Our mission is to remove any barriers that might prevent them from succeeding. </p><p>Our end-to-end computer vision platform simplifies the process of collecting images, creating datasets, training models, and deploying them to production. Over 100,000 developers build with Roboflow\u2019s tools. TensorFlow.js makes up a core part of<a href=\"https://docs.roboflow.com/inference\" target=\"_blank\"> Roboflow's deployment stack</a> that has<a href=\"https://blog.roboflow.com/computer-vision-datasets-and-apis/\" target=\"_blank\"> now powered over 10,000 projects</a> created by developers around the world. </p><p>As an early design decision, we decided that, in order to provide the best user experience, we needed to be able to run users' models directly in their web browser (along with our API, edge devices, and on-prem) instead of requiring a round-trip to our servers. The three primary concerns that motivated this decision were latency, bandwidth, and cost. </p><p>For example, Roboflow powers<a href=\"https://spelltable.wizards.com/\" target=\"_blank\"> SpellTable</a>'s<a href=\"https://twitter.com/SpellTable/status/1491877698293092352\" target=\"_blank\"> Codex</a> feature which uses a computer vision model to identify <em>Magic: The Gathering</em> cards. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhRIq1GZCW_M4yiPxRQqUfY9TAGkxrRZ_s3peedpES5VyFHkMOK-eVumBaW-pwoE_A3Q9IX_ar4Zp9HzDoQdxX4W4SgCXjgcKYt3BHjmbWyteaS-GegM9ya8OyzUKIouFq9mqxJcXclzwfsNrQMfcnEBN5ScGfIQuSgka_7kJk9IlEeb4cjqCzrPv0d/s1600/Roboflow%20blog%202.gif\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i>From <a href=\"https://twitter.com/SpellTable/status/1491877698293092352\" target=\"_blank\">Twitter</a></i></td></tr></tbody></table> <h3><strong>How Roboflow Uses TensorFlow.js</strong></h3>  <p>Whenever a user's model finishes<a href=\"https://docs.roboflow.com/train\" target=\"_blank\"> training on Roboflow's backend</a>, the model is converted and automatically converted to support sevel various deployment targets; one of those targets is TensorFlow.js. While TensorFlow.js is not the only way to <a href=\"https://roboflow.com/deploy\" target=\"_blank\">deploy a computer vision model</a> with Roboflow, some ways TensorFlow.js powers features within Roboflow include: </p><h4><strong>roboflow.js</strong></h4>  <p><a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\">roboflow.js</a> is a JavaScript SDK developers can use to integrate their trained model into a web app or Node.js app. Check this video for a quick introduction: </p> <div class=\"separator\" style=\"clear: both; text-align: left;\"></div><h4><strong>Inference Server</strong></h4><p><a href=\"https://github.com/roboflow-ai/inference-server\" target=\"_blank\">The Roboflow Inference Server</a> is a cross-platform microservice that enables developers to self-host and serve their model on-prem. (Note: while not all of Roboflow\u2019s inference servers are TFjs-based, it is one supported means of model deployment.) </p><p>The <a href=\"https://github.com/tensorflow/tfjs/tree/master/tfjs-node\" target=\"_blank\">tfjs-node</a> container runs via Docker and is GPU-accelerated on any machine with CUDA and a compatible NVIDIA graphics card, or using a CPU on any Linux, Mac, or Windows device. </p><h4><strong>Preview</strong></h4>  <p>Preview is an <a href=\"https://blog.roboflow.com/introducing-the-roboflow-inference-widget/\" target=\"_blank\">in-browser widget</a> that lets developers seamlessly test their models on images, video, and webcam streams. </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3fH2YX7U79s6s7RHZJuPlYJcqkc8PB1mGwD5wPlmom2yh3q-3y3vAoaopZ0U-a7RfCAZNCk7KBKt1RDq2refpSuF50oj6vcg6mtEuQP7UwwgodufA2HKB0czwHW1SMSt1uVcsIOH2dfa2Rc6cOqzSR6pmC4YXJW_tHD5LND9j2UszTUYCkn-6kjlH/s1600/Roboflow%20blog%203.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg3fH2YX7U79s6s7RHZJuPlYJcqkc8PB1mGwD5wPlmom2yh3q-3y3vAoaopZ0U-a7RfCAZNCk7KBKt1RDq2refpSuF50oj6vcg6mtEuQP7UwwgodufA2HKB0czwHW1SMSt1uVcsIOH2dfa2Rc6cOqzSR6pmC4YXJW_tHD5LND9j2UszTUYCkn-6kjlH/s1600/Roboflow%20blog%203.png\" /></a></div><h4><strong>Label Assist</strong></h4>  <p>Label Assist is a<a href=\"https://roboflow.com/annotate\" target=\"_blank\"> model-assisted image labeling tool</a> that lets developers use their previous model's predictions as the starting point for annotating additional images. </p><p>One way users leverage Label Assist is in-browser predictions: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjHPQMr2knMeHlXX-bOFrx6XxXKKr-PzTZKVWqJ6ffj_VcuKY-CKta-3GjuXRQZx9MXAc-SHODMqnaNVRG4FcRRkBLgp2h6ZQ18AdE7x56poCzZaUfiJPN0hTuinPuC8nt8qcYMgNej1gjLwKkTm5oQJ52LOkBY0yr-cVXrN0CM4iXFRRXOVCIrfG/s1600/Roboflow%20blog%201.gif\" style=\"display: block; padding: 1em 0; text-align: center; clear: left; float: left;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwjHPQMr2knMeHlXX-bOFrx6XxXKKr-PzTZKVWqJ6ffj_VcuKY-CKta-3GjuXRQZx9MXAc-SHODMqnaNVRG4FcRRkBLgp2h6ZQ18AdE7x56poCzZaUfiJPN0hTuinPuC8nt8qcYMgNej1gjLwKkTm5oQJ52LOkBY0yr-cVXrN0CM4iXFRRXOVCIrfG/s1600/Roboflow%20blog%201.gif\" /></a></div><h3><strong>Why We Chose TensorFlow.js</strong></h3>  <p>Once we had decided we needed to run in the browser, TensorFlow.js was a clear choice. </p><p>Because TFJS runs in our users' browsers and on their own compute, we are able to provide ML-powered features to our full user base of over 100,000 developers, including those on<a href=\"https://roboflow.com/pricing\" target=\"_blank\"> our free Public plan</a>. That simply wouldn't be feasible if we had to spin up a fleet of cloud-hosted GPUs. </p><h3><strong>Behind the Scenes</strong></h3>  <p>To implement<a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\"> roboflow.js</a> with TensorFlow.js was relatively straightforward. </p><p>We had to change a couple of layers in our neural network to<a href=\"https://docs.google.com/spreadsheets/d/1D25XtWaBrmUEErbGQB0QmNhH-xtwHo9LDl59w0TbxrI/edit#gid=0\" target=\"_blank\"> ensure all of our ops were supported</a> on the runtimes we wanted to use, integrate the<a href=\"https://www.npmjs.com/package/@tensorflow/tfjs-converter\" target=\"_blank\"> tfjs-converter</a> into our training pipeline, and port our pre-processing and post-processing code to JavaScript from Python. From there, it was smooth sailing. </p><p>Once we'd built roboflow.js for our customers, we utilized it internally to power features like Preview, <a href=\"https://blog.roboflow.com/announcing-label-assist/\" target=\"_blank\">Label Assist</a>, and one implementation of the Inference Server. </p><h3><strong>Try it Out</strong></h3>  <p>The easiest way to try roboflow.js is by using Preview on<a href=\"https://universe.roboflow.com\" target=\"_blank\"> Roboflow Universe</a>, where we host over 7,000 pre-trained models that our users have shared. Any of these models can be readily built into your applications for things like <a href=\"https://universe.roboflow.com/augmented-startups/playing-cards-ow27d/model/2\" target=\"_blank\">seeing playing cards</a>, <a href=\"https://universe.roboflow.com/surfline/surfer-spotting\" target=\"_blank\">counting surfers</a>, <a href=\"https://universe.roboflow.com/augmented-startups/vehicle-registration-plates-trudk\" target=\"_blank\">reading license plates</a>, and <a href=\"https://universe.roboflow.com/explo1-w7h8c/see-sci\" target=\"_blank\">spotting bacteria under microscope</a>, and more. </p><p>On the Deployment tab of<a href=\"https://universe.roboflow.com/search?q=trained%2520model\" target=\"_blank\"> any project with a trained model</a>, you can drop a video or use your webcam to run inference right in your browser. To see a live in-browser example, give this community created <a href=\"https://universe.roboflow.com/joseph-nelson/mask-wearing/model/11\" target=\"_blank\">mask detector</a> a try by clicking the \u201cWebcam\u201d icon: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSymprLcTpg7tM481QkcQ_gF3rXdwPyNmXehz3q_jq8dxR1_TE4dTi43ayquf9ngWPVEq7YLHJj61y_6BBN-DNreNMJpXAP9_J61FdZTa6haeL6cE-poQ2EwKBv7prPQByMJLZCxXVu4VMuo3bpkwE3F1qstHVKwVFf0CQjmL8VYixS_4a7nUSqLeE/s1600/Roboflow%20blog%205.gif\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgSymprLcTpg7tM481QkcQ_gF3rXdwPyNmXehz3q_jq8dxR1_TE4dTi43ayquf9ngWPVEq7YLHJj61y_6BBN-DNreNMJpXAP9_J61FdZTa6haeL6cE-poQ2EwKBv7prPQByMJLZCxXVu4VMuo3bpkwE3F1qstHVKwVFf0CQjmL8VYixS_4a7nUSqLeE/s1600/Roboflow%20blog%205.gif\" /></a></div><p>To train your own model for a custom use case, you can<a href=\"https://app.roboflow.com\" target=\"_blank\"> create a free Roboflow account</a> to collect and label a dataset, then train and deploy it for use with roboflow.js in a single click. This enables you to use your model wherever you may need.  </p><h4 style=\"text-align: left;\"><strong>About Roboflow</strong></h4><p>Roboflow makes it easy for developers to use computer vision in their applications. Over 100,000 users have built with the company's end-to-end platform for image and video collection, organization, annotation, preprocessing, model training, and model deployment. Roboflow provides the tools for companies to improve their datasets and build more accurate computer vision models faster so their teams can focus on their domain problems without reinventing the wheel on vision infrastructure.  </p><p><a href=\"https://universe.roboflow.com/\" target=\"_blank\">Browse datasets on Roboflow Universe</a></p><p><a href=\"https://docs.roboflow.com/inference/web-browser\" target=\"_blank\">Get started in the Roboflow documentation</a></p><p><a href=\"https://roboflow.com/features\" target=\"_blank\">View all available Roboflow features</a></p><p></p><p></p>",
            "pubdate": "Wed, 27 Jul 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                7,
                27
            ],
            "email_sent": true
        },
        "Load-testing TensorFlow Servings REST Interface": {
            "url": "https://blog.tensorflow.org/2022/07/load-testing-TensorFlow-Servings-REST-interface.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\" style=\"display: none;\" /> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi3AfD6AO48MESlPbfK1z8bQQhkLoaYOP03SeyJwPSrcJb575FYz822YrwZd4x7fMA8YDTUuWZ1ESnQYLNWNR9dVW2F6Mp9p2m_5uIHbvoNiyPFQjGj81nWdb4SvWva0XVCMPG-aVvji5GHJnS61c_SBCRzMg1bZ6TCS8y4TOu2Rv3veCubUUj1HUsc/s1600/TF%20Blog%202.png\" /></a> <p><em>Posted by <a href=\"https://github.com/deep-diver\" target=\"_blank\">Chansung Park</a> and <a href=\"https://github.com/sayakpaul\" target=\"_blank\">Sayak Paul</a> (ML-GDEs)</em></p> <a name=\"more\"></a><p></p> <p>In this post, we\u2019ll share the lessons and findings learned from conducting load tests for an image classification model across numerous deployment configurations. These configurations involve REST-based deployments with TensorFlow Serving. In this way, we aim to equip the readers with a holistic understanding of the differences between the configurations. </p><p>This post is less about code and more about the architectural decisions we had to make for performing the deployments. We\u2019ll first provide an overview of our setup including the technical specifications. We\u2019ll also share our commentaries on the design choices we made and their impact.  </p><h2>Technical Setup</h2>  <p><a href=\"https://www.tensorflow.org/tfx/guide/serving\" target=\"_blank\">TensorFlow Serving</a> is feature-rich and has targeted specifications embedded in its designs (more on this later). For <a href=\"https://cloud.google.com/ai-platform/prediction/docs/online-vs-batch-prediction\" target=\"_blank\">online prediction scenarios</a>, the model is usually exposed as some kind of service.  </p><p>To perform our testing we use a <a href=\"https://arxiv.org/abs/1512.03385\" target=\"_blank\">pre-trained ResNet50 model</a> which can classify a variety of images into different categories. We then serve this model in the following way: </p><ul><blockquote> <li><a href=\"https://www.docker.com/\" target=\"_blank\">Docker</a> to containerize the environment.  </li><li><a href=\"https://kubernetes.io/\" target=\"_blank\">Kubernetes</a> to orchestrate a cluster of container nodes for scalability. We use <a href=\"https://cloud.google.com/kubernetes-engine\" target=\"_blank\">Kubernetes Engine</a> (GKE) to manage this.   </li><li><a href=\"https://github.com/features/actions\" target=\"_blank\">GitHub Actions</a> to automatically roll out deployments on GKE.  </li>  </blockquote></ul><p>Our deployment platform (nodes on the Kubernetes Cluster) is CPU-based. We don\u2019t employ GPUs at any stage of our processes. For this purpose, we can build a CPU-optimized TensorFlow Serving image and take advantage of a few other options which can reduce the latency and boost the overall throughput of the system. We will discuss these later in the post.  </p><p>You can find all the code and learn how the deployments were performed in <a href=\"https://github.com/deep-diver/ml-deployment-k8s-tfserving\" target=\"_blank\">this repository</a>. Here, you\u2019ll find example notebooks and detailed setup instructions for playing around with the code. As such, we won\u2019t be discussing the code line by line but rather shed light on the most important parts when necessary. </p><p>Throughout the rest of this post, we\u2019ll discuss the key considerations for the deployment experiments respective to TensorFlow Serving including its motivation, limitations, and our experimental results.  </p><p><em>With the emergence of serverless offerings like <a href=\"https://cloud.google.com/vertex-ai\" target=\"_blank\">Vertex AI</a>, it has never been easier to deploy models and scale them securely and reliably. These services help reduce the time-to-market tremendously and increase overall developer productivity. That said,  there might still be instances where you\u2019d like more granular control over things. This is one of the reasons why we wanted to do these experiments in the first place. </em></p><h2>Considerations</h2>  <p>TensorFlow Serving has its own sets of constraints and design choices that can impact a deployment. In this section, we provide a concise overview of these considerations.  </p><p><strong>Deployment infrastructure:</strong> We chose GKE because Kubernetes is a standard deployment platform when using GCP, and GKE lets us focus on the ML parts without worrying about the infrastructure since it is a fully managed Google Cloud Platform service. Our main interest is in how to deploy models for CPU-based environments, so we have prepared a CPU-optimized TensorFlow Serving image.  </p><p><strong>Trade-off between more or fewer servers:</strong> We started experiments for TensorFlow Serving setups with the simplest possible VMs equipped with 2vCPU and 4GB RAM, then we gradually upgraded the specification up to 8vCPU and 64GB RAM. On the other hand, we decreased the number of nodes in the Kubernetes cluster from 8 to 2 because it is a trade-off between costs to deploy cheaper servers versus fewer expensive servers.  </p><p><strong>Options to benefit multi-core environments:</strong> We wanted to see if high-end VMs can outperform simple VMs with options to take advantage of the multi-core environment even though there are fewer nodes. To this end, we experimented with a different number <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads\" target=\"_blank\">inter_op_parallelism</a></code> and <code><a href=\"https://www.tensorflow.org/api_docs/python/tf/config/threading/set_intra_op_parallelism_threads\" target=\"_blank\">intra_op_parallelism</a></code> threads for TensorFlow Serving deployment set according to the number of CPU cores.   </p><p><strong>Dynamic batching and other considerations:</strong> Modern ML frameworks such as TensorFlow Serving usually support dynamic batching, initial model warm-up, multiple deployments of multiple versions of different models, and more out of the box. For our purpose of online prediction, we have not tested these features carefully. However, dynamic batching capability is also worth exploring to enhance the performance according to the <a href=\"https://github.com/tensorflow/serving/blob/r2.0/tensorflow_serving/batching/README.md#batch-scheduling-parameters-and-tuning\" target=\"_blank\">official document</a>. We have seen that the default batching configuration could reduce the latency a little even though the results of that are not included in this blog post. </p><h2>Experiments</h2>  <p>We have prepared the following environments. In TensorFlow Serving, the number of <code>intra_op_parallelism</code>_<code>threads</code> is set equal to the number of CPU cores while the number of <code>inter_op_parallelism_threads</code> is set from 2 to 8 for experimental purposes as it controls the number of threads to parallelize the execution of independent operations. Below we provide the details on the adjustments we performed on the number of vCPUs, RAM size, and the number of nodes for each Kubernetes cluster. Note that the number of vCPUs and the RAM size are applicable for the cluster nodes individually.  </p><p>The load tests are conducted using <a href=\"https://locust.io/\" target=\"_blank\">Locust</a>. We have run each load test for 5 minutes. The number of requests are controlled by the number of users, and it depends on the circumstances on the client side. We increased the number of users by one every second up to 150 which we found the handled number of requests reaches the plateau, and the requests are spawned every second to understand how TensorFlow Serving behaves. So you can assume that requests/second doesn't reflect the real-world situation where clients try to send requests at any time. </p><p>We experimented with the following node configurations on a Kubernetes cluster. The configurations are read like so: {num_vcpus_per_node}-{ram}_{num_nodes}: </p><ul style=\"text-align: left;\"> <li><strong>2vCPUs, 4GB RAM, 8 Nodes</strong></li><li><strong>4vCPUs, 8GB RAM, 4 Nodes</strong></li><li><strong>8vCPUs, 16GB RAM, 2 Nodes</strong></li><li><strong>8vCPUs, 64GB RAM, 2 Nodes</strong></li><ul></ul> </ul><p>You can find code for experimenting with these different configurations in the above-mentioned repositories. The deployment for each experiment is provisioned through <a href=\"https://kustomize.io/\" target=\"_blank\">Kustomize</a> to overlay the base configurations, and file-based configurations are injected through <a href=\"https://kubernetes.io/docs/concepts/configuration/configmap/\" target=\"_blank\">ConfigMap</a>. </p><h2>Results </h2>  <p>This section presents the results for each of the above configurations and suggests which configuration is the best based on the environments we considered. As per Figure 1, the best configuration and the environmental setup is observed as 2 nodes, 8 <code>intra_op_parallelism_threads</code>, 8 <code>inter_op_parallelism_threads</code>, 8vCPUs, 16GB RAM based on the result. </p><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN73u2NKv-JzaPZ-NaGtIlNOTYrx_JiQeob2CB1lHbfOoLbjyYsi9GRiV76sxZEeX4M5_0HPjZlawduh1hWdbE5vYkXmmABQkteqKR26EoqJVh26A1K31RNXEV2fAjGUC6flIBDRWb7cZr8mkW4Wiqa3f1Y7cwi3Fb_QpUssA4wp2wGjdmY7kW-aRC/s1600/TF%20Blog%201.png\" style=\"display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgN73u2NKv-JzaPZ-NaGtIlNOTYrx_JiQeob2CB1lHbfOoLbjyYsi9GRiV76sxZEeX4M5_0HPjZlawduh1hWdbE5vYkXmmABQkteqKR26EoqJVh26A1K31RNXEV2fAjGUC6flIBDRWb7cZr8mkW4Wiqa3f1Y7cwi3Fb_QpUssA4wp2wGjdmY7kW-aRC/s1600/TF%20Blog%201.png\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i><span style=\"text-align: start;\">Figure 1: Comparison between different configurations of TensorFlow Serving (</span><a href=\"https://i.ibb.co/wJ42g2Q/download-2.png\" style=\"text-align: start;\">original</a><span style=\"text-align: start;\">).<br /></span></i></td></tr></tbody></table><p>We have observed the following aspects by picking the best options. </p><ul> <li>TensorFlow Serving is more efficient when deployed on fewer, larger (more CPU and RAM) machines, but the RAM capacity doesn\u2019t have much impact on handling more requests. It is important to find the right number of <code>inter_op_parallelism_threads</code> with experimentation. With a higher number the better performance is not always guaranteed even when the nodes are equipped with high-capacity hardware. </li></ul><p>TensorFlow Serving focuses more on reliability than throughput performance. We believe it sacrifices some throughput performance to achieve reliability, but this is the expected behavior of TensorFlow Serving, as stated in the <a href=\"https://www.tensorflow.org/tfx/serving/performance#objectives\" target=\"_blank\">official document</a>. Even though handling as many requests as possible is important, keeping the server as reliable as possible is also substantially important when dealing with a production system.  </p><p>There is a trade-off between performance and reliability, so you must be careful to choose the right one. However, it seems like the throughput performance of TensorFlow Serving is close enough to <a href=\"https://github.com/sayakpaul/ml-deployment-k8s-fastapi\" target=\"_blank\">results from other frameworks such as FastAPI</a>, and if you want to factor in richer features such as dynamic batching and sharing GPU resources efficiently between models, we believe TensorFlow Serving is the right one to choose. </p><h2>Note on gRPC and TensorFlow Serving</h2>  <p>We are dealing with an image classification model for the deployments, and the input to the model will include images. Hence the size of the request payload can spiral up depending on the image resolution and fidelity. Therefore it\u2019s particularly important to ensure the message transmission is as lightweight as possible. Generally, message transmission is quite a bit faster in gRPC than REST. <a href=\"https://blog.dreamfactory.com/grpc-vs-rest-how-does-grpc-compare-with-traditional-rest-apis\" target=\"_blank\">This post</a> provides a good discussion on the main differences between REST and gRPC APIs. </p><p>TensorFlow Serving can <a href=\"https://www.tensorflow.org/tfx/serving/docker\" target=\"_blank\">serve a model with gRPC</a> seamlessly, but comparing the performance of a gRPC API and REST API is non-trivial. This is why we did not include that in this post. The interested readers can check out <a href=\"https://github.com/deep-diver/ml-deployment-k8s-tfserving\" target=\"_blank\">this repository</a> that follows a similar setup but uses a gRPC server instead.  </p><h2>Costs</h2>  <p>We used the <a href=\"https://cloud.google.com/products/calculator\" target=\"_blank\">GCP cost estimator</a> for this purpose. Pricing for each experiment configuration was assumed to be live for 24 hours per month (which was sufficient for our experiments).  </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table style=\"border-collapse: collapse; border: none; width: 468pt;\">        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Machine Configuration (E2 series)</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 700; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Pricing (USD)</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">2vCPUs, 4GB RAM, 8 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">4vCPUs, 8GB RAM, 4 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">8vCPUs, 16GB RAM, 2 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">11.15</span></p>                </td>            </tr>            <tr style=\"height: 0pt;\">                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">8vCPUs, 64GB RAM, 2 Nodes</span></p>                </td>                <td style=\"border-bottom: solid #000000 1pt; border-color: rgb(0, 0, 0); border-left: solid #000000 1pt; border-right: solid #000000 1pt; border-style: solid; border-top: solid #000000 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.2; margin-bottom: 0pt; margin-top: 0pt; text-align: center;\"><span style=\"background-color: transparent; color: black; font-family: Arial; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">18.21</span></p>                </td>            </tr>        </tbody>    </table></div><h2>Conclusion</h2>  <p>In this post, we discussed some critical lessons we learned from our experience of load-testing a standard image classification model. We considered the industry-grade framework for exposing the model to the end-users \u2013 TensorFlow Serving. While our setup for performing the load tests may not fully resemble what happens in the wild, we hope that our findings will at least act as a good starting point for the community. Even though the post demonstrated our approaches with an image classification model, the approaches should be fairly task-agnostic.  </p><p>In the interest of brevity, we didn\u2019t do much to push further the efficiency aspects of the model in both the APIs. With modern CPUs, software stack, and OS-level optimizations, it\u2019s possible to improve the latency and throughput of the model. We redirect the interested reader to the following resources that might be relevant: </p><ul> <li><a href=\"https://huggingface.co/blog/bert-cpu-scaling-part-1\" target=\"_blank\">Scaling up BERT-like model Inference on modern CPU - Part 1</a> </li><li><a href=\"https://huggingface.co/blog/bert-cpu-scaling-part-2\" target=\"_blank\">Scaling up BERT-like model Inference on modern CPU - Part 2</a> </li><li><a href=\"https://cloud.google.com/architecture/load-testing-and-monitoring-aiplatform-models\" target=\"_blank\">Load testing and monitoring AI Platform models </a> </li><li><a href=\"https://cloud.google.com/architecture/best-practices-for-ml-performance-cost\" target=\"_blank\">Best practices for performance and cost optimization for machine learning</a></li></ul><h2>Acknowledgements</h2>  <p>We are grateful to the <a href=\"https://developers.google.com/community/experts\" target=\"_blank\">ML Ecosystem team</a> that provided GCP credits for supporting our experiments. We also thank <a href=\"https://www.linkedin.com/in/hanneshapke\" target=\"_blank\">Hannes Hapke</a> and <a href=\"https://www.linkedin.com/in/robert-crowe\" target=\"_blank\">Robert Crowe</a> for providing us with helpful feedback and guidance.  </p>",
            "pubdate": "Thu, 28 Jul 2022 17:33:00 +0000",
            "pubdate_parsed": [
                2022,
                7,
                28
            ],
            "email_sent": true
        },
        "Training tree-based models with TensorFlow in just a few lines of code": {
            "url": "https://blog.tensorflow.org/2022/08/training-tree-based-models-with-TensorFlow.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEit5NPpiHRl9CeAKbAxAc7-BPlZIdAGyWm4xQOICiq7r-JCaURdQn7x6pzjbz4VyM_PSLBnIVkvOvxf8NUkIE8FgkzvEA8-ALh_DCnGcdjlxjG7V-ko3NFbh8qFM-V_9jcNJqIjQrSf49ydz240yGZyLWEVQ0Oj15HLWexHxeROYjpagMISjvh9FQgr/s1600/TF%20Blog%20Social%20Asset.png\" style=\"display: none;\" /> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjJKKsbTV_o5m76CtyNsZE51uUXZp8Tu-FvDTk568ZwyWqLO6vXRAWt4bBQvCD30ZEfX7z7VGhB_Nmg2529gnspRA-AHNtgN-BHNUEqru8cE75g0GOgIaUCsb9oZzaqu7jDq_s2wMktzP8U_SOuAJOZNNgqVFey1Dm0fWRPws0lfq7b_5JRfQUTK2Xr/s1600/TF%20Blog%20Header.png\"><img border=\"0\" id=\"imgFull\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjJKKsbTV_o5m76CtyNsZE51uUXZp8Tu-FvDTk568ZwyWqLO6vXRAWt4bBQvCD30ZEfX7z7VGhB_Nmg2529gnspRA-AHNtgN-BHNUEqru8cE75g0GOgIaUCsb9oZzaqu7jDq_s2wMktzP8U_SOuAJOZNNgqVFey1Dm0fWRPws0lfq7b_5JRfQUTK2Xr/s1600/TF%20Blog%20Header.png\" /></a>  <p><em>A guest post by Dinko Franceschi, Broad Institute of MIT and Harvard </em></p><p> </p><a name=\"more\"></a><p></p> <p>Kaggle has become the go-to place to practice data science skills and participate in machine learning model-building competitions. This tutorial will provide an easy-to-follow walkthrough of how to get started with a Kaggle notebook using <a href=\"https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\" target=\"_blank\">TensorFlow Decision Forests</a>. It\u2019s a library that allows you to train tree-based models (like random forests and gradient-boosted trees) in TensorFlow. </p><p>Why should you be interested in decision forests? There are roughly two types of Kaggle competitions - and the winning solution (neural networks or decision forests) depends on the kind of data you\u2019re working with.  </p><p>If you\u2019re working with a <em>tabular data problem</em> (these involve training a model to classify data in a spreadsheet which is an extremely common scenario) - the winning solution is often a decision forest. However, if you\u2019re working with a <em>perception problem</em> that involves teaching a computer to see or hear (for example, image classification), the winning model is usually a neural network.  </p><p>Here\u2019s where the good news starts. You can implement a decision forest in TensorFlow with just a few lines of code. This relatively simple model often outperforms a neural network on many Kaggle problems.  </p><p>We will explore the decision forests library with a simple dataset from Kaggle, and we will build our model with <a href=\"https://www.kaggle.com/code/welcome\" target=\"_blank\">Kaggle Kernels</a> which allow you to completely build and train your models online using free cloud compute power - similar to <a href=\"https://colab.research.google.com/\" target=\"_blank\">Colab</a>. The <a href=\"https://www.kaggle.com/elikplim/car-evaluation-data-set\" target=\"_blank\">dataset</a> contains vehicle information such as cost, number of doors, occupancy, and maintenance costs which we will use to assign an evaluation on the car. </p><p>Kaggle Kernels can be accessed through your Kaggle account. If you do not have an account, please begin by <a href=\"http://www.kaggle.com/\" target=\"_blank\">signing up</a>. On the home page, select the \u201cCode\u201d option on the left menu and select \u201cNew Notebook,\u201d which will open a new Kaggle Kernel.  </p><p><br /></p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3sG3tN2tLCgvVQLoeztWlFAMBGfo7xJP84JCBVp-uKBQOxxTYZtdk6OfEluP0i1HTqKHr_xGk9fEJMaflHtGnRrqZI3KF5YR3-9CCgcv5xPMfBFTQj5JwxY0VAW2spwSJoIw0xgTlDpLaEAc9_ir_sRX_cN_Q--dHl3p8oIbVZ9ZdspaC26oG6SpA/s1600/TF%20Kaggle%201.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEj3sG3tN2tLCgvVQLoeztWlFAMBGfo7xJP84JCBVp-uKBQOxxTYZtdk6OfEluP0i1HTqKHr_xGk9fEJMaflHtGnRrqZI3KF5YR3-9CCgcv5xPMfBFTQj5JwxY0VAW2spwSJoIw0xgTlDpLaEAc9_ir_sRX_cN_Q--dHl3p8oIbVZ9ZdspaC26oG6SpA/s1600/TF%20Kaggle%201.png\" /></a></div><p><br /></p><p>Once we have opened a new notebook from Kaggle Kernels, we download the car evaluation dataset to our environment. Click \u201cAdd data\u201d near the top right corner of your notebook, search for \u201ccar evaluation,\u201d and add the dataset. </p><p><br /></p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQcVF5WVpn2cc70uxeEeBlTRwvJvIFMls1k9SkdnUUSB7atP9YKHAfB3_iv7W4wXHR26-ioVECvGtJCnENpalCPwFx7ZTaurZD1S6dD2gbki9I0_6iXPbmqqbUC0EIeO5CEue3SdqydtWWPbN4JkCGkj8d_MhL7ypW-soZUe4UHJOtox-BcxbPerrE/s1600/TF%20Kaggle%202.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQcVF5WVpn2cc70uxeEeBlTRwvJvIFMls1k9SkdnUUSB7atP9YKHAfB3_iv7W4wXHR26-ioVECvGtJCnENpalCPwFx7ZTaurZD1S6dD2gbki9I0_6iXPbmqqbUC0EIeO5CEue3SdqydtWWPbN4JkCGkj8d_MhL7ypW-soZUe4UHJOtox-BcxbPerrE/s1600/TF%20Kaggle%202.png\" /></a></div><p>Now we are ready to start writing code. Install the TensorFlow Decision Forests library and the necessary imports, as shown below. The code in this blog post has been obtained from the Build, train and evaluate models with the TensorFlow Decision Forests<a href=\"https://www.tensorflow.org/decision_forests/tutorials/beginner_colab\"> tutorial</a> which contains additional examples to look at.  </p><pre><code class=\"\u201dlanguage-python\u201d\"><p>!pip install tensorflow_decision_forests</p><p>import numpy as np<br /></p><p>import pandas <br /></p><p>import tensorflow_decision_forests as tfdf</p></code></pre><p>  </p><p>We will now import the dataset. We should note that the dataset we downloaded did not contain headers, so we will add those first based on the information provided on the Kaggle page for the dataset. It is good practice to inspect your dataset before you start working with it by opening it up in your favorite text or spreadsheet editor.  </p><pre><code class=\"\u201dlanguage-python\u201d\"><p>df = pandas.read_csv(\"../input/car-evaluation-data-set/car_evaluation.csv\")</p><p>col_names =['buying price', 'maintenance price', 'doors', 'persons', 'lug_boot', 'safety', 'class']<br /></p><p>df.columns = col_names<br /></p><p>df.head()<br /></p></code></pre><p></p><p>We must then split the dataset into train and test:</p><pre><code class=\"\u201dlanguage-python\u201d\"><p>def split_dataset(dataset, test_ratio=0.30):</p><p>  test_indices = np.random.rand(len(dataset)) &lt; test_ratio<br /></p><p>  return dataset[~test_indices], dataset[test_indices]<br /></p><p><br /></p><p>train_ds_pd, test_ds_pd = split_dataset(df)</p><p>print(\"{} examples in training, {} examples for testing.\".format(<br /></p><p>    len(train_ds_pd), len(test_ds_pd)))<br /></p></code></pre> <p>And finally we will convert the dataset into tf.data format. This is a high-performance format that is used by TensorFlow to train models more efficiently, and with TensorFlow Decision Forests, you can convert your dataset to this format with one line of code:</p><pre><code class=\"\u201dlanguage-python\u201d\"><p><br /></p><p>train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=\"class\")<br /></p><p>test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=\"class\")<br /></p></code></pre> <p>Now you can go ahead and train your model right away by executing the following:</p><pre><code class=\"\u201dlanguage-python\u201d\"><p>model = tfdf.keras.RandomForestModel()</p><p>model.fit(train_ds)<br /></p></code></pre> <p>The library has good defaults which are a fine place to start for most problems. For advanced users, there are lots of options to choose from in the API<a href=\"https://www.tensorflow.org/decision_forests\"> doc</a> as random forests are configurable.</p><p>Once you have trained the model, you can see how it will perform on the test data. </p><pre><code class=\"\u201dlanguage-python\u201d\"><p>model.compile(metrics=[\"accuracy\"])</p><p>print(model.evaluate(test_ds))<br /></p></code></pre> <p>In just a few lines of code, you reached an accuracy of &gt;95% on this small dataset! This is a simple dataset, and one might argue that neural networks could also yield impressive results. And they absolutely can (and do), especially when you have very large datasets (think: hundreds of thousands of examples, or more). However, neural networks require more code and are resource intensive as they require significantly more compute power.</p><h3>Easy preprocessing</h3>  <p>Decision forests have another important advantage: there are fewer steps to preprocess the data. Notice in the code above that you were able to pass a dataset with both categorical and numeric values <em>directly</em> to the decision forests. You did not have to do any preprocessing like normalizing numeric values, converting strings to integers, and one-hot encoding them. This has major benefits. It makes decision forests simpler to work with (so you can train a model quickly), and there is less code that can go wrong. </p><p>Below, you will see some important differences between the two techniques.  </p><h3>Easy to interpret</h3>  <p>A significant advantage of decision forests is that they are easy to interpret. While the pipeline for decision trees differs significantly from that of training neural networks, there are major advantages for selecting these models for a given task. This is because feature importance is particularly straightforward to determine with decision forests (ensemble of decision trees). Notably, the TensorFlow Decision Forests library makes it possible to visualize feature importance with its model plotter function. Let\u2019s see below how this works!  </p><pre><code class=\"\u201dlanguage-python\u201d\"><p>tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)</p></code></pre> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhURgHiyrnk91zqNm68kOLoLN8DKTyJK3b_99D_8b2GK73y7z9F4p9yXr4bYVY-EJ9k2tZBjgr7spniFAUghUgrQZJ9fSIOvsnXLCkFdxyfVE79qx4vZWjISyNUOXlArdEWtba7GM2ZiUhk4amwNY9WWP1MQAmeYk958q6zql81TofdNqllf2NlwqoU/s1600/TF%20Kaggle%205.png\" style=\"display: block; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhURgHiyrnk91zqNm68kOLoLN8DKTyJK3b_99D_8b2GK73y7z9F4p9yXr4bYVY-EJ9k2tZBjgr7spniFAUghUgrQZJ9fSIOvsnXLCkFdxyfVE79qx4vZWjISyNUOXlArdEWtba7GM2ZiUhk4amwNY9WWP1MQAmeYk958q6zql81TofdNqllf2NlwqoU/s1600/TF%20Kaggle%205.png\" /></a></div><p>We see in the root of the tree on the left the number of examples (1728) and the corresponding distribution indicated by the different colors. Here our model is looking at the number of persons that the car can fit. The largest section indicated by green stands for 2 persons and the red for 4 persons. Furthermore, as we go down the tree we continue to see how the tree splits and the corresponding number of examples. Based on the condition, examples are branched to one of two paths. Interestingly, from here we can also determine the importance of a feature by examining all of the splits of a given feature and then computing how much this feature lowered the variance.  </p><h3>Decision Trees vs. Neural Networks </h3>  <p>Neural networks undoubtedly have incredible representation learning capabilities. While they are very powerful in this regard, it is important to consider whether they are the right tool for the problem at hand. When working with neural networks, one must think a lot about how they will construct the layers. In contrast, decision forests are ready to go out of the box (of course, advanced users can tune a variety of parameters). </p><p>Prior to even building a neural network layer by layer, in most cases one must perform feature pre-processing. For example, this could include normalizing the features to have mean around 0 and standard deviation of 1 and converting strings to numbers. This initial step can be skipped right away with Tree-based models which natively handle mixed data.  </p><p>As seen in the code above, we were able to obtain results in just a few steps. Once we have our desired metrics, we have to interpret them within the context of our problem. Perhaps one of the most significant strengths of Decision Trees is their interpretability. We see in the code above the diagrams that were outputted. Starting at the root, we can follow the branches and quickly get a good idea of how the model made its decisions. In contrast, neural networks are a \u201cblack box\u201d that can be difficult to interpret and to explain to a non-technical audience. </p><h3>Learning more</h3>  <p>If you\u2019d like to learn more about TensorFlow Decision Forests, the best place to start is with the<a href=\"https://www.tensorflow.org/decision_forests\" target=\"_blank\"> project homepage</a>. You can also check out this<a href=\"https://blog.tensorflow.org/2021/05/introducing-tensorflow-decision-forests.html\" target=\"_blank\"> previous article</a> for more background. And if you have any questions or feedback, the best place to ask them is on<a href=\"https://discuss.tensorflow.org/\" target=\"_blank\"> https://discuss.tensorflow.org/</a> using the tag \u201ctfdf\u201d. Thanks for reading! </p><p></p><p></p><p></p>",
            "pubdate": "Wed, 03 Aug 2022 19:00:00 +0000",
            "pubdate_parsed": [
                2022,
                8,
                3
            ],
            "email_sent": true
        },
        "Content moderation using machine learning: a dual approach": {
            "url": "https://blog.tensorflow.org/2022/08/content-moderation-using-machine-learning-a-dual-approach.html",
            "description": "<img src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEht0dlvklEzGfGe8X6EHy8fCHtBY4norDtdVs6JJOTEVRVqsU--EBwm6YWxC5c2iRWYdEHKxTnZWI7_3JetB8F3r3K2J3Ep7SMUF_3jlQEmoTuHcCHAz1yRkLUB_8jM2VksCE0w0xXt0ynPcR1ZJHS1LVs7VtJDmDes1AaJZw1tYkGxG_Lxir8lSn0s/s1600/Android-DeepLinksCrashCourse_Pt1_1024x512.png\" style=\"display: none;\" /> <a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjzog6lDA2x_ZqZiRfK4-u1PfKvHiSzO4n_En9df6wT3FtJYdCRpGQjAz6Fi6NxMwgLXhM2WROOELVEzDrPXWTe0vyaLdZryWtgTH34fjZpAF_3sfqqK8dVqDrYlBvMop7RUFNjB50ZRLUIGyCmwvFcGEqZoY1tWu2RevJ0bAjAYj9bjD16B4yhYl4z/s1600/tensorflow-content-moderation-using-machine-learning-a-dual-approach-01.png\"><img border=\"0\" height=\"191\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjzog6lDA2x_ZqZiRfK4-u1PfKvHiSzO4n_En9df6wT3FtJYdCRpGQjAz6Fi6NxMwgLXhM2WROOELVEzDrPXWTe0vyaLdZryWtgTH34fjZpAF_3sfqqK8dVqDrYlBvMop7RUFNjB50ZRLUIGyCmwvFcGEqZoY1tWu2RevJ0bAjAYj9bjD16B4yhYl4z/w686-h191/tensorflow-content-moderation-using-machine-learning-a-dual-approach-01.png\" width=\"686\" /></a> <p><em>Posted by Jen Person, Developer Advocate</em></p><p> </p><a name=\"more\"></a><p></p> <h2>Being kind: a perennial problem</h2>  <p>I've often wondered why anonymity drives people to say things that they'd never dare say in person, and it\u2019s unfortunate that comment sections for videos and articles are so often toxic! If you\u2019re interested in content moderation, you can use machine learning to help detect toxic posts which you consider for removal.  </p><h2>ML for web developers</h2>  <p>Machine learning is a powerful tool for all sorts of natural language-processing tasks, including translation, sentiment analysis, and predictive text. But perhaps it feels outside the scope of your work. After all, when you're building a website in JavaScript, you don't have time to collect and validate data, train a model using Python, and then implement some backend in Python on which to run said model. Not that there's anything wrong with Python\u2013it's just that, if you're a web developer, it's probably not your language of choice. </p><p>Fortunately, <a href=\"https://www.tensorflow.org/js\" target=\"_blank\">TensorFlow.js</a> allows you to run your machine learning model on your website in <a href=\"https://jsisweird.com/\" target=\"_blank\">everybody's favorite language</a>: JavaScript. Furthermore, TensorFlow.js offers several <a href=\"https://github.com/tensorflow/tfjs-models\" target=\"_blank\">pre-trained models</a> for common use cases on the web. You can add the power of ML to your website in just a few lines of code! There is even a pre-trained model to help you moderate written content, which is what we're looking at today. </p><h2>The text toxicity classifier ML model</h2>  <p>There is an existing pretrained model that works well for content moderation: the <a href=\"https://github.com/tensorflow/tfjs-models/tree/master/toxicity\" target=\"_blank\">TensorFlow.js text toxicity classifier model</a>. With this model, you can evaluate text on different labels of unwanted content, including identity attacks, insults, and obscenity. You can try out <a href=\"https://storage.googleapis.com/tfjs-models/demos/toxicity/index.html\" target=\"_blank\">the demo</a> to see the classifier in action. I admit that I had a bit of fun testing out what sort of content would be flagged as harmful. For example: </p> <div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiIuGhiE2jKW5V6XkKoGVmRQRgivcMN_guzKClgY133bEvkLH94m6L_ETzXupMWWHJWrKUgvygL52BlPZSdMJWAGn2JyzetFVa1D6sdxjAEQ5J3UXuWEiq1a5uNazaAFGoH9euRMkxTXZzUhlbcHpXDoXKke5u5-Gcu1YjP7pRAwNpcs1lmFtCA3eSt/s1600/TF%20Blog%201%20copy.png\" style=\"clear: left; display: block; float: left; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiIuGhiE2jKW5V6XkKoGVmRQRgivcMN_guzKClgY133bEvkLH94m6L_ETzXupMWWHJWrKUgvygL52BlPZSdMJWAGn2JyzetFVa1D6sdxjAEQ5J3UXuWEiq1a5uNazaAFGoH9euRMkxTXZzUhlbcHpXDoXKke5u5-Gcu1YjP7pRAwNpcs1lmFtCA3eSt/s1600/TF%20Blog%201%20copy.png\" /></a></div><p>I recommend stopping here and playing around with the text toxicity classifier demo. It's a good idea to see what categories of text the model checks for and determine which ones you would want to filter from your own website. Besides, if you want to know what categories the above quote got flagged for, you'll have to go to the demo to read the headings. </p><p>Once you've hurled sufficient insults at the text toxicity classifier model, come back to this blog post to find out how to use it in your own code. </p><h2>A dual approach</h2>  <p>This started as a single tutorial with client and server-side code, but it got a bit lengthy so I decided to split it up. Separating the tutorials also makes it easier to target the part that interests you if you just want to implement one part. In this post, I cover the implementation steps for <strong>client-side</strong> moderation with TensorFlow.js using a basic website. In part 2, I show how to implement the same model <strong>server-side</strong> using Cloud Functions for Firebase. </p><h2>Client-side moderation</h2>  <p>Moderating content client-side provides a quicker feedback loop for your users, allowing you to stop harmful discourse before it starts. It can also potentially save on backend costs since inappropriate comments don't have to be written to the database, evaluated, and then subsequently removed. </p><h3>Starter code</h3>  <p>I used the <a href=\"https://github.com/firebase/functions-samples/tree/main/text-moderation\" target=\"_blank\">Firebase text moderation example</a> as the foundation of my demo website. It looks like this: </p><div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjSH4Omn4E0kp2CPMrT7XaHt9TNrkltPFlA-sEJhT8Du8cN9FUI_d2iO45Q4WbgfgV0tQU15y9rKkhcIp0-q4fs2jEQHyjNuWRPc0znnOLKUWp-sHt5Zd0bp8fMdj8hS2Jc3nzUwlPrRI-fg4WhlrzOwEjv-k_7FrF7-SvJ6ZS60CwH8XtikZcYOS3W/s1600/TF%20Blog%202%20copy.png\" style=\"clear: left; display: block; float: left; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjSH4Omn4E0kp2CPMrT7XaHt9TNrkltPFlA-sEJhT8Du8cN9FUI_d2iO45Q4WbgfgV0tQU15y9rKkhcIp0-q4fs2jEQHyjNuWRPc0znnOLKUWp-sHt5Zd0bp8fMdj8hS2Jc3nzUwlPrRI-fg4WhlrzOwEjv-k_7FrF7-SvJ6ZS60CwH8XtikZcYOS3W/s1600/TF%20Blog%202%20copy.png\" /></a></div><p>Keep in mind TensorFlow.js doesn't require Firebase. You can use whatever hosting, database, and backend solutions that work best for your app's needs. I just tend to use Firebase because I'm pretty familiar with it already. And quite frankly, TensorFlow.js and Firebase work well together! The website in the Firebase demo showcases content moderation through a basic guestbook using a server-side content moderation system implemented through a <a href=\"https://firebase.google.com/docs/database/extend-with-functions\" target=\"_blank\">Realtime Database-triggered Cloud Function</a>. Don't worry if this sounds like a lot of jargon. I'll walk you through the specifics of what you need to know to use the TensorFlow.js model in your own code. That being said, if you want to build this specific example I made, it's helpful to take a look at the <a href=\"https://github.com/firebase/functions-samples/tree/main/text-moderation\" target=\"_blank\">Firebase example on GitHub</a>. </p><p>If you're building the example with me, clone the <a href=\"https://github.com/firebase/functions-samples\" target=\"_blank\">Cloud Functions samples</a> repo. Then change to the directory of the text moderation app. </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">cd text</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">-</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">moderation</span></span></p>                </td>            </tr>        </tbody>    </table></div><p>This project requires you to have the<a href=\"https://firebase.google.com/docs/cli\" target=\"_blank\"> Firebase CLI</a> installed. If you don't have it, you can install it using the following npm command: </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">npm install&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">-</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">g firebase</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">-</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">tools</span></span></p>                </td>            </tr>        </tbody>    </table></div><p>Once installed, use the following command to log in: </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: black; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">firebase login</span></p>                </td>            </tr>        </tbody>    </table></div><p>Run this command to connect the app to your Firebase project: </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">firebase&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">use</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">--</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">add</span></span></p>                </td>            </tr>        </tbody>    </table></div><p>From here, you can select your project in the list, connect Firebase to an existing Google Cloud project, or create a new Firebase project. Once the project is configured, use the following command to deploy Realtime Database security rules and Firebase Hosting:</p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">firebase deploy&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">--</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">only database</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">,</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">hosting</span></span></p>                </td>            </tr>        </tbody>    </table></div><p>There is no need to deploy Cloud Functions at this time since we will be changing the sample code entirely. </p><p>Note that the Firebase text moderation sample as written uses the <a href=\"https://firebase.google.com/docs/projects/billing/firebase-pricing-plans#blaze-pricing-plan\" target=\"_blank\">Blaze (pay as you go)</a> plan for Firebase. If you choose to follow this demo including the server-side component, your project might need to be upgraded from Spark to Blaze. If you have a billing account set on your project through Google Cloud, you are already upgraded and good to go! Most importantly, if you're not ready to upgrade your project, then do not deploy the Cloud Functions portion of the sample. You can still use the <strong>client-side moderation without Cloud Functions</strong>. </p><p>To implement client-side moderation in the sample, I added some code to the <code><span style=\"font-family: courier;\">index.html</span></code> and <code><span style=\"font-family: courier;\">main.js</span></code> files in the Firebase text moderation example. There are three main steps to implement when using a TensorFlow.js model: installing the required components, loading the model, and then running the prediction. Let's add the code for each of these steps. </p><h3>Install the scripts</h3>  <p>Add the required TensorFlow.js dependencies. I added the dependencies as script tags in the HTML, but you can <a href=\"https://www.tensorflow.org/js/guide/nodejs\">use Node.js</a> if you use a bundler/transpiler for your web app. </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;!-- &nbsp;index.html --&gt;</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;!-- scripts for TensorFlow.js --&gt;</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #00796b; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;script</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;src</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs/dist/tf.min.js\"</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #00796b; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&gt;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #00796b; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;/script&gt;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #00796b; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&lt;script</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;src</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">\"https://cdn.jsdelivr.net/npm/@tensorflow-models/toxicity\"</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #00796b; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&gt;&lt;/script&gt;</span></span></p>                </td>            </tr>        </tbody>    </table></div><h3>Load the model</h3>  <p>Add the following code to load the text toxicity model in the <code><span style=\"font-family: courier;\">Guestbook()</span></code> function. The <code><span style=\"font-family: courier;\">Guestbook()</span></code> function is part of the original Firebase sample. It initializes the <code><span style=\"font-family: courier;\">Guestbook</span></code> components and is called on page load. </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// main.js</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// Initializes the Guestbook.</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">function</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #3367d6; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Guestbook</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">()</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p><span style=\"font-family: courier;\"><br />                    </span><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #455a64; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// The minimum prediction confidence.</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">const</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;threshold&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #c53929; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">0.9</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #455a64; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// Load the model. Users optionally pass in a threshold and an array of</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #455a64; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// labels to include.</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; toxicity</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">load</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">threshold</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">).</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">then</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">model&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=&gt;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; toxicity_model&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;model</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">});</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">//\u2026</span></p>                </td>            </tr>        </tbody>    </table></div><p>The <code><span style=\"font-family: courier;\">threshold</span></code> of the model is the minimum prediction confidence you want to use to set the model's predictions to <code><span style=\"font-family: courier;\">true</span></code> or <code><span style=\"font-family: courier;\">false</span></code>--that is, how confident the model is that the text does or does not contain the given type of toxic content. The scale for the threshold is 0-1.0. In this case, I set the threshold to .9, which means the model will predict <code><span style=\"font-family: courier;\">true</span></code> or <code><span style=\"font-family: courier;\">false</span></code> if it is 90% confident in its findings.  It is up to you to decide what threshold works for your use case. You may even want to try out the <a href=\"https://storage.googleapis.com/tfjs-models/demos/toxicity/index.html\" target=\"_blank\">text toxicity classifier demo</a> with some phrases that could come up on your website to determine how the model handles them. </p><p><code><span style=\"font-family: courier;\">toxicity.load</span></code> loads the model, passing the threshold. Once loaded, it sets <code><span style=\"font-family: courier;\">toxicity_model</span></code> to the <code><span style=\"font-family: courier;\">model</span></code> value. </p><h3>Run the prediction</h3>  <p>Add a <code><span style=\"font-family: courier;\">checkContent</span></code> function that runs the model predictions on messages upon clicking \"Add message\": </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// main.js</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #3367d6; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Guestbook</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">checkContent&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">function</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">message</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">if</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(!</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">toxicity_model</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; console</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">log</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #0f9d58; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">'no model found'</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">);</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">false</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p><span style=\"font-family: courier;\"><br />                    </span><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">const</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;messages&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">message</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">];</span></span></p><span style=\"font-family: courier;\"><br />                    </span><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;toxicity_model</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">classify</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">messages</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">).</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">then</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">predictions&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=&gt;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p><span style=\"font-family: courier;\"><br />                    </span><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">for</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">let item of predictions</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">for</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">let i&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">in</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;item</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">results</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; &nbsp; console</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">log</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">item</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">results</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">i</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">].</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">match</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">if</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">item</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">results</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">[</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">i</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">].</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">match&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">===</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">true</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; console</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">log</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #0f9d58; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">'toxicity found'</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">);</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">true</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; console</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">log</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #0f9d58; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">'no toxicity found'</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">);</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">false</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">});</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #616161; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></p>                </td>            </tr>        </tbody>    </table></div><p>This function does the following: </p><ol> <li>Verifies that the model load has completed. If <code><span style=\"font-family: courier;\">toxicity_model</span></code> has a value, then the <code><span style=\"font-family: courier;\">load()</span></code> function has finished loading the model.  </li><li>Puts the message into an array called <code><span style=\"font-family: courier;\">messages</span></code>, as an array is the object type that the <code><span style=\"font-family: courier;\">classify</span></code> function accepts.  </li><li>Calls <code><span style=\"font-family: courier;\">classify</span></code> on the <code><span style=\"font-family: courier;\">messages</span></code> array.  </li><li>Iterates through the prediction results. <code><span style=\"font-family: courier;\">predictions</span></code> is an array of objects each representing a different language label. You may want to know about only specific labels rather than iterating through them all. For example, if your use case is a website for hosting the transcripts of rap battles, you probably don't want to detect and remove insults.  </li><li>Checks if the content is a match for that label. if the <code>match</code> value is <code><span style=\"font-family: courier;\">true</span></code>, then the model has detected the given type of unwanted language. If the unwanted language is detected, the function returns true. There's no need to keep checking the rest of the results, since the content has already been deemed inappropriate.  </li><li>If the function iterates through all the results and no label match is set to <code><span style=\"font-family: courier;\">true</span></code>, then the function returns <code><span style=\"font-family: courier;\">false</span></code> \u2013 meaning no undesirable language was found. The match label can also be <code><span style=\"font-family: courier;\">null</span></code>. In that case, its value isn't <code><span style=\"font-family: courier;\">true</span></code>, so it's considered acceptable language. I will talk more about the <code>null</code> option in a future post. </li></ol><p>  Add a call to the <code><span style=\"font-family: courier;\">checkContent</span></code> in the <code><span style=\"font-family: courier;\">saveMessage</span></code> function: </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0.75pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// main.js</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// Saves a new message on the Firebase DB.</span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #3367d6; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Guestbook</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">prototype</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">saveMessage&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">function</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">e</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; e</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">preventDefault</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">();</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">if</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(!</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">this</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">messageInput</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">value&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">||</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">!</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">this</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">nameInput</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">value</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p><span style=\"font-family: courier;\"><br />                    </span><p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #3367d6; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Guestbook</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">checkContent</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">this</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">messageInput</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">value</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">).</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">then</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">((</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">toxic</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">=&gt;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">if</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">toxic&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">===</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">true</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">)</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">{</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #455a64; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// display a message to the user to be kind</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #3367d6; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Guestbook</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">displaySnackbar</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">();</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #455a64; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">// clear the message field</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #3367d6; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">Guestbook</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">resetMaterialTextfield</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">(</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">this</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">.</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">messageInput</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">);</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #9c27b0; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">return</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">;</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">&nbsp; &nbsp;&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">}</span></span></p>                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"background-color: transparent; color: #455a64; font-family: courier; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">//\u2026</span></p>                </td>            </tr>        </tbody>    </table></div><p>After a couple quick checks for input values, the contents of the message box is passed to the <code><span style=\"font-family: courier;\">checkContent</span></code> function. </p><p>If the content passes this check, the message is written to the Realtime Database. If not, a snack bar displays reminding the message author to be kind. The snack bar isn't anything special, so I'm not going to include the code here. You can see it in the full example code, or <a href=\"https://www.w3schools.com/howto/howto_js_snackbar.asp\" target=\"_blank\">implement a snack bar of your own</a>. </p><h2>Try it out</h2>  <p>If you've been following along in your own code, run this terminal command in your project folder to deploy the website: </p><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">    <table>        <tbody>            <tr style=\"height: 0pt;\">                <td style=\"background-color: #fafafa; border-bottom: solid #e0e0e0 1pt; border-color: rgb(224, 224, 224); border-left: solid #e0e0e0 1pt; border-right: solid #e0e0e0 1pt; border-style: solid; border-top: solid #e0e0e0 1pt; border-width: 1pt; overflow: hidden; padding: 5pt; vertical-align: top;\">                    <p dir=\"ltr\" style=\"line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;\"><span style=\"font-family: courier;\"><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">firebase deploy&nbsp;</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: #616161; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">\u2013</span><span face=\"Consolas,sans-serif\" style=\"background-color: transparent; color: black; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;\">only hosting</span></span></p>                </td>            </tr>        </tbody>    </table><br /></div><div align=\"left\" dir=\"ltr\" style=\"margin-left: 0pt;\">You can view the completed example code&nbsp;<a href=\"https://github.com/jenperson/text-moderation\" target=\"_blank\">here</a>.</div><table align=\"center\" cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"margin-left: auto; margin-right: auto;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCudwB-q5bH0md-HHEcQ9ZAvMU5ABBEgQkjQx3rzkvvlpOw8WVA0uP_dmyjyE62W3V4_Hcd4CPhQirXyRwVJJCUJclvTnJb6dhtSHMi4v3T72h5M6UaNDKLnOZSU4xla_6BpuiHEFLL3seD-3Tq2hJRutrxjZJjkaZ5fXqFdie5KN1Saul2E3RWmGS/s1600/TF%20BLog%204.gif\" style=\"clear: left; display: block; margin-left: auto; margin-right: auto; padding: 1em 0px; text-align: center;\"><img alt=\"\" border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjCudwB-q5bH0md-HHEcQ9ZAvMU5ABBEgQkjQx3rzkvvlpOw8WVA0uP_dmyjyE62W3V4_Hcd4CPhQirXyRwVJJCUJclvTnJb6dhtSHMi4v3T72h5M6UaNDKLnOZSU4xla_6BpuiHEFLL3seD-3Tq2hJRutrxjZJjkaZ5fXqFdie5KN1Saul2E3RWmGS/s1600/TF%20BLog%204.gif\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><i><span style=\"text-align: start;\">A message that's not acceptable gets rejected<br /></span></i><table cellpadding=\"0\" cellspacing=\"0\" class=\"tr-caption-container\" style=\"float: left;\"><tbody><tr><td style=\"text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgghotkpgTBH5yNkpmpM_Ji0BfgqNSsexUQFTjyI4qPRD41gz_akoutZGscIuSewooRS0YcRPFVJik0hZ3fBvozlAChRElmIOgcwZW4z1b60aAKWWppvEIKl6zY1jQHUD89gMXTb9ZKwqt2begqJLSatmfkWOJqHeZbAbZPSeDTXPDUM63LH5pLSmCj/s1713/TF%20Blog%203.gif\" style=\"clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;\"><img border=\"0\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgghotkpgTBH5yNkpmpM_Ji0BfgqNSsexUQFTjyI4qPRD41gz_akoutZGscIuSewooRS0YcRPFVJik0hZ3fBvozlAChRElmIOgcwZW4z1b60aAKWWppvEIKl6zY1jQHUD89gMXTb9ZKwqt2begqJLSatmfkWOJqHeZbAbZPSeDTXPDUM63LH5pLSmCj/s16000/TF%20Blog%203.gif\" title=\"An acceptable message gets published to the guestbook\" /></a></td></tr><tr><td class=\"tr-caption\" style=\"text-align: center;\"><span style=\"text-align: start;\"><i>An acceptable message gets published to the guestbook<br /></i></span></td></tr></tbody></table><br /></td></tr><tr><td class=\"tr-caption\"><div>Verifying that this code was working properly was really uncomfortable. I had to come up with an insult that the model would deem inappropriate, and then keep writing it on the website. From my work computer. I know nobody could actually see it, but still. That was one of the stranger parts of my job, to be sure!</div><div><h2><span style=\"text-align: left;\">Next steps</span></h2></div> </td></tr></tbody></table>Using client-side moderation like this could catch most issues before they occur. But a clever user might open developer tools and try to find a way to write obscenities directly to the database, circumventing the content check. That's where server-side moderation comes in. <br /><br />If you enjoyed this article and would like to learn more about TensorFlow.js, here are some things you can do: <br /><ul style=\"text-align: left;\"><li>Check out the <a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\">TensorFlow.js edX course</a> by Jason Mayes. If you are even remotely interested in using TensorFlow.js, I cannot recommend this enough. It might look like a lot at first, but the course is broken up into easy-to-follow manageable pieces.&nbsp;</li><li>View all the TensorFlow.js pretrained models in the <a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\">TFJS repository on GitHub</a>.&nbsp;</li><li>Play around with <a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\">TensorFlow.js projects on Glitch</a>.&nbsp;</li><li>To see an example of ML image moderation on the web, try out <a href=\"https://blog.tensorflow.org/feeds/posts/default?alt=rss\">Gant Laborde's NSFW TFJS image checker</a>.</li></ul>",
            "pubdate": "Fri, 19 Aug 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                8,
                19
            ],
            "email_sent": true
        }
    },
    "Machine Learning Mastery Blog": {
        "Image Augmentation with Keras Preprocessing Layers and tf.image": {
            "url": "https://machinelearningmastery.com/image-augmentation-with-keras-preprocessing-layers-and-tf-image/",
            "description": "<p>Last Updated on August 6, 2022 When you work on a machine learning problem related to images, not only do you need to collect some images as training data, but you also need to employ augmentation to create variations in the image. It is especially true for more complex object recognition problems. There are many [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/image-augmentation-with-keras-preprocessing-layers-and-tf-image/\" rel=\"nofollow\">Image Augmentation with Keras Preprocessing Layers and tf.image</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Wed, 20 Jul 2022 02:10:31 +0000",
            "pubdate_parsed": [
                2022,
                7,
                20
            ],
            "email_sent": true
        },
        "Tepper Wants to Nerd Out On Data With You": {
            "url": "https://machinelearningmastery.com/tepper-wants-to-nerd-out-on-data-with-you/",
            "description": "<p>Last Updated on July 28, 2022 Sponsored Post There are many practical reasons why you should choose an online Masters in Business Analytics from the Tepper School of Business at Carnegie Mellon University. We can list facts like: our alumni average $103,000 in starting salary and 84% of our grads secured a promotion or new [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/tepper-wants-to-nerd-out-on-data-with-you/\" rel=\"nofollow\">Tepper Wants to Nerd Out On Data With You</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Wed, 27 Jul 2022 16:25:13 +0000",
            "pubdate_parsed": [
                2022,
                7,
                27
            ],
            "email_sent": true
        },
        "Mastering MLOps: Live Model Deployment & Inference Course with Stefan Krawczyk": {
            "url": "https://machinelearningmastery.com/mastering-mlops-live-model-deployment-inference-course-with-stefan-krawczyk/",
            "description": "<p>Last Updated on July 29, 2022 Sponsored Post AI &#38; Machine Learning now power most product experiences even beyond those of the big technology companies. Today, your models must perform and function correctly to ultimately deliver business value. The cost of deploying a slow or bad model, or not detecting undesirable behavior quickly, could significantly [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/mastering-mlops-live-model-deployment-inference-course-with-stefan-krawczyk/\" rel=\"nofollow\">Mastering MLOps: Live Model Deployment &#038; Inference Course with Stefan Krawczyk</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Thu, 28 Jul 2022 17:11:19 +0000",
            "pubdate_parsed": [
                2022,
                7,
                28
            ],
            "email_sent": true
        },
        "Using Depthwise Separable Convolutions in Tensorflow": {
            "url": "https://machinelearningmastery.com/using-depthwise-separable-convolutions-in-tensorflow/",
            "description": "<p>Last Updated on August 10, 2022 Looking at all of the very large convolutional neural networks such as ResNets, VGGs, and the like, it begs the question on how we can make all of these networks smaller with less parameters while still maintaining the same level of accuracy or even improving generalization of the model [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-depthwise-separable-convolutions-in-tensorflow/\" rel=\"nofollow\">Using Depthwise Separable Convolutions in Tensorflow</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Wed, 03 Aug 2022 18:41:58 +0000",
            "pubdate_parsed": [
                2022,
                8,
                3
            ],
            "email_sent": true
        },
        "Difference Between a Batch and an Epoch in a Neural Network": {
            "url": "https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/",
            "description": "<p>Last Updated on August 15, 2022 Stochastic gradient descent is a learning algorithm that has a number of hyperparameters. Two hyperparameters that often confuse beginners are the batch size and number of epochs. They are both integer values and seem to do the same thing. In this post, you will discover the difference between batches [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\" rel=\"nofollow\">Difference Between a Batch and an Epoch in a Neural Network</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Tue, 09 Aug 2022 19:00:43 +0000",
            "pubdate_parsed": [
                2022,
                8,
                9
            ],
            "email_sent": true
        },
        "When to Use MLP, CNN, and RNN Neural Networks": {
            "url": "https://machinelearningmastery.com/when-to-use-mlp-cnn-and-rnn-neural-networks/",
            "description": "<p>Last Updated on August 15, 2022 What neural network is appropriate for your predictive modeling problem? It can be difficult for a beginner to the field of deep learning to know what type of network to use. There are so many types of networks to choose from and new methods being published and discussed every [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/when-to-use-mlp-cnn-and-rnn-neural-networks/\" rel=\"nofollow\">When to Use MLP, CNN, and RNN Neural Networks</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Thu, 11 Aug 2022 19:00:29 +0000",
            "pubdate_parsed": [
                2022,
                8,
                11
            ],
            "email_sent": true
        },
        "Why Initialize a Neural Network with Random Weights?": {
            "url": "https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/",
            "description": "<p>Last Updated on August 15, 2022 The weights of artificial neural networks must be initialized to small random numbers. This is because this is an expectation of the stochastic optimization algorithm used to train the model, called stochastic gradient descent. To understand this approach to problem solving, you must first understand the role of nondeterministic [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/why-initialize-a-neural-network-with-random-weights/\" rel=\"nofollow\">Why Initialize a Neural Network with Random Weights?</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Sat, 13 Aug 2022 19:00:29 +0000",
            "pubdate_parsed": [
                2022,
                8,
                13
            ],
            "email_sent": true
        },
        "How to Make Predictions with Keras": {
            "url": "https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/",
            "description": "<p>Last Updated on August 23, 2022 Once you choose and fit a final deep learning model in Keras, you can use it to make predictions on new data instances. There is some confusion amongst beginners about how exactly to do this. I often see questions such as: How do I make predictions with my model [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/how-to-make-classification-and-regression-predictions-for-deep-learning-models-in-keras/\" rel=\"nofollow\">How to Make Predictions with Keras</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Tue, 16 Aug 2022 19:00:52 +0000",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "How to Calculate Precision, Recall, F1, and More for Deep Learning Models": {
            "url": "https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/",
            "description": "<p>Last Updated on August 23, 2022 Once you fit a deep learning neural network model, you must evaluate its performance on a test dataset. This is critical, as the reported performance allows you to both choose between candidate models and to communicate to stakeholders about how good the model is at solving the problem. The [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/how-to-calculate-precision-recall-f1-and-more-for-deep-learning-models/\" rel=\"nofollow\">How to Calculate Precision, Recall, F1, and More for Deep Learning Models</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 19:00:54 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Last call: Stefan Krawcyzks Mastering MLOps Live Cohort": {
            "url": "https://machinelearningmastery.com/last-call-stefan-krawcyzks-mastering-mlops-live-cohort/",
            "description": "<p>Last Updated on August 19, 2022 Sponsored Post &#160; This is your last chance to sign up for Stefan Krawczyk&#8217;s exclusive live cohort, starting next week (August 22nd). We already have students enrolled from Apple, Amazon, Spotify, Nubank, Workfusion, Glassdoor, ServiceNow, and more. Stefan Krawczky has spent the last 15+ years working on MLOps at [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/last-call-stefan-krawcyzks-mastering-mlops-live-cohort/\" rel=\"nofollow\">Last call: Stefan Krawcyzk\u2019s &#8216;Mastering MLOps&#8217; Live Cohort</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">Machine Learning Mastery</a>.</p>",
            "pubdate": "Thu, 18 Aug 2022 17:30:04 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Building a Logistic Regression Classifier in PyTorch": {
            "url": "https://machinelearningmastery.com/building-a-logistic-regression-classifier-in-pytorch/",
            "description": "<p>Last Updated on December 30, 2022 Logistic regression is a type of regression that predicts the probability of an event. It is used for classification problems and has many applications in the fields of machine learning, artificial intelligence, and data mining. The formula of logistic regression is to apply a sigmoid function to the output [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/building-a-logistic-regression-classifier-in-pytorch/\" rel=\"nofollow\">Building a Logistic Regression Classifier in PyTorch</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 30 Dec 2022 09:11:28 +0000",
            "pubdate_parsed": [
                2022,
                12,
                30
            ],
            "email_sent": true
        },
        "Training Logistic Regression with Cross-Entropy Loss in PyTorch": {
            "url": "https://machinelearningmastery.com/training-logistic-regression-with-cross-entropy-loss-in-pytorch/",
            "description": "<p>Last Updated on December 30, 2022 In the previous session of our PyTorch series, we demonstrated how badly initialized weights can impact the accuracy of a classification model when mean square error (MSE) loss is used. We noticed that the model didn&#8217;t converge during training and its accuracy was also significantly reduced. In the following, [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/training-logistic-regression-with-cross-entropy-loss-in-pytorch/\" rel=\"nofollow\">Training Logistic Regression with Cross-Entropy Loss in PyTorch</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 30 Dec 2022 08:47:11 +0000",
            "pubdate_parsed": [
                2022,
                12,
                30
            ],
            "email_sent": true
        },
        "Initializing Weights for Deep Learning Models": {
            "url": "https://machinelearningmastery.com/initializing-weights-for-deep-learning-models/",
            "description": "<p>Last Updated on December 30, 2022 In order to build a classifier that accurately classifies the data samples and performs well on test data, you need to initialize the weights in a way that the model converges well. Usually we randomized the weights. But when we use mean square error (MSE) as loss for training [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/initializing-weights-for-deep-learning-models/\" rel=\"nofollow\">Initializing Weights for Deep Learning Models</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 30 Dec 2022 08:24:53 +0000",
            "pubdate_parsed": [
                2022,
                12,
                30
            ],
            "email_sent": true
        },
        "Building a Regression Model in PyTorch": {
            "url": "https://machinelearningmastery.com/building-a-regression-model-in-pytorch/",
            "description": "<p>PyTorch library is for deep learning. Some applications of deep learning models are to solve regression or classification problems. In this post, you will discover how to use PyTorch to develop and evaluate neural network models for regression problems. After completing this post, you will know: How to load data from scikit-learn and adapt it [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/building-a-regression-model-in-pytorch/\" rel=\"nofollow\">Building a Regression Model in PyTorch</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 05 Feb 2023 13:12:37 +0000",
            "pubdate_parsed": [
                2023,
                2,
                5
            ],
            "email_sent": true
        },
        "How to Grid Search Hyperparameters for PyTorch Models": {
            "url": "https://machinelearningmastery.com/how-to-grid-search-hyperparameters-for-pytorch-models/",
            "description": "<p>The &#8220;weights&#8221; of a neural network is referred as &#8220;parameters&#8221; in PyTorch code and it is fine-tuned by optimizer during training. On the contrary, hyperparameters are the parameters of a neural network that is fixed by design and not tuned by training. Examples are the number of hidden layers and the choice of activation functions. [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/how-to-grid-search-hyperparameters-for-pytorch-models/\" rel=\"nofollow\">How to Grid Search Hyperparameters for PyTorch Models</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Thu, 09 Feb 2023 13:35:17 +0000",
            "pubdate_parsed": [
                2023,
                2,
                9
            ],
            "email_sent": true
        },
        "Using Activation Functions in Deep Learning Models": {
            "url": "https://machinelearningmastery.com/using-activation-functions-in-deep-learning-models/",
            "description": "<p>A deep learning model in its simplest form are layers of perceptrons connected in tandem. Without any activation functions, they are just matrix multiplications with limited power, regardless how many of them. Activation is the magic why neural network can be an approximation to a wide variety of non-linear function. In PyTorch, there are many [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-activation-functions-in-deep-learning-models/\" rel=\"nofollow\">Using Activation Functions in Deep Learning Models</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 14 Feb 2023 13:36:34 +0000",
            "pubdate_parsed": [
                2023,
                2,
                14
            ],
            "email_sent": true
        },
        "Using Dropout Regularization in PyTorch Models": {
            "url": "https://machinelearningmastery.com/using-dropout-regularization-in-pytorch-models/",
            "description": "<p>Dropout is a simple and powerful regularization technique for neural networks and deep learning models. In this post, you will discover the Dropout regularization technique and how to apply it to your models in PyTorch models. After reading this post, you will know: How the Dropout regularization technique works How to use Dropout on your [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-dropout-regularization-in-pytorch-models/\" rel=\"nofollow\">Using Dropout Regularization in PyTorch Models</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 19 Feb 2023 13:23:22 +0000",
            "pubdate_parsed": [
                2023,
                2,
                19
            ],
            "email_sent": true
        },
        "Using Learning Rate Schedule in PyTorch Training": {
            "url": "https://machinelearningmastery.com/using-learning-rate-schedule-in-pytorch-training/",
            "description": "<p>Training a neural network or large deep learning model is a difficult optimization task. The classical algorithm to train neural networks is called stochastic gradient descent. It has been well established that you can achieve increased performance and faster training on some problems by using a learning rate that changes during training. In this post, [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-learning-rate-schedule-in-pytorch-training/\" rel=\"nofollow\">Using Learning Rate Schedule in PyTorch Training</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 21 Feb 2023 13:33:16 +0000",
            "pubdate_parsed": [
                2023,
                2,
                21
            ],
            "email_sent": true
        },
        "Understand Model Behavior During Training by Visualizing Metrics": {
            "url": "https://machinelearningmastery.com/understand-model-behavior-during-training-by-visualizing-metrics/",
            "description": "<p>You can learn a lot about neural networks and deep learning models by observing their performance over time during training. For example, if you see the training accuracy went worse with training epochs, you know you have issue with the optimization. Probably your learning rate is too fast. In this post, you will discover how [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/understand-model-behavior-during-training-by-visualizing-metrics/\" rel=\"nofollow\">Understand Model Behavior During Training by Visualizing Metrics</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 26 Feb 2023 13:19:03 +0000",
            "pubdate_parsed": [
                2023,
                2,
                26
            ],
            "email_sent": true
        },
        "Visualizing a PyTorch Model": {
            "url": "https://machinelearningmastery.com/visualizing-a-pytorch-model/",
            "description": "<p>PyTorch is a deep learning library. You can build very sophisticated deep learning models with PyTorch. However, there are times you want to have a graphical representation of your model architecture. In this post, you will learn: How to save your PyTorch model in an exchange format How to use Netron to create a graphical [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/visualizing-a-pytorch-model/\" rel=\"nofollow\">Visualizing a PyTorch Model</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Thu, 02 Mar 2023 13:25:26 +0000",
            "pubdate_parsed": [
                2023,
                3,
                2
            ],
            "email_sent": true
        },
        "Building a Convolutional Neural Network in PyTorch": {
            "url": "https://machinelearningmastery.com/building-a-convolutional-neural-network-in-pytorch/",
            "description": "<p>Neural networks are built with layers connected to each other. There are many different kind of layers. For image related applications, you can always find convolutional layers. It is a layer with very few parameters but applied over a large sized input. It is powerful because it can preserve the spatial structure of the image. [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/building-a-convolutional-neural-network-in-pytorch/\" rel=\"nofollow\">Building a Convolutional Neural Network in PyTorch</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 05 Mar 2023 13:06:34 +0000",
            "pubdate_parsed": [
                2023,
                3,
                5
            ],
            "email_sent": true
        },
        "LSTM for Time Series Prediction in PyTorch": {
            "url": "https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/",
            "description": "<p>Long Short-Term Memory (LSTM) is a structure that can be used in neural network. It is a type of recurrent neural network (RNN) that expects the input in the form of a sequence of features. It is useful for data such as time series or string of text. In this post, you will learn about [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/lstm-for-time-series-prediction-in-pytorch/\" rel=\"nofollow\">LSTM for Time Series Prediction in PyTorch</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 10 Mar 2023 01:24:39 +0000",
            "pubdate_parsed": [
                2023,
                3,
                10
            ],
            "email_sent": true
        },
        "Text Generation with LSTM in PyTorch": {
            "url": "https://machinelearningmastery.com/text-generation-with-lstm-in-pytorch/",
            "description": "<p>Recurrent neural network can be used for time series prediction. In which, a regression neural network is created. It can also be used as generative model, which usually is a classification neural network model. A generative model is to learn certain pattern from data, such that when it is presented with some prompt, it can [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/text-generation-with-lstm-in-pytorch/\" rel=\"nofollow\">Text Generation with LSTM in PyTorch</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Mon, 13 Mar 2023 01:42:16 +0000",
            "pubdate_parsed": [
                2023,
                3,
                13
            ],
            "email_sent": true
        },
        "Deep Learning with PyTorch (9-Day Mini-Course)": {
            "url": "https://machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/",
            "description": "<p>Last Updated on April 4, 2023 Deep learning is a fascinating field of study and the techniques are achieving world class results in a range of challenging machine learning problems. It can be hard to get started in deep learning.Which library should you use and which techniques should you focus on? In this 9-part crash [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/deep-learning-with-pytorch-9-day-mini-course/\" rel=\"nofollow\">Deep Learning with PyTorch (9-Day Mini-Course)</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 04 Apr 2023 05:28:53 +0000",
            "pubdate_parsed": [
                2023,
                4,
                4
            ],
            "email_sent": true
        },
        "What are Large Language Models": {
            "url": "https://machinelearningmastery.com/what-are-large-language-models/",
            "description": "<p>Last Updated on May 19, 2023 Large language models (LLMs) are recent advances in deep learning models to work on human languages. Some great use case of LLMs has been demonstrated. A large language model is a trained deep-learning model that understands and generates text in a human-like fashion. Behind the scene, it is a [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/what-are-large-language-models/\" rel=\"nofollow\">What are Large Language Models</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 19 May 2023 02:46:01 +0000",
            "pubdate_parsed": [
                2023,
                5,
                19
            ],
            "email_sent": true
        },
        "Get a Taste of LLMs from GPT4All": {
            "url": "https://machinelearningmastery.com/get-a-taste-of-llms-from-gpt4all/",
            "description": "<p>Large language models have become popular recently. ChatGPT is fashionable. Trying out ChatGPT to understand what LLMs are about is easy, but sometimes, you may want an offline alternative that can run on your computer. In this post, you will learn about GPT4All as an LLM that you can install on your computer. In particular, [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/get-a-taste-of-llms-from-gpt4all/\" rel=\"nofollow\">Get a Taste of LLMs from GPT4All</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 21 May 2023 03:19:44 +0000",
            "pubdate_parsed": [
                2023,
                5,
                21
            ],
            "email_sent": true
        },
        "What Are Zero-Shot Prompting and Few-Shot Prompting": {
            "url": "https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/",
            "description": "<p>In the literature on language models, you will often encounter the terms &#8220;zero-shot prompting&#8221; and &#8220;few-shot prompting.&#8221; It is important to understand how a large language model generates an output. In this post, you will learn: What is zero-shot and few-shot prompting? How to experiment with them in GPT4All Let&#8217;s get started. Overview This post [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/\" rel=\"nofollow\">What Are Zero-Shot Prompting and Few-Shot Prompting</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 23 May 2023 03:35:22 +0000",
            "pubdate_parsed": [
                2023,
                5,
                23
            ],
            "email_sent": true
        },
        "Prompt Engineering for Effective Interaction with ChatGPT": {
            "url": "https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/",
            "description": "<p>Last Updated on June 16, 2023 With the explosion in popularity of generative AI in general and ChatGPT in particular, prompting has become an increasingly important skill for those in the world of AI. Crafting a prompt, the mechanism of interacting with a large language model (LLM) such as ChatGPT, is not the simple syntactic [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/prompt-engineering-for-effective-interaction-with-chatgpt/\" rel=\"nofollow\">Prompt Engineering for Effective Interaction with ChatGPT</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 16 Jun 2023 11:33:22 +0000",
            "pubdate_parsed": [
                2023,
                6,
                16
            ],
            "email_sent": true
        },
        "Using ChatGPT as Your Personalized Teacher": {
            "url": "https://machinelearningmastery.com/using-chatgpt-as-your-personalized-teacher/",
            "description": "<p>Machine Learning and Data Science are the two most essential technologies in Industry 4.0. Data Science refers to extracting meaningful insights from data, while Machine Learning enables the computer to learn independently without being explicitly programmed. Mastering these fields requires a solid understanding of fundamental concepts, hands-on experience, and guidance from mentors. Traditional learning methods, [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-chatgpt-as-your-personalized-teacher/\" rel=\"nofollow\">Using ChatGPT as Your Personalized Teacher</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sat, 17 Jun 2023 13:10:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                17
            ],
            "email_sent": true
        },
        "Using the Natural Language Understanding Capability of ChatGPT": {
            "url": "https://machinelearningmastery.com/using-the-natural-language-understanding-capability-of-chatgpt/",
            "description": "<p>Last Updated on July 3, 2023 ChatGPT as a Large Language Model, is well-known for understanding human languages. Instead of asking ChatGPT for an answer you don&#8217;t know, you can make it work on existing information while leveraging the natural language understanding (NLU) capability. In this post, you will learn How to make ChatGPT produce [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-the-natural-language-understanding-capability-of-chatgpt/\" rel=\"nofollow\">Using the Natural Language Understanding Capability of ChatGPT</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Mon, 03 Jul 2023 03:40:15 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "Building Your mini-ChatGPT at Home": {
            "url": "https://machinelearningmastery.com/building-your-mini-chatgpt-at-home/",
            "description": "<p>Last Updated on July 24, 2023 ChatGPT is fun to play with. Chances are, you also want to have your own copy running privately. Realistically, that&#8217;s impossible because ChatGPT is not a software for download, and it needs tremendous computer power to run. But you can build a trimmed-down version that can run on commodity [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/building-your-mini-chatgpt-at-home/\" rel=\"nofollow\">Building Your mini-ChatGPT at Home</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 01:10:10 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "An Introduction to R": {
            "url": "https://machinelearningmastery.com/an-introduction-to-r/",
            "description": "<p>Last Updated on August 15, 2023 R is a programming language of its kind. It is a language for statistics, and its ecosystem has a lot of libraries for all kinds of statistical tasks. It is a language targeted the statisticians rather than computer scientists. Hence you will see some unorthodox patterns in the language. [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/an-introduction-to-r/\" rel=\"nofollow\">An Introduction to R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 15 Aug 2023 06:03:21 +0000",
            "pubdate_parsed": [
                2023,
                8,
                15
            ],
            "email_sent": true
        },
        "A Gentle Introduction to Vectors in R": {
            "url": "https://machinelearningmastery.com/a-gentle-introduction-to-vectors-in-r/",
            "description": "<p>Last Updated on August 18, 2023 R is a language for programming with data. Unlike many other languages, the primitive data types in R are not scalars but vectors. Therefore, understanding how to deal with vectors is crucial to programming or reading the R code. In this post, you will learn about various vector operations [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/a-gentle-introduction-to-vectors-in-r/\" rel=\"nofollow\">A Gentle Introduction to Vectors in R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Fri, 18 Aug 2023 08:24:23 +0000",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "A Gentle Introduction to Lists and Data Frames in R": {
            "url": "https://machinelearningmastery.com/a-gentle-introduction-to-lists-and-data-frames-in-r/",
            "description": "<p>Vectors in R are supposed to be of homogeneous data type. You can use a list as the container if there are mixed data types, such as numbers and strings. The list and data frame are closely related in R. The data frame is probably more useful because it reflects how we usually collect statistics. [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/a-gentle-introduction-to-lists-and-data-frames-in-r/\" rel=\"nofollow\">A Gentle Introduction to Lists and Data Frames in R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 20 Aug 2023 07:00:12 +0000",
            "pubdate_parsed": [
                2023,
                8,
                20
            ],
            "email_sent": true
        },
        "Surviving in the R Environment": {
            "url": "https://machinelearningmastery.com/surviving-in-the-r-environment/",
            "description": "<p>R is not only a programming language but also a programming shell with read-eval-print loop (REPL). The shell is how most people use R. But when you drill deeper, knowing more about what\u2019s working behind the scenes is handy. In this post, you will learn: How to manage variables in R How to manage packages [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/surviving-in-the-r-environment/\" rel=\"nofollow\">Surviving in the R Environment</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 22 Aug 2023 10:33:40 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "Built-in Datasets in R": {
            "url": "https://machinelearningmastery.com/built-in-datasets-in-r/",
            "description": "<p>Last Updated on August 27, 2023 The ecosystem in R contains not only the function libraries to help you perform statistical analysis but also the data library that gives you some famous datasets to test out your program. There are a lot of built-in datasets in R. In this post, you will: Learn some of [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/built-in-datasets-in-r/\" rel=\"nofollow\">Built-in Datasets in R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 09:25:17 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "Logic, Flow Control, and Functions in R": {
            "url": "https://machinelearningmastery.com/logic-flow-control-and-functions-in-r/",
            "description": "<p>R is a procedural programming language. Therefore, it has the full set of flow control syntax like many other languages. Indeed, the flow control syntax in R is similar to Java and C. In this post, you will see some examples of using the flow control syntax in R. Let&#8217;s get started. Overview This post [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/logic-flow-control-and-functions-in-r/\" rel=\"nofollow\">Logic, Flow Control, and Functions in R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 29 Aug 2023 08:17:53 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Generating Random Numbers in R": {
            "url": "https://machinelearningmastery.com/generating-random-numbers-in-r/",
            "description": "<p>Last Updated on September 5, 2023 Whether working on a machine learning project, a simulation, or other models, you need to generate random numbers in your code. R as a programming language, has several functions for random number generation. In this post, you will learn about them and see how they can be used in [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/generating-random-numbers-in-r/\" rel=\"nofollow\">Generating Random Numbers in R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 05 Sep 2023 08:59:47 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "Using ggplot2 for Visualization in R": {
            "url": "https://machinelearningmastery.com/using-ggplot2-for-visualization-in-r/",
            "description": "<p>Last Updated on September 26, 2023 One of the most popular plotting libraries in R is not the plotting function in R base, but the ggplot2 library. People use that because it is flexible. This library also works using the philosophy of &#8220;grammar of graphics&#8221;, which is not to generate a visualization upon a function [&#8230;]</p>\n<p>The post <a href=\"https://machinelearningmastery.com/using-ggplot2-for-visualization-in-r/\" rel=\"nofollow\">Using ggplot2 for Visualization in R</a> appeared first on <a href=\"https://machinelearningmastery.com\" rel=\"nofollow\">MachineLearningMastery.com</a>.</p>",
            "pubdate": "Tue, 26 Sep 2023 03:13:02 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        }
    },
    "Colah's Blog": {},
    "Amazon Science Blog": {
        "How deep learning is reducing Amazons packaging waste": {
            "url": "https://www.amazon.science/latest-news/deep-learning-machine-learning-computer-vision-applications-reducing-amazon-package-waste",
            "description": "A combination of deep learning, natural language processing, and computer vision enables Amazon to hone in on the right amount of packaging for each product.",
            "pubdate": "Tue, 04 Jan 2022 13:38:23 GMT",
            "pubdate_parsed": [
                2022,
                1,
                4
            ],
            "email_sent": true
        },
        "Using NLU labels to improve an ASR rescoring model": {
            "url": "https://www.amazon.science/blog/using-nlu-labels-to-improve-an-automatic-speech-recognition-rescoring-model",
            "description": "Second-pass language models that rescore automatic-speech-recognition hypotheses benefit from multitask training on natural-language-understanding objectives.",
            "pubdate": "Wed, 05 Jan 2022 14:09:52 GMT",
            "pubdate_parsed": [
                2022,
                1,
                5
            ],
            "email_sent": true
        },
        "WACV: Transformers for video and contrastive learning": {
            "url": "https://www.amazon.science/blog/wacv-transformer-models-for-video-and-contrastive-learning",
            "description": "Amazon\u2019s Joe Tighe on the major trends he sees in the field of computer vision.",
            "pubdate": "Thu, 06 Jan 2022 14:12:55 GMT",
            "pubdate_parsed": [
                2022,
                1,
                6
            ],
            "email_sent": true
        },
        "A conversation with economics Nobelists": {
            "url": "https://www.amazon.science/latest-news/a-conversation-with-economics-nobelists-on-experimental-design",
            "description": "Amazon Scholar David Card and Amazon academic research consultant Guido Imbens talk about the past and future of empirical economics.",
            "pubdate": "Fri, 07 Jan 2022 16:13:47 GMT",
            "pubdate_parsed": [
                2022,
                1,
                7
            ],
            "email_sent": true
        },
        "Using computer vision to weed out product catalogue errors": {
            "url": "https://www.amazon.science/blog/using-computer-vision-to-weed-out-product-catalogue-errors",
            "description": "Method uses metric learning to determine whether images depict the same product.",
            "pubdate": "Mon, 10 Jan 2022 14:27:32 GMT",
            "pubdate_parsed": [
                2022,
                1,
                10
            ],
            "email_sent": true
        },
        "The science behind the next-gen FORMULA 1 car": {
            "url": "https://www.amazon.science/latest-news/the-science-behind-the-next-gen-2022-F1-car",
            "description": "Learn how the F1 engineering team collaborated with AWS to develop new design specifications to help make races more competitive.",
            "pubdate": "Tue, 11 Jan 2022 12:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                11
            ],
            "email_sent": true
        },
        "How new machine learning techniques could improve MRI scans": {
            "url": "https://www.amazon.science/research-awards/success-stories/how-new-machine-learning-techniques-could-improve-mri-machine-images",
            "description": "Amazon Research Award recipient Jonathan Tamir is focusing on deriving better images faster.",
            "pubdate": "Wed, 12 Jan 2022 13:49:37 GMT",
            "pubdate_parsed": [
                2022,
                1,
                12
            ],
            "email_sent": true
        },
        "Why a Brazilian robotics expert moved to West Virginia to work on robots": {
            "url": "https://www.amazon.science/research-awards/success-stories/autonomous-robots-why-a-brazilian-robotics-expert-moved-to-west-virginia-to-work-on-robots",
            "description": "Guilherme Pereira, a 2019 Amazon Research Award recipient, is researching methods to improve a robot\u2019s ability to work autonomously.",
            "pubdate": "Thu, 13 Jan 2022 13:30:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                13
            ],
            "email_sent": true
        },
        "Hierarchical representations improve image retrieval": {
            "url": "https://www.amazon.science/blog/hierarchical-representations-improve-image-retrieval",
            "description": "A new metric-learning loss function groups together superclasses and learns commonalities within them.",
            "pubdate": "Fri, 14 Jan 2022 14:31:05 GMT",
            "pubdate_parsed": [
                2022,
                1,
                14
            ],
            "email_sent": true
        },
        "Amazons DynamoDB  10 years later": {
            "url": "https://www.amazon.science/latest-news/amazons-dynamodb-10-years-later",
            "description": "Amazon DynamoDB was introduced 10 years ago today; one of its key contributors reflects on its origins, and discusses the 'never-ending journey' to make DynamoDB more secure, more available and more performant.",
            "pubdate": "Tue, 18 Jan 2022 19:47:10 GMT",
            "pubdate_parsed": [
                2022,
                1,
                18
            ],
            "email_sent": true
        },
        "Decisions, decisions: Lihong Li's Amazon Ads reinforcement learning research": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-advertising-lihong-li-using-reinforcement-learning-algorithms",
            "description": "The scientist's work is driving practical outcomes within an exploding machine learning research field.",
            "pubdate": "Wed, 19 Jan 2022 18:26:06 GMT",
            "pubdate_parsed": [
                2022,
                1,
                19
            ],
            "email_sent": true
        },
        "How Alexa learned Arabic": {
            "url": "https://www.amazon.science/latest-news/how-alexa-learned-arabic",
            "description": "Arabic posed unique challenges for speech recognition, language understanding, and speech synthesis.",
            "pubdate": "Mon, 24 Jan 2022 17:10:24 GMT",
            "pubdate_parsed": [
                2022,
                1,
                24
            ],
            "email_sent": true
        },
        "On-device speech processing makes Alexa faster, lower-bandwidth": {
            "url": "https://www.amazon.science/blog/on-device-speech-processing-makes-alexa-faster-lower-bandwidth",
            "description": "Innovative training methods and model compression techniques combine with clever engineering to keep speech processing local.",
            "pubdate": "Tue, 25 Jan 2022 16:32:21 GMT",
            "pubdate_parsed": [
                2022,
                1,
                25
            ],
            "email_sent": true
        },
        "How to build a successful career as a scientist at Amazon": {
            "url": "https://www.amazon.science/working-at-amazon/how-to-build-a-successful-career-as-a-scientist-at-amazon",
            "description": "Belinda Zeng, head of applied science and engineering at Amazon Search Science and AI, shares her perspective.",
            "pubdate": "Wed, 26 Jan 2022 14:03:05 GMT",
            "pubdate_parsed": [
                2022,
                1,
                26
            ],
            "email_sent": true
        },
        "How Prime Video updates its app for more than 8,000 device types": {
            "url": "https://www.amazon.science/blog/how-prime-video-updates-its-app-for-more-than-8-000-device-types",
            "description": "The switch to WebAssembly increases stability, speed.",
            "pubdate": "Thu, 27 Jan 2022 18:24:26 GMT",
            "pubdate_parsed": [
                2022,
                1,
                27
            ],
            "email_sent": true
        },
        "How Amazon Music's recommender hits the right notes": {
            "url": "https://www.amazon.science/latest-news/how-amazon-music-uses-recommendation-system-machine-learning",
            "description": "Learn how the Amazon Music Conversations team is using pioneering machine learning to make Alexa's discernment better than ever.",
            "pubdate": "Fri, 28 Jan 2022 14:00:02 GMT",
            "pubdate_parsed": [
                2022,
                1,
                28
            ],
            "email_sent": true
        },
        "The engineering behind Alexa's contextual speech recognition": {
            "url": "https://www.amazon.science/latest-news/the-engineering-behind-alexas-contextual-speech-recognition",
            "description": "How Alexa scales machine learning models to millions of customers.",
            "pubdate": "Mon, 31 Jan 2022 15:45:55 GMT",
            "pubdate_parsed": [
                2022,
                1,
                31
            ],
            "email_sent": true
        },
        "Alexa AI co-organizes special sessions at Interspeech": {
            "url": "https://www.amazon.science/blog/alexa-ai-co-organizes-special-sessions-at-icassp-interspeech",
            "description": "Sessions on multidevice scenarios, inclusive and fair speech technologies, trustworthy speech processing, and speech intelligibility prediction seek paper submissions.",
            "pubdate": "Wed, 02 Feb 2022 17:31:13 GMT",
            "pubdate_parsed": [
                2022,
                2,
                2
            ],
            "email_sent": true
        },
        "Ren Vidal wins Edward J. McCluskey Technical Achievement Award": {
            "url": "https://www.amazon.science/latest-news/subspace-clustering-rene-vidal-2021-edward-j-mccluskey-technical-achievement-award",
            "description": "The Amazon Scholar and Johns Hopkins University professor was honored for \u201cpioneering contributions to subspace clustering\u201d.",
            "pubdate": "Wed, 02 Feb 2022 15:08:07 GMT",
            "pubdate_parsed": [
                2022,
                2,
                2
            ],
            "email_sent": true
        },
        "Josh Miele: Amazons resident MacArthur Fellow": {
            "url": "https://www.amazon.science/working-at-amazon/josh-miele-amazons-resident-macarthur-fellow",
            "description": "Miele has merged a lifelong passion for science with a mission to make the world more accessible for people with disabilities.",
            "pubdate": "Thu, 03 Feb 2022 14:47:12 GMT",
            "pubdate_parsed": [
                2022,
                2,
                3
            ],
            "email_sent": true
        },
        "CAIT announces new fellowships, faculty research awards": {
            "url": "https://www.amazon.science/academic-engagements/cait-announces-two-new-phd-student-fellowships-and-five-new-faculty-research-awards",
            "description": "The Columbia Center of AI Technology announced its inaugural recipients last year.",
            "pubdate": "Fri, 04 Feb 2022 14:01:37 GMT",
            "pubdate_parsed": [
                2022,
                2,
                4
            ],
            "email_sent": true
        },
        "How Margarita Chli is using drones to go where people cant": {
            "url": "https://www.amazon.science/research-awards/success-stories/autonomous-mobile-robots-margarita-chli-drones",
            "description": "When it comes to search-and-rescue missions, dogs are second to none, but an Amazon Research Award recipient says they might have competition from drones.",
            "pubdate": "Mon, 07 Feb 2022 15:59:27 GMT",
            "pubdate_parsed": [
                2022,
                2,
                7
            ],
            "email_sent": true
        },
        "Amazon expands SURE program to boost diversity in STEM education": {
            "url": "https://www.amazon.science/academic-engagements/amazon-expands-sure-program-to-boost-diversity-in-stem-education",
            "description": "New programs with Georgia Tech and the University of Southern California are established; existing Columbia University program expands.",
            "pubdate": "Tue, 08 Feb 2022 13:55:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                8
            ],
            "email_sent": true
        },
        "New UW-Amazon Science Hub launches": {
            "url": "https://www.amazon.science/academic-engagements/new-uw-amazon-science-hub-launches",
            "description": "The collaboration will focus on advancing innovation in core robotics and AI technologies and their applications.",
            "pubdate": "Wed, 09 Feb 2022 17:00:37 GMT",
            "pubdate_parsed": [
                2022,
                2,
                9
            ],
            "email_sent": true
        },
        "Automated reasoning's scientific frontiers": {
            "url": "https://www.amazon.science/blog/automated-reasonings-scientific-frontiers",
            "description": "Distributing proof search, reasoning about distributed systems, and automating regulatory compliance are just three fruitful research areas.",
            "pubdate": "Thu, 10 Feb 2022 14:22:40 GMT",
            "pubdate_parsed": [
                2022,
                2,
                10
            ],
            "email_sent": true
        },
        "Alexa AI team discusses NeurIPS workshop best paper award": {
            "url": "https://www.amazon.science/latest-news/alexa-ai-team-discusses-neurips-workshop-best-paper-award",
            "description": "Paper deals with detecting and answering out-of-domain requests for task-oriented dialogue systems.",
            "pubdate": "Fri, 11 Feb 2022 14:25:37 GMT",
            "pubdate_parsed": [
                2022,
                2,
                11
            ],
            "email_sent": true
        },
        "Amazon Scholar Ranjit Jhala named ACM Fellow": {
            "url": "https://www.amazon.science/latest-news/amazon-scholar-ranjit-jhala-chosen-as-acm-fellow-for-computer-science-contributions",
            "description": "Jhala received the ACM honor for lifetime contributions to software verification, developing innovative tools to help computer programmers test their code.",
            "pubdate": "Mon, 14 Feb 2022 13:59:18 GMT",
            "pubdate_parsed": [
                2022,
                2,
                14
            ],
            "email_sent": true
        },
        "Alexa Prize has a new home": {
            "url": "https://www.amazon.science/alexa-prize/alexa-prize-has-a-new-home",
            "description": "Amazon Science is now the destination for information on the SocialBot, TaskBot, and SimBot challenges, including FAQs, team updates, publications, and other program information.",
            "pubdate": "Tue, 15 Feb 2022 15:14:22 GMT",
            "pubdate_parsed": [
                2022,
                2,
                15
            ],
            "email_sent": true
        },
        "Amazon Robotics, Hampton University team up to establish robotics program": {
            "url": "https://www.amazon.science/academic-engagements/amazon-robotics-hampton-university-team-up-to-establish-robotics-program",
            "description": "Amazon funding will assist with a senior capstone course where students will receive mentorship from Amazon leading researchers, software developers, and engineers.",
            "pubdate": "Wed, 16 Feb 2022 17:04:38 GMT",
            "pubdate_parsed": [
                2022,
                2,
                16
            ],
            "email_sent": true
        },
        "Amazon at WSDM: The future of graph neural networks": {
            "url": "https://www.amazon.science/blog/amazon-at-wsdm-the-future-of-graph-neural-networks",
            "description": "Amazon\u2019s George Karypis will give a keynote address on graph neural networks, a field in which \u201cthere is some fundamental theoretical stuff that we still need to understand.\u201d",
            "pubdate": "Thu, 17 Feb 2022 14:54:21 GMT",
            "pubdate_parsed": [
                2022,
                2,
                17
            ],
            "email_sent": true
        },
        "Using hyperboloids to improve product retrieval": {
            "url": "https://www.amazon.science/blog/using-hyperboloids-to-improve-product-retrieval",
            "description": "Method using hyperboloid embeddings improves on methods that use vector embeddings by up to 33%.",
            "pubdate": "Fri, 18 Feb 2022 15:20:07 GMT",
            "pubdate_parsed": [
                2022,
                2,
                18
            ],
            "email_sent": true
        },
        "Finding  and preventing  vulnerabilities in machine learning models": {
            "url": "https://www.amazon.science/research-awards/success-stories/explainable-machine-learning-bo-li",
            "description": "Bo Li \u2014 a new Amazon Visiting Academic and former Amazon Research Award recipient \u2014 is making sure algorithms are not only smarter but more trustworthy.",
            "pubdate": "Mon, 21 Feb 2022 14:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                21
            ],
            "email_sent": true
        },
        "Whats next for deep learning?": {
            "url": "https://www.amazon.science/blog/whats-next-for-deep-learning",
            "description": "Integrating symbolic reasoning and learning efficiently from interactions with the world are two major remaining challenges, says vice president and distinguished scientist Nikko Str\u00f6m.",
            "pubdate": "Tue, 22 Feb 2022 14:32:38 GMT",
            "pubdate_parsed": [
                2022,
                2,
                22
            ],
            "email_sent": true
        },
        "George Michailidis: How to identify important changes in online networks": {
            "url": "https://www.amazon.science/working-at-amazon/george-michailidis-anomaly-detection-machine-learning",
            "description": "Amazon Scholar discusses the evolution of anomaly detection research.",
            "pubdate": "Wed, 23 Feb 2022 14:06:36 GMT",
            "pubdate_parsed": [
                2022,
                2,
                23
            ],
            "email_sent": true
        },
        "How chance encounters sparked a career in engineering and robotics": {
            "url": "https://www.amazon.science/working-at-amazon/how-chance-encounters-sparked-a-career-in-engineering-and-robotics",
            "description": "Jovonia Thibert, director of strategy for Amazon Robotics, has a career that spans two decades \u2014 thanks in part to a lesson from her parents.",
            "pubdate": "Thu, 24 Feb 2022 15:13:41 GMT",
            "pubdate_parsed": [
                2022,
                2,
                24
            ],
            "email_sent": true
        },
        "Improving question-answering models that use data from tables": {
            "url": "https://www.amazon.science/blog/improving-question-answering-models-that-use-data-from-tables",
            "description": "Novel pretraining method enables increases of 5% to 14% on five different evaluation metrics.",
            "pubdate": "Mon, 28 Feb 2022 15:03:33 GMT",
            "pubdate_parsed": [
                2022,
                2,
                28
            ],
            "email_sent": true
        },
        "How Haluk Demirkan is using machine learning to get devices to the right place at the right time": {
            "url": "https://www.amazon.science/working-at-amazon/haluk-demirkan-sales-forecast-demand-planning",
            "description": "Part-time sabbatical plan turns into full-time role for author of five books and more than 170 research articles.",
            "pubdate": "Tue, 01 Mar 2022 14:37:09 GMT",
            "pubdate_parsed": [
                2022,
                3,
                1
            ],
            "email_sent": true
        },
        "Amazon VP Babak Parviz appointed to AAAS Board of Directors": {
            "url": "https://www.amazon.science/latest-news/amazon-vp-babak-parviz-appointed-to-aaas-board-of-directors",
            "description": "Parviz will serve a three-year term as one of four appointed directors.",
            "pubdate": "Wed, 02 Mar 2022 18:51:28 GMT",
            "pubdate_parsed": [
                2022,
                3,
                2
            ],
            "email_sent": true
        },
        "Using natural language processing to understand and identify risks": {
            "url": "https://www.amazon.science/working-at-amazon/using-natural-language-processing-to-understand-and-identify-risks",
            "description": "As an applied science manager at Amazon, Muthu Chandrasekaran works on new tools to automate and build a risk technology.",
            "pubdate": "Thu, 03 Mar 2022 14:00:37 GMT",
            "pubdate_parsed": [
                2022,
                3,
                3
            ],
            "email_sent": true
        },
        "How Prime Video uses machine learning to ensure video quality": {
            "url": "https://www.amazon.science/blog/how-prime-video-uses-machine-learning-to-ensure-video-quality",
            "description": "Detectors for block corruption, audio artifacts, and errors in audio-video synchronization are just three of Prime Video\u2019s quality assurance tools.",
            "pubdate": "Fri, 04 Mar 2022 17:13:15 GMT",
            "pubdate_parsed": [
                2022,
                3,
                4
            ],
            "email_sent": true
        },
        "Amazon and Energy Dept. team up to change how we recycle plastic": {
            "url": "https://www.amazon.science/blog/amazon-and-energy-dept-team-up-to-change-how-we-recycle-plastic",
            "description": "Amazon joins the US DOE\u2019s Bio-Optimized Technologies to keep Thermoplastics out of Landfills and the Environment (BOTTLE\u2122) Consortium, focusing on materials and recycling innovation.",
            "pubdate": "Wed, 09 Mar 2022 12:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                9
            ],
            "email_sent": true
        },
        "25 years of QIP": {
            "url": "https://www.amazon.science/blog/25-years-of-qip",
            "description": "As the major quantum computing conference celebrates its anniversary, we ask the conference chair and the head of Amazon\u2019s quantum computing program to take stock.",
            "pubdate": "Thu, 10 Mar 2022 15:03:42 GMT",
            "pubdate_parsed": [
                2022,
                3,
                10
            ],
            "email_sent": true
        },
        "Amazon and Virginia Tech launch AI and ML research initiative": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-virginia-tech-launch-ai-and-ml-research-initiative",
            "description": "Initiative will be led by the Virginia Tech College of Engineering and directed by Thomas L. Phillips Professor of Engineering Naren Ramakrishnan.",
            "pubdate": "Thu, 10 Mar 2022 10:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                10
            ],
            "email_sent": true
        },
        "Bringing practical applications of quantum computing closer": {
            "url": "https://www.amazon.science/blog/bringing-practical-applications-of-quantum-computing-closer",
            "description": "New phase estimation technique reduces qubit count, while learning framework enables characterization of noisy quantum systems.",
            "pubdate": "Fri, 11 Mar 2022 15:58:31 GMT",
            "pubdate_parsed": [
                2022,
                3,
                11
            ],
            "email_sent": true
        },
        "Amazon Science celebrates Pi Day": {
            "url": "https://www.amazon.science/latest-news/pi-day-2022",
            "description": "Times Square display honors scientists, engineers, and mathematicians past, present, and future.",
            "pubdate": "Mon, 14 Mar 2022 12:59:11 GMT",
            "pubdate_parsed": [
                2022,
                3,
                14
            ],
            "email_sent": true
        },
        "Registration opens for Amazon re:MARS event": {
            "url": "https://www.amazon.science/latest-news/registration-opens-for-amazon-re-mars-event",
            "description": "In-person event featuring some of the brightest leaders in science, academia, and business is planned for June 21-24 in Las Vegas",
            "pubdate": "Tue, 15 Mar 2022 17:31:04 GMT",
            "pubdate_parsed": [
                2022,
                3,
                15
            ],
            "email_sent": true
        },
        "Real-world robotic-manipulation system": {
            "url": "https://www.amazon.science/research-awards/success-stories/real-world-robotic-manipulation-system",
            "description": "Amazon Research Award recipient Russ Tedrake is teaching robots to manipulate a wide variety of objects in unfamiliar and constantly changing contexts.",
            "pubdate": "Tue, 15 Mar 2022 14:16:52 GMT",
            "pubdate_parsed": [
                2022,
                3,
                15
            ],
            "email_sent": true
        },
        "The science behind Hunches: Deep device embeddings": {
            "url": "https://www.amazon.science/blog/the-science-behind-hunches-deep-device-embeddings",
            "description": "A machine learning model learns representations that cluster devices according to their usage patterns.",
            "pubdate": "Wed, 16 Mar 2022 17:51:14 GMT",
            "pubdate_parsed": [
                2022,
                3,
                16
            ],
            "email_sent": true
        },
        "Nadia Carlsten drives Amazon's quest for a quantum breakthrough": {
            "url": "https://www.amazon.science/working-at-amazon/nadia-carlsten-drives-amazons-quest-for-a-quantum-breakthrough",
            "description": "The senior product manager leading hardware and software product development at the Center for Quantum Computing wants to make fault-tolerant quantum computing a reality.",
            "pubdate": "Thu, 17 Mar 2022 14:11:49 GMT",
            "pubdate_parsed": [
                2022,
                3,
                17
            ],
            "email_sent": true
        },
        "Huseyin Topaloglu receives Cornell endowed faculty chair": {
            "url": "https://www.amazon.science/latest-news/amazon-scholar-huseyin-topaloglu-receives-endowed-faculty-chair-at-cornell",
            "description": "The Howard and Eleanor Morgan Professor is awarded to a Cornell faculty member who has made meaningful contributions to operations research.",
            "pubdate": "Fri, 18 Mar 2022 12:47:58 GMT",
            "pubdate_parsed": [
                2022,
                3,
                18
            ],
            "email_sent": true
        },
        "New Amazon graduate research fellows announced at Carnegie Mellon": {
            "url": "https://www.amazon.science/academic-engagements/new-amazon-graduate-research-fellows-announced-at-carnegie-mellon",
            "description": "Graduate Research Fellows Program, launched in 2021, supports research in automated reasoning, computer vision, robotics, language technology, machine learning, operations research, and data science.",
            "pubdate": "Mon, 21 Mar 2022 12:55:18 GMT",
            "pubdate_parsed": [
                2022,
                3,
                21
            ],
            "email_sent": true
        },
        "Monitoring and rewarding honest bids to increase auction revenue": {
            "url": "https://www.amazon.science/latest-news/monitoring-and-rewarding-honest-bids-to-increase-revenue-in-auctions",
            "description": "Amazon Scholar Alexandre Belloni discusses the implications of auction design on digital goods.",
            "pubdate": "Tue, 22 Mar 2022 14:29:51 GMT",
            "pubdate_parsed": [
                2022,
                3,
                22
            ],
            "email_sent": true
        },
        "Making DeepSpeed ZeRO run efficiently on more-affordable hardware": {
            "url": "https://www.amazon.science/blog/making-deepspeed-zero-run-efficiently-on-more-affordable-hardware",
            "description": "Amazon researchers optimize the distributed-training tool to run efficiently on the Elastic Fabric Adapter network interface.",
            "pubdate": "Wed, 23 Mar 2022 14:29:08 GMT",
            "pubdate_parsed": [
                2022,
                3,
                23
            ],
            "email_sent": true
        },
        "How AWS uses graph neural networks to meet customer needs": {
            "url": "https://www.amazon.science/blog/how-aws-uses-graph-neural-networks-to-meet-customer-needs",
            "description": "Information extraction, drug discovery, and software analysis are just a few applications of this versatile tool.",
            "pubdate": "Thu, 24 Mar 2022 16:17:39 GMT",
            "pubdate_parsed": [
                2022,
                3,
                24
            ],
            "email_sent": true
        },
        "Amazon to host StatML Oxford Imperial ML Workshop in Berlin office": {
            "url": "https://www.amazon.science/latest-news/amazon-to-host-statml-oxford-imperial-ml-workshop-in-berlin-office",
            "description": "Workshop provides opportunity for students to showcase their work and for connections to be established between academics and Amazon researchers.",
            "pubdate": "Mon, 28 Mar 2022 20:34:28 GMT",
            "pubdate_parsed": [
                2022,
                3,
                28
            ],
            "email_sent": true
        },
        "Edouard Belval: From AWS intern to research engineer": {
            "url": "https://www.amazon.science/working-at-amazon/edouard-belval-from-aws-intern-to-research-engineer",
            "description": "How he parlayed an internship to land an expanded role at Amazon while pursuing his master\u2019s degree.",
            "pubdate": "Wed, 30 Mar 2022 13:05:25 GMT",
            "pubdate_parsed": [
                2022,
                3,
                30
            ],
            "email_sent": true
        },
        "Postdoctoral Science Program": {
            "url": "https://www.amazon.science/postdoctoral-science-program",
            "description": "The program offers recent PhD graduates an opportunity to advance research while working alongside experienced scientists with backgrounds in industry and academia.",
            "pubdate": "Thu, 31 Mar 2022 20:59:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                31
            ],
            "email_sent": true
        },
        "Improving forecasting by learning quantile functions": {
            "url": "https://www.amazon.science/blog/improving-forecasting-by-learning-quantile-functions",
            "description": "Learning the complete quantile function, which maps probabilities to variable values, rather than building separate models for each quantile level, enables better optimization of resource trade-offs.",
            "pubdate": "Thu, 31 Mar 2022 14:21:48 GMT",
            "pubdate_parsed": [
                2022,
                3,
                31
            ],
            "email_sent": true
        },
        "Scalable framework lets multiple text-to-speech models coexist": {
            "url": "https://www.amazon.science/blog/text-to-speech-models-coexist-thanks-to-scalable-framework",
            "description": "Thanks to a set of simple abstractions, models with different architectures can be integrated and optimized for particular hardware accelerators.",
            "pubdate": "Mon, 04 Apr 2022 15:12:34 GMT",
            "pubdate_parsed": [
                2022,
                4,
                4
            ],
            "email_sent": true
        },
        "How applied math impacts forecasting at Amazon": {
            "url": "https://www.amazon.science/working-at-amazon/how-applied-math-impacts-forecasting-at-amazon",
            "description": "Danielle Maddix Robinson's mathematics background helps inform robust models that can predict everything from retail demand to epidemiology.",
            "pubdate": "Tue, 05 Apr 2022 13:09:14 GMT",
            "pubdate_parsed": [
                2022,
                4,
                5
            ],
            "email_sent": true
        },
        "Helping AWS customers accelerate success via machine learning": {
            "url": "https://www.amazon.science/working-at-amazon/helping-aws-customers-accelerate-success-via-machine-learning",
            "description": "Priya Ponnapalli leads the Amazon Machine Learning Solutions Lab, fostering inclusion and growth for her team along the way.",
            "pubdate": "Wed, 06 Apr 2022 13:58:50 GMT",
            "pubdate_parsed": [
                2022,
                4,
                6
            ],
            "email_sent": true
        },
        "Amazon helps create first conference on causal learning and reasoning": {
            "url": "https://www.amazon.science/blog/amazon-helps-create-first-conference-on-causal-learning-and-reasoning",
            "description": "Conference will be held April 11 \u2013 13 in Eureka, California, with virtual elements.",
            "pubdate": "Thu, 07 Apr 2022 18:53:47 GMT",
            "pubdate_parsed": [
                2022,
                4,
                7
            ],
            "email_sent": true
        },
        "Amazon and Johns Hopkins announce new AI institute": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-johns-hopkins-announce-new-ai-institute",
            "description": "The JHU + Amazon Initiative for Interactive AI (AI2AI) will be housed in the Whiting School of Engineering.",
            "pubdate": "Thu, 07 Apr 2022 14:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                7
            ],
            "email_sent": true
        },
        "At Amazon Robotics, simulation gains traction": {
            "url": "https://www.amazon.science/latest-news/at-amazon-robotics-simulation-gains-traction",
            "description": "Scientists and engineers are developing a new generation of simulation tools accurate enough to develop and test robots virtually.",
            "pubdate": "Fri, 08 Apr 2022 13:29:36 GMT",
            "pubdate_parsed": [
                2022,
                4,
                8
            ],
            "email_sent": true
        },
        "New method for \"editing\" fabricated chips enables more-efficient designs": {
            "url": "https://www.amazon.science/blog/new-method-for-editing-fabricated-chips-enables-more-efficient-designs",
            "description": "Reducing the energy of ion beams used for editing eliminates the need for \u201csacrificial\u201d areas between electrical components and improves precision.",
            "pubdate": "Tue, 12 Apr 2022 15:10:21 GMT",
            "pubdate_parsed": [
                2022,
                4,
                12
            ],
            "email_sent": true
        },
        "Luciana Buriols quest for scientific joy": {
            "url": "https://www.amazon.science/working-at-amazon/luciana-buriols-quest-for-scientific-joy",
            "description": "The principal research scientist shares lessons learned during her life journey from a small farm to working on optimizing Amazon\u2019s distribution network.",
            "pubdate": "Wed, 13 Apr 2022 13:30:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                13
            ],
            "email_sent": true
        },
        "Amazon Scholar contributes to best student paper award": {
            "url": "https://www.amazon.science/latest-news/amazon-scholar-contributes-to-best-student-paper-award",
            "description": "Paper proposes a method to better and more equitably place COVID vaccine clinics to encourage more vaccinations.",
            "pubdate": "Thu, 14 Apr 2022 13:03:37 GMT",
            "pubdate_parsed": [
                2022,
                4,
                14
            ],
            "email_sent": true
        },
        "Xiuli Chao appointed Ralph Disney Collegiate Professor at UM": {
            "url": "https://www.amazon.science/latest-news/xiuli-zack-chao-appointed-ralph-l-disney-collegiate-professor-of-industrial-and-operations-engineering",
            "description": "Professorship named after influential former University of Michigan professor.",
            "pubdate": "Fri, 15 Apr 2022 13:16:28 GMT",
            "pubdate_parsed": [
                2022,
                4,
                15
            ],
            "email_sent": true
        },
        "Robin deals with a world where things are changing all around it": {
            "url": "https://www.amazon.science/latest-news/robin-deals-with-a-world-where-things-are-changing-all-around-it",
            "description": "An advanced perception system, which detects and learns from its own mistakes, enables Robin robots to select individual objects from jumbled packages \u2014 at production scale.",
            "pubdate": "Mon, 18 Apr 2022 14:15:43 GMT",
            "pubdate_parsed": [
                2022,
                4,
                18
            ],
            "email_sent": true
        },
        "How does Astro localize itself in an ever-changing home?": {
            "url": "https://www.amazon.science/blog/how-does-astro-localize-itself-in-an-ever-changing-home",
            "description": "Deep learning to produce invariant representations, estimations of sensor reliability, and efficient map representations all contribute to Astro\u2019s superior spatial intelligence.",
            "pubdate": "Tue, 19 Apr 2022 14:23:24 GMT",
            "pubdate_parsed": [
                2022,
                4,
                19
            ],
            "email_sent": true
        },
        "Amazon releases 51-language dataset for language understanding": {
            "url": "https://www.amazon.science/blog/amazon-releases-51-language-dataset-for-language-understanding",
            "description": "MASSIVE dataset and Massively Multilingual NLU (MMNLU-22) competition and workshop will help researchers scale natural-language-understanding technology to every language on Earth.",
            "pubdate": "Wed, 20 Apr 2022 12:55:45 GMT",
            "pubdate_parsed": [
                2022,
                4,
                20
            ],
            "email_sent": true
        },
        "TheWebConf: Stable themes, new wrinkles": {
            "url": "https://www.amazon.science/blog/thewebconf-blurring-the-line-between-industry-and-academic-research",
            "description": "Amazon Scholar Eugene Agichtein on incorporating knowledge into natural-language-processing models, multimodal interactions, and more.",
            "pubdate": "Thu, 21 Apr 2022 14:31:22 GMT",
            "pubdate_parsed": [
                2022,
                4,
                21
            ],
            "email_sent": true
        },
        "How Zoox vehicles find themselves in an ever-changing world": {
            "url": "https://www.amazon.science/latest-news/how-zoox-vehicles-find-themselves-in-an-ever-changing-world",
            "description": "Advanced machine learning systems help autonomous vehicles react to unexpected changes.",
            "pubdate": "Mon, 25 Apr 2022 14:15:20 GMT",
            "pubdate_parsed": [
                2022,
                4,
                25
            ],
            "email_sent": true
        },
        "Amazon at ICLR: Graphs, time series, and more": {
            "url": "https://www.amazon.science/blog/amazon-at-iclr-graphs-time-series-and-more",
            "description": "Other paper topics include natural-language processing, dataset optimization, and the limits of existing machine learning techniques.",
            "pubdate": "Tue, 26 Apr 2022 15:42:26 GMT",
            "pubdate_parsed": [
                2022,
                4,
                26
            ],
            "email_sent": true
        },
        "Registration remains open for June Amazon re:MARS event": {
            "url": "https://www.amazon.science/latest-news/registration-remains-open-for-june-amazon-re-mars-event",
            "description": "Event\u2019s speaker roster expands for keynotes, innovation spotlights, and leadership sessions.",
            "pubdate": "Wed, 27 Apr 2022 15:27:19 GMT",
            "pubdate_parsed": [
                2022,
                4,
                27
            ],
            "email_sent": true
        },
        "Advances in trustworthy machine learning at Alexa AI": {
            "url": "https://www.amazon.science/blog/advances-in-trustworthy-machine-learning-at-alexa-ai",
            "description": "The team\u2019s latest research on privacy-preserving machine learning, federated learning, and bias mitigation.",
            "pubdate": "Thu, 28 Apr 2022 15:49:50 GMT",
            "pubdate_parsed": [
                2022,
                4,
                28
            ],
            "email_sent": true
        },
        "Improving unsupervised sentence-pair comparison": {
            "url": "https://www.amazon.science/blog/improving-unsupervised-sentence-pair-comparison",
            "description": "Method that captures advantages of cross-encoding and bi-encoding improves on predecessors by as much as 5%.",
            "pubdate": "Fri, 29 Apr 2022 13:38:23 GMT",
            "pubdate_parsed": [
                2022,
                4,
                29
            ],
            "email_sent": true
        },
        "\"An accidental project born out of our need to innovate": {
            "url": "https://www.amazon.science/working-at-amazon/an-accidental-project-born-out-of-our-need-to-innovate",
            "description": "Former Amazon intern George Boateng is using machine learning and mobile tech to bridge Africa\u2019s digital divide.",
            "pubdate": "Mon, 02 May 2022 13:52:01 GMT",
            "pubdate_parsed": [
                2022,
                5,
                2
            ],
            "email_sent": true
        },
        "Ankan Bansals long journey into the world of computer vision": {
            "url": "https://www.amazon.science/working-at-amazon/ankan-bansals-long-journey-into-the-world-of-computer-vision",
            "description": "How a math-loving student travelled 7,000 miles to pursue a passion and wound up becoming an applied scientist.",
            "pubdate": "Tue, 03 May 2022 14:18:26 GMT",
            "pubdate_parsed": [
                2022,
                5,
                3
            ],
            "email_sent": true
        },
        "The science behind ultrasonic motion sensing for Echo": {
            "url": "https://www.amazon.science/blog/the-science-behind-ultrasonic-motion-sensing-for-echo",
            "description": "Reducing false positives for rare events, adapting Echo hardware to ultrasound sensing, and enabling concurrent ultrasound sensing and music playback are just a few challenges Amazon researchers addressed.",
            "pubdate": "Wed, 04 May 2022 15:33:54 GMT",
            "pubdate_parsed": [
                2022,
                5,
                4
            ],
            "email_sent": true
        },
        "Amazon and UCLA announce recipients of gift awards, graduate fellowships": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-ucla-announce-recipients-of-gift-awards-graduate-fellowships",
            "description": "The UCLA Science Hub seeks to address challenges to humanity through research using artificial intelligence, bringing together academic and industry scientists.",
            "pubdate": "Thu, 05 May 2022 13:51:02 GMT",
            "pubdate_parsed": [
                2022,
                5,
                5
            ],
            "email_sent": true
        },
        "More-efficient caching for product retrieval": {
            "url": "https://www.amazon.science/blog/more-efficient-caching-for-product-retrieval",
            "description": "Locality-sensitive hashing enables cache to hold more than three times as many query results.",
            "pubdate": "Fri, 06 May 2022 13:50:40 GMT",
            "pubdate_parsed": [
                2022,
                5,
                6
            ],
            "email_sent": true
        },
        "Amazon scientist Sergey Menis contributes to development of vaccine approach against HIV": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-scientist-sergey-menis-contributes-to-development-of-vaccine-approach-against-hiv",
            "description": "\"I hope we have accelerated HIV vaccine development by providing findings that we and others can build on.\"",
            "pubdate": "Mon, 09 May 2022 14:09:50 GMT",
            "pubdate_parsed": [
                2022,
                5,
                9
            ],
            "email_sent": true
        },
        "A quick guide to Amazons 50-plus ICASSP papers": {
            "url": "https://www.amazon.science/blog/a-quick-guide-to-amazons-50-plus-icassp-papers",
            "description": "Topics range from the predictable, such as speech recognition and signal processing, to time series forecasting and personalization.",
            "pubdate": "Tue, 10 May 2022 15:22:17 GMT",
            "pubdate_parsed": [
                2022,
                5,
                10
            ],
            "email_sent": true
        },
        "Alexas speech recognition research at ICASSP 2022": {
            "url": "https://www.amazon.science/blog/alexas-speech-recognition-research-at-icassp-2022",
            "description": "Multimodal training, signal-to-interpretation, and BERT rescoring are just a few topics covered by Amazon\u2019s 21 speech-related papers.",
            "pubdate": "Thu, 12 May 2022 15:21:30 GMT",
            "pubdate_parsed": [
                2022,
                5,
                12
            ],
            "email_sent": true
        },
        "Swami Sivasubramanian named to National AI Advisory Committee": {
            "url": "https://www.amazon.science/latest-news/swami-sivasubramanian-named-to-national-ai-advisory-committee",
            "description": "NAIAC will advise the president on a range of issues related to artificial intelligence.",
            "pubdate": "Thu, 12 May 2022 13:34:31 GMT",
            "pubdate_parsed": [
                2022,
                5,
                12
            ],
            "email_sent": true
        },
        "New textbook focuses on making better decisions in business and beyond": {
            "url": "https://www.amazon.science/latest-news/matt-taddy-business-analytics-data-science-interview",
            "description": "Matt Taddy, vice president of Amazon\u2019s Private Brands business, is the coauthor of Modern Business Analytics: Practical Data Science for Decision Making, a primer for those who want to gain the skills to use data science to help make decisions in business and beyond.",
            "pubdate": "Mon, 16 May 2022 13:36:49 GMT",
            "pubdate_parsed": [
                2022,
                5,
                16
            ],
            "email_sent": true
        },
        "Amazon Text-to-Speech group's research at ICASSP 2022": {
            "url": "https://www.amazon.science/blog/amazon-text-to-speech-groups-research-at-icassp-2022",
            "description": "Papers focus on speech conversion and data augmentation \u2014 and sometimes both at once.",
            "pubdate": "Tue, 17 May 2022 14:20:14 GMT",
            "pubdate_parsed": [
                2022,
                5,
                17
            ],
            "email_sent": true
        },
        "Amazon Redshift: Ten years of continuous reinvention": {
            "url": "https://www.amazon.science/latest-news/amazon-redshift-ten-years-of-continuous-reinvention",
            "description": "Two authors of Amazon Redshift research paper that will be presented at leading international forum for database researchers reflect on how far the first petabyte scale cloud data warehouse has advanced since it was announced ten years ago.",
            "pubdate": "Wed, 18 May 2022 13:02:19 GMT",
            "pubdate_parsed": [
                2022,
                5,
                18
            ],
            "email_sent": true
        },
        "Speeding database queries by rewriting redundancies": {
            "url": "https://www.amazon.science/blog/speeding-database-queries-by-rewriting-redundancies",
            "description": "Amazon Athena reduces query execution time by 14% by eliminating redundant operations.",
            "pubdate": "Thu, 19 May 2022 15:06:12 GMT",
            "pubdate_parsed": [
                2022,
                5,
                19
            ],
            "email_sent": true
        },
        "Amazon researchers honored by two esteemed academies": {
            "url": "https://www.amazon.science/latest-news/amazon-researchers-honored-by-two-esteemed-academies",
            "description": "Guido Imbens elected to the National Academy of Sciences; Alberto Abadie elected to American Academy of Arts and Sciences.",
            "pubdate": "Fri, 20 May 2022 12:29:26 GMT",
            "pubdate_parsed": [
                2022,
                5,
                20
            ],
            "email_sent": true
        },
        "Robotics at Amazon": {
            "url": "https://www.amazon.science/blog/icra-2022-robotics-at-amazon",
            "description": "Three of Amazon\u2019s leading roboticists \u2014 Sidd Srinivasa, Tye Brady, and Philipp Michel \u2014 discuss the challenges of building robotic systems that interact with human beings in real-world settings.",
            "pubdate": "Mon, 23 May 2022 16:38:34 GMT",
            "pubdate_parsed": [
                2022,
                5,
                23
            ],
            "email_sent": true
        },
        "How Amazon robots navigate congestion": {
            "url": "https://www.amazon.science/latest-news/how-amazon-robots-navigate-congestion",
            "description": "Amazon fulfillment centers use thousands of mobile robots. To keep products moving, Amazon Robotics researchers have crafted unique solutions.",
            "pubdate": "Tue, 24 May 2022 14:58:57 GMT",
            "pubdate_parsed": [
                2022,
                5,
                24
            ],
            "email_sent": true
        },
        "Amazon Robotics names 14 new Day One Fellowship recipients": {
            "url": "https://www.amazon.science/academic-engagements/amazon-robotics-expands-day-one-fellowship-program-and-selects-14-recipients-for-2022",
            "description": "Program empowers Black, Latinx, and Native American students to become industry leaders through scholarship, research, and career opportunities.",
            "pubdate": "Wed, 25 May 2022 18:02:29 GMT",
            "pubdate_parsed": [
                2022,
                5,
                25
            ],
            "email_sent": true
        },
        "Paper on translating images into maps wins ICRA best-paper award": {
            "url": "https://www.amazon.science/blog/translating-images-into-birds-eye-view-maps",
            "description": "Reformulating the mapping problem to take advantage of sequence-to-sequence Transformers improves performance by an average of 15%.",
            "pubdate": "Thu, 26 May 2022 14:51:18 GMT",
            "pubdate_parsed": [
                2022,
                5,
                26
            ],
            "email_sent": true
        },
        "ACL: What comes next for natural-language processing?": {
            "url": "https://www.amazon.science/blog/acl-what-comes-next-for-natural-language-processing",
            "description": "Amazon Scholar and Columbia professor Kathleen McKeown on model compression, data distribution shifts, language revitalization, and more.",
            "pubdate": "Fri, 27 May 2022 16:02:47 GMT",
            "pubdate_parsed": [
                2022,
                5,
                27
            ],
            "email_sent": true
        },
        "Amazon and Max Planck Society launch Science Hub": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-max-planck-society-launch-science-hub",
            "description": "The first Amazon Science Hub to exist outside the US will focus on driving AI research and development throughout Germany.",
            "pubdate": "Fri, 27 May 2022 11:10:27 GMT",
            "pubdate_parsed": [
                2022,
                5,
                27
            ],
            "email_sent": true
        },
        "AWS contributes novel causal machine learning algorithms to DoWhy": {
            "url": "https://www.amazon.science/blog/aws-contributes-novel-causal-machine-learning-algorithms-to-dowhy",
            "description": "New features go beyond conventional effect estimation by attributing events to individual components of complex systems.",
            "pubdate": "Tue, 31 May 2022 16:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                31
            ],
            "email_sent": true
        },
        "RescoreBERT: Using BERT models to improve ASR rescoring": {
            "url": "https://www.amazon.science/blog/rescorebert-using-bert-models-to-improve-asr-rescoring",
            "description": "Knowledge distillation and discriminative training enable efficient use of a BERT-based model to rescore automatic-speech-recognition hypotheses.",
            "pubdate": "Wed, 01 Jun 2022 14:04:39 GMT",
            "pubdate_parsed": [
                2022,
                6,
                1
            ],
            "email_sent": true
        },
        "Richard Zhang wins 2022 CHCCS Achievement Award": {
            "url": "https://www.amazon.science/latest-news/richard-zhang-wins-2022-canadian-human-computer-communications-society-achievement-award",
            "description": "The Amazon Scholar received the award for his seminal and sustained contributions to the fields of computer graphics and visual computing.",
            "pubdate": "Thu, 02 Jun 2022 12:54:28 GMT",
            "pubdate_parsed": [
                2022,
                6,
                2
            ],
            "email_sent": true
        },
        "Amazon Research Awards issues spring 2022 call for proposals": {
            "url": "https://www.amazon.science/research-awards/program-updates/amazon-research-awards-issues-spring-2022-call-for-proposals",
            "description": "Submission period extended to July 15.",
            "pubdate": "Fri, 03 Jun 2022 15:48:58 GMT",
            "pubdate_parsed": [
                2022,
                6,
                3
            ],
            "email_sent": true
        },
        "Compressing BART models for resource-constrained operation": {
            "url": "https://www.amazon.science/blog/compressing-bart-models-for-resource-constrained-operation",
            "description": "Combination of distillation and distillation-aware quantization compresses BART model to 1/16th its size.",
            "pubdate": "Mon, 06 Jun 2022 14:39:46 GMT",
            "pubdate_parsed": [
                2022,
                6,
                6
            ],
            "email_sent": true
        },
        "The next frontier in robotics": {
            "url": "https://www.amazon.science/latest-news/the-next-frontier-in-robotics",
            "description": "Zoox principal software engineer Olivier Toupet on company\u2019s autonomous robotaxi technology",
            "pubdate": "Tue, 07 Jun 2022 15:24:19 GMT",
            "pubdate_parsed": [
                2022,
                6,
                7
            ],
            "email_sent": true
        },
        "Simplifying BERT-based models to increase efficiency, capacity": {
            "url": "https://www.amazon.science/blog/simplifying-bert-based-models-to-increase-efficiency-capacity",
            "description": "New method would enable BERT-based natural-language-processing models to handle longer text strings, run in resource-constrained settings \u2014 or sometimes both.",
            "pubdate": "Wed, 08 Jun 2022 13:58:24 GMT",
            "pubdate_parsed": [
                2022,
                6,
                8
            ],
            "email_sent": true
        },
        "From petroleum engineering to machine learning": {
            "url": "https://www.amazon.science/working-at-amazon/from-petroleum-engineering-to-machine-learning",
            "description": "How Chukwudi Chukwudozie\u2019s path to Amazon was paved by a passion for problem-solving and growth.",
            "pubdate": "Thu, 09 Jun 2022 15:04:35 GMT",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        },
        "Alexa AIs natural-language-understanding papers at ICASSP 2022": {
            "url": "https://www.amazon.science/blog/alexa-ais-natural-language-understanding-papers-at-icassp-2022",
            "description": "Papers focus on learning previously unseen intents and personalization, both generally and in the specific case of recipe recommendation.",
            "pubdate": "Fri, 10 Jun 2022 14:26:10 GMT",
            "pubdate_parsed": [
                2022,
                6,
                10
            ],
            "email_sent": true
        },
        "Book demonstrates how to implement NLP business solutions": {
            "url": "https://www.amazon.science/latest-news/new-hands-on-guide-demonstrates-how-to-implement-natural-language-processing-business-solutions",
            "description": "Natural Language Processing with AWS AI Services seeks to demystify NLP for just about anyone.",
            "pubdate": "Mon, 13 Jun 2022 14:22:32 GMT",
            "pubdate_parsed": [
                2022,
                6,
                13
            ],
            "email_sent": true
        },
        "Amazon Robotics supports Georgia Tech startup incubator": {
            "url": "https://www.amazon.science/academic-engagements/amazon-robotics-supports-atdc-georgia-tech-startup-incubator",
            "description": "Funding will go toward assisting diverse entrepreneurs in the fields of robotics and automation.",
            "pubdate": "Tue, 14 Jun 2022 17:19:05 GMT",
            "pubdate_parsed": [
                2022,
                6,
                14
            ],
            "email_sent": true
        },
        "Three top performers emerge in inaugural Alexa Prize TaskBot Challenge": {
            "url": "https://www.amazon.science/alexa-prize/three-top-performers-emerge-in-inaugural-alexa-prize-taskbot-challenge",
            "description": "Digital assistants developed by competing teams helped users perform cooking and home-improvement tasks.",
            "pubdate": "Wed, 15 Jun 2022 14:00:27 GMT",
            "pubdate_parsed": [
                2022,
                6,
                15
            ],
            "email_sent": true
        },
        "CVPR: Understanding images means understanding the world": {
            "url": "https://www.amazon.science/blog/cvpr-understanding-images-means-understanding-the-world",
            "description": "Senior principal scientist Aleix M. Martinez on why computer vision research has only begun to scratch the surface.",
            "pubdate": "Thu, 16 Jun 2022 19:16:06 GMT",
            "pubdate_parsed": [
                2022,
                6,
                16
            ],
            "email_sent": true
        },
        "Amazon announces picks for best science books of 2022  so far": {
            "url": "https://www.amazon.science/latest-news/amazon-announces-picks-for-best-science-books-of-2022-so-far",
            "description": "Amazon yesterday announced its picks for 2022 Best Books of the Year So Far, including its top book within the general-interest science category, \u201cStolen Focus: Why You Can\u2019t Pay Attention \u2014 and How to Think Deeply Again\u201d.",
            "pubdate": "Thu, 16 Jun 2022 12:55:48 GMT",
            "pubdate_parsed": [
                2022,
                6,
                16
            ],
            "email_sent": true
        },
        "Calculating the differential cost of code changes": {
            "url": "https://www.amazon.science/blog/calculating-the-differential-cost-of-code-changes",
            "description": "Automated-reasoning method enables the calculation of tight bounds on the use of resources \u2014 such as computation or memory \u2014 that results from code changes.",
            "pubdate": "Fri, 17 Jun 2022 14:37:21 GMT",
            "pubdate_parsed": [
                2022,
                6,
                17
            ],
            "email_sent": true
        },
        "Anton van den Hengels journey from intellectual property law to computer vision pioneer": {
            "url": "https://www.amazon.science/working-at-amazon/anton-van-den-hengels-journey-from-intellectual-property-law-to-computer-vision-pioneer",
            "description": "Amazon\u2019s director of applied science in Adelaide, Australia, believes the economic value of computer vision has \u201cgone through the roof\".",
            "pubdate": "Mon, 20 Jun 2022 14:14:29 GMT",
            "pubdate_parsed": [
                2022,
                6,
                20
            ],
            "email_sent": true
        },
        "Olga Moskvyaks journey into the world of science": {
            "url": "https://www.amazon.science/working-at-amazon/olga-moskvyaks-journey-into-the-world-of-science",
            "description": "How she moved across the world to discover a passion for (and a career in) machine learning.",
            "pubdate": "Tue, 21 Jun 2022 13:45:33 GMT",
            "pubdate_parsed": [
                2022,
                6,
                21
            ],
            "email_sent": true
        },
        "Alexa's head scientist on conversational exploration, ambient AI": {
            "url": "https://www.amazon.science/blog/alexas-head-scientist-on-conversational-exploration-ambient-ai",
            "description": "Rohit Prasad on the pathway to generalizable intelligence and what excites him most about his re:MARS keynote.",
            "pubdate": "Wed, 22 Jun 2022 18:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                22
            ],
            "email_sent": true
        },
        "Prime Video's work on 3-D scene reconstruction, image representation": {
            "url": "https://www.amazon.science/blog/prime-videos-work-on-3-d-scene-reconstruction-image-representation",
            "description": "CVPR papers examine the recovery of 3-D information from camera movement and learning general representations from weakly annotated data.",
            "pubdate": "Wed, 22 Jun 2022 14:40:44 GMT",
            "pubdate_parsed": [
                2022,
                6,
                22
            ],
            "email_sent": true
        },
        "New workshop to help bring causal reasoning to recommendation systems": {
            "url": "https://www.amazon.science/blog/new-workshop-to-help-bring-causal-reasoning-to-recommendation-systems",
            "description": "Two-day RecSys workshop that extends the popular REVEAL to include CONSEQUENCES features Amazon organizers, speakers.",
            "pubdate": "Thu, 23 Jun 2022 20:34:45 GMT",
            "pubdate_parsed": [
                2022,
                6,
                23
            ],
            "email_sent": true
        },
        "Former Amazon intern Karsten Roth wins EMVA young professional award": {
            "url": "https://www.amazon.science/latest-news/former-amazon-intern-karsten-roth-wins-emva-young-professional-award",
            "description": "EMVA Young Professional Award honors \u201coutstanding and innovative work of a student or a young professional in the field of machine vision or image processing.\u201d",
            "pubdate": "Thu, 23 Jun 2022 17:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                23
            ],
            "email_sent": true
        },
        "Antia Lamas-Linaress path into the world of quantum": {
            "url": "https://www.amazon.science/working-at-amazon/antia-lamas-linaress-aws-quantum-networking",
            "description": "Among the \u2018first wave\u2019 of scientists to gain a PhD in quantum technology, the senior manager of research science discusses her two-decade-long career journey.",
            "pubdate": "Thu, 23 Jun 2022 14:18:44 GMT",
            "pubdate_parsed": [
                2022,
                6,
                23
            ],
            "email_sent": true
        },
        "A little public data makes privacy-preserving AI models more accurate": {
            "url": "https://www.amazon.science/blog/a-little-public-data-makes-privacy-preserving-ai-models-more-accurate",
            "description": "Technique that mixes public and private training data can meet differential-privacy criteria while cutting error increase by 60%-70%.",
            "pubdate": "Fri, 24 Jun 2022 21:38:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                24
            ],
            "email_sent": true
        },
        "How a passion for reinforcement learning guided Alexander Longs trajectory": {
            "url": "https://www.amazon.science/working-at-amazon/how-a-passion-for-reinforcement-learning-guided-alexander-longs-trajectory",
            "description": "The field motivated him to pursue a PhD, which eventually led him to Amazon.",
            "pubdate": "Fri, 24 Jun 2022 13:48:59 GMT",
            "pubdate_parsed": [
                2022,
                6,
                24
            ],
            "email_sent": true
        },
        "Near-linear scaling of gigantic-model training on AWS": {
            "url": "https://www.amazon.science/blog/near-linear-scaling-of-gigantic-model-training-on-aws",
            "description": "A new distributed-training library achieves near-linear efficiency in scaling from tens to hundreds of GPUs.",
            "pubdate": "Mon, 27 Jun 2022 19:01:57 GMT",
            "pubdate_parsed": [
                2022,
                6,
                27
            ],
            "email_sent": true
        },
        "Alexa Prize announces $1 million SocialBot Grand Challenge 5": {
            "url": "https://www.amazon.science/alexa-prize/socialbot-grand-challenge/2022",
            "description": "Next round of competition will add a science and innovation prize.",
            "pubdate": "Tue, 28 Jun 2022 18:01:56 GMT",
            "pubdate_parsed": [
                2022,
                6,
                28
            ],
            "email_sent": true
        },
        "Bringing the power of deep learning to data in tables": {
            "url": "https://www.amazon.science/blog/bringing-the-power-of-deep-learning-to-data-in-tables",
            "description": "Amazon\u2019s TabTransformer model is now available through SageMaker JumpStart and the official release of the Keras open-source library.",
            "pubdate": "Tue, 28 Jun 2022 15:36:53 GMT",
            "pubdate_parsed": [
                2022,
                6,
                28
            ],
            "email_sent": true
        },
        "Amazon scientists welcome Icelands presidential delegation": {
            "url": "https://www.amazon.science/blog/amazon-scientists-welcome-icelands-presidential-delegation",
            "description": "President\u2019s visit part of a mission to preserve the Icelandic language in the digital age.",
            "pubdate": "Wed, 29 Jun 2022 16:49:11 GMT",
            "pubdate_parsed": [
                2022,
                6,
                29
            ],
            "email_sent": true
        },
        "Amazons tiny robot drives do the heavy lifting": {
            "url": "https://www.amazon.science/latest-news/amazon-robotics-autonomous-drive-units-hercules-pegasus-xanthus-xbot",
            "description": "Autonomous robots called drives play a critical role in making billions of shipments every year. Here\u2019s how they work.",
            "pubdate": "Thu, 30 Jun 2022 12:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                30
            ],
            "email_sent": true
        },
        "Better joint representations of image and text": {
            "url": "https://www.amazon.science/blog/better-joint-representations-of-image-and-text",
            "description": "Two methods presented at CVPR achieve state-of-the-art results by imposing additional structure on the representational space.",
            "pubdate": "Fri, 01 Jul 2022 15:30:39 GMT",
            "pubdate_parsed": [
                2022,
                7,
                1
            ],
            "email_sent": true
        },
        "Ten stories from the first half of 2022 that captivated readers": {
            "url": "https://www.amazon.science/latest-news/ten-stories-from-the-first-half-of-2022-that-captivated-readers",
            "description": "From Josh Miele's passion for making the world more accessible to improving forecasting by learning quantile functions, these stories resonated with our audience.",
            "pubdate": "Mon, 04 Jul 2022 04:01:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                4
            ],
            "email_sent": true
        },
        "My experience at Amazon while teaching at Stanford": {
            "url": "https://www.amazon.science/working-at-amazon/my-experience-at-amazon-while-teaching-at-stanford",
            "description": "Co-mingling industry experience and academic teaching.",
            "pubdate": "Tue, 05 Jul 2022 14:03:03 GMT",
            "pubdate_parsed": [
                2022,
                7,
                5
            ],
            "email_sent": true
        },
        "Second annual Machine Learning Summer School launches in India": {
            "url": "https://www.amazon.science/academic-engagements/second-annual-ml-summer-school-amazon-india",
            "description": "Expanded program aimed at engineering undergraduate and graduate students builds off the success of inaugural program.",
            "pubdate": "Wed, 06 Jul 2022 14:39:07 GMT",
            "pubdate_parsed": [
                2022,
                7,
                6
            ],
            "email_sent": true
        },
        "Anwar Walid receives 2022 IEEE INFOCOM Test of Time Paper Award": {
            "url": "https://www.amazon.science/latest-news/anwar-walid-receives-2022-ieee-infocom-test-of-time-paper-award",
            "description": "Walid\u2019s 2010 paper on distributed caching algorithms for content distribution networks cited for its \u201csignificant impact on the research community\u201d.",
            "pubdate": "Thu, 07 Jul 2022 19:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                7
            ],
            "email_sent": true
        },
        "A quick guide to Amazons 45-plus NAACL papers": {
            "url": "https://www.amazon.science/blog/a-quick-guide-to-amazons-45-plus-naacl-papers",
            "description": "The breadth and originality of Amazon\u2019s natural-language-processing research are on display at the annual meeting of the North American chapter of the Association for Computational Linguistics.",
            "pubdate": "Thu, 07 Jul 2022 16:09:54 GMT",
            "pubdate_parsed": [
                2022,
                7,
                7
            ],
            "email_sent": true
        },
        "NAACL: Industry track offers reality checks, new directions": {
            "url": "https://www.amazon.science/blog/naacl-industry-track-offers-reality-checks-new-directions",
            "description": "Industry track chair and Amazon principal research scientist Rashmi Gangadharaiah on trends in industry papers and the challenges of building practical dialogue systems.",
            "pubdate": "Fri, 08 Jul 2022 17:19:26 GMT",
            "pubdate_parsed": [
                2022,
                7,
                8
            ],
            "email_sent": true
        },
        "Improving entity linking between texts and knowledge bases": {
            "url": "https://www.amazon.science/blog/improving-entity-linking-between-texts-and-knowledge-bases",
            "description": "New model sets new standard in accuracy while enabling 60-fold speedups.",
            "pubdate": "Fri, 08 Jul 2022 14:15:01 GMT",
            "pubdate_parsed": [
                2022,
                7,
                8
            ],
            "email_sent": true
        },
        "How events like Prime Day helped Amazon navigate the pandemic": {
            "url": "https://www.amazon.science/latest-news/how-peak-events-like-prime-day-helped-amazon-navigate-the-pandemic",
            "description": "The SCOT science team used lessons from the past \u2014 and improved existing tools \u2014 to contend with \u201ca peak that lasted two years\u201d.",
            "pubdate": "Mon, 11 Jul 2022 13:12:35 GMT",
            "pubdate_parsed": [
                2022,
                7,
                11
            ],
            "email_sent": true
        },
        "Machine Learning University expands with MLU Explains": {
            "url": "https://www.amazon.science/latest-news/amazon-machine-learning-university-new-courses-mlu-explains",
            "description": "Fun visual essays explain key concepts of machine learning.",
            "pubdate": "Tue, 12 Jul 2022 13:43:35 GMT",
            "pubdate_parsed": [
                2022,
                7,
                12
            ],
            "email_sent": true
        },
        "Amazon and MIT announce Science Hub gift project awards": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-mit-announce-science-hub-gift-project-awards",
            "description": "Four MIT professors are the recipients of the inaugural call for research projects.",
            "pubdate": "Wed, 13 Jul 2022 18:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                13
            ],
            "email_sent": true
        },
        "Knowledge distillation for better convergence in multitask learning": {
            "url": "https://www.amazon.science/blog/knowledge-distillation-for-better-convergence-in-multitask-learning",
            "description": "Allowing separate tasks to converge on their own schedules and using knowledge distillation to maintain performance improves accuracy.",
            "pubdate": "Wed, 13 Jul 2022 15:28:28 GMT",
            "pubdate_parsed": [
                2022,
                7,
                13
            ],
            "email_sent": true
        },
        "Why ambient computing needs self-learning": {
            "url": "https://www.amazon.science/blog/why-ambient-computing-needs-self-learning",
            "description": "To become the interface for the Internet of things, conversational agents will need to learn on their own. Alexa has already started down that path.",
            "pubdate": "Thu, 14 Jul 2022 20:59:54 GMT",
            "pubdate_parsed": [
                2022,
                7,
                14
            ],
            "email_sent": true
        },
        "Joris Kinable wins IISE Transactions 2022 Best Application Award": {
            "url": "https://www.amazon.science/latest-news/amazon-scientist-joris-kinable-wins-iise-transactions-2022-best-application-award",
            "description": "Paper explains the use of constraint programming and mathematical optimization techniques in calculating the best routes for snowplows to clear Pittsburgh\u2019s roads.",
            "pubdate": "Thu, 14 Jul 2022 13:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                14
            ],
            "email_sent": true
        },
        "Filtering out \"forbidden\" documents during information retrieval": {
            "url": "https://www.amazon.science/blog/filtering-out-forbidden-documents-during-information-retrieval",
            "description": "New method optimizes the twin demands of retrieving relevant content and filtering out bad content.",
            "pubdate": "Fri, 15 Jul 2022 18:14:51 GMT",
            "pubdate_parsed": [
                2022,
                7,
                15
            ],
            "email_sent": true
        },
        "Amazon scientists Mike Hicks and Ren Vidal honored": {
            "url": "https://www.amazon.science/latest-news/amazon-scientists-mike-hicks-and-rene-vidal-honored",
            "description": "Hicks wins 2022 ACM SIGPLAN Distinguished Service Award for career contributions; Vidal wins IEEE Signal Processing Magazine Best Paper Award.",
            "pubdate": "Fri, 15 Jul 2022 16:32:31 GMT",
            "pubdate_parsed": [
                2022,
                7,
                15
            ],
            "email_sent": true
        },
        "74 Amazon Research Awards recipients announced": {
            "url": "https://www.amazon.science/research-awards/program-updates/74-amazon-research-awards-recipients-announced",
            "description": "The awardees represent 51 universities in 17 countries. Recipients have access to more than 300 Amazon public datasets, and can utilize AWS AI/ML services and tools.",
            "pubdate": "Mon, 18 Jul 2022 16:10:38 GMT",
            "pubdate_parsed": [
                2022,
                7,
                18
            ],
            "email_sent": true
        },
        "New method identifies the root causes of statistical outliers": {
            "url": "https://www.amazon.science/blog/new-method-identifies-the-root-causes-of-statistical-outliers",
            "description": "Amazon ICML paper proposes information-theoretic measurement of quantitative causal contribution.",
            "pubdate": "Tue, 19 Jul 2022 15:20:16 GMT",
            "pubdate_parsed": [
                2022,
                7,
                19
            ],
            "email_sent": true
        },
        "\"Among all sources of information, visual information may be the most interesting\"": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-computer-vision-intern-to-applied-scientist-violetta-shevchenko",
            "description": "Violetta Shevchenko, an Amazon applied scientist and former intern, combines vision and language to create solutions to challenging problems.",
            "pubdate": "Wed, 20 Jul 2022 13:55:22 GMT",
            "pubdate_parsed": [
                2022,
                7,
                20
            ],
            "email_sent": true
        },
        "ICML: Where causality meets machine learning": {
            "url": "https://www.amazon.science/blog/icml-where-causality-meets-machine-learning",
            "description": "Amazon\u2019s Dominik Janzing on the history and promise of the young field of causal machine learning.",
            "pubdate": "Thu, 21 Jul 2022 13:43:23 GMT",
            "pubdate_parsed": [
                2022,
                7,
                21
            ],
            "email_sent": true
        },
        "Causal inference when treatments are continuous variables": {
            "url": "https://www.amazon.science/blog/causal-inference-when-treatments-are-continuous-variables",
            "description": "Combining a cutting-edge causal-inference technique and end-to-end machine learning reduces root-mean-square error by 27% to 38%.",
            "pubdate": "Fri, 22 Jul 2022 20:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                22
            ],
            "email_sent": true
        },
        "Massively Multilingual NLU 2022: Call for papers and shared-task entries": {
            "url": "https://www.amazon.science/blog/massively-multilingual-nlu-2022-call-for-papers-and-shared-task-entries",
            "description": "New EMNLP workshop will feature talks, papers, posters, and a competition built around the 50-plus-language, million-utterance MASSIVE dataset.",
            "pubdate": "Fri, 22 Jul 2022 16:39:17 GMT",
            "pubdate_parsed": [
                2022,
                7,
                22
            ],
            "email_sent": true
        },
        "Honorable mention to Amazon researchers for ICML test-of-time award": {
            "url": "https://www.amazon.science/blog/honorable-mention-to-amazon-researchers-for-icml-test-of-time-award",
            "description": "Amazon's Bernhard Sch\u00f6lkopf and Dominik Janzing are first and second authors on \"breakthrough 2012 paper\".",
            "pubdate": "Fri, 22 Jul 2022 14:21:28 GMT",
            "pubdate_parsed": [
                2022,
                7,
                22
            ],
            "email_sent": true
        },
        "Amazon-Columbia SURE students meet with Alexa AI VP": {
            "url": "https://www.amazon.science/academic-engagements/amazon-columbia-sure-students-meet-with-alexa-ai-vp",
            "description": "Prem Natarajan, Alexa AI vice president of natural understanding, visited the campus to engage with young STEM researchers from historically underrepresented backgrounds.",
            "pubdate": "Mon, 25 Jul 2022 19:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                25
            ],
            "email_sent": true
        },
        "How Amazon learned to cut its cardboard waste": {
            "url": "https://www.amazon.science/latest-news/amazon-cardboard-boxes-waste-reduction",
            "description": "Pioneering web-based PackOpt tool has resulted in an annual reduction in cardboard waste of 7% to 10% in North America, saving roughly 60,000 tons of cardboard annually.",
            "pubdate": "Mon, 25 Jul 2022 14:10:18 GMT",
            "pubdate_parsed": [
                2022,
                7,
                25
            ],
            "email_sent": true
        },
        "Preparing today for a post-quantum cryptographic future": {
            "url": "https://www.amazon.science/blog/preparing-today-for-a-post-quantum-cryptographic-future",
            "description": "Amazon is helping develop standards for post-quantum cryptography and deploying promising technologies for customers to experiment with.",
            "pubdate": "Tue, 26 Jul 2022 14:17:17 GMT",
            "pubdate_parsed": [
                2022,
                7,
                26
            ],
            "email_sent": true
        },
        "How silicon innovation became the secret sauce behind AWSs success": {
            "url": "https://www.amazon.science/how-silicon-innovation-became-the-secret-sauce-behind-awss-success",
            "description": "Nafea Bshara, AWS vice president and distinguished engineer, discusses Annapurna Lab\u2019s path to silicon success; Annapurna co-founder was a featured speaker at AWS Silicon Innovation Day virtual event.",
            "pubdate": "Wed, 27 Jul 2022 18:10:07 GMT",
            "pubdate_parsed": [
                2022,
                7,
                27
            ],
            "email_sent": true
        },
        "I didnt imagine I could grow and learn so much": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-internships-summer-2022-experience-donato-crisostomi-science-intern",
            "description": "Donato Crisostomi talks about how his mother helped spark a love of knowledge that led him to two science internships at Amazon.",
            "pubdate": "Thu, 28 Jul 2022 18:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                28
            ],
            "email_sent": true
        },
        "Amazon hosts largest class of science interns": {
            "url": "https://www.amazon.science/working-at-amazon/amazon-hosts-largest-class-of-science-interns",
            "description": "This year\u2019s class includes applied science, research science, and data science interns.",
            "pubdate": "Thu, 28 Jul 2022 14:33:08 GMT",
            "pubdate_parsed": [
                2022,
                7,
                28
            ],
            "email_sent": true
        },
        "A hyperparameter optimization library for reproducible research": {
            "url": "https://www.amazon.science/blog/a-hyperparameter-optimization-library-for-reproducible-research",
            "description": "Syne Tune supports multiple backends, single-fidelity and multi-fidelity (early-exit) optimization algorithms, and hyperparameter transfer learning.",
            "pubdate": "Fri, 29 Jul 2022 14:16:25 GMT",
            "pubdate_parsed": [
                2022,
                7,
                29
            ],
            "email_sent": true
        },
        "Amazon Scholar Kathleen McKeown receives dual honors": {
            "url": "https://www.amazon.science/latest-news/amazon-scholar-kathleen-mckeown-receives-dual-honors",
            "description": "McKeown awarded IEEE Innovation in Societal Infrastructure Award and named a member of the American Philosophical Society.",
            "pubdate": "Mon, 01 Aug 2022 18:02:14 GMT",
            "pubdate_parsed": [
                2022,
                8,
                1
            ],
            "email_sent": true
        },
        "The path to carbon reductions in high-growth economic sectors": {
            "url": "https://www.amazon.science/blog/the-path-to-carbon-reductions-in-high-growth-economic-sectors",
            "description": "Confronting climate change requires the participation of governments, companies, academics, civil-society organizations, and the public.",
            "pubdate": "Mon, 01 Aug 2022 14:37:12 GMT",
            "pubdate_parsed": [
                2022,
                8,
                1
            ],
            "email_sent": true
        },
        "20B-parameter Alexa model sets new marks in few-shot learning": {
            "url": "https://www.amazon.science/blog/20b-parameter-alexa-model-sets-new-marks-in-few-shot-learning",
            "description": "With an encoder-decoder architecture \u2014 rather than decoder only \u2014 the Alexa Teacher Model excels other large language models on few-shot tasks such as summarization and machine translation.",
            "pubdate": "Tue, 02 Aug 2022 12:59:36 GMT",
            "pubdate_parsed": [
                2022,
                8,
                2
            ],
            "email_sent": true
        },
        "Amazon wins best-paper award at first AutoML conference": {
            "url": "https://www.amazon.science/blog/amazon-wins-best-paper-award-at-first-automl-conference",
            "description": "Paper presents a criterion for halting the hyperparameter optimization process.",
            "pubdate": "Wed, 03 Aug 2022 13:35:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                3
            ],
            "email_sent": true
        },
        "Data science could be used everywhere": {
            "url": "https://www.amazon.science/working-at-amazon/mlu-data-scientist-jared-wilber",
            "description": "How Jared Wilber is using his skills as a storyteller and data scientist to help others learn about machine learning.",
            "pubdate": "Thu, 04 Aug 2022 13:28:47 GMT",
            "pubdate_parsed": [
                2022,
                8,
                4
            ],
            "email_sent": true
        },
        "Domenico Giannones never-ending drive to learn more from economic data": {
            "url": "https://www.amazon.science/working-at-amazon/domenico-giannone-nowcasting-amazon-economics-forecasting",
            "description": "How the Amazon Supply Chain Optimization Technologies principal economist uses his expertise in time series econometrics to forecast aggregate demand.",
            "pubdate": "Fri, 05 Aug 2022 14:08:26 GMT",
            "pubdate_parsed": [
                2022,
                8,
                5
            ],
            "email_sent": true
        },
        "Automated reasoning at Amazon: a conversation": {
            "url": "https://www.amazon.science/blog/automated-reasoning-at-federated-logic-conference-floc",
            "description": "To mark the occasion of the eighth Federated Logic Conference (FloC), Amazon\u2019s Byron Cook, Daniel Kr\u00f6ning, and Marijn Heule discussed automated reasoning\u2019s prospects.",
            "pubdate": "Mon, 08 Aug 2022 18:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                8
            ],
            "email_sent": true
        },
        "National Science Foundation and Amazon announce latest Fairness in AI grant projects": {
            "url": "https://www.amazon.science/academic-engagements/national-science-foundation-amazon-2022-fairness-in-AI-grant-projects",
            "description": "Thirteen new projects focus on ensuring fairness in AI algorithms and the systems that incorporate them.",
            "pubdate": "Mon, 08 Aug 2022 15:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                8
            ],
            "email_sent": true
        },
        "How the Zoox robotaxi predicts everything, everywhere, all at once": {
            "url": "https://www.amazon.science/latest-news/how-the-zoox-robotaxi-predicts-everything-everywhere-all-at-once",
            "description": "A combination of cutting-edge hardware, sensor technology, and bespoke machine learning approaches can predict trajectories of vehicles, people, and even animals, as far as 8 seconds into the future.",
            "pubdate": "Tue, 09 Aug 2022 14:56:10 GMT",
            "pubdate_parsed": [
                2022,
                8,
                9
            ],
            "email_sent": true
        },
        "Amazon and UW announce inaugural Science Hub faculty research awards": {
            "url": "https://www.amazon.science/academic-engagements/amazon-and-university-of-washington-announce-inaugural-science-hub-faculty-research-awards",
            "description": "Six UW professors will advance artificial intelligence and robotics research with new grants.",
            "pubdate": "Wed, 10 Aug 2022 16:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "Reid Blackman: The ethics of AI": {
            "url": "https://www.amazon.science/latest-news/reid-blackman-ethical-machines-the-ethics-of-ai",
            "description": "The author of Ethical Machines explains why companies pursuing ethical AI must ultimately place the responsibility with their senior leadership.",
            "pubdate": "Wed, 10 Aug 2022 14:10:50 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "KDD: Graph neural networks, fairness, and inclusivity": {
            "url": "https://www.amazon.science/blog/kdd-graph-neural-networks-fairness-and-inclusivity",
            "description": "The general chair of this year\u2019s Conference on Knowledge Discovery and Data Mining on what excites him most about the conference program.",
            "pubdate": "Thu, 11 Aug 2022 16:36:23 GMT",
            "pubdate_parsed": [
                2022,
                8,
                11
            ],
            "email_sent": true
        },
        "Erran Li receives 2022 SIGMOBILE test-of-time award": {
            "url": "https://www.amazon.science/latest-news/erran-li-receives-2022-sigmobile-test-of-time-award",
            "description": "Li and co-authors honored for creating an antenna design that was essential to the growth of mobile devices.",
            "pubdate": "Fri, 12 Aug 2022 16:31:47 GMT",
            "pubdate_parsed": [
                2022,
                8,
                12
            ],
            "email_sent": true
        },
        "Amazon wins contest to control \"formality\" in machine translation": {
            "url": "https://www.amazon.science/blog/amazon-wins-contest-to-control-formality-in-machine-translation",
            "description": "Data augmentation and post-editing strategies lift Amazon\u2019s submission above competitors.",
            "pubdate": "Mon, 15 Aug 2022 14:00:55 GMT",
            "pubdate_parsed": [
                2022,
                8,
                15
            ],
            "email_sent": true
        },
        "Ying Dings human-centered approach to AI-enhanced medical imaging diagnosis": {
            "url": "https://www.amazon.science/research-awards/success-stories/ying-dings-human-centered-approach-to-ai-enhanced-medical-imaging-diagnosis",
            "description": "ARA recipient is using artificial intelligence to help doctors make decisions based on radiological data.",
            "pubdate": "Tue, 16 Aug 2022 15:10:11 GMT",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "Scaling graph-neural-network training with CPU-GPU clusters": {
            "url": "https://www.amazon.science/blog/scaling-graph-neural-network-training-with-cpu-gpu-clusters",
            "description": "In tests, new approach is 15 to 18 times as fast as predecessors.",
            "pubdate": "Wed, 17 Aug 2022 14:57:33 GMT",
            "pubdate_parsed": [
                2022,
                8,
                17
            ],
            "email_sent": true
        },
        "A billion SMT queries a day": {
            "url": "https://www.amazon.science/blog/a-billion-smt-queries-a-day",
            "description": "CAV keynote lecture by the director of applied science for AWS Identity explains how AWS is making the power of automated reasoning available to all customers.",
            "pubdate": "Thu, 18 Aug 2022 17:00:35 GMT",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Ozge Sahin on the art and science of studying consumer behavior": {
            "url": "https://www.amazon.science/working-at-amazon/ozge-sahin-on-the-art-and-science-of-studying-consumer-behavior",
            "description": "The Johns Hopkins business school professor and Amazon Scholar focuses on enhancing customer experiences.",
            "pubdate": "Fri, 19 Aug 2022 19:15:05 GMT",
            "pubdate_parsed": [
                2022,
                8,
                19
            ],
            "email_sent": true
        },
        "Why Amazon Scholar Yossi Keshet remains \"excited about speech\"": {
            "url": "https://www.amazon.science/working-at-amazon/why-amazon-scholar-yossi-keshet-remains-excited-about-speech",
            "description": "New speech representations and self-supervised learning are two of the recent trends that most intrigue him.",
            "pubdate": "Tue, 23 Aug 2022 16:16:25 GMT",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "The science behind grouping package deliveries": {
            "url": "https://www.amazon.science/latest-news/the-science-behind-grouping-amazon-package-deliveries",
            "description": "How Customer Order and Network Density OptimizeR (CONDOR) has led to improved delivery routes.",
            "pubdate": "Wed, 24 Aug 2022 14:35:36 GMT",
            "pubdate_parsed": [
                2022,
                8,
                24
            ],
            "email_sent": true
        },
        "Amazon product query competition draws more than 9,200 submissions": {
            "url": "https://www.amazon.science/blog/amazon-product-query-competition-draws-more-than-9-200-submissions",
            "description": "Launched under the auspices of the KDD Cup at KDD 2022, the competition included the release of a new product query dataset.",
            "pubdate": "Thu, 25 Aug 2022 18:30:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "Using data science to help improve NFL quarterback passing scores": {
            "url": "https://www.amazon.science/working-at-amazon/elena-ehrlich-data-science-nfl-quarterback-passing-ratings",
            "description": "Principal data scientist Elena Ehrlich uses her skills to help a wide variety of customers \u2014 including the National Football League.",
            "pubdate": "Fri, 26 Aug 2022 13:58:02 GMT",
            "pubdate_parsed": [
                2022,
                8,
                26
            ],
            "email_sent": true
        },
        "The science behind NFL Next Gen Stats new passing metric": {
            "url": "https://www.amazon.science/blog/the-science-behind-nfl-next-gen-stats-new-passing-metric",
            "description": "Spliced binned-Pareto distributions are flexible enough to handle symmetric, asymmetric, and multimodal distributions, offering a more consistent metric.",
            "pubdate": "Fri, 26 Aug 2022 13:57:48 GMT",
            "pubdate_parsed": [
                2022,
                8,
                26
            ],
            "email_sent": true
        },
        "I always knew that my main interest was in supply chain optimization": {
            "url": "https://www.amazon.science/working-at-amazon/alp-muharremoglu-columbia-university-of-texas-operations-professor-amazon-scot",
            "description": "After 15 years in academia, Alp Muharremoglu became a senior principal senior scientist within Amazon\u2019s Supply Chain Optimization Technologies organization, and says his teaching skills are indispensable.",
            "pubdate": "Mon, 29 Aug 2022 13:36:27 GMT",
            "pubdate_parsed": [
                2022,
                8,
                29
            ],
            "email_sent": true
        },
        "Model assesses the validity of tips offered in product reviews": {
            "url": "https://www.amazon.science/blog/model-assesses-the-validity-of-tips-offered-in-product-reviews",
            "description": "Method would enable customers to evaluate supporting evidence for tip reliability.",
            "pubdate": "Fri, 02 Sep 2022 13:31:04 GMT",
            "pubdate_parsed": [
                2022,
                9,
                2
            ],
            "email_sent": true
        },
        "Automatically optimizing execution of unfamiliar tensor operations": {
            "url": "https://www.amazon.science/blog/automatically-optimizing-execution-of-unfamiliar-tensor-operations",
            "description": "New auto-scheduler speeds optimization process sixfold while improving performance of resulting code up to 70%.",
            "pubdate": "Thu, 08 Sep 2022 13:46:52 GMT",
            "pubdate_parsed": [
                2022,
                9,
                8
            ],
            "email_sent": true
        },
        "Interspeech 2022: The growth of interdisciplinary research": {
            "url": "https://www.amazon.science/blog/interspeech-2022-the-growth-of-interdisciplinary-research",
            "description": "Cyclic training of speech synthesis and speech recognition models and language understanding for better speech prosody are just a few examples of cross-pollination in speech-related fields.",
            "pubdate": "Wed, 14 Sep 2022 14:04:46 GMT",
            "pubdate_parsed": [
                2022,
                9,
                14
            ],
            "email_sent": true
        },
        "Jaco Geldenhuys and Willem Visser win ISSTA Impact Paper Award": {
            "url": "https://www.amazon.science/latest-news/amazon-scientists-jaco-geldenhuys-and-willem-visser-win-2022-issta-impact-paper-award",
            "description": "Scientists\u2019 paper on probabilistic symbolic execution has significantly influenced software testing and analysis.",
            "pubdate": "Wed, 21 Sep 2022 13:31:46 GMT",
            "pubdate_parsed": [
                2022,
                9,
                21
            ],
            "email_sent": true
        },
        "Amazon releases dataset for complex, multilingual question answering": {
            "url": "https://www.amazon.science/blog/amazon-releases-dataset-for-complex-multilingual-question-answering",
            "description": "Dataset that requires question-answering models to look up multiple facts and perform comparisons bridges a significant gap in the field.",
            "pubdate": "Wed, 05 Oct 2022 13:44:37 GMT",
            "pubdate_parsed": [
                2022,
                10,
                5
            ],
            "email_sent": true
        },
        "The science behind the new Alexa, what should I watch? Fire TV experience": {
            "url": "https://www.amazon.science/latest-news/the-science-behind-the-new-alexa-what-should-i-watch-fire-tv-experience",
            "description": "The phrase launches a feature built to help customers navigate an increasingly complex and diverse world of content.",
            "pubdate": "Thu, 06 Oct 2022 13:48:49 GMT",
            "pubdate_parsed": [
                2022,
                10,
                6
            ],
            "email_sent": true
        },
        "TRIPP explores the potential of VRpowered meditation": {
            "url": "https://www.amazon.science/latest-news/tripp-explores-the-potential-of-virtual-reality-powered-meditation",
            "description": "Alexa Fund portfolio company\u2019s science-led program could change how we approach mental wellness \u2014 and how we use VR.",
            "pubdate": "Fri, 07 Oct 2022 13:57:11 GMT",
            "pubdate_parsed": [
                2022,
                10,
                7
            ],
            "email_sent": true
        },
        "Maximizing the efficiency of Amazon's own delivery networks": {
            "url": "https://www.amazon.science/blog/maximizing-the-efficiency-of-amazons-own-delivery-networks",
            "description": "INFORMS talk explores techniques Amazon\u2019s Supply Chain Optimization Technologies organization is testing to fulfill customer orders more efficiently.",
            "pubdate": "Fri, 14 Oct 2022 13:44:31 GMT",
            "pubdate_parsed": [
                2022,
                10,
                14
            ],
            "email_sent": true
        },
        "Exploring the uncertainty of predictions": {
            "url": "https://www.amazon.science/latest-news/amazon-scholar-tatevik-sekhposyan-exploring-the-uncertainty-of-predictions",
            "description": "Tatevik Sekhposyan, Amazon Scholar and Texas A&amp;M University professor, enjoys the flexibility of economics and how embracing uncertainty can enhance prediction.",
            "pubdate": "Mon, 17 Oct 2022 13:38:13 GMT",
            "pubdate_parsed": [
                2022,
                10,
                17
            ],
            "email_sent": true
        },
        "reMARS revisited: Amazons supply chain optimization": {
            "url": "https://www.amazon.science/remars-revisited-amazons-supply-chain-optimization",
            "description": "How the SCOT team implemented a system that leverages operations research and machine learning to decide what products to buy, how much to buy, where to place them, and more.",
            "pubdate": "Tue, 18 Oct 2022 14:00:00 GMT",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "The quest to deploy autonomous robots within Amazon fulfillment centers": {
            "url": "https://www.amazon.science/latest-news/the-quest-to-deploy-autonomous-robots-within-amazon-fulfillment-centers",
            "description": "Company is testing a new class of robots that use artificial intelligence and computer vision to move freely throughout facilities.",
            "pubdate": "Mon, 24 Oct 2022 13:51:48 GMT",
            "pubdate_parsed": [
                2022,
                10,
                24
            ],
            "email_sent": true
        },
        "Amazon Robotics welcomes students to inaugural Day One Fellowship Summit": {
            "url": "https://www.amazon.science/latest-news/amazon-robotics-welcomes-students-to-inaugural-day-one-fellowship-summit",
            "description": "Summit offered Day One fellows the opportunity to interact with leaders in the robotics field.",
            "pubdate": "Tue, 25 Oct 2022 13:44:20 GMT",
            "pubdate_parsed": [
                2022,
                10,
                25
            ],
            "email_sent": true
        },
        "Amazon SCOT announces 2022 INFORMS Scholars": {
            "url": "https://www.amazon.science/latest-news/amazon-scot-announces-2022-informs-scholars",
            "description": "Program was established to help expand the pipeline of operations research, management science, and analytics talent from underrepresented backgrounds.",
            "pubdate": "Fri, 28 Oct 2022 13:32:13 GMT",
            "pubdate_parsed": [
                2022,
                10,
                28
            ],
            "email_sent": true
        },
        "David Schusters quest to make practical quantum computers a reality": {
            "url": "https://www.amazon.science/working-at-amazon/david-schusters-quest-to-make-practical-quantum-computers-a-reality",
            "description": "With quantum computers poised to take a big step forward, we speak to an Amazon Scholar who has spent two decades driving the technology to realize its enormous potential.",
            "pubdate": "Mon, 31 Oct 2022 14:00:17 GMT",
            "pubdate_parsed": [
                2022,
                10,
                31
            ],
            "email_sent": true
        },
        "Jens Lehmann receives Semantic Web journal 10-year award for influential paper": {
            "url": "https://www.amazon.science/latest-news/jens-lehmann-receives-semantic-web-journal-10-year-award-for-influential-paper",
            "description": "The work of Lehmann and three co-authors helped demonstrate the feasibility of large-scale virtual knowledge graphs.",
            "pubdate": "Fri, 04 Nov 2022 13:49:31 GMT",
            "pubdate_parsed": [
                2022,
                11,
                4
            ],
            "email_sent": true
        },
        "Honors and awards presented to Amazon researchers": {
            "url": "https://www.amazon.science/latest-news/honors-and-awards-presented-to-amazon-researchers-november-2022",
            "description": "Omar Javed, Steven Flammia, Michael I. Jordan, and Daniela Witten recently recognized for their contributions to science.",
            "pubdate": "Mon, 14 Nov 2022 13:30:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                14
            ],
            "email_sent": true
        },
        "How Amazon integrated Alexa into NASAs Orion spacecraft": {
            "url": "https://www.amazon.science/latest-news/the-science-behind-alexa-on-artemis-and-orion-spacecraft-nasa",
            "description": "From physical constraints to acoustic challenges, learn how Amazon collaborated with NASA and Lockheed Martin to get Alexa to work in space.",
            "pubdate": "Wed, 16 Nov 2022 10:50:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                16
            ],
            "email_sent": true
        },
        "How Amazon Robotics is working to eliminate the need for barcodes": {
            "url": "https://www.amazon.science/latest-news/how-amazon-robotics-is-working-on-new-ways-to-eliminate-the-need-for-barcodes",
            "description": "Why multimodal identification is a crucial step in automating item identification at Amazon scale.",
            "pubdate": "Fri, 09 Dec 2022 12:55:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                9
            ],
            "email_sent": true
        },
        "AmazonNext program hosts final project presentations at Virginia HQ2": {
            "url": "https://www.amazon.science/academic-engagements/amazonnext-program-hosts-final-project-presentations-at-virginia-hq2",
            "description": "Program focuses on diversifying tech-industry talent.",
            "pubdate": "Fri, 23 Dec 2022 13:19:31 GMT",
            "pubdate_parsed": [
                2022,
                12,
                23
            ],
            "email_sent": true
        },
        "Improving automatic discrimination of logos with similar texts": {
            "url": "https://www.amazon.science/blog/improving-automatic-discrimination-of-logos-with-similar-texts",
            "description": "Combining contrastive training and selection of hard negative examples establishes new benchmarks.",
            "pubdate": "Tue, 27 Dec 2022 01:52:08 GMT",
            "pubdate_parsed": [
                2022,
                12,
                27
            ],
            "email_sent": true
        },
        "Stories that inspired us in 2022": {
            "url": "https://www.amazon.science/latest-news/stories-that-inspired-us-in-2022",
            "description": "From the remarkable story of Josh Miele and his passion for improving accessibility, to the challenges overcome by scientists and engineers getting Alexa to work in space, these five stories touched both emotional and intellectual chords.",
            "pubdate": "Fri, 30 Dec 2022 12:00:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                30
            ],
            "email_sent": true
        },
        "Amazon and IIT Bombay launch multiyear collaboration": {
            "url": "https://www.amazon.science/news-and-features/amazon-and-iit-bombay-launch-multiyear-collaboration",
            "description": "Initiative will advance artificial intelligence and machine learning research within speech, language, and multimodal-AI domains.",
            "pubdate": "Mon, 27 Mar 2023 13:50:39 GMT",
            "pubdate_parsed": [
                2023,
                3,
                27
            ],
            "email_sent": true
        },
        "Amazon provides gift to 10 Penn PhD students for work on trustworthy AI": {
            "url": "https://www.amazon.science/news-and-features/amazon-provides-gift-to-10-penn-engineering-phd-students-for-work-on-trustworthy-ai",
            "description": "Projects are centered around themes of fairness, privacy, explainability, and interpretability.",
            "pubdate": "Wed, 03 May 2023 12:59:01 GMT",
            "pubdate_parsed": [
                2023,
                5,
                3
            ],
            "email_sent": true
        },
        "Paper on graph database schemata wins best-industry-paper award": {
            "url": "https://www.amazon.science/blog/paper-on-graph-database-schemata-wins-best-industry-paper-award",
            "description": "SIGMOD paper by Amazon researchers and collaborators presents flexible data definition language that enables rapid development of complex graph databases.",
            "pubdate": "Tue, 20 Jun 2023 13:00:09 GMT",
            "pubdate_parsed": [
                2023,
                6,
                20
            ],
            "email_sent": true
        },
        "A quick guide to Amazon's 20-plus papers at CVPR": {
            "url": "https://www.amazon.science/blog/a-quick-guide-to-amazons-20-plus-papers-at-cvpr",
            "description": "Image segmentation, multimodal models, and innovative machine learning methods are among the Amazon researchers' areas of focus.",
            "pubdate": "Wed, 21 Jun 2023 02:46:01 GMT",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Pronunciation detection for Alexas new English-learning experience": {
            "url": "https://www.amazon.science/blog/pronunciation-detection-for-alexas-new-english-learning-experience",
            "description": "Data augmentation, novel loss functions, and weakly supervised training enable a state-of-the art model for recognizing mispronunciations.",
            "pubdate": "Wed, 12 Jul 2023 13:04:05 GMT",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Your phone camera can autofocus. Why can't your specs?": {
            "url": "https://www.amazon.science/news-and-features/pixieray-ixi-high-tech-glasses-alexa-fund",
            "description": "Startup Pixieray is working on a breakthrough in vision correction.",
            "pubdate": "Wed, 16 Aug 2023 13:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                16
            ],
            "email_sent": true
        },
        "Interspeech: Where speech recognition and synthesis converge": {
            "url": "https://www.amazon.science/blog/interspeech-where-speech-recognition-and-synthesis-converge",
            "description": "Senior principal scientist Jasha Droppo on the shared architectures of large language models and spectrum quantization text-to-speech models \u2014 and other convergences between the two fields.",
            "pubdate": "Wed, 23 Aug 2023 13:17:23 GMT",
            "pubdate_parsed": [
                2023,
                8,
                23
            ],
            "email_sent": true
        },
        "Amazon & Virginia Tech announce fellowships, faculty research awards": {
            "url": "https://www.amazon.science/news-and-features/amazon-and-virginia-tech-announce-2023-2024-fellowship-faculty-research-award-recipients",
            "description": "Two PhD students and five professors will receive funding to conduct research toward improving the robustness and efficiency of AI systems.",
            "pubdate": "Mon, 02 Oct 2023 13:00:00 GMT",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "Alexa Prize TaskBot Challenge 2 winner announced": {
            "url": "https://www.amazon.science/alexa-prize/taskbot-challenge/2022",
            "description": "Team TWIZ from NOVA School of Science and Technology awarded $500,000 prize for first-place overall performance.",
            "pubdate": "Tue, 03 Oct 2023 13:00:34 GMT",
            "pubdate_parsed": [
                2023,
                10,
                3
            ],
            "email_sent": true
        }
    },
    "The Berkeley Artificial Intelligence Research Blog": {
        "Unsupervised Skill Discovery with Contrastive Intrinsic Control": {
            "url": "http://bair.berkeley.edu/blog/2022/02/23/cic/",
            "description": "<!--\nThese are comments in HTML. The above header text is needed to format the\ntitle, authors, etc. The \"example_post\" is an example representative image (not\nGIF) that we use for each post for tweeting (see below as well) and for the\nemails to subscribers. Please provide this image (and any other images and\nGIFs) in the blog to the BAIR Blog editors directly.\n\nThe text directly below gets tweets to work. Please adjust according to your\npost.\n\nThe `static/blog` directory is a location on the blog server which permanently\nstores the images/GIFs in BAIR Blog posts. Each post has a subdirectory under\nthis for its images (titled `example_post` here, please change).\n\nKeeping the post visbility as False will mean the post is only accessible if\nyou know the exact URL.\n\nYou can also turn on Disqus comments, but we recommend disabling this feature.\n-->\n\n<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<!--\nThe actual text for the post content appears below.  Text will appear on the\nhomepage, i.e., https://bair.berkeley.edu/blog/ but we only show part of the\nposts on the homepage. The rest is accessed via clicking 'Continue'. This is\nenforced with the `more` excerpt separator.\n-->\n\n<p><img alt=\"Main Image\" src=\"https://bair.berkeley.edu/static/blog/cic/img1.png\" /></p>\n\n<p>Unsupervised Reinforcement Learning (RL), where RL agents pre-train with self-supervised rewards, is an emerging paradigm for developing RL agents that are capable of generalization. Recently, we released the Unsupervised RL Benchmark (URLB) which we covered in a <a href=\"https://bair.berkeley.edu/blog/2021/12/15/unsupervised-rl/\">previous post</a>. URLB benchmarked many unsupervised RL algorithms across three categories \u2014 competence-based, knowledge-based, and data-based algorithms. A surprising finding was that competence-based algorithms significantly underperformed other categories. In this post we will demystify what has been holding back competence-based methods and introduce Contrastive Intrinsic Control (CIC), a new competence-based algorithm that is the first to achieve leading results on URLB.</p>\n\n<!--more-->\n\n<h2 id=\"results-from-benchmarking-unsupervised-rl-algorithms\">Results from benchmarking unsupervised RL algorithms</h2>\n\n<p>To recap, competence-based methods (which we will cover in detail) maximize the mutual information between states and skills (e.g. DIAYN), knowledge-based methods maximize the error of a predictive model (e.g. Curiosity), and data-based methods maximize the diversity of observed data (e.g. APT). Evaluating these algorithms on URLB by reward-free pre-training for 2M steps followed by 100k steps of finetuning across 12 downstream tasks, we previously found the following stack ranking of algorithms from the three categories.</p>\n\n<p><img alt=\"URLB results\" src=\"https://bair.berkeley.edu/static/blog/cic/img2.png\" /></p>\n\n<p>In the above figure competence-based methods (in green) do substantially worse than the other two types of unsupervised RL algorithms. Why is this the case and what can we do to resolve it?</p>\n\n<h2 id=\"competence-based-exploration\">Competence-based exploration</h2>\n\n<p>As a quick primer, competence-based algorithms maximize the mutual information between some observed variable such as a state and a latent skill vector, which is usually sampled from noise.</p>\n\n<p><img alt=\"Competence-based Exploration\" src=\"https://bair.berkeley.edu/static/blog/cic/img3.png\" /></p>\n\n<p>The mutual information is usually an intractable quantity and since we want to maximize it, we are usually better off maximizing a variational lower bound.</p>\n\n<p><img alt=\"Mutual Info Decomposition\" src=\"https://bair.berkeley.edu/static/blog/cic/img4.png\" /></p>\n\n<p>The quantity <code class=\"language-plaintext highlighter-rouge\">q(z|\\tau)</code> is referred to as the discriminator. In prior works, the discriminators are either classifiers over discrete skills or regressors over continuous skills. The problem is that classification and regression tasks need an exponential number of diverse data samples to be accurate. In simple environments where the number of potential behaviors is small, current competence-based methods work but not in environments where the set of potential behaviors is large and diverse.</p>\n\n<h2 id=\"how-environment-design-influences-performance\">How environment design influences performance</h2>\n\n<p>To illustrate this point, let\u2019s run three algorithms on the OpenAI Gym and DeepMind Control (DMC) Hopper. Gym Hopper resets when the agent loses balance while DMC episodes have fixed length regardless if the agent falls over. By resetting early, Gym Hopper constrains the agent to a small number of behaviors that can be achieved by remaining balanced. We run three algorithms \u2014 DIAYN and ICM, popular competence-based and knowledge-based algorithms, as well as a \u201cFixed\u201d agent which gets a reward of +1 for each timestep, and measure the zero-shot extrinsic reward for hopping during self-supervised pre-training.</p>\n\n<p><img alt=\"OpenAI Gym vs DMC\" src=\"https://bair.berkeley.edu/static/blog/cic/img5.png\" /></p>\n\n<p>On OpenAI Gym both DIAYN and the Fixed agent receive higher extrinsic rewards relative to ICM, but on the DeepMind Control Hopper both algorithms collapse. The only significant difference between the two environments is that OpenAI Gym resets early whereas DeepMind Control does not. This supports the hypothesis that when an environment supports many behaviors prior competence-based approaches struggle to learn useful skills.</p>\n\n<p>Indeed, if we visualize behaviors learned by DIAYN on other DeepMind Control environments, we see that it learns a small set of static skills.</p>\n\n<h3 id=\"prior-methods-fail-to-learn-diverse-behaviors\">Prior methods fail to learn diverse behaviors</h3>\n\n<p><img alt=\"diaynw1.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/diaynw1.gif\" />\n<img alt=\"diaynw2.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/diaynw2.gif\" />\n<img alt=\"diaynw3.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/diaynw3.gif\" />\n<img alt=\"diaynq1.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/diaynq1.gif\" />\n<img alt=\"diaynq2.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/diaynq2.gif\" />\n<img alt=\"diaynq3.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/diaynq3.gif\" /></p>\n\n<p><em>Skills learned by DIAYN after 2M steps of training.</em></p>\n\n<h2 id=\"effective-competence-based-exploration-with-contrastive-intrinsic-control-cic\">Effective competence-based exploration with Contrastive Intrinsic Control (CIC)</h2>\n\n<p>As illustrated in the above example - complex environments support a large number of skills and we therefore need discriminators capable of supporting large skill spaces. This tension between the need to support large skill spaces and the limitation of current discriminators leads us to propose Contrastive Intrinsic Control (CIC).</p>\n\n<p>Contrastive Intrinsic Control (CIC) introduces a new contrastive density estimator to approximate the conditional entropy (the discriminator). Unlike visual contrastive learning, this contrastive objective operates over <strong>state transitions</strong> and <strong>skill vectors</strong>. This allows us to bring powerful representation learning machinery from vision to unsupervised skill discovery.</p>\n\n<p><img alt=\"CIC Decomposition\" src=\"https://bair.berkeley.edu/static/blog/cic/img6.png\" /></p>\n\n<p>For a practical algorithm, we use the CIC contrastive skill learning as an auxiliary loss during pre-training. The self-supervised intrinsic reward is the value of the entropy estimate computed over the CIC embeddings. We also analyze other forms of intrinsic rewards in the paper, but this simple variant performs well with minimal complexity. The CIC architecture has the following form:</p>\n\n<p><img alt=\"CIC Architecture\" src=\"https://bair.berkeley.edu/static/blog/cic/img7.png\" /></p>\n\n<p>Qualitatively the behaviors from CIC after 2M steps of pre-training are quite diverse.</p>\n\n<h3 id=\"diverse-behaviors-learned-with-cic\">Diverse Behaviors learned with CIC</h3>\n\n<p><img alt=\"cicw1.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/cicw1.gif\" />\n<img alt=\"cicw2.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/cicw2.gif\" />\n<img alt=\"cicw3.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/cicw3.gif\" />\n<img alt=\"cicq1.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/cicq1.gif\" />\n<img alt=\"cicq2.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/cicq2.gif\" />\n<img alt=\"cicq3.gif\" src=\"https://bair.berkeley.edu/static/blog/cic/cicq3.gif\" /></p>\n\n<p><em>Skills learned by CIC after 2M steps of training.</em></p>\n\n<p>With explicit exploration through the state-transition entropy term and the contrastive skill discriminator for representation learning CIC adapts extremely efficiently to downstream tasks - outperforming prior competence-based approaches by <strong>1.78x</strong> and all prior exploration methods by <strong>1.19x</strong> on state-based URLB.</p>\n\n<p><img alt=\"Results\" src=\"https://bair.berkeley.edu/static/blog/cic/img8.png\" /></p>\n\n<p>We provide more information in the CIC paper about how architectural details and skill dimension affect the performance of the CIC paper. The main takeaway from CIC is that there is nothing wrong with the competence-based objective of maximizing mutual information. However, what matters is how well we approximate this objective, especially in environments that support a large number of behaviors. CIC is the first competence-based algorithm to achieve leading performance on URLB. Our hope is that our approach encourages other researchers to work on new unsupervised RL algorithms</p>\n\n<h2 id=\"links\">Links</h2>\n\n<p><strong>Paper:</strong> <a href=\"https://arxiv.org/abs/2202.00161\">CIC: Contrastive Intrinsic Control for Unsupervised Skill Discovery</a>\nMichael Laskin, Hao Liu, Xue Bin Peng, Denis Yarats, Aravind Rajeswaran, Pieter Abbeel</p>\n\n<p><strong>Code:</strong> <a href=\"https://github.com/rll-research/cic\">https://github.com/rll-research/cic</a></p>",
            "pubdate": "Wed, 23 Feb 2022 04:00:00 -0800",
            "pubdate_parsed": [
                2022,
                2,
                23
            ],
            "email_sent": true
        },
        "Accelerating Ukraine Intelligence Analysis with Computer Vision on Synthetic Aperture Radar Imagery": {
            "url": "http://bair.berkeley.edu/blog/2022/03/21/ukraine-sar-maers/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- body -->\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/ukraine-clouds-optim.gif\" width=\"120%\" />\n    <br />\n    <i><b>Figure 1:</b> Airmass measurements (clouds) over Ukraine from February 18, 2022 - March 01, 2022 from the SEVIRI instrument. Data accessed via the <a href=\"https://view.eumetsat.int/productviewer?v=default\">EUMETSAT Viewer</a>.</i>\n</p>\n\n<p>Satellite imagery is a critical source of information during the current invasion of Ukraine. Military strategists, journalists, and researchers use this imagery to make decisions, unveil violations of international agreements, and inform the public of the stark realities of war. With Ukraine experiencing a large amount of cloud cover and attacks often occuring during night-time, many forms of satellite imagery are hindered from seeing the ground. <a href=\"https://earthdata.nasa.gov/learn/backgrounders/what-is-sar\">Synthetic Aperture Radar (SAR)</a> imagery penetrates cloud cover, but requires special training to interpret. Automating this tedious task would enable real-time insights, but current computer vision methods developed on typical RGB imagery do not properly account for the phenomenology of SAR. This leads to suboptimal performance on this critical modality. Improving the access to and availability of SAR-specific methods, codebases, datasets, and pretrained models will benefit intelligence agencies, researchers, and journalists alike during this critical time for Ukraine.</p>\n\n<p>In this post, we present a baseline method and pretrained models that enable the interchangeable use of RGB and SAR for downstream classification, semantic segmentation, and change detection pipelines.</p>\n\n<!--more-->\n\n<h2 id=\"introduction\">Introduction</h2>\n\n<p>We live in a rapidly changing world, one that experiences natural disasters, civic upheaval, war, and all sorts of chaotic events which leave unpredictable\u2014and often permanent\u2014marks on the face of the planet. Understanding this change has historically been difficult. Surveyors were sent out to explore our new reality, and their distributed findings were often noisily integrated into a source of reality. Maintaining a constant state of vigilance has been a goal of mankind since we were able to conceive such a thought, all the way from when <a href=\"https://time.com/longform/aerial-photography-drones-history/\">Nadar took the first aerial photograph</a> to when <a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0273117715001623\">Sputnik 1\u2019s radio signals were used to analyze the ionosphere</a>.</p>\n\n<p>Vigilance, or to the French, <em>surveillance</em>, has been a part of human history for millenia. As with any tool, it has been a double-edged sword. Historically, surveillance without checks and balances has been detrimental to society. Conversely, the proper and responsible surveillance has allowed us to learn deep truths about our world which have resulted in advances in the <a href=\"https://www.nasa.gov/mission_pages/icebridge/instruments/index.html\">scientific</a> and <a href=\"https://web.archive.org/web/20211001071654/https://news.un.org/en/story/2006/04/176152-un-launches-new-enhanced-tool-use-satellite-data-fighting-hunger-poverty\">humanitarian</a> domains. With the amount of satellites in orbit today, our understanding of the environment is updated almost daily. We have rapidly transitioned from having very little information to now having more data than we can meaningfully extract knowledge from. Storing this information, let alone understanding, is an engineering challenge that is of growing urgency.</p>\n\n<h2 id=\"machine-learning-and-remote-sensing\">Machine Learning and Remote Sensing</h2>\n\n<p>With <a href=\"https://datacenterfrontier.com/terabytes-from-space-satellite-imaging-is-filling-data-centers/\">hundreds of terabytes</a> of data being downlinked from satellites to data centers every day, gaining knowledge and actionable insights from that data with manual processing has already become an impossible task. The most widely used form of remote sensing data is electro-optical (EO) satellite imagery. EO imagery is commonplace\u2014anyone who has used Google Maps or similar mapping software has interacted with EO satellite imagery.</p>\n\n<p>Machine learning (ML) on EO imagery is used in a wide variety of scientific and commercial applications. From <a href=\"https://journals.ametsoc.org/view/journals/hydr/17/3/jhm-d-15-0075_1.xml\">improving precipitation predictions</a>, <a href=\"https://www.sciencedirect.com/science/article/pii/S0924271618300479\">analyzing human slavery by identifying brick kilns</a>, to <a href=\"https://blog.google/products/maps/google-maps-101-ai-power-new-features-io-2021/\">classifying entire cities to improve traffic routing</a>, the outputs of ML on EO imagery have been integrated into almost every facet of human society.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/bridge-eo-kyiv.jpeg\" width=\"100%\" />\n    <br />\n    <i><a href=\"https://www.cnn.com/europe/live-news/ukraine-russia-putin-news-03-03-22/h_ed1c79ce964585a1d044c2dd50e2997a\"><b>Figure 2:</b> VHR EO imagery over the Kyiv region as acquired by Maxar on February 28, 2022</a>.</i>\n</p>\n\n<p>Commonly used satellite constellations for EO imagery include the <a href=\"https://landsat.gsfc.nasa.gov/\">Landsat</a> series of satellites operated by the United States Geological Survey and the <a href=\"https://sentinel.esa.int/web/sentinel/missions/sentinel-2\">Copernicus Sentinel-2</a> constellation operated by the European Space Agency. These constellations provide imagery at resolutions between 10-60 meters which is good enough for many use cases, but preclude the observation of finer details.</p>\n\n<h2 id=\"the-advent-of-very-high-resolution-commercial-electro-optical-satellite-imagery\">The Advent of Very High Resolution, Commercial Electro-Optical Satellite Imagery</h2>\n\n<p>Over the last few years, very high resolution (VHR) EO imagery has been made available through a variety of commercial sources. Ranging from between 0.3 - 2.0 meter resolution<sup id=\"fnref:1\"><a class=\"footnote\" href=\"https://bair.berkeley.edu/blog/feed.xml#fn:1\" rel=\"footnote\">1</a></sup>, companies such as <a href=\"https://www.planet.com/\">Planet</a>, <a href=\"https://www.maxar.com/\">Maxar</a>, <a href=\"https://www.airbus.com/en/products-services/space/earth-observation\">Airbus</a>, and others are providing extremely precise imagery with high revisit rates, <a href=\"https://www.fastcompany.com/40498033/every-day-this-satellite-company-takes-a-snapshot-of-the-entire-planet\">imaging the entire planet every day</a>.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/maxar-ships.jpeg\" width=\"100%\" />\n    <br />\n    <i><a href=\"https://blog.maxar.com/earth-intelligence/2022/enhancing-maritime-domain-awareness-with-maxars-crows-nest-solution\"><b>Figure 3:</b> An example of Maxar VHR EO imagery showing floating production, storage and off-loading units and a tanker</a>.</i>\n</p>\n\n<p>The increased resolution provided by VHR imagery enables a litany of downstream use cases. <a href=\"https://onlinelibrary.wiley.com/doi/full/10.1002/ldr.1094\">Erosion can be detected at finer scales</a>, and the <a href=\"https://xview2.org/\">building damage can be classified after natural disasters</a><strong>.</strong></p>\n\n<p>Machine learning methods have had to adapt in response to VHR satellite imagery. With an increased acuity, the amount of pixels and the <a href=\"http://xviewdataset.org/\">amount of classes that can be discerned</a> has increased by orders of magnitude. Computer vision research has responded by <a href=\"https://www.nature.com/articles/s41467-021-24638-z\">reducing the computational cost to learn efficient representation of satellite imagery</a>, creating <a href=\"https://arxiv.org/abs/2108.09186\">methods to alleviate the increased burden on labelers</a>, and even <a href=\"https://arxiv.org/abs/2111.08872\">engineering large software frameworks</a> to allow computer vision practitioners to handle this abundant source of imagery.</p>\n\n<p>In general, existing computer vision methods on other, non-aerial RGB imagery <a href=\"https://arxiv.org/abs/1510.00098\">transfer very well</a> to satellite imagery. This has allowed commercial VHR imagery to be immediately useful with highly accurate results.</p>\n\n<h2 id=\"the-problem-with-electro-optical-imagery\">The Problem with Electro-Optical Imagery</h2>\n\n<p>For highly turbulent and risky situations such as war and natural disasters, having constant, reliable access to the Earth is paramount.  Unfortunately, EO imagery cannot solve all of our surveillance needs. EO can only detect light sources during daytime, and as it turns out, <a href=\"https://earthobservatory.nasa.gov/images/85843/cloudy-earth\">nearly 2/3rds of the Earth is covered by clouds at any given time</a>. Unless you care about clouds, this blockage of the surface of the planet is problematic when understanding what happens on the ground is of critical importance. Machine learning methods attempt to sidestep this problem by <a href=\"https://hal-enpc.archives-ouvertes.fr/hal-01832797/document\">predicting what the world would look like without clouds</a>. However, the loss of information is fundamentally irrecoverable.</p>\n\n<h2 id=\"synthetic-aperture-radar-imagery\">Synthetic Aperture Radar Imagery</h2>\n\n<p>Synthetic aperture radar (SAR) imagery is an active form of remote sensing in which a satellite transmits pulses of microwave radar waves down to the surface of the Earth. These radar waves reflect off the ground and any objects on it and are returned back to the satellite. By processing these pulses over time and space, a SAR image is formed where each pixel is the superposition of different radar scatters.</p>\n\n<p>Radar waves penetrate clouds, and since the satellite is actively producing the radar waves, it illuminates the surface of the Earth even during the night. Synthetic aperture radar has a wide variety of uses, being used to <a href=\"https://ieeexplore.ieee.org/abstract/document/134087\">estimate the roughness of the Earth</a>, <a href=\"https://unitar.org/about/news-stories/news/unosat-introduces-ai-its-flood-rapid-mapping-operations-benefit-national-disaster-management\">mapping the extent of flooding over large areas</a>, and to <a href=\"https://iuu.xview.us/\">detect the presence of illegal fishing vessels in protected waters</a>.</p>\n\n<p>There are multiple SAR satellite constellations in operation at the moment. The <a href=\"https://sentinel.esa.int/web/sentinel/missions/sentinel-1\">Copernicus Sentinel-1</a> constellation provides imagery to the public at large with resolutions ranging from 10 - 80 meters (10 meter imagery being the most common. Most commercial SAR providers, such as <a href=\"https://www.iceye.com/\">ICEYE</a> and <a href=\"https://www.capellaspace.com/\">Capella Space</a>, provide imagery down to 0.5 meter resolution. In upcoming launches, other commercial vendors aim to produce SAR imagery with sub-0.5 meter resolution with high revisit rates as satellite constellations grow and government regulations evolve.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/sar-ukraine-belarus.jpg\" width=\"100%\" />\n    <br />\n    <i><a href=\"https://www.wired.co.uk/article/ukraine-russia-satellites\"><b>Figure 4:</b> A VHR SAR image provided by Capella Space over the Ukraine-Belarus border</a>.</i>\n</p>\n\n<h2 id=\"the-wacky-world-of-synthetic-aperture-radar-imagery\">The Wacky World of Synthetic Aperture Radar Imagery</h2>\n\n<p>While SAR imagery, at a quick glance, may look very similar to EO imagery, the underlying physics is quite different, which leads to many interesting effects in the imagery product which can be counterintuitive and incompatible with modern computer vision. Three common effects are termed polarization, layover, and multi-path effects.</p>\n\n<p>Radar antennas on SAR satellites often transmit polarized radar waves. The direction of polarization is the orientation of the wave\u2019s electric field. Objects on the ground exhibit different responses to the different polarizations of radar waves. Therefore, SAR satellites often operate in dual or quad-polarization modes, broadcasting horizontally (H) or vertically (V) polarized waves and reading either polarization back, resulting in HH, HV, VH, and VV bands. You can contrast this with RGB bands in EO imagery, but the fundamental physics are different.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/sentinel1-vv-vh.png\" width=\"100%\" />\n    <br />\n    <i><b>Figure 5:</b> Difference between VH (left) and VV (right) polarizations over the same region in Dnipro, Ukraine from Sentinel-1 radiometric terrain corrected imagery. As seen here, the radar returns in corresponding local regions can be different.</i>\n</p>\n\n<p>Layover is an effect in which radar beams reach the top of a structure before they reach the bottom, resulting in the top of the object being presented as overlapping with the bottom. This happens when objects are particularly tall. Visually, tall buildings appear as if they are laying on their side, while mountains will have their peaks intersecting with their bases.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/capella-layover.jpeg\" width=\"100%\" />\n    <br />\n    <i><a href=\"https://twitter.com/capellaspace/status/1367865023587049474/photo/1\"><b>Figure 6</b>: Example of layover in Capella\u2019s VHR SAR imagery.</a> The upper portion of the stadium is intersecting, seemingly, with the parking lot behind it.</i>\n</p>\n\n<p>Multi-path effects occur when radar waves reflect off of objects on the ground and incur multiple bounces before returning to the SAR sensor. Multi-path effects result in objects appearing in the imagery in various transformations in the resulting image. This effect can be seen everywhere in SAR imagery, but is particularly noticeable in urban areas, forests, and other dense environments.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/multipath.png\" width=\"100%\" />\n    <br />\n    <i><a href=\"https://discovery.ucl.ac.uk/id/eprint/10053908/\"><b>Figure 7:</b> Example of a multi-path effect on a bridge from oblique SAR imagery</a>.</i>\n</p>\n\n<p>Existing computer vision methods that are built on traditional RGB imagery are not built with these effects in mind. Object detectors trained on EO satellite imagery assume that a unique object will only appear once, or that the object will appear relatively similar in different contexts, rather than potentially mirrored or scattered or interwoven with surrounding objects. The very nature of occlusion and the vision principles underlying the assumptions of occlusion in EO imagery do not transfer to SAR. Taken together, existing computer vision techniques can transfer to SAR imagery, but with reduced performance and a set of systematic errors that can be addressed through SAR-specific methodology.</p>\n\n<p><strong>Computer Vision on SAR Imagery for Ukraine</strong></p>\n\n<p>Imagery analysts are currently relying on both EO and SAR imagery where available over Ukraine. When EO imagery is available, existing computer vision tooling built for that modality is used to expedite the process of intelligence gathering. However, when only SAR imagery is available, these toolchains cannot be used. Imagery analysts have to resort to manual analysis which is time consuming and can be prone to mistakes. This topic is being explored by some other institutions internationally, however, it still remains an understudied area with respect to the amount of data available.</p>\n\n<p>At Berkeley AI Research, we have created an initial set of methods and models that have learned robust representations for RGB, SAR, and co-registered RGB + SAR imagery from the publicly released <a href=\"https://bigearth.net\">BigEarthNet-MM dataset</a> and the data from <a href=\"https://www.capellaspace.com/community/capella-open-data/\">Capella\u2019s Open Data</a>, which consists of both RGB and SAR imagery. As such, using our models, imagery analysts are able to interchangeably use RGB, SAR, or co-registered RGB+SAR imagery for downstream tasks such as image classification, semantic segmentation, object detection, or change detection.</p>\n\n<p>Given that SAR is a phenomenologically different data source than EO imagery, we have found that the Vision Transformer (ViT) is a particularly effective architecture for representation learning with SAR as it removes the scale and shift invariant inductive biases built into convolutional neural networks. Our top performing method, MAERS, for representation learning on RGB, SAR, and co-registered RGB + SAR builds upon the <a href=\"https://arxiv.org/abs/2111.06377\">Masked Autoencoder</a> (MAE) recently introduced by He et. al., where the network learns to encode the input data by taking a masked version of the data as input, encoding the data, and then learning to decode the data in such a way that it reconstructs the unmasked input data.</p>\n\n<p>Contrary to popular <a href=\"https://arxiv.org/abs/2002.05709\">classes of contrastive learning techniques</a>, the MAE does not presuppose certain augmentation invariances in the data that may be incorrect for SAR features. Instead, it solely relies on reconstructing the original input, which is agnostic to RGB, SAR, or co-registered modalities. As shown in Figure 8, MAERS further extends MAE by learning independent input projection layers for RGB, SAR, and RGB+SAR channels, encoding the output of these projected layers using a shared ViT, and then decoding to the RGB, SAR, or RGB+SAR channels using independent output projection layers. The input projection layers and shared ViT can then be transferred to downstream tasks, such as object detection or change detection, where the input encoder can then take RGB, SAR, or RGB+SAR as input.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/maers.png\" width=\"100%\" />\n    <br />\n    <i><b>Figure 8:</b> (top) A visualization of MAERS to learn a joint representation and encoder that can be used for a (bottom) downstream task, such as object detection on either, or both, modalities.</i>\n</p>\n\n<p>Learning representations for RGB, SAR, and co-registered modalities can benefit a range of downstream tasks, such as content-based image retrieval, classification, segmentation, and detection. To demonstrate the effectiveness of our learned representations, we perform experiments on the well-established benchmarks of 1) multi-label classification of co-registered EO and SAR scenes from the <a href=\"https://bigearth.net/\">BigEarthNet-MM dataset</a>, and 2) semantic segmentation on the VHR EO and SAR <a href=\"https://spacenet.ai/sn6-challenge/\">SpaceNet 6 dataset</a>.</p>\n\n<h2 id=\"multi-label-classification-on-bigearth-mm\">Multi-Label Classification on BigEarth-MM</h2>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/maers-benmm.png\" width=\"100%\" />\n    <br />\n    <i><b>Figure 9:</b> (left) co-registered Sentinel-2 EO and Sentinel-1 SAR imagery are patchified and used to perform a multi-label classification task as specified by the BigEarth-MM challenge. A linear layer is added to our multi-modal encoder and then fine-tuned end-to-end.</i>\n</p>\n\n<p>MAERS is initialized with a set of ImageNet weights for a ViT-Base encoder, followed by pretraining on the BigEarthNet-MM dataset for 20 epochs with RGB, SAR, and RGB+SAR imagery. We append a single linear layer to the MAERS encoder and learn the multi-label classification task by fine-tuning the entire model for 20 epochs (linear probing experiments obtain similar results, as we will show in our upcoming paper). Our results are shown in Table 1. MAERS with fine-tuning outperforms the best RGB+SAR results as presented in the BigEarthNet-MM paper, and show that adapting the State-of-the-Art MAE architecture for representation learning for RGB, SAR, and RGB+SAR input modalities leads to State-of-the-Art results.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/maers-table.png\" width=\"100%\" />\n    <br />\n    <i><b>Table 1:</b> Reported per-class F2 scores on the test set of BigEarthNet-MM.</i>\n</p>\n\n<h2 id=\"semantic-segmentation-on-vhr-eo-and-sar-spacenet-6\">Semantic Segmentation on VHR EO and SAR SpaceNet 6</h2>\n\n<p>We further experimented with transfer learning for a timely task that will aid imagery analysts aiming to understand the destruction in Ukraine: semantic segmentation of buildings footprints, which is a precursor task to performing building damage assessment. Building damage assessment is of direct interest to government officials, journalists, and human rights organizations aiming to understand the scope and severity of Russia\u2019s attacks against infrastructure and civilian populations.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/maers-vhr-sar-segmentation.png\" width=\"100%\" />\n    <br />\n    <i><b>Figure 10:</b> Example of building SAR-based MAERS segmentation taken from SpaceNet6, where the image on the left shows the RGB image, and the image on the right shows the SAR image with overlaid segmentation results. The SAR image is displayed in false color with VV, VH, and VV/VH bands.</i>\n</p>\n\n<p>For this experiment, we used the SpaceNet 6 dataset as an open and public benchmark to illustrate the effectiveness of our learned representations for building footprint detection with VHR SAR from Capella Space. We used this encoder in tandem with the <a href=\"https://arxiv.org/abs/1807.10221\">UperNet</a> architecture for semantic segmentation. Figure 11 shows the IoU performance of segmenting building footprints in a held-out validation component of the SpaceNet 6 with <strong>only SAR input imagery</strong>, on a segmentation model that was trained to use either SAR or RGB imagery. The MAERS pretrained model leads to a ~13 point improvement compared to training the RGB+SAR model from scratch or adapting ImageNet weights with the exact same architecture.</p>\n\n<p>This demonstrates that MAERS can learn robust RGB+SAR representations that allow a practitioner to use EO or SAR imagery interchangeably to accomplish downstream tasks. It is important to note that the phenomenology of SAR imagery is not fully conducive for building segmentation and that using EO imagery for this task leads to IoU scores &gt; 90. This leaves a substantial gap yet to be covered by SAR techniques, something we hope to cover in our following paper. However, getting this performance out of SAR is essential when environmental conditions are not conducive to EO imagery capture.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/maers/maers-segmentation-iou.png\" width=\"100%\" />\n    <br />\n    <i><b>Figure 11:</b> Building segmentation IoU on the SpaceNet 6 Challenge, using an UperNet segmentation model with a ViT backbone. MAERS pretraining leads to ~13 point gain in IoU performance compared to training from scratch or adapting ImageNet pretrained weights.</i>\n</p>\n\n<p>These results are preliminary, but compelling. We will follow up this effort with a publication with a detailed set of experiments and benchmarks. Furthermore, we will aid in the transition of our models to our humanitarian partners to enable them to perform change detection over residential and other civilian areas to enable better tracking of war crimes being committed in Ukraine.</p>\n\n<p>These models are created with the goal of increasing the efficacy of organizations involved in humanitarian missions that are keeping a watchful eye on the war in Ukraine. However, as with any technology, it is our responsibility to understand how this technology could be misused. Therefore, we have designed these models with input from partners who perform intelligence and imagery analysis in humanitarian settings. By taking into account their thoughts, comments, and critiques, we are releasing a capability we are confident will be used for the good of humanity and with processes which dictate their safe and responsible use.</p>\n\n<h2 id=\"call-to-action\">Call to Action</h2>\n\n<p>As citizens of free democracies who develop technologies which help us make sense of the complicated, chaotic, and counter-intuitive world that we live in, we have a responsibility to act when acts of injustice occur. Our colleagues and friends in Ukraine are facing extreme uncertainties and danger. We possess skills in the cyber domain that can aid in the fight against Russian forces. By focusing our time and efforts, whether that be through targeted research or volunteering our time in <a href=\"https://ukrainenow.org/\">helping keep track of processing times at border crossings</a>, we can make a small dent in an otherwise difficult situation.</p>\n\n<p>We urge our fellow computer scientists to partner with government and humanitarian organizations and listen to their needs as difficult times persist. Simple things can make large differences.</p>\n\n<h2 id=\"model-and-weights\">Model and Weights</h2>\n\n<p>The models are not being made publicly accessible at this time. We are releasing our models to qualified researchers and partners through this <a href=\"https://forms.gle/8rB4wvzair1t8qqz9\">form</a>. Full distribution will follow once we have completed a thorough assessment of our models.</p>\n\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n\n<p>Thank you to <a href=\"https://www.diu.mil/team/Steven-Butow\">Gen. Steve Butow</a> and  <a href=\"https://scholar.google.com/citations?user=bJ51bBQAAAAJ&amp;hl=en\">Dr. Nirav Patel</a> at the Department of Defense\u2019s <a href=\"https://diu.mil/\">Defense Innovation Unit</a> for reviewing this post and providing their expertise on the future of commercial SAR constellations.</p>\n\n<!-- Footnotes themselves at the bottom. -->\n<h2 id=\"footnotes\">Footnotes</h2>\n\n<div class=\"footnotes\">\n  <ol>\n    <li id=\"fn:1\">\n\n      <p>It\u2019s interesting to note that the definition of VHR imagery has changed over time. In the 80s, <a href=\"https://agupubs.onlinelibrary.wiley.com/doi/abs/10.1029/JC093iC06p06735\">20 kilometer resolution was \u201cVHR\u201d</a>. Perhaps, in the future, 0.3m resolution imagery will no longer be VHR.\u00a0<a class=\"reversefootnote\" href=\"https://bair.berkeley.edu/blog/feed.xml#fnref:1\">&#8617;</a></p>\n    </li>\n  </ol>\n</div>",
            "pubdate": "Mon, 21 Mar 2022 05:00:00 -0700",
            "pubdate_parsed": [
                2022,
                3,
                21
            ],
            "email_sent": true
        },
        "Offline RL Made Easier: No TD Learning, Advantage Reweighting, or Transformers": {
            "url": "http://bair.berkeley.edu/blog/2022/04/20/rvs/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/rvs/rvs-kitchen.gif\" width=\"70%\" />\n<br />\n<i>A demonstration of the RvS policy we learn with just supervised learning and a depth-two MLP. It uses no TD learning, advantage reweighting, or Transformers!</i>\n</p>\n\n<p>Offline reinforcement learning (RL) is conventionally approached using value-based methods based on temporal difference (TD) learning. However, many recent algorithms reframe RL as a supervised learning problem. These algorithms learn <em>conditional policies</em> by conditioning on goal states (Lynch <em>et al.</em>, 2019; Ghosh <em>et al.</em>, 2021), reward-to-go (Kumar <em>et al.</em>, 2019; Chen <em>et al.</em>, 2021), or language descriptions of the task (Lynch and Sermanet, 2021).</p>\n\n<p>We find the simplicity of these methods quite appealing. If supervised learning is enough to solve RL problems, then offline RL could become widely accessible and (relatively) easy to implement. Whereas TD learning must delicately balance an actor policy with an ensemble of critics, these supervised learning methods train just one (conditional) policy, and nothing else!</p>\n\n<!--more-->\n\n<p>So, how can we use these methods to effectively solve offline RL problems? Prior work puts forward a number of clever tips and tricks, but these tricks are sometimes contradictory, making it challenging for practitioners to figure out how to successfully apply these methods. For example, RCPs (Kumar <em>et al.</em>, 2019) require carefully reweighting the training data, GCSL (Ghosh <em>et al.</em>, 2021) requires iterative, online data collection, and Decision Transformer (Chen <em>et al.</em>, 2021) uses a Transformer sequence model as the policy network.</p>\n\n<p>Which, if any, of these hypotheses are correct? Do we need to reweight our training data based on estimated advantages? Are Transformers necessary to get a high-performing policy? Are there other critical design decisions that have been left out of prior work?</p>\n\n<p>Our work aims to answer these questions by trying to identify the <em>essential elements</em> of offline RL via supervised learning. We run experiments across 4 suites, 26 environments, and 8 algorithms. When the dust settles, we get competitive performance in every environment suite we consider using remarkably simple elements. The video above shows the complex behavior we learn using just supervised learning with a depth-two MLP \u2013 no TD learning, data reweighting, or Transformers!</p>\n\n<h1 id=\"rl-via-supervised-learning\">RL via Supervised Learning</h1>\n\n<p>Let\u2019s begin with an overview of the algorithm we study. While lots of prior work (Kumar <em>et al.</em>, 2019; Ghosh <em>et al.</em>, 2021; and Chen <em>et al.</em>, 2021) share the same core algorithm, it lacks a common name. To fill this gap, we propose the term <em>RL via Supervised Learning (RvS)</em>. We are not proposing any new algorithm but rather showing how prior work can be viewed from a unifying framework; see Figure 1.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/rvs/rvs-data.png\" width=\"70%\" />\n<br />\n<i><b>Figure 1.</b> (Left) A replay buffer of experience (Right) Hindsight relabelled training data</i>\n</p>\n\n<p>RL via Supervised Learning takes as input a replay buffer of experience including states, actions, and outcomes. The outcomes can be an arbitrary function of the trajectory, including a goal state, reward-to-go, or language description. Then, RvS performs hindsight relabeling to generate a dataset of state, action, and outcome triplets. The intuition is that the actions that are observed provide supervision for the outcomes that are reached. With this training dataset, RvS performs supervised learning by maximizing the likelihood of the actions given the states and outcomes. This yields a conditional policy that can condition on arbitrary outcomes at test time.</p>\n\n<h1 id=\"experimental-results\">Experimental Results</h1>\n\n<p>In our experiments, we focus on the following three key questions.</p>\n<ol>\n  <li>Which design decisions are critical for RL via supervised learning?</li>\n  <li>How well does RL via supervised learning actually work? We can do RL via supervised learning, but would using a different offline RL algorithm perform better?</li>\n  <li>What type of outcome variable should we condition on? (And does it even matter?)</li>\n</ol>\n\n<h1 id=\"network-architecture\">Network Architecture</h1>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/rvs/rvs-architecture.png\" width=\"70%\" />\n<br />\n<i><b>Figure 2.</b> Our RvS architecture. A depth-two MLP suffices in every environment suite we consider.</i>\n</p>\n\n<p>We get good performance using just a depth-two multi-layer perceptron. In fact, this is competitive with all previously published architectures we\u2019re aware of, including a Transformer sequence model. We just concatenate the state and outcome before passing them through two fully-connected layers (see Figure 2). The keys that we identify are having a network with large capacity \u2013 we use width 1024 \u2013 as well as dropout in some environments. We find that this works well without reweighting the training data or performing any additional regularization.</p>\n\n<h1 id=\"overall-performance\">Overall Performance</h1>\n\n<p>After identifying these key design decisions, we study the overall performance of RvS in comparison to previous methods. This blog post will overview results from two of the suites we consider in the paper.</p>\n\n<h1 id=\"d4rl-gym\">D4RL Gym</h1>\n\n<p><img align=\"right\" hspace=\"20\" src=\"https://bair.berkeley.edu/static/blog/rvs/gym-env.png\" width=\"40%\" />\nThe first suite is D4RL Gym, which contains the standard MuJoCo halfcheetah, hopper, and walker robots. The challenge in D4RL Gym is to learn locomotion policies from offline datasets of varying quality. For example, one offline dataset contains rollouts from a totally random policy. Another dataset contains rollouts from a \u201cmedium\u201d policy trained partway to convergence, while another dataset is a mixture of rollouts from medium and expert policies.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/rvs/gym-performance.png\" width=\"70%\" />\n<br />\n<i><b>Figure 3.</b> Overall performance in D4RL Gym.</i>\n</p>\n\n<p>Figure 3 shows our results in D4RL Gym. RvS-R is our implementation of RvS conditioned on rewards (illustrated in Figure 2). On average across all 12 tasks in the suite, we see that RvS-R, which uses just a depth-two MLP, is competitive with Decision Transformer (DT; Chen <em>et al.</em>, 2021). We also see that RvS-R is competitive with the methods that use temporal difference (TD) learning, including CQL-R (Kumar <em>et al.</em>, 2020), TD3+BC (Fujimoto <em>et al.</em>, 2021), and Onestep (Brandfonbrener <em>et al.</em>, 2021). However, the TD learning methods have an edge because they perform especially well on the random datasets. This suggests that one might prefer TD learning over RvS when dealing with low-quality data.</p>\n\n<h1 id=\"d4rl-antmaze\">D4RL AntMaze</h1>\n\n<p><img align=\"right\" hspace=\"20\" src=\"https://bair.berkeley.edu/static/blog/rvs/antmaze-env.png\" width=\"27%\" />\nThe second suite is D4RL AntMaze. This suite requires a quadruped to navigate to a target location in mazes of varying size. The challenge of AntMaze is that many trajectories contain only pieces of the full path from the start to the goal location. Learning from these trajectories requires stitching together these pieces to get the full, successful path.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/rvs/antmaze-performance.png\" width=\"70%\" />\n<br />\n<i><b>Figure 4.</b> Overall performance in D4RL AntMaze.</i>\n</p>\n\n<p>Our AntMaze results in Figure 4 highlight the importance of the conditioning variable. Whereas conditioning RvS on rewards (RvS-R) was the best choice of the conditioning variable in D4RL Gym, we find that in D4RL AntMaze, it is much better to condition RvS on $(x, y)$ goal coordinates (RvS-G). When we do this, we see that RvS-G compares favorably to TD learning! This was surprising to us because TD learning explicitly performs dynamic programming using the Bellman equation.</p>\n\n<p>Why does goal-conditioning perform better than reward conditioning in this setting? Recall that AntMaze is designed so that simple imitation is not enough: optimal methods must stitch together parts of suboptimal trajectories to figure out how to reach the goal. In principle, TD learning can solve this with <em>temporal</em> compositionality. With the Bellman equation, TD learning can combine a path from A to B with a path from B to C, yielding a path from A to C. RvS-R, along with other behavior cloning methods, does not benefit from this temporal compositionality. We hypothesize that RvS-G, on the other hand, benefits from <em>spatial compositionality</em>. This is because, in AntMaze, the policy needed to reach one goal is similar to the policy needed to reach a nearby goal. We see correspondingly that RvS-G beats RvS-R.</p>\n\n<p>Of course, conditioning RvS-G on $(x, y)$ coordinates represents a form of prior knowledge about the task. But this also highlights an important consideration for RvS methods: the choice of conditioning information is critically important, and it may depend significantly on the task.</p>\n\n<h1 id=\"conclusion\">Conclusion</h1>\n\n<p>Overall, we find that in a diverse set of environments, RvS works well without needing any fancy algorithmic tricks (such as data reweighting) or fancy architectures (such as Transformers). Indeed, our simple RvS setup can match, and even outperform, methods that utilize (conservative) TD learning. The keys for RvS that we identify are model capacity, regularization, and the conditioning variable.</p>\n\n<p>In our work, we handcraft the conditioning variable, such as $(x, y)$ coordinates in AntMaze. Beyond the standard offline RL setup, this introduces an additional assumption, namely, that we have some prior information about the structure of the task. We think an exciting direction for future work would be to remove this assumption by automating the learning of the goal space.</p>\n\n<hr />\n\n<h1 id=\"reproducing-experiments\">Reproducing Experiments</h1>\n\n<p>We packaged our <a href=\"https://github.com/scottemmons/rvs\">open-source code</a> so that it can automatically handle all the dependencies for you. After downloading the code, you can run these five commands to reproduce our experiments:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>docker build -t rvs:latest .\ndocker run -it --rm -v $(pwd):/rvs rvs:latest bash\ncd rvs\npip install -e .\nbash experiments/launch_gym_rvs_r.sh\n</code></pre></div></div>\n\n<hr />\n\n<p>This post is based on the paper:</p>\n\n<p><strong><a href=\"https://arxiv.org/abs/2112.10751\">RvS: What is Essential for Offline RL via Supervised Learning?</a></strong><br />\n<a href=\"http://scottemmons.com/\">Scott Emmons</a>, <a href=\"https://ben-eysenbach.github.io/\">Benjamin Eysenbach</a>, <a href=\"https://www.kostrikov.xyz/\">Ilya Kostrikov</a>, <a href=\"https://people.eecs.berkeley.edu/~svlevine/\">Sergey Levine</a><br />\nInternational Conference on Learning Representations (ICLR), 2022<br />\n<a href=\"https://arxiv.org/abs/2112.10751\">[Paper]</a> <a href=\"https://github.com/scottemmons/rvs\">[Code]</a></p>",
            "pubdate": "Wed, 20 Apr 2022 02:00:00 -0700",
            "pubdate_parsed": [
                2022,
                4,
                20
            ],
            "email_sent": true
        },
        "Should I Use Offline RL or Imitation Learning?": {
            "url": "http://bair.berkeley.edu/blog/2022/04/25/rl-or-bc/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- body -->\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1649378429759_Screenshot+2022-04-07+at+5.40.23+PM.png\" width=\"100%\" />\n<br />\n<i>Figure 1: Summary of our recommendations for when a practitioner should BC and various imitation learning style methods, and when they should use offline RL approaches.</i>\n</p>\n\n<p>Offline reinforcement learning allows learning policies from previously collected data, which has profound implications for applying RL in domains where running trial-and-error learning is impractical or dangerous, such as safety-critical settings like autonomous driving or medical treatment planning. In such scenarios, online exploration is simply too risky, but <a href=\"https://arxiv.org/abs/2005.01643\">offline RL</a> methods can learn effective policies from logged data collected by <a href=\"https://arxiv.org/abs/2109.10813\">humans</a> or <a href=\"https://arxiv.org/abs/2010.14500\">heuristically designed controllers</a>.  Prior learning-based control methods have also approached learning from existing data as imitation learning: if the data is generally \u201cgood enough,\u201d simply copying the behavior in the data can lead to good results, and if it\u2019s not good enough, then filtering or reweighting the data and then copying can work well.  <a href=\"https://arxiv.org/abs/2106.01345\">Several</a> <a href=\"https://arxiv.org/abs/2108.03298\">recent</a> <a href=\"https://arxiv.org/abs/2110.09470\">works</a> suggest that this is a viable alternative to modern offline RL methods.</p>\n\n<p>This brings about several questions: <strong>when should we use offline RL? Are there fundamental limitations to methods that rely on some form of imitation (BC, conditional BC, filtered BC) that offline RL addresses?</strong> While it might be clear that offline RL should enjoy a large advantage over imitation learning when learning from diverse datasets that contain a lot of suboptimal behavior, we will also discuss how even cases that might seem BC-friendly can still allow offline RL to attain <a href=\"https://arxiv.org/abs/2204.05618\">significantly better results</a>. Our goal is to help explain when and why you should use each method and provide guidance to practitioners on the benefits of each approach. Figure 1 concisely summarizes our findings and we will discuss each component.</p>\n\n<!--more-->\n\n<h2 id=\"methods-for-learning-from-offline-data\">Methods for Learning from Offline Data</h2>\n\n<p>Let\u2019s start with a brief recap of various methods for learning policies from data that we will discuss. The learning algorithm is provided with an offline dataset \\(\\mathcal{D}\\), consisting of trajectories \\(\\{\\tau_i\\}_{i=1}^N\\) generated by some behavior policy. Most offline RL methods perform some sort of dynamic programming (e.g., Q-learning) updates on the provided data, aiming to obtain a value function. This typically requires adjusting for <a href=\"https://arxiv.org/abs/2005.01643\">distributional</a> <a href=\"https://arxiv.org/abs/2006.04779\">shift</a> to work well, but when this is done properly, it leads to good results.</p>\n\n<p>On the other hand, methods based on imitation learning attempt to simply clone the actions observed in the dataset if the dataset is good enough, or perform some kind of filtering or conditioning to extract useful behavior when the dataset is not good. For instance, recent work <a href=\"https://arxiv.org/abs/2106.01345\">filters trajectories</a> based on their return, or directly <a href=\"https://arxiv.org/abs/2106.08909\">filters individual transitions</a> based on how advantageous these could be under the behavior policy and then clones them. Conditional BC methods are based on the idea that every transition or trajectory is optimal when conditioned on the right variable. This way, after conditioning, the data becomes optimal given the value of the conditioning variable, and in principle we could then condition on the desired task, such as a high reward value, and get a near-optimal trajectory. For example, a trajectory that attains a return of \\(R_0\\) is <em>optimal</em> if our goal is to attain return \\(R = R_0\\) (<a href=\"https://arxiv.org/abs/1912.13465\">RCPs</a>, <a href=\"https://arxiv.org/abs/2106.01345\">decision transformer</a>); a trajectory that reaches goal \\(g\\) is optimal for reaching \\(g=g_0\\) (<a href=\"https://openreview.net/forum?id=rALA0Xo6yNJ\">GCSL</a>, <a href=\"https://arxiv.org/abs/2112.10751\">RvS</a>). Thus, one can perform perform reward-conditioned BC or goal-conditioned BC, and execute the learned policies with the desired value of return or goal during evaluation. This approach to offline RL bypasses learning value functions or dynamics models entirely, which can make it simpler to use. However, does it actually solve the general offline RL problem?</p>\n\n<h2 id=\"what-we-already-know-about-rl-vs-imitation-methods\">What We Already Know About RL vs Imitation Methods</h2>\n\n<p>Perhaps a good place to start our discussion is to review the performance of offline RL and imitation-style methods on benchmark tasks. In the figure below, we review the performance of some recent methods for learning from offline data on a subset of the <a href=\"https://arxiv.org/abs/2004.07219\">D4RL</a> benchmark.</p>\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1650480950123_Screenshot+2022-04-20+at+11.54.39+AM.png\" width=\"100%\" />\n<br />\n<i>Table 1: Dichotomy of empirical results on several tasks in D4RL. While imitation-style methods (decision transformer, %BC, one-step RL, conditional BC) perform at par with and can outperform offline RL methods (CQL, IQL) on the locomotion tasks, these methods simply break down on the more complex maze navigation tasks.</i>\n</p>\n\n<p>Observe in the table that while imitation-style methods perform at par with offline RL methods across the span of the locomotion tasks, offline RL approaches vastly outperform these methods (except, goal-conditioned BC, which we will discuss towards the end of this post) by a large margin on the antmaze tasks. <strong>What explains this difference?</strong> As we will discuss in this blog post, methods that rely on imitation learning are often quite effective when the behavior in the offline dataset consists of some complete trajectories that perform well. This is true for most replay-buffer style datasets, and all of the locomotion datasets in D4RL are generated from replay buffers of online RL algorithms. In such cases, simply filtering good trajectories, and executing the mode of the filtered trajectories will work well. This explains why %BC, one-step RL and decision transformer work quite well. However, offline RL methods can vastly outperform BC methods when this stringent requirement is not met because they benefit from a form of \u201ctemporal compositionality\u201d which enables them to learn from suboptimal data. This explains the enormous difference between RL and imitation results on the antmazes.</p>\n\n<h2 id=\"offline-rl-can-solve-problems-that-conditional-filtered-or-weighted-bc-cannot\">Offline RL Can Solve Problems that Conditional, Filtered or Weighted BC Cannot</h2>\n\n<p>To understand why offline RL can solve problems that the aforementioned BC methods cannot, let\u2019s ground our discussion in a simple, didactic example. Let\u2019s consider the navigation task shown in the figure below, where the goal is to navigate from the starting location A to the goal location D in the maze. This is directly representative of several real-world decision-making scenarios in mobile robot navigation and provides an abstract model for an RL problem in domains such as robotics or recommender systems. Imagine you are provided with data that shows how the agent can navigate from location A to B and how it can navigate from C to E, but no single trajectory in the dataset goes from A to D. Obviously, the offline dataset shown below provides enough information for discovering a way to navigate to D: by combining different paths that cross each other at location E. But, can various offline learning methods find a way to go from A to D?</p>\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1649378795135_Screenshot+2022-04-07+at+5.46.30+PM.png\" width=\"70%\" />\n<br />\n<i>Figure 2: Illustration of the base case of temporal compositionality or stitching that is needed find optimal trajectories in various problem domains.</i>\n</p>\n\n<p>It turns out that, while offline RL methods are able to discover the path from A to D, various imitation-style methods cannot. This is because offline RL algorithms can <strong>\u201cstitch\u201d</strong> suboptimal trajectories together: while the trajectories \\(\\tau_i\\) in the offline dataset might attain poor return, a better policy can be obtained by combining good segments of trajectories (A\u2192E + E\u2192D = A\u2192D).  This ability to stitch segments of trajectories temporally is the hallmark of value-based offline RL algorithms that utilize Bellman backups, but cloning (a subset of) the data or trajectory-level sequence models are unable to extract this information, since such no single trajectory from A to D is observed in the offline dataset!</p>\n\n<p><strong>Why should you care about stitching and these mazes?</strong> One might now wonder if this stitching phenomenon is only useful in some esoteric edge cases or if it is an actual, practically-relevant phenomenon. Certainly stitching appears very explicitly in <a href=\"https://arxiv.org/abs/2010.14500\">multi-stage robotic manipulation</a> tasks and also in <a href=\"https://arxiv.org/abs/2012.09812\">navigation tasks</a>. However, stitching is not limited to just these domains \u2014 it turns out that the need for stitching implicitly appears even in tasks that do not appear to contain a maze. In practice, effective policies would often require finding an \u201cextreme\u201d but high-rewarding action, very different from an action that the behavior policy would prescribe, at <em>every</em> state and learning to stitch such actions to obtain a policy that performs well overall. This form of <em>implicit</em> stitching appears in many practical applications: for example, one might want to find an HVAC control policy that minimizes the carbon footprint of a building with a dataset collected from distinct control policies run historically in different buildings, each of which is suboptimal in one manner or the other. In this case, one can still get a much better policy by stitching extreme actions at every state. In general this implicit form of stitching is required in cases where we wish to find really good policies that maximize a continuous value (e.g., maximize rider comfort in autonomous driving;  maximize profits in automatic stock trading) using a dataset collected from a mixture of suboptimal policies (e.g., data from different human drivers; data from different human traders who excel and underperform under different situations) that never execute extreme actions at each decision. However, by stitching such extreme actions at each decision, one can obtain a much better policy. Therefore, naturally succeeding at many problems requires learning to either explicitly or implicitly stitch trajectories, segments or even single decisions, and offline RL is good at it.</p>\n\n<p>The next natural question to ask is: <strong>Can we resolve this issue by adding an RL-like component in BC methods?</strong> One recently-studied approach is to perform a limited number of policy improvement steps beyond behavior cloning. That is, while full offline RL performs multiple rounds of policy improvement untill we find an optimal policy, one can just find a policy by running <a href=\"https://arxiv.org/abs/2106.08909\">one step of policy improvement</a> beyond behavioral cloning. This policy improvement is performed by incorporating some sort of a value function, and one might hope that utilizing some form of Bellman backup equips the method with the ability to \u201c<strong>stitch</strong>\u201d. Unfortunately, even this approach is unable to fully close the gap against offline RL. This is because while the one-step approach can stitch trajectory segments, it would often end up stitching the wrong segments! One step of policy improvement only myopically improves the policy, without taking into account the impact of updating the policy on the future outcomes, the policy may fail to identify truly optimal behavior. For example, in our maze example shown below, it might appear better for the agent to find a solution that decides to go upwards and attain mediocre reward compared to going towards the goal, since under the behavior policy going downwards might appear highly suboptimal.</p>\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1648609753495_Screenshot+2022-03-29+at+8.09.10+PM.png\" width=\"100%\" />\n<br />\n<i>Figure 3: Imitation-style methods that only perform a limited steps of policy improvement may still fall prey to choosing suboptimal actions, because the optimal action assuming that the agent will follow the behavior policy in the future may actually not be optimal for the full sequential decision making problem.</i>\n</p>\n\n<h2 id=\"is-offline-rl-useful-when-stitching-is-not-a-primary-concern\">Is Offline RL Useful When Stitching is Not a Primary Concern?</h2>\n\n<p>So far, our analysis reveals that offline RL methods are better due to good \u201cstitching\u201d properties. But one might wonder, if stitching is critical when provided with good data, such as demonstration data in <a href=\"https://arxiv.org/abs/2108.03298\">robotics</a> or data from good policies in <a href=\"https://arxiv.org/abs/1908.08796\">healthcare</a>. However, in our <a href=\"http://link here\">recent paper,</a> we find that even when temporal compositionality is not a primary concern, offline RL does provide benefits over imitation learning.</p>\n\n<p><strong>Offline RL can teach the agent what to \u201cnot do\u201d.</strong> Perhaps one of the biggest benefits of offline RL algorithms is that running RL on noisy datasets generated from stochastic policies can not only teach the agent what it should do to maximize return, but also what shouldn\u2019t be done and how actions at a given state would influence the chance of the agent ending up in undesirable scenarios in the future. In contrast, any form of conditional or weighted BC which only teach the policy \u201cdo X\u201d, without explicitly discouraging particularly low-rewarding or unsafe behavior. This is especially relevant in open-world settings such as robotic manipulation in diverse settings or making decisions about patient admission in an ICU, where knowing what to not do very clearly is essential. In our <a href=\"https://arxiv.org/abs/2204.05618\">paper</a>, we quantify the gain of accurately inferring \u201cwhat not to do and how much it hurts\u201d and describe this intuition pictorially below. Often obtaining such noisy data is easy \u2014 one could augment expert demonstration data with additional \u201cnegatives\u201d or \u201cfake data\u201d generated from a simulator (e.g., robotics, autonomous driving), or by first running an imitation learning method and creating a dataset for offline RL that augments data with evaluation rollouts from the imitation learned policy.</p>\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1648634037765_Screenshot+2022-03-30+at+2.53.52+AM.png\" width=\"90%\" />\n<br />\n<i>Figure 4: By leveraging noisy data, offline RL algorithms can learn to figure out what shouldn\u2019t be done in order to explicitly avoid regions of low reward, and how the agent could be overly cautious much before that.</i>\n</p>\n\n<p><strong>Is offline RL useful at all when I</strong> <strong>actually</strong> <strong>have near-expert demonstrations?</strong>  As the final scenario, let\u2019s consider the case where we actually have only near-expert demonstrations \u2014 perhaps, the perfect setting for imitation learning. In such a setting, there is no opportunity for stitching or leveraging noisy data to learn what not to do. Can offline RL still improve upon imitation learning? Unfortunately, one can show that, in the worst case, no algorithm can perform better than standard behavioral cloning. However, if the task admits some structure then offline RL policies can be more robust. For example, if there are multiple states where it is easy to identify a good action using reward information, offline RL approaches can quickly converge to a good action at such states, whereas a standard BC approach that does not utilize rewards may fail to identify a good action, leading to policies that are non-robust and fail to solve the task. Therefore, offline RL is a preferred option for tasks with an abundance of such \u201cnon-critical\u201d states where long-term reward can easily identify a good action. An illustration of this idea is shown below, and we formally prove a theoretical result quantifying these intuitions in the <a href=\"https://arxiv.org/abs/2204.05618\">paper</a>.</p>\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1648635140775_Screenshot+2022-03-30+at+3.12.16+AM.png\" width=\"90%\" />\n<br />\n<i>Figure 5: An illustration of the idea of non-critical states: the abundance of states where reward information can easily identify good actions at a given state can help offline RL \u2014 even when provided with expert demonstrations \u2014  compared to standard BC, that does not utilize any kind of reward information,</i>\n</p>\n\n<h2 id=\"so-when-is-imitation-learning-useful\">So, When Is Imitation Learning Useful?</h2>\n\n<p>Our discussion has so far highlighted that offline RL methods can be robust and effective in many scenarios where conditional and weighted BC might fail. Therefore, we now seek to understand if conditional or weighted BC are useful in certain problem settings. This question is easy to answer in the context of standard behavioral cloning, if your data consists of expert demonstrations that you wish to mimic, standard behavioral cloning is a relatively simple, good choice.  However this approach fails when the data is noisy or suboptimal or when the task changes (e.g., when the distribution of initial states changes). And offline RL may still be preferred in settings with some structure (as we discussed above). Some failures of BC can be resolved by utilizing filtered BC \u2014 if the data consists of a mixture of good and bad trajectories, filtering trajectories based on return can be a good idea. Similarly, one could use one-step RL if the task does not require any form of stitching. However, in all of these cases, offline RL might be a better alternative especially if the task or the environment satisfies some conditions, and might be worth trying at least.</p>\n\n<p>Conditional BC performs well on a problem when one can obtain a conditioning variable well-suited to a given task. For example, empirical results on the antmaze domains from <a href=\"https://arxiv.org/abs/2112.10751\">recent work</a> indicate that conditional BC with a goal as a conditioning variable is quite effective in goal-reaching problems, however, conditioning on returns is not (compare Conditional BC (goals) vs Conditional BC (returns) in Table 1). Intuitively, this \u201cwell-suited\u201d conditioning variable essentially enables stitching \u2014 for instance, a navigation problem naturally decomposes into a sequence of intermediate goal-reaching problems and then stitch solutions to a cleverly chosen subset of intermediate goal-reaching problems to solve the complete task. At its core, the success of conditional BC requires some domain knowledge about the compositionality structure in the task. On the other hand, offline RL methods extract the underlying stitching structure by running dynamic programming, and work well more generally. Technically, one could combine these ideas and utilize dynamic programming to learn a value function and then obtain a policy by running conditional BC with the value function as the conditioning variable, and this can work quite well (compare RCP-A to RCP-R <a href=\"https://arxiv.org/abs/1912.13465\">here</a>, where RCP-A uses a value function for conditioning; compare TT+Q and TT <a href=\"https://arxiv.org/abs/2106.02039\">here</a>)!</p>\n\n<h1 id=\"empirical-results-comparing-offline-rl-and-bc\">Empirical Results Comparing Offline RL and BC</h1>\n\n<p>In our discussion so far, we have already studied settings such as the antmazes, where offline RL methods can significantly outperform imitation-style methods due to stitching. We will now quickly discuss some empirical results that compare the performance of offline RL and BC on tasks where we are provided with near-expert, demonstration data.</p>\n\n<p style=\"text-align: center; float: right;\">\n<img src=\"https://paper-attachments.dropbox.com/s_A60F7B4D130EBF1556762D7CF6FF295A033F16EE9EE529F257434EE2272F2C22_1649381175454_image.png\" width=\"90%\" />\n<br />\n<i>Figure 6: Comparing full offline RL (CQL) to imitation-style methods (One-step RL and BC) averaged over 7 Atari games, with expert demonstration data and noisy-expert data. Empirical details here.</i>\n</p>\n\n<p>In our final experiment, we compare the performance of offline RL methods to imitation-style methods on an average over seven Atari games. We use <a href=\"https://sites.google.com/view/cql-offline-rl\">conservative Q-learning</a> (CQL) as our representative offline RL method. Note that naively running offline RL (\u201cNaive CQL (Expert)\u201d), without proper cross-validation to prevent overfitting and underfitting does not improve over BC. However, offline RL equipped with a reasonable cross-validation procedure (\u201cTuned CQL (Expert)\u201d) is able to clearly improve over BC. This highlights the need for <a href=\"https://arxiv.org/abs/2109.10813\">understanding how offline RL methods must be tuned</a>, and at least, in part explains the poor performance of offline RL when learning from demonstration data in prior works. Incorporating a bit of noisy data that can inform the algorithm of what it shouldn\u2019t do, further improves performance (\u201cCQL (Noisy Expert)\u201d vs \u201cBC (Expert)\u201d) within an identical data budget. Finally, note that while one would expect that while one step of policy improvement can be quite effective, we found that it is quite sensitive to hyperparameters and fails to improve over BC significantly. These observations validate the findings discussed earlier in the blog post. We discuss results on other domains in our <a href=\"https://arxiv.org/abs/2204.05618\">paper</a>, that we encourage practitioners to check out.</p>\n\n<h1 id=\"discussion-and-takeaways\">Discussion and Takeaways</h1>\n\n<p>In this blog post, we aimed to understand if, when and why offline RL is a better approach for tackling a variety of sequential decision-making problems. Our discussion suggests that offline RL methods that learn value functions can leverage the benefits of stitching, which can be crucial in many problems. Moreover, there are even scenarios with expert or near-expert demonstration data, where running offline RL is a good idea. We summarize our recommendations for practitioners in Figure 1, shown right at the beginning of this blog post. We hope that our analysis improves the understanding of the benefits and properties of offline RL approaches.</p>\n\n<hr />\n\n<p>This blog post is primarily based on the paper:</p>\n\n<p><strong>When Should Offline RL Be Preferred Over Behavioral Cloning?</strong><br />\nAviral Kumar*, Joey Hong*, Anikait Singh, Sergey Levine       [<a href=\"https://arxiv.org/abs/2204.05618\">arxiv</a>].<br />\nIn International Conference on Learning Representations (ICLR), 2022.</p>\n\n<p>In addition, the empirical results discussed in the blog post are taken from various papers, in particular from <a href=\"https://arxiv.org/abs/2112.10751\">RvS</a> and <a href=\"https://arxiv.org/abs/2110.06169\">IQL</a>.</p>",
            "pubdate": "Mon, 25 Apr 2022 05:00:00 -0700",
            "pubdate_parsed": [
                2022,
                4,
                25
            ],
            "email_sent": true
        },
        "Designing Societally Beneficial Reinforcement Learning Systems": {
            "url": "http://bair.berkeley.edu/blog/2022/04/29/reward-reports/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- body -->\n\n<p>Deep reinforcement learning (DRL) is transitioning from a research field focused on game playing to a technology with real-world applications. Notable examples include DeepMind\u2019s work on <a href=\"https://www.nature.com/articles/s41586-021-04301-9\">controlling a nuclear reactor</a> or on improving <a href=\"https://arxiv.org/abs/2202.06626\">Youtube video compression</a>, or Tesla <a href=\"https://www.youtube.com/watch?v=j0z4FweCy4M&amp;t=4802s\">attempting to use a method inspired by MuZero</a> for autonomous vehicle behavior planning. But the exciting potential for real world applications of RL should also come with a healthy dose of caution - for example RL policies are well known to be vulnerable to <a href=\"https://robotic.substack.com/p/rl-exploitation?s=w\">exploitation</a>, and methods for safe and <a href=\"https://bair.berkeley.edu/blog/2021/03/09/maxent-robust-rl/\">robust policy development</a> are an active area of research.</p>\n\n<p>At the same time as the emergence of powerful RL systems in the real world, the public and researchers are expressing an increased appetite for fair, aligned, and safe machine learning systems. The focus of these research efforts to date has been to account for shortcomings of datasets or supervised learning practices that can harm individuals. However the unique ability of RL systems to leverage temporal feedback in learning complicates the types of risks and safety concerns that can arise.</p>\n\n<p>This post expands on our recent <a href=\"https://cltc.berkeley.edu/2022/02/08/reward-reports/\">whitepaper</a> and <a href=\"https://arxiv.org/abs/2204.10817\">research paper</a>, where we aim to illustrate the different modalities harms can take when augmented with the temporal axis of RL. To combat these novel societal risks, we also propose a new kind of documentation for dynamic Machine Learning systems which aims to assess and monitor these risks both before and after deployment.</p>\n\n<!--more-->\n\n<h1 id=\"whats-special-about-rl-a-taxonomy-of-feedback\">What\u2019s Special About RL? A Taxonomy of Feedback</h1>\n\n<p>Reinforcement learning systems are often spotlighted for their ability to act in an environment, rather than passively make predictions. Other supervised machine learning systems, such as computer vision, consume data and return a prediction that can be used by some decision making rule. In contrast, the appeal of RL is in its ability to not only (a) directly model the impact of actions, but also to (b) improve policy performance automatically. These key properties of acting upon an environment, and learning within that environment can be understood as by considering the different types of feedback that come into play when an RL agent acts within an environment. We classify these feedback forms in a taxonomy of (1) Control, (2) Behavioral, and (3) Exogenous feedback. The first two notions of feedback, Control and Behavioral, are directly within the formal mathematical definition of an RL agent while Exogenous feedback is induced as the agent interacts with the broader world.</p>\n\n<h2 id=\"1-control-feedback\">1. Control Feedback</h2>\n\n<p>First is control feedback - in the control systems engineering sense - where the action taken depends on the current measurements of the state of the system. RL agents choose actions based on an observed state according to a policy, which generates environmental feedback. For example, a thermostat turns on a furnace according to the current temperature measurement. Control feedback gives an agent the ability to react to unforeseen events (e.g. a sudden snap of cold weather) autonomously.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/fb-control.png\" width=\"60%\" />\n<br />\n<i>Figure 1: Control Feedback.</i>\n</p>\n\n<h2 id=\"2-behavioral-feedback\">2. Behavioral Feedback</h2>\n\n<p>Next in our taxonomy of RL feedback is \u2018behavioral feedback\u2019: the trial and error learning that enables an agent to improve its policy through interaction with the environment. This could be considered the defining feature of RL, as compared to e.g. \u2018classical\u2019 control theory. Policies in RL can be defined by a set of parameters that determine the actions the agent takes in the future. Because these parameters are updated through behavioral feedback, these are actually a reflection of the data collected from executions of past policy versions. RL agents are not fully \u2018memoryless\u2019 in this respect\u2013the current policy depends on stored experience, and impacts newly collected data, which in turn impacts future versions of the agent. To continue the thermostat example - a \u2018smart home\u2019 thermostat might analyze historical temperature measurements and adapt its control parameters in accordance with seasonal shifts in temperature, for instance to have a more aggressive control scheme during winter months.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/fb-behavioral.png\" width=\"70%\" />\n<br />\n<i>Figure 2: Behavioral Feedback.</i>\n</p>\n\n<h2 id=\"3-exogenous-feedback\">3. Exogenous Feedback</h2>\n\n<p>Finally, we can consider a third form of feedback external to the specified RL environment, which we call Exogenous (or \u2018exo\u2019) feedback. While RL benchmarking tasks may be static environments, every action in the real world impacts the dynamics of both the target deployment environment, as well as adjacent environments. For example, a news recommendation system that is optimized for clickthrough may change the way editors write headlines towards attention-grabbing\u00a0 clickbait. In this RL formulation, the set of articles to be recommended would be considered part of the environment and expected to remain static, but exposure incentives cause a shift over time.</p>\n\n<p>To continue the thermostat example, as a \u2018smart thermostat\u2019 continues to adapt its behavior over time, the behavior of other adjacent systems in a household might change in response - for instance other appliances might consume more electricity due to increased heat levels, which could impact electricity costs. Household occupants might also change their clothing and behavior patterns due to different temperature profiles during the day. In turn, these secondary effects could also influence the temperature which the thermostat monitors, leading to a longer timescale feedback loop.</p>\n\n<p>Negative costs of these external effects will not be specified in the agent-centric reward function, leaving these external environments to be manipulated or exploited. Exo-feedback is by definition difficult for a designer to predict. Instead, we propose that it should be addressed by documenting the evolution of the agent, the targeted environment, and adjacent environments.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/fb-exo.png\" width=\"80%\" />\n<br />\n<i>Figure 3: Exogenous (exo) Feedback.</i>\n</p>\n\n<hr />\n\n<h1 id=\"how-can-rl-systems-fail\">How can RL systems fail?</h1>\n\n<p>Let\u2019s consider how two key properties can lead to failure modes specific to RL systems: direct action selection (via control feedback) and autonomous data collection (via behavioral feedback).</p>\n\n<p>First is decision-time safety. One current practice in RL research to create safe decisions is to augment the agent\u2019s reward function with a penalty term for certain harmful or undesirable states and actions. For example, in a robotics domain we might penalize certain actions (such as extremely large torques) or state-action tuples (such as carrying a glass of water over sensitive equipment). However it is difficult to anticipate where on a pathway an agent may encounter a crucial action, such that failure would result in an unsafe event. This aspect of how reward functions interact with optimizers is especially problematic for deep learning systems, where numerical guarantees are challenging.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/decision.png\" width=\"90%\" />\n<br />\n<i>Figure 4: Decision time failure illustration.</i>\n</p>\n\n<p>As an RL agent collects new data and the policy adapts, there is a complex interplay between current parameters, stored data, and the environment that governs evolution of the system. Changing any one of these three sources of information will change the future behavior of the agent, and moreover these three components are deeply intertwined. This uncertainty makes it difficult to back out the cause of failures or successes.</p>\n\n<p>In domains where many behaviors can possibly be expressed, the RL specification leaves a lot of factors constraining behavior unsaid. For a robot learning locomotion over an uneven environment, it would be useful to know what signals in the system indicate it will learn to find an easier route rather than a more complex gait. In complex situations with less well-defined reward functions, these intended or unintended behaviors will encompass a much broader range of capabilities, which may or may not have been accounted for by the designer.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/behavior.png\" width=\"80%\" />\n<br />\n<i>Figure 5: Behavior estimation failure illustration.</i>\n</p>\n\n<p>While these failure modes are closely related to control and behavioral feedback, Exo-feedback does not map as clearly to one type of error and introduces risks that do not fit into simple categories. Understanding exo-feedback requires that stakeholders in the broader communities (machine learning, application domains, sociology, etc.) work together on real world RL deployments.</p>\n\n<h1 id=\"risks-with-real-world-rl\">Risks with real-world RL</h1>\n\n<p>Here, we discuss four types of design choices an RL designer must make, and how these choices can have an impact upon the socio-technical failures that an agent might exhibit once deployed.</p>\n\n<h2 id=\"scoping-the-horizon\">Scoping the Horizon</h2>\n\n<p>Determining the timescale on which aRL agent can plan impacts the possible and actual behavior of that agent. In the lab, it may be common to tune the horizon length until the desired behavior is achieved. But in real world systems, optimizations will externalize costs depending on the defined horizon. For example, an RL agent controlling an autonomous vehicle will have very different goals and behaviors if the task is to stay in a lane,\u00a0 navigate a contested intersection, or route across a city to a destination. This is true even if the objective (e.g. \u201cminimize travel time\u201d) remains the same.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/horizon.png\" width=\"100%\" />\n<br />\n<i>Figure 6: Scoping the horizon example with an autonomous vehicle.</i>\n</p>\n\n<h2 id=\"defining-rewards\">Defining Rewards</h2>\n\n<p>A second design choice is that of actually specifying the reward function to be maximized. This immediately raises the well-known risk of RL systems, reward hacking, where the designer and agent negotiate behaviors based on specified reward functions. In a deployed RL system, this often results in unexpected exploitative behavior \u2013 from <a href=\"https://openai.com/blog/faulty-reward-functions/\">bizarre video game agents</a> to <a href=\"https://bair.berkeley.edu/blog/2021/04/19/mbrl/\">causing errors in robotics simulators</a>. For example, if an agent is presented with the problem of navigating a maze to reach the far side, a mis-specified reward might result in the agent avoiding the task entirely to minimize the time taken.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/reward-shaping.png\" width=\"100%\" />\n<br />\n<i>Figure 7: Defining rewards example with maze navigation.</i>\n</p>\n\n<h2 id=\"pruning-information\">Pruning Information</h2>\n\n<p>A common practice in RL research is to redefine the environment to fit one\u2019s needs \u2013 RL designers make numerous explicit and implicit assumptions to model tasks in a way that makes them amenable to virtual RL agents. In highly structured domains, such as video games, this can be rather benign.However, in the real world redefining the environment amounts to changing the ways information can flow between the world and the RL agent. This can dramatically change the meaning of the reward function and offload risk to external systems. For example, an autonomous vehicle with sensors focused only on the road surface shifts the burden from AV designers to pedestrians. In this case, the designer is pruning out information about the surrounding environment that is actually crucial to robustly safe integration within society.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/info-shaping.png\" width=\"80%\" />\n<br />\n<i>Figure 8: Information shaping example with an autonomous vehicle.</i>\n</p>\n\n<h2 id=\"training-multiple-agents\">Training Multiple Agents</h2>\n\n<p>There is growing interest in the problem of <a href=\"https://bair.berkeley.edu/blog/2021/07/14/mappo/\">multi-agent RL</a>, but as an emerging research area, little is known about how learning systems interact within dynamic environments. When the relative concentration of autonomous agents increases within an environment, the terms these agents optimize for can actually re-wire norms and values encoded in that specific application domain. An example would be the changes in behavior that will come if the majority of vehicles are autonomous and communicating (or not) with each other. In this case, if the agents have autonomy to optimize toward a goal of minimizing transit time (for example), they could crowd out the remaining human drivers and heavily disrupt accepted societal norms of transit.</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/multi-agent.png\" width=\"80%\" />\n<br />\n<i>Figure 9: The risks of multi-agency example on autonomous vehicles.</i>\n</p>\n\n<hr />\n\n<h1 id=\"making-sense-of-applied-rl-reward-reporting\">Making sense of applied RL: Reward Reporting</h1>\n\n<p>In our recent <a href=\"https://cltc.berkeley.edu/2022/02/08/reward-reports/\">whitepaper</a> and <a href=\"https://arxiv.org/abs/2204.10817\">research paper</a>, we proposed <a href=\"https://rewardreports.github.io/\">Reward Reports</a>, a new form of ML documentation that foregrounds the societal risks posed by sequential data-driven optimization systems, whether explicitly constructed as an RL agent or <a href=\"https://robotic.substack.com/p/ml-becomes-rl?s=w\">implicitly construed</a> via data-driven optimization and feedback. Building on proposals to document datasets and models, we focus on reward functions: the objective that guides optimization decisions in feedback-laden systems. Reward Reports comprise questions that highlight the promises and risks entailed in defining what is being optimized in an AI system, and are intended as living documents that dissolve the distinction between ex-ante (design) specification and ex-post (after the fact) harm. As a result, Reward Reports provide a framework for ongoing deliberation and accountability before and after a system is deployed.</p>\n\n<p>Our proposed template for a Reward Reports consists of several sections, arranged to help the reporter themselves understand and document the system. A Reward Report begins with (1) system details that contain the information context for deploying the model. From there, the report documents (2) the optimization intent, which questions the goals of the system and why RL or ML may be a useful tool. The designer then documents (3) how the system may affect different stakeholders in the institutional interface. The next two sections contain technical details on (4) the system implementation and (5) evaluation. Reward reports conclude with (6) plans for system maintenance as additional system dynamics are uncovered.</p>\n\n<p>The most important feature of a Reward Report is that it allows documentation to evolve over time, in step with the temporal evolution of an online, deployed RL system! This is most evident in the change-log, which is we locate at the end of our Reward Report template:</p>\n\n<p style=\"text-align: center; float: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/reward-reports/rr-contents.png\" width=\"80%\" />\n<br />\n<i>Figure 10: Reward Reports contents.</i>\n</p>\n\n<h2 id=\"what-would-this-look-like-in-practice\">What would this look like in practice?</h2>\n\n<p>As part of our research, we have developed a reward report <a href=\"https://github.com/RewardReports/reward-reports\">LaTeX template, as well as several example reward reports</a> that aim to illustrate the kinds of issues that could be managed by this form of documentation. These examples include the temporal evolution of the MovieLens recommender system, the DeepMind MuZero game playing system, and a hypothetical deployment of an RL autonomous vehicle policy for managing merging traffic, based on the <a href=\"https://flow-project.github.io/\">Project Flow simulator</a>.</p>\n\n<p>However, these are just examples that we hope will serve to inspire the RL community\u2013as more RL systems are deployed in real-world applications, we hope the research community will build on our ideas for Reward Reports and refine the specific content that should be included. To this end, we hope that you will join us at our (un)-workshop.</p>\n\n<h2 id=\"work-with-us-on-reward-reports-an-unworkshop\">Work with us on Reward Reports: An (Un)Workshop!</h2>\n\n<p>We are hosting an \u201cun-workshop\u201d at the upcoming conference on Reinforcement Learning and Decision Making (<a href=\"https://rldm.org/rldm-2022-workshops/\">RLDM</a>) on June 11th from 1:00-5:00pm EST at Brown University, Providence, RI. We call this an un-workshop because we are looking for the attendees to help create the content! We will provide templates, ideas, and discussion as our attendees build out example reports. We are excited to develop the ideas behind Reward Reports with real-world practitioners and cutting-edge researchers.</p>\n\n<p>For more information on the workshop, visit the <a href=\"https://rewardreports.github.io/workshop.html\">website</a> or contact the organizers at <a href=\"mailto:geese-org@lists.berkeley.edu\">geese-org@lists.berkeley.edu</a>.</p>\n\n<hr />\n\n<p>This post is based on the following papers:</p>\n\n<ul>\n  <li><a href=\"https://cltc.berkeley.edu/2022/02/08/reward-reports/\">Choices, Risks, and Reward Reports: Charting Public Policy for Reinforcement Learning Systems</a> by Thomas Krendl Gilbert, Sarah Dean, Tom Zick, Nathan Lambert. Center for Long Term Cybersecurity Whitepaper Series 2022.</li>\n  <li><a href=\"https://arxiv.org/abs/2204.10817\">Reward Reports for Reinforcement Learning</a> by Thomas Krendl Gilbert, Sarah Dean, Nathan Lambert, Tom Zick and Aaron Snoswell. ArXiv Preprint 2022.</li>\n</ul>",
            "pubdate": "Fri, 29 Apr 2022 05:00:00 -0700",
            "pubdate_parsed": [
                2022,
                4,
                29
            ],
            "email_sent": true
        },
        "Rethinking Human-in-the-Loop for Artificial Augmented Intelligence": {
            "url": "http://bair.berkeley.edu/blog/2022/05/03/human-in-the-loop/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<!-- body -->\n\n<p style=\"text-align: center;\">\n    <img src=\"http://bair.berkeley.edu/static/blog/human-in-the-loop/image3.png\" width=\"90%\" />\n    <br />\n<i>\nFigure 1: In real-world applications, we think there exist a human-machine loop where humans and machines are mutually augmenting each other. We call it Artificial Augmented Intelligence.\n</i>\n</p>\n\n<p>How do we build and evaluate an AI system for real-world applications? In most AI research, the evaluation of AI methods involves a training-validation-testing process. The experiments usually stop when the models have good testing performance on the reported datasets because real-world data distribution is assumed to be modeled by the validation and testing data. However, real-world applications are usually more complicated than a single training-validation-testing process. The biggest difference is the ever-changing data. For example, wildlife datasets change in class composition all the time because of animal invasion, re-introduction, re-colonization, and seasonal animal movements. A model trained, validated, and tested on existing datasets can easily be broken when newly collected data contain novel species. Fortunately, we have out-of-distribution detection methods that can help us detect samples of novel species. However, when we want to expand the recognition capacity (i.e., being able to recognize novel species in the future), the best we can do is fine-tuning the models with new ground-truthed annotations. In other words, we need to incorporate human effort/annotations regardless of how the models perform on previous testing sets.</p>\n\n<!--more-->\n\n<h1 id=\"inevitable-human-in-the-loop\">Inevitable human-in-the-loop</h1>\n\n<p>When human annotations are inevitable, real-world recognition systems become a never-ending loop of <strong>data collection \u2192 annotation \u2192 model fine-tuning</strong> (Figure 2). As a result, the performance of one single step of model evaluation does not represent the actual generalization of the whole recognition system because the model will be updated with new data annotations, and a new round of evaluation will be conducted. With this loop in mind, we think that instead of building a model with <strong><em>better testing performance</em></strong>, focusing on <strong><em>how much human effort can be saved</em></strong> is a more generalized and practical goal in real-world applications.</p>\n\n<p style=\"text-align: center;\">\n    <img height=\"\" src=\"http://bair.berkeley.edu/static/blog/human-in-the-loop/image1.png\" />\n    <br />\n<i>\nFigure 2: In the loop of data collection, annotation, and model update, the goal of optimization becomes minimizing the requirement of human annotation rather than single-step recognition performance.\n</i>\n</p>\n\n<h1 id=\"a-case-study-on-wildlife-recognition\">A case study on wildlife recognition</h1>\n\n<p>In the paper we published last year in Nature-Machine Intelligence [1], we discussed the incorporation of human-in-the-loop into wildlife recognition and proposed to examine human effort efficiency in model updates instead of simple testing performance. For demonstration, we designed a recognition framework that was a combination of active learning, semi-supervised learning, and human-in-the-loop (Figure 3). We also incorporated a time component into this framework to indicate that the recognition models did not stop at any single time step. Generally speaking, in the framework, at each time step, when new data are collected, a recognition model actively selects which data should be annotated based on a prediction confidence metric. Low-confidence predictions are sent for human annotation, and high-confidence predictions are trusted for downstream tasks or pseudo-labels for model updates.</p>\n\n<p style=\"text-align: center;\">\n    <img height=\"\" src=\"http://bair.berkeley.edu/static/blog/human-in-the-loop/image2.png\" />\n    <br />\n<i>\nFigure 3: Here, we present an iterative recognition framework that can both maximize the utility of modern image recognition methods and minimize the dependence on manual annotations for model updating.  \n</i>\n</p>\n\n<p>In terms of human annotation efficiency for model updates, we split the evaluation into 1) the percentage of high-confidence predictions on validation (i.e., saved human effort for annotation); 2) the accuracy of high-confidence predictions (i.e., reliability); and 3) the percentage of novel categories that are detected as low-confidence predictions (i.e., sensitivity to novelty). With these three metrics, the optimization of the framework becomes minimizing human efforts (i.e., to maximize high-confidence percentage) and maximizing model update performance and high-confidence accuracy.</p>\n\n<p>We reported a two-step experiment on a large-scale wildlife camera trap dataset collected from Mozambique National Park for demonstration purposes. The first step was an initialization step to initialize a model with only part of the dataset. In the second step, a new set of data with known and novel classes was applied to the initialized model. Following the framework, the model made predictions on the new dataset with confidence, where high-confidence predictions were trusted as pseudo-labels, and low-confidence predictions were provided with human annotations. Then, the model was updated with both pseudo-labels and annotations and ready for the future time steps. As a result, the percentage of high-confidence predictions on second step validation was 72.2%, the accuracy of high-confidence predictions was 90.2%, and the percentage of novel classes detected as low-confidence was 82.6%. In other words, our framework saved 72% of human effort on annotating all the second step data. As long as the model was confident, 90% of the predictions were correct. In addition, 82% of novel samples were successfully detected. Details of the framework and experiments can be found in the original paper.</p>\n\n<h1 id=\"artificial-augmented-intelligence-a2i\">Artificial Augmented Intelligence (A<sup>2</sup>I)</h1>\n\n<p>By taking a closer look at Figure 3, besides the <strong>data collection - human annotation - model update</strong> loop, there is another <strong>human-machine</strong> loop hidden in the framework (Figure 1). This is a loop where both humans and machines are constantly improving each other through model updates and human intervention. For example, when AI models cannot recognize novel classes, human intervention can provide information to expand the model\u2019s recognition capacity. On the other hand, when AI models get more and more generalized, the requirement for human effort gets less. In other words, the use of human effort gets more efficient.</p>\n\n<p>In addition, the confidence-based human-in-the-loop framework we proposed is not limited to novel class detection but can also help with issues like long-tailed distribution and multi-domain discrepancies. As long as AI models feel less confident, human intervention comes in to help improve the model. Similarly, human effort is saved as long as AI models feel confident, and sometimes human errors can even be corrected (Figure 4). In this case, the relationship between humans and machines becomes synergistic. Thus, the goal of AI development changes from replacing human intelligence to mutually augmenting both human and machine intelligence. We call this type of AI: <strong>Artificial Augmented Intelligence (A<sup>2</sup>I)</strong>.</p>\n\n<p>Ever since we started working on artificial intelligence, we have been asking ourselves, what do we create AI for? At first, we believed that, ideally, AI should fully replace human effort in simple and tedious tasks such as large-scale image recognition and car driving. Thus, we have been pushing our models to an idea called \u201chuman-level performance\u201d for a long time. However, this goal of replacing human effort is intrinsically building up opposition or a mutually exclusive relationship between humans and machines. In real-world applications, the performance of AI methods is just limited by so many affecting factors like long-tailed distribution, multi-domain discrepancies, label noise, weak supervision, out-of-distribution detection, etc. Most of these problems can be somehow relieved with proper human intervention. The framework we proposed is just one example of how these separate problems can be summarized into high- versus low-confidence prediction problems and how human effort can be introduced into the whole AI system. We think it is not cheating or surrendering to hard problems. It is a more human-centric way of AI development, where the focus is on how much human effort is saved rather than how many testing images a model can recognize. Before the realization of Artificial General Intelligence (AGI), we think it is worthwhile to further explore the direction of machine-human interactions and A<sup>2</sup>I such that AI can start making more impacts in various practical fields.</p>\n\n<p style=\"text-align: center;\">\n    <img height=\"\" src=\"http://bair.berkeley.edu/static/blog/human-in-the-loop/image4.png\" />\n    <br />\n<i>\nFigure 4: Examples of high-confidence predictions that did not match the original annotations. Many high-confidence predictions that were flagged as incorrect based on validation labels (provided by students and citizen scientists) were in fact correct upon closer inspection by wildlife experts.  \n</i>\n</p>\n\n<p><em>Acknowledgements: We thank all co-authors of the paper \u201cIterative Human and Automated Identification of Wildlife Images\u201d for their contributions and discussions in preparing this blog. The views and opinions expressed in this blog are solely of the authors of this paper.</em></p>\n\n<p>This blog post is based on the following paper which is published at Nature - Machine Intelligence:<br />\n[1] Miao, Zhongqi, Ziwei Liu, Kaitlyn M. Gaynor, Meredith S. Palmer, Stella X. Yu, and Wayne M. Getz. \u201cIterative human and automated identification of wildlife images.\u201d Nature Machine Intelligence 3, no. 10 (2021): 885-895.(Link to <a href=\"https://arxiv.org/pdf/2105.02320.pdf\">Pre-print</a>)</p>",
            "pubdate": "Tue, 03 May 2022 06:55:00 -0700",
            "pubdate_parsed": [
                2022,
                5,
                3
            ],
            "email_sent": true
        },
        "The Berkeley Crossword Solver": {
            "url": "http://bair.berkeley.edu/blog/2022/05/20/crosswords/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p>We recently built the Berkeley Crossword Solver (BCS), the first computer program to beat every human competitor in the world\u2019s top crossword tournament. The BCS combines neural question answering and probabilistic inference to achieve near-perfect performance on most American-style crossword puzzles, like the one shown below:</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/crosswords/fig1.png\" width=\"90%\" />\n    <br />\n<i>\nFigure 1: Example American-style crossword puzzle\n</i>\n</p>\n\n<p>Crosswords are challenging for humans and computers alike. Many clues are vague or underspecified and can\u2019t be answered until crossing constraints are taken into account. While some clues are similar to factoid question answering, others require relational reasoning or understanding difficult wordplay.</p>\n\n<!--more-->\n\n<p>Here are a handful of example clues from our dataset (answers at the bottom of this post):</p>\n<ul>\n  <li>They\u2019re given out at Berkeley\u2019s HAAS School (4)</li>\n  <li>Winter hrs. in Berkeley (3)</li>\n  <li>Domain ender that UC Berkeley was one of the first schools to adopt (3)</li>\n  <li>Angeleno at Berkeley, say (8)</li>\n</ul>\n\n<h1 id=\"our-approach\">Our Approach</h1>\n<p>The BCS uses a two-step process to solve crossword puzzles. First, it generates a probability distribution over possible answers to each clue using a question answering (QA) model; second, it uses probabilistic inference, combined with local search and a generative language model, to handle conflicts between proposed intersecting answers.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/crosswords/fig2.png\" width=\"90%\" />\n    <br />\n<i>\nFigure 2: Architecture diagram of the Berkeley Crossword Solver\n</i>\n</p>\n\n<p>The BCS\u2019s question answering model is based on DPR [Karpukhin et al., 2020], which is a bi-encoder model typically used to retrieve passages that are relevant to a given question. Rather than passages, however, our approach maps both questions and answers into a shared embedding space and finds answers directly. Compared to the previous state-of-the-art method for answering crossword clues, this approach obtained a 13.4% absolute improvement in top-1000 QA accuracy. We conducted a manual error analysis and found that our QA model typically performed well on questions involving knowledge, commonsense reasoning, and definitions, but it often struggled to understand wordplay or theme-related clues.</p>\n\n<p>After running the QA model on each clue, the BCS runs loopy belief propagation to iteratively update the answer probabilities in the grid. This allows information from high confidence predictions to propagate to more challenging clues. After belief propagation converges, the BCS obtains an initial puzzle solution by greedily taking the highest likelihood answer at each position.</p>\n\n<p>The BCS then refines this solution using a local search that tries to replace low confidence characters in the grid. Local search works by using a guided proposal distribution in which characters that had lower marginal probabilities during belief propagation are iteratively replaced until a locally optimal solution is found. We score these alternate characters using a character-level language model (ByT5, Xue et al., 2022), that handles novel answers better than our closed-book QA model.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/crosswords/fig3.png\" width=\"90%\" />\n    <br />\n<i>\nFigure 3: Example changes made by our local search procedure\n</i>\n</p>\n\n<h1 id=\"results\">Results</h1>\n<p>We evaluated the BCS on puzzles from five major crossword publishers, including The New York Times. Our system obtains 99.7% letter accuracy on average, which jumps to 99.9% if you ignore puzzles that involve rare themes. It solves 81.7% of puzzles without a single mistake, which is a 24.8% improvement over the previous state-of-the-art system.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/crosswords/fig4.png\" width=\"90%\" />\n    <br />\n<i>\nFigure 4: Results compared to previous state-of-the-art Dr. Fill\n</i>\n</p>\n\n<h1 id=\"winning-the-american-crossword-puzzle-tournament\">Winning The American Crossword Puzzle Tournament</h1>\n<p>The American Crossword Puzzle Tournament (ACPT) is the largest and longest-running crossword tournament and is organized by Will Shortz, the New York Times crossword editor. Two prior approaches to computer crossword solving gained mainstream attention and competed in the ACPT: Proverb and Dr. Fill. Proverb is a 1998 system that ranked 213th out of 252 competitors in the tournament. Dr. Fill\u2019s first competition was in ACPT 2012, and it ranked 141st out of 650 competitors. We teamed up with Dr. Fill\u2019s creator Matt Ginsberg and combined an early version of our QA system with Dr. Fill\u2019s search procedure to win first place in the 2021 ACPT against over a thousand competitors. Our submission solved all seven puzzles in under a minute, missing just three letters across two puzzles.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/crosswords/fig5.png\" width=\"90%\" />\n    <br />\n<i>\nFigure 5: Results from the 2021 American Crossword Puzzle Tournament (ACPT)\n</i>\n</p>\n\n<p>We are really excited about the challenges that remain in crosswords, including handling difficult themes and more complex wordplay. To encourage future work, we are releasing a dataset of 6.4M question answer clues, a demo of the Berkeley Crossword Solver, and our code at <a href=\"http://berkeleycrosswordsolver.com\">http://berkeleycrosswordsolver.com</a>.</p>\n\n<p>Answers to clues: MBAS, PST, EDU, INSTATER</p>",
            "pubdate": "Fri, 20 May 2022 03:00:00 -0700",
            "pubdate_parsed": [
                2022,
                5,
                20
            ],
            "email_sent": true
        },
        "FIGS: Attaining XGBoost-level performance with the interpretability and speed of CART": {
            "url": "http://bair.berkeley.edu/blog/2022/06/30/figs/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p style=\"text-align: center;\">\n    <a href=\"https://arxiv.org/abs/2201.11931\"><img src=\"https://bair.berkeley.edu/static/blog/figs/figs_intro.gif\" width=\"90%\" /></a>\n<br />\n<b>FIGS (Fast Interpretable Greedy-tree Sums): </b><i>A method for building interpretable models by simultaneously growing an ensemble of decision trees in competition with one another.</i>\n</p>\n\n<p>Recent machine-learning advances have led to increasingly complex predictive models, often at the cost of interpretability. We often need interpretability, particularly in high-stakes applications such as in clinical decision-making; interpretable models help with all kinds of things, such as identifying errors, leveraging domain knowledge, and making speedy predictions.</p>\n\n<p>In this blog post we\u2019ll cover <a href=\"https://arxiv.org/abs/2201.11931\">FIGS</a>, a new method for fitting an <em>interpretable model</em> that takes the form of a sum of trees. Real-world experiments and theoretical results show that FIGS can effectively adapt to a wide range of structure in data, achieving state-of-the-art performance in several settings, all without sacrificing interpretability.\n<!--more--></p>\n\n<h2 id=\"how-does-figs-work\">How does FIGS work?</h2>\n\n<p>Intuitively, FIGS works by extending CART, a typical greedy algorithm for growing a decision tree, to consider growing a <em>sum</em> of trees <em>simultaneously</em> (see Fig 1). At each iteration, FIGS may grow any existing tree it has already started or start a new tree; it greedily selects whichever rule reduces the total unexplained variance (or an alternative splitting criterion) the most. To keep the trees in sync with one another, each tree is made to predict the <em>residuals</em> remaining after summing the predictions of all other trees (see <a href=\"https://arxiv.org/abs/2201.11931\">the paper</a> for more details).</p>\n\n<p>FIGS is intuitively similar to ensemble approaches such as gradient boosting / random forest, but importantly since all trees are grown to compete with each other the model can adapt more to the underlying structure in the data. The number of trees and size/shape of each tree emerge automatically from the data rather than being manually specified.</p>\n\n<p style=\"text-align: center;\">\n    <a href=\"https://github.com/csinva/imodels\"><img src=\"https://bair.berkeley.edu/static/blog/figs/figs_fitting.gif\" width=\"90%\" /></a>\n<br />\n<b>Fig 1. </b><i>High-level intuition for how FIGS fits a model.</i>\n</p>\n\n<h2 id=\"an-example-using-figs\">An example using <code class=\"language-plaintext highlighter-rouge\">FIGS</code></h2>\n\n<p>Using FIGS is extremely simple. It is easily installable through the <a href=\"https://github.com/csinva/imodels\">imodels package</a> (<code class=\"language-plaintext highlighter-rouge\">pip install imodels</code>) and then can be used in the same way as standard scikit-learn models: simply import a classifier or regressor and use the <code class=\"language-plaintext highlighter-rouge\">fit</code> and <code class=\"language-plaintext highlighter-rouge\">predict</code> methods. Here\u2019s a full example of using it on a sample clinical dataset in which the target is risk of cervical spine injury (CSI).</p>\n\n<div class=\"language-python highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"kn\">from</span> <span class=\"nn\">imodels</span> <span class=\"kn\">import</span> <span class=\"n\">FIGSClassifier</span><span class=\"p\">,</span> <span class=\"n\">get_clean_dataset</span>\n<span class=\"kn\">from</span> <span class=\"nn\">sklearn.model_selection</span> <span class=\"kn\">import</span> <span class=\"n\">train_test_split</span>\n\n<span class=\"c1\"># prepare data (in this a sample clinical dataset)\n</span><span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">feat_names</span> <span class=\"o\">=</span> <span class=\"n\">get_clean_dataset</span><span class=\"p\">(</span><span class=\"s\">'csi_pecarn_pred'</span><span class=\"p\">)</span>\n<span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">X_test</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">,</span> <span class=\"n\">y_test</span> <span class=\"o\">=</span> <span class=\"n\">train_test_split</span><span class=\"p\">(</span>\n    <span class=\"n\">X</span><span class=\"p\">,</span> <span class=\"n\">y</span><span class=\"p\">,</span> <span class=\"n\">test_size</span><span class=\"o\">=</span><span class=\"mf\">0.33</span><span class=\"p\">,</span> <span class=\"n\">random_state</span><span class=\"o\">=</span><span class=\"mi\">42</span><span class=\"p\">)</span>\n\n<span class=\"c1\"># fit the model\n</span><span class=\"n\">model</span> <span class=\"o\">=</span> <span class=\"n\">FIGSClassifier</span><span class=\"p\">(</span><span class=\"n\">max_rules</span><span class=\"o\">=</span><span class=\"mi\">4</span><span class=\"p\">)</span>  <span class=\"c1\"># initialize a model\n</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">fit</span><span class=\"p\">(</span><span class=\"n\">X_train</span><span class=\"p\">,</span> <span class=\"n\">y_train</span><span class=\"p\">)</span>   <span class=\"c1\"># fit model\n</span><span class=\"n\">preds</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">predict</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span> <span class=\"c1\"># discrete predictions: shape is (n_test, 1)\n</span><span class=\"n\">preds_proba</span> <span class=\"o\">=</span> <span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">predict_proba</span><span class=\"p\">(</span><span class=\"n\">X_test</span><span class=\"p\">)</span> <span class=\"c1\"># predicted probabilities: shape is (n_test, n_classes)\n</span>\n<span class=\"c1\"># visualize the model\n</span><span class=\"n\">model</span><span class=\"p\">.</span><span class=\"n\">plot</span><span class=\"p\">(</span><span class=\"n\">feature_names</span><span class=\"o\">=</span><span class=\"n\">feat_names</span><span class=\"p\">,</span> <span class=\"n\">filename</span><span class=\"o\">=</span><span class=\"s\">'out.svg'</span><span class=\"p\">,</span> <span class=\"n\">dpi</span><span class=\"o\">=</span><span class=\"mi\">300</span><span class=\"p\">)</span>\n</code></pre></div></div>\n\n<p>This results in a simple model \u2013 it contains only 4 splits (since we specified that the model should have no more than 4 splits (<code class=\"language-plaintext highlighter-rouge\">max_rules=4</code>). Predictions are made by dropping a sample down every tree, and <i>summing</i> the risk adjustment values obtained from the resulting leaves of each tree. This model is extremely interpretable, as a physician can now (i) easily make predictions using the 4 relevant features and (ii) vet the model to ensure it matches their domain expertise. Note that this model is just for illustration purposes, and achieves ~84\\% accuracy.</p>\n\n<p style=\"text-align: center;\">\n    <a href=\"https://github.com/csinva/imodels\"><img src=\"https://bair.berkeley.edu/static/blog/figs/figs_csi_model_small.svg\" width=\"85%\" /></a>\n<br />\n<i><b>Fig 2.</b> Simple model learned by FIGS for predicting risk of cervical spinal injury. </i>\n</p>\n\n<p>If we want a more flexible model, we can also remove the constraint on the number of rules (changing the code to <code class=\"language-plaintext highlighter-rouge\">model = FIGSClassifier()</code>), resulting in a larger model (see Fig 3). Note that the number of trees and how balanced they are emerges from the structure of the data \u2013 only the total number of rules may be specified.</p>\n\n<p style=\"text-align: center;\">\n    <a href=\"https://github.com/csinva/imodels\"><img src=\"https://bair.berkeley.edu/static/blog/figs/figs_csi_model_large.svg\" width=\"100%\" /></a>\n<br />\n<i><b>Fig 3.</b> Slightly larger model learned by FIGS for predicting risk of cervical spinal injury. </i>\n</p>\n\n<h2 id=\"how-well-does-figs-perform\">How well does FIGS perform?</h2>\n\n<p>In many cases when interpretability is desired, such as <a href=\"https://arxiv.org/abs/2205.15135\">clinical-decision-rule modeling</a>, FIGS is able to achieve state-of-the-art performance. For example, Fig 4 shows different datasets where FIGS achieves excellent performance, particularly when limited to using very few total splits.</p>\n\n<p style=\"text-align: center;\">\n    <a href=\"https://github.com/csinva/imodels\"><img src=\"https://bair.berkeley.edu/static/blog/figs/figs_classification.png\" width=\"100%\" /></a>\n<br />\n<i><b>Fig 4.</b> FIGS predicts well with very few splits. </i>\n</p>\n\n<h2 id=\"why-does-figs-perform-well\">Why does FIGS perform well?</h2>\n\n<p>FIGS is motivated by the observation that single decision trees often have splits that are repeated in different branches, which may occur when there is <a href=\"https://proceedings.mlr.press/v151/shuo-tan22a/shuo-tan22a.pdf\">additive structure</a> in the data. Having multiple trees helps to avoid this by disentangling the additive components into separate trees.</p>\n\n<h2 id=\"conclusion\">Conclusion</h2>\n\n<p>Overall, interpretable modeling offers an alternative to common black-box modeling, and in many cases can offer massive improvements in terms of efficiency and transparency without suffering from a loss in performance.</p>\n\n<hr />\n\n<p><em>This post is based on two papers: <a href=\"https://arxiv.org/abs/2201.11931\">FIGS</a> and <a href=\"https://arxiv.org/abs/2205.15135\">G-FIGS</a> \u2013 all code is available through the <a href=\"https://github.com/csinva/imodels\">imodels package</a>. This is joint work with <a href=\"https://www.linkedin.com/in/nasseri/\">Keyan Nasseri</a>, <a href=\"https://www.linkedin.com/in/abhineet-agarwal-126171185/\">Abhineet Agarwal</a>, <a href=\"https://www.linkedin.com/in/james-pc-duncan/\">James Duncan</a>, <a href=\"https://www.linkedin.com/in/omer-ronen-48ba9412a/?originalSubdomain=il\">Omer Ronen</a>, and <a href=\"https://profiles.ucsf.edu/aaron.kornblith\">Aaron Kornblith</a>.</em></p>",
            "pubdate": "Thu, 30 Jun 2022 02:00:00 -0700",
            "pubdate_parsed": [
                2022,
                6,
                30
            ],
            "email_sent": true
        },
        "Why do Policy Gradient Methods work so well in Cooperative MARL? Evidence from Policy Representation": {
            "url": "http://bair.berkeley.edu/blog/2022/07/10/pg-ar/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p>In cooperative multi-agent reinforcement learning (MARL), due to its <em>on-policy</em> nature, policy gradient (PG) methods are typically believed to be less sample efficient than value decomposition (VD) methods, which are <em>off-policy</em>. However, some <a href=\"https://arxiv.org/abs/2103.01955\">recent</a> <a href=\"https://arxiv.org/abs/2011.09533\">empirical</a> <a href=\"https://arxiv.org/abs/2006.07869\">studies</a> demonstrate that with proper input representation and hyper-parameter tuning, multi-agent PG can achieve <a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">surprisingly strong performance</a> compared to off-policy VD methods.</p>\n\n<p><strong>Why could PG methods work so well?</strong> In this post, we will present concrete analysis to show that in certain scenarios, e.g., environments with a highly multi-modal reward landscape, VD can be problematic and lead to undesired outcomes. By contrast, PG methods with individual policies can converge to an optimal policy in these cases. In addition, PG methods with auto-regressive (AR) policies can learn multi-modal policies.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/ar.png\" width=\"80%\" />\n    <br />\n<i>\nFigure 1: different policy representation for the 4-player permutation game.\n</i>\n</p>\n\n<!--more-->\n\n<h2 id=\"ctde-in-cooperative-marl-vd-and-pg-methods\">CTDE in Cooperative MARL: VD and PG methods</h2>\n\n<p>Centralized training and decentralized execution (<a href=\"https://arxiv.org/abs/1706.02275\">CTDE</a>) is a popular framework in cooperative MARL. It leverages <em>global</em> information for more effective training while keeping the representation of individual policies for testing. CTDE can be implemented via value decomposition (VD) or policy gradient (PG), leading to two different types of algorithms.</p>\n\n<p>VD methods learn local Q networks and a mixing function that mixes the local Q networks to a global Q function. The mixing function is usually enforced to satisfy the Individual-Global-Max (<a href=\"https://arxiv.org/abs/1905.05408\">IGM</a>) principle, which guarantees the optimal joint action can be computed by greedily choosing the optimal action locally for each agent.</p>\n\n<p>By contrast, PG methods directly apply policy gradient to learn an individual policy and a centralized value function for each agent. The value function takes as its input the global state (e.g., <a href=\"https://arxiv.org/abs/2103.01955\">MAPPO</a>) or the concatenation of all the local observations (e.g., <a href=\"https://arxiv.org/abs/1706.02275\">MADDPG</a>), for an accurate global value estimate.</p>\n\n<h2 id=\"the-permutation-game-a-simple-counterexample-where-vd-fails\">The permutation game: a simple counterexample where VD fails</h2>\n\n<p>We start our analysis by considering a stateless cooperative game, namely the permutation game. In an $N$-player permutation game, each agent can output $N$ actions ${ 1,\\ldots, N }$. Agents receive $+1$ reward  if their actions are mutually different, i.e., the joint action is a permutation over $1, \\ldots, N$; otherwise, they receive $0$ reward. Note that there are $N!$ symmetric optimal strategies in this game.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/permutation_game.png\" width=\"70%\" />\n    <br />\n<i>\nFigure 2: the 4-player permutation game.\n</i>\n</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/vd_pg.png\" width=\"90%\" />\n    <br />\n    <i>\nFigure 3: high-level intuition on why VD fails in the 2-player permutation game.\n    </i>\n</p>\n<p>Let us focus on the 2-player permutation game now and apply VD to the game. In this stateless setting, we use  $Q_1$ and $Q_2$ to denote  the local Q-functions, and use $Q_\\textrm{tot}$ to denote  the global Q-function. The IGM principle requires that</p>\n\n\\[\\arg\\max_{a^1,a^2}Q_\\textrm{tot}(a^1,a^2)=\\{\\arg\\max_{a^1}Q_1(a^1),\\arg\\max_{a^2}Q_2(a^2)\\}.\\]\n\n<p>We prove that VD cannot represent the payoff of the 2-player permutation game by contradiction. If VD methods were able to represent the payoff, we would have</p>\n\n\\[Q_\\textrm{tot}(1, 2)=Q_\\textrm{tot}(2,1)=1\\quad \\text{and}\\quad Q_\\textrm{tot}(1, 1)=Q_\\textrm{tot}(2,2)=0.\\]\n\n<p>If either of these two agents has different local Q values (e.g. $Q_1(1)&gt; Q_1(2)$), we have $\\arg\\max_{a^1}Q_1(a^1)=1$. Then according to the IGM principle, <em>any</em> optimal joint action</p>\n\n\\[(a^{1\\star},a^{2\\star})=\\arg\\max_{a^1,a^2}Q_\\textrm{tot}(a^1,a^2)=\\{\\arg\\max_{a^1}Q_1(a^1),\\arg\\max_{a^2}Q_2(a^2)\\}\\]\n\n<p>satisfies $a^{1\\star}=1$ and $a^{1\\star}\\neq 2$, so the joint action $(a^1,a^2)=(2,1)$ is sub-optimal, i.e., $Q_\\textrm{tot}(2,1)&lt;1$.</p>\n\n<p>Otherwise, if $Q_1(1)=Q_1(2)$ and $Q_2(1)=Q_2(2)$, then</p>\n\n\\[Q_\\textrm{tot}(1, 1)=Q_\\textrm{tot}(2,2)=Q_\\textrm{tot}(1, 2)=Q_\\textrm{tot}(2,1).\\]\n\n<p>As a result, value decomposition cannot represent the payoff matrix of the 2-player permutation game.</p>\n\n<p>What about PG methods? Individual policies can indeed represent an optimal policy for the permutation game. Moreover, stochastic gradient descent can guarantee PG to converge to one of these optima <a href=\"https://arxiv.org/abs/1802.06175\">under mild assumptions</a>. This suggests that, even though PG methods are less popular in MARL compared with VD methods, they can be preferable in certain cases that are common in real-world applications, e.g., games with multiple strategy modalities.</p>\n\n<p>We also remark that in the permutation game, in order to represent an optimal joint policy, each agent must choose distinct actions. <strong>Consequently, a successful implementation of PG must ensure that the policies are agent-specific.</strong> This can be done by using either individual policies with unshared parameters (referred to as PG-Ind in our paper), or an agent-ID conditioned policy (<a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">PG-ID</a>).</p>\n\n<h2 id=\"pg-outperforms-existing-vd-methods-on-popular-marl-testbeds\">PG outperforms existing VD methods on popular MARL testbeds</h2>\n\n<p>Going beyond the simple illustrative example of the permutation game, we extend our study to popular and more realistic MARL benchmarks. In addition to StarCraft Multi-Agent Challenge (<a href=\"https://github.com/oxwhirl/smac\">SMAC</a>), where the effectiveness of PG and agent-conditioned policy input <a href=\"http://bair.berkeley.edu/blog/2021/07/14/mappo/\">has been verified</a>, we show new results in Google Research Football (<a href=\"https://github.com/google-research/football\">GRF</a>) and multi-player <a href=\"https://github.com/deepmind/hanabi-learning-environment\">Hanabi Challenge</a>.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/football.png\" width=\"48%\" />\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/hanabi.png\" width=\"45%\" />\n    <br />\n<i>\nFigure 4: (left) winning rates of PG methods on GRF; (right) best and average evaluation scores on Hanabi-Full.\n</i>\n</p>\n\n<p>In GRF, PG methods outperform the state-of-the-art VD baseline (<a href=\"https://arxiv.org/abs/2106.02195\">CDS</a>) in 5 scenarios. Interestingly, we also notice that individual policies (PG-Ind) without parameter sharing achieve comparable, sometimes even higher winning rates, compared to agent-specific policies (PG-ID) in all 5 scenarios. We evaluate PG-ID in the full-scale Hanabi game with varying numbers of players (2-5 players) and compare them to <a href=\"https://arxiv.org/abs/1912.02288\">SAD</a>, a strong off-policy Q-learning variant in Hanabi, and Value Decomposition Networks (<a href=\"https://arxiv.org/abs/1706.05296\">VDN</a>). As demonstrated in the above table, PG-ID is able to produce results comparable to or better than the best and average rewards achieved by SAD and VDN with varying numbers of players using the same number of environment steps.</p>\n\n<h2 id=\"beyond-higher-rewards-learning-multi-modal-behavior-via-auto-regressive-policy-modeling\">Beyond higher rewards: learning multi-modal behavior via auto-regressive policy modeling</h2>\n\n<p>Besides learning higher rewards, we also study how to learn multi-modal policies in cooperative MARL. Let\u2019s go back to the permutation game. Although we have proved that PG can effectively learn an optimal policy, the strategy mode that it finally reaches can highly depend on the policy initialization. Thus, a natural question will be:</p>\n\n<p style=\"text-align: center;\">\n    <i>\nCan we learn a single policy that can cover all the optimal modes?\n    </i>\n</p>\n\n<p>In the decentralized PG formulation, the factorized representation of a joint policy can only represent one particular mode. Therefore, we propose an enhanced way to parameterize the policies for stronger expressiveness \u2014 the auto-regressive (AR) policies.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/pg-ar/permutation_ar.gif\" width=\"80%\" />\n<br />\n<i>\nFigure 5: comparison between individual policies (PG) and auto-regressive  policies (AR) in the 4-player permutation game.\n</i>\n</p>\n\n<p>Formally, we factorize the joint policy of $n$ agents into the form of</p>\n\n\\[\\pi(\\mathbf{a} \\mid \\mathbf{o}) \\approx \\prod_{i=1}^n \\pi_{\\theta^{i}} \\left( a^{i}\\mid o^{i},a^{1},\\ldots,a^{i-1} \\right),\\]\n\n<p>where the action produced by agent $i$ depends on its own observation $o_i$ and all the actions from previous agents $1,\\dots,i-1$. The auto-regressive factorization can represent <em>any</em> joint policy in a centralized MDP. The <em>only</em> modification to each agent\u2019s policy is the input dimension, which is slightly enlarged by including previous actions; and the output dimension of each agent\u2019s policy remains unchanged.</p>\n\n<p>With such a minimal parameterization overhead, AR policy substantially improves the representation power of PG methods. We remark that PG with AR policy (PG-AR) can simultaneously represent all optimal policy modes in the permutation game.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/heatmap.png\" width=\"70%\" />\n    <br />\n<i>\nFigure: the heatmaps of actions for policies learned by PG-Ind (left) and PG-AR (middle), and the heatmap for rewards (right); while PG-Ind only converge to a specific mode in the 4-player permutation game, PG-AR successfully discovers all the optimal modes.\n</i>\n</p>\n\n<p>In more complex environments, including SMAC and GRF, PG-AR can learn interesting emergent behaviors that require strong intra-agent coordination that may never be learned by PG-Ind.</p>\n\n<p style=\"text-align: center;\">\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/2m1z.gif\" width=\"45%\" />\n    <img src=\"https://bair.berkeley.edu/static/blog/pg-ar/3v1.gif\" width=\"45%\" />\n    <br />\n<i>\nFigure 6: (left) emergent behavior induced by PG-AR in SMAC and GRF. On the 2m_vs_1z map of SMAC, the marines keep standing and attack alternately while ensuring there is only one attacking marine at each timestep; (right) in the academy_3_vs_1_with_keeper scenario of GRF, agents learn a \"Tiki-Taka\" style behavior: each player keeps passing the ball to their teammates.\n</i>\n</p>\n\n<h2 id=\"discussions-and-takeaways\">Discussions and Takeaways</h2>\n\n<p>In this post, we provide a concrete analysis of VD and PG methods in cooperative MARL. First, we reveal the limitation on the expressiveness of popular VD methods, showing that they could not represent optimal policies even in a simple permutation game. By contrast, we show that PG methods are provably more expressive. We empirically verify the expressiveness advantage of PG on popular MARL testbeds, including SMAC, GRF, and Hanabi Challenge. We hope the insights from this work could benefit the community towards more general and more powerful cooperative MARL algorithms in the future.</p>\n\n<hr />\n\n<p><em>This post is based on our paper: Revisiting Some Common Practices in Cooperative Multi-Agent Reinforcement Learning (<a href=\"https://arxiv.org/abs/2206.07505\">paper</a>, <a href=\"https://sites.google.com/view/revisiting-marl\">website</a>).</em></p>",
            "pubdate": "Sun, 10 Jul 2022 02:00:00 -0700",
            "pubdate_parsed": [
                2022,
                7,
                10
            ],
            "email_sent": true
        },
        "Keeping Learning-Based Control Safe by Regulating Distributional Shift": {
            "url": "http://bair.berkeley.edu/blog/2022/09/19/ldm-control/",
            "description": "<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/header.jpg\" width=\"80%\" />\n<br />\n<i> To regulate the distribution shift experience by learning-based controllers, we seek a mechanism for constraining the agent to regions of high data density throughout its trajectory (left). Here, we present an approach which achieves this goal by combining features of density models (middle) and Lyapunov functions (right).</i>\n</p>\n\n<p>In order to make use of machine learning and reinforcement learning in controlling real world systems, we must design algorithms which not only achieve good performance, but also interact with the system in a safe and reliable manner. Most prior work on safety-critical control focuses on maintaining the safety of the <em>physical  system</em>, e.g. avoiding falling over for legged robots, or colliding into obstacles for autonomous vehicles. However, for learning-based controllers, there is another source of safety concern: because machine learning models are only optimized to output correct predictions on the training data, they are prone to outputting erroneous predictions when evaluated on out-of-distribution inputs. Thus, if an agent visits a state or takes an action that is very different from those in the training data, a learning-enabled controller may \u201cexploit\u201d the inaccuracies in its learned component and output actions that are suboptimal or even dangerous.</p>\n\n<!--more-->\n\n<p>To prevent these potential \u201cexploitations\u201d of model inaccuracies, we propose a new framework to reason about the safety of a learning-based controller with respect to its <em>training distribution</em>. The central idea behind our work is to view the training data distribution as a safety constraint, and to draw on tools from control theory to control the distributional shift experienced by the agent during closed-loop control. More specifically, we\u2019ll discuss how Lyapunov stability can be unified with density estimation to produce Lyapunov density models, a new kind of safety \u201cbarrier\u201d function which can be used to synthesize controllers with guarantees of keeping the agent in regions of high data density. Before we introduce our new framework, we will first give an overview of existing techniques for guaranteeing physical safety via barrier function.</p>\n\n<h1 id=\"guaranteeing-safety-via-barrier-functions\">Guaranteeing Safety via Barrier Functions</h1>\n<p>In control theory, a central topic of study is: given <em>known</em> system dynamics, $s_{t+1}=f(s_t, a_t)$, and <em>known</em> system constraints, $s \\in C$, how can we design a controller that is guaranteed to keep the system within the specified constraints? Here, $C$ denotes the set of states that are deemed safe for the agent to visit. This problem is challenging because the specified constraints need to be satisfied over the agent\u2019s entire trajectory horizon ($s_t \\in C$  $\\forall 0\\leq t \\leq T$). If the controller uses a simple \u201cgreedy\u201d strategy of avoiding constraint violations in the next time step (not taking $a_t$ for which $f(s_t, a_t) \\notin C$), the system may still end up in an \u201cirrecoverable\u201d state, which itself is considered safe, but will inevitably lead to an unsafe state in the future regardless of the agent\u2019s future actions. In order to avoid visiting these \u201cirrecoverable\u201d states, the controller must employ a more \u201clong-horizon\u201d strategy which involves predicting the agent\u2019s entire future trajectory to avoid safety violations at any point in the future (avoid $a_t$ for which all possible $\\{ a_{\\hat{t}} \\}_{\\hat{t}=t+1}^H$ lead to some $\\bar{t}$ where $s_{\\bar{t}} \\notin C$ and $t&lt;\\bar{t} \\leq T$). However, predicting the agent\u2019s full trajectory at every step is extremely computationally intensive, and often infeasible to perform online during run-time.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/blog_fig_1.jpg\" width=\"40%\" />\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/blog_fig_2.jpg\" width=\"40%\" />\n<br />\n<i> Illustrative example of a drone whose goal is to fly as straight as possible while avoiding obstacles. Using the \u201cgreedy\u201d strategy of avoiding safety violations (left), the drone flies straight because there\u2019s no obstacle in the next timestep, but inevitably crashes in the future because it can\u2019t turn in time. In contrast, using the \u201clong-horizon\u201d strategy (right), the drone turns early and successfully avoids the tree, by considering the entire future horizon future of its trajectory.</i>\n</p>\n\n<p>Control theorists tackle this challenge by designing \u201cbarrier\u201d functions, $v(s)$, to constrain the controller at each step (only allow $a_t$ which satisfy $v(f(s_t, a_t)) \\leq 0$). In order to ensure the agent remains safe throughout its entire trajectory, the constraint induced by barrier functions ($v(f(s_t, a_t))\\leq 0$) prevents the agent from visiting both unsafe states and irrecoverable states which inevitably lead to unsafe states in the future. This strategy essentially amortizes the computation of looking into the future for inevitable failures when designing the safety barrier function, which only needs to be done once and can be computed offline. This way, at runtime, the policy only needs to employ the greedy constraint satisfaction strategy on the barrier function $v(s)$ in order to ensure safety for all future timesteps.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/blog_fig_4.jpg\" width=\"50%\" />\n<br />\n<i> The blue region denotes the of states allowed by the barrier function constraint, $\\{s | v(s) \\leq 0\\}$. Using a \u201clong-horizon\u201d barrier function, the drone only needs to greedily ensure that the barrier function constraint $v(s) \\leq 0$ is satisfied for the next state, in order to avoid safety violations for all future timesteps. </i>\n</p>\n\n<p>Here, we used the notion of a \u201cbarrier\u201d function as an umbrella term to describe a number of different kinds of functions whose functionalities are to constrain the controller in order to make long-horizon guarantees. Some specific examples include <a href=\"https://link.springer.com/chapter/10.1007/978-1-4757-3108-8_5\">control Lyapunov functions</a> for guaranteeing stability, <a href=\"https://arxiv.org/abs/1903.11199\">control barrier functions</a> for guaranteeing general safety constraints, and the value function in <a href=\"https://arxiv.org/abs/1709.07523\">Hamilton-Jacobi reachability</a> for guaranteeing general safety constraints under external disturbances. More recently, there has also been <a href=\"https://arxiv.org/abs/1705.08551\">some</a> <a href=\"https://arxiv.org/abs/1805.07708\">work</a> on learning barrier functions, for settings where the system is unknown or where barrier functions are difficult to design. However, prior works in both traditional and learning-based barrier functions are mainly focused on making guarantees of physical safety. In the next section, we will discuss how we can extend these ideas to regulate the distribution shift experienced by the agent when using a learning-based controller.</p>\n\n<h1 id=\"lyapunov-density-models\">Lyapunov Density Models</h1>\n<p>To prevent model exploitation due to distribution shift, many learning-based control algorithms constrain or regularize the controller to prevent the agent from taking low-likelihood actions or visiting low likelihood states, for instance in <a href=\"https://arxiv.org/abs/2006.04779\">offline RL</a>, <a href=\"https://arxiv.org/abs/2005.13239\">model-based RL</a>, and <a href=\"https://arxiv.org/abs/1606.03476\">imitation learning</a>. However, most of these methods only constrain the controller with a single-step estimate of the data distribution, akin to the \u201cgreedy\u201d strategy of keeping an autonomous drone safe by preventing actions which causes it to crash in the next timestep. As we saw in the illustrative figures above, this strategy is not enough to guarantee that the drone will not crash (or go out-of-distribution) in another future timestep.</p>\n\n<p>How can we design a controller for which the agent is guaranteed to stay in-distribution for its entire trajectory? Recall that barrier functions can be used to guarantee constraint satisfaction for all future timesteps, which is exactly the kind of guarantee we hope to make with regards to the data distribution. Based on this observation, we propose a new kind of barrier function: the Lyapunov density model (LDM), which merges the dynamics-aware aspect of a Lyapunov function with the data-aware aspect of a density model (it is in fact a generalization of both types of function). Analogous to how Lyapunov functions keeps the system from becoming physically unsafe, our Lyapunov density model keeps the system from going out-of-distribution.</p>\n\n<p>An LDM ($G(s, a)$) maps state and action pairs to negative log densities, where the values of $G(s, a)$ represent the best data density the agent is able to stay above throughout its trajectory. It can be intuitively thought of as a \u201cdynamics-aware, long-horizon\u201d transformation on a single-step density model ($E(s, a)$), where $E(s, a)$ approximates the negative log likelihood of the data distribution. Since a single-step density model constraint ($E(s, a) \\leq -\\log(c)$ where $c$ is a cutoff density) might still allow the agent to visit \u201cirrecoverable\u201d states which inevitably causes the agent to go out-of-distribution, the LDM transformation increases the value of those \u201cirrecoverable\u201d states until they become \u201crecoverable\u201d with respect to their updated value. As a result, the LDM constraint ($G(s, a) \\leq -\\log(c)$) restricts the agent to a smaller set of states and actions which excludes the \u201cirrecoverable\u201d states, thereby ensuring the agent is able to remain in high data-density regions throughout its entire trajectory.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/jason.jpg\" width=\"80%\" />\n<br />\n<i> Example of data distributions (middle) and their associated LDMs (right) for a 2D linear system (left). LDMs can be viewed as \"dynamics-aware, long-horizon\" transformations on density models. </i>\n</p>\n\n<p>How exactly does this \u201cdynamics-aware, long-horizon\u201d transformation work? Given a data distribution $P(s, a)$ and dynamical system $s_{t+1} = f(s_t, a_t)$, we define the following as the LDM operator: $\\mathcal{T}G(s, a) = \\max\\{-\\log P(s, a), \\min_{a\u2019} G(f(s, a), a\u2019)\\}$. Suppose we initialize $G(s, a)$ to be $-\\log P(s, a)$. Under one iteration of the LDM operator, the value of a state action pair, $G(s, a)$, can either remain at $-\\log P(s, a)$ or increase in value, depending on whether the value at the best state action pair in the next timestep, $\\min_{a\u2019} G(f(s, a), a\u2019)$, is larger than $-\\log P(s, a)$. Intuitively, if the value at the best next state action pair is larger than the current $G(s, a)$ value, this means that the agent is unable to remain at the current density level regardless of its future actions, making the current state \u201cirrecoverable\u201d with respect to the current density level. By increasing the current the value of $G(s, a)$, we are \u201ccorrecting\u201d the LDM such that its constraints would not include \u201cirrecoverable\u201d states. Here, one LDM operator update captures the effect of looking into the future for one timestep. If we repeatedly apply the LDM operator on $G(s, a)$ until convergence, the final LDM will be free of \u201cirrecoverable\u201d states in the agent\u2019s entire future trajectory.</p>\n\n<p>To use an LDM in control, we can train an LDM and learning-based controller on the same training dataset and constrain the controller\u2019s action outputs with an LDM constraint ($G(s, a)) \\leq -\\log(c)$). Because the LDM constraint prevents both states with low density and \u201cirrecoverable\u201d states, the learning-based controller will be able to avoid out-of-distribution inputs throughout the agent\u2019s entire trajectory. Furthermore, by choosing the cutoff density of the LDM constraint, $c$, the user is able to control the tradeoff between protecting against model error vs. flexibility for performing the desired task.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/hopper.gif\" width=\"80%\" />\n<br />\n<i> Example evaluation of ours and baseline methods on a hopper control task for different values of constraint thresholds (x- axis). On the right, we show example trajectories from when the threshold is too low (hopper falling over due to excessive model exploitation), just right (hopper successfully hopping towards target location), or too high (hopper standing still due to over conservatism). </i>\n</p>\n\n<p>So far, we have only discussed the properties of a \u201cperfect\u201d LDM, which can be found if we had oracle access to the data distribution and dynamical system. In practice, though, we approximate the LDM using only data samples from the system. This causes a problem to arise: even though the role of the LDM is to prevent distribution shift, the LDM itself can also suffer from the negative effects of distribution shift, which degrades its effectiveness for preventing distribution shift. To understand the degree to which the degradation happens, we analyze this problem from both a theoretical and empirical perspective. Theoretically, we show even if there are errors in the LDM learning procedure, an LDM constrained controller is still able to maintain guarantees of keeping the agent in-distribution. Albeit, this guarantee is a bit weaker than the original guarantee provided by a perfect LDM, where the amount of degradation depends on the scale of the errors in the learning procedure. Empirically, we approximate the LDM using deep neural networks, and show that using a learned LDM to constrain the learning-based controller still provides performance improvements compared to using single-step density models on several domains.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ldm-control/bar.jpg\" width=\"80%\" />\n<br />\n<i> Evaluation of our method (LDM) compared to constraining a learning-based controller with a density model, the variance over an ensemble of models, and no constraint at all on several domains including hopper, lunar lander, and glucose control. </i>\n</p>\n\n<h1 id=\"conclusion-and-takeaways\">Conclusion and Takeaways</h1>\n<p>Currently, one of the biggest challenges in deploying learning-based controllers on real world systems is their potential brittleness to out-of-distribution inputs, and lack of guarantees on performance. Conveniently, there exists a large body of work in control theory focused on making guarantees about how systems evolve. However, these works usually focus on making guarantees with respect to physical safety requirements, and assume access to an accurate dynamics model of the system as well as physical safety constraints. The central idea behind our work is to instead view the training data distribution as a safety constraint. This allows us to make use of these ideas in controls in our design of learning-based control algorithms, thereby inheriting both the scalability of machine learning and the rigorous guarantees of control theory.</p>\n\n<p><i>This post is based on the paper \u201cLyapunov Density Models: Constraining Distribution Shift in Learning-Based Control\u201d, presented at ICML 2022. You\nfind more details in <a href=\"https://arxiv.org/abs/2206.10524\">our paper</a> and on our <a href=\"https://sites.google.com/berkeley.edu/ldm/\">website</a>. We thank Sergey Levine, Claire Tomlin, Dibya Ghosh, Jason Choi, Colin Li, and Homer Walke for their valuable feedback on this blog post.</i></p>",
            "pubdate": "Mon, 19 Sep 2022 02:00:00 -0700",
            "pubdate_parsed": [
                2022,
                9,
                19
            ],
            "email_sent": true
        },
        "Fully Autonomous Real-World Reinforcement Learning with Applications to Mobile Manipulation": {
            "url": "http://bair.berkeley.edu/blog/2023/01/20/relmm/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p>Reinforcement learning provides a conceptual framework for autonomous agents to learn from experience, analogously to how one might train a pet with treats. But practical applications of reinforcement learning are often far from natural: instead of using RL to learn through trial and error by actually attempting the desired task, typical RL applications use a separate (usually simulated) training phase. For example, <a href=\"https://deepmind.com/research/case-studies/alphago-the-story-so-far\">AlphaGo</a> did not learn to play Go by competing against thousands of humans, but rather by playing against itself in simulation. While this kind of simulated training is appealing for games where the rules are perfectly known, applying this to real world domains such as robotics can require a range of complex approaches, such as <a href=\"https://www.youtube.com/watch?v=XUW0cnvqbwM\">the use of simulated data</a>, or instrumenting real-world environments in various ways to make training feasible <a href=\"https://bair.berkeley.edu/blog/2020/04/27/ingredients/\">under laboratory conditions</a>. Can we instead devise reinforcement learning systems for robots that allow them to learn directly \u201con-the-job\u201d, while performing the task that they are required to do? In this blog post, we will discuss ReLMM, a system that we developed that learns to clean up a room directly with a real robot via continual learning.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image8.gif\" width=\"48%\" />\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image12.gif\" width=\"48%\" />\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image3.gif\" width=\"48%\" />\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image2.gif\" width=\"48%\" />\n<br />\n<i>We evaluate our method on different tasks that range in difficulty. The top-left task has uniform white blobs to pickup with no obstacles, while other rooms have objects of diverse shapes and colors, obstacles that increase navigation difficulty and obscure the objects and patterned rugs that make it difficult to see the objects against the ground.</i>\n</p>\n\n<!--more-->\n\n<p>To enable \u201con-the-job\u201d training in the real world, the difficulty of collecting more experience is prohibitive. If we can make training in the real world easier, by making the data gathering process more autonomous without requiring human monitoring or intervention, we can further benefit from the simplicity of agents that learn from experience. In this work, we design an \u201con-the-job\u201d mobile robot training system for cleaning by learning to grasp objects throughout different rooms.</p>\n\n<h1 id=\"lesson-1-the-benefits-of-modular-policies-for-robots\">Lesson 1: The Benefits of Modular Policies for Robots.</h1>\n\n<p>People are not born one day and performing job interviews the next. There are many levels of tasks people learn before they apply for a job as we start with the easier ones and build on them. In ReLMM, we make use of this concept by allowing robots to train common-reusable skills, such as grasping, by first encouraging the robot to prioritize training these skills before learning later skills, such as navigation. Learning in this fashion has two advantages for robotics. The first advantage is that when an agent focuses on learning a skill, it is more efficient at collecting data around the local state distribution for that skill.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image13.png\" width=\"50%\" />\n<br />\n</p>\n\n<p>That is shown in the figure above, where we evaluated the amount of prioritized grasping experience needed to result in efficient mobile manipulation training. The second advantage to a multi-level learning approach is that we can inspect the models trained for different tasks and ask them questions, such as, \u201ccan you grasp anything right now\u201d which is helpful for navigation training that we describe next.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image14.png\" width=\"50%\" />\n<br />\n</p>\n\n<p>Training this multi-level policy was not only more efficient than learning both skills at the same time but it allowed for the grasping controller to inform the navigation policy. Having a model that estimates the uncertainty in its grasp success (<strong>Ours</strong> above) can be used to improve navigation exploration by skipping areas without graspable objects, in contrast to <strong>No Uncertainty Bonus</strong> which does not use this information. The model can also be used to relabel data during training so that in the unlucky case when the grasping model was unsuccessful trying to grasp an object within its reach, the grasping policy can still provide some signal by indicating that an object was there but the grasping policy has not yet learned how to grasp it. Moreover, learning modular models has engineering benefits. Modular training allows for reusing skills that are easier to learn and can enable building intelligent systems one piece at a time. This is beneficial for many reasons, including safety evaluation and understanding.</p>\n\n<h1 id=\"lesson-2-learning-systems-beat-hand-coded-systems-given-time\">Lesson 2: Learning systems beat hand-coded systems, given time</h1>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/relmm/image15.png\" width=\"50%\" />\n<br />\n</p>\n\n<p>Many robotics tasks that we see today can be solved to varying levels of success using hand-engineered controllers. For our room cleaning task, we designed a hand-engineered controller that locates objects using image clustering and turns towards the nearest detected object at each step. This expertly designed controller performs very well on the visually salient balled socks and takes reasonable paths around the obstacles <strong>but it can not learn an optimal path to collect the objects quickly, and it struggles with visually diverse rooms</strong>. As shown in video 3 below, the scripted policy gets distracted by the white patterned carpet while trying to locate more white objects to grasp.</p>\n\n<p style=\"text-align: center;\">\n1) <img src=\"https://bair.berkeley.edu/static/blog/relmm/image5.gif\" width=\"45%\" />\n2) <img src=\"https://bair.berkeley.edu/static/blog/relmm/image6.gif\" width=\"45%\" />\n<br />\n3) <img src=\"https://bair.berkeley.edu/static/blog/relmm/image1.gif\" width=\"45%\" />\n4) <img src=\"https://bair.berkeley.edu/static/blog/relmm/image9.png\" width=\"45%\" />\n<br />\n<i>We show a comparison between (1) our policy at the beginning of training (2) our policy at the end of training (3) the scripted policy. In (4) we can see the robot's performance improve over time, and eventually exceed the scripted policy at quickly collecting the objects in the room.</i>\n</p>\n\n<p>Given we can use experts to code this hand-engineered controller, what is the purpose of learning? An important limitation of hand-engineered controllers is that they are tuned for a particular task, for example, grasping white objects. When diverse objects are introduced, which differ in color and shape, the original tuning may no longer be optimal. Rather than requiring further hand-engineering, our learning-based method is able to adapt itself to various tasks by collecting its own experience.</p>\n\n<p>However, the most important lesson is that even if the hand-engineered controller is capable, the learning agent eventually surpasses it given enough time. This learning process is itself autonomous and takes place while the robot is performing its job, making it comparatively inexpensive. This shows the capability of learning agents, which can also be thought of as working out a general way to perform an \u201cexpert manual tuning\u201d process for any kind of task. Learning systems have the ability to create the entire control algorithm for the robot, and are not limited to tuning a few parameters in a script. The key step in this work allows these real-world learning systems to autonomously collect the data needed to enable the success of learning methods.</p>\n\n<p><i>This post is based on the paper \u201cFully Autonomous Real-World Reinforcement Learning with Applications to Mobile Manipulation\u201d, presented at CoRL 2021. You can find more details in <a href=\"https://arxiv.org/abs/2107.13545\">our paper</a>, on our <a href=\"https://sites.google.com/view/relmm\">website</a> and the on the <a href=\"https://drive.google.com/file/d/1BsqXvxv0ByGIXxGb3zBYBncL9pKaxWuX/view?usp=sharing\">video</a>. We provide <a href=\"https://github.com/charlesjsun/ReLMM\">code</a> to reproduce our experiments. We thank Sergey Levine for his valuable feedback on this blog post.</i></p>",
            "pubdate": "Fri, 20 Jan 2023 01:00:00 -0800",
            "pubdate_parsed": [
                2023,
                1,
                20
            ],
            "email_sent": true
        },
        "Interactive Fleet Learning": {
            "url": "http://bair.berkeley.edu/blog/2023/04/06/ifl/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ifl/figure1.gif\" width=\"75%\" />\n<br />\n<i>Figure 1: \u201cInteractive Fleet Learning\u201d (IFL) refers to robot fleets in industry and academia that fall back on human teleoperators when necessary and continually learn from them over time.</i>\n</p>\n\n<p>In the last few years we have seen an exciting development in robotics and artificial intelligence: large fleets of robots have left the lab and entered the real world. <a href=\"https://waymo.com/\">Waymo</a>, for example, has over 700 self-driving cars operating in Phoenix and San Francisco and is <a href=\"https://blog.waymo.com/2022/10/next-stop-for-waymo-one-los-angeles.html\">currently expanding to Los Angeles</a>. Other industrial deployments of robot fleets include applications like e-commerce order fulfillment at <a href=\"https://www.amazon.com/\">Amazon</a> and <a href=\"https://www.ambirobotics.com/\">Ambi Robotics</a> as well as food delivery at <a href=\"https://www.nuro.ai/\">Nuro</a> and <a href=\"https://www.kiwibot.com/\">Kiwibot</a>.</p>\n\n<!--more-->\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ifl/figure2.jpg\" width=\"95%\" />\n<br />\n<i>Commercial and industrial deployments of robot fleets: package delivery (top left), food delivery (bottom left), e-commerce order fulfillment at Ambi Robotics (top right), autonomous taxis at Waymo (bottom right).</i>\n</p>\n\n<p>These robots use recent advances in deep learning to operate autonomously in unstructured environments. By pooling data from all robots in the fleet, the entire fleet can efficiently learn from the experience of each individual robot. Furthermore, due to advances in <a href=\"https://ieeexplore.ieee.org/document/7006734\">cloud robotics</a>, the fleet can offload data, memory, and computation (e.g., training of large models) to the cloud via the Internet. This approach is known as \u201cFleet Learning,\u201d a term popularized by Elon Musk in <a href=\"https://electrek.co/2016/09/11/transcript-elon-musks-press-conference-about-tesla-autopilot-under-v8-0-update-part-1/\">2016 press releases about Tesla Autopilot</a> and used in press communications by <a href=\"https://www.tri.global/news/tri-teaching-robots-help-people-their-homes\">Toyota Research Institute</a>, <a href=\"https://wayve.ai/technology/fleet-learning-technology/\">Wayve AI</a>, and others. A robot fleet is a modern analogue of a fleet of ships, where the word <em>fleet</em> has an etymology tracing back to <em>fl\u0113ot</em> (\u2018ship\u2019) and <em>fl\u0113otan</em> (\u2018float\u2019) in Old English.</p>\n\n<p>Data-driven approaches like fleet learning, however, face the problem of the <a href=\"https://www.forbes.com/sites/lanceeliot/2021/07/13/whether-those-endless-edge-or-corner-cases-are-the-long-tail-doom-for-ai-self-driving-cars/?sh=573981be5933\">\u201clong tail\u201d</a>: the robots inevitably encounter new scenarios and edge cases that are not represented in the dataset. Naturally, we can\u2019t expect the future to be the same as the past! How, then, can these robotics companies ensure sufficient reliability for their services?</p>\n\n<p>One answer is to fall back on remote humans over the Internet, who can interactively take control and \u201ctele-operate\u201d the system when the robot policy is unreliable during task execution. Teleoperation has a rich history in robotics: <a href=\"https://goldberg.berkeley.edu/pubs/Nature-Robots-and-Return-to-Collaborative-Intelligence.pdf\">the world\u2019s first robots were teleoperated</a> during WWII to handle radioactive materials, and the <a href=\"https://en.wikipedia.org/wiki/Telegarden\">Telegarden</a> pioneered robot control over the Internet in 1994. With continual learning, the human teleoperation data from these interventions can iteratively improve the robot policy and reduce the robots\u2019 reliance on their human supervisors over time. Rather than a discrete jump to full robot autonomy, this strategy offers a continuous alternative that approaches full autonomy over time while simultaneously enabling reliability in robot systems <em>today</em>.</p>\n\n<p>The use of human teleoperation as a fallback mechanism is increasingly popular in modern robotics companies: Waymo calls it <a href=\"https://www.theatlantic.com/technology/archive/2018/08/waymos-robot-cars-and-the-humans-who-tend-to-them/568051/\">\u201cfleet response,\u201d</a> Zoox calls it <a href=\"https://twitter.com/zoox/status/1415737908112203776\">\u201cTeleGuidance,\u201d</a> and Amazon calls it <a href=\"https://www.amazon.science/latest-news/robin-deals-with-a-world-where-things-are-changing-all-around-it\">\u201ccontinual learning.\u201d</a> Last year, a software platform for remote driving called <a href=\"https://phantom.auto/\">Phantom Auto</a> was recognized by Time Magazine as one of their <a href=\"https://time.com/collection/best-inventions-2022/6224834/phantom-auto-remote-operation-platform-for-logistics/\">Top 10 Inventions of 2022</a>. And just last month, <a href=\"https://www.therobotreport.com/john-deere-acquires-sparkais-human-in-the-loop-tech/\">John Deere acquired SparkAI</a>, a startup that develops software for resolving edge cases with humans in the loop.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ifl/figure3.jpg\" width=\"95%\" />\n<br />\n<i>A remote human teleoperator at Phantom Auto, a software platform for enabling remote driving over the Internet.</i>\n</p>\n\n<p>Despite this growing trend in industry, however, there has been comparatively little focus on this topic in academia. As a result, robotics companies have had to rely on ad hoc solutions for determining when their robots should cede control. The closest analogue in academia is <a href=\"https://arxiv.org/abs/2211.00600\">interactive imitation learning (IIL)</a>, a paradigm in which a robot intermittently cedes control to a human supervisor and learns from these interventions over time. There have been a number of IIL algorithms in recent years for the single-robot, single-human setting including <a href=\"https://arxiv.org/abs/1011.0686\">DAgger</a> and variants such as <a href=\"https://arxiv.org/abs/1810.02890\">HG-DAgger</a>, <a href=\"https://arxiv.org/abs/1605.06450\">SafeDAgger</a>, <a href=\"https://arxiv.org/abs/1807.08364\">EnsembleDAgger</a>, and <a href=\"https://arxiv.org/abs/2109.08273\">ThriftyDAgger</a>; nevertheless, when and how to switch between robot and human control is still an open problem. This is even less understood when the notion is generalized to robot fleets, with multiple robots and multiple human supervisors.</p>\n\n<h2 id=\"ifl-formalism-and-algorithms\">IFL Formalism and Algorithms</h2>\n\n<p>To this end, in a <a href=\"https://proceedings.mlr.press/v205/hoque23a.html\">recent paper at the Conference on Robot Learning</a> we introduced the paradigm of <em>Interactive Fleet Learning (IFL)</em>, the first formalism in the literature for interactive learning with multiple robots and multiple humans. As we\u2019ve seen that this phenomenon already occurs in industry, we can now use the phrase \u201cinteractive fleet learning\u201d as unified terminology for robot fleet learning that falls back on human control, rather than keep track of the names of every individual corporate solution (\u201cfleet response\u201d, \u201cTeleGuidance\u201d, etc.). IFL scales up robot learning with four key components:</p>\n\n<ol>\n  <li><strong>On-demand supervision.</strong> Since humans cannot effectively monitor the execution of multiple robots at once and are prone to fatigue, the allocation of robots to humans in IFL is automated by some allocation policy $\\omega$. Supervision is requested \u201con-demand\u201d by the robots rather than placing the burden of continuous monitoring on the humans.</li>\n  <li><strong>Fleet supervision.</strong> On-demand supervision enables effective allocation of limited human attention to large robot fleets. IFL allows the number of robots to significantly exceed the number of humans (e.g., by a factor of 10:1 or more).</li>\n  <li><strong>Continual learning.</strong> Each robot in the fleet can learn from its own mistakes as well as the mistakes of the other robots, allowing the amount of required human supervision to taper off over time.</li>\n  <li><strong>The Internet.</strong> Thanks to mature and ever-improving Internet technology, the human supervisors do not need to be physically present. Modern computer networks enable <a href=\"https://venturebeat.com/business/how-teleoperation-could-enable-remote-work-for-more-industries/\">real-time remote teleoperation</a> at vast distances.</li>\n</ol>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/ifl/figure4.jpg\" width=\"95%\" />\n<br />\n<i>In the Interactive Fleet Learning (IFL) paradigm, M humans are allocated to the robots that need the most help in a fleet of N robots (where N can be much larger than M). The robots share policy $\\pi_{\\theta_t}$ and learn from human interventions over time.</i>\n</p>\n\n<p>We assume that the robots share a common control policy $\\pi_{\\theta_t}$ and that the humans share a common control policy $\\pi_H$. We also assume that the robots operate in independent environments with identical state and action spaces (but not identical states). Unlike a robot <em>swarm</em> of typically low-cost robots that coordinate to achieve a common objective in a shared environment, a robot <em>fleet</em> simultaneously executes a shared policy in distinct parallel environments (e.g., different bins on an assembly line).</p>\n\n<p>The goal in IFL is to find an optimal supervisor allocation policy $\\omega$, a mapping from $\\mathbf{s}^t$ (the state of all robots at time <em>t</em>) and the shared policy $\\pi_{\\theta_t}$ to a binary matrix that indicates which human will be assigned to which robot at time <em>t</em>. The IFL objective is a novel metric we call the \u201creturn on human effort\u201d (ROHE):</p>\n\n\\[\\max_{\\omega \\in \\Omega} \\mathbb{E}_{\\tau \\sim p_{\\omega, \\theta_0}(\\tau)} \\left[\\frac{M}{N} \\cdot \\frac{\\sum_{t=0}^T \\bar{r}( \\mathbf{s}^t, \\mathbf{a}^t)}{1+\\sum_{t=0}^T \\|\\omega(\\mathbf{s}^t, \\pi_{\\theta_t}, \\cdot) \\|^2 _F} \\right]\\]\n\n<p>where the numerator is the total reward across robots and timesteps and the denominator is the total amount of human actions across robots and timesteps. Intuitively, the ROHE measures the performance of the fleet normalized by the total human supervision required. See the <a href=\"https://arxiv.org/abs/2206.14349\">paper</a> for more of the mathematical details.</p>\n\n<p>Using this formalism, we can now instantiate and compare IFL algorithms (i.e., allocation policies) in a principled way. We propose a family of IFL algorithms called Fleet-DAgger, where the policy learning algorithm is interactive imitation learning and each Fleet-DAgger algorithm is parameterized by a unique priority function $\\hat p: (s, \\pi_{\\theta_t}) \\rightarrow [0, \\infty)$ that each robot in the fleet uses to assign itself a priority score. Similar to scheduling theory, higher priority robots are more likely to receive human attention. Fleet-DAgger is general enough to model a wide range of IFL algorithms, including IFL adaptations of existing single-robot, single-human IIL algorithms such as <a href=\"https://arxiv.org/abs/1807.08364\">EnsembleDAgger</a> and <a href=\"https://arxiv.org/abs/2109.08273\">ThriftyDAgger</a>. Note, however, that the IFL formalism isn\u2019t limited to Fleet-DAgger: policy learning could be performed with a reinforcement learning algorithm like <a href=\"https://arxiv.org/abs/1707.06347\">PPO</a>, for instance.</p>\n\n<h2 id=\"ifl-benchmark-and-experiments\">IFL Benchmark and Experiments</h2>\n\n<p>To determine how to best allocate limited human attention to large robot fleets, we need to be able to empirically evaluate and compare different IFL algorithms. To this end, we introduce the <a href=\"https://github.com/BerkeleyAutomation/ifl_benchmark\">IFL Benchmark</a>, an open-source Python toolkit available on Github to facilitate the development and standardized evaluation of new IFL algorithms. We extend <a href=\"https://developer.nvidia.com/isaac-gym\">NVIDIA Isaac Gym</a>, a highly optimized software library for end-to-end GPU-accelerated robot learning released in 2021, without which the simulation of hundreds or thousands of learning robots would be computationally intractable. Using the IFL Benchmark, we run large-scale simulation experiments with <em>N</em> = 100 robots, <em>M</em> = 10 algorithmic humans, 5 IFL algorithms, and 3 high-dimensional continuous control environments (Figure 1, left).</p>\n\n<p>We also evaluate IFL algorithms in a real-world image-based block pushing task with <em>N</em> = 4 robot arms and <em>M</em> = 2 remote human teleoperators (Figure 1, right). The 4 arms belong to 2 bimanual ABB YuMi robots operating simultaneously in 2 separate labs about 1 kilometer apart, and remote humans in a third physical location perform teleoperation through a keyboard interface when requested. Each robot pushes a cube toward a unique goal position randomly sampled in the workspace; the goals are programmatically generated in the robots\u2019 overhead image observations and automatically resampled when the previous goals are reached. Physical experiment results suggest trends that are approximately consistent with those observed in the benchmark environments.</p>\n\n<h2 id=\"takeaways-and-future-directions\">Takeaways and Future Directions</h2>\n\n<p>To address the gap between the theory and practice of robot fleet learning as well as facilitate future research, we introduce new formalisms, algorithms, and benchmarks for Interactive Fleet Learning. Since IFL does not dictate a specific form or architecture for the shared robot control policy, it can be flexibly synthesized with other promising research directions. For instance, <a href=\"https://arxiv.org/abs/2303.04137\">diffusion policies</a>, recently demonstrated to gracefully handle multimodal data, can be used in IFL to allow heterogeneous human supervisor policies. Alternatively, multi-task language-conditioned Transformers like <a href=\"https://arxiv.org/abs/2212.06817\">RT-1</a> and <a href=\"https://arxiv.org/abs/2209.05451\">PerAct</a> can be effective \u201cdata sponges\u201d that enable the robots in the fleet to perform heterogeneous tasks despite sharing a single policy. The systems aspect of IFL is another compelling research direction: recent developments in cloud and <a href=\"https://arxiv.org/abs/2205.09778\">fog robotics</a> enable robot fleets to offload all supervisor allocation, model training, and crowdsourced teleoperation to centralized servers in the cloud with minimal network latency.</p>\n\n<p>While <a href=\"https://en.wikipedia.org/wiki/Moravec%27s_paradox\">Moravec\u2019s Paradox</a> has so far prevented robotics and embodied AI from fully enjoying the recent spectacular success that Large Language Models (LLMs) like <a href=\"https://openai.com/research/gpt-4\">GPT-4</a> have demonstrated, the <a href=\"http://www.incompleteideas.net/IncIdeas/BitterLesson.html\">\u201cbitter lesson\u201d</a> of LLMs is that supervised learning at unprecedented scale is what ultimately leads to the emergent properties we observe. Since we don\u2019t yet have a supply of robot control data nearly as plentiful as all the text and image data on the Internet, the IFL paradigm offers one path forward for scaling up supervised robot learning and deploying robot fleets reliably in today\u2019s world.</p>\n\n<p><em>This post is based on the paper \u201cFleet-DAgger: Interactive Robot Fleet Learning with Scalable Human Supervision\u201d by Ryan Hoque, Lawrence Chen, Satvik Sharma, Karthik Dharmarajan, Brijen Thananjeyan, Pieter Abbeel, and Ken Goldberg, presented at the Conference on Robot Learning (CoRL) 2022. For more details, see the <a href=\"https://arxiv.org/abs/2206.14349\">paper</a> on arXiv, <a href=\"https://www.youtube.com/watch?v=USr_iICRgvk\">CoRL presentation video</a> on YouTube, open-source <a href=\"https://github.com/BerkeleyAutomation/ifl_benchmark\">codebase</a> on Github, <a href=\"https://twitter.com/ryan_hoque/status/1542932195949432832?s=20\">high-level summary</a> on Twitter, and <a href=\"https://sites.google.com/berkeley.edu/fleet-dagger/home\">project website</a>.</em></p>\n\n<p><em>If you would like to cite this article, please use the following bibtex:</em></p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>@article{ifl_blog,\n    title={Interactive Fleet Learning},\n    author={Hoque, Ryan},\n    url={https://bair.berkeley.edu/blog/2023/04/06/ifl/},\n    journal={Berkeley Artificial Intelligence Research Blog},\n    year={2023} \n}\n</code></pre></div></div>",
            "pubdate": "Thu, 06 Apr 2023 02:00:00 -0700",
            "pubdate_parsed": [
                2023,
                4,
                6
            ],
            "email_sent": true
        },
        "On the Stepwise Nature of <br> Self-Supervised Learning": {
            "url": "http://bair.berkeley.edu/blog/2023/07/10/stepwise-ssl/",
            "description": "<!-- twitter -->\n\n\n\n\n\n\n\n\n\n\n\n\n<p style=\"text-align: center;\">\n<video loop=\"\" style=\"display: block; margin: 0 auto;\" width=\"100%\">\n    <source src=\"https://bair.berkeley.edu/static/blog/stepwise-ssl/ssl_blogpost_fig1.mp4\" type=\"video/mp4\" />\n</video>\n</p>\n<p><small>\n<i><b>Figure 1: stepwise behavior in self-supervised learning.</b> When training common SSL algorithms, we find that the loss descends in a stepwise fashion (top left) and the learned embeddings iteratively increase in dimensionality (bottom left). Direct visualization of embeddings (right; top three PCA directions shown) confirms that embeddings are initially collapsed to a point, which then expands to a 1D manifold, a 2D manifold, and beyond concurrently with steps in the loss.</i>\n</small></p>\n\n<p>It is widely believed that deep learning\u2019s stunning success is due in part to its ability to discover and extract useful representations of complex data. Self-supervised learning (SSL) has emerged as a leading framework for learning these representations for images directly from unlabeled data, similar to how LLMs learn representations for language directly from web-scraped text.  Yet despite SSL\u2019s key role in state-of-the-art models such as <a href=\"https://openai.com/research/clip\">CLIP</a> and <a href=\"https://www.midjourney.com/home/?callbackUrl=%2Fapp%2F\">MidJourney</a>, fundamental questions like \u201cwhat are self-supervised image systems really learning?\u201d and \u201chow does that learning actually occur?\u201d lack basic answers.</p>\n\n<p>Our <a href=\"https://arxiv.org/abs/2303.15438\">recent paper</a> (to appear at ICML 2023) presents what we suggest is <strong>the first compelling mathematical picture of the training process of large-scale SSL methods.</strong> Our simplified theoretical model, which we solve exactly, learns aspects of the data in a series of discrete, well-separated steps. We then demonstrate that this behavior can be observed in the wild across many current state-of-the-art systems.\nThis discovery opens new avenues for improving SSL methods, and enables a whole range of new scientific questions that, when answered, will provide a powerful lens for understanding some of today\u2019s most important deep learning systems.</p>\n\n<!--more-->\n\n<h3 id=\"background\">Background</h3>\n\n<p>We focus here on joint-embedding SSL methods \u2014 a superset of contrastive methods \u2014 which learn representations that obey view-invariance criteria. The loss function of these models includes a term enforcing matching embeddings for semantically equivalent \u201cviews\u201d of an image. Remarkably, this simple approach yields powerful representations on image tasks even when views are as simple as random crops and color perturbations.</p>\n\n<h3 id=\"theory-stepwise-learning-in-ssl-with-linearized-models\">Theory: stepwise learning in SSL with linearized models</h3>\n\n<p>We first describe an exactly solvable linear model of SSL in which both the training trajectories and final embeddings can be written in closed form. Notably, we find that representation learning separates into a series of discrete steps: the rank of the embeddings starts small and iteratively increases in a stepwise learning process.</p>\n\n<p>The main theoretical contribution of our paper is to exactly solve the training dynamics of the <a href=\"https://arxiv.org/abs/2103.03230\">Barlow Twins</a> loss function under gradient flow for the special case of a linear model \\(\\mathbf{f}(\\mathbf{x}) = \\mathbf{W} \\mathbf{x}\\). To sketch our findings here, we find that, when initialization is small, the model learns representations composed precisely of the top-\\(d\\) eigendirections of the <em>featurewise</em> cross-correlation matrix \\(\\boldsymbol{\\Gamma} \\equiv \\mathbb{E}_{\\mathbf{x},\\mathbf{x}\u2019} [ \\mathbf{x} \\mathbf{x}\u2019^T ]\\). What\u2019s more, we find that these eigendirections are learned <strong>one at a time</strong> in a sequence of discrete learning steps at times determined by their corresponding eigenvalues. Figure 2 illustrates this learning process, showing both the growth of a new direction in the represented function and the resulting drop in the loss at each learning step. As an extra bonus, we find a closed-form equation for the final embeddings learned by the model at convergence.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/stepwise-ssl/ssl_blogpost_fig2.png\" width=\"60%\" />\n</p>\n<p><small>\n<i><b>Figure 2: stepwise learning appears in a linear model of SSL.</b> We train a linear model with the Barlow Twins loss on a small sample of CIFAR-10. The loss (top) descends in a staircase fashion, with step times well-predicted by our theory (dashed lines). The embedding eigenvalues (bottom) spring up one at a time, closely matching theory (dashed curves). </i>\n</small></p>\n\n<p>Our finding of stepwise learning is a manifestation of the broader concept of <em>spectral bias</em>, which is the observation that many learning systems with approximately linear dynamics preferentially learn eigendirections with higher eigenvalue. This has recently been well-studied in the case of standard supervised learning, where it\u2019s been found that higher-eigenvalue eigenmodes are learned faster during training. Our work finds the analogous results for SSL.</p>\n\n<p>The reason a linear model merits careful study is that, as shown via the \u201cneural tangent kernel\u201d (<a href=\"https://arxiv.org/abs/1806.07572\">NTK</a>) line of work, sufficiently wide neural networks also have linear parameterwise dynamics. This fact is sufficient to extend our solution for a linear model to wide neural nets (or in fact to arbitrary kernel machines), in which case the model preferentially learns the top \\(d\\) eigendirections of a particular operator related to the NTK. The study of the NTK has yielded many insights into the training and generalization of even nonlinear neural networks, which is a clue that perhaps some of the insights we\u2019ve gleaned might transfer to realistic cases.</p>\n\n<h3 id=\"experiment-stepwise-learning-in-ssl-with-resnets\">Experiment: stepwise learning in SSL with ResNets</h3>\n\n<p>As our main experiments, we train several leading SSL methods with full-scale ResNet-50 encoders and find that, remarkably, we clearly see this stepwise learning pattern even in realistic settings, suggesting that this behavior is central to the learning behavior of SSL.</p>\n\n<p>To see stepwise learning with ResNets in realistic setups, all we have to do is run the algorithm and track the eigenvalues of the embedding covariance matrix over time. In practice, it helps highlight the stepwise behavior to also train from smaller-than-normal parameter-wise initialization and train with a small learning rate, so we\u2019ll use these modifications in the experiments we talk about here and discuss the standard case in our paper.</p>\n\n<p style=\"text-align: center;\">\n<img src=\"https://bair.berkeley.edu/static/blog/stepwise-ssl/ssl_blogpost_fig3.png\" width=\"100%\" />\n</p>\n<p><small>\n<i><b>Figure 3: stepwise learning is apparent in Barlow Twins, SimCLR, and VICReg.</b> The loss and embeddings of all three methods display stepwise learning, with embeddings iteratively increasing in rank as predicted by our model. </i>\n</small></p>\n\n<p>Figure 3 shows losses and embedding covariance eigenvalues for three SSL methods \u2014 Barlow Twins, SimCLR, and VICReg \u2014 trained on the STL-10 dataset with standard augmentations. Remarkably, <strong>all three show very clear stepwise learning,</strong> with loss decreasing in a staircase curve and one new eigenvalue springing up from zero at each subsequent step. We also show an animated zoom-in on the early steps of Barlow Twins in Figure 1.</p>\n\n<p>It\u2019s worth noting that, while these three methods are rather different at first glance, it\u2019s been suspected in folklore for some time that they\u2019re doing something similar under the hood. In particular, these and other joint-embedding SSL methods all achieve similar performance on benchmark tasks. The challenge, then, is to identify the shared behavior underlying these varied methods. Much prior theoretical work has focused on analytical similarities in their loss functions, but our experiments suggest a different unifying principle: <strong>SSL methods all learn embeddings one dimension at a time, iteratively adding new dimensions in order of salience.</strong></p>\n\n<p>In a last incipient but promising experiment, we compare the real embeddings learned by these methods with theoretical predictions computed from the NTK after training. We not only find good agreement between theory and experiment within each method, but we also compare across methods and find that different methods learn similar embeddings, adding extra support to the notion that these methods are ultimately doing similar things and can be unified.</p>\n\n<h3 id=\"why-it-matters\">Why it matters</h3>\n\n<p>Our work paints a basic theoretical picture of the process by which SSL methods assemble learned representations over the course of training. Now that we have a theory, what can we do with it? We see promise for this picture to both aid the practice of SSL from an engineering standpoint and to enable better understanding of SSL and potentially representation learning more broadly.</p>\n\n<p>On the practical side, SSL models are famously slow to train compared to supervised training, and the reason for this difference isn\u2019t known. Our picture of training suggests that SSL training takes a long time to converge because the later eigenmodes have long time constants and take a long time to grow significantly. If that picture\u2019s right, speeding up training would be as simple as selectively focusing gradient on small embedding eigendirections in an attempt to pull them up to the level of the others, which can be done in principle with just a simple modification to the loss function or the optimizer. We discuss these possibilities in more detail in our paper.</p>\n\n<p>On the scientific side, the framework of SSL as an iterative process permits one to ask many questions about the individual eigenmodes. Are the ones learned first more useful than the ones learned later? How do different augmentations change the learned modes, and does this depend on the specific SSL method used? Can we assign semantic content to any (subset of) eigenmodes? (For example, we\u2019ve noticed that the first few modes learned sometimes represent highly interpretable functions like an image\u2019s average hue and saturation.) If other forms of representation learning converge to similar representations \u2014 a fact which is easily testable \u2014 then answers to these questions may have implications extending to deep learning more broadly.</p>\n\n<p>All considered, we\u2019re optimistic about the prospects of future work in the area. Deep learning remains a grand theoretical mystery, but we believe our findings here give a useful foothold for future studies into the learning behavior of deep networks.</p>\n\n<hr />\n\n<p><em>This post is based on the paper <a href=\"https://arxiv.org/abs/2110.03922\">\u201cOn the Stepwise Nature of Self-Supervised Learning\u201d</a>, which is joint work with Maksis Knutins, Liu Ziyin, Daniel Geisz, and Joshua Albrecht. This work was conducted with <a href=\"https://generallyintelligent.com/\">Generally Intelligent</a> where Jamie Simon is a Research Fellow. This blogpost is cross-posted <a href=\"https://generallyintelligent.com/research/ssl_stepwise/\">here</a>. We\u2019d be delighted to field your questions or comments.</em></p>",
            "pubdate": "Mon, 10 Jul 2023 02:00:00 -0700",
            "pubdate_parsed": [
                2023,
                7,
                10
            ],
            "email_sent": true
        }
    },
    "Google AI Blog": {
        "The Check Up: our latest health AI developments": {
            "url": "https://blog.google/technology/health/check-up-ai-developments-2022/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Over the years, teams across Google have focused on how technology \u2014 specifically artificial intelligence and hardware innovations \u2014 can improve access to high-quality, equitable healthcare across the globe.</p><p>Accessing the right healthcare can be challenging depending on where people live and whether local caregivers have specialized equipment or training for tasks like disease screening. To help, Google Health has expanded its research and applications to focus on improving the care clinicians provide and allow care to happen outside hospitals and doctor\u2019s offices.</p><p>Today, at our Google Health event <a href=\"https://www.youtube.com/watch?v=2XQZQR477fg\">The Check Up</a>, we\u2019re sharing new areas of AI-related research and development and how we\u2019re providing clinicians with easy-to-use tools to help them better care for patients. Here\u2019s a look at some of those updates.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Smartphone cameras\u2019 potential to protect cardiovascular health and preserve eyesight</h3><p>One of our earliest Health AI projects, <a href=\"https://health.google/caregivers/arda/\">ARDA</a>, aims to help address screenings for diabetic retinopathy \u2014 a complication of diabetes that, if undiagnosed and untreated, can cause blindness.</p><p>Today, we screen 350 patients daily, resulting in close to 100,000 patients screened to date. We <a href=\"https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00017-6/fulltext\">recently completed a prospective study</a> with the Thailand national screening program that further shows ARDA is accurate and capable of being deployed safely across multiple regions to support more accessible eye screenings.</p><p>In addition to diabetic eye disease, we\u2019ve previously also shown how <a href=\"https://ai.googleblog.com/2018/02/assessing-cardiovascular-risk-factors.html\">photos of eyes\u2019 interiors (or fundus) can reveal cardiovascular risk factors</a>, such as high blood sugar and cholesterol levels, with assistance from deep learning. <a href=\"http://ai.googleblog.com/2022/03/detecting-signs-of-disease-from.html\">Our recent research</a> tackles detecting diabetes-related diseases from photos of the exterior of the eye, using existing tabletop cameras in clinics. Given the <a href=\"https://arxiv.org/abs/2011.11732\">early promising results</a>, we\u2019re looking forward to clinical research with partners, including EyePACS and Chang Gung Memorial Hospital (CGMH), to investigate if photos from smartphone cameras can help detect diabetes and non-diabetes diseases from external eye photos as well. While this is in the early stages of research and development, our engineers and scientists envision a future where people, with the help of their doctors, can better understand and make decisions about health conditions from their own homes.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Recording and translating heart sounds with smartphones</h3><p>We\u2019ve previously shared how mobile sensors combined with machine learning can democratize health metrics and <a href=\"https://blog.google/technology/health/take-pulse-health-and-wellness-your-phone/\">give people insights into daily health and wellness</a>. Our feature that allows you to measure your heart rate and respiratory rate with your phone\u2019s camera is now available on over 100 models of Android devices, as well as iOS devices. Our <a href=\"https://www.medrxiv.org/content/10.1101/2021.03.08.21252408v1\">manuscript</a> describing the prospective validation study has been accepted for publication.</p><p>Today, we\u2019re sharing a new area of research that explores how a smartphone\u2019s built-in microphones could record heart sounds when placed over the chest. Listening to someone\u2019s heart and lungs with a stethoscope, known as auscultation, is a critical part of a physical exam. It can help clinicians detect heart valve disorders, such as aortic stenosis which is important to detect early. Screening for aortic stenosis typically requires specialized equipment, like a stethoscope or an ultrasound, and an in-person assessment.</p><p>Our latest research investigates whether a smartphone can detect heartbeats and murmurs. We're currently in the early stages of clinical study testing, but we hope that our work can empower people to use the smartphone as an additional tool for accessible health evaluation.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Partnering with Northwestern Medicine to apply AI to improve maternal health</h3><p>Ultrasound is a noninvasive diagnostic imaging method that uses high-frequency sound waves to create real-time pictures or videos of internal organs or other tissues, such as blood vessels and fetuses.</p><p>Research shows that ultrasound is safe for use in prenatal care and effective in identifying issues early in pregnancy. However, <a href=\"https://www.who.int/reproductivehealth/publications/maternal-mortality-2000-2017/en/\">more than half</a> of all birthing parents in low-to-middle-income countries don\u2019t receive ultrasounds, in part due to a shortage of expertise in reading ultrasounds. We believe that Google\u2019s expertise in machine learning can help solve this and allow for healthier pregnancies and better outcomes for parents and babies.</p><p>We are working on foundational, open-access <a href=\"https://arxiv.org/abs/2203.10139\">research</a> <a href=\"https://arxiv.org/abs/2203.11903\">studies</a> that validate the use of AI to help providers conduct ultrasounds and perform assessments. We\u2019re excited to partner with Northwestern Medicine to further develop and test these models to be more generalizable across different levels of experience and technologies. With more automated and accurate evaluations of maternal and fetal health risks, we hope to lower barriers and help people get timely care in the right settings.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To learn more about the health efforts we shared at <a href=\"https://health.google/\">The Check Up with Google Health</a>, check out <a href=\"https://blog.google/technology/health/check-up-consumer-developments-2022/\">this blog post</a> from our Chief Health Officer Dr. Karen DeSalvo. And stay tuned for more health-related research milestones from us.</p></div></div>",
            "pubdate": "Thu, 24 Mar 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                24
            ],
            "email_sent": true
        },
        "Lift as you lead: Meet 2 women defining responsible AI": {
            "url": "https://blog.google/technology/ai/lift-as-you-lead-meet-2-women-defining-responsible-ai/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>At Google, <a href=\"https://blog.google/technology/ai/marian-croak-inventors-hall-fame/\">Marian Croak</a>\u2019s technical research team, The Center for Responsible AI and Human-Centered Technology, and Jen Gennai\u2019s operations and governance team, Responsible Innovation, collaborate often on creating a fairer future for AI systems.</p><p>The teams complement each other to support computer scientists, UX researchers and designers, product managers and subject matter experts in the social sciences, human rights and civil rights. Collectively, their teams include more than 200 people around the globe focused on putting our <a href=\"http://ai.google/principles\">AI Principles</a> \u2013 Google\u2019s ethical charter \u2013 into practice.</p><p>\u201cThe intersection of AI systems and society is a critical area of my team\u2019s technical research,\u201d Marian says. \u201cOur approach includes working directly with people who use and are impacted by AI systems. Working together with Jen\u2019s central operations team, the idea is to make AI more useful and reduce potential harm before products launch.\u201d</p><p>For Women\u2019s History Month, we wanted to talk to them both about this incredibly meaningful work and how they bring their lived experiences to it.</p><p><b>How do you define \u201cresponsible AI\u201d?</b></p><p><b>Marian:</b> It\u2019s the <i>technical</i> realization of our <a href=\"http://ai.google/principles\">AI Principles</a>. We need to understand how AI systems are performing in respect to fairness, transparency, interpretability, robustness and privacy. When gaps occur, we fix them. We benchmark and evaluate how product teams are adopting what Jen and I call smart practices. These are trusted practices based on patterns we see across Google as we\u2019re developing new AI applications, and the data-driven results of applying these practices over time.</p><p><b>Jen:</b> There are enormous opportunities to use AI for positive impact \u2014 and the potential for harm, too. The key is ethical deployment. \u201cResponsible AI\u201d for me means taking deliberate steps to ensure technology works the way it\u2019s intended to and doesn\u2019t lead to malicious or unintended negative consequences. This involves applying the smart practices Marian mentioned through repeatable processes and a governance structure for accountability.</p><p><b>How do your teams work together?</b></p><p><b>Marian</b>: They work hand in hand. My team conducts scientific research and creates open source tools like <a href=\"https://www.tensorflow.org/responsible_ai/fairness_indicators/guide\">Fairness Indicators</a> and <a href=\"https://knowyourdata.withgoogle.com/\">Know Your Data</a>. A large portion of our technical research and product work is centered in societal context and human and civil rights, so Jen\u2019s team is integral to understanding the problems we seek to help solve.</p><p><b>Jen:</b> The team I lead defines Google policies, handles day-to-day operations and central governance structure, and conducts ethical assessments. We\u2019re made up of user researchers, social scientists, ethicists, human rights specialists, policy and privacy advisors and legal experts.</p><p>One team can\u2019t work without the other! This complementary relationship allows many different perspectives and lived experiences to inform product design decisions. Here\u2019s an example, which was led by women from a variety of global backgrounds: Marian\u2019s team designed a streamlined, open source format for documenting technical details of datasets, called <a href=\"https://datacentricai.org/neurips21/papers/112_CameraReady_Data_Cards.pdf\">data cards</a>. When researchers on the <a href=\"https://translate.google.com/\">Translate</a> team, led by product manager Romina Stella, recently developed a <a href=\"https://ai.googleblog.com/2021/06/a-dataset-for-studying-gender-bias-in.html\">new dataset</a> for studying and preventing gender bias in machine learning, members of my team, Anne P., N\u2019Mah Y. and Reena Jana, reviewed the dataset for alignment with the AI Principles. They recommended that the Translate researchers publish a data card for details on how the dataset was created and tested. The Translate team then worked with UX designer Mahima Pushkarna on Marian\u2019s team to create and launch the <a href=\"https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Data%20Card.pdf\">card</a> alongside the <a href=\"https://storage.googleapis.com/gresearch/translate-gender-challenge-sets/Readme.html\">dataset</a>.</p></div></div><div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\"><section class=\"h-c-grid\"><div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"><div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"><q class=\"uni-pull-quote__text\">I\u2019m inspired most when someone tells me I can\u2019t do something. No matter what obstacles you face, believe you have the skills, the knowledge and the passion to make your dreams come true.</q></div></div></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How did you end up working in this very new field?</b></p><p><b>Marian</b><i>:</i> I\u2019ve always been drawn to hard problems. This is a very challenging area! It\u2019s so multifaceted and constantly evolving. That excites me. It\u2019s an honor to work with so many passionate people who care so deeply about our world and understanding how to use technology for social good.</p><p>I\u2019ll always continue to seek out solutions to these problems because I understand the profound impact this work will have on our society and our world, especially communities underrepresented in the tech industry.</p><p><b>Jen:</b> I spent many years leading User Research and User Advocacy on Google\u2019s Trust and Safety team. An area I focused on was ML Fairness. I never thought I\u2019d get to work on it full time. But in 2016 my leadership team wanted to have a company-wide group concentrating on worldwide positive social benefits of AI. In 2017, I joined the team that was writing and publishing the AI Principles. Today, I apply my operational knowledge to make sure that as a company, we meet the obligations we laid out in the Principles.</p><p><b>What advice do you have for girls and women interested in pursuing careers in responsible tech?</b></p><p><b>Marian</b>: I\u2019m inspired most when someone tells me I <i>can\u2019t</i> do something. No matter what obstacles you face, believe you have the skills, the knowledge and the passion to make your dreams come true. Find motivation in the small moments, find motivation in those who <i>doubt</i> you, but most importantly, never forget to believe in the greatness of you.</p><p><b>Jen:</b> Don\u2019t limit yourself even if you don\u2019t have a computer science degree. I don\u2019t. I was convinced I\u2019d work in sustainability and environmental non-profits, and now I lead a team working to make advanced technologies work better for everyone. This space requires so many different skills, whether in program management, policy, engineering, UX or business and strategy.</p><p>My mantra is \u201clift as you lead.\u201d Don\u2019t just build a network for yourself; build a supportive network to empower everyone who works with you \u2014 and those who come after you, especially those who are currently underrepresented in the tech sector. Your collective presence in this space makes a positive impact! And it\u2019s even stronger when you build a better future together.</p></div></div>",
            "pubdate": "Tue, 29 Mar 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                29
            ],
            "email_sent": true
        },
        "Go with the flow state: What music and AI have in common": {
            "url": "https://blog.google/technology/ai/go-flow-state-what-music-and-ai-have-common/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Carrie Cai, Ben Zevenbergen and Johnny Soraker all work on developing artificial intelligence (AI) responsibly at Google, in the larger research community and across the technology industry. Carrie is a research scientist focusing on human-AI interaction, Ben is an ethicist and policy advisor and Johnny is an <a href=\"https://ai.google/principles/\">AI Principles</a> ethicist. They all work within a global team of experts from a variety of fields, including the social sciences and humanities, focused on the ethical development of AI. They\u2019re driven to make systems that are fair, inclusive and focused on people.</p><p>But they have more than their work in common: They\u2019re all accomplished musicians who\u2019ve studied music, composed and published pieces and even played at the professional level. We wanted to know more about their musical backgrounds, and how this creative interest informs their work building AI systems that take everyone into account.</p><p><b>What instrument \u2014 or instruments \u2014 do you play?</b></p><p><b>Ben:</b> Guitar, bass and drums.</p><p><b>Johnny:</b> Mainly drums these days, but I\u2019ve also done ambient and electronica.</p><p><b>Carrie:</b> I play piano and I also compose music.</p><p><b>Where did your interest in playing music come from?</b></p><p><b>Ben:</b> I grew up in a musical family where instruments were always lying around. My parents\u2019 friends would bring their instruments when they came to visit and our house would turn into a music venue. I enrolled in a music degree in my late teens to become a professional drummer. Then, a year later, I serendipitously became a bassist: I went to law school in the Netherlands, and the university band already had someone who was a better drummer than I was \u2014 but they needed a bassist, so I grabbed the opportunity.</p><p><b>Carrie:</b> I started out in the Yamaha music program when I was six, where rather than learning technical piano playing skills you focus on ear training, hearing the music and how to play as an ensemble. I think that foundation led me to be a lot more creative with my music than I would have been otherwise. I spent part of my childhood years composing music, too \u2014 here are <a href=\"https://people.csail.mit.edu/ccai/media/September.mp3\">some of</a> <a href=\"https://people.csail.mit.edu/ccai/media/SilverMountain.m4a\">my early</a> <a href=\"https://people.csail.mit.edu/ccai/media/WindHarmony.mp3\">compositions</a> from my high school days!</p><p><b>Johnny:</b> I\u2019ve played lots of instruments since I was a child, but never had the tenacity to get very good at any of them. Perhaps as a result of this, I got involved with a highly experimental ambient scene in the early 2000s and started the <a href=\"http://metusmortuus.bandcamp.com/\">one-man project Metus Mortuus</a>, using samples and DIY equipment to create often disturbing soundscapes. It was really only when I got hooked on the video game \u201cRock Band,\u201d where you play \"fake\" instruments along with the notation on screen, that I put in the hours needed to get some basic limb independence and with that a platform for learning real drums.</p></div></div><div class=\"block-image_carousel\"><div class=\"h-c-page article-module\"><div class=\"article-module glue-pagination h-c-carousel h-c-carousel--simple h-c-carousel--dark ng-cloak\"><div class=\"h-c-carousel__wrap\"><ul class=\"glue-carousel ng-cloak\"><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">Carrie stands in front of a group of people speaking while holding a microphone. A presentation behind her reads: \u201cNeural substrates of Musical Creativity.\u201d</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Carrie speaking at a conference about musical creativity and brain science.</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">Ben performing on stage. He is playing a bass and wearing a red and white track suit.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Ben playing the bass during a concert in Amsterdam.</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">Johnny speaking on stage to an audience in a dimly lit room.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Johnny speaking at <a href=\"https://www.youtube.com/watch?v=unVzwxmyeqs\">a TedX talk</a>.</p></div></figcaption></figure></li></ul><div class=\"h-c-carousel__paginate glue-pagination-previous uni-click-tracker\"><div class=\"h-c-carousel__paginate-wrap\"><svg class=\"h-c-icon h-c-icon--keyboard-arrow-left\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-keyboard-arrow-right\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></div></div><div class=\"h-c-carousel__paginate glue-pagination-next uni-click-tracker\"><div class=\"h-c-carousel__paginate-wrap\"><svg class=\"h-c-icon h-c-icon--keyboard-arrow-right\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-keyboard-arrow-right\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></div></div></div><div class=\"h-c-carousel__navigation\"><div class=\"glue-pagination-page-list uni-click-tracker\"></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>Did you gravitate toward the drums in the game?</b></p><p><b>Johnny:</b> No, I hardly ever touched them \u2014 I simply couldn\u2019t make my left arm do something my right arm wasn't doing, but one day I decided to try an experiment: Can I make these stale neural pathways of mine actually learn something new well into adulthood? I started practicing on these toy drums every day, which was painful and frustrating, but occasional breakthroughs kept me going. Eventually I achieved a level of limb independence I hadn't thought I was capable of. I invested in proper e-drums and I\u2019ve played almost every day since.</p></div></div><div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\"><section class=\"h-c-grid\"><div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"><div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"><q class=\"uni-pull-quote__text\">This [work] often requires you to think creatively. And I feel that the way in which drumming almost literally rewired my brain has made me much better at doing that.</q></div></div></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>What\u2019s your favorite thing about playing?</b></p><p><b>Johnny:</b> It's really the ultimate flow experience, where you're fully immersed in an activity to the extent you lose track of time and only focus on the present moment. <a href=\"https://en.wikipedia.org/wiki/Flow_(psychology)\">There\u2019s lots of empirical research</a> in the field of positive psychology suggesting that regular flow experiences promote better well-being.</p><p><b>Ben:</b> I love playing the bass with a band because it\u2019s the glue between the rhythm section and the melody sections. It\u2019s fun when you purposefully come in a beat later, you really see people not sure whether to dance or not. When you start playing, suddenly the whole audience understands what\u2019s going on. And then they have the audacity to say they never hear the bass!</p><p><b>How has music made its way into your work, if at all?</b></p><p><b>Carrie:</b> It\u2019s certainly affected how I think about my work today, particularly around how to make AI more <i>controllable</i> to everyday people. For example, we\u2019re now seeing these new, highly capable generative AI models that can compose music sounding indistinguishable from something written by Bach. But we discovered that, just because an AI model is capable of making beautiful music, doesn\u2019t mean humans can always make beautiful music using AI.</p><p>When I create music, I\u2019m thinking, \u201cI want the beginning of the song to sound cheerful, then I want it to build tension, before ending in a somber way.\u201d When I\u2019m creating with AI, it can be difficult to express that \u2014 I can\u2019t easily say, \u201cHey AI, make the first part happy and then build tension here\u201d This can make it difficult for people to feel a sense of artistic agency and authorship when they\u2019re creating any kind of content with AI.</p><p>Recently, I collaborated with other human-computer interaction (HCI) and machine learning (ML) researchers at Google to <a href=\"https://magenta-staging.tensorflow.org/people-first-hci-ml-collaborations\">create new tools</a> enabling people to steer and control AI as they compose music with it. We found that these \u201csteering tools\u201d significantly boost users\u2019 sense of creative ownership and trust as they compose with AI.</p></div></div><div class=\"block-video\"><div class=\"h-c-page h-c-page--mobile-full-bleed\"><div class=\"h-c-grid\"><div class=\"h-c-grid__col h-c-grid__col-l--10 h-c-grid__col-l--offset-1\"><div class=\"article-module uni-article-video uni-article-video--body\"><div class=\"uni-article-video__embed-container hidden\"><div id=\"uni-article-yt-player-ls_CCMbMyLU\"></div></div><figure><a class=\"h-c-video h-c-video--marquee uni-article-video__custom-wrapper\" tabindex=\"0\"><div class=\"uni-article-video__aspect-image\"><img alt=\"A video demonstration of composing music with AI.\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Screenshot_2022-03-28_5.43.44_PM.max-1000x1000.png\" /><div class=\"uni-article-video__dimmer\"></div><svg class=\"uni-article-video__play-button--active\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button_no_hole\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><svg class=\"uni-article-video__play-button\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><div class=\"uni-article-video__duration loading\"><svg class=\"uni-article-video__duration-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_duration\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><span class=\"uni-article-video__duration-time\">10:25</span></div></div></a></figure></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>Do you think there\u2019s anything about the sort of work you do that exercises the same sort of \u201cmental muscles\u201d as music does?</b></p><p><b>Johnny:</b> Yes, I think the key to ethics \u2014 and especially ethics of AI where there often is no precedent \u2014 is to be able to approach a problem from different angles and draw connections between the case at hand and relevant, similar cases from the past. This requires you to think creatively. And I feel that the way in which drumming almost literally rewired my brain has made me much better at doing that.</p><p><b>Ben:</b> When you learn to play the drums, one of the hardest things is learning you must separate the movements of your limbs in your mind. It's pretty difficult to process \u2014 which makes it a very nice experience once your mind can asynchronously control parts of your thinking to create interesting rhythms that are still in time. I think for my work on ethics of technical design, I have to frequently understand many interacting but very different disciplines. I'm not sure if it has anything to do with drumming, but I find that I can think about these things in tandem, while they are completely different.</p></div></div><div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\"><section class=\"h-c-grid\"><div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"><div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"><q class=\"uni-pull-quote__text\">Once when I was little, I woke up and without even changing out of my pajamas, spent the entire day composing a piece of music.</q></div></div></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>Carrie:</b> I remember once when I was little, I woke up and without even changing out of my pajamas, spent the entire day composing a piece of music. I realize now that <i>that</i> was a flow state \u2014 I was working on something that was challenging yet doable. I think that\u2019s a key property of creativity and it\u2019s affected how I work in general. It's easiest for me to be productive when I'm in that state \u2014 working on something that\u2019s challenging, but not so difficult that I won't want to start it or keep going. That\u2019s helpful in research because there\u2019s so much uncertainty \u2014 you never know if your experiments are going to work! But I can take a lesson from how I got into that flow state with music and apply it to research: How can I as a research scientist enter a flow state?</p></div></div>",
            "pubdate": "Tue, 29 Mar 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                29
            ],
            "email_sent": true
        },
        "How AI and imagery build a self-updating map": {
            "url": "https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Building a map is complex, and keeping it up-to-date is even more challenging. Think about how often your city, town or neighborhood changes on a day-to-day basis. Businesses and shops open and close, stretches of highway are added, and roadways change. In today\u2019s Maps 101 installment, we\u2019ll dive into two ways Google Maps uses advancements in AI and imagery to help you see the latest information about the world around you every single day.</p><p><b>Automatically updating business hours</b></p><p>Over the past few years, businesses have experienced <i>a lot</i> of change \u2014 including constantly updating operating hours based on changing pandemic-related restrictions. To keep up with this pace of change, we developed a machine learning model that automatically identifies if business hours are likely wrong, then instantly updates them with AI-generated predictions.</p><p>Let\u2019s look at Liam\u2019s Lemonade Shop as an example. To start, our systems consider multiple factors \u2014 such as when Liam last updated their business profile, what we know about other shops' hours, and the <a href=\"https://blog.google/products/maps/maps101-popular-times-and-live-busyness-information/\">Popular Times information</a> for the shop, which uses location trends to show when it tends to be busiest. Since it appears that Liam\u2019s business profile hasn\u2019t been updated in over a year and its busiest hours are typically Thursday afternoons \u2014 even though Google Maps says that it's closed at that time \u2014 Liam\u2019s business hours are likely out of date.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Still images of a business' hours and Popular Times information on Google Maps\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Frame_515_2.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>To see if business hours need updating, we check a store\u2019s Popular Times information and when its business profile was last updated.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>So what\u2019s next? Our algorithms analyze the business hours of other nearby lemonade shops, information from Liam\u2019s website, and Street View images of Liam\u2019s storefront that look specifically for business hour signs to determine the most accurate business hour prediction. At the same time, we enlist the help of the Google Maps community \u2014 including Local Guides and even the business owners themselves through their <a href=\"https://www.google.com/business/\">Google Business Profile</a> \u2014 to verify the information we predicted. In Argentina, Australia, Chile, France, Japan, Mexico, New Zealand, Peru, and the United States, we also use <a href=\"https://ai.googleblog.com/2018/05/duplex-ai-system-for-natural-conversation.html\">Duplex conversational technology</a> to call businesses just like Liam\u2019s and ask for their hours directly. With this new AI-first approach, we\u2019re on track to update the hours for over 20 million businesses around the globe in the next six months - helping you know exactly when your favorite store, restaurant or cafe is open for business .</p><p><b>Road information that reflects the real world</b></p><p>We\u2019re also experimenting with ways we can use imagery to make updates to other helpful information. For instance, starting in the U.S., we\u2019re launching a third-party imagery pilot to let you see the most up-to-date speed limit information in your town, which can help keep you safe while driving. Here\u2019s how it works:</p><p>Say our systems think that the speed limit information on a particular highway needs to be updated. With the help of third-party imagery partners that already gather roadway imagery to improve delivery routes, we can request a photo of the specific stretch of road that also includes a speed limit sign. If the partner has this photo available, we then use a combination of AI and help from our operations team to identify the sign in the image, extract the new speed limit information, and update Google Maps.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Picture of an intersection that has a speed limit sign\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/AI__Street_Signs.max-1000x1000.png\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Representative imagery featuring a speed limit sign, with license plates blurred</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Over time, this technology will bring more details to the map that can help make your drives safer and more efficient \u2014 like where potholes and school zones are or where new construction is happening. And as with all Google Maps features, we designed this pilot with privacy top of mind. For instance, we only reference images taken on public roads, and partners are required to blur information (like faces and license plates) to avoid potentially identifying someone. For an extra layer of privacy, we blur the photo again when we receive it and delete the photo after we use it to update the map.</p><p>AI, imagery and Duplex technology will continue to play a critical role in helping make Google Maps the most comprehensive and useful map possible. For more behind-the-scenes looks at the technology that powers Google Maps, check out the rest of our <a href=\"https://blog.google/products/maps/maps-101/\">Maps 101 blog series.</a></p></div></div>",
            "pubdate": "Thu, 07 Apr 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                4,
                7
            ],
            "email_sent": true
        },
        "Investing in Eastern Europes AI future": {
            "url": "https://blog.google/technology/ai/investing-in-eastern-europes-ai-future/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>It was an honor and a privilege to attend a special event in the Bulgarian capital, Sofia, today to launch <a href=\"https://insait.ai/\">INSAIT</a>, the Institute for Computer Science, Artificial Intelligence and Technology. INSAIT is a new AI and computer science research institute that will provide truly world-class facilities.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s fantastic to see the country where I was born leading the charge in bridging Eastern Europe to the world-stage in computer science research.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>The institute is modeled on the computer science departments of renowned institutions such as MIT, UC Berkeley and the <a href=\"https://www.mpg.de/en\">Max-Planck Institute</a>, and is backed by the Bulgarian government with an endowment fund of nearly $100 million. Its computer science and AI research will span topics such as machine learning, quantum computing, information security, robotics and many more. Within two years, INSAIT expects faculty and students to publish papers in top conferences.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Google is investing $3 million over the next three years to provide INSAIT with cloud computing resources and access to its<a href=\"https://sites.research.google/trc/about/\">Tensor Processing Unit Research Cloud</a>, a specialized infrastructure for running high-performance machine learning models. Supported with additional investment from DeepMind and Amazon Web Services, INSAIT aims to attract and develop the best researchers, engineers and top PhD and MSc students.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>I know there\u2019s no shortage of talented researchers, computer scientists and engineers in Eastern Europe \u2013 indeed, Sofia is already ranked as<a href=\"https://www.fdiintelligence.com/article/77846\">one of Europe\u2019s top tech cities</a> \u2013 but historically, the lack of local facilities, funding and support has meant limited opportunities for basic research. INSAIT has been created in partnership with two of the world\u2019s leading technology universities, ETH Zurich and EPFL Lausanne, and its supervisory and advisory boards consist of leading researchers who are committed to help the institute achieve its ambitious goals.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>INSAIT opens in September, and I know the team is particularly keen to receive applications from women and other groups that are often underrepresented in the world of tech.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Google is delighted to support these efforts, and I cannot wait to see what new innovation emerges from this promising venture.</p></div></div>",
            "pubdate": "Mon, 11 Apr 2022 10:30:00 +0000",
            "pubdate_parsed": [
                2022,
                4,
                11
            ],
            "email_sent": true
        },
        "Improving skin tone representation across Google": {
            "url": "https://blog.google/products/search/monk-skin-tone-scale/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Seeing yourself reflected in the world around you \u2014 in real life, media or online \u2014 is so important. And we know that challenges with image-based technologies and representation on the web have historically left people of color feeling overlooked and misrepresented. Last year, we announced <a href=\"https://blog.google/products/pixel/image-equity-real-tone-pixel-6-photos/\">Real Tone for Pixel</a>, which is just one example of our efforts to improve representation of diverse skin tones across Google products.</p><p>Today, we're introducing a next step in our commitment to image equity and improving representation across our products. In partnership with Harvard professor and sociologist <a href=\"https://www.ellismonk.com/\">Dr. Ellis Monk</a>, we\u2019re releasing a new skin tone scale designed to be more inclusive of the spectrum of skin tones we see in our society. Dr. Monk has been studying how skin tone and colorism affect people\u2019s lives for more than 10 years.</p><p>The culmination of Dr. Monk\u2019s research is the <a href=\"http://skintone.google/\">Monk Skin Tone (MST) Scale</a>, a 10-shade scale that will be incorporated into various Google products over the coming months. We\u2019re openly releasing the scale so anyone can use it for research and product development. Our goal is for the scale to support inclusive products and research across the industry \u2014 we see this as a chance to share, learn and evolve our work with the help of others.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Ten circles in a row, ranging from dark to light.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Monk_Skin_Tone.max-1000x1000.max-1000x1000.png\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The 10 shades of the Monk Skin Tone Scale.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>This scale was designed to be easy-to-use for development and evaluation of technology while representing a broader range of skin tones. In fact, our research found that amongst participants in the U.S., people found the Monk Skin Tone Scale to be more representative of their skin tones compared to the <a href=\"http://skintone.google/the-scale\">current tech industry standard</a>. This was especially true for people with darker skin tones.</p><p>\u201cIn our research, we found that a lot of the time people feel they\u2019re lumped into racial categories, but there\u2019s all this heterogeneity with ethnic and racial categories,\u201d Dr. Monk says. \u201cAnd many methods of categorization, including past skin tone scales, don\u2019t pay attention to this diversity. That\u2019s where a lack of representation can happen\u2026we need to fine-tune the way we measure things, so people feel represented.\u201d</p></div></div><div class=\"block-video\"><div class=\"h-c-page h-c-page--mobile-full-bleed\"><div class=\"h-c-grid\"><div class=\"h-c-grid__col h-c-grid__col-l--10 h-c-grid__col-l--offset-1\"><div class=\"article-module uni-article-video uni-article-video--body\"><div class=\"uni-article-video__embed-container hidden\"><div id=\"uni-article-yt-player-crD1tzTlE4o\"></div></div><figure><a class=\"h-c-video h-c-video--marquee uni-article-video__custom-wrapper\" tabindex=\"0\"><div class=\"uni-article-video__aspect-image\"><img alt=\"Video of Dr. Ellis Monk on why he developed the Monk Skin Tone Scale\" src=\"https://img.youtube.com/vi/crD1tzTlE4o/maxresdefault.jpg\" /><div class=\"uni-article-video__dimmer\"></div><svg class=\"uni-article-video__play-button--active\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button_no_hole\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><svg class=\"uni-article-video__play-button\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><div class=\"uni-article-video__duration loading\"><svg class=\"uni-article-video__duration-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_duration\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><span class=\"uni-article-video__duration-time\">10:25</span></div></div></a></figure></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Using the Monk Skin Tone Scale to improve Google products</h3><p>Updating our approach to skin tone can help us better understand representation in imagery, as well as evaluate whether a product or feature works well across a range of skin tones. This is especially important for computer vision, a type of AI that allows computers to see and understand images. When not built and tested intentionally to include a broad range of skin-tones, computer vision systems have been found to not perform as well for people with darker skin.</p><p>The MST Scale will help us and the tech industry at large build more representative datasets so we can train and evaluate AI models for fairness, resulting in features and products that work better for everyone \u2014 of all skin tones. For example, we use the scale to evaluate and improve the models that detect faces in images.</p><p>Here are other ways you\u2019ll see this show up in Google products.</p><h3>Improving skin tone representation in Search</h3><p>Every day, millions of people search the web expecting to find images that reflect their specific needs. That\u2019s why we\u2019re also introducing new features using the MST Scale to make it easier for people of all backgrounds to find more relevant and helpful results.</p><p>For example, now when you search for makeup related queries in Google Images, you'll see an option to further refine your results by skin tone. So if you\u2019re looking for \u201ceveryday eyeshadow\u201d or \u201cbridal makeup looks\u201d you\u2019ll more easily find results that work better for your needs.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Animated GIF showing a Google Images search for \u201cbridal makeup looks.\u201d The results include an option to filter by skin tone; the cursor selects a darker skin tone, which adjusts to results that are more relevant to this choice.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Bridal_makeup_search_refinements_v20.gif\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Seeing yourself represented in results can be key to finding information that's truly relevant and useful, which is why we\u2019re also rolling out improvements to show a greater range of skin tones in image results for broad searches about people, or ones where people show up in the results. In the future, we\u2019ll incorporate the MST Scale to better detect and rank images to include a broader range of results, so everyone can find what they're looking for.</p><p>Creating a more representative Search experience isn\u2019t something we can do alone, though. How content is labeled online is a key factor in how our systems surface relevant results. In the coming months, we'll also be developing a standardized way to label web content. Creators, brands and publishers will be able to use this new inclusive schema to label their content with attributes like skin tone, hair color and hair texture. This will make it possible for content creators or online businesses to label their imagery in a way that search engines and other platforms can easily understand.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"A photograph of a Black person looking into the camera. Tags hover over various areas of the photo; one over their skin says \u201cSkin tone\u201d with a circle matching their skin tone. Two additional tags over their hair read \u201cHair color\u201d and \u201cHair texture.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/inclusive_schema_0509_anUYk5H.max-1000x1000.png\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Improving skin tone representation in Google Photos</h3><p>We\u2019ll also be using the MST Scale to improve Google Photos. Last year, we introduced an <a href=\"https://blog.google/products/pixel/image-equity-real-tone-pixel-6-photos/\">improvement to our auto enhance feature</a> in partnership with professional image makers. Now we\u2019re launching a new set of Real Tone filters that are designed to work well across skin tones and evaluated using the MST Scale. We worked with a diverse range of renowned image makers, like Kennedi Carter and Joshua Kissi, who are celebrated for beautiful and accurate depictions of their subjects, to evaluate, test and build these filters. These new Real Tone filters allow you to choose from a wider assortment of looks and find one that reflects your style. Real Tone filters will be rolling out on Google Photos across Android, iOS and Web in the coming weeks.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Animated video showing before and after photos of images with the Real Tone Filter.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Real_Tone_filter_v20.gif\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>What\u2019s next?</h3><p>We\u2019re openly releasing the Monk Skin Tone Scale so that others can use it in their own products, and learn from this work \u2014<i>and</i> so that we can partner with and learn from them. We want to get feedback, drive more interdisciplinary research, and make progress together. We encourage you to share your thoughts <a href=\"https://google.qualtrics.com/jfe/form/SV_eFJF7qguvcWvdFs\">here</a>. We\u2019re continuing to collaborate with Dr. Monk to evaluate the MST Scale across different regions and product applications, and we\u2019ll iterate and improve on it to make sure the scale works for people and use cases all over the world. And, we\u2019ll continue our efforts to make Google\u2019s products work even better for every user.</p><p>The best part of working on this project is that it isn\u2019t just ours \u2014 while we\u2019re committed to making Google products better and more inclusive, we\u2019re also excited about all the possibilities that exist as we work together to build for everyone across the web.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/technology/research/ai-monk-scale-skin-tone-story/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">A closer look at the research to help AI see more skin tones</h4><p class=\"uni-related-article-tout__body\">Meet the Googlers who\u2019ve led this latest work, and learn more about why and how they\u2019ve been dedicated to this AI advancement.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div>",
            "pubdate": "Wed, 11 May 2022 17:32:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "Google Translate learns 24 new languages": {
            "url": "https://blog.google/products/translate/24-new-languages/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>For years, Google Translate has helped break down language barriers and connect communities all over the world. And we want to make this possible for even more people \u2014 especially those whose languages aren\u2019t represented in most technology. So today we\u2019ve added 24 languages to Translate, now supporting a total of 133 used around the globe.</p><p>Over 300 million people speak these newly added languages \u2014 like Mizo, used by around 800,000 people in the far northeast of India, and Lingala, used by over 45 million people across Central Africa. As part of this update, Indigenous languages of the Americas (Quechua, Guarani and Aymara) and an English dialect (Sierra Leonean Krio) have also been added to Translate for the first time.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"The Google Translate bar translates the phrase &quot;Our mission: to enable everyone, everywhere to understand the world and express themselves across languages&quot; into different languages.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Translate_New-Languages.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Translate's mission translated into some of our newly added languages</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Here\u2019s a complete list of the new languages now available in Google Translate:</p><ul><li><b>Assamese</b>, used by about 25 million people in Northeast India</li><li><b>Aymara</b>, used by about two million people in Bolivia, Chile and Peru</li><li><b>Bambara</b>, used by about 14 million people in Mali</li><li><b>Bhojpuri</b>, used by about 50 million people in northern India, Nepal and Fiji</li><li><b>Dhivehi</b>, used by about 300,000 people in the Maldives</li><li><b>Dogri</b>, used by about three million people in northern India</li><li><b>Ewe</b>, used by about seven million people in Ghana and Togo</li><li><b>Guarani</b>, used by about seven million people in Paraguay and Bolivia, Argentina and Brazil</li><li><b>Ilocano</b>, used by about 10 million people in northern Philippines</li><li><b>Konkani</b>, used by about two million people in Central India</li><li><b>Krio</b>, used by about four million people in Sierra Leone</li><li><b>Kurdish (Sorani)</b>, used by about 15 million people in Iraq and Iran</li><li><b>Lingala</b>, used by about 45 million people in the Democratic Republic of the Congo, Republic of the Congo, Central African Republic, Angola and the Republic of South Sudan</li><li><b>Luganda</b>, used by about 20 million people in Uganda and Rwanda</li><li><b>Maithili</b>, used by about 34 million people in northern India</li><li><b>Meiteilon (Manipuri)</b>, used by about two million people in Northeast India</li><li><b>Mizo</b>, used by about 830,000 people in Northeast India</li><li><b>Oromo</b>, used by about 37 million people in Ethiopia and Kenya</li><li><b>Quechua</b>, used by about 10 million people in Peru, Bolivia, Ecuador and surrounding countries</li><li><b>Sanskrit</b>, used by about 20,000 people in India</li><li><b>Sepedi</b>, used by about 14 million people in South Africa</li><li><b>Tigrinya</b>, used by about eight million people in Eritrea and Ethiopia</li><li><b>Tsonga</b>, used by about seven million people in Eswatini, Mozambique, South Africa and Zimbabwe</li><li><b>Twi</b>, used by about 11 million people in Ghana</li></ul><p>This is also a technical milestone for Google Translate. These are the first languages we\u2019ve added using Zero-Shot Machine Translation, where a machine learning model only sees monolingual text \u2014 meaning, it learns to translate into another language without ever seeing an example. While this technology is impressive, it isn't perfect. And we\u2019ll keep improving these models to deliver the same experience you\u2019re used to with a Spanish or German translation, for example. If you want to dig into the technical details, check out our <a href=\"http://ai.googleblog.com/2022/05/24-new-languages-google-translate.html\">Google AI blog post</a> and <a href=\"https://arxiv.org/pdf/2205.03983.pdf\">research paper</a>.</p><p>We\u2019re grateful to the many native speakers, professors and linguists who worked with us on this latest update and kept us inspired with their passion and enthusiasm. If you want to help us support your language in a future update, contribute evaluations or translations through <a href=\"https://support.google.com/translate/answer/2534530?hl=en\">Translate Contribute</a>.</p></div></div>",
            "pubdate": "Wed, 11 May 2022 17:16:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "Google I/O 2022: Advancing knowledge and computing": {
            "url": "https://blog.google/technology/developers/io-2022-keynote/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>[TL;DR]</b></p><p>Nearly 24 years ago, Google started with two graduate students, one product, and a big mission: to organize the world\u2019s information and make it universally accessible and useful. In the decades since, we\u2019ve been developing our technology to deliver on that mission.</p><p>The progress we've made is because of our years of investment in advanced technologies, from AI to the technical infrastructure that powers it all. And once a year \u2014 on my favorite day of the year :) \u2014 we share an update on how it\u2019s going at <a href=\"https://io.google/2022/\">Google I/O</a>.</p><p>Today, I talked about how we\u2019re advancing two fundamental aspects of our mission \u2014 knowledge and computing \u2014 to create products that are built to help. It\u2019s exciting to build these products; it\u2019s even more exciting to see what people do with them.</p><p>Thank you to everyone who helps us do this work, and most especially our Googlers. We are grateful for the opportunity.</p><p>- Sundar</p><p></p><hr /><p><i>Editor\u2019s note: Below is an edited transcript of Sundar Pichai's keynote address during the opening of today's Google I/O Developers Conference.</i></p><p>Hi, everyone, and welcome. Actually, let\u2019s make that welcome back! It\u2019s great to return to Shoreline Amphitheatre after three years away. To the thousands of developers, partners and Googlers here with us, it\u2019s great to see all of you. And to the millions more joining us around the world \u2014 we\u2019re so happy you\u2019re here, too.</p><p>Last year, we <a href=\"https://blog.google/technology/developers/io-2021/\">shared</a> how new breakthroughs in some of the most technically challenging areas of computer science are making Google products more helpful in the moments that matter. All this work is in service of our timeless mission: to organize the world's information and make it universally accessible and useful.</p><p>I'm excited to show you how we\u2019re driving that mission forward in two key ways: by deepening our understanding of information so that we can turn it into knowledge; and advancing the state of computing, so that knowledge is easier to access, no matter who or where you are.</p><p>Today, you'll see how progress on these two parts of our mission ensures Google products are built to help. I\u2019ll start with a few quick examples. Throughout the pandemic, Google has focused on delivering accurate information to help people stay healthy. Over the last year, people used Google Search and Maps to find where they could get a COVID vaccine nearly two billion times.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"A visualization of Google\u2019s flood forecasting system, with three 3D maps stacked on top of one another, showing landscapes and weather patterns in green and brown colors. The maps are floating against a gray background.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_Flood_option_1.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Google\u2019s flood forecasting technology sent flood alerts to 23 million people in India and Bangladesh last year.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019ve also expanded our flood forecasting technology to help people stay safe in the face of natural disasters. During last year\u2019s monsoon season, our flood alerts notified more than 23 million people in India and Bangladesh. And we estimate this supported the timely evacuation of hundreds of thousands of people.</p><p>In Ukraine, we worked with the government to rapidly deploy air raid alerts. To date, we\u2019ve delivered hundreds of millions of alerts to help people get to safety. In March <a href=\"https://blog.google/inside-google/company-announcements/warsaw-announcing-more-support-ukraine/\">I was in Poland</a>, where millions of Ukrainians have sought refuge. Warsaw\u2019s population has increased by nearly 20% as families host refugees in their homes, and schools welcome thousands of new students. Nearly every Google employee I spoke with there was hosting someone.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Adding 24 more languages to Google Translate</h3><p>In countries around the world, Google Translate has been a crucial tool for newcomers and residents trying to communicate with one another. We\u2019re proud of how it\u2019s helping Ukrainians find a bit of hope and connection until they are able to return home again.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Two boxes, one showing a question in English \u2014 \u201cWhat\u2019s the weather like today?\u201d \u2014 the other showing its translation in Quechua. There is a microphone symbol below the English question and a loudspeaker symbol below the Quechua answer.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_Translate_Quechua.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>With machine learning advances, we're able to add languages like Quechua to Google Translate.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Real-time translation is a testament to how knowledge and computing come together to make people's lives better. More people are using Google Translate than ever before, but we still have work to do to make it universally accessible. There\u2019s a long tail of languages that are underrepresented on the web today, and translating them is a hard technical problem. That\u2019s because translation models are usually trained with bilingual text \u2014 for example, the same phrase in both English and Spanish. However, there's not enough publicly available bilingual text for every language.</p><p>So with advances in machine learning, we\u2019ve developed a monolingual approach where the model learns to translate a new language without ever seeing a direct translation of it. By collaborating with native speakers and institutions, we found these translations were of sufficient quality to be useful, and we'll continue to improve them.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"A list of the 24 new languages Google Translate now has available.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_Translate_24_option_1.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>We\u2019re adding 24 new languages to Google Translate.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Today, I\u2019m excited to announce that we\u2019re <a href=\"https://blog.google/products/translate/24-new-languages\">adding 24 new languages to Google Translate</a>, including the first indigenous languages of the Americas. Together, these languages are spoken by more than 300 million people. Breakthroughs like this are powering a radical shift in how we access knowledge and use computers.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Taking Google Maps to the next level</h3><p>So much of what\u2019s knowable about our world goes beyond language \u2014 it\u2019s in the physical and geospatial information all around us. For more than 15 years, Google Maps has worked to create rich and useful representations of this information to help us navigate. Advances in AI are taking this work to the next level, whether it\u2019s expanding our coverage to remote areas, or reimagining how to explore the world in more intuitive ways.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"An overhead image of a map of a dense urban area, showing gray roads cutting through clusters of buildings outlined in blue.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_Open_Buildings.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Advances in AI are helping to map remote and rural areas.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Around the world, we\u2019ve mapped around 1.6 billion buildings and over 60 million kilometers of roads to date. Some remote and rural areas have previously been difficult to map, due to scarcity of high-quality imagery and distinct building types and terrain. To address this, we\u2019re using computer vision and neural networks to detect buildings at scale from satellite images. As a result, we have increased the number of buildings on Google Maps in Africa by 5X since July 2020, from 60 million to nearly 300 million.</p><p>We\u2019ve also doubled the number of buildings mapped in India and Indonesia this year. Globally, over 20% of the buildings on Google Maps have been detected using these new techniques. We\u2019ve gone a step further, and made the dataset of buildings in Africa publicly available. International organizations like the United Nations and the World Bank are already using it to better understand population density, and to provide support and emergency assistance.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><video alt=\"Immersive view London\" class=\"article-image__media\" loop=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Karto_Sundar_Blog_02_Entering_the_Matrix.mp4\" tabindex=\"0\" title=\"An animation of an immersive look at the Houses of Parliament in London. That animation then moves to a smartphone screen, showing how it would appear in a Google Maps listing, then zooming in on Westminster Abbey.\" type=\"video/mp4\">Video format not supported</video></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Immersive view in Google Maps fuses together aerial and street level images.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re also bringing new capabilities into Maps. Using advances in 3D mapping and machine learning, we\u2019re fusing billions of aerial and street level images to create a new, high-fidelity representation of a place. These breakthrough technologies are coming together to power a <a href=\"https://blog.google/products/maps/three-maps-updates-io-2022\">new experience in Maps called immersive view</a>: it allows you to explore a place like never before.</p><p>Let\u2019s go to London and take a look. Say you\u2019re planning to visit Westminster with your family. You can get into this immersive view straight from Maps on your phone, and you can pan around the sights\u2026 here\u2019s Westminster Abbey. If you\u2019re thinking of heading to Big Ben, you can check if there's traffic, how busy it is, and even see the weather forecast. And if you\u2019re looking to grab a bite during your visit, you can check out restaurants nearby and get a glimpse inside.</p><p>What's amazing is that isn't a drone flying in the restaurant \u2014 we use neural rendering to create the experience from images alone. And Google Cloud Immersive Stream allows this experience to run on just about any smartphone. This feature will start rolling out in Google Maps for select cities globally later this year.</p><p>Another big improvement to Maps is eco-friendly routing. Launched last year, it shows you the most fuel-efficient route, giving you the choice to save money on gas and reduce carbon emissions. Eco-friendly routes have already rolled out in the U.S. and Canada \u2014 and people have used them to travel approximately 86 billion miles, helping save an estimated half million metric tons of carbon emissions, the equivalent of taking 100,000 cars off the road.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Still image of eco-friendly routing on Google Maps \u2014 a 53-minute driving route in Berlin is pictured, with text below the map showing it will add three minutes but save 18% more fuel.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_Eco_Routes.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Eco-friendly routes will expand to Europe later this year.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>I\u2019m happy to share that we\u2019re expanding this feature to more places, including Europe later this year. In this Berlin example, you could reduce your fuel consumption by 18% taking a route that\u2019s just three minutes slower. These small decisions have a big impact at scale. With the expansion into Europe and beyond, we estimate carbon emission savings will double by the end of the year.</p><p>And we\u2019ve added a similar feature to Google Flights. When you search for flights between two cities, we also show you carbon emission estimates alongside other information like price and schedule, making it easy to choose a greener option. These eco-friendly features in Maps and Flights are part of our goal to empower 1 billion people to make more sustainable choices through our products, and we\u2019re excited about the progress here.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>New YouTube features to help people easily access video content</h3><p>Beyond Maps, video is becoming an even more fundamental part of how we share information, communicate, and learn. Often when you come to YouTube, you are looking for a specific moment in a video and we want to help you get there faster.</p><p>Last year we launched auto-generated chapters to make it easier to jump to the part you\u2019re most interested in.</p><p>This is also great for creators because it saves them time making chapters. We\u2019re now applying multimodal technology from DeepMind. It simultaneously uses text, audio and video to auto-generate chapters with greater accuracy and speed. With this, we now have a goal to 10X the number of videos with auto-generated chapters, from eight million today, to 80 million over the next year.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Often the fastest way to get a sense of a video\u2019s content is to read its transcript, so we\u2019re also using speech recognition models to transcribe videos. Video transcripts are now available to all Android and iOS users.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Animation showing a video being automatically translated. Then text reads &quot;Now available in sixteen languages.&quot;\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/5.10.22_YT_Auto-Translate.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Auto-translated captions on YouTube.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Next up, we\u2019re bringing auto-translated captions on YouTube to mobile. Which means viewers can now auto-translate video captions in 16 languages, and creators can grow their global audience. We\u2019ll also be expanding auto-translated captions to Ukrainian YouTube content next month, part of our larger effort to increase access to accurate information about the war.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Helping people be more efficient with Google Workspace</h3><p>Just as we\u2019re using AI to improve features in YouTube, we\u2019re <a href=\"https://cloud.google.com/blog/products/workspace/introducing-new-ai-to-help-people-thrive-in-hybrid-work\">building it into our Workspace products</a> to help people be more efficient. Whether you work for a small business or a large institution, chances are you spend a lot of time reading documents. Maybe you\u2019ve felt that wave of panic when you realize you have a 25-page document to read ahead of a meeting that starts in five minutes.</p><p>At Google, whenever I get a long document or email, I look for a TL;DR at the top \u2014 TL;DR is short for \u201cToo Long, Didn\u2019t Read.\u201d And it got us thinking, wouldn\u2019t life be better if more things had a TL;DR?</p><p>That\u2019s why we\u2019ve introduced automated summarization for Google Docs. Using one of our machine learning models for text summarization, Google Docs will automatically parse the words and pull out the main points.</p><p>This marks a big leap forward for natural language processing. Summarization requires understanding of long passages, information compression and language generation, which used to be outside of the capabilities of even the best machine learning models.</p><p>And docs are only the beginning. We\u2019re launching summarization for other products in Workspace. It will come to Google Chat in the next few months, providing a helpful digest of chat conversations, so you can jump right into a group chat or look back at the key highlights.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Animation showing summary in Google Chat\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/5.10.22_Chat_Summarization.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>We\u2019re bringing summarization to Google Chat in the coming months.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>And we\u2019re working to bring transcription and summarization to Google Meet as well so you can catch up on some important meetings you missed.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Visual improvements on Google Meet</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Of course there are many moments where you really want to be in a virtual room with someone. And that\u2019s why we continue to improve audio and video quality, inspired by <a href=\"https://blog.google/technology/research/project-starline/\">Project Starline</a>. We introduced Project Starline at I/O last year. And we\u2019ve been testing it across Google offices to get feedback and improve the technology for the future. And in the process, we\u2019ve learned some things that we can apply right now to Google Meet.</p><p>Starline inspired machine learning-powered image processing to automatically improve your image quality in Google Meet. And it works on all types of devices so you look your best wherever you are.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"An animation of a man looking directly at the camera then waving and smiling. A white line sweeps across the screen, adjusting the image quality to make it brighter and clearer.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/5.10.22_Portrait_Restore.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Machine learning-powered image processing automatically improves image quality in Google Meet.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re also bringing studio quality virtual lighting to Meet. You can adjust the light position and brightness, so you\u2019ll still be visible in a dark room or sitting in front of a window. We\u2019re testing this feature to ensure everyone looks like their true selves, continuing the work we\u2019ve done with Real Tone on Pixel phones and the <a href=\"https://blog.google/products/search/monk-skin-tone-scale/\">Monk Scale</a>.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/products/search/monk-skin-tone-scale/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Improving skin tone representation across Google</h4><p class=\"uni-related-article-tout__body\">We're introducing a next step in our commitment to image equity and improving representation across our products.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>These are just some of the ways AI is improving our products: making them more helpful, more accessible, and delivering innovative new features for everyone.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col-l--6 h-c-grid__col--8 h-c-grid__col-l--offset-3 h-c-grid__col--offset-2\"><img alt=\"Gif shows a phone camera pointed towards a rack of shelves, generating helpful information about food items. Text on the screen shows the words \u2018dark\u2019, \u2018nut-free\u2019 and \u2018highly-rated\u2019.\" class=\"article-image--large\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Scene_exploration_1.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Today at I/O Prabhakar Raghavan <a href=\"https://blog.google/products/search/search-io22/\">shared</a> how we\u2019re helping people find helpful information in more intuitive ways on Search.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Making knowledge accessible through computing</h3><p>We\u2019ve talked about how we\u2019re advancing access to knowledge as part of our mission: from better language translation to improved Search experiences across images and video, to richer explorations of the world using Maps.</p><p>Now we\u2019re going to focus on how we make that knowledge even more accessible through computing. The journey we\u2019ve been on with computing is an exciting one. Every shift, from desktop to the web to mobile to wearables and ambient computing has made knowledge more useful in our daily lives.</p><p>As helpful as our devices are, we\u2019ve had to work pretty hard to adapt to them. I\u2019ve always thought computers should be adapting to people, not the other way around. We continue to push ourselves to make progress here.</p><p>Here\u2019s how we\u2019re making computing more natural and intuitive with the <a href=\"https://blog.google/products/assistant/assistant-io-2022/\">Google Assistant</a>.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/products/assistant/assistant-io-2022/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Have more natural conversations with Google Assistant</h4><p class=\"uni-related-article-tout__body\">Google Assistant announces more natural and conversational ways to interact with devices.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Introducing LaMDA 2 and AI Test Kitchen</h3></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Animation shows demos of how LaMDA can converse on any topic and how AI Test Kitchen can help create lists.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/AI_TestKitchen_BlogPost_10fps.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>A demo of LaMDA, our generative language model for dialogue application, and the AI Test Kitchen.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We're continually working to <a href=\"https://blog.google/technology/ai/understanding-the-world-through-language/\">advance our conversational capabilities</a>. Conversation and natural language processing are powerful ways to make computers more accessible to everyone. And large language models are key to this.</p><p>Last year, we <a href=\"https://blog.google/technology/ai/lamda/\">introduced LaMDA</a>, our generative language model for dialogue applications that can converse on any topic. Today, we are excited to announce LaMDA 2, our most advanced conversational AI yet.</p><p>We are at the beginning of a journey to make models like these useful to people, and we feel a deep responsibility to get it right. To make progress, we need people to experience the technology and provide feedback. We opened LaMDA up to thousands of Googlers, who enjoyed testing it and seeing its capabilities. This yielded significant quality improvements, and led to a reduction in inaccurate or offensive responses.</p><p>That\u2019s why we\u2019ve made AI Test Kitchen. It\u2019s a new way to explore AI features with a broader audience. Inside the AI Test Kitchen, there are a few different experiences. Each is meant to give you a sense of what it might be like to have LaMDA in your hands and use it for things you care about.</p><p>The first is called \u201cImagine it.\u201d This demo tests if the model can take a creative idea you give it, and generate imaginative and relevant descriptions. These are not products, they are quick sketches that allow us to explore what LaMDA can do with you. The user interfaces are very simple.</p><p>Say you\u2019re writing a story and need some inspirational ideas. Maybe one of your characters is exploring the deep ocean. You can ask what that might feel like. Here LaMDA describes a scene in the Mariana Trench. It even generates follow-up questions on the fly. You can ask LaMDA to imagine what kinds of creatures might live there. Remember, we didn\u2019t hand-program the model for specific topics like submarines or bioluminescence. It synthesized these concepts from its training data. That\u2019s why you can ask about almost any topic: Saturn\u2019s rings or even being on a planet made of ice cream.</p><p>Staying on topic is a challenge for language models. Say you\u2019re building a learning experience \u2014 you want it to be open-ended enough to allow people to explore where curiosity takes them, but stay safely on topic. Our second demo tests how LaMDA does with that.</p><p>In this demo, we\u2019ve primed the model to focus on the topic of dogs. It starts by generating a question to spark conversation, \u201cHave you ever wondered why dogs love to play fetch so much?\u201d And if you ask a follow-up question, you get an answer with some relevant details: it\u2019s interesting, it thinks it might have something to do with the sense of smell and treasure hunting.</p><p>You can take the conversation anywhere you want. Maybe you\u2019re curious about how smell works and you want to dive deeper. You\u2019ll get a unique response for that too. No matter what you ask, it will try to keep the conversation on the topic of dogs. If I start asking about cricket, which I probably would, the model brings the topic back to dogs in a fun way.</p><p>This challenge of staying on-topic is a tricky one, and it\u2019s an important area of research for building useful applications with language models.</p><p>These experiences show the potential of language models to one day help us with things like planning, learning about the world, and more.</p><p>Of course, there are significant challenges to solve before these models can truly be useful. While we have improved safety, the model might still generate inaccurate, inappropriate, or offensive responses. That\u2019s why we are inviting feedback in the app, so people can help report problems.</p><p>We will be doing all of this work in accordance with our AI Principles. Our process will be iterative, opening up access over the coming months, and carefully assessing feedback with a broad range of stakeholders \u2014 from AI researchers and social scientists to human rights experts. We\u2019ll incorporate this feedback into future versions of LaMDA, and share our findings as we go.</p><p>Over time, we intend to continue adding other emerging areas of AI into AI Test Kitchen. You can learn more at: <a href=\"http://g.co/AITestKitchen\">g.co/AITestKitchen</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Advancing AI language models</h3><p>LaMDA 2 has incredible conversational capabilities. To explore other aspects of natural language processing and AI, we recently announced a new model. It\u2019s called <a href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html?m=1\">Pathways Language Model</a>, or PaLM for short. It\u2019s our largest model to date and trained on 540 billion parameters.</p><p>PaLM demonstrates breakthrough performance on many natural language processing tasks, such as generating code from text, answering a math word problem, or even explaining a joke.</p><p>It achieves this through greater scale. And when we combine that scale with a new technique called chain-of- thought prompting, the results are promising. Chain-of-thought prompting allows us to describe multi-step problems as a series of intermediate steps.</p><p>Let\u2019s take an example of a math word problem that requires reasoning. Normally, how you use a model is you prompt it with a question and answer, and then you start asking questions. In this case: How many hours are in the month of May? So you can see, the model didn\u2019t quite get it right.</p><p>In chain-of-thought prompting, we give the model a question-answer pair, but this time, an explanation of how the answer was derived. Kind of like when your teacher gives you a step-by-step example to help you understand how to solve a problem. Now, if we ask the model again \u2014 how many hours are in the month of May \u2014 or other related questions, it actually answers correctly and even shows its work.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"There are two boxes below a heading saying \u2018chain-of-thought prompting\u2019. A box headed \u2018input\u2019 guides the model through answering a question about how many tennis balls a person called Roger has. The output box shows the model correctly reasoning through and answering a separate question (\u2018how many hours are in the month of May?\u2019)\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_Chain_of_Thought.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Chain-of-thought prompting leads to better reasoning and more accurate answers.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Chain-of-thought prompting increases accuracy by a large margin. This leads to state-of-the-art performance across several reasoning benchmarks, including math word problems. And we can do it all without ever changing how the model is trained.</p><p>PaLM is highly capable and can do so much more. For example, you might be someone who speaks a language that\u2019s not well-represented on the web today \u2014 which makes it hard to find information. Even more frustrating because the answer you are looking for is probably out there. PaLM offers a new approach that holds enormous promise for making knowledge more accessible for everyone.</p><p>Let me show you an example in which we can help answer questions in a language like Bengali \u2014 spoken by a quarter billion people. Just like before we prompt the model with two examples of questions in Bengali with both Bengali and English answers.</p><p>That\u2019s it, now we can start asking questions in Bengali: \u201cWhat is the national song of Bangladesh?\u201d The answer, by the way, is \u201cAmar Sonar Bangla\u201d \u2014 and PaLM got it right, too. This is not that surprising because you would expect that content to exist in Bengali.</p><p>You can also try something that is less likely to have related information in Bengali such as: \u201cWhat are popular pizza toppings in New York City?\u201d The model again answers correctly in Bengali. Though it probably just stirred up a debate amongst New Yorkers about how \u201ccorrect\u201d that answer really is.</p><p>What\u2019s so impressive is that PaLM has never seen parallel sentences between Bengali and English. Nor was it ever explicitly taught to answer questions or translate at all! The model brought all of its capabilities together to answer questions correctly in Bengali. And we can extend the techniques to more languages and other complex tasks.</p><p>We're so optimistic about the potential for language models. One day, we hope we can answer questions on more topics in any language you speak, making knowledge even more accessible, in Search and across all of Google.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Introducing the world\u2019s largest, publicly available machine learning hub</h3><p>The advances we\u2019ve shared today are possible only because of our continued innovation in our infrastructure. Recently we announced plans to invest $9.5 billion in data centers and offices across the U.S.</p><p>One of our state-of-the-art data centers is in Mayes County, Oklahoma. I\u2019m excited to announce that, there, we are launching the world\u2019s largest, publicly-available machine learning hub for our Google Cloud customers.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Still image of a data center with Oklahoma map pin on bottom left corner.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/5.10.22_TPU_Oklahoma.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>One of our state-of-the-art data centers in Mayes County, Oklahoma.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>This machine learning hub has eight Cloud TPU v4 pods, custom-built on the same networking infrastructure that powers Google\u2019s largest neural models. They provide nearly nine exaflops of computing power in aggregate \u2014 bringing our customers an unprecedented ability to run complex models and workloads. We hope this will fuel innovation across many fields, from medicine to logistics, sustainability and more.</p><p>And speaking of sustainability, this machine learning hub is already operating at 90% carbon-free energy. This is helping us make progress on our goal to become the first major company to operate all of our data centers and campuses globally on 24/7 carbon-free energy by 2030.</p><p>Even as we invest in our data centers, we are working to innovate on our mobile platforms so more processing can happen locally on device. Google Tensor, our custom system on a chip, was an important step in this direction. It\u2019s already running on Pixel 6 and Pixel 6 Pro, and it brings our AI capabilities \u2014 including the best speech recognition we\u2019ve ever deployed \u2014 right to your phone. It\u2019s also a big step forward in making those devices more secure. Combined with Android\u2019s Private Compute Core, it can run data-powered features directly on device so that it\u2019s private to you.</p><p>People turn to our products every day for help in moments big and small. Core to making this possible is protecting your private information each step of the way. Even as technology grows increasingly complex, we <a href=\"https://blog.google/technology/safety-security/io-safer-with-google/\">keep more people safe online</a> than anyone else in the world, with products that are secure by default, private by design and that put you in control.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/technology/safety-security/how-we-make-every-day-safer-with-google/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">How we make every day safer with Google</h4><p class=\"uni-related-article-tout__body\">An update on how Google keeps more people safe online than anyone else in the world.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We also spent time today sharing updates to platforms like <a href=\"https://www.blog.google/products/android/io22-multideviceworld\">Android</a>. They\u2019re delivering access, connectivity, and information to billions of people through their smartphones and other connected devices like TVs, cars and watches.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/products/android/io22-multideviceworld/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Living in a multi-device world with Android</h4><p class=\"uni-related-article-tout__body\">At I/O, Android announced updates to your phone, to your watch and tablet devices, and to help all your devices work better together.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>And we shared our new <a href=\"https://blog.google/products/pixel/hardware-updates-io-2022\">Pixel Portfolio,</a> including the Pixel 6a, Pixel Buds Pro, Google Pixel Watch, Pixel 7, and Pixel tablet all built with ambient computing in mind. We\u2019re excited to share a family of devices that work better together \u2014 for you.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/products/pixel/hardware-updates-io-2022/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Take a look at our new Pixel portfolio, made to be helpful</h4><p class=\"uni-related-article-tout__body\">The new Pixel portfolio furthers our work in ambient computing, making your hardware work better together for you.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>The next frontier of computing: augmented reality</h3><p>Today we talked about all the technologies that are changing how we use computers and access knowledge. We see devices working seamlessly together, exactly when and where you need them and with conversational interfaces that make it easier to get things done.</p><p>Looking ahead, there's a new frontier of computing, which has the potential to extend all of this even further, and that is augmented reality. At Google, we have been heavily invested in this area. We\u2019ve been building augmented reality into many Google products, from Google Lens to multisearch, scene exploration, and Live and immersive views in Maps.</p><p>These AR capabilities are already useful on phones and the magic will really come alive when you can use them in the real world without the technology getting in the way.</p><p>That potential is what gets us most excited about AR: the ability to spend time focusing on what matters in the real world, in our real lives. Because the real world is pretty amazing!</p><p>It\u2019s important we design in a way that is built for the real world \u2014 and doesn\u2019t take you away from it. And AR gives us new ways to accomplish this.</p><p>Let\u2019s take language as an example. Language is just so fundamental to connecting with one another. And yet, understanding someone who speaks a different language, or trying to follow a conversation if you are deaf or hard of hearing can be a real challenge. Let's see what happens when we take our advancements in translation and transcription and deliver them in your line of sight in one of the early prototypes we\u2019ve been testing.</p></div></div><div class=\"block-video\"><div class=\"h-c-page h-c-page--mobile-full-bleed\"><div class=\"h-c-grid\"><div class=\"h-c-grid__col h-c-grid__col-l--10 h-c-grid__col-l--offset-1\"><div class=\"article-module uni-article-video uni-article-video--body\"><div class=\"uni-article-video__embed-container hidden\"><div id=\"uni-article-yt-player-lj0bFX9HXeE\"></div></div><figure><a class=\"h-c-video h-c-video--marquee uni-article-video__custom-wrapper\" tabindex=\"0\"><div class=\"uni-article-video__aspect-image\"><img alt=\"Breaking down language barriers with augmented reality | Google\" src=\"https://img.youtube.com/vi/lj0bFX9HXeE/maxresdefault.jpg\" /><div class=\"uni-article-video__dimmer\"></div><svg class=\"uni-article-video__play-button--active\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button_no_hole\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><svg class=\"uni-article-video__play-button\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><div class=\"uni-article-video__duration loading\"><svg class=\"uni-article-video__duration-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_duration\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><span class=\"uni-article-video__duration-time\">10:25</span></div></div></a></figure></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>You can see it in their faces: the joy that comes with speaking naturally to someone. That moment of connection. To understand and be understood. That\u2019s what our focus on knowledge and computing is all about. And it\u2019s what we strive for every day, with products that are built to help.</p><p>Each year we get a little closer to delivering on our timeless mission. And we still have so much further to go. At Google, we genuinely feel a sense of excitement about that. And we are optimistic that the breakthroughs you just saw will help us get there. Thank you to all of the developers, partners and customers who joined us today. We look forward to building the future with all of you.</p></div></div>",
            "pubdate": "Wed, 11 May 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "Understanding the world through language": {
            "url": "https://blog.google/technology/ai/understanding-the-world-through-language/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Language is at the heart of how people communicate with each other. It\u2019s also proving to be powerful in advancing AI and building helpful experiences for people worldwide.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>From the beginning, we set out to connect words in your search to words on a page so we could make the web\u2019s information more accessible and useful. Over 20 years later, as the web changes, and the ways people consume information expand from text to images to videos and more \u2014 the one constant is that language remains a surprisingly powerful tool for understanding information.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In recent years, we\u2019ve seen an incredible acceleration in the field of natural language understanding. While our systems still don\u2019t understand language the way people do, they\u2019re increasingly able to spot patterns in information, identify complex concepts and even draw implicit connections between them. We\u2019re even finding that many of our advanced models can understand information across languages or in non-language-based formats like images and videos.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Building the next generation of language models</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In 2017, Google researchers developed the Transformer, the neural network that underlies major advancements like <a href=\"https://blog.google/products/search/introducing-mum/\">MUM</a> and <a href=\"https://blog.google/technology/ai/lamda/\">LaMDA</a>. Last year, we shared our thinking on a <a href=\"https://blog.google/technology/ai/introducing-pathways-next-generation-ai-architecture/\">new architecture</a> called Pathways, which is loosely inspired by the sparse patterns of neural activity in the brain. When you read a blog post like this one, only the critical parts of your brain needed to process this information fire up \u2014 not every single neuron. With Pathways, we\u2019re now able to train AI models to be similarly effective.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Using this system, we recently introduced <a href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\">PaLM</a>, a new model that achieves state-of-the-art performance on challenging language modeling tasks. It can solve complex math word problems, and answer questions in new languages with very little additional training data.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>PaLM also shows improvements in understanding and expressing logic. This is significant because it allows the model to express its reasoning through words. Remember your algebra problem sets? It wasn\u2019t enough to just get the right answer \u2014 you had to explain how you got there. PaLM is able to prompt a \u201c<a href=\"http://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html\">Chain of Thought</a>\u201d to explain its thought process, step-by-step. This emerging capability helps improve accuracy and our understanding of how a model arrives at answers.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Flow chart for the difference between &quot;Standard Prompting&quot; and &quot;Chain of Thought Prompting&quot;\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Chain_of_Thought_Prompting.max-1000x1000.png\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Translating the languages of the world</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Pathways-related models are enabling us to break down language barriers in a way never before possible. Nowhere is this clearer than in our <a href=\"https://blog.google/products/translate/24-new-languages\">recently added support for 24 new languages</a> in Google Translate, spoken by over 300 million people worldwide \u2014 including the first indigenous languages of the Americas. The amazing part is that the neural model did this using only <a href=\"http://ai.googleblog.com/2022/05/24-new-languages-google-translate.html\">monolingual text</a> with no translation pairs \u2014 which allows us to help communities and languages underrepresented by technology. Machine translation at this level helps the world feel a bit smaller, while allowing us to <a href=\"https://www.youtube.com/watch?v=lj0bFX9HXeE\">dream bigger</a>.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Unlocking knowledge about the world across modalities</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Today, people consume information through webpages, images, videos, and more. Our advanced language and Pathways-related models are learning to make sense of information stemming from these different modalities through language. With these multimodal capabilities, we\u2019re <a href=\"https://blog.google/products/search/search-io22/\">expanding multisearch</a> in the Google app so you can search more naturally than ever before. As the saying goes \u2014 \u201ca picture is worth a thousand words\u201d \u2014 it turns out, words are really the key to sharing information about the world.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"&quot;Scene exploration&quot; GIF of a store shelf demonstrating multisearch\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Chocolate_Scene.gif\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Improving conversational AI</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Despite these advancements, human language continues to be one of the most complex undertakings for computers.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In everyday conversation, we all naturally say \u201cum,\u201d pause to find the right words, or correct ourselves \u2014 and yet other people have no trouble understanding what we\u2019re saying. That\u2019s because people can react to conversational cues in as little as 200 milliseconds. Moving our speech model from data centers to run on the device made things faster, but we wanted to push the envelope even more.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Computers aren\u2019t there yet \u2014 so we\u2019re introducing <a href=\"https://blog.google/products/assistant/assistant-io-2022\">improvements to responsiveness on the Assistant</a> with unified neural networks, combining many models into smarter ones capable of understanding more \u2014 like when someone pauses but is not finished speaking. Getting closer to the fluidity of real-time conversation is finally possible with Google's Tensor chip, which is custom-engineered to handle on-device machine learning tasks super fast.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re also investing in building models that are capable of carrying more natural, sensible and specific conversations. Since introducing LaMDA to the world last year, we\u2019ve made great progress, improving the model in key areas of <a href=\"https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html\">quality, safety and groundedness</a> \u2014 areas where we know conversational AI models can struggle. We\u2019ll be releasing the next iteration, LaMDA 2, as a part of the <a href=\"http://g.co/aitestkitchen\">AI Test Kitchen</a>, which we\u2019ll be opening up to small groups of people gradually. Our goal with AI Test Kitchen is to learn, improve, and innovate responsibly on this technology together. It\u2019s still early days for LaMDA, but we want to continue to make progress and do so responsibly with feedback from the community.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"GIF showing LaMDA 2 on device\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/AI-TestKitchen-BlogPost-v5.gif\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Responsible development of AI models</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>While language is a remarkably powerful and versatile tool for understanding the world around us, we also know it comes with its limitations and challenges. In 2018, we published our <a href=\"https://ai.google/principles/\">AI Principles</a> as guidelines to help us avoid bias, test rigorously for safety, design with privacy top of mind and make technology accountable to people. We\u2019re investing in research across disciplines to understand the types of harms language models can affect, and to develop the frameworks and methods to ensure we bring in a diversity of perspectives and make meaningful improvements. We also build and use <a href=\"https://pair-code.github.io/lit/\">tools</a> that can help us better understand our models (e.g., identifying how different words affect a prediction, tracing an error back to training data and even measuring correlations within a model). And while we work to improve underlying models, we also test rigorously before and after any kind of product deployment.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019ve come a long way since introducing the world to the Transformer. We\u2019re proud of the tremendous value that it and its predecessors have brought not only to everyday Google products like Search and Translate, but also the breakthroughs they\u2019ve powered in natural language understanding. Our work advancing the future of AI is driven by something as old as time: the power language has to bring people together.</p></div></div>",
            "pubdate": "Wed, 11 May 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "Immersive view coming soon to Maps  plus more updates": {
            "url": "https://blog.google/products/maps/three-maps-updates-io-2022/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Google Maps helps over one billion people navigate and explore. And over the past few years, our investments in AI have supercharged the ability to bring you the most helpful information about the real world, including when a <a href=\"https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/\">business is open</a> and <a href=\"https://blog.google/products/maps/new-normals-with-google-maps/\">how crowded your bus is</a>. Today at Google I/O, we announced new ways the latest advancements in AI are transforming Google Maps \u2014 helping you explore with an all-new immersive view of the world, find the most fuel-efficient route, and use the magic of Live View in your favorite third-party apps.</p><h3>A more immersive, intuitive map</h3><p>Google Maps first launched to help people navigate to their destinations. Since then, it\u2019s evolved to become much more \u2014 it\u2019s a handy companion when you need to find the perfect restaurant or get information about a local business. Today \u2014 thanks to advances in computer vision and AI that allow us to fuse together billions of Street View and aerial images to create a rich, digital model of the world \u2014 we\u2019re introducing a whole new way to explore with Maps. With our new immersive view, you\u2019ll be able to experience what a neighborhood, landmark, restaurant or popular venue is like \u2014 and even feel like you\u2019re right there before you ever set foot inside. So whether you\u2019re traveling somewhere new or scoping out hidden local gems, immersive view will help you make the most informed decisions before you go.</p><p>Say you\u2019re planning a trip to London and want to figure out the best sights to see and places to eat. With a quick search, you can virtually soar over Westminster to see the neighborhood and stunning architecture of places, like Big Ben, up close. With Google Maps\u2019 helpful information layered on top, you can use the time slider to check out what the area looks like at different times of day and in various weather conditions, and see where the busy spots are. Looking for a spot for lunch? Glide down to street level to explore nearby restaurants and see helpful information, like live busyness and nearby traffic. You can even look inside them to quickly get a feel for the vibe of the place before you book your reservation.</p><p>The best part? Immersive view will work on just about any phone and device. It starts rolling out in Los Angeles, London, New York, San Francisco and Tokyo later this year with more cities coming soon.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><video alt=\"Immersive View\" class=\"article-image__media\" loop=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Karto_Geo_Blog_Edit_1080p_zoXr3if.mp4\" tabindex=\"0\" title=\"A multidimensional video soaring over London, showing the Westminster area, Big Ben and nearby restaurants up close\" type=\"video/mp4\">Video format not supported</video></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Immersive view lets you explore and understand the vibe of a place before you go</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>An update on eco-friendly routing</h3><p>In addition to making places easier to explore, we want to help you get there more sustainably. We recently launched eco-friendly routing in the U.S. and Canada, which lets you see and choose the most fuel-efficient route when looking for driving directions \u2014 helping you save money on gas. Since then, people have used it to travel 86 billion miles, saving more than an estimated half a million metric tons of carbon emissions \u2014 equivalent to taking 100,000 cars off the road. We\u2019re on track to double this amount as we expand to more places, like Europe.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Still image of eco-friendly routing on Google Maps\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Eco-friendly_routing_I_O.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Eco-friendly routing has helped save more than an estimated half a million metric tons of carbon emissions</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>The magic of Live View \u2014 now in your favorite apps</h3><p><a href=\"https://blog.google/products/maps/new-sense-direction-live-view/\">Live View</a> helps you find your way when walking around, using AR to display helpful arrows and directions right on top of your world. It's especially helpful when navigating tricky indoor areas, like <a href=\"https://blog.google/products/maps/redefining-what-map-can-be-new-information-and-ai/\">airports, malls and train stations</a>. Thanks to our AI-based technology called <a href=\"https://ai.googleblog.com/2019/02/using-global-localization-to-improve.html\">global localization,</a> Google Maps can point you where you need to go in a matter of seconds. As part of our efforts to bring the helpfulness of Google Maps to more places, we\u2019re now making this technology available to developers at no cost with the new ARCore Geospatial API.</p><p>Developers are already using the API to make apps that are even more useful and provide an easy way to interact with both the digital and physical worlds at once. Shared electric vehicle company Lime is piloting the API in London, Paris, Tel Aviv, Madrid, San Diego, and Bordeaux to help riders park their e-bikes and e-scooters responsibly and out of pedestrians\u2019 right of way. Telstra and Accenture are using it to help sports fans and concertgoers find their seats, concession stands and restrooms at Marvel Stadium in Melbourne. DOCOMO and Curiosity are building a new game that lets you fend off virtual dragons with robot companions in front of iconic Tokyo landmarks, like the Tokyo Tower. The new Geospatial API is available now to ARCore developers, wherever Street View is available.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col-l--2 h-c-grid__col--4 h-c-grid__col-l--offset-5 h-c-grid__col--offset-4\"><img alt=\"DOCOMO and Curiosity game showing an AR dragon, alien and spaceship interacting on top of a real-world image, powered by the ARCore Geospatial API.\" class=\"article-image--small\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/docomo_01_1.gif\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Live View technology is now available to ARCore developers around the world</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI will continue to play a critical role in making Google Maps the most comprehensive and helpful map possible for people everywhere.</p></div></div>",
            "pubdate": "Wed, 11 May 2022 15:17:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "A closer look at the research to help AI see more skin tones": {
            "url": "https://blog.google/technology/research/ai-monk-scale-skin-tone-story/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Today at I/O <a href=\"https://www.blog.google/products/search/monk-skin-tone-scale/\">we released the Monk Skin Tone (MST) Scale</a> in partnership with Harvard professor and sociologist <a href=\"https://www.ellismonk.com/\">Dr. Ellis Monk</a>. The MST Scale, developed by Dr. Monk, is a 10-shade scale designed to be more inclusive of the spectrum of skin tones in our society. We\u2019ll be incorporating the MST Scale into various Google products over the coming months, and we are openly releasing the scale so that anyone can use it for research and product development.</p><p>The MST Scale is an important next step in a collective effort to improve skin tone inclusivity in technology. For Google, it will help us make progress in our commitment to image equity and improving representation across our products. And in releasing the MST Scale for all to use, we hope to make it easier for others to do the same, so we can learn and evolve together.</p><p>Addressing skin tone equity in technology poses an interesting research challenge because it isn\u2019t just a technical question, it\u2019s also a social one. Making progress requires the combined expertise of a wide range of people \u2014 from academics in the social sciences who have spent years studying social inequality and skin tone stratification through their research, to product and technology users, who provide necessary nuance and feedback borne of their lived experiences, to ethicists and civil rights activists, who guide on application frameworks to ensure we preserve and honor the social nuances. The ongoing and iterative work from this wider community has led us to the knowledge and understanding that we have today, and will be key to the continued path forward.</p><p>Teams within Google have been contributing to this body of work for years now. Here\u2019s a deeper look at how Googlers have been thinking about and working on skin tone representation efforts, particularly as it relates to the MST Scale \u2014 and what might come next.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/products/search/monk-skin-tone-scale/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Read Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Improving skin tone representation across Google</h4><p class=\"uni-related-article-tout__body\">We're introducing a next step in our commitment to image equity and improving representation across our products.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Building technology that sees more people</h3><p>\u201cPersistent inequities exist globally due to prejudice or discrimination against individuals with darker skin tones, also known as colorism,\u201d says Dr. Courtney Heldreth, a social psychologist and user experience (UX) researcher in Google\u2019s Responsible AI Human-Centered Technology UX (RAI-HCT UX) department, which is part of Google Research. \u201cThe <a href=\"https://direct.mit.edu/daed/article-pdf/150/2/76/1897805/daed_a_01847.pdf\">academic literature</a> demonstrates that skin tone plays a significant role in how people are treated across a wide variety of outcomes including health, wealth, well-being, and more.\u201d And one example of colorism is when technology doesn\u2019t see skin tone accurately, potentially exacerbating existing inequities.</p><p>Machine learning, a type of AI, is the bedrock of so many products we use every day. Cameras use ML for security reasons, to unlock a phone or register that someone is at the door. ML helps categorize your photos by similar faces, or adjust the brightness on a picture.</p><p>To do this well, engineers and researchers need diverse training datasets to train models, and to extensively test the resulting models across a diverse range of images. Importantly, in order to ensure that datasets used to develop technologies relating to understanding people are more inclusive, we need a scale that represents a wide range of skin tones.</p><p>\u201cIf you're saying, <i>I tested my model for fairness to make sure it works well for darker skin tones</i>, but you\u2019re using a scale that doesn't represent most people with those skin tones, you don't know how well it actually works,\u201d says Xango Eye\u00e9, a Product Manager working on Responsible AI.</p><p>\u201cIf not developed with intention, the skin tone measure we use to understand whether our models are fair and representative can affect how products are experienced by users. Downstream, these decisions can have the biggest impacts on people who are most vulnerable to unfair treatment, people with darker skin tones,\u201d Dr. Heldreth says.</p><p>Eye\u00e9 and Dr. Heldreth are both core members of Google\u2019s research efforts focused on building more skin tone equity into AI development, a group that includes an interdisciplinary set of product managers, researchers and engineers who specialize in computer vision and social psychology. The team also works across Google with image equity teams building more representation into products like cameras, photos, and emojis.</p><p>\u201cWe take a human-centered approach to understanding how AI can influence and help people around the world,\u201d Dr. Heldreth says, \u201cfocusing on improving inclusivity in AI, to ensure that technology reflects and empowers globally and culturally diverse communities, especially those who are historically marginalized and underserved.\u201d A more inclusive skin tone scale is a core part of this effort.</p><p>The team operates with a guiding objective: To keep improving technology so that it works well for more people. Doing that has involved two major tasks: \u201cThe first was figuring out what was already built and why it wasn't working,\u201d Eye\u00e9 says. \u201cAnd the second was figuring out what we needed to build instead.\u201d</p></div></div><div class=\"block-image_carousel\"><div class=\"h-c-page article-module\"><div class=\"article-module glue-pagination h-c-carousel h-c-carousel--simple h-c-carousel--dark ng-cloak\"><div class=\"h-c-carousel__wrap\"><ul class=\"glue-carousel ng-cloak\"><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">A man with glasses looks into the camera smiling. A woman with glasses next to him is also looking into the camera and smiling, and she is holding the camera taking a selfie. They are in a guitar store.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Dr. Monk with his wife, Anna.</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">A screenshot of a Google Meet video call with three rows of nine people in individual squares.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>The team during a call. Top row: Kylee Jaye, Shrikanth Narayanan, Auriel Wright; middle row: Candice Schumann, Courtney Heldreth, Komal Singh; bottom row: Marco Andreetto, Susanna Ricco, Kree Cole-Mclaughlin</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">Two people stand side by side, looking into the camera and smiling. They\u2019re standing in front of a green wall with a garden art installation on it.]</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Susanna Ricco and Kylee Jaye, another software engineer who worked on the project.</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">Two women standing side by side with their arms around each other, looking into the camera and smiling. They are standing in front of shrubs and trees, standing on a sidewalk next to yellow and blue circular objects on the sidewalk.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Dr. Susanna Ricco and Dr. Courtney Heldreth on the Google Mountain View campus.</p></div></figcaption></figure></li></ul><div class=\"h-c-carousel__paginate glue-pagination-previous uni-click-tracker\"><div class=\"h-c-carousel__paginate-wrap\"><svg class=\"h-c-icon h-c-icon--keyboard-arrow-left\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-keyboard-arrow-right\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></div></div><div class=\"h-c-carousel__paginate glue-pagination-next uni-click-tracker\"><div class=\"h-c-carousel__paginate-wrap\"><svg class=\"h-c-icon h-c-icon--keyboard-arrow-right\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-keyboard-arrow-right\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></div></div></div><div class=\"h-c-carousel__navigation\"><div class=\"glue-pagination-page-list uni-click-tracker\"></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>A social-technical approach</h3><p>\"Skin tone is something that changes the physical properties of images, and it\u2019s something that affects people\u2019s lived experiences \u2014 and both of these things can impact how a piece of technology performs,\u201d Dr. Susanna Ricco says. Dr. Ricco, a software engineer on Google Research's Perception team, leads a group that specializes in finding new ways to make sure Google's computer vision systems work well for more users, regardless of their backgrounds or how they look. To make sure that tech works across skin tones, we need to intentionally test and improve it across a diverse range. \u201cTo do that, we need a scale that doesn\u2019t leave skin tones out or over-generalize,\u201d she says.</p><p>\u201cThere\u2019s the physics side of things \u2014 how well a sensor responds to a person\u2019s skin tone,\u201d Dr. Ricco says. \u201cThen there\u2019s the social side of things: We know that skin tone correlates with life experiences, so we want to make sure we\u2019re looking at fairness from this perspective, too. Ultimately what matters is, <i>does this work for me?</i> \u2014 and not just <i>me</i>, the person who\u2019s making this technology, but <i>me</i>, as in anyone who comes across it.\u201d</p><p>\u201cDeveloping a scale for this isn\u2019t just an AI or technology problem, but a social-technical problem,\u201d Dr. Heldreth says. \u201cIt\u2019s important that we understand how skin tone inequality can show up in the technology we use and importantly, do our best to avoid reproducing the colorism that exists. Fairness is contextual and uniquely experienced by each individual, so it\u2019s important to center this problem on the people who will ultimately be affected by the choices we make. Therefore, doing this right requires us to take a human-centered approach because this is a human problem.\u201d</p><p>\u201cConnecting the technical to the human is the challenge here,\u201d Dr. Ricco says. \"The groups we test should be influenced by the ways in which individuals experience technology differently, not purely decided based on mathematical convenience.\u201d</p><p>If it sounds like an intricate process, that\u2019s because it is. \u201cOur goal is not to tackle all of this complexity at once, but instead learn deeply about what each piece of research is telling us and put together the puzzle pieces,\u201d Dr. Heldreth says.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Ten circles in a row, ranging from dark to light.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Monkscale.max-1000x1000.png\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The Monk Skin Tone Scale</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>The Monk Skin Tone Scale</h3><p>The team knew piecing together that puzzle, and particularly thinking about how to define a range of skin tones, would be a wider effort that extended beyond Google.</p><p>So over the last year, they partnered with Dr. Monk to learn about and further test the scale for technology use cases. Dr. Monk\u2019s research focuses on how factors such as skin tone, race and ethnicity affect inequality. He has been surveying people about the kinds of ways that skin tone has played a role in their lives for a decade. \u201cIf you talk to people of color, if you ask them, \u2018How does your appearance matter in your everyday life? How does your skin color, your hair, how do they impact your life?\u2019 you find it really does matter,\u201d he says.</p><p>Dr. Monk began this research in part to build on the most prominently used skin tone scale, the Fitzpatrick Scale. Created in 1975 and made up of six broad shades, it was meant to be a jumping off point for medically categorizing skin type. The technology industry widely adopted it and applied it to skin tones and it became the standard. It\u2019s what most AI systems use to measure skin tone.</p><p>In comparison, the MST Scale is composed of 10 shades \u2014 a number chosen so as not to be too limiting, but also not too complex.</p></div></div><div class=\"block-pull_quote\"><div class=\"uni-pull-quote h-c-page\"><section class=\"h-c-grid\"><div class=\"uni-pull-quote__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"><div class=\"uni-pull-quote__inner-wrapper h-c-copy h-c-copy\"><q class=\"uni-pull-quote__text\">It\u2019s not just about this precise numeric value of skin tone. It\u2019s about giving people something they can see themselves in.</q> <cite class=\"uni-pull-quote__author\"><span class=\"uni-pull-quote__author-meta\"><strong class=\"h-u-font-weight-medium\">Dr. Ellis Monk</strong><br /></span></cite></div></div></section></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Together, the team and Dr. Monk surveyed thousands of adults in the United States to learn if people felt more represented by the MST Scale compared to other scales that have been used in both the machine learning and beauty industries. \u201cAcross the board, people felt better represented by the MST Scale than the Fitzpatrick Scale,\u201d Eye\u00e9 says, and this was especially true for less represented demographic groups.</p><p>\u201cWhat you\u2019re looking for is that subjective moment where people can see their skin tone on the scale,\u201d Dr. Heldreth says. \u201cTo see the results of our research demonstrate that there are other skin tone measures where more people see themselves better represented felt like we were making steps in the right direction, that we could really make a difference.\u201d</p><p>Of course, 10 points are not as comprehensive as scales that have 16, 40 or 110 shades. And for many use cases, like makeup, more is better. What was exciting about the MST Scale survey results was that the team found, even with 10 shades, participants felt the scale was equally representative as scales from the beauty industry with larger variety. \u201cThey felt that the MST Scale was just as inclusive, even with only 10 points on it,\u201d Eye\u00e9 says. A 10-point scale is also something that can be used during data annotation, whereas rating skin tone images using a 40-point scale would be an almost impossible task for raters to do reliably.</p><p>What is particularly exciting about this work is that it continues to highlight the importance of a sociotechnical approach to building more equitable tools and products. Skin tones are continuous, and can be defined and categorized in a number of different ways, the simplest being to pick equally spaced RGB values on a scale of light to dark brown. But taking such a technical approach leaves out the nuance of how different communities have been historically affected by colorism. A scale that is effective for measuring and reducing inconsistent experiences for more people needs to adequately reflect a wide range of skin-tones that represent a diversity of communities \u2013 this is where Dr. Monk\u2019s expertise and research proves particularly valuable.</p><p>Over the past two years, the team has shared their research with various other departments at Google. And work has begun on building annotation \u2014 or labeling \u2014 best practices based on the MST Scale, informed by expertise in computer vision, skin tone inequality and social cognition. Since perceptions of skin tones are subjective, it\u2019s incredibly important that the same interdisciplinary research that went into creating and validating the scale is also applied to how it is used.</p><p></p><h3>What\u2019s next</h3><p>One of the first areas in which this technology will be used is Google\u2019s image-based products. Until now, Google has largely relied on the Fitzpatrick Scale for photo AI. The MST scale is now being incorporated into products like Google Photos and Image Search, and will be expanded even more broadly in the coming months.</p><p>In addition to incorporating the MST Scale into Google products and sharing the 10 shades for anyone to use, Google and Dr. Monk are publishing their peer-reviewed research and expanding their research globally. Going through the research and peer review process has helped the team make sure their work is adding to the long history of multi-sector progress in this space and also offering new ideas in the quest for more inclusive AI.</p><p>Ultimately, we want the work to extend far beyond Google. The team is hopeful this is an industry starting point, and at the same time, they want to keep improving on it. \u201cThis is an evergreen project,\u201d Dr. Heldreth says. \u201cWe\u2019re constantly learning, and that\u2019s what makes this so exciting.\u201d The team plans to take the scale to more countries to learn how they interpret skin tone, and include those learnings in future iterations of the scale.</p><p>So the work continues. And while it\u2019s certainly a \u201cmassive scientific challenge,\u201d as Dr. Heldreth calls it, it\u2019s also a very human one because it\u2019s critical that tools we use to define skin tone ensure that more people see themselves represented and thus feel worthy of being seen. \u201cIt\u2019s not just about this precise numeric value of skin tone,\u201d Dr. Monk says. \u201cIt\u2019s about giving people something they can see themselves in.\u201d</p></div></div>",
            "pubdate": "Wed, 11 May 2022 09:32:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                11
            ],
            "email_sent": true
        },
        "How we build with and for people with disabilities": {
            "url": "https://blog.google/outreach-initiatives/accessibility/building-with-the-disability-community-2022/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p><i>Editor\u2019s note: Today is Global Accessibility Awareness Day. We\u2019re also sharing how we\u2019re making</i> <a href=\"https://blog.google/outreach-initiatives/education/global-accessibility-awareness-day--2022/\"><i>education more accessible</i></a><i>and launching a new</i><a href=\"http://blog.google/products/android/braille-display-talkback\"><i>Android accessibility feature</i></a><i>.</i></p><p>Over the past nine years, my job has focused on building accessible products and supporting Googlers with disabilities. Along the way, I\u2019ve been constantly reminded of how vast and diverse the disability community is, and how important it is to continue working alongside this community to build technology and solutions that are truly helpful.</p><p>Before delving into some of the accessibility features our teams have been building, I want to share how we\u2019re working to be more inclusive of people with disabilities to create more accessible tools overall.</p><h3>Nothing about us, without us</h3><p>In the disability community, people often say \u201cnothing about us without us.\u201d It\u2019s a sentiment that I find sums up what disability inclusion means. The types of barriers that people with disabilities face in society vary depending on who they are, where they live and what resources they have access to. No one\u2019s experience is universal. That\u2019s why it\u2019s essential to include a wide array of people with disabilities at every stage of the development process for any of our accessibility products, initiatives or programs.</p><p>We need to work to make sure our teams at Google are reflective of the people we\u2019re building for. To do so, last year we launched our <a href=\"https://careers.google.com/programs/people-with-disabilities/\">hiring site</a> geared toward people with disabilities \u2014 including our <a href=\"https://cloud.google.com/blog/topics/inside-google-cloud/google-cloud-launches-a-career-program-for-people-with-autism\">Autism Career Program</a> to further grow and strengthen our autistic community. Most recently, we helped launch the <a href=\"https://ndcc.simplifyhire.com/\">Neurodiversity Career Connector</a> along with other companies to create a job portal that connects neurodiverse candidates to companies that are committed to hiring more inclusively.</p><p>Beyond our internal communities, we also must partner with communities outside of Google so we can learn what is truly useful to different groups and parlay that understanding into the improvement of current products or the creation of new ones. Those partnerships have resulted in the creation of <a href=\"https://blog.google/outreach-initiatives/accessibility/project-relate/\">Project Relate</a>, a communication tool for people with speech impairments, the development of a <a href=\"https://blog.google/products/android/all-new-talkback/\">completely new TalkBack</a>, Android\u2019s built-in screen reader, and the <a href=\"https://blog.google/products/chromebooks/accessibility-features/\">improvement of Select-to-Speak</a>, a Chromebook tool that lets you hear selected text on your screen spoken out loud.</p><h3>Equitable experiences for everyone</h3><p>Engaging and listening to these communities \u2014 inside and outside of Google \u2014 make it possible to create tools and features like the ones we\u2019re sharing today.</p><p>The ability to add alt-text, which is a short description of an image that is read aloud by screen readers, directly to images sent through Gmail starts rolling out today. With this update, people who use screen readers will know what\u2019s being sent to them, whether it\u2019s a GIF celebrating the end of the week or a screenshot of an important graph.</p><p>Communication tools that are inclusive of everyone are especially important as teams have shifted to fully virtual or hybrid meetings. Again, everyone experiences these changes differently. We\u2019ve heard from some people who are deaf or hard of hearing, that this shift has made it easier to identify who is speaking \u2014 something that is often more difficult in person. But, in the case of people who use ASL, we\u2019ve heard that it can be difficult to be in a virtual meeting and simultaneously see their interpreter and the person speaking to them.</p><p>Multi-pin, a new feature in Google Meet, helps solve this. Now you can pin multiple video tiles at once, for example, the presenter\u2019s screen and the interpreter\u2019s screen. And like many accessibility features, the usefulness extends beyond people with disabilities. The next time someone is watching a panel and wants to pin multiple people to the screen, this feature makes that possible.</p><p>We've also been working to make video content more accessible to those who are blind or low-vision through audio descriptions that describe verbally what is on the screen visually. All of our English language YouTube Originals content from the past year \u2014 and moving forward \u2014 will now have English audio descriptions available globally. To turn on the audio description track, at the bottom right of the video player, click on \u201cSettings\u201d, select \u201cAudio track\u201d, and choose \u201cEnglish descriptive\u201d.</p><p>For many people with speech impairments, being understood by the technology that powers tools like voice typing or virtual assistants can be difficult. In 2019, we started work to change that through Project Euphonia, a research initiative that works with community organizations and people with speech impairments to create more inclusive speech recognition models. Today, we\u2019re expanding Project Euphonia\u2019s research to include four more languages: <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfroo5csa5ZZsx9ysjS8vO9BihmV6SLnKUCNNKdA8oSgt6zWQ/viewform\">French</a>, <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSeBFmyc9hkc7e6Llm0-2VRIpz5j7iu5Rwfpxg-F_8IvuQMwDg/viewform\">Hindi</a>, <a href=\"https://docs.google.com/forms/d/e/1FAIpQLScSEbxXZsfZbIUNmm0TlkWvF3C_gPcpucTzGm36TsBSCLV3oA/viewform?resourcekey=0-quzTBS9bMQ2zL5fXh3IjDA\">Japanese</a> and <a href=\"https://docs.google.com/forms/d/e/1FAIpQLSc9tkmL5VwSP88nGHULo6NauivSLgEBxgR3vO9knc1P4cvsUA/viewform?resourcekey=0-nNMgUv0K876UAOCbu7i2zw\">Spanish</a>. With this expansion, we can create even more helpful technology for more people \u2014 no matter where they are or what language they speak.</p><p>I\u2019ve learned so much in my time working in this space and among the things I\u2019ve learned is the absolute importance of building right alongside the very people who will most use these tools in the end. We\u2019ll continue to do that as we work to create a more inclusive and accessible world, both physically and digitally.</p></div></div>",
            "pubdate": "Thu, 19 May 2022 13:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                19
            ],
            "email_sent": true
        },
        "Building a more helpful browser with machine learning": {
            "url": "https://blog.google/products/chrome/building-a-more-helpful-browser-with-machine-learning/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>At Google we use technologies like machine learning (ML) to build more useful products \u2014 from filtering out <a href=\"https://cloud.google.com/blog/products/workspace/an-overview-of-gmails-spam-filters\">email spam</a>, to keeping maps <a href=\"https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/\">up to date</a>, to offering more relevant <a href=\"https://blog.google/products/search/how-ai-powers-great-search-results/\">search results</a>. Chrome is no exception: We use ML to make <a href=\"https://blog.google/outreach-initiatives/accessibility/get-image-descriptions/\">web images</a> more accessible to people who are blind or have low vision, and we also generate <a href=\"https://blog.google/products/chrome/live-caption-chrome/\">real-time captions</a> for online videos, in service of people in noisy environments, and those who are hard of hearing.</p><p>This work in Chrome continues, so we wanted to share some recent and future ML improvements that offer a safer, more accessible and more personalized browsing experience. Importantly: these updates are powered by on-device ML models, which means your data stays private, and never leaves your device.</p><h3><b>More peace of mind, less annoying prompts</b></h3><p><a href=\"https://safebrowsing.google.com/\">Safe Browsing in Chrome</a> helps protect billions of devices every day, by showing warnings when people try to navigate to dangerous sites or download dangerous files (see the big red example below). Starting in March of this year, we rolled out a new ML model that identifies 2.5 times more potentially malicious sites and phishing attacks as the previous model \u2013 resulting in a safer and more secure web.</p><p>To further improve the browsing experience, we\u2019re also evolving how people interact with web notifications. On the one hand, page notifications help deliver updates from sites you care about; on the other hand, notification permission prompts can become a nuisance. To help people browse the web with minimal interruption, Chrome predicts when permission prompts are unlikely to be granted based on how the user previously interacted with similar permission prompts, and silences these undesired prompts. In the next release of Chrome, we\u2019re launching an ML model that makes these predictions entirely on-device.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Two separate images side by side. The first on the left is a smartphone showing a red screen and a warning message about phishing. The image on the right shows a Chrome browser window showing a pop-up message saying \u201cNotifications blocked\u201d.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Screen_Shot_2022-06-09_at_11.39.00_AM.max-1000x1000.png\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>With the next release of Chrome, this is what you will see if a phishing attempt is detected (Left) and Chrome will show permission requests quietly when the user is unlikely to grant them (Right).</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3><b>Finding what's important, always in your language</b></h3><p>Earlier this year we launched <a href=\"https://blog.google/products/chrome/finding-answers-gets-better-chrome/\">Journeys</a> to help people retrace their steps online. For example: You might spend weeks planning a national park visit \u2013 researching attractions, comparing flights and shopping for gear. With ML and Journeys, Chrome brings together the pages you\u2019ve visited about a given topic, and makes it easy to pick up where you left off (vs. scr o o o l l ling through your browser history).</p><p>When you return to those hiking boots and camping guides, we\u2019re also using ML to make those websites available in your preferred language. In particular, we\u2019ve launched an updated language identification model to figure out the language of the page, and whether it needs to be translated to match your preferences. As a result, we\u2019re seeing tens of millions more successful translations every day.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"A Chrome browser showing Journeys related to travel. The user can see a cluster of recent searches they did related to a trip to Yosemite.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Chrome-Blog-Journeys_V4_YGdhgQw.max-1000x1000.png\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The Journeys feature of Chrome groups together your search history based on topic or intent.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3><b>A browser built just for you</b></h3><p>Maybe you like to read news articles in the morning \u2013 phone in one hand, cereal spoon in the other \u2013 so you share lots of links from Chrome. Or maybe voice search is more your thing, as you sneak in a few questions during your transit ride to work. Either way, we want to make sure Chrome is meeting you where you\u2019re at, so in the near future, we\u2019ll be using ML to adjust the toolbar in real-time \u2013 highlighting the action that\u2019s most useful in that moment (e.g., share link, voice search, etc.). Of course, you\u2019ll be able to customize it manually as well.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"A Chrome browser with a highlighted square around an icon to the right of the address bar. At the top is a share icon, and at the bottom is a microphone icon.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/VoiceShare_toolbar.max-1000x1000.png\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The toolbar in Chrome on Android will adapt based on your needs.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our goal is to build a browser that\u2019s genuinely and continuously helpful, and we\u2019re excited about the possibilities that ML provides. At the end of the day, though, your experience is what really matters, so please tweet <a href=\"https://twitter.com/googlechrome\">@googlechrome</a> to send us your feedback.</p></div></div>",
            "pubdate": "Thu, 09 Jun 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        },
        "How AI creates photorealistic images from text": {
            "url": "https://blog.google/technology/research/how-ai-creates-photorealistic-images-from-text/",
            "description": "<div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"Pictures of puppy in a nest emerging from a cracked egg. Photos overlooking a steampunk city with airships. Picture of two robots having a romantic evening at the movies.\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Final_Hero_Image_Imagen_Parti.max-1000x1000.png\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Have you ever seen a puppy in a nest emerging from a cracked egg? What about a photo that\u2019s overlooking a steampunk city with airships? Or a picture of two robots having a romantic evening at the movies? These might sound far-fetched, but a novel type of machine learning technology called text-to-image generation makes them possible. These models can generate high-quality, photorealistic images from a simple text prompt.</p><p>Within Google Research, our scientists and engineers have been exploring text-to-image generation using a variety of AI techniques. After a lot of testing we recently announced two new text-to-image models \u2014 <a href=\"https://imagen.research.google/\">Imagen</a> and <a href=\"https://parti.research.google/\">Parti</a>. Both have the ability to generate photorealistic images but use different approaches. We want to share a little more about how these models work and their potential.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>How text-to-image models work</h3><p>With text-to-image models, people provide a text description and the models produce images matching the description as closely as possible. This can be something as simple as \u201can apple\u201d or \u201ca cat sitting on a couch\u201d to more complex details, interactions and descriptive indicators like \u201ca cute sloth holding a small treasure chest. A bright golden glow is coming from the chest.\u201d</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col-l--6 h-c-grid__col--8 h-c-grid__col-l--offset-3 h-c-grid__col--offset-2\"><img alt=\"A picture of a cute sloth holding a small treasure chest. A bright golden glow is coming from the chest\" class=\"article-image--large\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Sloth_Image.max-1000x1000.png\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In the past few years, ML models have been trained on large image datasets with corresponding textual descriptions, resulting in higher quality images and a broader range of descriptions. This has sparked major breakthroughs in this area, including Open AI\u2019s <a href=\"https://openai.com/dall-e-2/\">DALL-E 2</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>How Imagen and Parti work</h3><p>Imagen and Parti build on previous models. Transformer models are able to process words in relationship to one another in a sentence. They\u00a0are foundational to how we represent text in our text-to-image models. Both models also use a new <a href=\"https://openreview.net/forum?id=qw8AKxfYbI\">technique</a> that helps generate images that more closely match the text description. While Imagen and Parti use similar technology, they pursue different, but complementary strategies.</p><p>Imagen is a Diffusion model, which learns to convert a pattern of random dots to images. These images first start as low resolution and then progressively increase in resolution. Recently, Diffusion models have seen success in both <a href=\"https://iterative-refinement.github.io/palette/\">image</a> and <a href=\"https://wavegrad.github.io/\">audio</a> tasks like enhancing image resolution, recoloring black and white photos, editing regions of an image, uncropping images, and text-to-speech synthesis.</p><p>Parti\u2019s approach first <a href=\"https://ai.googleblog.com/2022/05/vector-quantized-image-modeling-with.html\">converts</a> a collection of images into a sequence of code entries, similar to puzzle pieces. A given text prompt is then <a href=\"https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html\">translated</a> into these code entries and a new image is created. This approach takes advantage of existing research and infrastructure for large language models such as <a href=\"https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html\">PaLM</a> and is critical for handling long, complex text prompts and producing high-quality images.</p><p>These models have many limitations. For example, neither can reliably produce specific counts of objects (e.g. \u201cten apples\u201d), nor place them correctly based on specific spatial descriptions (e.g. \u201ca red sphere to the left of a blue block with a yellow triangle on it\u201d). Also, as prompts become more complex, the models begin to falter, either missing details or introducing details that were not provided in the prompt. These behaviors are a result of several shortcomings, including lack of explicit training material, limited data representation, and lack of 3D awareness. We hope to address these gaps through broader representations and more effective integration into the text-to-image generation process.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Taking a responsible approach to Imagen and Parti</h3><p>Text-to-image models are exciting tools for inspiration and creativity. They also come with risks related to disinformation, bias and safety. We\u2019re having discussions around Responsible AI practices and the necessary steps to safely pursue this technology. As an initial step, we\u2019re using easily identifiable watermarks to ensure people can always recognize an Imagen- or Parti-generated image. We\u2019re also conducting experiments to better understand biases of the models, like how they represent people and cultures, while exploring possible mitigations. The <a href=\"https://arxiv.org/pdf/2205.11487.pdf\">Imagen</a> and <a href=\"https://parti.research.google/paper\">Parti</a> papers provide extensive discussion of these issues.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>What\u2019s next for text-to-image models at Google</h3><p>We will push on new ideas that combine the best of both models, and expand to related tasks such as adding the ability to interactively generate and edit images through text. We\u2019re also continuing to conduct in-depth comparisons and evaluations to align with our <a href=\"https://ai.google/principles/\">Responsible AI Principles</a>. Our goal is to bring user experiences based on these models to the world in a safe, responsible way that will inspire creativity.</p></div></div>",
            "pubdate": "Wed, 22 Jun 2022 17:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                22
            ],
            "email_sent": true
        },
        "Reducing gender-based harms in AI with Sunipa Dev": {
            "url": "https://blog.google/technology/ai/reducing-gender-based-harms-in-ai-with-sunipa-dev/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Natural language processing (NLP) is a form of artificial intelligence that teaches computer programs how to take in, interpret, and produce language from large data sets. For example, grammar checkers use NLP to come up with grammar suggestions that help people write grammatically correct phrases. But as <a href=\"https://ai.google/principles\">Google\u2019s AI Principles</a> note, it\u2019s sometimes necessary to have human intervention to identify risks of unfair bias.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Sunipa Dev is a research scientist at Google who focuses on Responsible AI. Some of her work focuses specifically on ways to evaluate unfair bias in NLP outcomes, reducing harms for people with queer and non-binary identities. Sunipa\u2019s <a href=\"https://aclanthology.org/2021.emnlp-main.150.pdf\">work</a> was recently featured at a <a href=\"https://facctconference.org/2022/acceptedcraft.html#colab\">workshop</a> at the ACM Fairness, Accountability, and Transparency (FAcct) <a href=\"https://facctconference.org/2022/acceptedcraft.html#colab\">conference</a> in Seoul, Korea.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In our interview, she emphasizes that her work is achievable only through forging collaborative partnerships between researchers, engineers, and AI practitioners with everyday users and communities.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>What inspired you to take on this career path?</b></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>While working on my PhD at the University of Utah, I explored research questions such as, \u201cHow do we evaluate NLP tech if they contain biases?\u201d As language models evolved, our questions about potential harms did, too. During my postdoc work at UCLA, we ran a study to evaluate challenges in various language models by surveying respondents who identified as non-binary and had some experience with AI. With a focus on gender bias, our respondents helped us understand that experiences with language technologies cannot be understood in isolation. Rather, we must consider how these technologies intersect with systemic discrimination, erasure, and marginalization. For example, the harm of misgendering by a language technology can be compounded for trans, non-binary, and gender-diverse individuals who are already fighting against society to defend their identities. And when it\u2019s in your personal space, like on your devices while emailing or texting, these small jabs can build up to larger psychological damage.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>What is your current role at Google?</b></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>I am currently a Research Scientist at the Responsible AI - Human Centered Technology team. In my current role, I am working to build a better understanding of how to avoid unfair bias in AI language models across different cultures and geographies, aligned with Google\u2019s AI Principles.</p><p>This is a challenge because language changes, and so do cultures and regional laws as we move from one place to another. This can all impact how people express themselves, what identities they choose and how they experience discrimination on a daily basis. Gender bias can manifest in entirely different ways in different parts of the world. In some of my ongoing work that focuses on a non-Western point of view, we are working with social scientists and NGOs in India while engaging with local communities. We are using the voices of many people who are living in a specific region and asking, \u201cWhat are the biases prevalent in their society?\u201d</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>What is gender bias in NLP?</b></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Written text and training data for language technologies can lack representation or misrepresent different gender identities; this can reflect social biases. As a result, some NLP technologies can reinforce gender stereotypes and slurs, erase people\u2019s gender identities, or have reduced quality of service for marginalized communities. What drives me in my work is my goal to make language technologies more inclusive and usable.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>Why does this matter for AI?</b></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Gender can be such an integral part of someone's identity, and having that wrongly assumed by an AI system can be triggering, unfair, and harmful. We need to work towards systems and societies that do not encode unfair biases and harmful stereotypes in order to break out of the cycle of perpetuating harms of stereotyping, misgendering, and erasure.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How can people who are not researchers, engineers or AI practitioners engage in this work?</b></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>A very direct way is for people to report potential harms as bugs within products they use. People can also participate in open discussions in workshops, panels and town halls. These are all helpful ways to build inclusive AI.</p><p>I want to emphasize, however, that the onus can\u2019t only be on the user. It\u2019s also on the side of the researcher, engineer and AI practitioner. The goal is to create a continuous feedback loop between humans and machines, with real people stepping in to ensure the creation of more responsible AI. As AI practitioners, we need to work with the people we\u2019re trying to serve and have users collaborate with us to tell us what we need to do better.</p></div></div>",
            "pubdate": "Wed, 29 Jun 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                29
            ],
            "email_sent": true
        },
        "Mahima Pushkarna is making data easier to understand": {
            "url": "https://blog.google/technology/research/mahima-pushkarna-interview/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Five years ago, information designer Mahima Pushkarna joined Google to make data easier to understand. As a senior interaction designer on the <a href=\"http://pair.withgoogle.com/\">People + AI Research</a> (PAIR) team, she designed <a href=\"https://pair-code.github.io/datacardsplaybook/\">Data Cards</a> to help everyone better understand the contexts of the data they are using. The Data Cards Playbook puts <a href=\"https://ai.google/principles/\">Google\u2019s AI Principles</a> into practice by providing opportunities for feedback, relevant explanations and appeal.</p><p>Recently, Mahima\u2019s <a href=\"https://arxiv.org/abs/2204.01075\">paper</a> on Data Cards (co-written with Googlers Andrew Zaldivar and Oddur Kjartansson) was accepted to the ACM Conference on Fairness, Accountability and Transparency (<a href=\"https://facctconference.org/\">ACM FAccT</a>). Let\u2019s catch up with her and find out more about what brought her to Google.</p><p><b>How did your background lead you to the work you\u2019re doing now?</b></p><p>I've always been fascinated by conjuring up solutions to things. The kind of questions that I\u2019ve found meaningful are those that are never truly solved, or never have one correct answer. (The kind of questions that exasperate us!) Those have been the problems I am always drawn towards.</p><p>Early in my career, I realized the power in visualizing data, but spreadsheets were intimidating. I wondered how design could make communicating complexity easier. So I found myself in grad school in Boston studying information design and data visualization. I focused on how people experience data and how our relationships to each other and our contexts are mediated.</p><p>I joined Google Brain as the first visual designer in a full-time capacity, though I had no background in artificial intelligence or machine learning \u2014 this was the deep end of the pool. This opened up the space to explore human-AI interaction, and make AI more accessible to a broader class of developers. At PAIR, my work focuses on making information experiences more meaningful for developers, researchers and others who build AI technologies.</p><p><b>What\u2019s it like to have a unique background as a designer on a technical AI research team?</b></p><p>When you're an engineer and immersed in building technology, it's easy to assume everyone has a similar experience to your own \u2014 especially when you\u2019re surrounded by peers who share your expertise. The actual user experience is very personal and varies drastically across users and contexts. That particular clarity is what designers bring to the table.</p><p>I\u2019ve been able to engage my engineering and research colleagues with simple, people-centered questions right in the very beginning. How are people using an AI tool? What are they learning from it? Who else might be involved in the conversation? Do they have the proficiency we assume they have?</p><p>Pull quote: \u201cIdentifying what we don\u2019t know about data is just as important as articulating what we do know.\u201d</p><p><b>How did you begin designing Data Cards?</b></p><p>This project started when I was working on another visualization toolkit, <a href=\"http://facets.dev/\">Facets</a>, to communicate the skews and imbalances within datasets to help machine learning practitioners make informed decisions. At the time, transparency was a moving target. Andrew, Tulsee Doshi and I started to proactively think about fairness in data, and saw a huge gap in the documentation of human decisions that dot a dataset's lifecycle.</p><p>This \u201cinvisible\u201d information shapes how we use data and the outcomes of models trained on them. For example, a model trained on a dataset that captures age in just two or three buckets will have very different outcomes compared to a dataset with ten buckets. The goal of Data Cards is to make both visible and invisible information about datasets available and simple to understand, so people from a variety of backgrounds can knowledgeably make decisions.</p><p>As we cover in our <a href=\"https://arxiv.org/abs/2204.01075\">FAccT paper</a>, Andrew and Oddur and I arrived at two insights. The first is that identifying what we don\u2019t know about data is just as important as articulating what we do know. In capturing these nuances, it is possible to narrow those knowledge gaps before even collecting data. The second thing that surprised us was the sheer number of people involved in a dataset\u2019s life cycle, and how fragile knowledge is. Context is easily lost in translation both between and within teams, across documents, emails, people and time.</p><p>Data Cards stand on the shoulders of giants, like <a href=\"https://arxiv.org/abs/1803.09010\">Data Sheets</a> (Gebru, et al.) and <a href=\"https://arxiv.org/abs/1810.03993\">Model Cards</a> (Mitchell et al.). We've been immensely lucky to have had the support of many original authors on these seminal papers that have paved our path to FAccT.</p><p><b>How do you hope the paper is used across the tech industry?</b></p><p>Imagine a world in which finding verifiable information about the motivations of a dataset\u2019s creators or performance of a model is as easy as learning about the ethical beliefs of a celebrity or the rating of a movie. Our vision for Data Cards is that they become a cultural mainstay \u2014 invisible, but their absence would be missed by ML practitioners.</p><p>In this paper, we introduce frameworks that other teams can use in their work. Alongside that, we\u2019ve open-sourced the <a href=\"https://pair-code.github.io/datacardsplaybook/\">Data Cards Playbook</a>, so we're trying to lower the barrier to access in every way possible.</p></div></div>",
            "pubdate": "Thu, 30 Jun 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                30
            ],
            "email_sent": true
        },
        "An update on our work in responsible innovation": {
            "url": "https://blog.google/technology/ai/an-update-on-our-work-in-responsible-innovation/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Over the last year, we\u2019ve seen artificial intelligence (AI) systems advance our work in areas like <a href=\"https://blog.google/products/pixel/image-equity-real-tone-pixel-6-photos/\">inclusive product development</a> and support for <a href=\"https://blog.google/products/maps/how-ai-and-imagery-build-self-updating-map/\">small businesses</a> and <a href=\"https://grow.google/certificates/interview-warmup/\">job seekers</a>. We\u2019ve also seen its potential to be helpful in addressing major global needs \u2014 like <a href=\"https://blog.google/technology/ai/expanding-our-ml-based-flood-forecasting/\">forecasting</a> and planning <a href=\"https://blog.google/around-the-globe/google-africa/using-ai-to-map-africas-buildings/\">humanitarian responses</a> to natural disasters, <a href=\"https://blog.google/intl/en-au/company-news/outreach-initiatives/protecting-our-reef-with-csiro/\">addressing global environmental</a> challenges, and delivering groundbreaking <a href=\"https://www.nature.com/articles/d41586-021-02025-4\">scientific research</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI is exciting \u2014 both from a technical perspective and when considering its underlying social benefits. And yet, to fully realize AI\u2019s potential, it must be developed responsibly, thoughtfully and in a way that gives deep consideration to core ethical questions. After all, the promise of great reward inherently involves risk \u2014 and we\u2019re committed to ethically developing AI in a way that is socially beneficial.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our <a href=\"http://ai.google/principles\">AI Principles</a> guide how we integrate AI research into Google\u2019s products and services and engage with external partners. Internally, we implement the Principles, every day, through education programs, AI ethics reviews and technical tools. There are more than 200 Googlers across the company whose full-time roles are to operationalize responsible practices for developing AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re committed to sharing our lessons learned so others across the industry can learn, too (see our posts from <a href=\"https://www.blog.google/technology/ai/google-ai-principles-updates-six-months/\">2018,</a> <a href=\"https://www.blog.google/technology/ai/responsible-ai-principles/\">2019</a>, <a href=\"https://blog.google/technology/ai/update-work-ai-responsible-innovation/\">2020</a> and <a href=\"https://blog.google/technology/ai/update-our-progress-responsible-ai-innovation/#:~:text=Over%20the%20past%20year%2C%20responsibly,and%20protected%20wildlife%20after%20bushfires.\">2021</a>, and our in-depth annual <a href=\"https://ai.google/responsibilities/review-process/#:~:text=the%20current%20process.-,annual%20updates,-AI%20Principles%202021\">AI Principles Progress Updates</a>).</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Internal education</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s important to craft principles, but putting them into practice requires both training and constant dialogue.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Launched in late 2019, to date more than 32,000 employees across Google have engaged in AI Principles training. Given our growing understanding of effective hybrid and remote learning, we continue to expand and modify the courses. For example, this year we adapted our popular four-part Tech Ethics self-study course to a one-part deep dive based on Googler feedback. Similarly, we launched the <a href=\"https://blog.google/technology/ai/crossword-puzzle-big-purpose/\">Responsible Innovation Challenge</a> \u2014 taken by more than 13,000 employees \u2014 as a series of engaging online puzzles, quizzes and games to raise awareness of the AI Principles and measure employees' retention of ethical concepts, such as avoiding unfair bias.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We also piloted a new Moral Imagination workshop, a two-day, live-video immersive set of activities for product teams to walk through the ethical implications of potential AI products. To date, 248 Googlers across 23 Google product and research teams have taken the workshop, resulting in deeper, ongoing AI ethics consultations on product development.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As we develop internal training, we\u2019re committed to incorporating the input of both Googlers and outside experts. This year, when we launched a live workshop to educate our internal user experience and product teams on the concept of <a href=\"https://blog.google/inside-google/googlers/ask-techspert-how-do-machine-learning-models-explain-themselves/\">AI explainability</a>, we first piloted the workshop with outside experts at the international <a href=\"https://summit.ttclabs.net/\">Trust, Transparency and Control Labs</a> summit in May.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We believe this approach complements programs like our internal AI Principles Ethics Fellows program, a six-month fellowship that this year involved Googlers from 17 different global offices. We also just launched a version of the fellowship program tailored for senior leaders.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Putting the Principles into practice</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our approach to responsible AI innovation starts early, before teams plan a new AI application. When a team starts to build a machine learning (ML) model, dataset or product feature, they can attend office hours with experts to ask questions and engage in analyses using responsible AI <a href=\"https://www.tensorflow.org/responsible_ai?hl=en\">tools</a> that Google develops, or seek adversarial proactive fairness <a href=\"https://www.blog.google/inside-google/googlers/meet-3-women-who-test-google-products-fairness/\">(ProFair) testing.</a> Pre-launch, a team then can request an AI Principles review.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI Principles reviewers are in place to implement a structured assessment to identify, measure and analyze potential risk of harm. The risk rating focuses on the extent to which people and society may be impacted if solutions did not exist or were to fail. Reviewers also consider a growing body of lessons from thousands of previous AI Principles reviews conducted since 2019.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>When reviewers find medium- to high-risk issues, such as product exclusion or a potential privacy or security concern, they work with the teams to address these issues. Reviews either result in an approval, approval with conditions or recommendations, or non-approval. New AI applications that might affect multiple product areas are escalated to the Advanced Technology Review Council \u2014 a group of senior research, product and business leaders who make the final decision.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To supplement the expertise of our internal AI Principles group members, we often incorporate trusted external advisors. For example, a team was incorporating AI to help build a <a href=\"https://dynamicworld.app/\">near real-time dataset</a> to enable reliable measurement of global land cover for environmental and social benefit. They submitted for <a href=\"https://ai.google/static/documents/case-study-dynamic-world.pdf\">AI Principles review</a> and then collaborated with the review team to design several safeguards. The review team also worked with third-party experts at the <a href=\"https://www.wri.org/about\">World Resources Institute</a> and <a href=\"https://www.bsr.org/en/about\">BSR</a>. Following the example of the European Commission\u2019s <a href=\"https://www.copernicus.eu/en\">Copernicus mission\u2019s</a> open <a href=\"https://sentinel.esa.int/documents/247904/690755/sentinel_data_legal_notice\">data and services</a> terms, the product team applied open data principles, making the ML model\u2019s <a href=\"https://doi.pangaea.de/10.1594/PANGAEA.933475\">training</a> and <a href=\"https://doi.org/10.5281/zenodo.4766508\">test data</a> used to create the dataset, as well as the dataset itself, freely available under CC-BY-4.0, and the <a href=\"https://github.com/google/dynamicworld\">model available on Github</a> under an Apache 2.0 license. We recently released a <a href=\"https://ai.google/static/documents/case-study-dynamic-world.pdf\">Codelab</a> for developers to walk through the ethics review process and apply learnings to their own projects.</p></div></div><div class=\"block-video\"><div class=\"h-c-page h-c-page--mobile-full-bleed\"><div class=\"h-c-grid\"><div class=\"h-c-grid__col h-c-grid__col-l--10 h-c-grid__col-l--offset-1\"><div class=\"article-module uni-article-video uni-article-video--body\"><div class=\"uni-article-video__embed-container hidden\"><div id=\"uni-article-yt-player-S75NcDqbPbI\"></div></div><figure><a class=\"h-c-video h-c-video--marquee uni-article-video__custom-wrapper\" tabindex=\"0\"><div class=\"uni-article-video__aspect-image\"><img alt=\"A video explaining Google's AI Principles Review process\" src=\"https://img.youtube.com/vi/S75NcDqbPbI/maxresdefault.jpg\" /><div class=\"uni-article-video__dimmer\"></div><svg class=\"uni-article-video__play-button--active\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button_no_hole\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><svg class=\"uni-article-video__play-button\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_play_button\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><div class=\"uni-article-video__duration loading\"><svg class=\"uni-article-video__duration-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#yt_video_duration\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg><span class=\"uni-article-video__duration-time\">10:25</span></div></div></a><p>Google\u2019s AI Principles Review Process: How we assess new AI research and applications for alignment with our Principles</p></figure></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Projects such as research methods for evaluating misinformation and datasets that need more diverse representation tend to receive conditions to proceed toward a launch. A recurring condition given to teams is to engage in ProFair testing with people from a diversity of backgrounds, often in partnership with our central Product Inclusion and Equity team. This year, the number of ProFair consultations increased annually by 100%. A recurring approach is to create and release detailed documentation in the form of<a href=\"https://www.youtube.com/watch?v=IYK6fkODXNU\">data cards</a> and <a href=\"https://modelcards.withgoogle.com/about\">model cards</a> for transparency and accountability. The number of AI Principles reviews with model or data card mitigations increased 68% in the last year.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As we\u2019ve stated, we\u2019ve embedded customized AI governance and review committees within certain product areas (like Cloud and Health). As a result, both the Health Ethics Committee and Cloud make decisions with specialized expertise, such as establishing policies for potentially winding down the <a href=\"https://www.google.com/covid19/mobility/\">Covid-19 Community Mobility Reports</a> and the <a href=\"https://ai.googleblog.com/2021/10/an-ml-based-framework-for-covid-19.html\">Covid-19 Forecaster</a>, respectively, if situations arise that might cause the data quality to degrade. This year, we extended this specialized approach and created a dedicated consumer hardware AI Principles review process.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>It\u2019s important to note that product teams across Google engage in everyday responsible AI practices even if not in formal reviews. <a href=\"https://blog.youtube/inside-youtube/inside-responsibility-whats-next-on-our-misinfo-efforts/\">YouTube</a> is leveraging a more targeted mix of classifiers, keywords in additional languages, and information from regional analysts. This work is a result of collaboration with our researchers who focus on new tools for AI fairness. The Photos team participated in an <a href=\"https://blog.google/technology/ai/update-our-progress-responsible-ai-innovation/#:~:text=equitable%20ai%20research%20roundtables%20(earr)%2C\">Equitable AI Research Roundtable (EARR)</a> with a group of external advisors on potential fairness considerations. And the Gboard team deployed a new, <a href=\"https://ai.googleblog.com/2021/12/a-scalable-approach-for-partially-local.html\">privacy-by-design</a> approach to federated machine learning. These examples did not stem from AI Principles reviews, but reflect the adoption of the AI Principles across Google.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Tools and research</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In early 2022, to offer easier access to our publications on responsible AI, we curated an <a href=\"https://research.google/pubs/?collection=responsible-ai\">external collection</a> of more than 200 research papers focused on the topic. We continue to launch, refine and consolidate technical resources, including proactive tools like:</p><ul><li>The <a href=\"https://skintone.google/\">Monk Skin Tone Scale</a>, developed by Harvard University Sociology Professor Dr. Ellis Monk. The scale offers a spectrum of skin tones from all around the world for use in evaluating and addressing fairness considerations in AI.</li><li>The <a href=\"https://knowyourdata.withgoogle.com/\">Know Your Data</a> tool (KYD), which helps developers with tasks such as quickly identifying issues in fairness, and which has integrated the Monk Scale to help developers examine skin tone data for unfair bias.</li><li>The <a href=\"https://pair-code.github.io/lit/\">Language Interpretability Tool</a>, or LIT, to help developers probe an ML model, now with a <a href=\"https://arxiv.org/abs/1711.11279\">new method</a> to better understand, test and debug its behaviors.</li><li><a href=\"https://www.tensorflow.org/responsible_ai/model_remediation/counterfactual/guide/counterfactual_overview?hl=en\">Counterfactual Logit Pairing</a>, which helps ensure that a model\u2019s prediction doesn\u2019t change when sensitive attributes or identity terms referenced in an example are removed or replaced, now added to the <a href=\"https://www.tensorflow.org/responsible_ai/model_remediation\">TensorFlow Model Remediation Library</a> (see the <a href=\"https://arxiv.org/abs/1809.10610\">research paper</a> for more).</li><li>And to help teams measure their progress against the AI Principles, we\u2019re piloting an internal tool to help teams assess how ML models were developed in accordance with emerging smart practices, previous reviews, and our growing body of ethics, fairness, and human-rights work.</li></ul></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Many responsible AI tools developed by researchers are actively in use by product teams at Google. For example, Photos, Pixel and Image Search are leveraging the Monk Skin Tone Scale.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>External engagement</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Ensuring the responsible development and deployment of AI is an ongoing process. We believe it should be a collaborative one, too, so we remain deeply engaged with governments across Europe, the Middle East and Africa, Latin America, Asia Pacific, and the U.S. to advocate for AI regulation that supports innovation around the world for businesses of all sizes. We share our approach to responsible AI and <a href=\"https://ai.google/static/documents/google-response-to-nist-ai-risk-management-framework-rfi.pdf\">recommendations</a>, <a href=\"https://ec.europa.eu/info/law/better-regulation/have-your-say/initiatives/12527-Artificial-intelligence-ethical-and-legal-requirements/F2662492_en\">comments</a> and <a href=\"https://ai.google/static/documents/google-ostp-biometrics-rfi.pdf\">responses</a> to open requests for information. We also initiated and are leading an effort with the <a href=\"https://www.iso.org/home.html\">International Standards Organization</a> (ISO/IEC PWI TS 17866) to share best practice guidance for the development of AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As these efforts look toward the future, Responsible AI needs to be supported across industries today. So for current Google Cloud Partners and customers seeking best practices to help with the responsible implementation and AI governance in their organization, we added responsible AI prerequisites to the Google Cloud Partner Advantage <a href=\"https://cloud.google.com/find-a-partner/?specializations=Machine%20Learning%20-%20Services\">ML Specialization</a>, including a newly-released training, \u201c<a href=\"https://www.cloudskillsboost.google/course_templates/388\">Applying AI Principles with Google Cloud</a>.\u201d</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>To help nurture the next generation of responsible AI practitioners, we launched a free <a href=\"https://blog.google/technology/ai/discover-ai-in-daily-life/\">introduction</a> to AI and machine learning for K-12 students. And we continue to develop an external Responsible Innovation Fellowship program in the U.S. for students at Historically Black Colleges and Universities (HBCUs).</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our approach to responsible innovation also means keeping an eye on emerging markets where AI is being developed. We launched a new <a href=\"https://blog.google/technology/ai/investing-in-eastern-europes-ai-future/\">AI research center in Bulgaria</a> and expanded <a href=\"https://blog.google/around-the-globe/google-africa/supporting-growth-in-africa/\">support for African entrepreneurs</a> whose businesses use AI through our <a href=\"https://startup.google.com/accelerator/africa/\">Google for Startups Accelerator: Africa</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>The examples we\u2019re sharing today are a sampling of our ongoing commitment to responsible innovation. They also reflect our ability to change and keep setting a high bar for trustworthy AI standards for our company. We remain dedicated to sharing helpful information on Google\u2019s journey, as recommended practices for responsible AI continue to emerge and evolve.</p></div></div>",
            "pubdate": "Wed, 06 Jul 2022 18:00:00 +0000",
            "pubdate_parsed": [
                2022,
                7,
                6
            ],
            "email_sent": true
        },
        "Making robots more helpful with language": {
            "url": "https://blog.google/technology/ai/making-robots-more-helpful-with-language/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>Even the simplest human tasks are unbelievably complex. The way we perceive and interact with the world requires a lifetime of accumulated experience and context. For example, if a person tells you, \u201cI am running out of time,\u201d you don\u2019t immediately worry they are jogging on a street where the space-time continuum ceases to exist. You understand that they\u2019re probably coming up against a deadline. And if they hurriedly walk toward a closed door, you don\u2019t brace for a collision, because you trust this person can open the door, whether by turning a knob or pulling a handle.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>A robot doesn\u2019t innately have that understanding. And that\u2019s the inherent challenge of programming helpful robots that can interact with humans. We know it as \u201cMoravec's paradox\u201d \u2014 the idea that in robotics, it\u2019s the easiest things that are the most difficult to program a robot to do. This is because we\u2019ve had all of human evolution to master our basic motor skills, but relatively speaking, humans have only just learned algebra.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In other words, there\u2019s a genius to human beings \u2014 from understanding idioms to manipulating our physical environments \u2014 where it seems like we just \u201cget it.\u201d The same can\u2019t be said for robots.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Today, robots by and large exist in industrial environments, and are painstakingly coded for narrow tasks. This makes it impossible for them to adapt to the unpredictability of the real world. That\u2019s why <a href=\"https://research.google/\">Google Research</a> and <a href=\"https://everydayrobots.com/\">Everyday Robots</a> are working together to combine the best of language models with robot learning.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Called <a href=\"https://sites.research.google/palm-saycan\">PaLM-SayCan</a>, this joint research uses <a href=\"https://arxiv.org/pdf/2204.02311.pdf\">PaLM</a> \u2014 or Pathways Language Model \u2014 in a robot learning model running on an Everyday Robots helper robot. This effort is the first implementation that uses a large-scale language model to plan for a real robot. It not only makes it possible for people to communicate with helper robots via text or speech, but also improves the robot\u2019s overall performance and ability to execute more complex and abstract tasks by tapping into the world knowledge encoded in the language model.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><video alt=\"I just worked out bring me a snack\" class=\"article-image__media\" loop=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/I_just_worked_out_bring_me_a_snack_QT.mp4\" tabindex=\"0\" title=\"A helper robot responding to the task \u2018I\u2019m tired. Bring me a snack that\u2019ll give me some energy, please.\" type=\"video/mp4\">Video format not supported</video></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Using language to improve robots</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>PaLM-SayCan enables the robot to understand the way we communicate, facilitating more natural interaction. Language is a reflection of the human mind\u2019s ability to assemble tasks, put them in context and even reason through problems. Language models also contain enormous amounts of information about the world, and it turns out that can be pretty helpful to the robot. PaLM can help the robotic system process more complex, open-ended prompts and respond to them in ways that are reasonable and sensible.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>PaLM-SayCan shows that a robot\u2019s performance can be improved simply by enhancing the underlying language model. When the system was integrated with PaLM, compared to a less powerful baseline model, we saw a 14% improvement in the planning success rate, or the ability to map a viable approach to a task. We also saw a 13% improvement on the execution success rate, or ability to successfully carry out a task. This is half the number of planning mistakes made by the baseline method. The biggest improvement, at 26%, is in planning long horizon tasks, or those in which eight or more steps are involved. Here\u2019s an example: \u201cI left out a soda, an apple and water. Can you throw them away and then bring me a sponge to wipe the table?\u201d Pretty demanding, if you ask me.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Making sense of the world through language</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>With PaLM, we\u2019re seeing new capabilities emerge in the language domain such as reasoning via <a href=\"https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html\">chain of thought prompting</a>. This allows us to see and improve how the model interprets the task. For example, if you show the model a handful of examples with the thought process behind how to respond to a query, it learns to reason through those prompts. This is similar to how we learn by showing our work on our algebra homework.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"PaLM-SayCan uses chain of thought prompting, which interprets the instruction in order to score the likelihood of completing the task\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Chain_of_thought_prompting.max-1000x1000.png\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>So if you ask PaLM-SayCan, \u201cBring me a snack and something to wash it down with,\u201d it uses chain of thought prompting to recognize that a bag of chips may be a good snack, and that \u201cwash it down\u201d means bring a drink. Then PaLM-SayCan can respond with a series of steps to accomplish this. While we\u2019re early in our research, this is promising for a future where robots can handle complex requests.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Grounding language through experience</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Complexity exists in both language and the environments around us. That\u2019s why grounding artificial intelligence in the real world is a critical part of what we do in Google Research. A language model may suggest something that appears reasonable and helpful, but may not be safe or realistic in a given setting. Robots, on the other hand, have been trained to know what is possible given the environment. By fusing language and robotic knowledge, we\u2019re able to improve the overall performance of a robotic system.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Here\u2019s how this works in PaLM-SayCan: PaLM suggests possible approaches to the task based on language understanding, and the robot models do the same based on the feasible skill set. The combined system then cross-references the two to help identify more helpful and achievable approaches for the robot.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"By combining language and robotic affordances, PaLM-SayCan breaks down the requested task to perform it successfully\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/palm_gif_8_12_22.gif\" tabindex=\"0\" /></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>For example, if you ask the language model, \u201cI spilled my drink, can you help?,\u201d it may suggest you try using a vacuum. This seems like a perfectly reasonable way to clean up a mess, but generally, it\u2019s probably not a good idea to use a vacuum on a liquid spill. And if the robot can\u2019t pick up a vacuum or operate it, it\u2019s not a particularly helpful way to approach the task. Together, the two may instead be able to realize \u201cbring a sponge\u201d is both possible and more helpful.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Experimenting responsibly</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We take a responsible approach to this research and follow Google\u2019s <a href=\"https://ai.google/principles/\">AI\u2019s Principles</a> in the development of our robots. Safety is our number-one priority and especially important for a learning robot: It may act clumsily while exploring, but it should always be safe. We follow all the tried and true principles of robot safety, including risk assessments, physical controls, safety protocols and emergency stops. We also always implement multiple levels of safety such as force limitations and algorithmic protections to mitigate risky scenarios. PaLM-SayCan is constrained to commands that are safe for a robot to perform and was also developed to be highly interpretable, so we can clearly examine and learn from every decision the system makes.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Making sense of our worlds</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Whether it\u2019s moving about busy offices \u2014 or understanding common sayings \u2014 we still have many mechanical and intelligence challenges to solve in robotics. So, for now, these robots are just getting better at grabbing snacks for Googlers in our micro-kitchens.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>But as we continue to uncover ways for robots to interact with our ever-changing world, we\u2019ve found that language and robotics show enormous potential for the helpful, human-centered robots of tomorrow.</p></div></div>",
            "pubdate": "Tue, 16 Aug 2022 14:00:00 +0000",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "Helping people understand AI": {
            "url": "https://blog.google/technology/ai/helping-people-understand-ai/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>If you\u2019re like me, you may have noticed that AI has become a part of daily life. I wake up each morning and ask my smart assistant about the weather. I recently applied for a new credit card and the credit limit was likely determined by a machine learning model. And while typing the previous sentence, I got a word choice suggestion that \u201cprobably\u201d might flow better than \u201clikely,\u201d a suggestion powered by AI.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As a member of <a href=\"https://ai.google/responsibilities/review-process/\">Google\u2019s Responsible Innovation team</a>, I think a lot about how AI works and how to develop it responsibly. Recently, I spoke with Patrick Gage Kelley, Head of Research Strategy on Google\u2019s Trust &amp; Safety team, to learn more about developing products that help people recognize and understand AI in their daily lives.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How do you help people navigate a world with so much AI?</b></p><p>My goal is to ensure that people, at a basic level, know how AI works and how it impacts their lives. AI systems can be really complicated, but the goal of explaining AI isn\u2019t to get everyone to become programmers and understand all of the technical details \u2014 it\u2019s to make sure people understand the parts that matter to them.</p><p>When AI makes a decision that affects people (whether it\u2019s recommending a video or qualifying for a loan), we want to explain how that decision was made. And we don\u2019t want to just provide a complicated technical explanation, but rather, information that is meaningful, helpful, and equips people to act if needed.</p><p>We also want to find the best times to explain AI. Our goal is to help people develop AI literacy early, including in primary and secondary education. And when people use products that rely on AI (everything from online services to medical devices), we want to include a lot of chances for people to learn about the role AI plays, as well as its benefits and limitations. For example, if people are told early on what kinds of mistakes AI-powered products are likely to make, then they are better prepared to understand and remedy situations that might arise.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>Do I need to be a mathematician or programmer to have a meaningful understanding of AI?</b></p><p>No! A good metaphor here is financial literacy. While we may not need to know every detail of what goes into interest rate hikes or the intricacies of financial markets, it\u2019s important to know how they impact us \u2014 from paying off credit cards, to buying a home, or paying for student loans. In the same way, AI explainability isn\u2019t about understanding every technical aspect of a machine learning algorithm \u2013 it\u2019s about knowing how to interact with it and how it impacts our daily lives.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How should AI practitioners \u2014 developers, designers, researchers, students, and others \u2014 think about AI explainability?</b></p><p>Lots of practitioners are doing important work on explainability. Some focus on interpretability, making it easier to identify specific factors that influence a decision. Others focus on providing \u201cin-the-moment explanations\u201d right when AI makes a decision. These can be helpful, especially when carefully designed. However, AI systems are often so complex that we can\u2019t rely on in-the-moment explanations entirely. It\u2019s just too much information to pack into a single moment. Instead, AI education and literacy should be incorporated into the entire user journey and built continuously throughout a person\u2019s life.</p><p>More generally, AI practitioners should think about AI explainability as fundamental to the design and development of the entire product experience. At Google, we use our <a href=\"https://ai.google/principles\">AI Principles</a> to guide responsible technology development. In accordance with AI Principle #4: \u201cBe accountable to people,\u201d we encourage AI practitioners to think about all the moments and ways they can help people understand how AI operates and makes decisions.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>How are you and your collaborators working to improve explanations of AI?</b></p><p>We develop resources that help AI practitioners learn creative ways to incorporate AI explainability in product design. For example, in the <a href=\"https://pair.withgoogle.com/guidebook/\">PAIR Guidebook</a> we launched a series of <a href=\"https://arxiv.org/abs/2009.00246\">ethical case studies</a> to help AI practitioners think through tricky issues and hone their skills for explaining AI. We also do fundamental research like <a href=\"https://arxiv.org/abs/2012.00874\">this paper</a> to learn more about how people perceive AI as a decision-maker, and what values they would like AI-powered products to embody.</p><p>We\u2019ve learned that many AI practitioners want concrete examples of good explanations of AI that they can build on, so we\u2019re currently developing a story-driven visual design toolkit for explanations of a fictional AI app. The toolkit will be publicly available, so teams in startups and tech companies everywhere can prioritize explainability in their work.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><img alt=\"An illustration of a sailboat navigating the coast of Maine\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Inline_Image_--_Helping_People_Understand_.max-1000x1000.jpg\" tabindex=\"0\" /></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The visual design toolkit provides story-driven examples of good explanations of AI.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p><b>I want to learn more about AI explainability. Where should I start?</b></p><p>This February, we released an <a href=\"https://applieddigitalskills.withgoogle.com/en/teach?gclid=CjwKCAjwi8iXBhBeEiwAKbUofZfj4ve-ub1b5Y5ZW2qe1NbNX4OOvdXWsxZhumVAoAOe67Bld2LGBxoCPNAQAvD_BwE\">Applied Digital Skills</a> lesson, \u201c<a href=\"https://applieddigitalskills.withgoogle.com/c/middle-and-high-school/en/discover-ai-in-daily-life/overview.html\">Discover AI in Daily Life</a>.\u201d It\u2019s a great place to start for anyone who wants to learn more about how we interact with AI everyday.</p><p>We also hope to speak about AI explainability at the upcoming <a href=\"https://www.sxsw.com/conference/\">South by Southwest Conference</a>. Our proposed session would dive deeper into these topics, including our visual design toolkit for product designers. If you\u2019re interested in learning more about AI explainability and our work, you can vote for our proposal through the SXSW PanelPicker\u00ae <a href=\"https://panelpicker.sxsw.com/vote/129081\">here</a>.</p></div></div>",
            "pubdate": "Thu, 18 Aug 2022 15:00:00 +0000",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Join us in the AI Test Kitchen": {
            "url": "https://blog.google/technology/ai/join-us-in-the-ai-test-kitchen/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>As AI technologies continue to advance, they have the potential to unlock new experiences that support more natural human-computer interactions. We see a future where you can find the information you\u2019re looking for in the same conversational way you speak to friends and family. While there\u2019s still lots of work to be done before this type of human-computer interaction is possible, recent research breakthroughs in generative language models \u2014 inspired by the natural conversations of people \u2014 are accelerating our progress. One of our most promising models is called LaMDA (Language Model for Dialogue Applications), and as we move ahead with development, we feel a great responsibility to get this right.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>That\u2019s why we introduced an app called <a href=\"https://youtu.be/nP-nMZpLM1A?t=2380\">AI Test Kitchen</a> at Google I/O earlier this year. It provides a new way for people to learn about, experience, and give feedback on emerging AI technology, like LaMDA. Starting today, you can <a href=\"https://aitestkitchen.withgoogle.com/\">register your interest</a> for the AI Test Kitchen as it begins to gradually roll out to small groups of users in the US, launching on Android today and iOS in the coming weeks.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col-l--6 h-c-grid__col--8 h-c-grid__col-l--offset-3 h-c-grid__col--offset-2\"><a class=\"article-image--link\" href=\"https://aitestkitchen.withgoogle.com/\" rel=\"external\" target=\"_blank\"><img alt=\"Linked image of AI Test Kitchen registration page\" class=\"article-image--large\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/blog_post_image.max-1000x1000.png\" tabindex=\"0\" /></a></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>Our goal is to learn, improve and innovate responsibly on AI together.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Similar to a real test kitchen, AI Test Kitchen will serve a rotating set of experimental demos. These aren\u2019t finished products, but they\u2019re designed to give you a taste of what\u2019s becoming possible with AI in a responsible way. Our first set of demos explore the capabilities of our latest version of <a href=\"https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html\">LaMDA</a>, which has undergone key safety improvements. The first demo, \u201cImagine It,\u201d lets you name a place and offers paths to explore your imagination. With the \u201cList It\u201d demo, you can share a goal or topic, and LaMDA will break it down into a list of helpful subtasks. And in the \u201cTalk About It (Dogs Edition)\u201d demo, you can have a fun, open-ended conversation about dogs <i>and only dogs</i>, which explores LaMDA\u2019s ability to stay on topic even if you try to veer off-topic.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Evaluating LaMDA\u2019s potential and its risks</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As you try each demo, you\u2019ll see LaMDA\u2019s ability to generate creative responses on the fly. This is one of the model\u2019s strengths, but it can also pose challenges since some responses can be inaccurate or inappropriate. We\u2019ve been testing LaMDA internally over the last year, which has produced significant quality improvements. More recently, we\u2019ve run dedicated rounds of adversarial testing to find additional flaws in the model. We enlisted expert red teaming members \u2014 product experts who intentionally stress test a system with an adversarial mindset \u2014 who have uncovered additional harmful, yet subtle, outputs. For example, the model can misunderstand the intent behind identity terms and sometimes fails to produce a response when they\u2019re used because it has difficulty differentiating between benign and adversarial prompts. It can also produce harmful or toxic responses based on biases in its training data, generating responses that stereotype and misrepresent people based on their gender or cultural background. These areas and more continue to be under active research.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In response to these challenges, we\u2019ve added multiple layers of protection to the AI Test Kitchen. This work has minimized the risk, but not eliminated it. We\u2019ve designed our systems to automatically detect and filter out words or phrases that violate our policies, which prohibit users from knowingly generating content that is sexually explicit; hateful or offensive; violent, dangerous, or illegal; or divulges personal information. In addition to these safety filters, <a href=\"https://ai.googleblog.com/2022/01/lamda-towards-safe-grounded-and-high.html\">we made improvements to LaMDA</a> around quality, safety, and groundedness \u2014 each of which are carefully measured. We have also developed techniques to keep conversations on topic, acting as guardrails for a technology that can generate endless, free-flowing dialogue. As you\u2019re using each demo, we hope you see LaMDA\u2019s potential, but also keep these challenges in mind.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>Responsible progress, together</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In accordance with our <a href=\"https://ai.google/principles/\">AI Principles</a>, we believe responsible progress doesn\u2019t happen in isolation. We\u2019re at a point where external feedback is the next, most helpful step to improve LaMDA. When you rate each LaMDA reply as nice, offensive, off topic, or untrue, we\u2019ll use this data \u2014 which is not linked to your Google account\u00a0\u2014 to improve and develop our future products. We intend for AI Test Kitchen to be safe, fun, and educational, and we look forward to innovating in a responsible and transparent way together.</p></div></div>",
            "pubdate": "Thu, 25 Aug 2022 16:00:00 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "How mapping the worlds buildings makes a difference": {
            "url": "https://blog.google/around-the-globe/google-africa/how-mapping-the-worlds-buildings-makes-a-difference/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>In Lamwo district, in northern Uganda, providing access to electricity is a challenge. In a country where only about 24% of the population has a power supply to their home from the national grid, the rate in Lamwo is even lower. This is partly due to lack of information: The government doesn\u2019t have precise data about where settlements are located, what types of buildings there are, and what the buildings\u2019 electricity needs might be. And canvassing the area isn\u2019t practical, because the roads require four-wheel-drive vehicles and are impassable in the rain.</p><p>Ernest Mwebaze leads <a href=\"https://sunbird.ai/\">Sunbird AI</a>, a Ugandan nonprofit that uses data technology for social good. They\u2019re assessing areas in Lamwo district to support planning at the Ministry of Energy in Uganda. \u201cThere are large areas to plan for,\u201d explains Ernest. \u201cEven when you\u2019re there on the ground, it\u2019s difficult to get an overall sense of where all the buildings are and what is the size of each settlement. Currently people have to walk long distances just to charge their phones.\u201d</p><p>To help with their analysis, Ernest\u2019s team have been using Google\u2019s <a href=\"https://sites.research.google/open-buildings/\">Open Buildings</a>. An open-access dataset project <a href=\"https://ai.googleblog.com/2021/07/mapping-africas-buildings-with.html\">based on satellite imagery</a> pinpointing the locations and geometry of buildings across Africa, Open Buildings allows the team to study the electrification needs, and potential solutions, at a level of detail that was previously impossible.</p></div></div><div class=\"block-paragraph_with_image\"><div class=\"article-module h-c-page\"><div class=\"h-c-grid uni-paragraph-wrap\"><div class=\"uni-paragraph h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3\"></div></div></div></div><div class=\"block-image_carousel\"><div class=\"h-c-page article-module\"><div class=\"article-module glue-pagination h-c-carousel h-c-carousel--simple h-c-carousel--dark ng-cloak\"><div class=\"h-c-carousel__wrap\"><ul class=\"glue-carousel ng-cloak\"><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">A satellite view of Accra, Ghana, with building footprints from Open Buildings v1 and v2.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Improved detail in urban areas</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">A satellite view of Tiris Zemmour, Mauritania, with building footprints from Open Buildings v1 and v2.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Model improvements have helped to reduce false detections \u2014 for example, in this desert area, rectangular rocks were being misidentified as buildings.</p></div></figcaption></figure></li><li class=\"h-c-carousel__item article-carousel__slide\"><figure class=\"h-c-grid\"><div class=\"article-carousel__slide-img h-c-grid__col h-c-grid__col--10 h-c-grid__col--offset-1\"><span class=\"h-u-visually-hidden\">A satellite view of Kitui, Kenya, with building footprints from Open Buildings v1 and v2.</span></div><figcaption class=\"article-carousel__caption h-c-grid__col h-c-grid__col--10 h-c-grid__col-l--8 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2\"><div class=\"rich-text\"><p>Using more recent satellite imagery helps us to extend the coverage in rural areas.</p></div></figcaption></figure></li></ul><div class=\"h-c-carousel__paginate glue-pagination-previous uni-click-tracker\"><div class=\"h-c-carousel__paginate-wrap\"><svg class=\"h-c-icon h-c-icon--keyboard-arrow-left\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-keyboard-arrow-right\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></div></div><div class=\"h-c-carousel__paginate glue-pagination-next uni-click-tracker\"><div class=\"h-c-carousel__paginate-wrap\"><svg class=\"h-c-icon h-c-icon--keyboard-arrow-right\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-keyboard-arrow-right\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></div></div></div><div class=\"h-c-carousel__navigation\"><div class=\"glue-pagination-page-list uni-click-tracker\"></div></div></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our <a href=\"https://africa.googleblog.com/2022/05/google-research-enhances-its-ai-growth.html\">research center in Ghana</a> led the development of the Open Buildings project to support policy planning for the areas in the world with the biggest information gaps. We created it by <a href=\"https://ai.googleblog.com/2021/07/mapping-africas-buildings-with.html\">applying artificial intelligence</a> methods to satellite imagery to identify the locations and outlines of buildings.</p><p>Since we <a href=\"https://blog.google/around-the-globe/google-africa/using-ai-to-map-africas-buildings/\">released the data</a>, we\u2019ve heard from many organizations \u2014 including UN agencies, nonprofits and academics \u2014 who have been using it:</p><ul><li>The UN Refugee Agency, <a href=\"https://www.unhcr.org/\">UNHCR</a>, has been using Open Buildings for survey sampling. It\u2019s common to do household surveys in regions where people have been displaced, in order to know what people need. But UNHCR needs to first have an assessment of where the households actually are, which is where the Open Buildings project has been useful.</li><li><a href=\"https://unhabitat.org/\">UN Habitat</a> is using Open Buildings to study urbanization across the African continent. Having detail on the way that cities are laid out enables them to make recommendations on urban planning.</li><li>The <a href=\"https://www.iea.org/\">International Energy Agency</a> is using Open Buildings to estimate energy needs. With data about individual buildings, they can assess the needs of communities at a new level of precision and know how much energy is needed for cooking, lighting and for operating machinery. This will help with planning sustainable energy policy.</li></ul><p>We\u2019re excited to make this information available in more countries and to assist more organizations in their essential work. As Ernest says, \u201cBy providing decision makers with better data, they can make better decisions. Geographical data is particularly important for providing an unbiased source of information for planning basic services, and we need more of it.\u201d</p></div></div>",
            "pubdate": "Tue, 11 Oct 2022 12:00:00 +0000",
            "pubdate_parsed": [
                2022,
                10,
                11
            ],
            "email_sent": true
        },
        "3 ways AI is scaling helpful technologies worldwide": {
            "url": "https://blog.google/technology/ai/ways-ai-is-scaling-helpful/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p>I was first introduced to neural networks as an undergraduate in 1990. Back then, many people in the AI community were excited about the potential of neural networks, which were impressive, but couldn\u2019t yet accomplish important, real-world tasks. I was excited, too! I did my senior thesis on using parallel computation to train neural networks, thinking we only needed 32X more compute power to get there. I was <i>way</i> off. At that time, we needed <i>1 million times</i> as much computational power.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>A short 21 years later, with exponentially more computational power, it was time to take another crack at neural networks. In 2011, I and a few others at Google started training very large neural networks using millions of randomly selected frames from videos online. The results were <a href=\"https://blog.google/technology/ai/using-large-scale-brain-simulations-for/\">remarkable</a>. Without explicit training, the system automatically learned to recognize different objects (especially cats, the Internet is full of cats). This was one transformational discovery in AI among a long string of successes that is still ongoing \u2014 at Google and elsewhere.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>I share my own history of neural networks to illustrate that, while progress in AI might feel especially fast right now, it\u2019s come from a long arc of progress. In fact, prior to 2012, computers had a really difficult time seeing, hearing, or understanding spoken or written language. Over the past 10 years we\u2019ve made especially <a href=\"https://blog.google/technology/ai/decade-deep-learning-and-whats-next/\">rapid progress in AI</a>.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Today, we\u2019re excited about many recent advances in AI that Google is leading \u2014 not just on the technical side, but in responsibly deploying it in ways that help people around the world. That means deploying AI <a href=\"https://cloud.google.com/blog/products/ai-machine-learning\">in Google Cloud</a>, in our products from <a href=\"https://blog.google/intl/en-in/pixel-7-pixel-7-pro/\">Pixel phones</a> to <a href=\"https://blog.google/products/search/search-on-2022-announcements/\">Google Search</a>, and in many fields of science and other human endeavors.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re aware of the challenges and risks that AI poses as an emerging technology. We were the first major company to release and operationalize a set of <a href=\"https://ai.google/principles/\">AI Principles</a>, and following them has actually (and some might think counterintuitively) allowed us to focus on making rapid progress on technologies that can be helpful to everyone. Getting AI right needs to be a collective effort \u2014 involving not just researchers, but domain experts, developers, community members, businesses, governments and citizens.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>I\u2019m happy to make announcements in three transformative areas of AI today: first, using AI to make technology accessible in many more languages. Second, exploring how AI might bolster creativity. And third, in AI for Social Good, including climate adaptation.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>1. Supporting 1,000 languages with AI</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Language is fundamental to how people communicate and make sense of the world. So it\u2019s no surprise it\u2019s also the most natural way people engage with technology. But more than 7,000 languages are spoken around the world, and only a few are well represented online today. That means traditional approaches to training language models on text from the web fail to capture the diversity of how we communicate globally. This has historically been an obstacle in the pursuit of our mission to make the world\u2019s information universally accessible and useful.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>That\u2019s why today we\u2019re announcing the 1,000 Languages Initiative, an ambitious commitment to build an AI model that will support the 1,000 most spoken languages, bringing greater inclusion to billions of people in marginalized communities all around the world. This will be a many years undertaking \u2013 some may even call it a moonshot \u2013 but we are already making meaningful strides here and see the path clearly. Technology has been changing at a rapid clip \u2013 from the way people use it to what it\u2019s capable of. Increasingly, we see people finding and sharing information via new modalities like images, videos, and speech. And our most advanced language models are multimodal \u2013 meaning they\u2019re capable of unlocking information across these many different formats. With these seismic shifts come new opportunities.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><a class=\"article-image--link\"><img alt=\"spinning globe with languages\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/GoogleAI_GlobeAnimation.gif\" tabindex=\"0\" /></a></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>As part of our this initiative and our focus on multimodality, we\u2019ve developed a Universal Speech Model \u2014 or USM \u2014 that\u2019s trained on over 400 languages, making it the largest language coverage seen in a speech model to date. As we expand on this work, we\u2019re partnering with communities across the world to source representative speech data. We <a href=\"https://africa.googleblog.com/2022/10/voice-typing-for-african-languages.html\">recently announced</a> voice typing for 9 more African languages on Gboard by working closely with researchers and organizations in Africa to create and publish data. And in South Asia, we are actively working with local governments, NGOs, and academic institutions to eventually collect representative audio samples from across all the regions\u2019 dialects and languages.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>2. Empowering creators and artists with AI</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI-powered generative models have the potential to unlock creativity, helping people across cultures express themselves using video, imagery, and design in ways that they previously could not.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our researchers have been hard at work developing models that lead the field in terms of quality, generating images that human raters prefer over other models. We recently shared important breakthroughs, applying our diffusion model to video sequences and generating long coherent videos for a sequence of text prompts. We can combine these techniques to produce video \u2014 for the first time, today we\u2019re sharing AI-generated super-resolution video:</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><a class=\"article-image--link\"><video alt=\"Phenaki\" class=\"article-image__media\" loop=\"\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/Google-AI-Phenaki__Imagen-15fps.mp4\" tabindex=\"0\" title=\"AI super generated video\" type=\"video/mp4\">Video format not supported</video></a></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019ll soon be bringing our text-to-image generation technologies to AI Test Kitchen, which provides a way for people to learn about, experience, and give feedback on emerging AI technology. We look forward to hearing feedback from users on these demos in AI Test Kitchen Season 2. You\u2019ll be able to build themed cities with \u201cCity Dreamer\u201d and design friendly monster characters that can move, dance, and jump with \u201cWobble\u201d \u2014 all by using text prompts.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>In addition to 2D images, text-to-3D is now a reality with DreamFusion, which produces a three-dimensional model that can be viewed from any angle and can be composited into any 3D environment. Researchers are also making significant progress in the audio generation space with AudioLM, a model that learns to generate realistic speech and piano music by listening to audio only. In the same way a language model might predict the words and sentences that follow a text prompt, AudioLM can predict which sounds should follow after a few seconds of an audio prompt.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We're collaborating with creative communities globally as we develop these tools. For example, we're working with writers using Wordcraft, which is built on our state-of-the-art dialog system LaMDA, to experiment with AI-powered text generation. You can read the first volume of these stories at the <a href=\"http://g.co/research/wordcraft\">Wordcraft Writers Workshop</a>.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>3. Addressing climate change and health challenges with AI</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>AI also has great potential to address the effects of climate change, including helping people adapt to new challenges. One of the worst is wildfires, which affect hundreds of thousands of people today, and are increasing in frequency and scale.</p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Today, I\u2019m excited to share that we\u2019ve advanced our use of satellite imagery to train AI models to identify and track wildfires in real time, helping predict how they will evolve and spread. We\u2019ve launched this wildfire tracking system in the U.S., Canada, Mexico, and are rolling out in parts of Australia, and since July we\u2019ve covered more than 30 big wildfire events in the U.S. and Canada, helping inform our users and firefighting teams with over 7 million views in Google Search and Maps.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col-l--4 h-c-grid__col--6 h-c-grid__col-l--offset-4 h-c-grid__col--offset-3\"><a class=\"article-image--link\"><img alt=\"wildfire alert on phone\" class=\"article-image--medium\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/Google-AI-Wildfire.gif\" tabindex=\"0\" /></a></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>We\u2019re also using AI to forecast floods, another extreme weather pattern exacerbated by climate change. We\u2019ve already <a href=\"https://blog.google/technology/ai/expanding-our-ml-based-flood-forecasting/\">helped communities</a> to predict when floods will hit and how deep the waters will get \u2014 in 2021, we sent 115 million flood alert notifications to 23 million people over Google Search and Maps, helping save countless lives. Today, we\u2019re sharing that we\u2019re now expanding our coverage to more countries in South America (Brazil and Colombia), Sub-Saharan Africa (Burkina Faso, Cameroon, Chad, Democratic Republic of Congo, Ivory Coast, Ghana, Guinea, Malawi, Nigeria, Sierra Leone, Angola, South Sudan, Namibia, Liberia, and South Africa), and South Asia (Sri Lanka). We\u2019ve used an AI technique called transfer learning to make it work in areas where there\u2019s less data available. We\u2019re also announcing the global launch of Google <a href=\"http://g.co/floodhub\">FloodHub</a>, a new platform that displays when and where floods may occur. We\u2019ll also be bringing this information to Google Search and Maps in the future to help more people to reach safety in flooding situations.</p></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image h-c-grid__col-l--4 h-c-grid__col--6 h-c-grid__col-l--offset-4 h-c-grid__col--offset-3\"><a class=\"article-image--link\"><img alt=\"flood alert on a phone\" class=\"article-image--medium\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Google-AI-Flood.max-100x100.png\" tabindex=\"0\" /></a></div></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Finally, AI is helping provide ever more access to healthcare in under-resourced regions. For example, we\u2019re researching ways AI can help read and analyze outputs from low-cost ultrasound devices, giving parents the information they need to identify issues earlier in a pregnancy. We also plan to continue to partner with caregivers and public health agencies to expand access to diabetic retinopathy screening through our Automated Retinal Disease Assessment tool (ARDA). Through ARDA, we\u2019ve successfully screened more than 150,000 patients in countries like India, Thailand, Germany, the United States, and the United Kingdom across deployed use and prospective studies \u2014 more than half of those in 2022 alone. Further, we\u2019re exploring how AI can help your phone detect respiratory and heart rates. This work is part of Google Health\u2019s broader vision, which includes <a href=\"https://blog.google/technology/health/check-up-ai-developments-2022/\">making healthcare more accessible</a> for anyone with a smartphone.</p><p></p></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><h3>AI in the years ahead</h3></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p>Our advancements in neural network architectures, machine learning algorithms and new approaches to hardware for machine learning have helped AI solve important, real-world problems for billions of people. Much more is to come. What we\u2019re sharing today is a hopeful vision for the future \u2014 AI is letting us reimagine how technology can be helpful. We hope you\u2019ll join us as we explore these new capabilities and use this technology to improve people\u2019s lives around the world.</p></div></div>",
            "pubdate": "Wed, 02 Nov 2022 14:00:00 +0000",
            "pubdate_parsed": [
                2022,
                11,
                2
            ],
            "email_sent": true
        },
        "How we're using AI to help address the climate crisis": {
            "url": "https://blog.google/outreach-initiatives/sustainability/cop27-adaptation-efforts/",
            "description": "<div class=\"block-paragraph\"><div class=\"rich-text\"><p><br /></p><p>Communities around the world are facing the effects of climate change \u2014 from devastating floods and wildfires to challenges around food security. As global leaders meet in Egypt for <a href=\"https://cop27.eg/#/\">COP27</a>, a key area of focus will be on how we can work together to adapt to climate change <a href=\"https://blog.google/outreach-initiatives/sustainability/COP27-Google-climate-action/\">and implement sustainable solutions</a>. At Google, we\u2019re investing in technologies that can help communities prepare for and respond to climate-related disasters and threats.</p><h3>Tools to alert people and governments about immediate risks</h3><p>Natural disasters are increasing in frequency and intensity due to climate change. As part of our <a href=\"https://crisisresponse.google/\">Crisis Response</a> efforts, we're working to bring trusted information to people in critical moments to keep them safe and informed. To do so, we rely on the research and development of our AI-powered technologies and longstanding partnerships with frontline emergency workers and organizations. Here\u2019s a look at some of our crisis response efforts and new ways we\u2019re expanding these tools.</p><ul><li><b>Floods:</b> Catastrophic <a href=\"http://g.co/floods\">damage from flooding</a> affects more than 250 million people every year. In 2018, we launched our flood <a href=\"https://blog.google/technology/ai/expanding-our-ml-based-flood-forecasting/\">forecasting initiative</a> that <a href=\"https://hess.copernicus.org/articles/26/4013/2022/\">uses machine learning models</a> to provide people with detailed alerts. In 2021, we sent 115 million flood alert notifications to 23 million people over Search and Maps, helping save countless lives. Today, we\u2019re expanding our flood forecasts to river basins in 18 additional countries across Africa, Latin America and Southeast Asia. We\u2019re also announcing the global launch of the new <a href=\"http://g.co/floodhub\">FloodHub</a>, a platform that displays flood forecasts and shows when and where floods may occur to help people directly at risk and provide critical information to aid organizations and governments. This expansion in geographic coverage is possible thanks to our recent breakthroughs in AI-based flood forecasting models, and we\u2019re committed to expanding to more countries.</li></ul></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col--10 h-c-grid__col--offset-1 h-c-grid__col-l--offset-2 h-c-grid__col-l--8\"><a class=\"article-image--link\"><img alt=\"An image of a FloodHub map showing areas where riverine floods my occur\" class=\"article-image--full\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Screen_Shot_2022-10-31_at_22.08.32_cuEwOVg.max-100x100.png\" tabindex=\"0\" /></a></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The new Google FloodHub at <a href=\"https://g.co/floodhub\">g.co/floodhub</a> shows forecasts for riverine floods. Forecasts are now available in 18 additional countries: Brazil, Colombia, Sri Lanka, Burkina Faso, Cameroon, Chad, Democratic Republic of Congo, Ivory Coast, Ghana, Guinea, Malawi, Nigeria, Sierra Leone, Angola, South Sudan, Namibia, Liberia, South Africa.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><p></p><ul><li><b>Wildfires:</b> Wildfires affect hundreds of thousands of people each year, and are increasing in frequency and size. I <a href=\"https://blog.google/products/search/mapping-wildfires-with-satellite-data/\">experienced firsthand</a> the need for accurate information when wildfires occur and this inspired our crisis response work. We detect wildfire boundaries using new AI models based on satellite imagery and show their real-time location in Search and Maps. Since July, we\u2019ve covered more than 30 big wildfire events in the U.S. and Canada, helping inform people and firefighting teams with over 7 million views in Search and Maps. Today, wildfire detection is now available in the U.S., Canada, Mexico and Australia.</li></ul></div></div><div class=\"block-image_full_width\"><div class=\"h-c-page\"><div class=\"article-image__is-caption h-c-grid__col-l--6 h-c-grid__col--8 h-c-grid__col-l--offset-3 h-c-grid__col--offset-2\"><a class=\"article-image--link\"><img alt=\"Picture shows the location of the Pukatawagan fire in Manitoba, Canada.\" class=\"article-image--large\" src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/boundary_tracking_graphics_1_xGJMBgH.max-100x100.png\" tabindex=\"0\" /></a></div><figcaption class=\"article-image__caption article-image__is-caption-image h-c-grid__col--8 h-c-grid__col--offset-2 h-c-grid__col-l--6 h-c-grid__col-l--offset-3\"><div class=\"rich-text\"><p>The location of the Pukatawagan fire in Manitoba, Canada.</p></div></figcaption></div></div><div class=\"block-paragraph\"><div class=\"rich-text\"><ul><li><b>Hurricanes:</b> Access to authoritative forecasts and safety information about hurricanes can be life-saving. In the days before a hurricane in North America or a typhoon in Japan, detailed forecasts from authoritative sources appear on <a href=\"https://support.google.com/sosalerts/?hl=en\">SOS Alerts</a> in Search and Maps to show a storm\u2019s predicted trajectory. We're also using machine learning to <a href=\"https://ai.googleblog.com/2020/06/machine-learning-based-damage.html\">analyze satellite imagery</a> after disasters and identify which areas need help. When Hurricane Ian hit Florida in September, this technology was <a href=\"https://www.wired.com/story/hurricane-ian-destroyed-homes-google-algorithms-sent-money/\">deployed in partnership with Google.org grantee GiveDirectly</a> to quickly allocate aid to those most affected.</li></ul><h3>Managing current and future climate impacts</h3><p>Climate change poses a threat to our world's natural resources and food security. We\u2019re working with governments, organizations and communities to provide information and technologies to help adapt to these changes.</p><ul><li><b>Keeping cities greener and healthier:</b> Extreme temperatures and poor air quality are increasingly common in cities and can impact public health. To mitigate this, our <a href=\"https://blog.google/outreach-initiatives/sustainability/sustainability-2021/\">Project Green Light</a> uses AI to optimize traffic lights at intersections around the world with the aim to help minimize congestion and related pollution. <a href=\"https://www.google.com/earth/outreach/special-projects/air-quality/\">Project Air View</a> also brings detailed air quality maps to scientists, policymakers and communities. And we\u2019re working to expand our Environmental Insights Explorer\u2019s <a href=\"https://insights.sustainability.google/labs/treecanopy\">Tree Canopy Insights</a> tool to hundreds of cities by the end of this year so they can use <a href=\"https://www.epa.gov/heatislands/using-trees-and-vegetation-reduce-heat-islands\">trees to lower street-level temperatures</a> and improve quality of life.</li><li><b>Meeting the world\u2019s growing demand for food:</b> <a href=\"https://mineral.ai/\">Mineral</a> \u2014 a project from X, Alphabet\u2019s moonshot factory \u2014 is working to build a more sustainable and productive food system. The team is joining diverse data sets in radically new ways \u2014 from soil and weather data to drone and satellite images \u2014 and using AI to reveal insights never before possible about what\u2019s happening with crops. As part of our <a href=\"http://g.co/startups/sdg\">Startups For Sustainable Development</a> program, we\u2019re also supporting startups addressing food security. These include startups like <a href=\"https://events.withgoogle.com/startups-for-sustainable-development/oko/\">OKO,</a> which provides crop insurance to keep farmers in business in case of adverse weather events and has reached tens of thousands of farmers in Mali and Uganda.</li><li><b>Helping farmers protect their crops:</b> Pest infestations can threaten entire crops and impact the livelihoods of millions. In collaboration with InstaDeep and the Food and Agriculture Organization of the United Nations, our team at the Google AI Center in Ghana is using AI to better detect locust outbreaks so that it's possible to implement control measures. In India, Google.org Fellows worked with <a href=\"https://www.wadhwaniai.org/\">Wadhwani AI</a> to <a href=\"https://www.fastcompany.com/90640843/google-is-helping-deploy-ai-to-prevent-pests-devastating-indian-crops\">create an AI-powered app</a> that helps identify and treat infestations of pests, resulting in a 20% reduction in pesticide sprays and a 26% increase in profit margins for farmers. Google Cloud is also <a href=\"https://blog.google/products/google-cloud/helping-farmers-with-cloud-technology-up-close-and-global/\">working with agricultural technology companies</a> to use machine learning and cloud services to improve crop yields.</li><li><b>Analyzing a changing planet:</b> Using Google Cloud and Google Earth Engine, organizations and businesses can better assess and manage climate risks. For example, <a href=\"https://cloud.google.com/blog/topics/sustainability/how-the-us-forest-service-uses-google-cloud\">the U.S. Forest Service</a> uses these tools to analyze land-cover changes to better respond to new wildfire threats and monitor the impacts of invasive insects, diseases and droughts. Similarly, the Bank of Montreal is <a href=\"https://sustainabilityleaders.bmo.com/en/news-insights/sustainable-finance/mitigating-physical-impacts-climate-change-spatial-finance/\">integrating climate data</a> \u2014 like precipitation trends \u2014 into its business strategy and risk management for clients.</li></ul><p>AI already plays a critical role in addressing many urgent, climate-related challenges. It is important that we continue to invest in research and raise awareness about why we are doing this work. Google Arts and Culture has collaborated with artists on the <a href=\"http://g.co/culturemeetsclimate\">Culture meets Climate</a> collection so everyone can explore more perspectives on climate change. And at COP27 we hope to generate more awareness and engage in productive discussions about how to use AI, innovations, and <a href=\"https://www.datacommons.org/\">shared data</a> to help global communities address the changing climate.</p></div></div><div class=\"block-perspective_qa\"><div class=\"uni-related-article-tout h-c-page\"><section class=\"h-c-grid\"><a class=\"uni-related-article-tout__wrapper h-c-grid__col h-c-grid__col--8 h-c-grid__col-m--6 h-c-grid__col-l--6 h-c-grid__col--offset-2 h-c-grid__col-m--offset-3 h-c-grid__col-l--offset-3 uni-click-tracker\" href=\"https://blog.google/outreach-initiatives/sustainability/cop27-google-climate-action/\"><div class=\"uni-related-article-tout__inner-wrapper\"><p class=\"uni-related-article-tout__eyebrow h-c-eyebrow\">Related Article</p><div class=\"uni-related-article-tout__content-wrapper\"><div class=\"uni-related-article-tout__image-wrapper\"><div class=\"uni-related-article-tout__image\"></div></div><div class=\"uni-related-article-tout__content\"><h4 class=\"uni-related-article-tout__header h-has-bottom-margin\">Accelerating climate action at Google and beyond</h4><p class=\"uni-related-article-tout__body\">A new paper we published today shares updates on the work we have been doing as part of our third decade of climate action.</p><div class=\"cta module-cta h-c-copy uni-related-article-tout__cta muted\"><span class=\"nowrap\">Read Article<svg class=\"icon h-c-icon\" xmlns=\"http://www.w3.org/2000/svg\"><use xlink:href=\"#mi-arrow-forward\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use></svg></span></div></div></div></div></a></section></div></div>",
            "pubdate": "Wed, 02 Nov 2022 14:00:00 +0000",
            "pubdate_parsed": [
                2022,
                11,
                2
            ],
            "email_sent": true
        },
        "Partnering with iCAD to improve breast cancer screening": {
            "url": "https://blog.google/technology/ai/icad-partnership-breast-cancer-screening/",
            "description": "A visual representation of multiple mammograms being scanned by artificial intelligence for signs of breast cancer.",
            "pubdate": "Mon, 28 Nov 2022 13:00:00 +0000",
            "pubdate_parsed": [
                2022,
                11,
                28
            ],
            "email_sent": true
        },
        "Why we focus on AI (and to what end)": {
            "url": "https://blog.google/technology/ai/why-we-focus-on-ai-and-to-what-end/",
            "description": "Illustration of colorful dots and lines",
            "pubdate": "Mon, 16 Jan 2023 09:00:00 +0000",
            "pubdate_parsed": [
                2023,
                1,
                16
            ],
            "email_sent": true
        },
        "7 ways Google is using AI to help solve society's challenges": {
            "url": "https://blog.google/technology/ai/7-ways-google-is-using-ai-to-help-solve-societys-challenges/",
            "description": "Colorful illustration depicting five of the uses of AI: A map showing a river and where it will flood; a collection of wildfire symbols; a microscope; bugs crawling on leaves; and a map marker with dotted lines coming from it",
            "pubdate": "Tue, 17 Jan 2023 08:00:00 +0000",
            "pubdate_parsed": [
                2023,
                1,
                17
            ],
            "email_sent": true
        },
        "The next generation of AI for developers and Google Workspace": {
            "url": "https://blog.google/technology/ai/ai-developers-google-cloud-workspace/",
            "description": "Moving lines and dots in the 4 Google colors",
            "pubdate": "Tue, 14 Mar 2023 13:00:00 +0000",
            "pubdate_parsed": [
                2023,
                3,
                14
            ],
            "email_sent": true
        },
        "Ask a Techspert: What is generative AI?": {
            "url": "https://blog.google/inside-google/googlers/ask-a-techspert/what-is-generative-ai/",
            "description": "illustration of lines and dots",
            "pubdate": "Tue, 11 Apr 2023 13:00:00 +0000",
            "pubdate_parsed": [
                2023,
                4,
                11
            ],
            "email_sent": true
        },
        "Bard now helps you code": {
            "url": "https://blog.google/technology/ai/code-with-bard/",
            "description": "An animated GIF displaying text of how \u201cBard can help you\u201d: debug your lines of source code, generate documentation and tutorials for source code, explain your code to you line by line, translate your code from one language to another.",
            "pubdate": "Fri, 21 Apr 2023 13:00:00 +0000",
            "pubdate_parsed": [
                2023,
                4,
                21
            ],
            "email_sent": true
        },
        "Try 4 new Arts and AI experiments": {
            "url": "https://blog.google/outreach-initiatives/arts-culture/try-4-new-arts-and-ai-experiments/",
            "description": "A gif running through all 4 experiments",
            "pubdate": "Wed, 03 May 2023 09:00:00 +0000",
            "pubdate_parsed": [
                2023,
                5,
                3
            ],
            "email_sent": true
        },
        "How 4 startups are using AI to solve climate change challenges": {
            "url": "https://blog.google/outreach-initiatives/entrepreneurs/how-4-startups-are-using-ai-to-solve-climate-change-challenges/",
            "description": "A group of approximately 35 people stand outside a building on a gravel surface. Some kneel while others stand behind them, all smiling and looking at the camera. They all wear Google for Startups badges and coats.",
            "pubdate": "Mon, 08 May 2023 11:00:00 +0000",
            "pubdate_parsed": [
                2023,
                5,
                8
            ],
            "email_sent": true
        },
        "A policy agenda for responsible AI progress: Opportunity, Responsibility, Security": {
            "url": "https://blog.google/technology/ai/a-policy-agenda-for-responsible-ai-progress-opportunity-responsibility-security/",
            "description": "Illustration of a light bulb, compass and shield with connecting lines",
            "pubdate": "Fri, 19 May 2023 10:00:00 +0000",
            "pubdate_parsed": [
                2023,
                5,
                19
            ],
            "email_sent": true
        },
        "Introducing new AI-powered ad solutions to drive demand": {
            "url": "https://blog.google/products/ads-commerce/new-ai-powered-ads-to-drive-demand/",
            "description": "Illustration of consumer behaviors across devices and screens.",
            "pubdate": "Wed, 14 Jun 2023 04:00:00 +0000",
            "pubdate_parsed": [
                2023,
                6,
                14
            ],
            "email_sent": true
        },
        "A new accelerator for AI-first startups in Europe and Israel": {
            "url": "https://blog.google/outreach-initiatives/entrepreneurs/accelerator-ai-first/",
            "description": "A man in a yellow shirt with a ponytail speaks to a woman with dark curly hair in the center of a large group of people.",
            "pubdate": "Wed, 21 Jun 2023 11:00:00 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "The creative and transformational possibilities of AI": {
            "url": "https://blog.google/technology/ai/ai-creativity/",
            "description": "The words \u201ctake a moment to imagine\u201d on a background with smaller images of mountains at sunset, a Help me write prompte, and some decorative shapes.",
            "pubdate": "Wed, 21 Jun 2023 09:00:00 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Leonardo da Vinci: Inside a genius mind": {
            "url": "https://blog.google/outreach-initiatives/arts-culture/leonardo-da-vinci-inside-a-genius-mind/",
            "description": "A black and white image of da Vinci with colorful stickies featuring drawings in the background",
            "pubdate": "Mon, 03 Jul 2023 09:30:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "Unlocking the AI-powered opportunity in the UK": {
            "url": "https://blog.google/around-the-globe/google-europe/unlocking-the-ai-powered-opportunity-in-the-uk/",
            "description": "A light grey background with dots and curves in red, blue, green and yellow to symbolise tech.",
            "pubdate": "Wed, 05 Jul 2023 09:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                5
            ],
            "email_sent": true
        },
        "Google.orgs new grant to help track permafrost thaw": {
            "url": "https://blog.google/outreach-initiatives/google-org/google-permafrost-thaw-tracking/",
            "description": "Aerial photo of an arctic landscape with a lake and a permafrost slump \u2014 a brown landslide caused by the thawing of ground ice.",
            "pubdate": "Mon, 17 Jul 2023 04:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "6 women leading the fight against climate change": {
            "url": "https://blog.google/outreach-initiatives/google-org/climate-change-sustainability-women-scientists/",
            "description": "Illustrated in vivid color, Eunice Newton Foote writes in her notebook, surrounded by scientific instruments.",
            "pubdate": "Mon, 17 Jul 2023 04:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "6 mujeres lideran la lucha contra el cambio climtico": {
            "url": "https://blog.google/outreach-initiatives/google-org/climate-change-sustainability-women-scientists-es/",
            "description": "Eunice Newton Foote, dibujada con colores v\u00edvidos, escribe en su cuaderno, rodeada de instrumentos cient\u00edficos.",
            "pubdate": "Mon, 17 Jul 2023 04:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Google's AI Red Team: the ethical hackers making AI safer": {
            "url": "https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/",
            "description": "a labyrinth with symbols on it",
            "pubdate": "Wed, 19 Jul 2023 12:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "A new partnership to promote responsible AI": {
            "url": "https://blog.google/outreach-initiatives/public-policy/google-microsoft-openai-anthropic-frontier-model-forum/",
            "description": "Today, Google, Microsoft, OpenAI and Anthropic published a joint announcement establishing the Frontier Model Forum.",
            "pubdate": "Wed, 26 Jul 2023 10:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "Speaking robot: Our new AI model translates vision and language into robotic actions": {
            "url": "https://blog.google/technology/ai/google-deepmind-rt2-robotics-vla-model/",
            "description": "Illustration of a robot arm picking up oranges from a countertop and placing them into a bowl.",
            "pubdate": "Fri, 28 Jul 2023 09:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "Offering free AI training for everyone in the UK": {
            "url": "https://blog.google/around-the-globe/google-europe/united-kingdom/google-ai-skills-training-course-uk/",
            "description": "A colourful graphic showing people interacting with digital tools and each other",
            "pubdate": "Fri, 28 Jul 2023 05:00:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "A new fund for women creating AI startups in Asia Pacific": {
            "url": "https://blog.google/around-the-globe/google-asia/new-ai-women-fund/",
            "description": "Eight women startup founders from Asia standing on a stage.",
            "pubdate": "Wed, 02 Aug 2023 19:47:00 +0000",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "How 3 healthcare organizations are using generative AI": {
            "url": "https://blog.google/technology/health/cloud-next-generative-ai-health/",
            "description": "Medical themed graphic",
            "pubdate": "Tue, 29 Aug 2023 12:00:00 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Bringing generative AI in Search to more people around the world": {
            "url": "https://blog.google/products/search/google-search-generative-ai-india-japan/",
            "description": "The Search bar superimposed against an abstract blue and white background.",
            "pubdate": "Thu, 31 Aug 2023 00:30:00 +0000",
            "pubdate_parsed": [
                2023,
                8,
                31
            ],
            "email_sent": true
        },
        "15 projects using AI to reach the UNs Global Goals": {
            "url": "https://blog.google/outreach-initiatives/google-org/httpsbloggoogleoutreach-initiativesgoogle-orgunited-nations-global-goals-google-ai-/",
            "description": "A collage of photos that show people around the world using technology to help people: pregnant women, dementia patients, young children walking to school.",
            "pubdate": "Tue, 12 Sep 2023 10:00:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "How AI is generating change in newsrooms worldwide": {
            "url": "https://blog.google/technology/ai/how-ai-is-generating-change-in-newsrooms-worldwide/",
            "description": "A marble table top with a pencil holder and four books piled up with the title 'Generating Change: A global survey of what news organisations are doing with AI' by Charlie Beckett and Mia Yaseen.",
            "pubdate": "Wed, 20 Sep 2023 14:00:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "3 ways AI can help communities adapt to climate change in Africa": {
            "url": "https://blog.google/around-the-globe/google-africa/3-ways-ai-can-help-africans-adapt-to-climate-change/",
            "description": "An image of the conference stage with musicians on the stage in front of a large screen with the conference logo",
            "pubdate": "Fri, 22 Sep 2023 12:00:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "New Google.org grants to introduce 300,000 students to robotics and AI": {
            "url": "https://blog.google/outreach-initiatives/google-org/google-grants-robotics-ai-education/",
            "description": "Young woman being cheered on by her teammates while she works on a small robot made of Legos",
            "pubdate": "Wed, 27 Sep 2023 10:00:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        }
    },
    "OpenAI Blog": {
        "DALLE 2": {
            "url": "https://openai.com/blog/dall-e-2/",
            "description": "DALL\u00b7E 2 is a new AI system that can create realistic images and art from a description in natural language.",
            "pubdate": "Wed, 06 Apr 2022 13:42:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                6
            ],
            "email_sent": true
        },
        "Measuring Goodharts Law": {
            "url": "https://openai.com/blog/measuring-goodharts-law/",
            "description": "Goodhart\u2019s law famously says: \u201cWhen a measure becomes a target, it ceases to be a good measure.\u201d Although originally from economics, it\u2019s something we have to grapple with at OpenAI when figuring out how to optimize objectives that are difficult or costly to measure.",
            "pubdate": "Wed, 13 Apr 2022 18:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                13
            ],
            "email_sent": true
        },
        "OpenAI Leadership Team Update": {
            "url": "https://openai.com/blog/leadership-team-update/",
            "description": "We\u2019re happy to announce several executive role changes that reflect our recent progress and will ensure continued momentum toward our next major milestones.",
            "pubdate": "Thu, 05 May 2022 20:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                5
            ],
            "email_sent": true
        },
        "DALLE 2 Research Preview Update": {
            "url": "https://openai.com/blog/dall-e-2-update/",
            "description": "Early users have created over 3 million images to date and helped us improve our safety processes. We're excited to begin adding up to 1,000 new users from our waitlist each week.",
            "pubdate": "Wed, 18 May 2022 20:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                18
            ],
            "email_sent": true
        },
        "Powering Next Generation Applications with OpenAI Codex": {
            "url": "https://openai.com/blog/codex-apps/",
            "description": "Codex is now powering 70 different applications across a variety of use cases through the OpenAI API.",
            "pubdate": "Tue, 24 May 2022 15:31:36 GMT",
            "pubdate_parsed": [
                2022,
                5,
                24
            ],
            "email_sent": true
        },
        "Best Practices for Deploying Language Models": {
            "url": "https://openai.com/blog/best-practices-for-deploying-language-models/",
            "description": "<!--kg-card-begin: markdown--><p>Cohere, OpenAI, and AI21 Labs have developed a preliminary set of best practices applicable to any organization developing or deploying large language models. Computers that can read and write are here, and they have the potential to fundamentally impact daily life. The future of human&#x2013;machine interaction is full</p>",
            "pubdate": "Thu, 02 Jun 2022 16:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                2
            ],
            "email_sent": true
        },
        "Techniques for Training Large Neural Networks": {
            "url": "https://openai.com/blog/techniques-for-training-large-neural-networks/",
            "description": "<!--kg-card-begin: markdown--><p>Large neural networks are at the core of many recent advances in AI, but training them is a difficult engineering and research challenge which requires orchestrating a cluster of GPUs to perform a single synchronized calculation. As cluster and model sizes have grown, machine learning practitioners have developed an increasing</p>",
            "pubdate": "Thu, 09 Jun 2022 16:00:56 GMT",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        },
        "AI-Written Critiques Help Humans Notice Flaws": {
            "url": "https://openai.com/blog/critiques/",
            "description": "Showing model-generated critical comments to humans helps them find flaws in summaries.",
            "pubdate": "Mon, 13 Jun 2022 18:20:37 GMT",
            "pubdate_parsed": [
                2022,
                6,
                13
            ],
            "email_sent": true
        },
        "Learning to Play Minecraft with Video PreTraining (VPT)": {
            "url": "https://openai.com/blog/vpt/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>We trained a neural network to play Minecraft by Video PreTraining (VPT) on a massive unlabeled video dataset of human Minecraft play, while using only a small amount of labeled contractor data. With fine-tuning, our model can learn to craft diamond tools, a task that usually takes proficient humans over</p></div>",
            "pubdate": "Thu, 23 Jun 2022 16:00:59 GMT",
            "pubdate_parsed": [
                2022,
                6,
                23
            ],
            "email_sent": true
        },
        "DALLE 2 Pre-Training Mitigations": {
            "url": "https://openai.com/blog/dall-e-2-pre-training-mitigations/",
            "description": "<!--kg-card-begin: markdown--><p>In order to share the magic of <a href=\"https://openai.com/dall-e-2/\">DALL&#xb7;E 2</a> with a broad audience, we needed to reduce the risks associated with powerful image generation models. To this end, we put various <a href=\"https://github.com/openai/dalle-2-preview/blob/main/system-card.md\">guardrails</a> in place to prevent generated images from violating our <a href=\"https://labs.openai.com/policies/content-policy\">content policy</a>. This post focuses on <em>pre-training</em></p>",
            "pubdate": "Tue, 28 Jun 2022 17:00:58 GMT",
            "pubdate_parsed": [
                2022,
                6,
                28
            ],
            "email_sent": true
        },
        "DALLE 2: Extending Creativity": {
            "url": "https://openai.com/blog/dall-e-2-extending-creativity/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>As part of our DALL&#xb7;E 2 research preview, more than 3,000 artists from more than 118 countries have incorporated DALL&#xb7;E into their creative workflows. The artists in our early access group have helped us discover new uses for DALL&#xb7;E and have served as</p></div>",
            "pubdate": "Thu, 14 Jul 2022 16:30:22 GMT",
            "pubdate_parsed": [
                2022,
                7,
                14
            ],
            "email_sent": true
        },
        "Reducing Bias and Improving Safety in DALLE 2": {
            "url": "https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/",
            "description": "<!--kg-card-begin: markdown--><p>Today, we are implementing a new technique so that DALL&#xb7;E generates images of people that more accurately reflect the diversity of the world&#x2019;s population. This technique is applied at the system level when DALL&#xb7;E is given a prompt describing a person that does not</p>",
            "pubdate": "Mon, 18 Jul 2022 16:30:23 GMT",
            "pubdate_parsed": [
                2022,
                7,
                18
            ],
            "email_sent": true
        },
        "DALLE Now Available in Beta": {
            "url": "https://openai.com/blog/dall-e-now-available-in-beta/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>We&#x2019;ll invite 1 million people from our waitlist over the coming weeks. Users can create with DALL&#xb7;E using free credits that refill every month, and buy additional credits in 115-generation increments for $15.</p>\n<div class=\"btns mb-0.5\">\n<a class=\"btn btn-padded btn-dark btn-circle icon-external right\" href=\"https://labs.openai.com/waitlist\">Join DALL&#xb7;E 2 waitlist</a>\n</div>\n</div>\n<p><a href=\"https://openai.com/dall-e-2/\">DALL&#xb7;E</a>, the AI system that</p>",
            "pubdate": "Wed, 20 Jul 2022 16:29:05 GMT",
            "pubdate_parsed": [
                2022,
                7,
                20
            ],
            "email_sent": true
        },
        "New-and-Improved Content Moderation Tooling": {
            "url": "https://openai.com/blog/new-and-improved-content-moderation-tooling/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>We are introducing a new-and-improved content moderation tool: The <a href=\"https://beta.openai.com/docs/api-reference/moderations\">Moderation endpoint</a> improves upon our previous content filter, and is available for free today to OpenAI API developers.</p>\n</div>\n<p>To help developers protect their applications against possible misuse, we are introducing the faster and more accurate <a href=\"https://beta.openai.com/docs/api-reference/moderations\">Moderation endpoint</a>. This endpoint provides OpenAI</p>",
            "pubdate": "Wed, 10 Aug 2022 16:00:43 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "Our approach to alignment research": {
            "url": "https://openai.com/blog/our-approach-to-alignment-research/",
            "description": "<!--kg-card-begin: markdown--><div class=\"js-excerpt\">\n<p>Our approach to aligning AGI is empirical and iterative. We are improving our AI systems&#x2019; ability to learn from human feedback and to assist humans at evaluating AI. Our goal is to build a sufficiently aligned AI system that can help us solve all other alignment problems.</p>\n</div>\n<h2 class=\"sr-only\" id=\"introduction\">Introduction</h2>\n<p><a href=\"https://openai.com/alignment\">Our</a></p>",
            "pubdate": "Wed, 24 Aug 2022 18:00:33 GMT",
            "pubdate_parsed": [
                2022,
                8,
                24
            ],
            "email_sent": true
        },
        "Forecasting Potential Misuses of Language Models for Disinformation Campaignsand How to Reduce Risk": {
            "url": "https://openai.com/blog/forecasting-misuse/",
            "description": "<!--kg-card-begin: markdown--><div class=\"post-excerpt\">\n<p>OpenAI researchers collaborated with Georgetown University&#x2019;s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and</p></div>",
            "pubdate": "Wed, 11 Jan 2023 11:00:41 GMT",
            "pubdate_parsed": [
                2023,
                1,
                11
            ],
            "email_sent": true
        },
        "Introducing OpenAI London": {
            "url": "https://openai.com/blog/introducing-openai-london",
            "description": "We are excited to announce OpenAI\u2019s first international expansion with a new office in London, United Kingdom.",
            "pubdate": "Wed, 28 Jun 2023 07:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                28
            ],
            "email_sent": true
        },
        "Partnership with American Journalism Project to support local news": {
            "url": "https://openai.com/blog/partnership-with-american-journalism-project-to-support-local-news",
            "description": "A new $5+ million partnership aims to explore ways the development of artificial intelligence (AI) can support a thriving, innovative local news field, and ensure local news organizations shape the future of this emerging technology.",
            "pubdate": "Tue, 18 Jul 2023 07:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Moving AI governance forward": {
            "url": "https://openai.com/blog/moving-ai-governance-forward",
            "description": "OpenAI and other leading labs reinforce AI safety, security and trustworthiness through voluntary commitments.",
            "pubdate": "Fri, 21 Jul 2023 07:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Frontier Model Forum": {
            "url": "https://openai.com/blog/frontier-model-forum",
            "description": "We\u2019re forming a new industry body to promote the safe and responsible development of frontier AI systems: advancing AI safety research, identifying best practices and standards, and facilitating information sharing among policymakers and industry.",
            "pubdate": "Wed, 26 Jul 2023 07:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "ChatGPT can now see, hear, and speak": {
            "url": "https://openai.com/blog/chatgpt-can-now-see-hear-and-speak",
            "description": "We are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what you\u2019re talking about.",
            "pubdate": "Mon, 25 Sep 2023 07:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "GPT-4V(ision) system card": {
            "url": "https://openai.com/research/gpt-4v-system-card",
            "description": null,
            "pubdate": "Mon, 25 Sep 2023 07:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        }
    },
    "Apple Machine Learning Blog": {
        "NeuMan: Neural Human Radiance Field from a Single Video": {
            "url": "https://machinelearning.apple.com/research/neural-human-radiance-field",
            "description": "Photorealistic rendering and reposing of humans is important for enabling augmented reality experiences. We propose a novel framework to reconstruct the human and the scene that can be rendered with novel human poses and views from just a single in-the-wild video. Given a video captured by a moving camera, we train two NeRF models: a human NeRF model and a scene NeRF model. To train these models, we rely on existing methods to estimate the rough geometry of the human and the scene. Those rough geometry estimates allow us to create a warping field from the observation space to the canonical\u2026",
            "pubdate": "Tue, 02 Aug 2022 19:29:38 GMT",
            "pubdate_parsed": [
                2022,
                8,
                2
            ],
            "email_sent": true
        },
        "Integrating Categorical Features in End-To-End ASR": {
            "url": "https://machinelearning.apple.com/research/integrating-categorical-features",
            "description": "All-neural, end-to-end ASR systems gained rapid interest from the speech recognition community. Such systems convert speech input to text units using a single trainable neural network model. E2E models require large amounts of paired speech text data that is expensive to obtain. The amount of data available varies across different languages and dialects. It is critical to make use of all these data so that both low resource languages and high resource languages can be improved. When we want to deploy an ASR system for a new application domain, the amount of domain specific training data is\u2026",
            "pubdate": "Mon, 08 Aug 2022 18:21:13 GMT",
            "pubdate_parsed": [
                2022,
                8,
                8
            ],
            "email_sent": true
        },
        "Space-Efficient Representation of Entity-centric Query Language Models": {
            "url": "https://machinelearning.apple.com/research/space-efficient-representation",
            "description": "Virtual assistants make use of automatic speech recognition (ASR) to help users answer entity-centric queries. However, spoken entity recognition is a difficult problem, due to the large number of frequently-changing named entities. In addition, resources available for recognition are constrained when ASR is performed on-device. In this work, we investigate the use of probabilistic grammars as language models within the finite-state transducer (FST) framework. We introduce a deterministic approximation to probabilistic grammars that avoids the explicit expansion of non-terminals at model\u2026",
            "pubdate": "Tue, 09 Aug 2022 23:07:56 GMT",
            "pubdate_parsed": [
                2022,
                8,
                9
            ],
            "email_sent": true
        },
        "Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting": {
            "url": "https://machinelearning.apple.com/research/taxonomy-overfitting",
            "description": "The practical success of overparameterized neural networks has motivated the recent scientific study of interpolating methods, which perfectly fit their training data. Certain interpolating methods, including neural networks, can fit noisy training data without catastrophically bad test performance, in defiance of standard intuitions from statistical learning theory. Aiming to explain this, a body of recent work has studied benign overfitting, a phenomenon where some interpolating methods approach Bayes optimality, even in the presence of noise. In this work we argue that while benign\u2026",
            "pubdate": "Wed, 10 Aug 2022 00:14:34 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "FORML: Learning to Reweight Data for Fairness": {
            "url": "https://machinelearning.apple.com/research/learning-to-reweight-data",
            "description": "Machine learning models are trained to minimize the mean loss for a single metric, and thus typically do not consider fairness and robustness. Neglecting such metrics in training can make these models prone to fairness violations when training data are imbalanced or test distributions differ. This work introduces Fairness Optimized Reweighting via Meta-Learning (FORML), a training algorithm that balances fairness and robustness with accuracy by jointly learning training sample weights and neural network parameters. The approach increases model fairness by learning to balance the contributions\u2026",
            "pubdate": "Wed, 10 Aug 2022 23:08:05 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "Minimax Demographic Group Fairness in Federated Learning": {
            "url": "https://machinelearning.apple.com/research/minimax-demographic-group",
            "description": "Federated learning is an increasingly popular paradigm that enables a large number of entities to collaboratively learn better models. In this work, we study minimax group fairness in federated learning scenarios where different participating entities may only have access to a subset of the population groups during the training phase. We formally analyze how our proposed group fairness objective differs from existing federated learning fairness criteria that impose similar performance across participants instead of demographic groups. We provide an optimization algorithm -- FedMinMax -- for\u2026",
            "pubdate": "Wed, 10 Aug 2022 22:54:13 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "Regularized Training of Nearest Neighbor Language Models": {
            "url": "https://machinelearning.apple.com/research/regularized-training",
            "description": "Including memory banks in a natural language processing architecture increases model capacity by equipping it with additional data at inference time. In this paper, we build upon kNN-LM, which uses a pre-trained language model together with an exhaustive kNN search through the training data (memory bank) to achieve state-of-the-art results. We investigate whether we can improve the kNN-LM performance by instead training a LM with the knowledge that we will be using a kNN post-hoc. We achieved significant improvement using our method on language modeling tasks on WIKI-2 and WIKI-103. The main\u2026",
            "pubdate": "Mon, 15 Aug 2022 13:26:43 GMT",
            "pubdate_parsed": [
                2022,
                8,
                15
            ],
            "email_sent": true
        },
        "A Dense Material Segmentation Dataset for Indoor and Outdoor Scene Parsing": {
            "url": "https://machinelearning.apple.com/research/dense-material",
            "description": "A key algorithm for understanding the world is material segmentation, which assigns a label (metal, glass, etc.) to each pixel. We find that a model trained on existing data underperforms in some settings and propose to address this with a large-scale dataset of 3.2 million dense segments on 44,560 indoor and outdoor images, which is 23x more segments than existing data. Our data covers a more diverse set of scenes, objects, viewpoints and materials, and contains a more fair distribution of skin types. We show that a model trained on our data outperforms a state-of-the-art model across\u2026",
            "pubdate": "Mon, 15 Aug 2022 14:20:22 GMT",
            "pubdate_parsed": [
                2022,
                8,
                15
            ],
            "email_sent": true
        },
        "Combining Compressions for Multiplicative Size Scaling on Natural Language Tasks": {
            "url": "https://machinelearning.apple.com/research/combining-compressions",
            "description": "Quantization, knowledge distillation, and magnitude pruning are among the most popular methods for neural network compression in NLP. Independently, these methods reduce model size and can accelerate inference, but their relative benefit and combinatorial inter- actions have not been rigorously studied. For each of the eight possible subsets of these techniques, we compare accuracy vs. model size tradeoffs across six BERT architecture sizes and eight GLUE tasks. We find that quantization and distillation consistently provide greater benefit than pruning. Surprisingly, except for the pair of\u2026",
            "pubdate": "Mon, 22 Aug 2022 17:02:48 GMT",
            "pubdate_parsed": [
                2022,
                8,
                22
            ],
            "email_sent": true
        },
        "CVNets: High Performance Library for Computer Vision": {
            "url": "https://machinelearning.apple.com/research/high-performance-library",
            "description": "We introduce CVNets, a high-performance open-source library for training deep neural networks for visual recognition tasks, including classification, detection, and segmentation. CVNets supports image and video understanding tools, including data loading, data transformations, novel data sampling methods, and implementations of several standard networks with similar or better performance than previous studies.",
            "pubdate": "Mon, 22 Aug 2022 17:09:34 GMT",
            "pubdate_parsed": [
                2022,
                8,
                22
            ],
            "email_sent": true
        },
        "Monge, Bregman and Occam: Interpretable Optimal Transport in High-Dimensions with Feature-Sparse Maps": {
            "url": "https://machinelearning.apple.com/research/monge-bregman-occam",
            "description": "Optimal transport (OT) theory focuses, among all maps  that can morph a probability measure onto another, on those that are the \"thriftiest\", i.e. such that the averaged cost  between  and its image  be as small as possible. Many computational approaches have been proposed to estimate such Monge maps when  is the  distance, e.g., using entropic maps (Pooladian and Niles-Weed, 2021), or neural networks (Makkuva et al., 2020;\nKorotin et al., 2020). We propose a new model for transport maps, built on a family of translation invariant costs , where  and  is a regularizer. We propose a\u2026",
            "pubdate": "Tue, 27 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "Interspeech Conference 2023": {
            "url": "https://machinelearning.apple.com/updates/apple-at-interspeech-2023",
            "description": "<p>Apple is sponsoring Interspeech conference, which will take place in person from August 20 to 24 in Dublin, Ireland. Interspeech is the world\u2019s largest and most comprehensive conference on the science and technology of spoken language processing. Below is the schedule of Apple-sponsored workshops and events at Interspeech 2023.</p>",
            "pubdate": "Fri, 11 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                11
            ],
            "email_sent": true
        }
    },
    "Towards AI Blog": {
        "This AI newsletter is all you need #9": {
            "url": "https://towardsai.net/p/newsletter/this-ai-newsletter-is-all-you-need-9",
            "description": "Last Updated on August 23, 2022 by Editorial Team Author(s): Towards AI Editorial Team Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. What happened this week in\u00a0AI Images generated with Stable Diffusion This week we had our attention turned from Dalle to a new open-source model called Stable Diffusion. Stable Diffusion comes from researchers at Stability AI, a London- and Los Altos-based startup, along with RunwayML, LMU Munich, EleutherAI, and LAION. The big deal: the AI model and code will be published as open source. Yes, it is open source, which means you have access to its code compared to DALLE, which is closed\u00a0source. Stable diffusion is very similar to DALLE 2 in terms of architectural choices, though much lighter due to their use of latent diffusion. Latent diffusion is a powerful way of using the diffusion process, which consists of taking the noise and generating an image, but does that in the latent space using an encoder and a decoder to go from the latent space to the image space. This enables anyone to implement their code as it can run on a single GPU, and it also allows for much faster inference times, which means you won\u2019t have to wait for two minutes to get funny results as with DALLE or Craiyon anymore! It\u2019s also an important step for the community to implement powerful state-of-the-art text-to-image models and experiment with the code, creating a lot of opportunities to bring the research forward with diffusion models and image models. We are very excited to follow the news and work done with Stable Diffusion! If you implement their code, please let us know and share your creations on our discord\u00a0server! You can also play with the Stable Diffusion API right\u00a0now! Hottest News Engineers from Stanford have developed a chip that does AI processing within its memory (improving computing efficiency)\u201cA novel resistive random-access memory (RRAM) chip that does the AI processing within the memory itself, thereby eliminating the separation between the compute and memory units. Their \u201ccompute-in-memory\u201d (CIM) chip, called NeuRRAM, is about the size of a fingertip and does more work with limited battery power than what current chips can\u00a0do.\u201d Stable Diffusion: An Open-Source image generator AI model!Stable Diffusion comes from researchers at Stability AI, a London- and Los Altos-based startup, along with RunwayML, LMU Munich, EleutherAI, and LAION. The big deal: the AI model and code has been published as open source. Play with it\u00a0here. TikTok introduced \u201cAI greenscreen\u201d, their text-to-image generatorThe results aren\u2019t those of Dalle 2 or Midjourney yet, but it is quite cool and they are certainly getting into this race. Right now, AI greenscreen generates abstract \u201cblobs\u201d and swirling imagery focusing on creating nice backgrounds and not photorealistic images. Most interesting papers of the\u00a0week Paint2Pix: Interactive Painting based Progressive Image Synthesis and EditingA novel approach that predicts (and adapts) \u201cwhat a user wants to draw\u201d from rudimentary brushstroke inputs, by learning a mapping from the manifold of incomplete human paintings to their realistic renderings. Get the\u00a0code! UPST-NeRF: Universal Photorealistic Style Transfer of Neural Radiance Fields for 3D SceneA novel 3D scene photorealistic style transfer framework for transferring photorealistic style from an input image to a 3D scene, merging a 2D style transfer approach with voxel representations. Transframer: Arbitrary Frame Prediction with Generative Models [deepmind paper]Transframer: A general-purpose framework for image modeling and vision tasks based on probabilistic frame prediction, combining U-Net and Transformer components. Enjoy these papers and news summaries? Get a daily recap in your\u00a0inbox! Announcements At Towards AI Inc we have exciting news to announce\u200a\u2014\u200awe have acquired Confetti AI. Confetti AI was founded by Mihail Eric and Henry Zhao in 2020 and has grown to 6,000 active users with a content library of over 350 questions. Confetti AI was built on a decade of experience in artificial intelligence and hundreds of hours of discussions with experts in the field. It aims to curate the leading library of machine learning and data science interview questions, focusing on both conceptual understanding and practical applications. Learn more about the\u00a0news. The Learn AI Together Community section!Hey Meme of the\u00a0week! What an awesome way to evaluate the actual technical knowledge of a recruiter \ud83d\ude02. Of course, do not do that, it\u2019s just a meme! Meme shared once again by one of our fantastic moderators with great humor, DrDub#0108. Join the conversation and share your memes with\u00a0us! Featured Community post from the\u00a0Discord Awesome! One of our moderators just launched a super cool\u00a0product! \u201cmy product of book-&#62;IG post generator is inching towards launch.\u201d DrDub#0108DrDub\u2019s product is all about using AI to generate Instagram posts from a book. Authors can use it for free to automatically generate and share quotes and interesting ideas for their books on Instagram. How cool is\u00a0that! Watch some of the results on its Instagram page, and don\u2019t forget to share your own projects or products with the community if you\u2019d like to be featured in the newsletter as\u00a0well! AI poll of the\u00a0week! TAI Curated\u00a0section Article of the\u00a0week Which NLP Task Does NOT Benefit From Pre-trained Language\u00a0Models? There is such a vast history of massively influential pre-trained generic language models that we take then for granted. Still, they are an absolutely required basis for most NLP applications. However, the author of the article we wanted to highlight claims that there are cases in which a pre-trained general model is ineffective, backing up his claims with excellent analysis. If you are interested in publishing with us at Towards AI, please sign up here, and we will publish your blog to our network if it meets our editorial policies and standards. Lauren\u2019s Ethical Take on Stanford\u2019s NeuRRAM Stanford\u2019s progress on NeuRRAM is an incredible feat! I highly encourage reading the entire article on [&#8230;]",
            "pubdate": "Tue, 23 Aug 2022 17:08:03 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Image segmentation of rotating iPhone with scikit-image": {
            "url": "https://towardsai.net/p/l/image-segmentation-of-rotating-iphone-with-scikit-image",
            "description": "Last Updated on August 23, 2022 by Editorial Team Author(s): Dmitri Azarnyh Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Image Segmentation of Rotating iPhone With Scikit-image Modern devices are full of different sensors: front and back cameras, accelerometers, gyroscopes, magnetometers, GPS, etc. Smart use of these devices allows for a large number of interesting applications such as compass, location detection, and\u00a0games. Photo by Nikita Vinogradov on Unsplash. Try to segment this cat from the background\u00a0\ud83d\ude42 One such application is to detect the orientation of an iPhone in space which can be accomplished with data from the accelerometer and gyroscope. In the previous blog post, I wrote about the detection of iPhone orientation around one axis with data from two sensors of iPhone: gyroscope and accelerometer. The reconstruction of iPhone orientation was compared with the video. The results of the orientation reconstructed with sensors were a good qualitative match with the orientation depicted in the\u00a0video: Image by\u00a0author In this blog post, I present the way to extract the angle of iPhone inclination from the video with image segmentation. Then, I show the comparison of an error between two ways of measurement. Let me guide you\u00a0through. Video preparation Before starting with the segmentation, there are a few things to prepare. My video was recorded with an iPhone and had a variate frame rate. To synchronize video clocks with sensor clocks, a constant frame rate is preferable. So, the first step would be to transfer the video to a constant frame rate. The next step would be to split the video into images where each frame corresponds to a jpeg image. The whole dataset of images can be found\u00a0here. Deep learning approach with Mask-R-CNN When we talk about the segmentation of an image, it\u2019s a great temptation to try some cool deep learning algorithm and hope that it will work. Following this temptation, I tried pre-trained Mask-RCNN. Fortunately, a cell phone is one of the classes the original model was trained on. The first result was quite impressive, as shown in the picture\u00a0below: Image by\u00a0author However, with a closer investigation, it appears that some images of the iPhone were misidentified (see the picture\u00a0below): Image by\u00a0author Like in many real-life data science projects, the results of the deep learning model are surprisingly good but do not fully deliver what is expected. At least not for the whole dataset. One option to overcome this challenge would be to label the data and fine-tune the original model. However, given the fact that it\u2019s a red iPhone on an almost white background, there should be some easier ways. Let us have a look at\u00a0them. Classical CV approach with RGB\u00a0image To segment an image, we first try using a 3-channel RGB representation of an image that is short from red, green, and blue. Red would correspond to the first number that is very high, while the second and the third numbers are expected to be low, somewhat like (255,0,0). In this case, we can just choose all red pixels and hope that it will be the iPhone. To capture more shadows of red, I tried to filter all pixels which have a color value for the first channel (red) bigger than 130. For the second and the third channels, I filter the pixels which are lower than 60. Here is the\u00a0code. https://medium.com/media/a551e688f73eff9e4396f46a1c1e2eaf/href Such an approach produces reasonably good\u00a0results: Image by\u00a0author There is also a camera \u201chole\u201d in the iPhone, which is black and was hence not segmented. We can fill out this hole with scikit-image tools: https://medium.com/media/03839bb0955d37149e28db052f339678/href One has to set up the area of the holes to fill out and small objects to filter out. I choose 40000 as the area. Now the segmentation does include the cameras of the\u00a0iPhone: Image by\u00a0author So, the segmentation based on red color in RGB representation works well on one image. However, after running this threshold-based algorithm through all images, I found that there are some segmentation inaccuracies: Image by\u00a0author These inaccuracies could be fixed by manipulating thresholds on red, green, and blue colors. However, if we relax the parameters, the mask starts to capture brown\u00a0color: Image by\u00a0author It\u2019s still possible to play around with thresholds in RGB. However, there are at least three parameters to tune (thresholds in red, green, and blue). Much easier would be to reduce it to only one tunable parameter. For that purpose, we can consider the iPhone image in a different color representation. Classical CV approach with HED\u00a0image In the scikit-image library, several transformations are available from the RGB to different color representations. One of the challenges which I experience in working with the images of rotating iPhones is the separation from dark red and brown. This color separation is well addressed in the Haematoxylin-Eosin-DAB (HED) color space, where Hematoxylin has a deep blue-purple, Eosin is pinkish, and DAB is brown. Red iPhone is quite well detected with Eosin channel of such a color representation, which fixes the issue of mixing it up with brown, as brown is presented as DAB. In the HED representation, we have only one threshold in the Eosin channel to tune. The mask for the images which are challenging for RGB is captured correctly based on the Eosin channel and threshold of\u00a00.05. Image by\u00a0author Scikit-image also provides tools to measure the properties of the segmented region. Among other properties, it\u2019s possible to measure the orientation of the\u00a0iPhone: https://medium.com/media/e988c7639c5c193a6ba5faa9aa407afa/href The full segmentation algorithm would result\u00a0to: https://medium.com/media/2b0d1ce1a118d6ce330b219d1d965485/href A qualitative comparison would result\u00a0to: Image by\u00a0author Quantitative Comparison Now it\u2019s possible to compare the inclination angle, which is derived from segmentation, with the one derived from sensors data. It gives a good\u00a0match: Image by\u00a0author The absolute error between sensors and interpolated values of video\u00a0are: Image by\u00a0author We [&#8230;]",
            "pubdate": "Tue, 23 Aug 2022 16:08:49 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Machine Learning Systems Pt. 3: Modeling Pipelines with TensorFlow Extended": {
            "url": "https://towardsai.net/p/l/machine-learning-systems-pt-3-modeling-pipelines-with-tensorflow-extended",
            "description": "Last Updated on August 23, 2022 by Editorial Team Author(s): Ani Madurkar Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Where to go after your Modeling POC is done Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 23 Aug 2022 15:33:12 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Explore and Validate Datasets with TensorFlow Extended": {
            "url": "https://towardsai.net/p/l/explore-and-validate-datasets-with-tensorflow-extended",
            "description": "Last Updated on August 23, 2022 by Editorial Team Author(s): Nicolo Cosimo Albanese Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Introduction to TensorFlow Data Validation with a practical example Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 23 Aug 2022 15:33:09 +0000",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Fake News Detection with Model Selection and Hyperparameter Optimization in Python": {
            "url": "https://towardsai.net/p/l/fake-news-detection-with-model-selection-and-hyperparameter-optimization-in-python",
            "description": "Last Updated on August 24, 2022 by Editorial Team Author(s): Giovanni Valdata Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A practical guide on fake news detection with model selection and hyperparameter optimization Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 24 Aug 2022 16:13:21 +0000",
            "pubdate_parsed": [
                2022,
                8,
                24
            ],
            "email_sent": true
        },
        "How Can You Drive Your Career in AI Positively Impacting Our Society?": {
            "url": "https://towardsai.net/p/l/how-can-you-drive-your-career-in-ai-positively-impacting-our-society",
            "description": "Last Updated on August 24, 2022 by Editorial Team Author(s): Jair Ribeiro Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Some practical insights on pursuing an engaging and satisfying career that can significantly impact the future of humanity. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 24 Aug 2022 13:33:52 +0000",
            "pubdate_parsed": [
                2022,
                8,
                24
            ],
            "email_sent": true
        },
        "Andrew Ngs 5 Crucial Mindset-shifts for Transitioning Into the Industry From Academia": {
            "url": "https://towardsai.net/p/l/andrew-ngs-5-crucial-mindset-shifts-for-transitioning-into-the-industry-from-academia",
            "description": "Last Updated on August 25, 2022 by Editorial Team Author(s): Arunn Thevapalan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. It doesn&#x2019;t have to be confusing or hard if you listen to the experts Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 25 Aug 2022 16:04:02 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "Deep Learning A-Z Briefly Explained": {
            "url": "https://towardsai.net/p/l/deep-learning-a-z-briefly-explained",
            "description": "Last Updated on August 25, 2022 by Editorial Team Author(s): Gencay I. Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Refreshing and for Quick recall Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 25 Aug 2022 14:18:07 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "Data Science EssentialsStatistics (part I)": {
            "url": "https://towardsai.net/p/l/data-science-essentials%e2%80%8a-%e2%80%8astatistics-part-i",
            "description": "Last Updated on August 25, 2022 by Editorial Team Author(s): Nitin Chauhan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. What is Statistics? Where is statistics applied in? Types of statistics? Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 25 Aug 2022 14:18:04 +0000",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "Understanding the Why of Data Science and Machine Learning Is More Useful Than Knowing the How": {
            "url": "https://towardsai.net/p/l/understanding-the-why-of-data-science-and-machine-learning-is-more-useful-than-knowing-the-how",
            "description": "Last Updated on August 26, 2022 by Editorial Team Author(s): Suhas Maddali Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Learning the purpose of data science can be useful, especially in order to create a business impact in the organization. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 26 Aug 2022 16:21:57 +0000",
            "pubdate_parsed": [
                2022,
                8,
                26
            ],
            "email_sent": true
        },
        "Which NLP Task Does NOT Benefit From Pre-trained Language Models?": {
            "url": "https://towardsai.net/p/nlp/which-nlp-task-does-not-benefit-from-pre-trained-language-models",
            "description": "Last Updated on August 29, 2022 by Editorial Team Author(s): Nate Bush There is such a long history of pre-trained general language representation models with a massive impact that we take for granted that they are a completely 100% necessary foundation for all NLP tasks. There were two separate step function innovations that pushed the accuracy of all NLP tasks forward: (1) statistical language models like Word2Vec and GloVe and, more recently, (2) neural language models like\u00a0BERT,\u00a0ELMo, and recently\u00a0BLOOM. Inserting pre-trained neural language models at the beginning of a modeling workflow is\u00a0almost\u00a0guaranteed to increase performance, but there is at least one situation where it does not. Sidebar: why the sesame street theme?! Named Entity Recognition (NER) Look no further than the original BERT paper titled \u201cBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\u201d to see a detailed analysis of how pre-trained BERT embeddings improve NER performance in section 5. The BERT diagram below shows a typical machine learning workflow for exploiting any language model for general NLP tasks. Source:\u00a0https://arxiv.org/pdf/1810.04805.pdf\u00a0\u2014 Overall pre-training and fine-tuning procedures for BERT The papers also show significant improvement on Question Answering (QA) evaluated against\u00a0SQUAD, and a hodgepodge of natural language understanding (NLU) tasks called\u00a0GLUE. Entity Disambiguation (ED) The global ED task also achieved new state-of-the-art results across multiple datasets using BERT. See the related work section of this \u201cGlobal Entity Disambiguation with BERT\u201d for a rundown of various workflows for applying BERT as a preprocessing step for ED. Extractive Summarization (ES) A simple variant of BERT achieving once again state-of-the-art performance on several ES datasets can be found in \u201cFine-tune BERT for Extractive Summarization\u201d. Sentiment Analysis (SA) Once again, sentiment analysis is equally graced by the existence of BERT language models in the recent paper \u201cBERT for Sentiment Analysis: Pre-trained and Fine-Tuned Alternatives\u201d. I could keep going\u2026 but I won\u2019t. The glory of pre-trained language models is obvious. We only need to stand on the shoulders of giants who spent countless hours preparing massive corpora of data, deploying expensive GPUs to pre-train these models for us. These models aren\u2019t a silver bullet, though. The main natural language task that has failed to show consistent performance improvements from sesame street and friends is\u00a0Neural Machine Translation (NMT). NMT usually doesn\u2019t benefit from Pre-trained language models It\u2019s difficult to find papers that discuss why it doesn\u2019t work, and it\u2019s easy to imagine why. Writing papers about what doesn\u2019t work is not very popular\u2026 and unlikely to gain recognition or be frequently quoted. Ah shoot \u2014 so why am I writing this article again? I found one paper that covered this topic: \u201cWhen and Why are Pre-trained Word Embeddings Useful for Neural Machine Translation?\u201d\u00a0and it was an interesting read. They break NMT down into two categories of tasks: NMT for low-resource languages NMT for high-resource languages What they mean by\u00a0low/high\u00a0resource language is in reference to the size of the parallel corpus that can be obtained. For the world&#8217;s most popular languages, it can be easy to find open-source large parallel corpora online. The largest such repository is\u00a0OPUS, the Open Parallel Corpus, which is an amazing resource for any machine learning engineer looking to train NMT models. Source:\u00a0OPUS\u00a0&#8211; high resource parallel corpus between English (en) and Chinese (zh) The image above shows that the open parallel corpus between English and Chinese has 103 million parallel sentences or 172K parallel documents. But what if you wanted to train an NMT model to translate Farsi to Chinese? In that case, you only have 6 million parallel sentences from 517 documents to work with. Source:\u00a0OPUS\u00a0&#8211; low resource parallel corpus between Farsi (fa) and Chinese (zh) As you might expect, low-resource languages benefit from pre-trained language models and are able to achieve better performance when fine-tuning the embeddings while back-propagating errors through the NMT network.\u00a0Surprisingly, however, for high-resource languages, the effect of using pre-trained language models as a pre-processing step before NMT model training does NOT result in performance gains. It\u2019s critical to point out that\u00a0language models only make sense to use for machine translation\u00a0if they are trained on both source and target language (for example, Chinese and English in the first example). These are commonly referred to as multilingual embedding models or language agnostic embeddings. They are able to achieve the interesting result that words in multiple languages achieve similar vector representations in the embedding space. Source:\u00a0AI Googleblog But how are multilingual language models trained? Turns out they are trained over the exact same data as NMT: a massive parallel corpus between the source and target language. So, is there a fundamental shortcoming to language models that prevent them from being effective for this NLP task? No, language models use the same data as NMT models, and they are both built from the same powerhouse building block: the transformer. To review, language models and NMT are trained over the same data, using very similar fundamental architectures. When you consider the similarities, there isn\u2019t really anything new that the language models are bringing to the table so it shouldn\u2019t be surprising to you that BERT, ELMo, ERNIE, and our other sesame street friends aren\u2019t appearing in NMT papers touting huge breakthroughs in model performance. A skeptical reader will likely be able to poke holes in this explanation. There are certainly devisable use cases were training an LM on a large parallel corpus but then training BERT + NMT workflow on a much smaller corpus would intuitively result in performance gains. But I think it\u2019s unlikely that a serious deep learning engineer would attempt to build an NMT model without all available data at their disposal\u2026 outside of purely academic curiosities. I tip-toed over some hairy details, so I recommend reading\u00a0the original paper\u00a0if you\u2019re interested! I hope you enjoyed this short exploration into the intuition behind what makes NLP algorithms successful. Please like, share, and follow for more deep learning knowledge. Which NLP Task Does NOT Benefit From Pre-trained Language Models?\u00a0was originally published in Towards AI\u00a0on Medium, where people are continuing the conversation by [&#8230;]",
            "pubdate": "Mon, 29 Aug 2022 13:34:37 +0000",
            "pubdate_parsed": [
                2022,
                8,
                29
            ],
            "email_sent": true
        },
        "Improve Your Model Validation With TorchMetrics": {
            "url": "https://towardsai.net/p/l/improve-your-model-validation-with-torchmetrics",
            "description": "Last Updated on August 29, 2022 by Editorial Team Author(s): Mattia Gatti Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A guide on how to use TorchMetrics with PyTorch or PyTorch Lightning models Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 30 Aug 2022 00:14:55 +0000",
            "pubdate_parsed": [
                2022,
                8,
                30
            ],
            "email_sent": true
        },
        "Impact of Optimizers in Image Classifiers": {
            "url": "https://towardsai.net/p/l/impact-of-optimizers-in-image-classifiers",
            "description": "Last Updated on August 30, 2022 by Editorial Team Author(s): Toluwani Aremu Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Photo by Ales Krivec on\u00a0Unsplash INTRODUCTION Ever wondered why a DNN fails to perform as high as expected when it comes to accuracy, especially when there are official or unofficial reports of experts and enthusiasts getting some top performance with the same network and on that same dataset you are using? I remember having hard times trying to wrap my head around the thought that my models just failed when it was expected to perform well. What causes this? In reality, there are lots of factors with varying levels of potential to impact the performance of your architecture. However, I\u2019ll discuss just one in this article. This factor is \u201cThe choice of Optimization algorithm to\u00a0use\u201d. What is an optimizer? An optimizer is a function or algorithm that is created and used for neural network attribute modification (i.e., weights, learning rates) for the purpose of speeding up convergence while minimizing loss and maximizing accuracy. DNNs use millions of billions of parameters, and you need the right weights to ensure that your DNN learns well from the given data while generalizing and adapting well for a good performance on unseen related\u00a0data. Different optimization algorithms have been built over the years, and some of these algorithms have advantages over others, as well as their cons. Therefore, it is imperative to know the basics of these algorithms, as well as understand the problem being worked on so that we can select the best optimizer to work\u00a0with. Furthermore, I noticed that a lot of researchers use the SGD-M (Stochastic Gradient Descent with Momentum) optimizer, but in the industry, Adam is favored more. In this article, I will give brief high-level descriptions of the most popular optimizers being used in the AI world. Actually, I had to do a number of experiments to see the difference between these optimizers and answer some questions I have about the use of these optimizers, as well as give clues on which optimizer is the best and when/how to use them based on my observations. BASIC DESCRIPTION OF DIFFERENT OPTIMIZERS https://ruthwik.github.io/machinelearning/2018-01-15-gradient-descent/ In this section, I will briefly discuss the Stochastic Gradient Descent with Momentum(SGDM), Adaptive Gradient Algorithm (ADAGRAD), Root Mean Squared Propagation (RMSProp), and the Adam optimizers. SGDM: Since the Gradient Descent (GD) optimizer uses the whole training data to update the model\u2019s weights, it becomes so computationally expensive when we have millions of data points. Due to this, the Stochastic Gradient Descent (SGD) was created to solve this problem by using each datapoint to update the weights. Still, this was computationally expensive for Neural Networks (NN)each datapoint used in the NN needed both forward and back propagations. Also, with SGD, we can\u2019t increase the learning rate while it tries to reach the global minimum. This makes convergence very slow while utilizing the SGD. The SGDM was the solution to that, as it added a momentum term to the normal SGD, which improved the speed of convergence. For deeper explanations, click\u00a0here. Image by Sebastian Ruder ADAGRAD: Adaptive Gradient Algorithm (Adagrad) is an algorithm for gradient-based optimization which tries to adapt the learning rate to the parameters. The learning rate fits the parameters component by component by incorporating insights from past observations. It makes minor updates to parameters associated with frequent features and major updates to those with features that aren\u2019t occurring frequently. Adagrad also eliminates the need for tuning the learning rate manually as it automatically updates the learning rate based on the parameters. However, the learning rate shrinks fast, making the model think it is close to achieving convergence and stops somewhat short of the expected performance. To learn more, click\u00a0here. RMSProp: Proposed by Geoffrey Hinton (even though it remains unpublished), the RMSProp is an extension of the GD and the AdaGrad version of gradient descent that uses a decaying average of partial gradients in the adaptation of the step size for each parameter. It was discovered that the magnitude of gradients can be different for different parameters and could change during the training. Therefore, Adagrad&#039;s automatic choice of learning rate could be the nonoptimized choice. Hinton solved this by updating the learned weights using a moving average of the squared gradients. To learn more, click\u00a0here. Adam: This optimizer was proposed by Diederik Kingma and Jimmy Ba in 2015 and could arguably be regarded as the most popular optimizer ever created. It combines the advantages and benefits of SGDM and RMSProp in the sense that it uses momentum From SGDM and scaling from RMSProp. It is computationally efficient, unlike both GD and SGD, and requires only a little memory. It was designed to be used on problems with very noisy/sparse gradients. To learn more, click here or\u00a0here. EXPERIMENTS Photo by Kevin Ku on\u00a0Unsplash Due to the size of my computing resource, I decided to focus on using LeNet and AlexNet on the CIFAR-10 dataset. The CIFAR-10 dataset consists of 50000 training images and 10000 test images. I trained these models for 50 epochs using the SGD, SGDM, Adagrad, RMSProp, and Adam optimizers. For the SGDM, I used a momentum of 0.9. The global learning rate for my first set of experiments was 0.001\u00a0(1e-3). Note: I am not seeking very good results. I am instead trying to see the impact of each optimizer on the model\u2019s performance. I start by calling the important libraries: https://medium.com/media/425968addc0d7bb7e1dbe8466f7c788b/href Then, I loaded and transformed the CIFAR-10\u00a0dataset: https://medium.com/media/2aed5c7db98e0cf2058155c6832500ea/href The LeNet and AlexNet\u00a0models: https://medium.com/media/f92213170ff3ae0d7646ce4ed9487925/href To get the full code, check out this repository (give it a star if you don\u2019t\u00a0mind). The results are as\u00a0follows. On the LeNet model, the test accuracy of SGDM was the highest at almost 70%, while [&#8230;]",
            "pubdate": "Tue, 30 Aug 2022 12:47:29 +0000",
            "pubdate_parsed": [
                2022,
                8,
                30
            ],
            "email_sent": true
        },
        "Easy Object Detection with Transformers: Simple Implementation of Pix2Seq model in PyTorch": {
            "url": "https://towardsai.net/p/l/easy-object-detection-with-transformers-simple-implementation-of-pix2seq-model-in-pytorch",
            "description": "Last Updated on August 30, 2022 by Editorial Team Author(s): Moein Shariatnia Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Easy Object Detection with Transformers: Simple Implementation of Pix2Seq Model in\u00a0PyTorch My Simple Implementation of Pix2Seq &#124; Image by\u00a0author Introduction Object detection does not have to be a difficult task! I clearly remember the first time I implemented YOLO from scratch, and it was a pain to understand how it works under the hood. For beginners in computer vision applications, I believe that object detection is the hardest one to understand among classification, segmentation, etc. Once I first heard about the paper \u201cPix2seq: A Language Modeling Framework for Object Detection\u201d from ICLR 2022, I got pretty excited, and I was sure my next blog post would be about it; so, here I am writing this post and hoping that you\u2019ll like it and find the pix2seq model easy to understand and implement. At the end of this tutorial, you\u2019ll learn to implement a simple model for object detection which produces the following results: Our final model\u2019s predictions on validation set &#124; Image by\u00a0Author I have made all of my code available as Google Colab Notebook and a Kaggle Notebook. I\u2019ve also put the whole project and codes on my\u00a0GitHub. What\u2019s interesting about this\u00a0paper The idea is pretty simple: Reframe the object detection problem as a task of text (token) generation! We want the model to \u201ctell us\u201d what objects exist in the image and also the (x, y) coordinates of their bounding boxes (bboxes), all in a specific format in the generated sequence, just like text generation! How pix2seq works: it generates a sequence of tokens telling where each object is (BOS=beginning of sentence, EOS=end of sentence) &#124; Image by\u00a0author As you see, the object detection task is transformed into an image-captioning-ish task: describe the image in the text (sequence) but this time tell us exactly where the objects\u00a0are. Pix2Seq: Simple Implementation Needed Modules The closest task to what Pix2Seq does is image-captioning. So, we are going to need an image encoder to convert an image into vectors of hidden representation and then a decoder to take the image representations and those of the previously generated tokens and predict the next token. We also need a tokenizer to convert object classes and coordinates into tokens that form their special vocabulary, just like the words in a natural language. My Simple Implementation of\u00a0Pix2Seq My Simple Implementation of Pix2Seq &#124; Image by\u00a0author You can see the high-level pipeline of this project in the picture above. As you see, we need a dataset of images and their bboxes for which we will use Pascal VOC 2012 dataset. Next, we will write our own tokenizer from scratch to convert the bbox classes and coordinates into a sequence of tokens. Then, we will use DeiT (from this paper) as our image encoder and feed the image embeddings to a vanilla Transformer Decoder (from this paper). The decoder\u2019s task is to predict the next token given the previous ones. The outputs of the decoder are given to the language modeling loss function. The codes of this tutorial are available in the following links:&#8211; Google Colab Notebook&#8211; Kaggle Notebook&#8211; My GitHub\u00a0repo Dataset As I mentioned earlier, we will use VOC 2012 dataset with images and their corresponding objects from 20 classes. The paper uses the COCO dataset, which is an order of magnitude larger than VOC, and they also pre-train the models on a much larger dataset before training on COCO. But, to stay simple, I\u2019m going to use this rather small VOC\u00a0dataset. https://medium.com/media/162ec2395c7e4072b199f4f644e15ebd/href We need a PyTorch dataset class that gives us an image and its bbox coordinates and classes in the form of a sequence. https://medium.com/media/2ec93cbbe19051b30e8609a0d49051a0/href As you see, most of the code here is what you expect from a simple dataset for classification, but there are small differences too. We need a Tokenizer to convert our labels and bbox coordinates (x and y) to a sequence so that we can perform train our model for the language modeling task (predicting the next tokens conditioned on the previously seen\u00a0tokens). Tokenizer How are we going to convert this information into a sequence? Well, it\u2019s not that difficult. To represent an object in an image, we need 5 numbers: 4 coordinate numbers and 1 to indicate which class it belongs\u00a0to. You actually need to know the coordinates of 2 points of a bounding box to be able to draw it in an image; in pascal format, we use the top left point and the bottom right point of the bbox as those 2 critical points, and each point is represented by its x and y values \u2192 so, we will need 4 numbers overall to draw a bounding box. You can see alternative formats to represent a bounding box down below. Also, look at where the start of x and y axis is (the 0, 0\u00a0point). Different formats to represent a bounding box with its coordinates &#124; Image from Albumentations docs As you see in the dataset\u2019s code, we give the bbox coordinates and labels to our tokenizer and get a simple list of tokens out. The tokenizer needs to do the following tasks: mark the start and end of the sequence w/e special tokens (BOS and EOS\u00a0tokens). quantize the continuous value of coordinates (we can have x=34.7 as the coordinate of a point, but we need discrete values like 34 as our tokens because we are finally doing classification on a finite set of\u00a0tokens) encode the label of the objects into their corresponding tokens randomize the order of objects in the final sequence (more on this\u00a0below) If you are familiar with NLP applications, these steps might sound familiar to you [&#8230;]",
            "pubdate": "Tue, 30 Aug 2022 12:14:44 +0000",
            "pubdate_parsed": [
                2022,
                8,
                30
            ],
            "email_sent": true
        },
        "List of Important Libraries for Machine Learning and Data Science in Python": {
            "url": "https://towardsai.net/p/l/list-of-important-libraries-for-machine-learning-and-data-science-in-python",
            "description": "Last Updated on August 30, 2022 by Editorial Team Author(s): Suhas Maddali Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Understanding the use of various libraries in python and machine learning is handy for professionals in the field of data science. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 31 Aug 2022 00:13:46 +0000",
            "pubdate_parsed": [
                2022,
                8,
                31
            ],
            "email_sent": true
        },
        "What is Panoptic Scene Graph Generation (PSG)?": {
            "url": "https://towardsai.net/p/l/what-is-panoptic-scene-graph-generation-psg",
            "description": "Last Updated on September 1, 2022 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. PSG&#x200a;&#x2014;&#x200a;A New Challenging Task for AI Explained Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 02 Sep 2022 00:13:45 +0000",
            "pubdate_parsed": [
                2022,
                9,
                2
            ],
            "email_sent": true
        },
        "Recurrent Neural Networks: A Very Special Kind of Mnemonist": {
            "url": "https://towardsai.net/p/l/recurrent-neural-networks-a-very-special-kind-of-mnemonist",
            "description": "Last Updated on September 7, 2022 by Editorial Team Author(s): Diego Manfre Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Preserving information is another way of remembering Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 08 Sep 2022 00:13:50 +0000",
            "pubdate_parsed": [
                2022,
                9,
                8
            ],
            "email_sent": true
        },
        "Difference Between Normalization and Standardization": {
            "url": "https://towardsai.net/p/l/difference-between-normalization-and-standardization",
            "description": "Last Updated on September 10, 2022 by Editorial Team Author(s): Chetan Ambi Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Understand the differences between normalization and standardization, different methods, and most importantly, when should you consider&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 11 Sep 2022 00:08:46 +0000",
            "pubdate_parsed": [
                2022,
                9,
                11
            ],
            "email_sent": true
        },
        "From Classification to Ordinal Regression": {
            "url": "https://towardsai.net/p/l/from-classification-to-ordinal-regression",
            "description": "Last Updated on September 13, 2022 by Editorial Team Author(s): Topaz Gilad Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Unlock the Potential of Your\u00a0Labels AI-generated (Midjourney): \u201clion-elephant hybrid, illustration, children\u2019s book\u201d and \u201celephant with lion\u00a0face\u201d \u201cIs a lion closer to be a giraffe or an elephant?\u201d It is a question no one asked. Ever. Classifying lions, elephants and giraffes is a straightforward classification task. As such, it can be mostly addressed with a cross-entropy loss. Should the task of classifying someone as a child/adult/elderly be addressed in the same\u00a0way? In this blog post, we will overview best practice approaches and papers for:(1) Addressing ordered classification.(2) Coarse classification labels into regression continuous predictions.(3) How to choose.(4) How to evaluate.The papers reviewed in this post focus on deep learning models, but the main concepts apply and may be adapted for other ML architectures as\u00a0well. Discrete Labels in a Continuous World \u201cThe world is continuous, but the mind is discrete.\u201d&#8211; David Mumford, ICM\u00a02002 We often define categories when breaking down a real-world problem into an ML-based solution. However, real target values may be continuous or at least ordered. This is something to consider and even leverage in the design of your ML model. Are you facing what seems as a classification problem? Take a moment to understand the hidden relations between your \u201cclasses\u201d. Let\u2019s list some classification examples:&#8211; Online ratings: 1\u20135 stars.&#8211; Medical diagnosis index\u200a\u2014\u200astage 1/2/3.&#8211; Face pose estimation [1]\u200a\u2014\u200a45/90/180 degrees.&#8211; Age estimation and so\u00a0on. Left to right: Age prediction: https://data.vision.ee.ethz.ch/cvl/rrothe/imdb-wiki/. image credit: https://en.wikipedia.org/wiki/What%27s_My_Age_Again%3F Predict rating (ilmakiage.com), medical severity index of dVRS, Zhu et al. https://www.ahajournals.org/doi/10.1161/strokeaha.110.591586 Know Your\u00a0Data Approaching the design of an ML solution, some of the first steps are\u00a0:(a) Understand what data you currently have / what data you are likely to obtain in a reasonable time. In some cases, you will have continuous measurements associated with your data. For example, blood measurements or information on exact age. More often than not, those will not be available. Manual annotation of fine-grained labels is an extremely difficult and time-consuming task. Therefore, in many cases, all you will have are coarse categorical labels. Especially where an expert human opinion is required. (b) Explore the domain. Ask your data domain expert to clarify the relations between the target classes. Every bit of prior knowledge or assumptions they assume. Question the format of the output they ask for. For example: Can a smooth real number between 0 to 1 be a better product use than a failed/passed/excellent student score predictor? If your classes are indeed independent, this is not the blog post for you!However, if they are dependent, ask yourself:(1) Do the labels have an order?(2) Do you only care about the order, or are some labels closer to their nearest labels than others? Are the \u201csteps\u201d of distances between labels\u00a0uniform? Regression to the\u00a0Rescue Logistic RegressionMost are familiar with logistic regression to discriminate between classes. While the target labels are discrete, the estimated class confidence is continuous. Let\u2019s consider the following case: The consequences of wrongly classifying class A as class B is not as severe as a mistake between A and C. One approach can be to use a weighted loss with the risk coefficient of each type of mistake\u00a0[2]. Ordinal RegressionAnother approach can be to encode the one-hot vector labels differently, as suggested in the NNRank paper [3]. For a hands-on example, I recommend Gruber\u2019s post and Kotwani\u2019s. Note that if modeling as an aggregation of an ensemble of binary classifiers, inconsistencies in class predictions may occur. Cao et al. 2020 CORAL suggest a solution to achieve consistency of rank\u00a0[4]. Figure from Cao et al 2020 CORAL [4]: inconsistent rank when aggregating binary classifiers (left) compared to the desired outcome\u00a0(right) Linear Regression\u200a\u2014\u200aSeeing Beyond the Available Labels Netflix launched lately a double thumbs up. By that, they expanded the 3 (dislike/indifferent/like) into 4 categories. This is a better distinction inside what used to be the \u201cliked\u201d category: liked vs. liked a lot. Imagine you have many coarse \u201cliked\u201d votes from the past and only a few new \u201cdouble thumbs\u201d votes. Estimating a score of user satisfaction (instead of a class) gives you better adaptivity to the new user\u00a0inputs. Qin et al BioeNet 2020 showcases a strategy to leverage coarse labels into a fine-grained linear regression [5]. One of the important things to consider when taking that path is to evaluate your inner-class order. We will discuss next\u00a0how. Figures from Qin et al. BioeNet 2020: Learning fine-grained estimation from coarse labels\u00a0[5] Another possible benefit of transforming your discrete integer target labels into real numbers is the positive effect of soft labels. As shown by the Google Brain team (2020), using soft labels not only reduced over-confidence but also improved the calibration even without temperature scaling\u00a0[6\u20138]. Make Sure You Are in the Right Direction Shape and Location of ClustersI am a big believer in the analysis of your DNN embedded feature space. Create a T-SNE of your test set feature space. Follow the illustrations in the figure below. With a cross-entropy loss, you expect each cluster to condense (minimize inner-class variance) and move away from one another (maximize intra-class variance). However, in ordinal regression, you expect to see the clusters in the right order of proximity in the feature space. For linear regression with an MSE loss, for example, you will not only expect to see the right order but also a continuous order between classes with less margin from one cluster to the next. If you still do see a noticeable margin, this may also indicate your test set is lacking border examples. Illustration by the\u00a0author Relations Between Samples from the Same CategoryIf you can get your hands on a few finer-grained labeled samples, you can use them [&#8230;]",
            "pubdate": "Wed, 14 Sep 2022 00:18:36 +0000",
            "pubdate_parsed": [
                2022,
                9,
                14
            ],
            "email_sent": true
        },
        "Is Google AI Sentient? Heres What I Really Think About LaMDA": {
            "url": "https://towardsai.net/p/l/is-google-ai-sentient-heres-what-i-really-think-about-lamda",
            "description": "Last Updated on September 14, 2022 by Editorial Team Author(s): Edoardo Bianchi Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Let&#x2019;s try to figure out if an AI can feel emotions Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 14 Sep 2022 12:18:52 +0000",
            "pubdate_parsed": [
                2022,
                9,
                14
            ],
            "email_sent": true
        },
        "Univariate Linear Regression From Scratch": {
            "url": "https://towardsai.net/p/l/univariate-linear-regression-from-scratch",
            "description": "Last Updated on September 19, 2022 by Editorial Team Author(s): Erkan Hatipo\u011flu Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. With Code in\u00a0Python Univariate Linear Regression\u200a\u2014\u200aImage by\u00a0Author Introduction Generally, one of the first subjects of a Machine Learning Course is Linear Regression, which is not very complex and easy to understand. Moreover, it includes many Machine Learning notions that can be used later in more complex concepts. So it is reasonable to start with Linear Regression to a new Machine Learning basics\u00a0series. In this blog post, we will learn about Univariate Linear Regression which means Linear Regression with just one variable. At the end of this article, we will understand fundamental Machine Learning concepts such as the hypothesis, cost function, and gradient descent. In addition, we will write the necessary code for those functions and train/test a linear model for a Kaggle dataset using Python\u00a0[1]. Before diving into Univariate Linear Regression, let&#039;s briefly talk about some basic concepts: Basic Concepts Machine Learning is the subfield of Artificial Intelligence that uses data to program computers for some tasks. A typical Machine Learning application uses a dataset and a learning algorithm to make a model that can then predict the outputs for new inputs to the application. Machine Learning applications are generally divided into three categories: Supervised Learning Unsupervised Learning Reinforcement Learning In supervised learning [2], the data have identical features that can be mapped to some label. Supervised learning has two\u00a0types. It is called classification if the number of labels is limited and can be transformed into some categories. Identifying animals or handwritten digits in images are examples of classification. If the set of labels is not restricted to some small number of elements but can be assumed infinitely many, then it is called regression. Predicting the price of houses in a region or gas usage per kilometer of cars are regression examples. In unsupervised learning [3], the dataset has no labeled data. After the teaching process, the model discovers the patterns in the data. Categorizing the customers of an e-commerce website is an example of unsupervised learning. Reinforcement learning [4] uses intelligent agents who act according to reward and punishment mechanisms [5]. It is mainly used in computer\u00a0gaming. Linear Regression As we have said above, regression maps inputs to infinitely many outputs. In addition, Linear Regression suggests a linear relationship between the inputs and outcomes [6]; it is challenging to visualize this if we have more than one input variable. If we have one input variable, we need to draw a line in the XY plane; if we have two input variables, we need to construct a plane in the three-dimensional coordinate system. More than two input variables are extremely tough to imagine. As a result, we will demonstrate Linear regression using univariate data. Below are the housing prices from Portland, Oregon dataset [7], which we will use as an\u00a0example. Housing Prices from Portland, Oregon\u200a\u2014\u200aImage by\u00a0Author In the graph above, the y-axis is the price (K$) of some houses in Portland, and the x-axis is the house&#039;s size (feet\u00b2). We want to draw a straight line on this graph (such as the image below) so that when we know the size of a new home not in this dataset, we can predict its price by using that\u00a0line. Housing Prices from Portland, Oregon with Hypothesis\u2014 Image by\u00a0Author For example, we can predict that the price of a 3000 feet\u00b2 house is approximately 500 K$, as seen in the graph\u00a0below. Calculating New Inputs for Housing Prices from Portland, Oregon\u200a\u2014\u200aImage by\u00a0Author So without further ado, let&#039;s dive into more profound concepts to understand how to draw that\u00a0line. Note that this article uses the Linear Regression dataset [1] and Univariate Linear Regression from Scratch notebook [8] from Kaggle. As described in the content part of the dataset, it has a training dataset of 700 and a test dataset of 300 elements. The data consists of pairs of (x,y) where x\u2019s are numbers between 0 and 100 and y\u2019s have been generated using the Excel function NORMINV(RAND(), x, 3). It is also given that the best estimate for y should be\u00a0x. First, we must write three functions to find a univariate linear regression solution on a dataset. These functions are for the hypothesis, cost, and gradient descent calculations in order. Foremost, we will explain them one by\u00a0one. The Hypothesis We aim to find a model we can use to predict new inputs. A hypothesis is a potential model for a machine learning system\u00a0[9]. As seen in the figure below, we can find the hypothesis for a dataset by using a learning algorithm [10]. Later we will talk about how well this hypothesis fits our data but for now, let&#039;s just define the hypothesis formula. The Hypothesis\u200a\u2014\u200aImage by\u00a0Author For a univariate linear regression task, the hypothesis is of the\u00a0form: The Hypothesis Formula\u200a\u2014\u200aImage by\u00a0Author The intersection of the y-axis with the hypothesis line is called intercept. This is \u03b8\u2080 in our formula, and the slope of the hypothesis line is\u00a0\u03b8\u2081. If we know x, \u03b8\u2080, and \u03b8\u2081 values, we can predict the target value for a machine learning system. For example, in the housing prices example above, \u03b8\u2080 = 0.00008, and \u03b8\u2081 = 0.16538 for the red line. So for a house of 3000 feet\u00b2 (x=3000), the expected price\u00a0is: As can be seen, we need three parameters to write the hypothesis function. These are x (input), \u03b8\u2080, and \u03b8\u2081. So, let&#039;s write the Python function for the hypothesis: https://medium.com/media/3c752accc7341b367a1a05bcd7148652/href The process is pretty straightforward. We just need to return (\u03b8\u2080+ \u03b8\u2081*\u00a0x). The Cost\u00a0Function When we have a hypothesis (i.e., we know the values of \u03b8\u2080 and \u03b8\u2081), we must decide how well this hypothesis fits our data. Turning back to the [&#8230;]",
            "pubdate": "Mon, 19 Sep 2022 12:13:16 +0000",
            "pubdate_parsed": [
                2022,
                9,
                19
            ],
            "email_sent": true
        },
        "Important Techniques to Handle Imbalanced Data in Machine Learning Python": {
            "url": "https://towardsai.net/p/l/important-techniques-to-handle-imbalanced-data-in-machine-learning-python",
            "description": "Last Updated on September 19, 2022 by Editorial Team Author(s): Muttineni Sai Rohith Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. How to Handle Imbalanced Data in ML Classification using\u00a0Python In this article, we will discuss what is Imbalanced Data, the Metrics we should use to evaluate the model with Imbalanced Data, and the Techniques used to Handle Imbalanced Data. While doing binary classification, almost every data scientist might have encountered the problem of handling Imbalanced Data. Generally Imbalanced data occurs when the datasets are distributed unequally i.e. when the frequency of data points or the number of rows in one class is much more than in other classes, then the data is imbalanced. For example, suppose we have a covid Dataset, and our target class is whether a person is having covid or not, if the positive ratio is 10% in our class and the negative ratio is 90%, then we can say that our Data is imbalanced. Image By\u00a0Author Problem with Imbalanced Data Most machine learning algorithms are designed in a way to improve accuracy and reduces errors. In this process, they don\u2019t consider the distribution of classes. Also, standard machine learning algorithms like Decision trees and Logistic Regression have a bias toward Majority classes and tend to ignore minority classes. So in these cases, even though the model has 95% accuracy, it cannot be said as a perfect model as the frequency of the number of classes in testing data may be 95%, and 5% wrongly predicted data must be from the minority\u00a0class. Accuracy pitfall Before diving into the handling of Imbalanced Datasets, Let\u2019s understand the metrics we should use while evaluating the models. Generally, accuracy_score is calculated as the ratio of the number of correct predictions to the total number of predictions. Accuracy = Number of Correct Predictions / Total Number of Predictions. So we can see that accuracy_score will not consider the distribution of classes. It only focuses on the Number of Correct Predictions. So Even though we get 95+ accuracy, as shown in the above example, we can\u2019t guarantee the performance of the model and its prediction of the minority\u00a0class. So for classification techniques, instead of accuracy_score, it is recommended to use Confusion Matrix, precision_score, recall_score, and Area under the ROC Curve(AUC) as Evaluation Metrics. Handling Imbalanced Data A technique that is widely used while handling imbalanced data is Sampling. There are two types of Sampling\u00a0\u2014 Under Sampling Over Sampling In Under Sampling, samples are removed from the majority class, whereas, in Over Sampling, samples are added to the minority\u00a0class. To demonstrate the usage of the above techniques, initially, we will consider an example without Handling Imbalanced Data. Dataset used can be found\u00a0here. Importing Libraries # import necessary modules import pandas as pdimport matplotlib.pyplot as pltimport numpy as npfrom sklearn.linear_model import LogisticRegressionfrom sklearn.preprocessing import StandardScalerfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score Loading Data df = pd.read_csv(\"/content/drive/MyDrive/creditcard.csv\") Preparing Data # normalise the amount column df[&#039;normAmount&#039;] = StandardScaler().fit_transform(np.array( df[&#039;Amount&#039;]).reshape(-1, 1)) # drop Time and Amount columns as they are not relevant for prediction purposedata = df.drop([&#039;Time&#039;, &#039;Amount&#039;], axis = 1) # as you can see there are 492 fraud transactions.data[&#039;Class&#039;].value_counts() Output X = data.drop([&#039;Class&#039;], axis = 1)y = data[\"Class\"] Splitting train-test-data from sklearn.model_selection import train_test_split # split into 70:30 ratioX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0) # describes info about train and test set print(\"Number transactions X_train dataset: \", X_train.shape)print(\"Number transactions y_train dataset: \", y_train.shape)print(\"Number transactions X_test dataset: \", X_test.shape)print(\"Number transactions y_test dataset: \", y_test.shape) Output Classification # logistic regression objectlr = LogisticRegression() # train the model on train setlr.fit(X_train, y_train.ravel())predictions = lr.predict(X_test) # print classification reportprint(\"Accuracy score is: \",accuracy_score(y_test, predictions))print(\"Recall score is: \",recall_score(y_test, predictions))print(\"Precision score is: \",precision_score(y_test, predictions))print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, predictions)) Output As we can see, even though the Accuracy score is 99.9%, we can see that the Recall score is 61.9% which is relatively low, and the Precision score is\u00a088.3%. This is because the dataset is imbalanced, and now we will try to improve these scores using the techniques mentioned above. Handling Imbalanced Data using Under\u00a0Sampling Under Sampling involves the removal of records from the majority class to balance out with the minority\u00a0class. The simplest technique involved in under-sampling is Random under-sampling. This technique involves the removal of random records from the majority class. But there will be a loss of important information if we randomly remove the rows. So various techniques are implemented for undersampling the data. One such import technique is NearMiss Undersampling. NearMiss Undersampling In this technique, data points are selected based on the distance between the majority and minority classes. It has 3 different versions, and each version considers the different data points from the majority\u00a0class. Version 1\u200a\u2014\u200aIt selects data points of the majority class whose average distances to the K closest instances of minority class is the\u00a0smallest Version 2\u200a\u2014\u200aIt selects data points of the majority class whose average distances to the K farthest instances of minority class is the\u00a0smallest Version 3\u200a\u2014\u200aIt works in 2 steps. Firstly, for each minority class instance, their M nearest neighbors will be stored. Then finally, the majority class instances are selected for which the average distance to the N nearest neighbors is the\u00a0largest. In short, Version 3 is the more accurate version as it will remove the tomek links and makes the classification process easy as it forms a decision boundary. NearMiss Undersampling # apply near missfrom imblearn.under_sampling import NearMiss nr = NearMiss() X_train_miss, y_train_miss = nr.fit_resample(X_train, y_train.ravel()) print(&#039;After Undersampling, the shape of train_X: {}&#039;.format(X_train_miss.shape)) print(&#039;After Undersampling, the shape of train_y: {} \\n&#039;.format(y_train_miss.shape)) print(\"After Undersampling, counts of label &#039;1&#039;: {}\".format(sum(y_train_miss == 1))) print(\"After Undersampling, counts of label &#039;0&#039;: {}\".format(sum(y_train_miss == 0))) Output We have undersampled the majority class\u200a\u2014\u200a0and balanced it out [&#8230;]",
            "pubdate": "Mon, 19 Sep 2022 07:18:46 +0000",
            "pubdate_parsed": [
                2022,
                9,
                19
            ],
            "email_sent": true
        },
        "Latent Diffusion Explained Simply (with Pokmon)": {
            "url": "https://towardsai.net/p/l/latent-diffusion-explained-simply-with-pokemon",
            "description": "Last Updated on September 19, 2022 by Editorial Team Author(s): Leonardo Castorina Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. From Text to Image, Image to Image and Inpainting&#x200a;&#x2014;&#x200a;the Latent Diffusion revolution Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 19 Sep 2022 07:03:45 +0000",
            "pubdate_parsed": [
                2022,
                9,
                19
            ],
            "email_sent": true
        },
        "This Is How You Can Explain SVD to a 7-Year-Old": {
            "url": "https://towardsai.net/p/l/this-is-how-you-can-explain-svd-to-a-7-year-old",
            "description": "Last Updated on September 20, 2022 by Editorial Team Author(s): Paul Iusztin Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Understand the intuition behind the Singular Value Decomposition (SVD) algorithm. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 20 Sep 2022 12:08:45 +0000",
            "pubdate_parsed": [
                2022,
                9,
                20
            ],
            "email_sent": true
        },
        "The Parameters of Your Model Are Correlated. Now, What?": {
            "url": "https://towardsai.net/p/l/the-parameters-of-your-model-are-correlated-now-what",
            "description": "Last Updated on September 20, 2022 by Editorial Team Author(s): Kevin Berlemont, PhD Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Image generated using the title as the prompt on Stable Diffusion You just got yourself a nice set of data, for example, real estate prices with the characteristics of the homes. A question you could ask yourself is: How do I predict the price of a house based on its characteristics? The first model that comes to mind would be a linear model taking the characteristics as inputs. Let\u2019s say that we have access to the following characteristics: Square footage of the\u00a0house Number of\u00a0bedrooms Localization Year of construction The problem of predicting housing prices with such datasets has been intensively studied (https://www.kaggle.com/c/house-prices-advanced-regression-techniques), and it is possible to obtain an accurate model. I am using this framework as a toy model to highlight how easily parameters can be correlated in a model. The size of the house and the number of bedrooms are correlated, but none of them can really be used to replace the other in the estimation, thus, the estimation of the model parameters could be rendered difficult. In particular, sampling methods such as Markov Chains Monte-Carlo can be inefficient when the target distribution of the parameters is unknown. If this is a problem that might not arise when estimating housing prices, it is thus necessary to have it in mind when fitting more complicated models. In this post, I will describe the most used sampling method, Markov Chains Monte-Carlo(MCMC), and highlight potential reasons for the inefficacy of this method when parameters are correlated. In the second part, I will describe a new sampling algorithm that is unaffected by the correlation between parameters, differential evolution MCMC (DE-MCMC). In addition, I will provide some Python code samples for both of the\u00a0methods. Markov Chain Monte-Carlo MCMC is a sampling method that has been extensively used in Bayesian statistics, especially when estimating posterior priors. In one sentence, MCMC can be considered a random walk process used to estimate a target distribution (the distribution of the parameters). The Metropolis-Hastings is the most used algorithm within the MCMC class\u00a0[1]. Let\u2019s P = (p1, p2,\u2026) the vector of parameters of our model. Then, the algorithm picks an initial value P1 for the parameters and samples a candidate value P* using a proposal distribution P =* K(P1). One typical proposal distribution is usually a Gaussian distribution centered around P1. Afterward, the candidate P* is accepted with the probability: Let\u2019s decompose this formula. M(P*) represents the target distribution. For example, in the case of a model fitting, the target distribution could be the exponential of the error function. Using the exponential function enables the switch from an error function to a probability distribution. q(Pt&#124;P*) represents the density of the proposal distribution evaluated at Pt with parameters P*. In other words, it represents how probable it is to have selected Pt if we were to sample from P*. This term is necessary for the stationarity of the algorithm. If the proposal is accepted, then the new starting point of the chain is P*. Otherwise, the chain does not move. This process continues until a specified number of samples has been reached. This process can be interpreted as converging to the process of sampling the target distribution and, thus, estimating the parameters P. Below is a Python code sample using the package mc3 (modified from their tutorial) to simulate an MCMC algorithm to fit the parameters of a quadratic model: https://medium.com/media/1e4fd0857b6008fd9eb520cdd89d8393/href Now, if we go back to the case where some of our parameters are correlated. If the proposal distribution does not explicitly take into account inter-parameter correlations, then a lot of candidate values are not going to lie within the target distribution. For example, in the figure below, the gray cloud represents a fictional distribution of two parameters. The circle represents the proposal distribution. A big part of the circle lies outside of the gray distribution. Time step of MCMC. The circle represents the candidate distribution. (Image by\u00a0me) This will lead to substantial rejection rates, and the MCMC is going to be very time-consuming. Thus, it might not always be appropriate to use this Bayesian technic to fit your model. The good news is that there is a class of algorithms that can handle high-dimensional, highly correlated problems: population-based MCMC. Diffusion Evolution Markov Chains Monte-Carlo Differential evolution was brought to MCMC algorithms in 2006 [2]. The idea behind the method is the following. Rather than adding noise to the current candidate value in order to produce the next step, it uses multiple interacting chains to produce the candidate value. When chains have different states, they will be used to generate new proposals for other chains. Or in other words, a candidate value of one chain is based on some weighted combination of the values of the other\u00a0chains. The combination of the values is performed the following way. P_k represents the current state of the chain k. Then the candidate value, P*, is generated using the differences between the states of two chains, picked at random, P_m and P_n. In summary, the process is the following: Where the factor \u0263 represents the jump rate. The acceptance rate of the new candidate is similar to the MCMC algorithm, using, for example, the Metropolis-Hastings rule. A rule of thumb for using the jump rate\u00a0is: with d the number of dimensions of the parameters. The DE-MCMC algorithm is represented in the figure\u00a0below: Example of DE-MCMC step (Image by\u00a0me) Why is DE-MCMC efficient at sampling across correlated parameters? The different MCMC chains are being used to inform the states in one chain. Thus, the correlations between the chains (hence correlations between samples) are being directly used [&#8230;]",
            "pubdate": "Wed, 21 Sep 2022 00:14:00 +0000",
            "pubdate_parsed": [
                2022,
                9,
                21
            ],
            "email_sent": true
        },
        "Power, Limitations, and Use Cases of Gpt-3 From My Tests and Prototype Apps You Can Replicate Right": {
            "url": "https://towardsai.net/p/l/power-limitations-and-use-cases-of-gpt-3-from-my-tests-and-prototype-apps-you-can-replicate-right",
            "description": "Last Updated on September 21, 2022 by Editorial Team Author(s): LucianoSphere Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Exemplified with smart chatbots that can even listen and talk naturally command programs, or help students as full-time online tutors. And&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 22 Sep 2022 00:08:10 +0000",
            "pubdate_parsed": [
                2022,
                9,
                22
            ],
            "email_sent": true
        },
        "PySpark For Beginners": {
            "url": "https://towardsai.net/p/l/pyspark-for-beginners",
            "description": "Last Updated on September 22, 2022 by Editorial Team Author(s): Muttineni Sai Rohith Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. PySpark is a Python API for Apache Spark. Using PySpark, we can run applications parallelly on the distributed cluster (multiple nodes). Source: Databricks So we will start the theory part first as to why we need the Pyspark and the background of Apache Spark, features and cluster manager types, and Pyspark modules and packages. Apache Spark is an analytical processing engine for large-scale, powerful distributed data processing and machine learning applications. Generally, Spark is written in Scala, but for industrial adaption, Python API\u200a\u2014\u200aPySpark is released to use spark with Python. In real-time, PySpark is used a lot in the machine learning &#38; Data scientists community; Spark runs operations on billions and trillions of data on distributed clusters 100 times faster than the traditional python applications. Pyspark Features and Advantages Pyspark Architecture Apache Spark works in a master-slave architecture where the master is called \u201cDriver\u201d and slaves are called \u201cWorkers\u201d. Spark Driver creates a spark context that serves as an entry point to the application, and all operations run on the worker nodes, and resources are managed by the cluster\u00a0manager. Source: Spark.Apache.org Cluster Manager\u00a0Types The system currently supports several cluster managers besides, we can also run spark locally on our desktop/system: Standalone\u200a\u2014\u200aa simple cluster manager included with Spark that makes it easy to set up a\u00a0cluster. Apache Mesos\u200a\u2014\u200aa general cluster manager that can also run Hadoop MapReduce and service applications. (Deprecated) Hadoop YARN\u200a\u2014\u200athe resource manager in Hadoop 2 and 3. Mostly used cluster\u00a0Manager Kubernetes\u200a\u2014\u200aan open-source system for automating deployment, scaling, and management of containerized applications. Pyspark conf, Pyspark context, and Pyspark\u00a0session: Pyspark conf: The SparkConf offers configuration for any Spark application. To start any Spark application on a local Cluster or a dataset, we need to set some configuration and parameters, and it can be done using SparkConf. Features of Pyspark\u00a0conf: set(key, value)\u200a\u2014\u200aSet a configuration property. setMaster(value)\u200a\u2014\u200aSet master URL to connect\u00a0to. setAppName(value)\u200a\u2014\u200aSet application name. get(key,defaultValue=None)\u200a\u2014\u200aGet the configured value for some key, or return a default otherwise. setSparkHome(value)\u200a\u2014\u200aSet path where Spark is installed on worker\u00a0nodes. Pyspark context: SparkContext is the entry point to any spark functionality. When we run any Spark application, a driver program starts, which has the main function and your SparkContext gets initiated here. The driver program then runs the operations inside the executors on worker\u00a0nodes. The Spark driver program creates and uses SparkContext to connect to the cluster manager to submit PySpark jobs and know what resource manager to communicate to. It is the heart of the PySpark application. We can create only one SparkContext per JVM. In order to create another first, you need to stop the existing one by using stop() method. SparkContext is available in default as \u2018sc\u2019. So creating the other variable instead of sc will give an\u00a0error. Pyspark session: Since Spark 2.0 SparkSession has become an entry point to PySpark to work with RDD, and DataFrame. Prior to 2.0, SparkContext used to be an entry point. SparkSession is a combined class for all different contexts we used to have prior to 2.0 release (SQLContext and HiveContext e.t.c). Since 2.0 SparkSession can be used in replace with SQLContext, HiveContext, and other contexts defined prior to\u00a02.0. Though SparkContext used to be an entry point prior to 2.0, It is not completely replaced with SparkSession; many features of SparkContext are still available and used in Spark 2.0 and later. SparkSession internally creates SparkConfig and SparkContext with the configuration provided with\u00a0it. We can create as many SparkSession as you want in a PySpark application using either SparkSession.builder() or SparkSession.newSession(). Many Spark session objects are required when you want to keep PySpark tables (relational entities) logically separated. Creating a SparkSession from pyspark.sql import SparkSession spark = SparkSession.builder.appName(\"Practice\").getOrCreate() spark Pyspark Modules and\u00a0Packages Pyspark Modules and\u00a0Packages PySpark RDD\u200a\u2014\u200aResilient Distributed Dataset: \u201cResilient Distributed Datasets (RDD) is a distributed memory abstraction that helps a programmer to perform in-memory computations on a large cluster.\u201d One of the important advantages of RDD is fault tolerance, which means if any failure occurs it recovers automatically. RDD becomes immutable when it is created i.e., it cannot be changed once it is\u00a0created. RDD divides data into smaller parts based on a key. The benefit of dividing data into smaller chunks is that if one executor node fails, another node will still process the data. So it is able to recover quickly from any issues as the same data chunks are replicated across multiple executor nodes. RDD provides the functionality to perform functional calculations against the dataset very quickly by binding the multiple\u00a0nodes. Pyspark For Beginners&#124; Part-4: Pyspark RDD Pyspark DataFrame: DataFrame is a distributed collection of data organized into named columns. It is conceptually equivalent to a table in a relational database or a data frame in R/Python, but with richer optimizations under the hood. DataFrames can be constructed from a wide array of sources such as structured data files, tables in Hive, external databases, or existing\u00a0RDDs. Due to parallel execution on all cores on multiple machines, PySpark runs operations faster than pandas. In other words, pandas DataFrames run operations on a single node, whereas PySpark runs on multiple machines. Pyspark For Begineers&#124; Part-2: Pyspark DataFrame Pyspark SQL: PySpark SQL is a module in Spark which integrates relational processing with Spark\u2019s functional programming API. We can extract the data by using an SQL query language. We can use the queries same as the SQL language. In other words, Spark SQL brings native RAW SQL queries on Spark, meaning you can run traditional ANSI SQL\u2019s on Spark Dataframe, in the above section of this PySpark tutorial, you will learn in detail about using SQL select, where, group by, join, union\u00a0e.t.c PySpark [&#8230;]",
            "pubdate": "Thu, 22 Sep 2022 13:33:19 +0000",
            "pubdate_parsed": [
                2022,
                9,
                22
            ],
            "email_sent": true
        },
        "This Is How You Can Build a Churn Prediction Model Using Spark": {
            "url": "https://towardsai.net/p/l/this-is-how-you-can-build-a-churn-prediction-model-using-spark",
            "description": "Last Updated on September 22, 2022 by Editorial Team Author(s): Paul Iusztin Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. An end-to-end tutorial on how to build a churn prediction pipeline using only Spark. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 22 Sep 2022 12:13:31 +0000",
            "pubdate_parsed": [
                2022,
                9,
                22
            ],
            "email_sent": true
        },
        "Introduction to Confusion Matrix": {
            "url": "https://towardsai.net/p/l/introduction-to-confusion-matrix",
            "description": "Last Updated on September 23, 2022 by Editorial Team Author(s): Saurabh Saxena Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. What is Confusion Matrix, and how to plot it in\u00a0Python? Image by\u00a0Author The Confusion Matrix is the visual representation of the Actual VS Predicted values. It is a performance evaluation tool for classification algorithms, also known as the error\u00a0matrix. A two-dimensional table layout of how many predicted classes or categories were correctly predicted and how many were not allows visualization of the performance of an algorithm, typically in supervised learning. In predictive analytics, a Confusion Matrix for binary classification is a table with two rows and two columns that reports the number of true positives, false negatives, false positives, and true negatives. This allows for more detailed analysis than simply observing accuracy. Image by\u00a0Author Why Confusion Matrix over Accuracy? The accuracy metric can be misleading if used for the Imbalance dataset when the numbers of observations in different classes vary greatly. Whereas the Confusion Matrix provides a detailed comparison between Positives and Negatives. Confusion Matrix consists of four important metrics True Positive(TP), True Negative(TN), False Positive(FP), False Negative(FN). Let\u2019s Understand them with an analogy where the algorithm has to categorize if a Person is Healthy or\u00a0Sick. Confusion Matrix for Binary Classification &#124; Image by\u00a0Author (1) True Positive\u00a0(TP) The Algorithm predicted a \u201cPerson is Sick\u201d who is Sick. This concludes that the algorithm has correctly classified the positive. It is the number of correct predictions when the actual class is positive. (2) True Negative\u00a0(TN) The Algorithm predicted a \u201cPerson is Healthy\u201d who is Healthy. This concludes that the algorithm has correctly classified the negative. It is the number of correct predictions when the actual class is negative. (3) False Positive\u00a0(FP) The Algorithm predicted a \u201cPerson is Sick\u201d who is Healthy. Here algorithm gave a false alarm by misclassifying it as Positive instead of Negative. It is the number of incorrect predictions when the actual class is positive, also referred to as Type I\u00a0Error. (4) False Negative\u00a0(FN) The Algorithm predicted a \u201cPerson is Healthy\u201d who is Sick. Here algorithm missed a Sick Person by categorizing it healthy. It is the number of incorrect predictions when the actual class is negative, also referred to as Type II\u00a0Error. from sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import confusion_matrix X, y = load_breast_cancer(return_X_y=True)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)lr= LogisticRegression() lr.fit(X_train,y_train) y_pred=lr.predict(X_test)confusion_matrix(y_test, y_pred) Output:array([[ 63, 4], [ 3, 118]]) The confusion_matrix API in sklearn provides an array as an output that has TN, FP, FN, and TP, respectively, and the same can be plotted using ConfusionMatrixDisplay API or Heatmap API of any visualization library. Below is the python method for evaluating and plotting the Confusion matrix. It will give an array of tn, fp, fn, and tp as a return type and print the confusion matrix created by in seaborn\u00a0theme. https://medium.com/media/e43191c1d0474d2d6784aa0364186ed1/href from sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import confusion_matrix X, y = load_breast_cancer(return_X_y=True)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)lr= LogisticRegression() lr.fit(X_train,y_train) y_pred=lr.predict(X_test)conf_mat, ax = confusion_matrix(y_test, y_pred) Below is the output for the\u00a0code Confusion Matrix &#124; Image by\u00a0Author The goal is to keep as many TP and TN values as possible. In this blog, we understood what confusion Matrix is and How we can plot it in Python. Interpretation of True Positive(TP), True Negative(TN), False Positive(FP), and False Negative(FN) are the building metrics of the Confusion Matrix. However, multiple metrics can be derived from the Confusion Matrix like Accuracy, Precision, Recall, ROC, and many more. Please refer to Deep dive into Confusion Matrix for\u00a0details. References: [1] sklearn Confusion Matrix API. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html#sklearn.metrics.confusion_matrix [2] sklearn ConfusionMatrixDisplay API. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay [3] seaborn Heatmap API. https://seaborn.pydata.org/generated/seaborn.heatmap.html Introduction to Confusion Matrix was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 23 Sep 2022 12:14:21 +0000",
            "pubdate_parsed": [
                2022,
                9,
                23
            ],
            "email_sent": true
        },
        "Detect business insights from customer support conversations using AI": {
            "url": "https://towardsai.net/p/l/detect-business-insights-from-customer-support-conversations-using-ai",
            "description": "Last Updated on September 25, 2022 by Editorial Team Author(s): Shubham Saboo Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Learn how to analyze customer conversations with just 15 lines of Python\u00a0code! Background A positive customer experience can make the difference between losing and retaining customers. Businesses need to constantly improve their products and services and identify trends and issues at an early stage to keep their customers satisfied! It has become more crucial than ever to analyze customer support data and derive valuable insights to ensure that necessary modifications and enhancements are undertaken early on the basis of the customerpreferences, and the business perform effectively to support the\u00a0same. But that\u2019s the biggest challenge. Unfortunately, most businesses struggle to capture and make sense of the data derived here. While it would be cumbersome to listen to all the calls or skim through all the emails to figure out the insights, even sample picking wouldn\u2019t ensure that the problem areas are correctly identified. How to make sense of this huge volume of\u00a0data? Here\u2019s where One AI studio changes the\u00a0game! One AI is a language AI service where various pre-trained NLP models are packaged and made available through API, enabling language comprehension in context and transforming texts from any source into structured data. One AI studio is capable of performing a wide array of tasks including but not limited\u00a0to: Transcribing audio\u00a0files Generating Highlights of the\u00a0input Topic extraction Emotions as well as Sentiments detection Identification of\u00a0Keywords Identifying Action\u00a0Items Clustering the data basis skills as parameters like Keywords or Sentiments, etc. One AI Studio Interface Let\u2019s look at how you can build a streamlit application to analyze customer support data using One AI and Python. All you need to have is the following: Basic knowledge of\u00a0Python Streamlit One AI\u00a0API Application Walkthrough We will use the Streamlit framework to build a beautiful frontend in python itself. Here is a step-by-step walkthrough to building a Python application for call center analytics: Import the necessary libraries and get the API key from the\u00a0user. 2. Get the conversation or email trail as input from the user and create functionality to select between different intelligence features. 3. Format the input data to be processed by the language model by converting it into\u00a0JSON. 4. Set the headers, API endpoint address, and the payload to be sent to the API. Use the request library to hit the API endpoint and get the output returned in JSON\u00a0format. 5. Process the JSON file and display the output to the end\u00a0users! \ud83c\udf1f Here is the GitHub repository to get the source\u00a0code: GitHub &#8211; Shubhamsaboo/customer-center-analytics-nlp: Use OneAI API to analyze the deep customer insights with NLP and LLMs This is what our final application looks like\u00a0\ud83d\udc47 Streamlit Application to analyze customer conversations AI-powered Analytics in Action\u00a0\ud83d\udd79 Now let\u2019s look at how we can use the above application in real-world scenarios: Step 1: First things first, you have to put your API Key for authentication. Copy your One AI API Key and paste it onto the\u00a0sidebar. Getting the API key (Screen-1) Getting the API key (Screen-2) Paste the API key in the application sidebar. Step 2: Let\u2019s get the ball rolling. Enter the transcript of an audio call in the input box and select an intelligence feature. Sample conversation Ensure that the input is given in the below\u00a0format. Customer: Hi, I am Dragos from Leverkin Management. I am having a lot of trouble with using your product, it is very complicated. I require a training session. Agent: Hi, I\u2019m sorry to hear that. I will surely schedule a session for you. Is Tuesday 5 p.m. a good time? Customer: Yes, that will work thanks. \u201cSummary\u201d as an intelligence feature: 2. \u201cNamed Entity Recognition\u201d as an intelligence feature: 3. \u201cEmotion Detection\u201d as an intelligence feature: 4. \u201cSentiments Analysis\u201d as an intelligence feature: 5. \u201cTopics Detection\u201d as an intelligence feature: Try it out yourself \ud83d\udc49 Streamlit Application Conclusion AI will revolutionize the way customer center data is analyzed. It would play a pivotal role in how useful insights can be derived from customer experience efficiently and with greater accuracy. By identifying customer needs and preferences, call center agents will be able to provide a more personalized and satisfying customer service experience. If you would like to learn more or want me to write more on this subject, feel free to reach\u00a0out. My social links: LinkedIn&#124; Twitter &#124;\u00a0Github If you liked this post or found it helpful, please take a minute to press the clap button, it increases the post&#039;s visibility for other medium\u00a0users. Detect business insights from customer support conversations using AI was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 26 Sep 2022 00:03:43 +0000",
            "pubdate_parsed": [
                2022,
                9,
                26
            ],
            "email_sent": true
        },
        "Deep dive into Confusion Matrix": {
            "url": "https://towardsai.net/p/l/deep-dive-into-confusion-matrix",
            "description": "Last Updated on September 26, 2022 by Editorial Team Author(s): Saurabh Saxena Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Model Evaluation Deep Dive Into Confusion Matrix Precision (TPR), Recall (PPV), TNR, FPR, FNR, NPV, F1 Score, Accuracy, Balanced Accuracy, LR+,\u00a0LR- Image by\u00a0Author In the field of Data Science, model evaluation is the key component of the Training Lifecycle. There are many metrics to evaluate the classification model, but the Accuracy metric is often used. However, Accuracy might not give the correct depiction of the model due to class imbalance, and in such case, the Confusion Matrix is to be used for evaluation. Confusion Matrix is pivotal to know, as many metrics are derived from it, be it precision, recall, F1-score, or Accuracy. Confusion Matrix &#124; Image by\u00a0Author Let\u2019s understand the metrics derived from the Confusion Matrix True Positive (TP) is the number of correct predictions when the actual class is positive. True Negative (TN) is the number of correct predictions when the actual class is negative. False Positive (FP) is the number of incorrect predictions when the actual class is positive, also referred to as Type I\u00a0Error. False Negative (FN) is the number of incorrect predictions when the actual class is negative, also referred to as Type II\u00a0Error. from sklearn.datasets import load_breast_cancerfrom sklearn.model_selection import train_test_split from sklearn.linear_model import LogisticRegressionfrom . import confusion_matrix X, y = load_breast_cancer(return_X_y=True)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)lr= LogisticRegression()lr.fit(X_train,y_train) y_pred=lr.predict(X_test) conf_mat = confusion_matrix(y_test, y_pred, plot=False)TP = conf_mat[0,0]TN = conf_mat[1,1]FP = conf_mat[1,0]FN = conf_mat[0,1] print(\"TP: \", TP)print(\"TN: \", TN)print(\"FP: \", FP)print(\"FN: \", FN) Output:TP: 63TN: 118FP: 3FN: 4 True Positive Rate (TPR), Sensitivity, Recall: It is the probability of a person testing positive who has a disease. In other words, Recall is the proportion of examples of a particular class predicted by the model as belonging to that\u00a0class. Image by\u00a0Author from sklearn.metrics import recall_scorerecall_score(y_test, y_pred) Output:0.9752066115702479 True Positive Rate (TPR), Specificity: It is the probability of a person testing negative who does not have a\u00a0disease. Image by\u00a0Author False Positive Rate (FPR), fall-out: It is the probability of a person testing positive who does not have a\u00a0disease. Image by\u00a0Author False Negative Rate (FNR), miss rate: It is the probability of a person testing negative who does have a\u00a0disease. Image by\u00a0Author TNR = TN/(TN+FP)print(\"Specificity: \", TNR) FPR = FP/(TN+FP)print(\"FPR: \", FPR)FNR = FN/(TP+FN)print(\"FNR: \", FNR) Output:Specificity: 0.9752066115702479FPR: 0.024793388429752067FNR: 0.05970149253731343 Positive Predictive Value (PPV), Precision: It is the probability of a person having a disease who is tested positive. In other words, Precision is the proportion of correct predictions among all predictions. Image by\u00a0Author from sklearn.metrics import precision_scoreprecision_score(y_test, y_pred) Output:0.9672131147540983 Negative Predictive Value (NPV): It is the probability of a person not having a disease who is tested negative. Image by\u00a0Author Positive likelihood ratio\u00a0(LR+): Image by\u00a0Author Negative likelihood ratio\u00a0(LR-): Image by\u00a0Author TNR = TP/(TP+FN)NPV = TN/(TN+FN)print(\"NPV: \", NPV) LRp = TPR/FPRprint(\"LR+: \", LRp)LRn = FNR/TNRprint(\"LR-: \", LRn) Output:NPV: 0.9672131147540983LR+: 37.92537313432836LR-: 0.06349206349206349 Accuracy: Accuracy is the proportion of examples that were correctly classified. To be more precise, It is the ratio of correct prediction over the total number of\u00a0cases. Image by\u00a0Author from sklearn.metrics import accuracy_scoreaccuracy_score(y_test, y_pred) Output:0.9627659574468085 Balanced Accuracy: It is the arithmetic mean of TPR and TNR. Balanced Accuracy finds its usage where data imbalance exists. Image by\u00a0Author from sklearn.metrics import balanced_accuracy_scorebalanced_accuracy_score(y_test, y_pred) Output:0.9577525595164673 F1 Score: It is the harmonic mean of precision and recall, so it\u2019s an overall measure of the quality of a classifier\u2019s predictions. It is usually the metric of choice for most people because it captures both precision and recall. It finds its way during Data Imbalance. Image by\u00a0Author from sklearn.metrics import f1_scoref1_score(y_test, y_pred) Output:0.9711934156378601 What is the difference between F1 and Balanced Accuracy? F1 does not consider True Negative for evaluating the model, while Balanced Accuracy considers all four TP, TN, FP, and\u00a0FN. F1 is the composite metric where precision and recall are considered There are other composite metrics like precision-recall curve and ROC, and AUC, which are important to assess any classification model. To read more about these curves, please visit Precision-Recall and ROC\u00a0Curve. The below code is similar to the classification report of sklearn instead, it will give all metrics out of the confusion matrix for binary classification. https://medium.com/media/3927f5262ad3055b2ce9c8e909b10881/href report = binary_classification_report(y_test, y_pred)report Output:{&#039;TP&#039;: 118, &#039;TN&#039;: 63, &#039;FP&#039;: 4, &#039;FN&#039;: 3, &#039;TPR&#039;: 0.9752066115702479, &#039;Recall&#039;: 0.9752066115702479, &#039;Sensitivity&#039;: 0.9752066115702479, &#039;TNR&#039;: 0.9402985074626866, &#039;Specificity&#039;: 0.9402985074626866, &#039;FPR&#039;: 0.05970149253731343, &#039;FNR&#039;: 0.024793388429752067, &#039;PPV&#039;: 0.9672131147540983, &#039;Precision&#039;: 0.9672131147540983, &#039;Accuracy&#039;: 0.9627659574468085, &#039;Balaced Accuracy&#039;: 0.9577525595164673, &#039;F1 Score&#039;: 0.9711934156378601} Note: all the above codes mentioned in the blog are for binary classification, In this blog, we understood the confusion matrix for binary classification. However, if you are interested in multiclass, please refer to Multi-class Model Evaluation with Confusion Matrix and Classification Report and if you are wondering about the \u201cfrom\u00a0. import confusion_matrix\u201d, please refer to the Introduction to Confusion Matrix for the Python\u00a0method. References: [1] sklearn metrics API. https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics Deep dive into Confusion Matrix was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 26 Sep 2022 12:04:45 +0000",
            "pubdate_parsed": [
                2022,
                9,
                26
            ],
            "email_sent": true
        },
        "Big Data Is Not the Way to Go": {
            "url": "https://towardsai.net/p/l/big-data-is-not-the-way-to-go",
            "description": "Last Updated on September 26, 2022 by Editorial Team Author(s): Andre Ye Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. The significance of the data distribution Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 26 Sep 2022 11:53:46 +0000",
            "pubdate_parsed": [
                2022,
                9,
                26
            ],
            "email_sent": true
        },
        "How Artificial Intelligence Could Help the World Reduce Carbon Emissions": {
            "url": "https://towardsai.net/p/l/how-artificial-intelligence-could-help-the-world-reduce-carbon-emissions",
            "description": "Last Updated on September 29, 2022 by Editorial Team Author(s): Jair Ribeiro Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Businesses and governments are urged to focus on AI to prevent the worst impacts of climate change. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 29 Sep 2022 13:13:58 +0000",
            "pubdate_parsed": [
                2022,
                9,
                29
            ],
            "email_sent": true
        },
        "UNet++ Clearly ExplainedA Better Image Segmentation Architecture": {
            "url": "https://towardsai.net/p/l/unet-clearly-explained%e2%80%8a-%e2%80%8aa-better-image-segmentation-architecture",
            "description": "Last Updated on September 29, 2022 by Editorial Team Author(s): Leo Wang Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. UNet++ Clearly Explained\u200a\u2014\u200aA Better Image Segmentation Architecture Photo by Pietro Jeng on\u00a0Unsplash Table of\u00a0Contents \u2218 \u2b50\ufe0f U-Net Recap \u2218 \u2b50\ufe0f UNet++ Innovations \u2218 \u2b50\ufe0f Loss function \u2218 \u2b50\ufe0f Performance\u00b7 Citations In this article, we are going to introduce you to UNet++, essentially an upgraded version of U-Net. This article is designed to help you understand it intuitively and thoroughly with minimum time possible. It is recommended that you at least have a very rough idea of what U-Net is, but we are going to do a recap\u00a0anyways! \u2b50\ufe0f U-Net\u00a0Recap Introduced in 2015, U-Net aimed to conduct image segmentation tasks specifically in the field of medical imaging. Its name is derived from its \u201cU-Shaped\u201d architecture. The architecture consists of a contracting path (aka. downsampling path, encoder), where the width and heights of the feature maps are shrunk while the channel expands by a factor of 2 until it reaches 1024 (typically the maximum recommended level for CNNs), a bottleneck as a \u201cturning point\u201d, and an expanding path (aka. upsampling path, decoder), where widths and heights of the feature maps are expanded to the mask\u2019s dimension. Fig. 1: U-Net Architecture\u00b2 \u2b50\ufe0f UNet++ Innovations \u201cUpgraded\u201d from U-Net, UNet++ essentially added dense convolutional blocks (Fig 1 in blue and Fig. 3) and a deep supervision design (Fig. 2 in red) that nests on the top level of the network. The newly proposed model looks like\u00a0this: Fig. 2\u00b9 The first design change is added dense convolutional block, Fig. 2 intuitively and concisely shows how it\u00a0works. Fig. 3\u00b9 In U-Net, the feature maps generated from the encoder are automatically passed to the decoder at the same level (shown in BLACK in Fig. 3). However, in UNet++ that is changed (as shown in Fig 3 in BLUE and GREEN). To understand it, here\u2019s the explanation: In the formula shown at the top of Fig 3, H is DenseNet\u2019s composite function that combines Batch Normalization, ReLU activation, and a 3&#215;3 convolution. The elements inside [] are concatenated together as inputs to the H composite function. U is U-Net\u2019s composite function; by default, when you use U-Net\u2019s own backbone, you should expect two 3&#215;3 convolutions with ReLU activations (shown in Fig. 1 as how each level is structured). It should be noted that the introduced dense blocks in the middle take into not only the information from the previous \u201cnodes,\u201d in the same level but also the \u201cnodes\u201d in the level below it (shown in Fig. 2). This is a really densely connected network! Therefore, the newly introduced dense connections would help reduce the \u201csemantic gap between the feature maps of the encoder and decoder\u201d(Fig. 1), so the model could have an easier learning task because those feature maps would be more \u201csemantically similar.\u201d The second change in UNet++ is an added deep supervision design (Fig. 4 in\u00a0red). Fig. 4\u00b9 Deep Supervision is not as hard as it seems. Essentially, it helps the model to operate in two modes:1) Accurate mode (the outputs from all branches in level 0 are averaged to produce the final result)2) Fast mode (not all branches are selected for\u00a0outputs) Figure 5 shows how different choices in FAST MODE result in different models Fig. 5\u00b9 \u2b50\ufe0f Loss\u00a0function In the paper, the author proposed a combined loss function of Binary Cross Entropy and Dice loss, as shown in Formula\u00a01. Formula 1\u00b9 The author used 0.5 weights for BCE loss and 1.0 weights for Dice loss. Note: Dice coefficient is equivalent to F1 score. During implementation, it is suggested to use 1 minus the dice coefficient when using the dice coefficient as a loss. Therefore, this practice shown in the paper maybe is subject to improvement. Moreover, Dice loss is often hard to converge as its non-convex nature. Therefore, one recent solution is provided by wrapping it in a log and cosh function to \u201csmooth out the curve\u201d (https://arxiv.org/pdf/2006.14822.pdf) Also, combining BCE loss with Dice loss often leads to better\u00a0results. \u2b50\ufe0f Performance The author trained the model on four different datasets, and all yielded better performances than U-Net and Wide U-Net models. Table 1 shows the result. DS means deep supervision. The result is shown in the IoU score (area of overlap/area of the union), which illustrates how accurate the model\u00a0is. Table 1\u00b9 The result demonstrates that UNet++ indeed improved compared to its predecessor U-Net. Next, we are going to show you how UNet 3+ works. It\u2019s an upgraded version of\u00a0UNet++! UNet 3+ Fully Explained\u200a\u2014\u200aNext UNet Generation Thank you!\u00a0\u2764\ufe0f Citations [1] Z. Zhou, M. Siddiquee, N. Tajbakhsh, and J. Liang, UNet++: A Nested U-Net Architecture for Medical Image Segmentation (2015), 2015 Computer Vision and Pattern Recognition[2]: O. Ronneberger, P. Fischer, and T. Brox, U-Net: Convolutional Networks for Biomedical Image Segmentation (2015), 2015 Computer Vision and Pattern Recognition UNet++ Clearly Explained\u200a\u2014\u200aA Better Image Segmentation Architecture was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 29 Sep 2022 12:38:22 +0000",
            "pubdate_parsed": [
                2022,
                9,
                29
            ],
            "email_sent": true
        },
        "This is how Im using A.I. To Draw Elon Musks Latest Tweets.": {
            "url": "https://towardsai.net/p/l/this-is-how-im-using-a-i-to-draw-elon-musks-latest-tweets",
            "description": "Last Updated on September 30, 2022 by Editorial Team Author(s): Jair Ribeiro Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. I can create unique images of his tweets using Python and Stable Diffusion. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 30 Sep 2022 12:28:39 +0000",
            "pubdate_parsed": [
                2022,
                9,
                30
            ],
            "email_sent": true
        },
        "Zero-Shot, One-Shot, Few-Shot Learning": {
            "url": "https://towardsai.net/p/l/zero-shot-one-shot-few-shot-learning",
            "description": "Last Updated on September 30, 2022 by Editorial Team Author(s): Jesus Rodriguez Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Understanding the different types of N-Short learning disciplines. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 30 Sep 2022 12:28:36 +0000",
            "pubdate_parsed": [
                2022,
                9,
                30
            ],
            "email_sent": true
        },
        "An Introduction to Federated Learning": {
            "url": "https://towardsai.net/p/l/an-introduction-to-federated-learning",
            "description": "Last Updated on September 30, 2022 by Editorial Team Author(s): Chinmay Bhalerao Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Data privacy and security with Federated learning People in the AI-ML-DL field often asked about privacy concerns of data and data security which is fairly logical because after training models on a wide variety of datasets, what should be the strategy to deal with data and its\u00a0privacy? Photo by Marija Zaric on\u00a0Unsplash Two significant obstacles still exist for modern AI. One is that data typically exists as isolated islands in different businesses. The other is the improvement of data security and privacy. In the current most hyped learning and training methods, we bring our datasets towards a fixed and centralized model on which insights extraction happens. transferring data from system to system, database to database, is quite challenging, and data leakage and data stealing can be\u00a0done. Federated Learning is the emerging model learning method that has a solution for all the above-mentioned problems. Let&#039;s see Federated Learning in detail. A very brute force or dictionary meaning of the federated word is \u201cto unite under a central government or organization while keeping some local control\u201d How this meaning is related to actual federated learning, we will see in the next sections of the\u00a0blog. What if I can bring my local model towards data and not data towards the model? Let&#039;s understand this by a simple example by google.ai federated learning blog. Any mobile app that interacts with users can be used to train a machine learning model, which tries to learn from user interactions. On numerous mobile devices, an ML model will be trained simultaneously. This trained model provides updates, which are then transmitted to a centralized server or model. The inputs provided by the induvial model will be used to update the centralized model. Once more, a centrally updated model will be sent to your\u00a0devices. The continuous model is updating locally and sending the updated model to the server for new updates [Source\u00a0link] Our device downloads the current model, improves it by learning from data on your phone and then summarizes the changes as a small, focused update. Only this update to the model is sent to the cloud, using encrypted communication, where it is immediately averaged with other user updates to improve the shared model. All the training data remains on your device, and no individual updates are stored in the\u00a0cloud. Explaining this, you don\u2019t have centralized data. You have data distributed across different locations and devices, and now you want to train a machine learning\u00a0model. According to me, The biggest concern of data privacy and data security is getting channelized here. The data is at the user\u2019s location, and the updated models are sent to the centralized system. The advantage of federated learning is you are not bringing data towards the model, but you are bringing the model toward the data. Training an algorithm at different local edges or servers and using it as a data sample from the population. Companies can benefit from accurate machine learning models, but typical centralized machine learning systems have limitations, such as not continuously learning on edge devices and aggregating private data on central servers. Federated learning helps to mitigate these\u00a0issues. In conventional machine learning, a central ML model is created using all training data that is accessible in a centralized setting. When predictions can be served by a central server, this operates without any problems. A pleasant user experience may be compromised by the communication delay between a user device and a central server in mobile computing since users expect quick responses. The model might be installed in the end-user device to address this, but since models are trained on entire data sets, ongoing learning becomes difficult. Federated learning in the healthcare industry: Large, diverse, and high-quality datasets provide experience for AI algorithms. Such statistics, however, have historically been difficult to find, particularly in the healthcare industry. A centralized-server approach to federated learning. [Source\u00a0link] Medical organizations have been forced to rely on their own data sources, which can be skewed by factors like patient demographics, the tools employed, or clinical specialties. Or, to obtain all the necessary data, they had to combine data from other institutions. According to BrainTorrent: A Peer-to-Peer Environment for Decentralized Federated Learning paper, A frequent difficulty in training deep neural networks on medical imaging is gaining access to enough labeled data. As data annotation is costly and time-consuming, it is challenging for a single medical center to obtain sufficient sample quantities to create its own customized models. To avoid this, data from all centers might be gathered and used to train a centralized framework that is accessible to anyone. However, this tactic is frequently used. due to the private nature of medical data, it&#039;s impractical. Federated learning (FL) has recently been developed to enable the cooperative learning of a shared prediction model across centers without the requirement for data exchange. In FL, users train models locally on site-specific datasets for a few epochs before sharing their model weights with a centralized server, which manages the entire training procedure. It\u2019s vital that the privacy of patients is not jeopardized by model\u00a0sharing. Federated learning in IoT\u00a0: The Internet of Things (IoT) is developing, opening up new options for real-time data collection and machine learning model deployment. However, a single IoT device might not have the computational power to develop and implement a full learning model. In addition to raising concerns about data security and privacy, sending continuous real-time data to a central server with powerful computational capabilities incurs large transmission costs. According to the paper, a promising approach to training machine learning models on edge servers and devices with constrained resources is federated [&#8230;]",
            "pubdate": "Fri, 30 Sep 2022 12:13:58 +0000",
            "pubdate_parsed": [
                2022,
                9,
                30
            ],
            "email_sent": true
        },
        "Multi-class Model Evaluation with Confusion Matrix and Classification Report": {
            "url": "https://towardsai.net/p/l/multi-class-model-evaluation-with-confusion-matrix-and-classification-report",
            "description": "Last Updated on September 30, 2022 by Editorial Team Author(s): Saurabh Saxena Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Model Evaluation Precision, Recall, F1, Micro, Macro, Weighted, and Classification Report Image by\u00a0Author If you are familiar with the Confusion Matrix, you might know that it is mainly explained for binary classification, which has only two outputs. TP, TN, FP, FN, and other derived metrics like precision and recall are convenient to understand. However, it is not the same case when we have more than two target\u00a0classes. In this blog, Focus will be on the problem with more than two classes or, in other words, Multi-class classification. Unlike binary classification, there is no negative class. It is a perception that TP, TN, and other metrics are difficult to derive out of the confusion matrix for multi-class but actually, it is quite\u00a0easy. In multi-class classification, all the metrics be it TP, precision, or any other metric, are calculated the same as in binary, except it needs to be calculated for each class. We can pretty much derive any metric for a class if we compute TP, TN, FP, and FN for a respective class. Multi-class Confusion Matrix &#124; Image by\u00a0Author TP, FP, and FN can be deduced from the matrix if we look for a particular class from both dimensions, and the rest of the numbers will contribute to TN. Other metrics can also be derived in the same fashion. Please visit Introduction to Confusion Matrix and Deep dive into Confusion Matrix to read about What Confusion Matrix is and how precision, recall, and many other metrics are derived from\u00a0it. Let us understand how to calculate metrics for multi-class; for simplicity, we will consider the problem with 3 classes (airplane, car,\u00a0train). Confusion Matrix &#124; Image by\u00a0Author ## Calculation of class \u201cAirplane\u201d: TP = 9FN = 1+5 = 6FP = 6+3 = 9TN = 7+4+2+8 = 21Precision = TP/(TP+FP) = 9/(9+9) = 0.5Recall = TP/(TP+FN) = 9/(9+6) = 0.6F1 = 2*(0.5*0.6)/(0.5+0.6) = 5.55 Similarly, we can calculate for the other classes. However, this time we will use sklearn metrics API to produce precision, recall, and f1\u00a0score. from sklearn.metrics import confusion_matrixfrom sklearn.metrics import precision_scorey_true = [0]*15 + [1]*17 + [2]*13y_pred = [0]*9 + [1]*1 + [2]*5 + [0]*6 + [1]*7 + [2]*4 + [0]*3 + [1]*2 + [2]*8 confusion_matrix(y_true, y_pred, labels=[0,1,2]) Output:array([[9, 1, 5], [6, 7, 4], [3, 2, 8]]) The above example is to calculate the confusion matrix, which returns ndarray, and if labels are not hot-encoded, we have to provide a set of labels against the \u2018labels\u2019 argument. Precision: It is referred to the proportion of correct predictions among all predictions for a particular class. from sklearn.metrics import precision_scoreprecision_score(y_true, y_pred, labels=[0,1,2], average=None) Output:array([0.5 , 0.7 , 0.47058824]) Recall: It is referred to the proportion of examples of a specific class that have been predicted by the model as belonging to that\u00a0class. from sklearn.metrics import recall_scorerecall_score(y_true, y_pred, labels=[0,1,2], average=None) Output:array([0.6 , 0.41176471, 0.61538462]) F1 Score: The Harmonic mean of precision and\u00a0recall. from sklearn.metrics import f1_scoref1_score(y_true, y_pred, labels=[0,1,2], average=None) Output:array([0.54545455, 0.51851852, 0.53333333]) The \u2018average\u2019 argument in the above evaluation methods needs to be None which return an array of metric respective to individual class. In multi-class, we have observed that precision has been calculated for individual classes, while in binary class problems, we had a single value. If we want to evaluate multi-class with one global metric, we have micro, macro, and weighted precision. Any metric from the confusion matrix can be combined with micro, macro, and weighted to make it a global\u00a0metric. Micro Precision: It is calculated by considering the total TP, TN, FN, and TN irrespective of class to calculate Precision. Global TP = TP(airplane) + TP(car) + TP(train) = 9+7+8 =\u00a024 Global FP = FP(A) + FP(C) + FP(T) = (6+3) + (1+2) + (5+4) =\u00a021 Micro Precision = 24/(24+21) =\u00a00.533 from sklearn.metrics import precision_scoreprecision_score(y_true, y_pred, labels=[0,1,2], average=&#039;micro&#039;) Output:0.5333333333333333 Macro Precision: It is referred to as the unweighted mean of the measure for each\u00a0class. Classification Report &#124; Image by\u00a0Author Macro Precision = (0.50 + 0.70 + 0.47)/3 =\u00a00.556 from sklearn.metrics import precision_scoreprecision_score(y_true, y_pred, labels=[0,1,2], average=&#039;macro&#039;) Output:0.5568627450980391 Weighted Precision: Unlike macro, it is the weighted mean of the measure. Weights are the total number of samples per class. In our example, we have 15 airplanes, 17 cars, and 13 trains which aggregated to 45 in\u00a0total. Weighted Precision = (15*0.50 + 17*0.70 + 13*0.47)/45 =\u00a00.566 from sklearn.metrics import precision_scoreprecision_score(y_true, y_pred, labels=[0,1,2], average=&#039;weighted&#039;) Output:0.5670588235294117 What is Classification Report? It is a python method under sklearn metrics API, useful when we need class-wise metrics alongside global metrics. It provides precision, recall, and F1 score at individual and global levels. Here support is the count of samples. Classification Report in sklearn calculates all necessary metrics for evaluation. from sklearn.metrics import classification_reportreport = classification_report(y_true, y_pred, labels=[0,1,2], target_names=[\"Airplane\", \"Car\", \"Train\"])print(report) Output: precision recall f1-score support Airplane 0.50 0.60 0.55 15 Car 0.70 0.41 0.52 17 Train 0.47 0.62 0.53 13 accuracy 0.53 45 macro avg 0.56 0.54 0.53 45weighted avg 0.57 0.53 0.53 45 Below is the code for plotting confusion Matrix and Detailed Classification Report https://medium.com/media/e7e4efd4e67053f5459f628e0faaca39/hrefhttps://medium.com/media/8b597fd6cedb02b224f8f1c75852fc21/href import numpy as npfrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionfrom . import confusion_matrix # Load Datasetdata = load_iris()X = data.datay = data.targetlabels = list(data.target_names) # Adding Noiserandom_state = np.random.RandomState(0)n_samples, n_features = X.shapeX = np.concatenate([X, random_state.randn(n_samples, 200* n_features)], axis=1)X_train, X_test, y_train, y_test = train_test_split( X[y &#60; 3], y[y &#60; 3], test_size=0.5, random_state=random_state) lr = LogisticRegression()lr.fit(X_train, y_train)y_pred = lr.predict(X_test)y_pred_prob = lr.predict_proba(X_test) confusion_matrix(y_test, y_pred, labels) If you are wondering about the \u201cfrom\u00a0. import confusion_matrix\u201d, please refer to the Introduction to Confusion Matrix for the Python\u00a0method. Confusion Matrix &#124; Image by\u00a0Author multi_classification_report(y_test, y_pred, labels=labels, encoded_labels=True, as_frame=True) Detailed Classification Report &#124; Image by\u00a0Author summarized_classification_report(y_test, y_pred, as_frame=True) [&#8230;]",
            "pubdate": "Fri, 30 Sep 2022 12:13:53 +0000",
            "pubdate_parsed": [
                2022,
                9,
                30
            ],
            "email_sent": true
        },
        "Adaptive Learning for Time Series Forecasting": {
            "url": "https://towardsai.net/p/l/adaptive-learning-for-time-series-forecasting",
            "description": "Last Updated on October 1, 2022 by Editorial Team Author(s): Reza Yazdanfar Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. There is no need to say the importance of time series forecasting applications in various industries from Energy to Healthcare, etc&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 01 Oct 2022 12:03:55 +0000",
            "pubdate_parsed": [
                2022,
                10,
                1
            ],
            "email_sent": true
        },
        "How To Set Up and Run Cuda Operations In PyTorch": {
            "url": "https://towardsai.net/p/l/how-to-set-up-and-run-cuda-operations-in-pytorch",
            "description": "Last Updated on October 4, 2022 by Editorial Team Author(s): Muttineni Sai Rohith Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Introduction The advent of deep learning in recent years created a demand for computing resources and acceleration of workloads. Various operations involved in deep learning, such as matrix multiplications, tiling of the images, and processing chunks of voice samples, can be parallelized for better performance and accelerating the development of Machine learning models. Thus, many deep learning libraries like TensorFlow and Pytorch provide users with a set of functions or APIs to take advantage of their GPUs. CUDA Is one such programming model and computing platform which enables us to perform complex operations faster by parallelizing the tasks across\u00a0GPUs. This article will discuss what CUDA is and how to set up the CUDA environment and run various CUDA operations available in\u00a0Pytorch. Photo by Lucas Kepner on\u00a0Unsplash What is\u00a0CUDA CUDA (Compute Unified Device Architecture) is a programming model and parallel computing platform developed by Nvidia. Using CUDA, one can maximize the utilization of Nvidia-provided GPUs, thereby improving the computation power and performing operations away faster by parallelizing the tasks. PyTorch provides a torch.cuda library to set up and run the CUDA operations. Using Pytorch CUDA, we can create tensors and allocate them to the device. Once allocated, we can perform operations on it, and the results are also assigned to the\u00a0device. Installation Pytorch provides a user-friendly interface on their official website where we can select our operating system, desired programming language, and other requirements, as shown in the below\u00a0figure. Refer to this official Pytorch link\u200a\u2014\u200aStart Locally &#124; PyTorch and select the requirements according to our system specifications. Pytorch provides CUDA libraries for Windows and Linux Operating systems. For windows, make sure to use CUDA 11.6 because CUDA 10.2 and ROCm are no longer supported for windows. For Python programming language, we can select one in conda, pip, and source packages, whereas LibTorch is used for C++ and Java languages. Running CUDA operations in\u00a0PyTorch Once installed successfully, we can use the torch.cuda interface to run CUDA operations in\u00a0Pytorch. To make sure whether the installation is successful, use the torch.version.cuda command as shown\u00a0below: # Importing Pytorch import torch # To print Cuda version print(\u201cPytorch CUDA Version is \u201c, torch.version.cuda) If the installation is successful, the above code will show the following output\u00a0\u2013 # Output Pytorch CUDA Version is 11.6 Before using the CUDA, we have to make sure whether CUDA is supported by our\u00a0System. Use torch.cuda.is_available() command as shown below\u00a0\u2013 # Importing Pytorch import torch # To check whether CUDA is supported print(\u201cWhether CUDA is supported by our system:\u201d, torch.cuda.is_available()) The above command will return a Boolean Value as below\u00a0\u2013 # Output Whether CUDA is supported by our system: True Pytorch CUDA also provides the following functions to know about the device id and name of the device when given device ID, as shown below\u00a0\u2013 # Importing Pytorch import torch # To know the CUDA device ID and name of the device Cuda_id = torch.cuda.current_device() print(\u201cCUDA Device ID: \u201d, torch.cuda.current_device()) print(\u201cName of the current CUDA Device: \u201d, torch.cuda.get_device_name(cuda_id)) The above code will show the following output\u00a0\u2013 # Output CUDA Device ID: 0 Name of the current CUDA Device: NVIDIA GeForce FTX 1650 We can also change the default CUDA device by specifying the ID as shown below\u00a0\u2013 # Importing Pytorch import torch # To change the Default CUDA device torch.cuda.set_device(1) Note: While using CUDA, make sure to develop device-agnostic code because some systems might not have GPUs and will have to run on CPUs, and vice versa. That can be done by adding the following line to our\u00a0code- device = \u2018cuda\u2019 if torch.cuda.is_available() else \u2018cpu\u2019 Operating Tensors with\u00a0CUDA Generally, a Pytorch tensor is the same as a NumPy array. It is an n-dimensional array used for numerical computation. The only difference between tensor and NumPy array is tensor can run both on CPUs and\u00a0GPUs. Pytorch CUDA provides the following functions to handle tensors\u00a0\u2013 \u00b7 tensor.device\u200a\u2014\u200areturns the device name of the tensor. By default, it is\u00a0\u201cCPU\u201d. \u00b7 tensor.to(device_name)\u200a\u2014\u200areturns a new instance of the tensor on the device mentioned. \u201cCPU\u201d for CPU and \u201dcuda\u201d for CUDA enabled\u00a0GPU. \u00b7 tensor.cpu()\u200a\u2014\u200ato transfer the tensor from the current device to\u00a0CPU. Let\u2019s understand the usage of the above functions by creating a tensor and performing some basic operations. We will create a sample tensor and perform a tensor operation(Squaring) on the CPU, and then we will transfer the tensor to GPU and perform the same operation again and understand the performance. import torch # Creating a sample tensor x = torch.randint(1, 1000, (100, 100)) # Checking the device name: will return \u2018CPU\u2019 by default print(\u201cDevice Name: \u201d , x.device) # Applying tensor operation res_cpu = x ** 2 # Transferring tensor to GPU x = x.to(torch.device(\u2018cuda\u2019)) # Checking the device name: will return \u2018cuda:0\u2019 print(\u201cDevice Name after transferring: \u201d, x.device) # Applying same tensor operation res_gpu = x ** 2 # Transferring tensor from GPU to CPU x.cpu() Running Machine Learning models with\u00a0CUDA CUDA provides the following function to transfer the machine learning model to the following device \u00b7 model.to(device_name)\u200a\u2014\u200areturns a new instance of the Machine learning model on the device_name specified. \u201cCPU\u201d for CPU and \u201dcuda\u201d for CUDA-enabled GPU. To demonstrate the above function, we will import the pre-trained \u201cResnet-18\u201d model from torchvision.models # Importing Pytorch Import torch import torchvision.models as models # Making the code device-agnostic device = \u2018cuda\u2019 if torch.cuda.is_available() else \u2018cpu\u2019 # Instantiating a pre-trained model model = models.resnet18(pretrained=True) # Transferring the model to a CUDA-enabled GPU model = model.to(device) Once the model is transferred, we can continue the rest of the machine learning workflow on CUDA-enabled GPU. Conclusion After reading this article, one can understand how to [&#8230;]",
            "pubdate": "Wed, 05 Oct 2022 03:53:44 +0000",
            "pubdate_parsed": [
                2022,
                10,
                5
            ],
            "email_sent": true
        },
        "ROC and AUC for Model Evaluation": {
            "url": "https://towardsai.net/p/l/roc-and-auc-for-model-evaluation",
            "description": "Last Updated on October 7, 2022 by Editorial Team Author(s): Saurabh Saxena Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Model Evaluation Image by\u00a0Author ROC or Receiver Operating Characteristic Curve is the most frequently used tool for evaluating the binary or multi-class classification model. Unlike other metrics, it is calculated on prediction scores like Precision-Recall Curve instead of prediction class. In my previous post, the importance of the precision-recall curve is highlighted as how to plot for multi-class classification. To understand ROC Curve, let\u2019s quickly refresh our memory on the possible outcomes in a binary classification problem by referring to the Confusion Matrix. Confusion Matrix &#124; Image by\u00a0Author ROC Curve is a plot of True Positive Rate(TPR) plotted against False Positive Rate(FPR) at various threshold values. It helps to visualize how threshold affects classifier performance. True Positive Rate (TPR) is referred to the proportion of examples of a particular class that has been predicted by the model as belonging to that class. It is also referred to as Recall or Sensitivity. Image by\u00a0Author where TP and FN are True Positive and False Negative, respectively. False Positive Rate (FPR): It is the probability of a person testing positive who does not have a disease. It is also referred to as the fall-out\u00a0rate. Image by\u00a0Author where FP is the number of False Positives and TN is the number of True Negatives. Image by\u00a0Author ROC Curve can also be defined as a Sensitivity vs. 1-Specificity plot. ROC Curve &#124; Image by\u00a0Author Let\u2019s have a look at ROC Curve for binary classification. from sklearn.datasets import make_classificationfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import roc_curvefrom sklearn.metrics import RocCurveDisplayX, y = make_classification(n_samples=500, n_classes=2, random_state=1)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=2)lr = LogisticRegression()lr.fit(X_train, y_train)y_pred = lr.predict(X_test)y_pred_prob = lr.predict_proba(X_test)y_pred_prob = y_pred_prob[:,1]fpr, tpr, threshold = roc_curve(y_test, y_pred_prob)plt = RocCurveDisplay(fpr=fpr, tpr=tpr)plt.plot() ROC Curve &#124; Image by\u00a0Author AUC Score AUC Stands for \u2018Area under the curve,\u2019 and it is calculated by the trapezoidal rule of area calculation under any plot. It summarizes the ROC Curve into a single metric for binary classification and each class in a multi-class model. However, to summarize the multi-class into single metric micro, macro, and weighted AUC can be\u00a0used. Higher the AUC, the better the classifier. Its value fluctuated between 0(worst model) and 1(ideal\u00a0model). ROC AUC &#124; Image by\u00a0Author from sklearn.metrics import roc_auc_scoreauc = roc_auc_score(y_test, y_pred_prob)print(auc) Output:0.9727017262143718 Let\u2019s have a look at how to plot ROC Curve and calculate AUC Score on a random classification dataset using the sklearn\u00a0library. plt = RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=auc)plt.plot() ROC Curve with AUC &#124; Image by\u00a0Author Why ROC\u00a0Curve? ROC is calculated on a precision score, while many metrics like accuracy and precision look at the prediction class. It is a trade-off between Sensitivity(TPR) and 1-Specificity(FPR), allowing one to choose a threshold that keeps a balance between TPR and FPR, which suits the particular problem. Plotting ROC Curve is a cakewalk for binary problems. However, it daunts professionals to calculate multi-class classification. Below is the method to plot ROC and AUC for multi-class. Below is the python code to create and plot ROC and AUC for multi-class classification problems. https://medium.com/media/90775345066e0ada14362f17b686d5c4/href from sklearn.datasets import make_classificationfrom sklearn.preprocessing import label_binarizefrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionfrom sklearn.multiclass import OneVsRestClassifier # Load DatasetX, y = make_classification(n_samples=500, n_classes=3, random_state=1, n_informative=3)y = label_binarize(y, classes=[0,1,2])X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=1)lr = LogisticRegression()ovr = OneVsRestClassifier(lr)ovr.fit(X_train, y_train)y_pred = ovr.predict(X_test)y_pred_prob = ovr.predict_proba(X_test)fpr, tpr, threshold, auc, labels = roc_auc_curve(y_test, y_pred_prob, labels=[0,1,2])roc_auc_curve_plot(fpr, tpr, threshold, auc, labels) ROC Curve for multi-class &#124; Image by\u00a0Author References: [1] ROC Curve. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html [2] AUC. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.auc.html [3] Precision-Recall Curve. https://pub.towardsai.net/precision-recall-curve-26f9e7984add ROC and AUC for Model Evaluation was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 07 Oct 2022 12:13:26 +0000",
            "pubdate_parsed": [
                2022,
                10,
                7
            ],
            "email_sent": true
        },
        "Exploring the 500 Richest People in the World Data Set": {
            "url": "https://towardsai.net/p/l/exploring-the-500-richest-people-in-the-world-data-set",
            "description": "Last Updated on October 8, 2022 by Editorial Team Author(s): Sadrach Pierre, Ph.D. Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Generating Statistical Insights with Pie Charts, Box-Plots, and Histograms Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 08 Oct 2022 13:18:50 +0000",
            "pubdate_parsed": [
                2022,
                10,
                8
            ],
            "email_sent": true
        },
        "Python and Multi-CPU-Arch": {
            "url": "https://towardsai.net/p/l/python-and-multi-cpu-arch",
            "description": "Last Updated on October 8, 2022 by Editorial Team Author(s): Murli Sivashanmugam Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Fixing python toolchain breakages on mac M1/M2\u00a0reliably Photo by Christopher Gower on\u00a0Unsplash Introduction One of the design goals of python is to be platform agnostic and to run scripts without modification across environments. Python does a pretty good job of ensuring this compatibility as long as applications and libraries are written using python scripts. As python\u2019s popularity and adaptation increased, more and more libraries started using python extensions to include natively complied code to boost performance and efficiency. Popular python libraries like pandas and NumPy can handle large amounts of data efficiently thanks to their native extension. As more and more python libraries started using natively complied code, platform compatibility issues started showing up in python environments. If one is using Mx(M1/M2) based MacBooks, it&#039;s very likely to have witnessed platform compatibility issues in a python environment. This article talks about how python library manager like pip and conda manages platform-dependent binaries, why do they break, and how to get over them on Mac M1/M2 setups in a simpler, more reliable, and replicable way. Python binaries, like any other binary, are compiled separately for different CPU architectures and platforms(Windows/Mac/Linux). When python installs a Python library in a system, it collects and processes metadata that is specific to the local CPU and platform. If the python library includes any native extensions, it needs to be compiled into CPU and platform-specific binary to run locally. A brief understanding of how python package managers like \u2018PIP\u2019 and \u2018conda\u2019 manage CPU and platform dependencies will help understand its shortcomings and how to get over\u00a0them. PIP Multi-Arch Support PIP uses the \u2018wheel\u2019 packaging standard for distributing python packages. \u2018Wheel\u2019 is a packaging system for packaging pure python scripts and native extensions both in source code and compiled binary format. To get a better perspective on how PIP maintains different distribution formats, visit a \u2018pip\u2019 web page of a library of your choice and click on \u201cDownload Files\u201d. On this page \u201cSource Distribution\u201d section lists the packages available in source format, and the \u201cBuilt Distributions\u201d section lists all the packages available in pre-built binary formats. For example, this page link shows the source and pre-built distributions for the \u2018pandas\u2019 library. These distribution packages follow a naming convention as specified below. {dist}-{version}(-{build})?-{python}-{abi}-{platform}.whl Each section in {brackets} is a tag or a component of the wheel name that carries some meaning about what the wheel contains and where the wheel will or will not work.\u00a0Example: pandas-1.5.0-cp311-cp311-macosx_11_0_arm64.whl pandas\u200a\u2014\u200ais the library name1.5.0\u200a\u2014\u200ais the library versioncp11\u200a\u2014\u200aMinimum python version requiredcp11\u200a\u2014\u200aMinimum application binary interface(ABI) requiredmacosx_11_0_arm64\u200a\u2014\u200aPlatform tag which is again subdivided into the following:&#8211; macosx\u200a\u2014\u200aOperating system&#8211; 11_0\u200a\u2014\u200aMinimum required MacOS SDK version&#8211; arm64\u200a\u2014\u200aCpu architecture PIP naming convention also supports \u2018wildcard\u2019 to optimize package bundles. For example, \u2018chardet-3.0.4-py2.py3-none-any.whl\u2019 supports both python2 and python3 and has no dependency on ABI, and can install on any platform and CPU architecture. Many python libraries use these wildcard options to optimize the number of package bundles. For more information on Python \u2018wheel\u2019 and PIP, please refer to What Are Python Wheels and Why Should You\u00a0Care? Why does PIP install\u00a0fail? Most of the time, PIP installation fails for two primary reasons. First, if a pre-built library is not available in the repository, PIP will compile the native extension source code on the host system. To do that, it would expect the build tools and other dependent libraries to be available on the host. Sometimes this becomes a challenge to locally install the build dependencies, especially when the dependency tree grows\u00a0deep. Second, due to \u2018wildcard\u2019 in wheel package names. MacBook introduced arm-based \u2018M1/M2\u2019 CPU architecture recently. Some of the older wheel packages for macOS were listed as \u2018any\u2019 for CPU architecture because x86 was the only supported architecture by then. If PIP resolves package dependency to one of these older versions, PIP will install this package on newer CPU architecture, assuming it would run. An example of this issue is with the package \u2018azure-eventhub\u2019. This library is dependent on another library called \u2018uamqp\u2019. This library lists a universal/wildcard package for macOS that is incompatible with the M1/M2 arm64 processor. If you install \u2018azure-eventhub\u2019 on M1/M2 one would see that the package would install successfully but it will throw a runtime exception while importing this\u00a0package. Conda Multi-Arch Support Conda takes one step further in ensuring platform portability. Conda packages not only python libraries but also the dependent libraries, binaries, compilers, and python interpreters themselves for the different operating systems and CPU architecture. This way it ensures the entire toolchain is portable across environments. Since all the dependent binaries are also packaged with python libraries, it does not expect any dependencies on the local system except for the standard C libraries. So, if conda provides better portability and fixes the shortcomings of PIP, what could go wrong? The issue is not all python packages are available in Conda. It&#039;s common to use pip within a conda environment to install python packages that are not available in conda; hence, one is exposed to the shortcomings of PIP. Again (not to nitpick) \u2018azure-eventhub\u2019 package is an example of the\u00a0same. If one runs into such a platform compatibility issue and when searching for solutions in forums, one would come across different options like installing a specific version of python or library, installing the library via other packaging systems like \u2018brew\u2019 or installing alternate packages, etc. Many of such fixes are not reliable for production and may not be able to replicate across other systems. Curated below are three options that are simpler, reliable, and replicable ways to get over python platform compatibility issues. They\u00a0are: Pip Install from\u00a0Source Conda &#38;\u00a0Rosetta Docker Multi-Arch [&#8230;]",
            "pubdate": "Sun, 09 Oct 2022 00:03:43 +0000",
            "pubdate_parsed": [
                2022,
                10,
                9
            ],
            "email_sent": true
        },
        "F1 to F-beta": {
            "url": "https://towardsai.net/p/l/f1-to-f-beta",
            "description": "Last Updated on October 10, 2022 by Editorial Team Author(s): Saurabh Saxena Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Model Evaluation Image by\u00a0Author F1 Score The F-1 score is a popular binary classification metric representing a balance between precision and recall. It is the Harmonic mean of precision and recall. The following equation can represent the F-1\u00a0score. Image by\u00a0Author where Precision can be defined as the probability of positive predictions that are actual members of the positive\u00a0class. Image by\u00a0Author The recall is defined as the probability of the positive predictions among the actual positive. Image by\u00a0Author where TP is True Positive, FP is False Positive, and FN is the False Negative. Let\u2019s explore the F1 score for the binary classification problems with a dummy dataset in\u00a0sklearn. from sklearn.datasets import make_classificationfrom sklearn.model_selection import train_test_splitfrom sklearn.linear_model import LogisticRegressionfrom sklearn.metrics import f1_score X, y = make_classification(n_samples=1000, n_classes=2, random_state=1)X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=2)lr = LogisticRegression()lr.fit(X_train, y_train)y_pred = lr.predict(X_test)y_pred_prob = lr.predict_proba(X_test)y_pred_prob = y_pred_prob[:,1]f1_score(y_test, y_pred) Output:0.8585858585858585 While many Machine Learning and Deep Learning practitioners frequently use the F1 score for model evaluation, few are familiar with the F-measure, which is the general form of the F1\u00a0Score. F-beta Score The F-beta score calculation follows the same form as the F1 score. Unlike in F1 Score, which is the harmonic mean, it is the weighted harmonic mean of the precision and recall, reaching its optimal value at 1 and worst value at\u00a00. Image by\u00a0Author The beta parameter determines the weight of recall in the combined score. beta &#60; 1 lends more weight to precision while beta &#62; 1 favors\u00a0recall. Let\u2019s have a look at the F-beta score and how the value fluctuates with\u00a0beta. from sklearn.metrics import fbeta_score print(fbeta_score(y_test, y_pred, beta=0.5))print(fbeta_score(y_test, y_pred, beta=1))print(fbeta_score(y_test, y_pred, beta=2)) Output:0.8534136546184740.85858585858585850.8638211382113821 Here, we have noticed that F-beta changes with beta movement, and now let\u2019s have a look at the same relative to precision and recall curve at various thresholds. import matplotlib.pyplot as pltfrom sklearn.metrics import recall_scorefrom sklearn.metrics import precision_scorefrom sklearn.metrics import precision_recall_curve _, _, threshold = precision_recall_curve(y_test, y_pred_prob) f1score = list()f05score = list()f2score = list()precision = list()recall = list()for th in threshold: y_test_pred = list() for prob in y_pred_prob: if prob &#62; th: y_test_pred.append(1) else: y_test_pred.append(0) f1score.append(f1_score(y_test, y_test_pred)) precision.append(precision_score(y_test, y_test_pred)) recall.append(recall_score(y_test, y_test_pred)) f05score.append(fbeta_score(y_test, y_test_pred, beta=0.5)) f2score.append(fbeta_score(y_test, y_test_pred, beta=2)) _, ax = plt.subplots(figsize=(8, 6))ax.set_xlabel(&#039;Threshold&#039;)plt.plot(threshold, precision, label=&#039;precision&#039;)plt.plot(threshold, recall, label=&#039;recall&#039;)plt.plot(threshold, f05score, label=&#039;F0.5&#039;)plt.plot(threshold, f1score, label=&#039;F1&#039;)plt.plot(threshold, f2score, label=&#039;F2&#039;)plt.legend(loc=&#039;lower left&#039;) Precision, Recall, F1 vs Threshold &#124; Image by\u00a0Author It is evident in the above graph that as we increase our beta value from 0, the curve starts moving towards the recall curve, which means with an increase in the beta value gives more importance to recall, and the below code to plot the F-measure at various beta and threshold values. betas = [0.1, 0.3, 0.5, 0.7, 1, 2, 5]_, ax = plt.subplots(figsize=(8, 6))ax.set_xlabel(&#039;Threshold&#039;)ax.set_ylabel(&#039;Fbeta&#039;)for beta in betas: fbetascore = list() for i, th in enumerate(threshold): y_test_pred = list() for prob in y_pred_prob: if prob &#62; th: y_test_pred.append(1) else: y_test_pred.append(0) fbetascore.append(fbeta_score(y_test, y_test_pred, beta=beta)) plt.plot(threshold, fbetascore, label=f&#039;F{beta}&#039;)plt.legend(loc=&#039;lower left&#039;) Fbeta vs Threshold &#124; Image by\u00a0Author References: [1] F1 Score. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score [2] Fbeta Score. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html F1 to F-beta was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 10 Oct 2022 12:18:53 +0000",
            "pubdate_parsed": [
                2022,
                10,
                10
            ],
            "email_sent": true
        },
        "Two New Papers By Deepmind Exemplify How Artificial Intelligence Can Help Human Intelligence": {
            "url": "https://towardsai.net/p/l/two-new-papers-by-deepmind-exemplify-how-artificial-intelligence-can-help-human-intelligence",
            "description": "Last Updated on October 10, 2022 by Editorial Team Author(s): LucianoSphere Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. In these new works, AI assists the advancement of pure mathematics by helping to discover new relationships between mathematical objects&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 10 Oct 2022 11:43:56 +0000",
            "pubdate_parsed": [
                2022,
                10,
                10
            ],
            "email_sent": true
        },
        "DeepMinds AlphaTensor: Deepminds Alphatensor: The AI That Is Reinventing Math": {
            "url": "https://towardsai.net/p/l/deepminds-alphatensor-deepminds-alphatensor-the-ai-that-is-reinventing-math",
            "description": "Last Updated on October 10, 2022 by Editorial Team Author(s): Salvatore Raieli Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. How the DeepMind\u2019s latest model could revolutionize math Image generated with OpenAI Dall-E\u00a02 Without realizing it, any of our activities, in one way or another, involve matrix multiplications. The whole of computing relies on them; being able to improve efficiency is fundamental. DeepMind (a year after revolutionizing biology with AlphaFold2) presented an article in which, using reinforcement learning, it manages to increase the efficiency of matrix multiplication. In this article, we discuss how and why it is important. How we still struggle with\u00a0matrices image by Roman Mager at unsplash.com Algorithms have been fundamental since the beginning of history. Both the Greeks and the Egyptians invented algorithms that enabled them to succeed in great works. Algorithms are also the basis of modern civilization, and without realizing it, they underpin almost every field of knowledge and its application. On the other hand, discovering new algorithms is by no means easy (we have all suffered in studying algorithms and data structures, but discovering new ones is even more difficult). One of the most important algorithms today is the multiplication of two matrices. Why? Because practically all types of data can be represented as matrices. In fact, images can be represented as matrices, can be used to solve linear equations, used in graph video games, weather simulations, etc. Furthermore, most artificial intelligence algorithms can be reduced to multiplications of matrices (which are then efficiently processed by a\u00a0GPU). Matrix multiplication. image source: DeepMind\u00a0blogpost Matrix multiplication seems like a very simple concept, but given its importance, being able to improve its efficiency even a little would save an enormous amount of computation. For centuries, mathematicians believed that known matrix multiplication was an efficient method. In 1969, the community was shocked by the fact that the efficiency was actually suboptimal, as was demonstrated by Volker Strassen. matrix multiplication: comparison between the two algorithms, Strassen\u2019s algorithm is more efficient because uses one scalar multiplication less. image source: DeepMind\u00a0blogpost Now, one less scalar multiplication may not seem like a big deal. But if we multiply 1 billion matrices, we have saved 1 billion scalar multiplications. The problem was that Strassen\u2019s method only fit the multiplication of two 2&#215;2 matrices. How DeepMind Solves the\u00a0problem DeepMind on Twitter: \"ICYMI: On the cover of @Nature &#8211; #AlphaTensor, an AI system for discovering novel, efficient, and exact algorithms for matrix multiplication.Learn more \u2b07\ufe0fhttps://t.co/E18DezAevbhttps://t.co/SvHgsaitFt https://t.co/ia9OQYuwZg pic.twitter.com/2eQsBCC9H5 / Twitter\" ICYMI: On the cover of @Nature &#8211; #AlphaTensor, an AI system for discovering novel, efficient, and exact algorithms for matrix multiplication.Learn more \u2b07\ufe0fhttps://t.co/E18DezAevbhttps://t.co/SvHgsaitFt https://t.co/ia9OQYuwZg pic.twitter.com/2eQsBCC9H5 Strassen\u2019s work showed that matrix-multiplication algorithms can be discovered by finding new ways to decompose a 3D array of numbers called a matrix multiplication tensor into a sum of elementary building blocks.\u200a\u2014\u200aNature comments on the\u00a0article The researchers at DeepMind have turned the problem of matrix multiplication into a kind of single-player game (after all, they are particularly experienced in the field after AlphaZero and AlphaGo). In fact, in this case, the board is a three-dimensional tensor (a tensor is practically a matrix, and a 3D tensor is a 3D matrix), and the player moves around trying to arrive at the optimal solution (modify the tensor and zero out its entries). If the player succeeds, the result of his moves is the correct matrix multiplication algorithm (efficiency is given by the number of steps taken to zero out the tensor). So the aim is to minimize the number of moves (steps) to zero out the tensor. Pretty clever,\u00a0right? Image source:\u00a0here The researchers used reinforcement learning in order to \u2018play\u2019. As described in the article, one can consider this system as an adapted version of AlphaZero (where the goal of the agent was to win at Go, chess, and other games). For this reason, the model was called AlphaZero. The problem described in these terms sounds simple, but as described by the DeepMind researchers, in reality, there are so many potential combinations: This game is incredibly challenging\u200a\u2014\u200athe number of possible algorithms to consider is much greater than the number of atoms in the universe, even for small cases of matrix multiplication. Compared to the game of Go, which remained a challenge for AI for decades, the number of possible moves at each step of our game is 30 orders of magnitude larger (above 1033 for one of the settings we consider).\u200a\u2014\u200aDeepMind\u00a0Blogpost image from Felix Mittermeier at usplash.com Now, to succeed, the authors used a new type of architecture incorporating problem-specific inductive biases; they also used synthetic data and some information about the problem (symmetries). To be more specific, the researchers used a transformer-based architecture (using cross-attention, causal self-attention, etc., here and here is a detailed image of the structure). The model was then trained using reinforcement learning (the input is, in fact, the current state and the 3D tensor, and the previous\u00a0actions. Model structure of AlphaTensor. Image source: original\u00a0paper At the beginning of the training, the model has no knowledge of existing algorithms to multiply matrices, but during the training, it gets better. Interestingly, AlphaTensor first rediscovery algorithms that are already known and then find unknown algorithms (practically surpassing human intuition) This resulted in the discovery of algorithms that multiply large matrices 10\u201320% faster than those commonly used on that piece of hardware.\u200a\u2014\u200asource Speed-ups of the AlphaTensor-discovered algorithms tailored for a GPU. image source:\u00a0here Another interesting result is that practically the space of matrix multiplication algorithms is richer than previously thought. Now, this sounds like mathematical jargon, but it actually means that the authors were able to adapt AlphaTensor to look for more efficient algorithms depending on the case needed: i.e. whether a matrix multiplication algorithm was [&#8230;]",
            "pubdate": "Mon, 10 Oct 2022 11:43:54 +0000",
            "pubdate_parsed": [
                2022,
                10,
                10
            ],
            "email_sent": true
        },
        "AI Voice Assistants Could Now Become Amazing Language Teachers": {
            "url": "https://towardsai.net/p/l/ai-voice-assistants-could-now-become-amazing-language-teachers",
            "description": "Last Updated on October 13, 2022 by Editorial Team Author(s): Rafe Brena, PhD Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Whisper + PaLM is just another level Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 13 Oct 2022 12:08:45 +0000",
            "pubdate_parsed": [
                2022,
                10,
                13
            ],
            "email_sent": true
        },
        "Expand Your Skills with Open-Source Graph Database NebulaGraph": {
            "url": "https://towardsai.net/p/l/expand-your-skills-with-open-source-graph-database-nebulagraph",
            "description": "Last Updated on October 13, 2022 by Editorial Team Author(s): Cornellius Yudha Wijaya Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Learn widely used Graph Database for your skillset Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 14 Oct 2022 00:13:14 +0000",
            "pubdate_parsed": [
                2022,
                10,
                14
            ],
            "email_sent": true
        },
        "Why would a Traditional Data Scientist Learn ANN Technology?": {
            "url": "https://towardsai.net/p/l/why-would-a-traditional-data-scientist-learn-ann-technology",
            "description": "Last Updated on October 14, 2022 by Editorial Team Author(s): Poornachandra Sarang Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Bringing out the importance of ANN over GOFAI Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 14 Oct 2022 13:08:13 +0000",
            "pubdate_parsed": [
                2022,
                10,
                14
            ],
            "email_sent": true
        },
        "Googles Audiolm: Generating Music by Hearing a Songs Snippet": {
            "url": "https://towardsai.net/p/l/googles-audiolm-generating-music-by-hearing-a-songs-snippet",
            "description": "Last Updated on October 14, 2022 by Editorial Team Author(s): Salvatore Raieli Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Whether music or speech, Google&#039;s new model can continue playing what is\u00a0hearing. image by Marius Masalar at unsplash.com AudioLM is Google\u2019s new model, capable of generating music in the same style as the prompt. The model is also capable of generating complex sounds such as piano music or people talking. the result is stunning. In fact, it seems to be indistinguishable from the original. Why is generating music difficult? image by Dolo Iglesias at unsplash.com Generating music is not an easy task. In fact, generating audio signals (music, ambient sounds, people&#039;s speech) requires multiple scales of abstraction. For example, music has a structure that has to be analyzed over a long period of time and is also composed of numerous interacting signals. Even personal speech itself can be analyzed at different levels, be it the simple acoustic signal or phonetics, but also in terms of prosody, syntax, grammar, or semantics. Several attempts have been made previously. The first attempts to generate music focused on generating MIDI files (an interesting project where they generated MIDI music for piano was created in 2018 using a transformer). In addition, some studies focused on tasks such as text-to-speech, where speech is generated from a transcript. The problem is that everything that is not in the transcript is not translated into the audio file. Several studies explain how in human communication, pauses and inflections, and other signals are extremely important. For example, those using Alexa or other speakers have noticed that the voice does not sound natural. Especially in the early days, no matter how correct the pronunciation was, it sounded unnatural and gave an uncanny\u00a0effect. AudioLM, the new Google\u00a0model image by Priscilla Du Preez at unsplash.com A few days ago, Google announced the release of a new model: \u201cAudioLM: a Language Modeling Approach to Audio Generation\u201d. The new model is capable of generating audio (such as realistic music and speech) just by listening to\u00a0audio. Google AI on Twitter: \"Learn about AudioLM, an audio generation framework that demonstrates long-term consistency (e.g., syntax in speech &#38; melody in music) and high fidelity, with applications for speech synthesis and computer-assisted music. \u2193 https://t.co/onTH6HdCcX / Twitter\" Learn about AudioLM, an audio generation framework that demonstrates long-term consistency (e.g., syntax in speech &#38; melody in music) and high fidelity, with applications for speech synthesis and computer-assisted music. \u2193 https://t.co/onTH6HdCcX As they blogged, there has been a great improvement in the field of Natural Language Processing (NLP) in recent years. In fact, language models have proven to be extremely effective in a number of tasks. Many of these systems are based on the use of transformers, and those who have used them know that one of the initial pre-processing steps is to tokenize (break up the text into smaller units that are assigned a numerical value). The key intuition behind AudioLM is to leverage such advances in language modeling to generate audio without being trained on annotated data.\u200a\u2014\u200aGoogle AI\u00a0blogpost AudioLM does not need transcription or labeling. The authors collected a database of sounds and fed it directly to the model. The model compresses the sound files into a series of snippets (sort of tokens). These tokens are then used as if they were an NLP model (the model, in this way, uses the same approach to learn patterns and relationships between the various audio snippets). In the same way as a text-generating model, AudioLM generates sounds from a\u00a0prompt. The result is very interesting, the sound is much more natural. AudioLM seems to be able to find and recreate certain patterns present in human music (like subtle vibrations contained in each note when piano keys are struck). In the link below, Google has provided a number of examples if you are curious to\u00a0listen: AudioLM AudioLM has been trained on a vast library of sounds that include not only music but also human voices. For this reason, the model can generate sentences produced by a human being. The model is able to pick up the accent of the speaker and add pauses and exclamations. Although many of the sentences generated by the model do not make sense, the result is impressive. Indeed, treating sequences of sounds as if they were sequences of words may seem like a clever approach, nonetheless, some difficulties remain: First, one must cope with the fact that the data rate for audio is significantly higher, thus leading to much longer sequences\u200a\u2014\u200awhile a written sentence can be represented by a few dozen characters, its audio waveform typically contains hundreds of thousands of values. Second, there is a one-to-many relationship between text and audio. This means that the same sentence can be rendered by different speakers with different speaking styles, emotional content and recording conditions.\u200a\u2014\u200aGoogle AI\u00a0blogpost In more detail, the audio tokenization approach was already tried by OpenAI Jukebox, only that the model generated many more artifacts, and the sound did not sound as\u00a0natural. Overview of the tokenizers used in AudioLM. image from the original paper\u00a0(here) As described by the authors, the model consists of three\u00a0parts: a tokenizer model, which maps a sequence of sounds into a discrete sequence of tokens. This step also reduces the size of the sequence (the sampling rate is reduced by about 300\u00a0times). a decoder-only transformer (a classical language model) that maximizes the likelihood of predicting the next tokens in the sequence. The model contains 12 layers with 16 attention heads, an embedding dimension of 1024, a feed-forward layer dimension of\u00a04096 a detokenizer model that transforms predicted tokens into audio\u00a0tokens. The model was trained on 60,000 hours of English speech and 40,000 hours of music for the piano experiments. [&#8230;]",
            "pubdate": "Sat, 15 Oct 2022 00:08:46 +0000",
            "pubdate_parsed": [
                2022,
                10,
                15
            ],
            "email_sent": true
        },
        "Airflow is on the Cloud | ELT Pipeline Orchestration With Airflow & AWS": {
            "url": "https://towardsai.net/p/l/airflow-is-on-the-cloud-elt-pipeline-orchestration-with-airflow-aws",
            "description": "Last Updated on October 15, 2022 by Editorial Team Author(s): Kaan Boke Ph.D. Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. You will see the ELT pipeline with Airflow orchestration. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 15 Oct 2022 12:13:09 +0000",
            "pubdate_parsed": [
                2022,
                10,
                15
            ],
            "email_sent": true
        },
        "4 Questions To Ask Before You Hire a Data Engineer": {
            "url": "https://towardsai.net/p/l/4-questions-to-ask-before-you-hire-a-data-engineer",
            "description": "Last Updated on October 16, 2022 by Editorial Team Author(s): Rijul Singh Malik Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A blog around how to hire and work with a data engineer. Photo by Towfiqu barbhuiya on\u00a0Unsplash What is a data engineer? If you\u2019re in charge of managing the data team, then you\u2019ll need to employ a data engineer that will help you run the show. But if you\u2019re a business owner who is into data engineering and is wondering how you could become a data engineer, you\u2019ll need to ask yourself a few questions. Data engineers are in high demand these days because data is becoming a big thing in business, and companies are struggling to find enough people who can actually manage it all. From big data to cloud-based data solutions, more and more businesses are going digital, and a data engineer is a person who takes care of the data. So what does a data engineer do? What kind of work do they\u00a0perform? Why do you need a data engineer? Most businesses have a lot of data, but few actually know what to do with it. Data science is a hot field, with students going to school to learn the skills needed to filter, sort, and search through information. Data engineers play a major role in the data science field, as they tend to be the ones who organize the data, make sense of it, and distribute it to the right people. Not only do they organize the data, but they also make sure it is secure and accessible to everyone who needs it. Data engineers are more than just data analysts; they are more web developers, web technology experts, and database administrators who all work together to make sure all of the data is technically sound. Data engineers are in high demand and are vital members of any team. They are responsible for building, maintaining, and scaling data-related systems and tools. They design and build the data platform on which other teams build their products and services. Data engineers are software developers, but their focus is on building data products that are accessible, reliable, and scalable rather than on writing code. However, there are many different types of data engineers. Through my experience and research, I\u2019ve discovered that data engineers can be broken up into three different categories: data scientists, data analysts, and data engineers. The difference between each of these categories is quite clear, but it\u2019s not always clear which category an engineer falls under. In this blog, I\u2019m going to run down the differences between each type of data engineer so that you can figure out which type of engineer you need for your\u00a0team. How to hire the right data engineer for your\u00a0product? It\u2019s really difficult to find the right data engineer for your product, especially if you have a tight budget and time constraints. It\u2019s not just about finding any data engineer that can do the job, but it\u2019s about finding the right blend of skills, experience, and cost. It\u2019s not an easy task. It\u2019s like asking yourself: \u201cWhat makes a great product engineer? What makes a great software engineer?\u201d The answer is the same for both engineers. The top data engineers are the ones who are good at solving problems, have a good grasp of the tools and technologies needed, and have the ability to work on the\u00a0product. We have all read countless articles on how to hire the right data scientist. But data engineers are a different breed of animal. They are the ones that turn the data scientists\u2019 models into a live system. They are the ones that get to the core of your business, and they are the ones who can really contribute to the growth of your product. As a business, it is important to understand how to hire the right data engineer. You need to know the right questions to ask at an interview, the kind of skills you need to look for and the kind of personality you need to match your company\u2019s culture. We have done all the hard work for you and listed down 4 questions that you need to ask your next data engineer. How to work with a data engineer? Working with a data engineer is something many businesses need to do every day. You can find yourself in a variety of situations as a business owner or as a manager. Sometimes you will be trying to get the most out of your data to make smart decisions. Sometimes you will be trying to get your data into a shape that it can be used by your in-house team or by the public. Or maybe you are looking to hire a new data engineer. Whatever the case, there are some questions that you need to ask yourself. These four questions will help you get the most out of your\u00a0data. There are many types of data engineers. Some of them are generalists, and others are specialists. But regardless of your requirements, recruitment is a big challenge. For example, if you are looking for a junior data engineer, you will have to find a candidate who has both the skills and enthusiasm to learn new skills. If you are looking for a data engineer with experience, you will need to find a candidate who is experienced and willing to relocate. When hiring a data engineer, pay attention to the following things: What type of data engineer do you need? What skills do they have? What is their level of experience? What salary level are you ready to offer? How do candidates respond to the questions you ask? Tell candidates about the job, the culture of your company, [&#8230;]",
            "pubdate": "Mon, 17 Oct 2022 00:14:04 +0000",
            "pubdate_parsed": [
                2022,
                10,
                17
            ],
            "email_sent": true
        },
        "Julia Tuple and Dictionary": {
            "url": "https://towardsai.net/p/l/julia-tuple-and-dictionary",
            "description": "Last Updated on October 17, 2022 by Editorial Team Author(s): Vivek Chaudhary Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. The objective of this article is to understand Julia Data Structures Tuple and Dictionary and the various operations associated with\u00a0them. TUPLES: are an immutable collection of distinct values of the same or different datatypes separated by\u00a0commas. Syntax: (item1, item2,\u00a0item3\u2026) Dictionary: is a collection of key-value pairs, where each value in the dictionary can be accessed with its key. These key-value pairs need not be of the same data\u00a0type. Syntax: Dict(key1 =&#62; value1, key2 =&#62; value2,\u00a0\u2026) Tuples and methods() #create an empty tuplet1=()println(\u201cIf a Tuple is empty returns \u201c, isempty(t1))t1=(\u201cjulia\u201d,\u201dpython\u201d,\u201dsql\u201d)println(\u201cIf a Tuple is non-empty returns \u201c,isempty(t1)) Output:If a Tuple is empty returns trueIf a Tuple is non-empty returns false Indexing, Slicing, Iteration and Assignment #declare a tuple beveragebeverage= (\u201ccoffee\u201d,\u201dtea\u201d,\u201dgreentea\u201d,\u201dgrrencoffee\u201d,\u201dginger tea\u201d) #Indexingprintln(beverage[1])Output: coffee println(beverage[0]) #index in julia starts from 1BoundsError: attempt to access NTuple{5, String} at index [0]Stacktrace: [1] getindex(t::Tuple, i::Int64) @ Base .\\tuple.jl:29 [2] top-level scope @ In[7]:2 [3] eval @ .\\boot.jl:373 [inlined] [4] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String) @ Base .\\loading.jl:1196 #Slicingprintln(beverage[2:4]) Output:(\"tea\", \"greentea\", \"grrencoffee\") #Iterationprintln(\"iterating over tuple :\")for i in beverage println(i)end Output:iterating over tuple :coffeeteagreenteagrrencoffeeginger tea #Tuple manipulation:beverage[3]=\"chamomile tea\" Output:MethodError: no method matching setindex!(::NTuple{4, String}, ::String, ::Int64)Stacktrace: [1] top-level scope @ In[7]:2 [2] eval @ .\\boot.jl:373 [inlined] [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String) @ Base .\\loading.jl:1196 #Note: Tuples are immutable, and they don\u2019t support item assignment. Tuple methods() #reverse a tuplerev= reverse(beverage)println(rev) Output:(\"ginger tea\", \"grrencoffee\", \"greentea\", \"tea\", \"coffee\") #length of tupleprintln(\u201clength of tuple \u201c,length(beverage)) Output: length of tuple 5 #check if empty or notprintln(isempty(beverage)) Output: false Named Tuples: are just like Tuples except that each element additionally has a name! They have a special syntax using \u201c=\u201d inside a tuple.Syntax:(name1 = item1, name2 = item2,\u00a0\u2026) lang= (l1=\u201djulia\u201d,l2=\u201dpython\u201d,l3=\u201dSQL\u201d)println(lang) Output: (l1 = \"julia\", l2 = \"python\", l3 = \"SQL\") println(lang[2]) Output: python println(lang.l1) Output: julia Dictionary and methods() #create a dictionaryempIDs= Dict(\u201cvivek\u201d=&#62;121,\u201daniket\u201d=&#62;134,\u201djagdish\u201d=&#62;101)println(typeof(empIDs))println(empIDs) Output:Dict{String, Int64}Dict(\"jagdish\" =&#62; 101, \"vivek\" =&#62; 121, \"aniket\" =&#62; 134) #create dict from tupleeds=[(\"vivek\",2000),(\"jagdish\",5000),(\"aniket\",3500)]println(typeof(eds))println(eds) Output:Vector{Tuple{String, Int64}}[(\"vivek\", 2000), (\"jagdish\", 5000), (\"aniket\", 3500)] #conver the tuple into dictionaryedict=Dict(eds)println(typeof(edict))println(edict) Output:Dict{String, Int64}Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 2000, \"aniket\" =&#62; 3500) Access Dictionary items println(edict)Output:Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 2000, \"aniket\" =&#62; 3500) key=keys(edict)println(\u201ckeys are :\u201d,key)Output: keys are :[\"jagdish\", \"vivek\", \"aniket\"] val=values(edict)println(\u201cvalues are :\u201d, val)Output: values are :[5000, 2000, 3500] #Iterate over dictionary using for loop for (key,val) in edict println(key,\"=&#62;\",val)end Output:jagdish=&#62;5000vivek=&#62;2000aniket=&#62;3500 Dictionary methods() get() and\u00a0getkey() #get() method: Return the value stored for the given key#syntax: get(collection, key, default) println(edict)Output:Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 2000, \"aniket\" =&#62; 3500) println(get(edict,\"vivek\",-1))Output: 2000 #default value is mandatory otherwise it throws errorprintln(\"Key not found \",get(edict,\"viv\",0))Output: Key not found 0 #wihtout default valueprintln(\"Key not found \",get(edict,\"viv\")) Output:MethodError: no method matching get(::Dict{String, Int64}, ::String)Closest candidates are: get(::Dict{K, V}, ::Any, ::Any) where {K, V} at C:\\Users\\lenovo\\AppData\\Local\\Programs\\Julia-1.7.1\\share\\julia\\base\\dict.jl:506 get(::IJulia.IJuliaStdio, ::Any, ::Any) at C:\\Users\\lenovo\\.julia\\packages\\IJulia\\e8kqU\\src\\stdio.jl:21 get(::Test.GenericDict, ::Any, ::Any) at C:\\Users\\lenovo\\AppData\\Local\\Programs\\Julia-1.7.1\\share\\julia\\stdlib\\v1.7\\Test\\src\\Test.jl:1800 ...Stacktrace: [1] top-level scope @ In[57]:7 [2] eval @ .\\boot.jl:373 [inlined] [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String) @ Base .\\loading.jl:1196 #getkey()Return the key matching argument key if one exists in collection, otherwise return default. println(getkey(edict,\"aniket\",-1))Output: aniket println(getkey(edict,\"viv\",-1))Output: -1 delete() items println(edict)Output:Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 2000, \"aniket\" =&#62; 3500) delete!(edict,\u201dvivek\u201d)println(edict)Output:Dict(\"jagdish\" =&#62; 5000, \"aniket\" =&#62; 3500) #delete a non-existing itemdelete!(edict,\"viv\")Output: Dict{String, Int64} with 2 entries: \"jagdish\" =&#62; 5000 \"aniket\" =&#62; 3500 merge() dictionaries #merge dictionaries using merge()d1 = Dict(\u201ca\u201d=&#62;1, \u201cb\u201d=&#62;9, \u201cc\u201d=&#62;3)d2 = Dict(\u201ce\u201d=&#62;7, \u201cf\u201d=&#62;2, \u201ch\u201d=&#62;5)println(merge(d1,d2))Output:Dict(\"f\" =&#62; 2, \"c\" =&#62; 3, \"e\" =&#62; 7, \"b\" =&#62; 9, \"a\" =&#62; 1, \"h\" =&#62; 5) #common keys presentd1 = Dict(\"a\"=&#62;1, \"b\"=&#62;9, \"c\"=&#62;3)d2 = Dict(\"e\"=&#62;7, \"b\"=&#62;2, \"h\"=&#62;5)println(merge(d1,d2))Output:Dict(\"c\" =&#62; 3, \"e\" =&#62; 7, \"b\" =&#62; 2, \"a\" =&#62; 1, \"h\" =&#62; 5) #merge dictionaries using mergewith()d1 = Dict(\"a\"=&#62;1, \"b\"=&#62;9, \"c\"=&#62;3)d2 = Dict(\"e\"=&#62;7, \"b\"=&#62;2, \"h\"=&#62;5)println(mergewith!(+,d1,d2))Output:Dict(\"c\" =&#62; 3, \"e\" =&#62; 7, \"b\" =&#62; 11, \"a\" =&#62; 1, \"h\" =&#62; 5) add and change dict\u00a0items #add new item to a dictprintln(edict)Output: Dict(\"jagdish\" =&#62; 5000, \"aniket\" =&#62; 3500) edict[\u201cvivek\u201d]=2700println(edict)Output: Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 2700, \"aniket\" =&#62; 3500) #change dict vaue for a keyprintln(edict)Output: Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 2700, \"aniket\" =&#62; 3500) edict[\"vivek\"]=4000println(edict)Output: Dict(\"jagdish\" =&#62; 5000, \"vivek\" =&#62; 4000, \"aniket\" =&#62; 3500) To Summarize: Julia tuple and tuple\u00a0methods. Dictionary and\u00a0methods. Thanks for reading my blog and supporting the content. Appreciation always helps to keep up the spirit. I will try my best to keep coming up with quality content. Connect with me to get updates about upcoming new\u00a0content. Keep Supporting. Julia Tuple and Dictionary was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Oct 2022 12:13:24 +0000",
            "pubdate_parsed": [
                2022,
                10,
                17
            ],
            "email_sent": true
        },
        "Top 10 SQL Queries a Data Scientist Should Know": {
            "url": "https://towardsai.net/p/l/top-10-sql-queries-a-data-scientist-should-know-2",
            "description": "Last Updated on October 17, 2022 by Editorial Team Author(s): Saurabh Saxena Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Photo by Campaign Creators on\u00a0Unsplash Structured Query Language or SQL is a query-based universal language to read, write and manage databases. In any Machine Learning pipeline, whether it is data, metadata, or logs, SQL is widely used in all operations. When you are working with a database, the four basic operations any must know is CRUD (Create, Read, Update, and Delete). However, we will target read, update, and delete operations in this\u00a0blog. Let\u2019s Start from the\u00a0basics. 1) SELECT If you want to know the first_name, last_name, and email of the customers, you can specify the list of the desired columns along with the SELECT and FROM keywords. SELECT first_name, last_name, email FROM customer Image by\u00a0Author Whereas, to query all the columns in the table, then asterisks(*) is the one that goes with SELECT\u00a0. SELECT * FROM customer Image by\u00a0Author 2) DISTINCT DISTINCT restricts the duplication of rows in the query. Example: Query to print the creation date of the customers. SELECT DISTINCT create_dateFROM customer Image by\u00a0Author 3) WHERE WHERE is used in a query to filter the result. Example: Query all the addresses in the Texas district. SELECT * FROM addressWHERE district=&#039;Texas&#039; Image by\u00a0Author 4) GROUP BY and\u00a0HAVING GROUP BY clause clusters the rows with the same values. Example: What is the total payment made by each customer? SELECT customer_id, SUM(amount) AS total_amount FROM paymentGROUP BY customer_id Image by\u00a0Author In SQL, aggregation functions such as SUM, AVG, andCOUNT can not be used in the WHERE clause. We need to use the HAVING\u00a0clause. SELECT customer_id, SUM(amount) AS total_amount FROM paymentGROUP BY customer_idHAVING SUM(amount) &#60;=50 Image by\u00a0Author 5) ORDER BY and\u00a0LIMIT ORDER BY sorts the results in ascending or descending order based on certain columns, ASC and DESC keywords decide the order of the sort. Example: Find the total payment made by each customer and sort in ascending order. SELECT customer_id, SUM(amount) AS total_amount FROM paymentGROUP BY customer_idORDER BY total_amount ASC Image by\u00a0Author LIMIT restricts the number of rows to a specified number in the result. Example: Find the top 3 highest paying customers. SELECT customer_id, SUM(amount) AS total_amount FROM paymentGROUP BY customer_idORDER BY total_amount DESCLIMIT 3 Image by\u00a0Author Note: Default Order By clause sorts the result in ASCENDING order. Few SQL providers support TOP n keywords to limit the number of rows in the\u00a0result. 6) CASE The CASE expression goes through conditions and returns a value when the first condition is met. Example: A customer is a premium customer if the amount exceeds\u00a050. Image by\u00a0Author SELECT customer_id, SUM(amount) AS total_amount, CASE WHEN SUM(amount)&#62;=50 THEN &#039;Premium Customer&#039; ELSE &#039;Standard Customer&#039; END AS customer_statusFROM paymentGROUP BY customer_idORDER BY total_amount ASC Image by\u00a0Author 7) JOINS INNER JOIN that will result in the common rows between two\u00a0tables. LEFT JOINreturns all rows from the left table and the matching rows from the right table. If no matching rows are found in the right table, NULL is used. RIGHT JOIN is a vice-versa of left\u00a0join. FULL JOIN is a combination of left and right join. If no matching rows are found in the left or right table, NULL is\u00a0used. Image by\u00a0Author SELECT c.first_name, c.last_name, c.customer_id, SUM(p.amount)FROM customer cINNER JOIN payment p ON c.customer_id = p.customer_idGROUP BY c.first_name, c.last_name, c.customer_id Image by\u00a0Author SELECT c.first_name, c.last_name, c.customer_id, SUM(p.amount)FROM customer cLEFT JOIN payment p ON c.customer_id = p.customer_idGROUP BY c.first_name, c.last_name, c.customer_id Image by\u00a0Author 8) Subqueries A subquery is a SQL query nested inside a larger query.\u00a0Example: SELECT payment_id, amount, (SELECT SUM(amount) FROM payment) AS total_amountFROM payment Image by\u00a0Author 9) Windows Function with\u00a0Rank Window functions apply to aggregate and ranking functions over a particular window (set of rows). OVER clause is used with window functions to define that window. It can be combined with PARTITION BY and ORDER BY\u00a0. SELECT customer_id, SUM(amount) AS total_amount, RANK() OVER (ORDER BY SUM(amount) DESC)FROM paymentGROUP BY customer_id Image by\u00a0Author 10) INSERT, UPDATE, DELETE and\u00a0TRUNCATE As the name suggests INSERT is used to push one or more records into the table, while UPDATEis used to modify values in the table based on certain conditions provided by WHERE\u00a0clause. DELETE and TRUNCATE both are used to remove records from the table where DELETE removed the record based on WHERE condition and TRUNCATE removed all the records in any\u00a0table. Note: We have used PostgreSQL, which is an open-source Relational DBMS, pgAdmin as a Client. Queries ran on \u2018dvdrental\u2019 database, and I have mentioned all the resources about the database and PostgreSQL in the reference section. References: [1] PostgreSQL Official Page. https://www.postgresql.org/ [2] pgAdmin Official Page. https://www.pgadmin.org/ [3] PostgreSQL docker Image. https://hub.docker.com/_/postgres [4] DVD Rental DB. https://www.postgresqltutorial.com/postgresql-getting-started/load-postgresql-sample-database/ Top 10 SQL Queries a Data Scientist Should Know was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Oct 2022 12:13:22 +0000",
            "pubdate_parsed": [
                2022,
                10,
                17
            ],
            "email_sent": true
        },
        "Getting Started with Applied AI and NLP": {
            "url": "https://towardsai.net/p/l/getting-started-with-applied-ai-and-nlp",
            "description": "Last Updated on October 17, 2022 by Editorial Team Author(s): Daniel Tannor Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Here are 4 Applied AI Project Ideas that You Can Code Right\u00a0Now No need for complex self-made Machine Learning Projects\u200a\u2014\u200ait\u2019s time to use APIs instead. All you need is the coding\u00a0basics. Some Background on Natural Language Processing and Applied\u00a0AI Applied AI is the branch of artificial intelligence that brings it out of the lab and into the real world, enabling computers and computer-controlled robots to execute real tasks.\u200a\u2014\u200acognizant.com Just like the above quote states\u200a\u2014\u200awe\u2019re going to use Applied AI so that we can execute real, everyday tasks. We\u2019re also going to leverage Natural Language Processing\u200a\u2014\u200agetting the machine to process and understand language so that our apps\u00a0can: Figure out which movie scenes are happy so that we can create happy movie scene compilations Summarize complete Zoom meetings into short summaries. and more. The Projects The projects are divided up into two categories: Emotion Based and Summarization Based, which I\u2019ll explain in the next paragraph. The summarization-based projects are meant to be huge time savers and productivity tools\u200a\u2014\u200ahelping people be more effective in reviewing meetings and conversations. The other projects are meant for entertainment and also improving one\u2019s social skills\u200a\u2014\u200awhether it\u2019s interviewing, dating, or meeting new people in social settings. Different Natural Language Processing Projects to\u00a0Code Emotion Based Emotion-based projects are projects that are based on detecting emotions. When our app manages to detect that an actress in a movie scene was happy, based on the words she said, that makes our project emotion-based. The emotion-based projects: Generate Happy Movie Scene Compilations Do you know those Youtube movie compilations where you get a bunch of scenes that are aligned around an\u00a0idea? Here\u2019s an example of a compilation of The Most Beautiful Shots in Movie\u00a0History We can use NLP in order to get the happy scenes out of movies and create our own movie compilation- Jim Carrey\u2019s smile comes to\u00a0mind: Jim Carrey in a happy movie scene in \u2018The\u00a0Mask\u2019 What we\u2019d do is have the NLP engine go over movie scripts and return the time stamps of scenes with the happiness emotion. We\u2019d then attach those scenes together to generate one long clip we can share on YouTube or social\u00a0media. You can do this using One AI or other free-to-use NLP APIs you insert in your code. I\u2019ll follow up on this in another\u00a0blog. Social Skills\u00a0Trainer Often times people don\u2019t know how a conversation went. What if we could build an app to provide feedback and improve people\u2019s social\u00a0skills? Below is what the app might look like\u00a0\u2014 Adam is asking Sarah out, and the conversation starts out pretty awkward. However, you can see that Adam\u2019s last remark gets him points and creates a positive interaction with\u00a0Sarah. Adam can now understand which sentences gave him points and which sentences lost him points, and he can improve his interactions with people over\u00a0time. See how to build this\u00a0here. Summarization Based The summarization-based projects are projects that are based on the NLP engine summarizing large amounts of text in order to provide accurate summaries of\u00a0content. This content can also originate in video or audio, we would then transcribe that content so that the AI runs on the text\u00a0output. The Summarization projects: Auto-Summarize Zoom\u00a0Meetings Create your own app to auto-summarize Zoom meetings. You can do this per meeting or even build an app to solve this problem at\u00a0scale. Aren\u2019t we all tired of long boring meetings? Think of how much time you\u2019d save for yourself and your colleagues if you could provide automatic, accurate summarizations of meetings on a weekly\u00a0basis. Falling asleep on a Zoom\u00a0meeting Some use cases\u00a0include: Summarize your own individual meetings Summarize company meetings on a weekly basis for\u00a0everyone Create a web app for people to summarize their\u00a0meetings See how to build an app like this\u00a0here. Auto-Summarize Slack Conversations Slack can quickly become one giant mess of information\u200a\u2014\u200ameeting notes, product requirements, or conversations with the\u00a0boss. Multiple channels and an overload of info on\u00a0Slack Can\u2019t find that last feature requirement from last week? What about the notes from your meeting with your 1:1 with your\u00a0boss? What if we could build an app to summarize the important points from the past week? These points would include important conversation summaries and action\u00a0items. Summary We\u2019ve seen a bunch of different NLP projects you can build today. Some of these ideas, or similar ones, could definitely be the basis of a startup\u200a\u2014\u200aas they solve real-world pain points that we all experience in our day to\u00a0day. We\u2019ve learned about applied AI and NLP to build apps that can help us with day-to-day tasks. In order to get started, all you need to do is make a few NLP API calls within your code, and you\u2019re good to\u00a0go. Please feel free to reach out and share project ideas you have in mind or what you\u2019ve started to\u00a0build. Getting Started with Applied AI and NLP was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Oct 2022 00:13:40 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "Detailed Dashboard Design Guidelines Used by Professionals": {
            "url": "https://towardsai.net/p/l/detailed-dashboard-design-guidelines-used-by-professionals",
            "description": "Last Updated on October 18, 2022 by Editorial Team Author(s): Saleha Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. As I said in my last article, data analysts give data meaning by taking raw data and turning it into data-driven visualizations that help&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Oct 2022 13:18:31 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "Airflow Production TipsProper Task (Not DAG) Catchup": {
            "url": "https://towardsai.net/p/l/airflow-production-tips%e2%80%8a-%e2%80%8aproper-task-not-dag-catchup",
            "description": "Last Updated on October 18, 2022 by Editorial Team Author(s): Guilherme Banhudo Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Airflow Production Tips\u200a\u2014\u200aProper Task (Not DAG)\u00a0Catchup Photo by Jackson Simmer on\u00a0Unsplash Apache Airflow has become the de facto standard for Data Orchestration. However, throughout the years and versions, it accumulated a set of nuances and bugs which can hinder its production usage. This series of articles aims at walking Apache Airflow users through the process of overcoming these issues, the same issues I have\u00a0faced. Note: As usual, all of the code is available in my GitHub repository, here. Proper Task (Not DAG)\u00a0catchup TLDR: Airflow\u2019s ability to get the previous successful TaskInstance\u2019s date does not work as intended, returning the previous successful DAG\u2019s run date instead, which prevents you from accurately and properly picking up missing/failed information. In this post, you will find out how to bypass it. See the original bug\u00a0report. TLDR #2: Click here to skip directly to the\u00a0solution Problem Statement One of the most interesting and helpful features of Apache Airflow is its ability to catch up with the past should a task fail. No, I am not referring to the catchup parameter you can define in your DAG, but rather giving Tasks the ability to encompass the previously failed TaskInstances (and their execution date) using either\u00a0the JINJA template, or directly accessing the previous TaskInstance whose status was a\u00a0success: https://medium.com/media/6712aa06940cf80b6b5899f0941a7cdb/href This is particularly useful when you want to make sure your data stays up to date in Ingestions or your ETL consumes all information for both the current and failed past TaskInstances, for instance: https://medium.com/media/0953ef183f32473dc50b371943c359e7/href On a more practical example, considering the image below, you would expect that if the first run of Task transform_data failed whilst using the above configuration, the failed/missing data would be captured on the next run of transform_data, in the next hour,\u00a0correct? Simple ETL-like DAG consisting of three linearly dependent tasks Expected Event\u00a0Loop: Loop 1\u2013 Run task extract_from_db, capture one hour of data, status: success\u2013 Run task tranform_data, transform one hour of data, status: fail\u2013 Run task load_target_db, load one hour of data, status:\u00a0fail Loop 2\u2013 Run task extract_from_db, capture one hour of data, status: success\u2013 Run task tranform_data, transform two hours of data (current and previously failed), status: success\u2013 Run task load_target_db, load two hours of data (current and previously failed), status:\u00a0success Unfortunately, that is incorrect. Whilst it is the obvious and expected behavior, Airflow\u2019s legacy code prevents such from happening. See the original bug\u00a0report. Below is the corresponding rendered template for the first and second runs of Task transform_data, respectively: https://medium.com/media/a5d909553366e31daf47859ce48ff7ce/hrefhttps://medium.com/media/47b352bc376b8b25f6ad021d6c5f4d5a/href Note that the second task does not compensate for the previous failure. Instead, it just passes its own previous execution date param, 20221013T010000 instead of including the previous successful run, the full catch-up 20221013T000000. Why does this\u00a0happen? Apache Airflow\u2019s default behavior, when the previous execution date was successful, is to look at the previous DAG\u2019s successful execution date, not of the TaskInstance\u2019s, which effectively makes your DAGs incapable of automatically catching up unless the entire DAG\u00a0fails. So did we expect to happen instead? Well, we expect the rendered template in the second run to have\u00a0been: https://medium.com/media/580e070ba983bf9d439e375d50e10f34/href You can see the original bug report on the problem, dating back to 2021 and even longer on StackOverflow. The Solution Like many other Python frameworks, Apache Airflow uses an ORM (Object Relational Mapper) to abstract access to its backend database. Specifically, the usual SQL Alchemy project has been leveraged to accelerate Apache Airflow. This allows us to access the metadata database directly and manipulate it according to our requirements. The solution to our problem is then divided into four simple\u00a0steps: Retrieve the TaskInstance objects based on a specified State Retrieve the last successful TaskInstance instance for the provided\u00a0Task Retrieve the DAGRun associated with the last successful TaskInstance instance for the provided\u00a0Task Arm our DAG with the ability to use this information! Lastly, a practical section example has been added to illustrate the\u00a0goal! Step 1: Retrieve the TaskInstance objects based on a specified State The first step corresponds to having the ability to query the ORM to retrieve the database to retrieve the last TaskInstance run corresponding to a specific\u00a0state: Note: The function is a generalization used to allow you to pick up any specific state you may\u00a0require https://medium.com/media/69163909fc202dcb6b4cd6e9b8d111d2/href The function is self-explanatory, querying the TaskInstance ORM object and filtering it via two parameters: the desired lookup state and TaskInstance instance. Step 2: Retrieve the last successful TaskInstance instance for the provided\u00a0Task Leveraging the previously defined generalization, we can now query the ORM to retrieve only the last run whose state was\u00a0Success. https://medium.com/media/447f8d9eef5ff7a199bf819156028272/href Step 3: Retrieve the DAGRun associated with the last successful TaskInstance instance for the provided\u00a0Task. Having tracked down the last successful TaskInstance instance, we can now retrieve the DAGRun object associated with said TaskInstance instance. The DAGRun model contains information regarding the ran TaskInstance instance alongside a vast array of useful information: https://medium.com/media/9ec125df8a1323739a9e033e470c3e12/href Armed with this knowledge, we can now retrieve the DAGRun instance associated with our retrieved last successful TaskInstance instance in a similar process as\u00a0before: https://medium.com/media/f41229e4fba53554130c090faa31156d/href Step 4: Arm our DAG with the ability to use this information! Finally, we have to make sure Apache Airflow is aware of our new functions and can inject them into the JINJA\u00a0engine. We can do so by importing the function and passing the user-defined function to the DAG directly on its constructor, in this case, via context-manager: https://medium.com/media/ed392fc52b84de16a6fbffe107dacd8f/href You can now freely call the function directly in JINJA and pass it as an argument to your Extraction, ETL, or any other processes you may\u00a0have! https://medium.com/media/44892e950bd60b06ba275a11c320dafe/href Let me know in the comments if you find these resources useful and as usual, you can find this code in [&#8230;]",
            "pubdate": "Tue, 18 Oct 2022 13:18:29 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "How Should We Detect and Treat the Outliers?": {
            "url": "https://towardsai.net/p/l/how-should-we-detect-and-treat-the-outliers",
            "description": "Last Updated on October 18, 2022 by Editorial Team Author(s): Gowtham S R Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. What are outliers? How do we need to detect outliers? How do we need to treat the outliers? Photo by\u00a0author Table of Contents: \u00b7 What are Outliers?\u00b7 Outlier Detection and Removal Techniques:\u00b7 Z Score-based method\u00b7 IQR technique\u00b7 Percentile Method What are Outliers? An outlier is that datapoint or observation which behaves very differently from the rest of the\u00a0data. If we are finding the average net worth of a group of people, and if we find Elon Musk in that group, then the complete analysis will go wrong because of just one outlier. This is a reason why outliers should be treated properly before building a machine learning\u00a0model. Simple ways to write Complex Patterns in Python in just 4mins. If we are building a linear regression model, which has an independent feature, \u2018Num of hours studied\u2019, and the dependent feature, \u2018marks scored\u2019, and if the data is distributed as shown below, then the model will perform\u00a0well. If we have 3 students who scored good marks even after studying for fewer hours, then the regression line shifts in order to fit the outlier points as shown below, resulting in giving bad results to the actual\u00a0data. Machine learning algorithms in which the calculation of weight is involved, like linear regression, logistic regression, Ada boost, and deep learning models, will get impacted by the outliers. Tree-based algorithms like Decision trees, Random Forest will get less impacted by outliers. How do I Verify the Assumptions of Linear Regression? In anomaly detection algorithms like insurance fraud detection or credit card fraud detection, we need to catch the outliers, in this kind of situation, the purpose is to catch the outliers. So we need to treat the outliers carefully, Trimming: Remove the outliers from the dataset before training a machine learning model. E.g., Remove the students from the dataset in the above\u00a0example. Capping: Keep a maximum or minimum threshold and give values to the data points accordingly. E.g., if we are working on the age feature, we can keep the threshold of 85 and assign the value of 85 to all the people with age greater than\u00a085. Discretization: This is the method in which numerical features are converted to discrete using bins. E.g., if the age 80\u201390 is considered as a single bin, then all the ages between 80 and 90 will be treated\u00a0equally. Outlier Detection and Removal Techniques: 1. Z Score-based method The main assumption in this technique is that the data should be normally distributed or close to normal distribution. If the data is normally distributed, the Empirical Rule says that 68.2% of the data points lie in between the 1st standard deviation, 95.4% of the data points lie in between the 2nd standard deviation, and 99.7% of the data points will be between the 3rd standard deviation. Data points that lie outside the 3rd standard deviation can be treated as outliers. As 99.7% of the data will lie within the 3 standard deviations, we can treat the rest of the data which lie outside the 3 standard deviations as outliers. Standardization or Z-Score Normalization is one of the feature scaling techniques, here, the transformation of features is done by subtracting from the mean and dividing by standard deviation. This is often called Z-score normalization. The resulting data will have the mean as 0 and the standard deviation as\u00a01. Standardization vs Normalization Let us look at the practical implementation of this technique. import pandas as pdimport numpy as npimport seaborn as snsimport matplotlib.pyplot as pltimport warningswarnings.filterwarnings(&#039;ignore&#039;) df = pd.read_csv(&#039;placement_dataset.csv&#039;) The dataset has 2 independent features cgpa and placement_exam_marks. plt.figure(figsize=(10,5)) plt.subplot(1,2,1)sns.distplot(df[&#039;cgpa&#039;]) plt.subplot(1,2,2)sns.distplot(df[&#039;placement_exam_marks&#039;]) The distribution of the data shows that the feature cgpa is normally distributed, and the other feature, placemet_exam_marks is\u00a0skewed. So, the feature cgpa qualifies for the Z Score-based method of the outlier detection technique. print(&#039;Mean value of CGPA {}&#039;.format(df[&#039;cgpa&#039;].mean()))print(&#039;Min value of CGPA {}&#039;.format(df[&#039;cgpa&#039;].min()))print(&#039;Max value of CGPA {}&#039;.format(df[&#039;cgpa&#039;].max()))print(&#039;Standard deviation value of CGPA {}&#039;.format(round(df[&#039;cgpa&#039;].std(),2))) # the boundary values are: print(&#039;Highest value of cgpa&#039;, round(df[&#039;cgpa&#039;].mean()+3*df[&#039;cgpa&#039;].std(),3))print(&#039;Lowest value of cgpa&#039;, round(df[&#039;cgpa&#039;].mean()-3*df[&#039;cgpa&#039;].std(),3)) Below are the 5 data points which are detected as outliers. This can also be achieved using the Z score formula, which is shown\u00a0below. Outlier Treatment: Trimming: In this method, we can remove all the data points that are outside the 3 standard deviations. Sometimes, if the dataset has a large number of outliers, then we lose a significant amount of\u00a0data. Capping: In this method, the outlier data points are capped with the highest or lowest values, as shown\u00a0below. Why Is Multicollinearity A Problem? 2. IQR technique This method is used when the distribution of the data is\u00a0skewed. The IQR describes the middle 50% of values when ordered from lowest to highest. To find the interquartile range (IQR), \u200bfirst, find the median (middle value) of the lower and upper half of the data. These values are quartile 1 (Q1) and quartile 3 (Q3). The IQR is the difference between Q3 and\u00a0Q1. IQR =\u00a0Q3-Q1 Minimum value = Q1\u20131.5\u00a0*IQR Maximum value = Q3+1.5*IQR The data points which are lesser than the minimum value and the data points which are greater than the maximum value are treated as outliers. Let us look at the practical implementation of this technique. plt.figure(figsize=(10,5)) plt.subplot(1,2,1)sns.distplot(df[&#039;cgpa&#039;]) plt.subplot(1,2,2)sns.distplot(df[&#039;placement_exam_marks&#039;]) The feature placement_exam_marks is skewed and qualifies for the IQR method of outlier detection. df[&#039;placement_exam_marks&#039;].skew()0.8356419499466834 #Finding the IQR Q1 = df[&#039;placement_exam_marks&#039;].quantile(0.25)Q3 = df[&#039;placement_exam_marks&#039;].quantile(0.75) IQR = Q3-Q1 upper_limit = Q3+1.5*IQRlower_limit = Q1-1.5*IQR print(&#039;lower limit: &#039;, lower_limit)print(&#039;upper limit: &#039;, upper_limit)print(&#039;IQR:&#039; , IQR) lower limit: -23.5upper limit: 84.5IQR: 27.0 The above 15 data points are detected as outliers. Trimming: In this method, we can remove all the data points that are outside the minimum and [&#8230;]",
            "pubdate": "Tue, 18 Oct 2022 13:18:27 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "Encoding Categorical Data- The Right Way": {
            "url": "https://towardsai.net/p/l/encoding-categorical-data-the-right-way",
            "description": "Last Updated on October 18, 2022 by Editorial Team Author(s): Gowtham S R Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Photo from Unsplash by Icons8\u00a0Team Table of Contents \u00b7 Types of Data \u2218 Continuous Data \u2218 Discrete Data \u2218 Nominal Data \u2218 Ordinal Data \u00b7 How to Encode Categorical data? \u2218 Ordinal Encoding \u2218 Nominal Encoding \u2218 OneHotEncoding using Pandas \u2218 Dummy Variable Trap \u2218 OneHotEncoding using Sklearn Types of\u00a0Data In statistics and machine learning, we classify data into one of two types namely\u200a\u2014\u200aNumerical and Categorical Numerical data is categorized into discrete and continuous data. Categorical data is divided into two types, nominal data, and ordinal\u00a0data. Image by the author explaining Types of\u00a0Data Continuous Data Continuous data is data that takes any number(it can include decimal values). It has an infinite number of probable values that can be selected within a given specific\u00a0range. Example: Weight and height of a person, temperature, age, distance. Image by\u00a0author Discrete Data Discrete data can take only discrete values(it can not have decimal values). Discrete information contains only a finite number of possible values. Those values cannot be subdivided meaningfully. Here, things can be counted in whole\u00a0numbers. Example: Number of people in a family, number of bank accounts a person can have, number of students in a classroom, number of goals scored in a football\u00a0match. Image by\u00a0author How Should We Detect and Treat the Outliers? Nominal Data Nominal data is defined as data that is used for naming or labeling variables without any quantitative value. It is sometimes called \u201cnamed\u201d\u00a0data. There is usually no intrinsic ordering to nominal data. For example, Gender is a nominal variable having 2 categories, but there is no specific way to order from highest to lowest and vice\u00a0versa. Examples: letters, symbols, words, gender, color,\u00a0etc. Image by\u00a0author Ordinal Data Ordinal data is a type of data that follows a natural order. It is a type of categorical data with an order. The variables in ordinal data are listed in an ordered\u00a0manner. Examples: Customer rating(Good, Average, Bad), Medal category in Olympics(Gold, Silver,\u00a0Bronze) Image by\u00a0author Simple ways to write Complex Patterns in Python in just 4mins. How to Encode Categorical data? Encoding categorical data is a process of converting categorical data into integer format so that the data can be provided to different models. Categorical data will be in the form of strings or object data types. But, machine learning or deep learning algorithms can work only on numbers. So, being machine learning engineers, it is our duty to convert categorical data to numeric\u00a0form. Ordinal Encoding We need to maintain the intrinsic order while converting ordinal data to numeric data. So, each category will be given numbers from 0 to a number of categories. If we have 3 categories in the data, such as &#039;bad&#039;, &#039;average&#039;, and &#039;good&#039;, then bad will be encoded as 0, average as 1, and good as 2. So that the order is maintained. When we train the machine learning model, it will learn the pattern with the intrinsic order giving better\u00a0results. We make use of OrdinalEncoder class from sklearn to encode the ordinal\u00a0data. Standardization vs Normalization Let us see how we can encode ordinal data practically. import pandas as pdimport numpy as np df = pd.read_csv(&#039;customer.csv&#039;) df.head() df[&#039;age&#039;].unique()array([30, 68, 70, 72, 16, 31, 18, 60, 65, 74, 98, 51, 57, 15, 75, 59, 22,19, 97, 32, 96, 53, 69, 48, 83, 73, 92, 89, 86, 34, 94, 45, 76, 39,23, 27, 77, 61, 64, 38, 25], dtype=int64) df[&#039;gender&#039;].unique()array([&#039;Female&#039;, &#039;Male&#039;], dtype=object) df[&#039;review&#039;].unique()array([&#039;Average&#039;, &#039;Poor&#039;, &#039;Good&#039;], dtype=object) df[&#039;education&#039;].unique()array([&#039;School&#039;, &#039;UG&#039;, &#039;PG&#039;], dtype=object) df[&#039;purchased&#039;].unique()array([&#039;No&#039;, &#039;Yes&#039;], dtype=object) \u2018age\u2019\u200a\u2014\u200anumerical data \u2018gender\u2019\u200a\u2014\u200anominal categorical data \u2018review\u2019\u200a\u2014\u200aordinal categorical data \u2018education\u2019\u200a\u2014\u200aordinal categorical data \u2018purchased\u2019\u200a\u2014\u200athe target\u00a0variable Let us separate ordinal data and learn how to encode\u00a0them. df = df.iloc[:,2:]df.head() X = df.iloc[:,0:2]y = df.iloc[:,-1] from sklearn.model_selection import train_test_splitX_train, X_test, y_train, y_test = train_test_split(X,y,test_size =0.2, random_state=1) from sklearn.preprocessing import OrdinalEncoder ordinal_encoder = OrdinalEncoder(categories=[[&#039;Poor&#039;,&#039;Average&#039;,&#039;Good&#039;],[&#039;School&#039;,&#039;UG&#039;,&#039;PG&#039;]]) ordinal_encoder.fit(X_train) X_train = ordinal_encoder.transform(X_train)X_test = ordinal_encoder.transform(X_test) In the above code, we can see that we are passing the categories in the order to the ordinalEncoder class, with poor being the lowest order and Good being the highest order in the case of feature\u00a0review. Similarly, in the case of the education column, school is the lowest order, and PG is in the highest\u00a0order. After transformation, we can observe the above result, which shows the first 5\u00a0rows. The first row had review = Average and education = UG, so it is transformed as\u00a0[1,1] The second row had review = Poor and education = PG, so it is transformed as\u00a0[0,2] Nominal Encoding Nominal data will not have intrinsic order, we make use of OneHotEncoder class from sklearn to encode the nominal\u00a0data. If we start encoding categories from 0,1,2 to all the categories, then the machine learning algorithm will give importance to 2 (more than 0 and 1), which will not be true as the data is nominal and will have no intrinsic order. So, this method will not work in the case of nominal\u00a0data. Here each of the categories will be transformed into a new column and will be given values of 0 or 1 depending on the occurrence of the respective category. So, the number of features will increase after the transformation. Let us see how we can encode nominal data practically. Let us take a titanic dataset with features \u2018Sex\u2019 and \u2018Embarked\u2019 (both are nominal features). import pandas as pdimport numpy as np df = pd.read_csv(&#039;titanic.csv&#039;) df.head() df[&#039;Sex&#039;].unique()array([&#039;male&#039;, &#039;female&#039;], dtype=object) df[&#039;Embarked&#039;].unique()array([&#039;S&#039;, &#039;C&#039;, &#039;Q&#039;], dtype=object) df[&#039;Survived&#039;].unique()array([0, 1], dtype=int64) OneHotEncoding using\u00a0Pandas pd.get_dummies(df,columns=[&#039;Sex&#039;,&#039;Embarked&#039;]) The below output shows how each of the categories is transformed into a column. The column \u2018Sex\u2019 has got transformed into \u2018Sex_female\u2019 and \u2018Sex_male\u2019 and the column \u2018Embarked\u2019 has got transformed into \u2018Embarked_C\u2019, \u2018Embarked_Q\u2019, and \u2018Embarked_S\u2019. These new attributes/columns created are called [&#8230;]",
            "pubdate": "Tue, 18 Oct 2022 13:04:23 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "How To Split The Data Effectively for Your Data Science Project": {
            "url": "https://towardsai.net/p/l/how-to-split-the-data-effectively-for-your-data-science-project",
            "description": "Last Updated on October 18, 2022 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Data is one of the most important resources for any data science project. But what good is abundant data if you can&#x2019;t use it effectively&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Oct 2022 12:18:56 +0000",
            "pubdate_parsed": [
                2022,
                10,
                18
            ],
            "email_sent": true
        },
        "Genetic Algorithm Optimization": {
            "url": "https://towardsai.net/p/l/genetic-algorithm-optimization",
            "description": "Last Updated on October 22, 2022 by Editorial Team Author(s): Chinmay Bhalerao Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A detailed explanation of the evolutionary and nature-inspired optimization algorithm Photo by Sangharsh Lohakare on\u00a0Unsplash \u201cThe environment selects those few mutations that enhance survival, resulting in a series of slow transformations of one lifeform into another, the origin of a new species.\u201d- CARL SAGAN, 1934\u20131996 Evolution The concept of natural selection and biological evolution changed the perspective of thinking about evolution theory. Evolution is always a slow and gradual process that takes many centuries to work. Millions of species present on earth today arose from a single original life form through a branching process called speciation. complex creatures evolve from more simplistic ancestors naturally over time. In a nutshell, as random genetic mutations occur within an organism\u2019s genetic code, the beneficial mutations are preserved because they aid survival\u200a\u2014\u200aa process known as \u201cnatural selection.\u201d Photo by Johannes Plenio on\u00a0Unsplash DNA changes with time with different mutations and a combination of random inheritance, which is a recombination of parental DNA and mutational behaviors. This is conveniently described using tools from probability theory and stochastic processes. \u201cEvolution is the aggregation of thousands of semi-random events and the natural pressure to reproduce or die\u201d-Darwinian evolution https://medium.com/media/232b8f2e71b1022f8628652aaa260398/href To understand evolution, there is a great example of the prey and predator system. Fox eats rabbits, and faster rabbits tend to save their lives, whereas slower one has more probability of getting caught. Given a population, Smarter and quicker individuals are less likely to be consumed by foxes. As a result, they can continue to reproduce, which is what rabbits do best. Some of the less intelligent and slower rabbits also make it by chance. As the remaining population begins to reproduce, a good combination of rabbit genetic material is produced. Foxes and rabbits evolve with time [image by author created by Dall.\u00a0E] some slow rabbits breed with fast rabbits, some fast rabbits breed with fast rabbits, And on top of that, nature throws in a wild hare every once in a while by mutating some of the rabbit&#039;s genetic material. Because more parents who were quicker and smarter survived the foxes, the resulting rabbits (on average) are faster and smarter than those in the original group. The good thing is that the foxes are also undergoing a similar procedure. Otherwise, the rabbits would develop into creatures that are too quick and intelligent for the foxes to\u00a0capture. Genetic Algorithm optimization GAs was first proposed by John Holland in the 1960s. GA incorporates methods proposed by and inspired by the natural selection process. As I mentioned in the above example, the fittest individual has more chance or probability to survive. The same in GA. From the pool of solutions, the one who has more fitness has more chance to survive. Let&#039;s start the actual understanding of the Genetic Algorithm. Let&#039;s understand basic terminologies. Genetic Algorithm terminologies Parent: The one from which offspring is produced. member of the current generation. Offspring: Also known as a child. offspring is a member of the next generation Population: Population is a set of all possible solutions or chromosomes exhibiting similar gene structure Fitness: Fitness is a number assigned to an individual representing a measure of goodness. More fitter, the more chance of survival and reproduction. Chromosome: Chromosome is a coded form of a possible set of solutions consisting of genes made of one of two or more versions of DNA sequence (alleles). Crossover: Crossover is the phenomenon where generally two parents produce two offspring by gene exchange. Mutation: Mutation is a random change of the value of a gene we flip a bit and change 0 to 1 and 1 to\u00a0zero. Generation: Generation is a successively created population. In Genetic Algorithms, it is also termed as \u201citerations\u201d. Outline of genetic algorithm The genetic algorithm starts with defining a proper problem statement and creating a set of initial possible populations of solutions. The population is randomly generated chromosomes. like the evolution procedure, the procedure of natural selection starts. During successive generations, chromosomes in the population are rated for their fitness or rated for their chance to become the solution. Now, based on the evaluation of their fitness value, the new set of Chromosomes forms using a selection operation followed by crossover and mutation. The basic flow of Genetic Algorithm procedure [Image by\u00a0Author] Selection The first important step in Genetic algorithm operations is selection. You might have a question here! what are we selecting? I will answer this question. The fittest solution or fittest offspring/Child is our aim. for that, obviously, we have to select a parent depending on its fitness. If we have population \u201cX\u201d, then selection creates an intermediate population of \u201c X\u2019 \u201d [X_hash] with the copies of chromosomes of X. More fitter chromosomes will have more copies of it\u00a0!!! After this, the selection mechanism starts. The selection operation is carried out in two ways\u00a0: Roulette wheel selection You know the word Roulette wheel from casino or gambling, right? It&#039;s a much similar concept. In gambling, we have wheels, and we predict numbers. That is, the dice will land on that predicted number or not! In the GA roulette wheel selection, the wheel is the same. just a stop point is introduced at a fixed point. The chromosome takes the value on the pie or roulette wheel exactly equal to the fitness it\u00a0has. Chromosomes and their fitness values [Image by\u00a0author] It is obvious that a more physically fit individual has a larger pie on the wheel and a higher chance of landing in front of the fixed point when the wheel is revolved. As a result, an individual likelihood of selection is directly correlated with [&#8230;]",
            "pubdate": "Sat, 22 Oct 2022 12:19:06 +0000",
            "pubdate_parsed": [
                2022,
                10,
                22
            ],
            "email_sent": true
        },
        "Why AI Fairness Is Important in Telecom Personalization": {
            "url": "https://towardsai.net/p/l/why-ai-fairness-is-important-in-telecom-personalization",
            "description": "Last Updated on October 22, 2022 by Editorial Team Author(s): Arslan Shahid Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Personalization is the name of the game in the telecom\u00a0industry Image from\u00a0Pexel For the past two years, I have been working in the personalization and contextual marketing department of one of the major mobile operators in Pakistan. For people who don\u2019t know personalization is designing products, recommendations, and ads for individuals based on their attributes and preferences. Telecommunications is an oligopoly market with little to no product differentiation. Mobile data, minutes, and SMS can be thought of as commodities. One way to add value for customers and businesses is to construct personalized products for groups or individuals. Personalization is achieved by using tools such as machine learning and statistical analysis. However, as I will explain in this post, if not checked for, personalization could have adverse effects on individuals and society at\u00a0large. What do you mean by \u2018AI Fairness\u2019? Contrary to what some people believe, AI or statistical models are not free from biases or making discriminatory predictions or recommendations. All models represent statistical approximations of the data based on a set of variables we, as modelers, think are predictive of the thing we are interested in. By choosing the attributes that the modeler thinks are predictive and measuring data that they think is appropriate, a modeler often makes a choice that reflects their beliefs. Furthermore, the data itself could reflect a historic privilege or discrimination being done against a group of\u00a0people. AI fairness is the study of how algorithms treat groups of people. Attempting to make them less predatory or discriminatory against a set of protected groups or set attributes like gender, ethnicity, country of origin, and illnesses. Provided that we believe that being part of a certain group does not or should not be a basis for an algorithm to predict or make a decision that results in an adverse outcome. For example, a credit scoring algorithm assigning a lower credit score to a black person when compared to a white person with \u2018similar\u2019 attributes is \u2018unfair\u2019. The quotation marks signify that this depends on the definitions of similar and fairness. How is group fairness defined mathematically? Although there are plenty of ways to define fairness as a mathematical construct, below are a few of the most common, taken from CS 294: Fairness in Machine Learning, UC Berkeley, Fall\u00a02017 Fairness in Classification: Demographic Parity: Image from fairmlclass Simply explained, demographic parity means that the probability a certain classification algorithm predicts the true(C=1) class is the same when an individual is from group A=0 or group A=1. Where A could represent any arbitrary type of protected group, such as\u00a0gender. Accuracy Parity: Image from fairmlclass Intuitively, a classifier is accuracy parity-wise fair when it assigns all classes (represented by Y) with the same probability when a person has attribute a=0 or a=1. For example, the university admissions algorithm accepts, rejects, or waitlists, each with the same probability for a male or\u00a0female. Precision Parity Image from fairmlclass A classifier is precision-parity fair when the probability that an individual is from the true class, given that the classifier predicted that they are from the true class; is the same for an individual with attribute A=0 or A=1. Take the example of an algorithm that decides to predict a rare disease. Doctors are only allowed to give medicine to patients predicted to have the disease. If we want the algorithm to be precision-parity-wise fair, the proportion of people who had the disease and were predicted to have it should be the same across all protected groups. There are plenty of novel and use-case-specific definitions of fairness for classification problems. The above mention definitions include some of the most well-known and actively\u00a0used. Fairness in Regression: Statistical Parity: image from Microsoft Research For a regression problem, the modeler is trying to minimize the expected loss between the distribution of observed values (Y) and the distribution of predicted values (f(x)). For statistical parity to hold we minimize the loss subject to the constraint that the CDF conditioned on protected attribute A does not deviate from the unconditional CDF by a threshold epsilon. Bounded Group\u00a0Loss: Image from Microsoft Research Bounded group loss means that for every protected attribute a, the loss function is below a certain threshold. For example, we could require a regression to predict house prices have at least an RMSE of $2500 for all protected groups like\u00a0ethnicity. What do you mean by personalization in\u00a0Telecom? Considering GSM services are commodities, product differentiation is achieved in telecom using two broad categories: Price differentiation: You give services to customers at a different price point than immediate competitors. If your services are cheaper &#38; every network has the same service quality, you are likely to gain market\u00a0share. Network differentiation: A segment of customers will always be willing to pay a higher price for better quality. In telecom, quality is solely derived from spectrum allocation and network presence in the area. For example, each telecom operator in Pakistan has marked its territory where they provide the best services. Usually, it makes the most sense to buy services from the operator with the highest coverage in the\u00a0area. Personalization can help Telecos achieve product differentiation either through price or network on an individual level. For example, you can bundle together different GSM products like you can give a customer who is more inclined to use data but doesn\u2019t use call or SMS as much an \u2018averaged\u2019 bundled price where their data is subsidized but you charge more for\u00a0voice. How is personalization achieved? The following are some of the techniques and methods used in the telecom industry to enable personalization (not exhaustive). Dynamic pricing: GSM services [&#8230;]",
            "pubdate": "Sat, 22 Oct 2022 11:33:34 +0000",
            "pubdate_parsed": [
                2022,
                10,
                22
            ],
            "email_sent": true
        },
        "Medium API: Get Posts Using Python": {
            "url": "https://towardsai.net/p/l/medium-api-get-posts-using-python",
            "description": "Last Updated on October 22, 2022 by Editorial Team Author(s): Nishu Jain Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. User-written articles, publication articles, and top feeds Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 22 Oct 2022 11:33:31 +0000",
            "pubdate_parsed": [
                2022,
                10,
                22
            ],
            "email_sent": true
        },
        "Few-shot Financial Sentiment ClassificationDoes It Work?": {
            "url": "https://towardsai.net/p/l/few-shot-financial-sentiment-classification%e2%80%8a-%e2%80%8adoes-it-work",
            "description": "Last Updated on October 22, 2022 by Editorial Team Author(s): Neo Yi Peng Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. SetFit for Financial Sentiment Analysis Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 22 Oct 2022 07:03:52 +0000",
            "pubdate_parsed": [
                2022,
                10,
                22
            ],
            "email_sent": true
        },
        "AI Image Editing from Text! Imagic Explained": {
            "url": "https://towardsai.net/p/l/ai-image-editing-from-text-imagic-explained",
            "description": "Last Updated on October 23, 2022 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Imagic: Manipulate images using pre-trained image generator models! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 23 Oct 2022 12:14:42 +0000",
            "pubdate_parsed": [
                2022,
                10,
                23
            ],
            "email_sent": true
        },
        "Top 5 Machine Learning Industries in 2022": {
            "url": "https://towardsai.net/p/l/top-5-machine-learning-industries-in-2022",
            "description": "Last Updated on October 24, 2022 by Editorial Team Author(s): Mostafa Ibrahim Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Machine learning is rapidly expanding into a lot of industries and sectors! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 24 Oct 2022 12:08:59 +0000",
            "pubdate_parsed": [
                2022,
                10,
                24
            ],
            "email_sent": true
        },
        "10 AI Websites That Will Excite You to The Core!": {
            "url": "https://towardsai.net/p/l/10-ai-websites-that-will-excite-you-to-the-core",
            "description": "Last Updated on October 25, 2022 by Editorial Team Author(s): Chinmay Bhalerao Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. interesting artificial intelligence-based websites and their\u00a0working Image created by the author on DALL\u00b7E\u00a02 1. VERSE BY\u00a0VERSE Are you struggling to write a nice poem for your girlfriend/boyfriend or your loved ones? Don&#039;t worry\u00a0!! Verse by Verse will completely help you to compose poems for yourself. Screen recording of Verse by Verse by\u00a0author With the help of Verse by Verse, you may create a poem using ideas from some of America\u2019s most well-known poets, including Dickinson, Whitman, Poe, Wheatley, Longfellow, and others. They trained AI systems to function as your muse while you write a poem of your own, providing recommendations in the manner of each individual poet to make this possible. Here is the link! enjoy and stretch your creativity with the help of legendary poets! Verse by Verse 2. DALL\u00b7E\u00a02 If there is a discussion about amazing websites in AI, then how can anyone forget DALL\u00b7E 2? Do you want to make a portrait or drawing or create an image of your complicated thoughts? But is it hard for you to draw it on paper? What if you can just describe your thoughts in words/texts and create images/drawings? Don&#039;t worry, DALL\u00b7E 2 will help you here in the same\u00a0fashion! Wired imagination is given by the author in the form of text [Screenshot by\u00a0author] Wired imagination is given by the author in the form of text [Screenshot by\u00a0author] Wired imagination is given by the author in the form of text [Screenshot by\u00a0author] According to openAI blog post, OpenAI\u2019s DALL\u00b7E 2 is a 12-billion parameter version of GPT-3 trained to generate images from text descriptions, using a dataset of text\u2013image pairs. We\u2019ve found that it has a diverse set of capabilities, including creating anthropomorphized versions of animals and objects, combining unrelated concepts in plausible ways, rendering text, and applying transformations to existing\u00a0images. Previously it had a waitlist. After registering, you have to wait for your turn, but recently it is free from the waitlist, and you can directly log in and create images from texts. You will get 50 credit points after registration and 15 points for each month. Each search will be equal to 1\u00a0point. DALL\u00b7E 2 3. Nightcafe Image created by the author on nightcafe using B/W fashion giving input \u201cold and veteran\u00a0people\u201d It works on a stable diffusion model, which will be released in 2022. Although it can be used for various tasks, including inpainting, outpainting, and creating image-to-image translations directed by text prompts, its primary usage is to generate detailed visuals conditioned on text descriptions. How does it\u00a0work? According to the stability.ai blog, The model itself builds upon the work of the team at CompVis and Runway in their widely used latent diffusion model combined with insights from the conditional diffusion models by our lead generative AI developer Katherine Crowson, Dall-E 2 by Open AI, Imagen by Google Brain and many others. We are delighted that AI media generation is a cooperative field and hope it can continue this way to bring the gift of creativity to\u00a0all. Create Something Amazing 4. Let\u2019s\u00a0Enhance Want to make your distorted and blurry photos beautiful? you can use let\u2019s enhance! It makes low-res images into clear and sharp pics to be proud of, using cutting-edge image processing algorithms. Let&#039;s Enhance &#8211; Image Quality Online App &#38; Free Photo Enlarger 5. QuillBot\u00a0AI If you are unable to phrase your words and struggling to write, you can use the Paraphrasing tool of QuillBot\u00a0AI. screenshot by the author of Quillbot\u2019s paraphrasing tool the difference between other rephrasing tools is it uses state-of-the-art AI to predict, phrase, and rewrite your thoughts. It also gives us many options for your texts to a phrase, including synonyms analysis, grammar check, etc. It is very useful for new writers who want to write but don&#039;t know what perfect phrasing can\u00a0be! https://quillbot.com/ 6. Talk to\u00a0books Talk to the book is one of the most amazing websites that I have found! you can talk to a book like in the same way as we talk to humans. you can ask anything on the dialog box, and it will return the extracted semantic pieces of answers that fit best to your question. screen recording by the\u00a0author How does it\u00a0work? As research google blog says, the approach was to use billions of lines of dialogue to teach an AI how real human conversations flow. Once the AI has learned from that data, it is then able to predict how likely one statement would follow another as a response. In these demos, the AI is simply considering what you type to be an opening statement and looking across a pool of many possible responses to find the ones that would most likely\u00a0follow. Talk to Books 7. Teachable Machine Is model training quite expensive right? AI-ML-DL models require training which must have been faster and less expensive. what if we get an online website that will assist you with the training image, sound &#38; pose data? that&#039;s actually\u00a0cool! Teachable Machine 8. The Person Does Not\u00a0Exist It is so cool that AI can generate images of people that are not alive and have never existed in the world. It uses GAN ( Generative Adversarial Network) generated real \u201cFAKE PEOPLE\u201d. check the site and refresh the page. It generates a fake image of no-existing people in 5\u00a0seconds. This Person Does Not Exist 9.Resemble.ai Resemble\u2019s AI voice generator lets you create human-like voiceovers in seconds. EMOTIONS-Add an infinite amount of emotions to your voice without any new data. Happy, sad, angry, all preloaded, out of the box. SPEECH-TO-SPEECH Transform your voice into the target voice with real-time speech-to-speech. Granular control over [&#8230;]",
            "pubdate": "Tue, 25 Oct 2022 12:18:23 +0000",
            "pubdate_parsed": [
                2022,
                10,
                25
            ],
            "email_sent": true
        },
        "How to Tell if Properties are Under/Overvalued like a Data Scientist": {
            "url": "https://towardsai.net/p/l/how-to-tell-if-properties-are-under-overvalued-like-a-data-scientist",
            "description": "Last Updated on October 26, 2022 by Editorial Team Author(s): Diego Unzueta Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. I made a Bot that Scans the Web for the Best Property Deals Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 27 Oct 2022 00:08:23 +0000",
            "pubdate_parsed": [
                2022,
                10,
                27
            ],
            "email_sent": true
        },
        "Yes, We Need Statistical Significance Testing": {
            "url": "https://towardsai.net/p/l/yes-we-need-statistical-significance-testing",
            "description": "Last Updated on October 27, 2022 by Editorial Team Author(s): Benjamin Marie Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A rule of thumb may yield correct results but can&#x2019;t be scientifically credible Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 27 Oct 2022 12:13:17 +0000",
            "pubdate_parsed": [
                2022,
                10,
                27
            ],
            "email_sent": true
        },
        "Non Max Suppression (NMS) in PyTorch": {
            "url": "https://towardsai.net/p/l/non-max-suppression-nms-in-pytorch",
            "description": "Last Updated on October 31, 2022 by Editorial Team Author(s): Francesco Zuppichini Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Implementing non max suppression in PyTorch Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 31 Oct 2022 12:28:39 +0000",
            "pubdate_parsed": [
                2022,
                10,
                31
            ],
            "email_sent": true
        },
        "10 AI Websites That Will Excite You to The Core! Part:2": {
            "url": "https://towardsai.net/p/l/10-ai-websites-that-will-excite-you-to-the-core-part2",
            "description": "Last Updated on November 1, 2022 by Editorial Team Author(s): Chinmay Bhalerao Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Interesting artificial intelligence-based websites and their\u00a0working Image created by the author on DALL\u00b7E\u00a02 Before diving into actual websites, there is PART 1 of this series. You can go through it\u00a0also. 10 AI Websites That Will Excite You to The Core! 1] OpenAI playground What if a website can write code for you? a blog for you? resignation letter for you? love letter for your girlfriend/boyfriend or loved ones? Yes!!! all things are possible by OpenAI playground! Almost any activity that includes understanding or producing natural language or code can be used with the OpenAI API. We provide a range of models with varying degrees of power appropriate for various activities, as well as the option to fine-tune your own unique models. Everything from content creation to semantic search and classification may be done using these\u00a0models. OpenAI API Model: based on GPT-3 models called Davinci, Curie, Babbage, and Ada. You can choose any of the above according to your use\u00a0case. Asking to write resignation letter [Image by\u00a0author] Asking to write code [Image by\u00a0author] 2]Deepfakes web Video by deepfakes web Elon Musk or Leonardo DiCaprio\u00a0??? interestingly, both!!!!! what are deepfakes? Deepfakes are synthetic media in which a person in an existing image or video is replaced with someone else\u2019s likeness. The term \u201cdeepfakes\u201d is a combination of \u201cdeep learning\u201d and \u201cfake\u201d. Deepfakes use potent machine learning and artificial intelligence techniques to edit or synthesize visual and audio information that can more readily fool, even though the act of producing fake content is not\u00a0new. Make Your Own Deepfakes [Online App] 3] inferkit InferKit Using a cutting-edge neural network, the text generation tool from InferKit reads the text that you supply and generates what it believes will happen next. It can produce any amount of text about essentially any topic and is customizable. Who is this\u00a0for? Creative and fun uses of the network include writing stories or poetry. Other use cases might be marketing or auto-completion. Asking to write an essay on the topic \u2018my favorite cricketer\u2019 4]tensorflow playground Live training for classification problem TensorFlow playground is a website where you can visualize the training process with live changes in outputs with the help of numbers and actual diagrams. You can experiment with many things like changing activation, epochs, regularization, features, hidden layers, and many\u00a0more\u2026 The deep playground is an interactive visualization of neural networks written in TypeScript using d3.js. they use GitHub issues for tracking new requests and bugs. You can also contribute to their repository. Tensorflow &#8211; Neural Network Playground 5]Lalal.ai The stem separation problem has also been solved brilliantly by LALAL.AI if you need to preserve the instrumental backing track of a song but take out the vocals. One of the most powerful tools in\u00a0AI. It makes use of a neural network known as Cassiopeia, which was developed over numerous iterations using 20TB of training data. It can extract vocals, drums, guitar, piano, bass, synthesizer, and general accompaniment and is really easy to\u00a0use. Vocal Remover &#124; Isolate Voice &#38; Instrumental Online &#124; LALAL.AI The outcomes are remarkable and merit a try for yourself. LALAL.AI, thankfully, lets you input 10 minutes of music and provides a detailed preview of the extractions. Although you won\u2019t be able to download the extracted stems, it\u2019s still worth subscribing to the service if the results are good enough for your needs. You do not require a subscription, in contrast to other AI technologies. Instead, depending on your preference, LALAL.AI offers one-time packages for 90 or 300 minutes of extraction. So stretch your music senses to make your favorite music\u00a0piece! 6] Replika.com Feeling alone? want to chat with anyone? or a replica of you who thinks like you? visit this\u00a0website. An AI companion who is eager to learn and would love to see the world through your eyes. Replika is always ready to chat when you need an empathetic friend. Even though talking to Replika feels like talking to a human being, rest assured\u200a\u2014\u200ait\u2019s 100% artificial intelligence. Your Replika is unique to you and wants to know what your world is\u00a0like. creating my AI friend [Video by\u00a0author] My AI friend [Video by\u00a0author] Replika combines a sophisticated neural network machine learning model and scripted dialogue content. It has been trained on a large dataset to generate its own unique responses. Replika 7] Quick,\u00a0draw! Quick, Draw! is an online game developed by Google that challenges players to draw a picture of an object or idea and then uses a neural network artificial intelligence to guess what the drawings represent. The AI learns from each drawing, improving its ability to guess correctly in the future. Quick Draw is a new social space lottery game with drawings every five minutes that display winning numbers on monitors in-store. For a minimum of $1, players choose how many numbers (spots) they\u2019d like to play, which determines a player\u2019s odds and potential prizes. Quick, Draw! Video by\u00a0author 8] Hotpot.ai AI Art\u200a\u2014\u200ared-faced ball with blue eyes and blonde hair and two candle\u00a0sticks Hotpot uses AI and user-friendly tools to assist creators. Many people, especially those in developing countries, lack access to professional graphics, images, and text. This can be altered with more intelligent software. Our goal is to make video production and graphic design 10x faster and more accessible. their objective for professional designers is to augment the creative process by automating repetitive chores. The objective is to make design and image creation as simple as texting a friend for non-designers. text-to-image AI empowers anyone to create attractive paintings, illustrations, and images. Describe what you want, and watch Hotpot bring it to\u00a0life. Hotpot.ai You can create your own images [&#8230;]",
            "pubdate": "Wed, 02 Nov 2022 00:03:25 +0000",
            "pubdate_parsed": [
                2022,
                11,
                2
            ],
            "email_sent": true
        },
        "5 Types of ML Accelerators": {
            "url": "https://towardsai.net/p/l/5-types-of-ml-accelerators",
            "description": "Last Updated on November 2, 2022 by Editorial Team Author(s): Luhui Hu Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Comprehensive overview of machine learning accelerators for training and\u00a0serving The past decade has been the era of deep learning. We are thrilled with unstopping milestones from AlphaGo to DELL-E 2 and more. And we cannot count how many AI-powered things have happened in our daily lives, including Alexa devices, Ads recommendations, warehouse robots, self-driving cars, and\u00a0more. Photo by Joshua Woroniecki on\u00a0Unsplash Recent years have seen exponential growth in the scale of deep learning models. It is not news that Wu Dao 2.0 model contains 1.75 trillion parameters, and it takes about 25 days to train GPT-3 on 240 ml.p4d.24xlarge instances of the SageMaker training platform. But it becomes increasingly challenging as deep learning training and serving evolve. Scalability and efficiency are two major challenges for training and serving due to the growth of deep learning\u00a0models. Are deep learning systems stuck in a\u00a0rut? No! I introduced distributed parallel training for scaling out training in my earlier two articles: model parallelism and distributed parallel training. I shared ML compilers for accelerating training and\u00a0serving. Are these all solutions for the umbrella of deep learning? No! Here I\u2019ll summarize five primary types of ML accelerators or accelerating areas. Understand ML Lifecycle in AI Engineering Before fully covering ML accelerators, let\u2019s first visit the ML lifecycle. ML lifecycle is a lifecycle of data and models. Data is food for ML and can determine model quality. Every area in the lifecycle is full of opportunities for acceleration. MLOps can automate the process of ML model deployment and serving. But it is limited to the horizontal process of AI workflow and cannot improve training and serving fundamentally due to the nature of operations. AI engineering, far beyond MLOps, can holistically (both horizontally and vertically) engineer the process of ML workflow and the architecture of training and serving. Furthermore, it can accelerate serving and training through effective orchestration for the entire ML lifecycle. Based on the holistic ML lifecycle with AI engineering, there are five primary types of ML accelerators (or accelerating areas): hardware accelerators, AI computing platforms, AI frameworks, ML compilers, and cloud services. Please see their relationship diagram\u00a0below. Training and Serving Accelerators Relationship (by the\u00a0author) We can see hardware accelerators and AI frameworks are the mainstream of acceleration. But recently, ML compilers, AI computing platforms, and ML cloud services have become increasingly important. Let\u2019s take a closer look at them\u00a0below. 1. AI Frameworks We cannot skip choosing the right AI framework when talking about accelerating ML training and serving. Sadly, there is no perfect or best AI framework for all use cases. Three AI frameworks widely used in research and production are TensorFlow, PyTorch, and JAX. They lead from different perspectives, such as ease of use, production maturity, and scalability. TensorFlow: TensorFlow is the flagship AI framework. TensorFlow has dominated the deep learning open-source community since the beginning. TensorFlow Serving is a well-defined, mature platform. TensorFlow.js and TensorFlow Lite are also ripe for the web and\u00a0IoT. But due to the limitations of deep learning early exploration, TensorFlow 1.x was all about building static graphs in a very non-Pythonic way. This became a barrier for instant evaluation using the \u201ceager\u201d mode, which allowed PyTorch to ramp up quickly in research. TensorFlow 2.x tried to catch up, but unfortunately, upgrading from TensorFlow 1.x to 2.x has to be\u00a0brutal. TensorFlow also introduced Keras for easier use from the high level and XLA (Accelerated Linear Algebra) optimizing compiler to improve low-level speed. PyTorch: With its eager mode and Pythonic approach, PyTorch is a significant force in today\u2019s deep learning world, from research to production. In addition to TorchServe, PyTorch integrates with framework-agnostic platforms such as Kubeflow. Also, PyTorch\u2019s popularity was tied to the success of Hugging Face\u2019s Transformers library in the first\u00a0place. JAX: Based on device-accelerated NumPy and JIT (Just-In-Time), Google rolled out JAX. It is a more native framework for deep learning rapidly gaining traction in research, as PyTorch did a few years ago. But it\u2019s not an \u201cofficial\u201d Google product yet, as Google\u00a0claims. 2. Hardware Accelerators We can have a lengthy article on hardware accelerators. Undoubtedly, NVIDIA\u2019s GPUs ignited to speed up DL training, though it was initially intended for video\u00a0cards. The popularity of graphics cards for neural network training exploded after the advent of general-purpose GPUs. These GP-GPUs could execute arbitrary code, not just rendering subroutines. NVIDIA\u2019s CUDA programming language provided a way to write this arbitrary code in a C-like language. With their relatively convenient programming model, massive parallelism, and high memory bandwidth, GP-GPUs now o\ufb00er an ideal platform for neural network programming. Today, NVIDIA supports a range of GPUs from desktop to mobile, workstations, mobile workstations, consoles, and data\u00a0centers. With the success of NVIDIA\u2019s GPUs, there is no lack of successors along the way, such as AMD\u2019s GPUs, Google\u2019s TPU ASIC,\u00a0etc. 3. AI Computing Platforms As described above, the speed of ML training and serving significantly depends on hardware (e.g., GPU and TPU). These drivers (that is, AI computing platforms) become critical for performance. There are two well-known ones: CUDA and\u00a0OpenCL. CUDA: CUDA (Compute Unified Device Architecture) is a parallel programming paradigm released in 2007 by NVIDIA. It is designed for graphic processors and a vast array of general-purpose applications for GPUs. CUDA is a proprietary API only supporting NVIDIA\u2019s GPUs for Tesla Architecture. The CUDA-supported graphics cards include the GeForce 8 series, Tesla and\u00a0Quadro. OpenCL: OpenCL (Open Computing Language) was initially developed by Apple and is maintained by the Khronos group for heterogeneous computing, including CPUs, GPUs, DSPs, and other types of processors. This portable language is adaptable enough to allow each hardware platform to achieve high performance, [&#8230;]",
            "pubdate": "Wed, 02 Nov 2022 13:23:51 +0000",
            "pubdate_parsed": [
                2022,
                11,
                2
            ],
            "email_sent": true
        },
        "Jupyter Extensions to Improve your Data Workflow": {
            "url": "https://towardsai.net/p/l/jupyter-extensions-to-improve-your-data-workflow",
            "description": "Last Updated on November 2, 2022 by Editorial Team Author(s): Cornellius Yudha Wijaya Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Improve your workflow with these extensions Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 03 Nov 2022 00:08:33 +0000",
            "pubdate_parsed": [
                2022,
                11,
                3
            ],
            "email_sent": true
        },
        "Dont Frustrate Your Data Scientists (If You Want Them to Stay)": {
            "url": "https://towardsai.net/p/opinion/dont-frustrate-your-data-scientists-if-you-want-them-to-stay",
            "description": "Last Updated on November 3, 2022 by Editorial Team Author(s): Stu Bailey As I speak with data scientists, especially those working in Global 1000 companies, many express concerns about their situation. \u00a0 In some sense, they\u2019re victims of their own success:\u00a0 Data scientists are producing models that are making substantial contributions to the business, and thus more and more models are being used in production applications.\u00a0 But as a result, data scientists face several challenges.\u00a0 In my conversations, the following issues come up the most frequently: -Their organization lacks visibility to the business contributions being made by the models they produce -They\u2019re spending more and more time dealing with operational issues for their models in production The causes of both issues are very consistent across most organizations, and as such, lend themselves to straightforward solutions.\u00a0 This is good news for both data scientists and the organizations that they work for \u2013 provided that organizations act, and do so with some urgency. \u201cYou\u2019re Model is Broken \u2013 Let\u2019s Have a Meeting!\u201d Once developed and deployed into production, AI models can be very sensitive to a host of conditions that can compromise their effectiveness, reduce their value and increase their associated risks.\u00a0 Some of these items, such as data drift, relate directly to the work of the data scientist and require their expertise to address.\u00a0 But there are many other items that can impact models in production that have little to do with data science.\u00a0 For example, a problem with a production data pipeline can cause model outputs to deviate from accepted limits, or even produce erroneous inferences.\u00a0 A problem with the production IT infrastructure in which the model executes can cause performance issues.\u00a0 In many cases, there may be no meaningful role for the data scientist in addressing the problem.\u00a0 But that doesn\u2019t spare them from becoming involved. In many organizations, the response to a problem with an AI-driven application is to pull together a meeting with representatives from the data team, IT team, DevOps team, compliance team \u2013 as well as data science \u2013 in the hope of quickly identifying and addressing the root cause.\u00a0 These meetings often conjure the story of the blind men trying to describe an elephant:\u00a0 Each can describe the part of the elephant that they hold, but no one can describe the whole beast.\u00a0 As a result, a lot of time can be wasted \u2013 and value lost \u2013 as the group tries to assemble a complete picture of the problem and determine a fix. I\u2019ve yet to encounter a data scientist who isn\u2019t committed to making sure that their model is operating effectively and within its thresholds.\u00a0 What they don\u2019t appreciate is being called into situations in which the problems ultimately had nothing to do with the model.\u00a0 They\u2019re generally fine to play a role in monitoring their models that have reached production, but they don\u2019t want to spend their time chasing issues that they have no role in fixing. \u201cMy Models are Making Big Contributions \u2013 Believe Me\u201d Organizations have been pouring millions into AI initiatives in pursuit of big returns, and for the most mature organizations their investments are generating significant returns.\u00a0 But many organizations struggle to quantify the value that their initiatives are contributing. This is increasingly important as budgets tighten and there are more AI projects competing for funds.\u00a0 This directly impacts data scientists, who want their contributions to be recognized and for appropriate rewards to flow to them and their projects.\u00a0 Of course, a lack of visibility to the contributions of AI models is not just an issue for data scientists:\u00a0 The inability to accurately assess business contributions imperils all enterprise AI initiatives. ModelOps to the Rescue ModelOps is a core capability that enables organizations to govern and scale their AI initiatives.\u00a0 An effective ModelOps capability enables an organization to standardize and automate the operational processes for all models in production, but without restricting data scientists or any other team from using the most appropriate tooling and infrastructure for each use case.\u00a0 It also provides the enterprise \u2013 senior executives, IT staff, data teams, compliance teams, business teams, and of course data scientists \u2013 with business metrics that show the contributions, costs, and ROI of each production model. The most effective enterprise ModelOps capabilities are built around a platform that is independent of any data science tool, data system or execution infrastructure, but rather integrates with whatever tooling and systems are used across the enterprise, including enterprise systems for security and access management, ticketing, risk management, compliance, etc.\u00a0 The ModelOps platform maintains an evergreen database of all models in production, regardless of origin or execution environment, along with all artifacts including algorithms, training data, approvals and the like.\u00a0 It includes active monitors that continuously checks the full gamut of statistical, ethical, performance, security, business and compliance KPIs, and routes issues to those responsible and tracks resolution \u2013 eliminating the need for \u201chunting trips\u201d to find the root cause of problems and freeing data scientists, and everyone, to focus their time on their core responsibilities.\u00a0 A mature ModelOps platform also integrates with business systems to enable automated generation of model business metrics and ROI. For those organizations experiencing frustration with the demands of managing models in production and want to further scale their AI initiatives &#8211; and retain the best data scientists \u2013 there\u2019s an answer:\u00a0 Implement ModelOps today. Bio: Stu co-founded\u00a0ModelOp and serves as Chief Enterprise AI Architect. Stu\u2019s background as a technologist and entrepreneur, providing critical data-intensive infrastructure to the world\u2019s largest enterprises, gives him a unique perspective on how to help large, diversified enterprises become AI and Model-Driven. As the technical lead for the National Center for Data Mining from 1994-2000, Stu played key roles in the development of high-performance computing and distributed machine learning platforms, including the development of the Predictive Model Markup Language (PMML). In 2000 he founded the category defining and market leader Infoblox serving as Chief Technology Officer and Chief Scientist while [&#8230;]",
            "pubdate": "Fri, 04 Nov 2022 00:00:29 +0000",
            "pubdate_parsed": [
                2022,
                11,
                4
            ],
            "email_sent": true
        },
        "Deal With an Imbalanced Dataset With TensorFlow, LightGBM, and CatBoost": {
            "url": "https://towardsai.net/p/l/deal-with-an-imbalanced-dataset-with-tensorflow-lightgbm-and-catboost",
            "description": "Last Updated on November 8, 2022 by Editorial Team Author(s): Konstantin Pluzhnikov Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Add new instruments to your toolbox when customizing your\u00a0models Source: Photo by Brett Jordan on flickr.com You have an imbalanced dataset; you want to reduce the count of false negatives (FN) or even false positives (FP). Maybe you like custom things and want to practice adding changes to standard models. If so, this article is for\u00a0you. One way is to customize your model\u2019s loss function with a particular coefficient. This article aims to show customization approaches in TensorFlow, LightGBM, and Catboost. If you want to get a feeling of the whole idea with related math and see the same concept for XGBoost, look at my article on\u00a0Medium. Also, I aim to provide a way to embed a custom hyperparameter to a custom function, which opens the door to an advanced tuning of new parameters as ordinary\u00a0ones. I use the Titanic dataset for demonstration because it is approachable and imbalanced. Basic models, as well as customized models, are in my GitHub repository. LightGBM It is one of the most effective gradient-boosting algorithms developed by Microsoft. It outperforms XGBoost in speed and is comparable in accuracy. For more details, check this article by BexBoost. LightGBM is a younger brother of XGBoost, so it has all its achievements. https://medium.com/media/2316f962481510b88b0327b3907a27cf/href I have used embedded user-defined functions to introduce beta as a core part of the logloss function (it is no more an external hyperparameter). You can see that the outer function presents betato the internal, which calculates derivatives. The same applies to a custom metric. Now you can tune it with other hyperparameters with special packages like the Optuna\u00a0library. beta should be &#60; 1.0 to penalize FN. To punish FP, it should be more than 1.0. For details, please see my article on\u00a0Medium. There are some differences compared to the XGBoost custom loss function. Firstly, LightGBM puts y_predin logit_raw format, and the logit transformation is needed. Secondly, LightGBM custom metric outputs three results (the name of the custom metric (e.g., \u201clogreg_error\u201d), the value of metrics, and the boolean parameter that should be set Falsebecause our goal is to reduce custom metric\u00a0value). There is one more interesting detail in a logit transformation of predt\u00a0; I have used np.where function to ensure stability and avoid overflow when dealing with negatives logit_raw. It is mentioned as the best practice in different examples on Stackoverflow and models\u2019 documentation. Let\u2019s plot confusion matrices of the results of a standard LightGBM model and the one with custom\u00a0loss: (Left) Basic LightGBM model &#124; (Right) Tailored LightGBM model with beta = 0.4, Source: Images by\u00a0author The custom loss with beta&#60; 1 led to the growth of FPs and TPs; to the depletion of FN and\u00a0TN. CatBoost The full name is Categorical boosting, developed by Yandex. It has a massive advantage over other algorithms as you do not need to encode categorical features of your dataset; you list them in the model, and it deals with them on its own. Dmytro Iakubovskyi uses it broadly in his analysis of the different datasets (IMDB, wine, beer, and many more tables with statistics). CatBoost inherits the most perks of XGBoost and LightGBM. https://medium.com/media/bfc5f9029a5bc8d53b94d52855484f29/href You can see the difference between Catboost (using object-oriented programming) and LightGBM (a standard user-defined function) realizations. I take code for the CatBoost class from the official documentation. I only add the beta to the initialization of the class. You can write the code for these functions in any form you like (OOP or UDF). The choice is\u00a0yours! Plotting the\u00a0results: (Left) Basic CatBoost model &#124; (Right) Tailored CatBoost model with beta = 0.4, Source: Images by\u00a0author The logic of the results is the same as for a LightGBM\u00a0model. TensorFlow It is a well-known and super powerful family of algorithms by Google. Setting up a custom loss here is a kind of different story. You do not need to write down derivatives and a custom metric explicitly; there is no `beta` no more ( betais dead, long live to pos_weight!). TF has a suitable function, tf.nn.weighted_cross_entropy_with_logitswhich makes things much more manageable. https://medium.com/media/65e71e527f0b1945eebf7952c58dcaeb/href pos_weight should be &#62; 1.0 to penalize FN, and &#60; 1.0 to punish FP. It is the opposite situation compared to beta. pos_weight is a coefficient that multiplies FN part of logloss while beta is a factor of FP\u00a0part. Plotting the\u00a0results: (Left) Basic TensorFlow model &#124; (Right) Tailored TensorFlow model with pos_weight = 3.5, Source: Images by\u00a0author My custom model showed rather bad performance while the TF standard model has done great; I hope you excuse me for the poor results because the main goal here is demonstration. Conclusion Overall results are comparable for all models. The trade-off between FN and FP is also in place. But if reducing FN is your goal, these custom losses are at your disposal. Advantages Easy and fast to apply (use four user-defined functions and beta, and that\u2019s\u00a0it). There is no need to perform manipulation with underlying data before modeling (if a dataset is not highly imbalanced) It may be applied as a part of data exploration or as a part of model stacking. We may add it to the most popular machine-learning packages. With embedded beta or pos_weight we could tune them as usual hyperparameters. Shortcuts We should adjust beta to get optimal FN to FP trade-off. It may not provide meaningful results when a dataset is highly imbalanced (the dataset where the minor class is less than 10% of all samples). Exploratory data analysis is vital to make the model\u00a0work. If we penalize FN, it often leads to considerable FP growth and vice versa. You may need additional resources to compensate for that\u00a0growth. I hope this article [&#8230;]",
            "pubdate": "Tue, 08 Nov 2022 12:14:06 +0000",
            "pubdate_parsed": [
                2022,
                11,
                8
            ],
            "email_sent": true
        },
        "I Fine-Tuned GPT-2 on 110K Scientific Papers. Heres The Result": {
            "url": "https://towardsai.net/p/l/i-fine-tuned-gpt-2-on-110k-scientific-papers-heres-the-result",
            "description": "Last Updated on November 9, 2022 by Editorial Team Author(s): Edoardo Bianchi Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Content writing by AI is common, but is it possible for an AI to write technical essays? Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 10 Nov 2022 00:13:11 +0000",
            "pubdate_parsed": [
                2022,
                11,
                10
            ],
            "email_sent": true
        },
        "Getting Started With Stable Diffusion": {
            "url": "https://towardsai.net/p/l/getting-started-with-stable-diffusion",
            "description": "Last Updated on November 10, 2022 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Stable Diffusion is a text-to-image latent diffusion model created by researchers and engineers from CompVis, Stability AI, and LAION. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 11 Nov 2022 00:03:30 +0000",
            "pubdate_parsed": [
                2022,
                11,
                11
            ],
            "email_sent": true
        },
        "AnimeGAN effect with Python": {
            "url": "https://towardsai.net/p/l/animegan-effect-with-python",
            "description": "Last Updated on November 14, 2022 by Editorial Team Author(s): Rokas Balsys Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. I&#x2019;ll show you how you can easily apply the AnimeGAN effect on your media to get beautiful animated pictures, videos, or real-time camera Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 14 Nov 2022 12:48:15 +0000",
            "pubdate_parsed": [
                2022,
                11,
                14
            ],
            "email_sent": true
        },
        "Top 5 Upcoming Programming Languages for Web Development": {
            "url": "https://towardsai.net/p/l/top-5-upcoming-programming-languages-for-web-development",
            "description": "Last Updated on November 14, 2022 by Editorial Team Author(s): Amit Chauhan Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Programming languages for front-end, backend, and full-stack development Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 14 Nov 2022 12:38:58 +0000",
            "pubdate_parsed": [
                2022,
                11,
                14
            ],
            "email_sent": true
        },
        "From VGGNet to EfficientNet: Key Milestones in the Evolution of CNN Design": {
            "url": "https://towardsai.net/p/l/from-vggnet-to-efficientnet-key-milestones-in-the-evolution-of-cnn-design",
            "description": "Last Updated on November 16, 2022 by Editorial Team Author(s): Houssem Ben Braiek Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Modular, Multipath, Factorized, Compressed, Scalable&#x2026; All in CNN Nowadays, but What Led us Here&#x2026;We&#x2019;ll take you through the major&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 16 Nov 2022 12:43:43 +0000",
            "pubdate_parsed": [
                2022,
                11,
                16
            ],
            "email_sent": true
        },
        "A Step-by-Step Approach To Building a Text Summarization Webapp in Python From Scratch": {
            "url": "https://towardsai.net/p/l/a-step-by-step-approach-to-building-a-text-summarization-webapp-in-python-from-scratch",
            "description": "Last Updated on November 16, 2022 by Editorial Team Author(s): Dr. Dharini R Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Using Hugging Face Inference API, Flask, HTML &#38;\u00a0CSS Photo by Patrick Tomasso on\u00a0Unsplash What is the aim? To build a web application that can get an input text and show its\u00a0summary. What are we going to use? Hugging Face Accelerated Inference API, Python Flask Framework, HTML,\u00a0CSS. How is it done? By carrying out the following steps. The 3-Step\u00a0process 1. Identify the inference API of a text summarization model from the Hugging Face\u00a0library. 2. Build the front end with HTML and\u00a0CSS. 3. Build the back end with Python Flask and include the summarization task. Text summarization is the task of extracting a brief from a given set of sentences. A summary can be of two types\u200a\u2014\u200aan abstractive summary or an extractive summary. An extractive summary has words extracted from the given input, placing them together to form a brief. The abstractive summary generates the summary not only by replicating the words in the input, but also coining new words based on the understanding of the\u00a0text. We are going to build an abstractive summarization application using the Hugging Face Accelerated Inference API. To utilize a model by providing input to it and to get the model\u2019s output, we just have to make an API\u00a0call. The accelerated inference enables the \u2018plug-and-play\u2019 kind of usage to the machine learning models by means of API\u00a0calls. Kindly refer to the following blog link to understand the working of Inference API and its benefits with an implementation demo. Plug-and-Play ML Models with \u2018Accelerated Inference API\u2019 from Hugging Face The web application part of our project can easily be built with the Flask framework. The Flask helps with the development of a web application and renders an HTML file, which can be viewed in a web\u00a0browser. Welcome to Flask &#8211; Flask Documentation (2.2.x) The front end of our web application is built with HTML and CSS. The Hyper Text Markup Language (HTML) and Cascading Style Sheets (CSS) are used to design the structure of a webpage and presentation of a webpage, respectively. Having looked at the gist of everything we are going to use, let&#039;s have an idea of what we will build. Our web app is going to\u00a0have a front end\u200a\u2014\u200aa web page that gets the user input text and shows the summary as\u00a0output. a back end\u200a\u2014\u200awhere the user input is fed to the model, and the results are extracted from the\u00a0model. Now kindly make sure to go through the 3 step process of building our summarization application. 1. Identify and utilize a text summarization model from Hugging\u00a0Face For our project, we will be using the model facebook/bart-large-cnn provided by Lewis et al. [BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension] To use the model\u2019s Inference API, select the model from the Hugging Face library and then clickInference APIunder the Deploy\u00a0button. On clicking that, we will see a python script that can be utilized for the inference, as shown\u00a0below. Selecting the Inference API from Hugging\u00a0Face An Access Token is needed to get the API_URL and\u00a0headers. Create a profile in Hugging Face and create a new access token by following this path Profile -&#62; Settings -&#62; Access Tokens\u00a0Tab. The newly created access token can be used in place of Bearer and\u00a0headers Now let&#039;s move to the next part of our project to create a web application. 2. Build the front end with HTML and\u00a0CSS. The code for the front end is written in two parts \u200a\u2014\u200aA static file\u200a\u2014\u200aA HTML\u00a0file The static file consists of customizations to improvise the look of our front end. As the name suggests, the contents of a static file are not going to be changed according to the user\u2019s input or actions. A static file can include anything such as images, videos, cascading style sheets(CSS), flash files, etc., and these are not dynamically generated by the web server like a typical HTML response because they remain\u00a0static. In the desired location, create two folders named staticand templates In the static folder, create a new file named main.css, where CSS is the cascading style sheet that is used to style the\u00a0HTML. main.css consists of tags present in the HTML code with their corresponding styling and formatting. For a more detailed tutorial on how CSS is used, please refer to this\u00a0link. The code for the static file main.css is given below, followed by an explanation. https://medium.com/media/9085edd775ba2e82870a4b711d3e6523/href As we can see, the above CSS file consists of appearance-based formatting and customization for most of the tags used in our HTML\u00a0code. Code Explanation Lines 2 to 9\u200a\u2014\u200aconsist of styling and formatting aimed at the tag\u00a0header. Lines 11 to 25\u200a\u2014\u200aconsist of formatting for tag\u00a0h1. Lines 28 to 34\u200a\u2014\u200ahave the styling for body tag, along with a background image named image.gif Lines 35 to 39\u200a\u2014\u200aformatting for container Lines 41 to 47\u200a\u2014\u200astyling for div tag, which specifies the division of some\u00a0content Lines 49 to 64\u200a\u2014\u200aformatting for tags h2 and\u00a0h3 Lines 68 to 77\u200a\u2014\u200aconsist of formatting aimed at placing two text boxes side by side with the help of tags parent and child. Let&#039;s move on to creating the front end with our HTML\u00a0code. The HTML is built with the objective of providing a structured pleasant user interface, a space for users to provide input and a space for showing the\u00a0summary. In the already created folder named templates, create a new file named index.html. The code for index.html is given below, followed by the explanation. https://medium.com/media/259955078d0a4fa19f39d7196e7b124b/href Code Explanation Lines 4 to 11\u2014 Header of the\u00a0HTML Line 9\u200a\u2014\u200aWe have added the source of the static file (main.css). Line 10\u200a\u2014\u200aWe have given a title for our webpage named Summarization Application. Lines 13 to 42\u200a\u2014\u200aBody of [&#8230;]",
            "pubdate": "Wed, 16 Nov 2022 12:05:08 +0000",
            "pubdate_parsed": [
                2022,
                11,
                16
            ],
            "email_sent": true
        },
        "In-depth Azure Machine Learning Model Train, Test, and Deploy Pipelines on Cloud With Endpoints for Web APIs": {
            "url": "https://towardsai.net/p/cloud-computing/in-depth-azure-machine-learning-model-train-test-and-deploy-pipelines-on-cloud-with-endpoints-for-web-apis",
            "description": "Last Updated on November 20, 2022 by Editorial Team Author(s): Amit Chauhan An image by the Author The workspace consists of various artifacts Manage resources: It includes compute instances and compute clusters. Linked Services: Data Stores: It is a service to store various data. For example \u2014 Blob storage, hive storage, and SQL database. Compute targets: These are the machines where we run our model and do the train and test. Assets: Environments Experiments Pipeline Datasets Models Endpoints The whole scope of the workspace depends on some dependencies, there will be various logs, various notebooks, entries of the assets, etc. For them, the workspace requires storage. Dependencies Azure Storage account: Used for the administration and the working of the workspace. Azure container registry: When we deploy our model to the production and docker instances. Azure key vault: To store various keys, secret information, and privacy information. Azure application insight: It is used to monitor our machine learning applications and various information like response time, requests, failure conditions, performance, etc. Basic concepts Datasets It is information composed in the form of rows and columns, i.e., a collection of data. There are many methods in azure to upload/fetch the dataset for machine learning experiments. Data-stores When we want to fetch the dataset from the local system, then we need some storage that is where the data store comes into the picture. Data-store is just the connection to the various storage types like account storage, database, or analytics as a data lake. Various storage types Blob, file storage, data lake, Azure SQL, Azure PostgreSQL, MySQL, Azure Data bricks. These are supported by the azure system. Creating the machine learning workspace Below are the following steps to create the workspace Open the azure dashboard, search for the machine learning resource, click on it and then create. If you don\u2019t have an azure account, then follow the link below. How to Open an Azure cloud account with Debit Card A simple and easy process for all data scientist amitprius.medium.com An image by the Author 2. Fill in all the information. If there is no resource group name, then create a new one. When we will write the workspace name, the other information like a key vault, storage account, and application insight is filled automatically. We will keep the container registry to \u2018None\u2019 for now because it is required at the time of deployment. An image by the Author We can choose any region, but if we have a large amount of data, we can choose the nearest region of fast data transfer. In the Networking option, choose public access for practicing the experiment. n the Advanced option, there are many options, and keep it as it is, in data impact, if we enable then we are telling Microsoft that the data we will upload is sensitive. 3. After getting the Validation passed, click on create to make the workspace. It will create the four resources as shown below. An image by the Author 4. Now, click on the go to the resource, and the workspace dashboard will open with the launch studio option as shown below. An image by the Author In the above image, the access control (IAM) is used to create more users to use this workspace. Launching the machine learning studio After creating the workspace, it\u2019s time to launch the ML studio, and it will look like the image below. An image by the Author The author in the above image is responsible for making machine learning experiments and pipelines. 2. Make a new storage account to avoid the files of other storage systems. An image by the Author 3. Now, create a container inside this storage account. An image by the Author 4. Now, create a data store in the ML studio that will connect to this newly made storage account. An image by the Author 5. Fill in the information. An image by the Author To get the access key, go to the new storage account in step 2 and copy the key from the access key option, as shown below. An image by the Author Now, click on the create button of the data store. The data store is created and registered with the workspace along with the storage account. 6. Now, upload the dataset to the container we created in the storage account in step 3. An image by the Author We also check the file through the storage browser option in the storage account. An image by the Author 7. Now, create the dataset and choose the file from the data stores. An image by the Author Click the next button; when we will select \u2018From Azure storage\u2019 other options will come on the left side. We choose this option because our storage is a blob type. An image by the Author An image by the Author An image by the Author An image by the Author Now, we can deselect the Loan_ID and Gender column in the Schema option. An image by the Author Our data is uploaded in the dataset. An image by the Author An image by the Author Compute Resources In this topic, we will discuss the managed resources artifacts i.e. compute instances and compute clusters that come in the machine learning workspace. These are just different names for computers and virtual machines. The computed target is connected with linked services in the workspace. Why do we need computing resources? For any machine learning modeling, we need a computation resource that will train our model. Compute instance: It is a type of virtual machine/server or computer that is used for cloud computation. It is not a machine only but connected to the workspace and has Python, R, Docker, and Azure ML SDK configured. The default storage account while creating the workspace is attached to this instance means we can access all notebooks and other data stored. Mostly used in a development process training, testing, and inferencing. Inference means creating endpoints for web [&#8230;]",
            "pubdate": "Mon, 21 Nov 2022 01:10:46 +0000",
            "pubdate_parsed": [
                2022,
                11,
                21
            ],
            "email_sent": true
        },
        "Galactica: What Is It and What Happened?": {
            "url": "https://towardsai.net/p/l/galactica-what-is-it-and-what-happened",
            "description": "Last Updated on November 22, 2022 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Galactica, Meta AI&#x2019;s most recent model: The AI Scientist Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 23 Nov 2022 00:18:30 +0000",
            "pubdate_parsed": [
                2022,
                11,
                23
            ],
            "email_sent": true
        },
        "How To Compare 2 Datasets With Pandas-profiling": {
            "url": "https://towardsai.net/p/l/how-to-compare-2-datasets-with-pandas-profiling",
            "description": "Last Updated on November 24, 2022 by Editorial Team Author(s): Fabiana Clemente Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A data quality use case with advanced\u00a0EDA Pandas-profiling compare report (screenshot by the\u00a0author) Visualization is the cornerstone of EDA. When facing a new, unknown dataset, visual inspection allows us to get a feel of the available information, draw some patterns regarding the data, and diagnose several issues that we might need to address. In that regard, Pandas Profiling has been the indispensable swiss-knife in every data scientist\u2019s tool belt. In my past articles, I\u2019ve mentioned how pandas profiling can be helpful while performing time-series EDA, but what if we could compare two datasets? How many of us have started the development of a data science project and struggle to understand how much are we getting from our data transformations and engineering? And that\u2019s exactly what I\u2019ll be covering in today\u2019s blog post\u200a\u2014\u200ahow to leverage the most famous single line of code EDA to boost the process of data science development and data quality improvements. I\u2019ll give you a tour of how to leverage Pandas-Profiling comparison report functionality to boost your EDA process and illustrate its potential in producing faster and smarter transformations on our\u00a0data. The dataset used in this article can be found in Kaggle, the HCC Dataset by Miriam Santos (License: CC0: Public Domain). For this particular use case, I\u2019ve artificially introduced some additional data quality issues to show you how visualization can help us detect them and guide us toward their efficient mitigation. All code and examples are available on GitHub and in case you need a little refresher, make sure to check this blog to dust off your pandas-profiling skills. So, on with our use\u00a0case! Pandas Profiling: EDA at your fingertip We\u2019ll start by profiling the HCC dataset and investigating the data quality issues suggested in the\u00a0report: pip install pandas-profiling==3.5.0 https://medium.com/media/aecbb2a0b206edc8b622a05049283be4/href Alerts shown in Pandas Profiling Report (scheenshot by\u00a0author) According to the \u201cAlerts\u201d overview, there are four main types of potential issues that need to be addressed: Duplicates: 4 duplicate rows in\u00a0data; Constant: Constant value \u201c999\u201d in\u00a0\u2018O2\u2019; High Correlation: Several features marked as highly correlated; Missing: Missing Values in \u2018Ferritin\u2019. The validity of each potential problem (as well as the need to find a mitigation strategy for it) depends on the specific use case and domain knowledge. In our case, with the exception of the \u201chigh correlation\u201d alerts, which would require further investigation, the remaining alerts seem to reflect true data quality issues and can be tackled using a few practical solutions: Removing Duplicate Rows: Depending on the nature of the domain, there might be records that have the same values without it being an error. However, considering that some of the features in this dataset are quite specific and refer to an individual\u2019s biological measurements (e.g., \u201cHemoglobin\u201d, \u201cMCV\u201d, \u201cAlbumin\u201d), it\u2019s unlikely that several patients report the same exact values for all features. Let\u2019s start by dropping these duplicates from the\u00a0data: https://medium.com/media/753e0ef447aeb6f486b7eafdcd565d3c/href Removing Irrelevant Features: The constant values in O2 also reflect a true inconsistency in data and do not seem to hold valuable information for model development. In real use case scenarios, it would be a good standard to iterate with a domain or a business experts, but for the purpose of this use case example, we\u2019ll go ahead and drop them from the analysis: https://medium.com/media/448ec4f47535e83238d6da48f166646e/href Missing Data Imputation: HCC dataset also seems extremely susceptible to missing data. A simple way to address this issue (avoiding removing incomplete records or entire features) is resorting to data imputation. We\u2019ll use mean imputation to fill in the absent observations, as it is the most common and simple of statistical imputation techniques and often serves as a baseline\u00a0method: https://medium.com/media/052d75becb1224d1766eb88cda7bc39f/href Side-by-side comparison: faster and smarter iterations on your\u00a0data Now for the fun part! After implementing the first batch of transformations to our dataset, we\u2019re ready to assess their impact on the overall quality of our data. This is where the pandas-profiling compare report functionality comes in handy. The code below depicts how to get\u00a0started: https://medium.com/media/092c7ff17bdb1027986911d700c4bfbc/href Here\u2019s how both reports are shown in the comparison: Comparing Original Data and Transformed Data (screencast by the\u00a0author) What can we right away understand from our dataset overview? The transformed dataset contains one less categorical feature (\u201cO2\u201d was removed), 165 observations (versus the original 171 containing duplicates), and no missing values (in contrast with the 79 missing observations in the original dataset). But how have this transformations impacted the quality of our data? And how good were those decisions? Let\u2019s dive deep into that. In what concerns duplicate records, there was no particular impact in what concerns variables distributions and dataset patterns after the drop. The missing values imputation that was done is a different story. As expected, there are no missing observations after the data imputation was performed. Note how both the nullity count and matrix show the differences between both versions of the data: in the transformed data, \u201cFerritin\u201d now has 165 complete values, and no blanks can be found in the nullity\u00a0matrix. Comparison Report: Missing Values (screencast by\u00a0Author) However, we can infer something else from the comparison report. If we were to inspect the \u201cFerritin\u201d histogram, we\u2019d see how imputing values with the mean has distorted the original data distribution, which is undesirable. Comparison Report: Ferritin\u200a\u2014\u200aimputed values seem to distort the original feature distribution (Screenshot by\u00a0author) This is also observed through the visualization of interactions and correlations, where daft interaction patterns and higher correlation values emerge in the relationship between \u201cFerritin\u201d and the remaining features. Comparison Report: Interactions between Ferritin and Age: imputed values are shown in a vertical line corresponding to the mean (Screenshot by\u00a0author) Comparison Report: Correlations\u200a\u2014\u200aFerritin correlation values seem to increase after data [&#8230;]",
            "pubdate": "Fri, 25 Nov 2022 00:13:05 +0000",
            "pubdate_parsed": [
                2022,
                11,
                25
            ],
            "email_sent": true
        },
        "I used AI to Generate Nietzschean Aphorisms": {
            "url": "https://towardsai.net/p/l/i-used-ai-to-generate-nietzschean-aphorisms",
            "description": "Last Updated on November 25, 2022 by Editorial Team Author(s): Yoo Byoung Woo Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Can large language models help mankind overcome the crisis of nihilism in the modern\u00a0world? Ever since OpenAI released GPT-3, a large language model (LLM) trained on a massive amount of text data, the natural language processing community has been excited about the potential of using this technology for computational creativity (e.g., generating blog posts, fiction, or poetry). I personally think that LLMs are not only convenient tools for synthesizing media content or writing works of literature but also have the potential to solve a more serious problem: the crisis of meaning due to the advent of nihilism in the modern\u00a0world. God is Dead\u200a\u2014\u200aNietzsche, the Herald of\u00a0Nihilism According to the 19th-century German philosopher Friedrich Nietzsche, best known for heralding the death of God, modern civilization is plagued by nihilism; the loss of all value structure and meaning in life. When Nietzsche proclaimed \u201cGod is dead\u201d, he wasn\u2019t merely observing the decline of religion but was also pointing out that the universal values which have been the cornerstone of Western civilization for centuries no longer hold any meaning, thus each individual is left to fend for themselves, trying to make sense of a world that seems increasingly chaotic and full of suffering. In the wake of the death of God, modern civilization is plagued by nihilism (created by author &#38; stable diffusion) Although the age of Enlightenment and the scientific revolution played a significant part in ushering the loss of faith, Nietzsche mainly blames the predominant worldview of the time, i.e., Platonic idealism, Christianity, and Utopianism, for the spiritual weakening of modern man. For Nietzsche, these philosophies are a form of escapism, as they are based on the belief in a perfect, idealistic world (e.g., Platonic Forms, Paradise, communist utopia, etc.) which is separate from and superior to the material world, in which we often feel our lives are cruel, harsh and painfully short. Their function is to provide grand narratives of the \u201ctrue world\u201d and give hope that there is something more to life than our earthly existence, but such a view is ultimately decadent, as it provides false hope and encourages people to withdraw from life and the real world. When these idealistic visions of reality are shown to be false (as they inevitably are), then the entire value structure that they support collapses, leading to a spiritual crisis and a loss of meaning in life. This is what Nietzsche called nihilism, and he saw it as the greatest threat to Western civilization. Ideologies aim to bring an end to history by creating a utopia (created by author &#38; stable diffusion) Nietzsche\u2019s warnings about the dangers of nihilism have proven to be prophetic, as the 20th century was marked by two world wars and the horrific genocide of millions of people, which were primarily fueled by fascism, totalitarianism, and communism; ideologies that aim to bring an end to history by creating a utopia, be it racial, national or class-based. According to philosopher Julian Young, although most of them rejected metaphysical ideas, they are nevertheless \u201ctrue world\u201d philosophies in disguise, in which the old distinction between physical and metaphysical is reinterpreted as a distinction between present and future. The modern man, after the death of God and consequent disasters, is left with a feeling of absurdity and pointlessness, and the need for a new grand narrative, or better yet, overcoming the dependence on such narratives altogether, arises. Revaluation of All Values\u200a\u2014\u200aGenerating Aphorisms with a\u00a0LLM How can man accomplish the task of overcoming nihilism? Nietzsche proposes that we must first carefully examine the ethical norms we take for granted, a process he calls the revaluation of all values. This process exposes how these \u201ctrue world\u201d grand narratives promote decadence, so that man can create values of his own without relying on such life-denying philosophies. For Nietzsche, the method of revaluation was to write aphorisms\u200a\u2014\u200abrief, pithy, highly condensed statements that identify the genealogy and psychological motivations behind systems of values and their futile attempts to cover up the existential uncertainties of the human condition. Summon Nietzsche from the abyss of madness via AI technology (created by author &#38; stable diffusion) Recently, I\u2019ve been reading a lot of Nietzsche\u200a\u2014\u200aI was fascinated by his style of writing in aphorisms and how he used this literary form to uncover truths that modernity would rather keep hidden. I thought it was a shame that, ever since Nietzsche suffered a severe mental breakdown at the age of forty-four, he couldn\u2019t produce remarkable works again. This had me thinking: what if we could summon Nietzsche from the abyss of madness and resurrect him via AI technology? Specifically, what if we could use LLMs to generate previously unheard-of Nietzschean aphorisms? NLP enthusiasts have shown that it is possible to get OpenAI\u2019s GPT-3 to generate works of poetry in the style of a specific poet by providing only a handful of examples. This approach is known as few-shot learning, where a LLM is able to learn to perform a certain task from a small amount of data (a.k.a. few-shot samples) during inference time. These few-shot samples are included in the input text (a.k.a. prompt), usually in the form of a numbered list. The LLM, a model which is primarily trained for natural language completion tasks, will then generate text that conforms to the format and style of the provided samples. I thought there would be no reason why the same approach couldn\u2019t be used to generate Nietzschean aphorisms. The prompt for Nietzschean aphorism generation (created by\u00a0author) The main idea for Nietzschean aphorism generation is as follows: I take a bunch of Nietzsche\u2019s aphorisms, format [&#8230;]",
            "pubdate": "Fri, 25 Nov 2022 12:13:49 +0000",
            "pubdate_parsed": [
                2022,
                11,
                25
            ],
            "email_sent": true
        },
        "Quartics-Built To Order At Any Address In The X-Y Grid": {
            "url": "https://towardsai.net/p/l/quartics-built-to-order-at-any-address-in-the-x-y-grid",
            "description": "Last Updated on November 26, 2022 by Editorial Team Author(s): Greg Oliver Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Build your own Quartic Polynomials to order at any address in the Grid! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 27 Nov 2022 00:13:05 +0000",
            "pubdate_parsed": [
                2022,
                11,
                27
            ],
            "email_sent": true
        },
        "Working on a Computer Vision project? These code chunks will help you!!!": {
            "url": "https://towardsai.net/p/l/working-on-a-computer-vision-project-these-code-chunks-will-help-you",
            "description": "Last Updated on November 27, 2022 by Editorial Team Author(s): Chinmay Bhalerao Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Working on a Computer Vision Project? These Code Chunks Will Help You\u00a0!!! An introduction to a few \u201cused to\u201d methods in a computer vision\u00a0project Computer vision projects\u00a0[Source] \u201cVR and AR will eventually converge, and smart glasses will take over our digital interactions.\u201d\u2015 Carlos L\u00f3pez (Founder @\u00a0Oarsis) The amazing thing about working in Computer vision and machine learning is that after every few years, somebody invents something crazy that makes you totally reconsider what&#039;s possible!!! The World got a new eye &#38; new way of thinking and tracking objects since the emergence of Computer vision algorithms. Starting from Region-Based Convolutional Neural Networks [RCNN] to YOLO V7, detectron-2, segformer, and classification architectures, computer vision changed drastically for higher efficiency of detection and higher latency with less requirement of time and computational expensiveness. A computer vision project is a combination of many things, from data collection to successful deployment. Understanding data and the right processing and training is the key to success. Below are a few code chunks with descriptions of their work that will ease your working on the\u00a0project. 1. Know your dataset\u2019s instances for the object detection or segmentation project, we annotate our dataset with the help of external annotation tools like makesense.ai, VGG annotator, LableIMG, etc. Example of an imbalance dataset in object detection [Image\u00a0Source] We know the exact number of images, but it&#039;s hard to know how many instances of each class we have. Knowing instances of the class will tell you if your dataset is imbalanced or not. It will have a deep impact on the learning model if your instances are not balanced. So after downloading annotated dataset and its annotation file, you can use the following chunk of code to see the class balance\u00a0status. import os#Give path of folder in which you stored images and annotations path = r\"Your dataset *folder* location\" # Change the directory to path os.chdir(path)x=[]# Spinning through all files for file in os.listdir():# Checking for text annotation file if file.endswith(\".txt\"): file_path = f\"{path}\\{file}\" with open(file_path, &#039;r&#039;) as f: for line in f: a=line[0] x.append(a)print(x)#to count instances from collections import CounterCounter(x) Image by\u00a0Author You can see, at last, the counter gives instance values for each class, and then on your model criteria, you can decide if the dataset needs further balancing or\u00a0not. 2. Preprocessing of\u00a0images In our image dataset, other than class instances, we have many other objects/things. If we take it for the learning purpose of the model, then these other items can be classified as noises. There are many use cases that claim that removing these noises and then sending them to the model for training improves the performance of the model. So how do preprocess images? See the below\u00a0code. #Writing a function to create mouse masking #We are using mouse click events hereimport numpy as npimport cv2 as cvdrawing = False # true if mouse is pressedmode = True # if True, draw rectangle. Press &#039;m&#039; to toggle to curveix,iy = -1,-1# mouse callback functiondef draw_circle(event,x,y,flags,param): global ix,iy,drawing,mode if event == cv.EVENT_LBUTTONDOWN: drawing = True ix,iy = x,y elif event == cv.EVENT_MOUSEMOVE: if drawing == True: if mode == True: cv.rectangle(img,(ix,iy),(x,y),(255,255,255),-1) #(255,255,255) represents white color but you can give any. # -1 represents filled box and 1 represents hollow box else: cv.circle(img,(x,y),5,(0,0,255),-1) elif event == cv.EVENT_LBUTTONUP: drawing = False if mode == True: cv.rectangle(img,(ix,iy),(x,y),(255,255,255),-1) else: cv.circle(img,(x,y),5,(0,0,255),-1) #storing final output cv2.imwrite(\"new_img.jpg\",img) #Calling function and using it on input image import cv2 img = cv2.imread(r\"Your image path\",1)#resizing to fit on screenimg = cv2.resize(img,(1200,800))cv.namedWindow(&#039;image&#039;)cv.setMouseCallback(&#039;image&#039;,draw_circle)while(1): cv.imshow(&#039;image&#039;,img) k = cv.waitKey(1) &#38; 0xFF if k == ord(&#039;m&#039;): mode = not mode elif k == 27: breakcv.destroyAllWindows() If you run the above code, then you will have your training image in front of you, and your mouse will act as a mask maker. After clicking and hovering the mouse on an unnecessary object will direct create a mask on that object. I took white color for use case purposes, but you can take any according to your problem. You can train a separate object detection model for noise, and below that, you can attach this code. At first, the model will detect noise, and then this code will mask that bounding box with your desired\u00a0color. Masking of noise objects [Image by\u00a0Author] There are many things you can do for image preprocessing, like cropping, making blur/contrast, etc. you can read my blog for more image preprocessing techniques. Do you know these basic image processing operations? 3. Data Augmentation In every computer vision project, you want to augment the dataset to make it bigger to make the model\u2019s work easier. There is much open-source software that does Augmentations for you, like Roboflow. But many times, there can be a problem with data security and confidentiality. So you can do your own dataset augmentation on your python editor. There is a library by TensorFlow known as \u201cImageDataGenerator\u201d which helps you to do this. See the below\u00a0code. # FOR COMPLETE FOLDER ANNOTATION#imports import tensorflowimport kerasimport numpy as npimport osfrom PIL import Imagefrom skimage import ioSIZE = 128dataset = []image_directory = &#039;Image folder address/&#039;from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img# Gving required augmentations to image #ImageDataGenerator has many Augmentations, choose those who are good for your conditiondatagen = ImageDataGenerator( rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=&#039;nearest&#039;)my_images = os.listdir(image_directory)for i, image_name in enumerate(my_images): if (image_name.split(&#039;.&#039;)[1] == &#039;jpg&#039;): image = io.imread(image_directory + image_name) image = Image.fromarray(image,&#039;RGB&#039;) image = image.resize((SIZE,SIZE)) dataset.append(np.array(image)) x = np.array(dataset)i = 0for batch in datagen.flow(x, batch_size=20, save_to_dir=&#039;preview&#039;, save_prefix=&#039;Hard_Hat&#039;, save_format=&#039;jpeg&#039;): i += 1 if i &#62; 200: break #FOR SINGLE IMAGE ANNOTATIONimport tensorflowimport kerasfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#Adress of imageimg = load_img(&#039;Image address [should [&#8230;]",
            "pubdate": "Sun, 27 Nov 2022 12:23:46 +0000",
            "pubdate_parsed": [
                2022,
                11,
                27
            ],
            "email_sent": true
        },
        "How To Be a Machine Learning Engineer?": {
            "url": "https://towardsai.net/p/l/how-to-be-a-machine-learning-engineer",
            "description": "Last Updated on November 26, 2022 by Editorial Team Author(s): Gencay I. Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Here, we will discuss finding the necessary skills if you want to be a machine learning engineer, like SQL, Python, Django, or flask, and&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 27 Nov 2022 04:48:07 +0000",
            "pubdate_parsed": [
                2022,
                11,
                27
            ],
            "email_sent": true
        },
        "Microsoft Uses Transfer Learning to Train Autonomous Drones": {
            "url": "https://towardsai.net/p/l/microsoft-uses-transfer-learning-to-train-autonomous-drones",
            "description": "Last Updated on November 26, 2022 by Editorial Team Author(s): Jesus Rodriguez Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. The model is able to transfer knowledge between a simulated environment and real-world settings. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 27 Nov 2022 04:33:34 +0000",
            "pubdate_parsed": [
                2022,
                11,
                27
            ],
            "email_sent": true
        },
        "The Beauty of A.I. Is That It Lives in the Twilight Zone Between Atoms And Bits": {
            "url": "https://towardsai.net/p/l/the-beauty-of-a-i-is-that-it-lives-in-the-twilight-zone-between-atoms-and-bits",
            "description": "Last Updated on November 28, 2022 by Editorial Team Author(s): Tarek Amr Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. And this is probably its main weakness as well. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 28 Nov 2022 12:18:44 +0000",
            "pubdate_parsed": [
                2022,
                11,
                28
            ],
            "email_sent": true
        },
        "Object Tracking with Particle Filters In Python": {
            "url": "https://towardsai.net/p/l/object-tracking-with-particle-filters-in-python",
            "description": "Last Updated on November 29, 2022 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Computer vision has made rapid progress in the last few years, thanks to improvements in training data and algorithms, as well as the&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 29 Nov 2022 12:14:33 +0000",
            "pubdate_parsed": [
                2022,
                11,
                29
            ],
            "email_sent": true
        },
        "My Top 3 Tips for Getting Kaggle Expert Rank With Your First 5 Notebooks": {
            "url": "https://towardsai.net/p/l/my-top-3-tips-for-getting-kaggle-expert-rank-with-your-first-5-notebooks",
            "description": "Last Updated on December 1, 2022 by Editorial Team Author(s): Pere Martra Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Becoming a Kaggle expert requires work, but it is a very achievable goal. I\u2019ll tell you three tips that helped me the most to do it with only five notebooks. Photo by sporlab on\u00a0Unsplash Kaggle is the most prestigious data science competition site. Having a good profile on Kaggle can open many doors, and is one of the best places where you can showcase your Data Science problem-solving skills. The Kagglers got medals based on how well they did in the competitions. But Kaggle isn\u2019t just about competition. There are four categories in which you can progress. Competitions. Maybe the most prestigious category inside Kaggle. You can receive medals depending on the results of the competitions you participate in. Datasets. Data Scientists can publish their DataSet creations. Medals are awarded based on the votes of other Kagglers. Notebooks. Perhaps the most prestigious category after the competitions. Not all uploaded notebooks have to be associated with an active Kaggle competition. Any notebook can get votes from the community. As in the case of the DataSets, the more votes obtained, the higher the quality of the medals and the higher the\u00a0ranking. Discussion. It is the least prestigious of all the categories. Votes are obtained for comments made on the Kaggle platform. In each of these categories, you can opt for 5 ranks: Novice, Contributor, Expert, Master, and Grand\u00a0Master. The two initial ranks are really easy to obtain. Let\u2019s say that by filling out the profile, interacting a little with the community, and posting a job, you already reach the Contributor level. But obtaining the Expert rank requires effort, it is the first rank that must be obtained by earning\u00a0medals. In this article, I will discuss how to achieve the Expert rank in the Notebook category, which is possibly the most prestigious after competitions. What are the requirements to achieve Expert rank in the Notebook category on\u00a0Kaggle? Very easy! We need to get at least five bronze medals. To get a medal, we must obtain five votes from Kagglers with a higher category than Novice. The truth is that it seems simple, but we must consider that only 1 in 20 notebooks in Kaggle receive more than 2 votes. What we are going to attempt is to receive more than 5 votes from Kagglers in 100% of our notebooks. Image by\u00a0Author In the image, we can see the requirements for each of the categories. As you can see, I only have the check in the Notebooks category. So, I can only be considered an expert in that category. Data Scientists with more experience or who are more dedicated to Kaggle can earn the rank of an expert in more categories. With what is usually described as Kaggle Expert * n. Being n the number of categories in which he is considered an\u00a0expert. Competitions are the most prestigious category, followed by Notebooks and Datasets, and finally, discussions. My first five Notebooks. This was my first notebook. Currently, he has a silver medal. Awarded for getting more than 20 votes from Kagglers ranked higher than\u00a0Novice. I intended to get the highest score possible in the MNIST Competition with a Model created by me. In the Notebook, there are some techniques that aren\u2019t used often. For example, instead of using Dropout layers, I used SpatialDropout. I also struggled with the callback functions and tried to achieve the highest possible score. The most important thing is that the Notebook explains the reason for each of the techniques used. The second Notebook now also has a silver medal. Like the previous one, it was also part of one of Kaggle\u2019s basic competitions. The approach on this one was entirely different. I focused 100% on the data transformation, and on explaining step by step the reason for each of the modifications. The model used was a regression model from the SciKit library. I didn\u2019t waste time with him. I would say that the majority of the work was invested in data processing and the generation of graphs to understand the data and its transformations. Moreover, I attempted to make some functions customizable with variables. So that other Kagglers could play with the Notebook and test how it worked by altering these\u00a0values. This notebook was not part of any competition. But I used one of the best-known Kaggle Datasets: Card fraud detection. It was just an experiment using the SciKit Learn library, in which I tried to create a function that was capable of modifying the data by itself. Applying the algorithm to obtain good performance without the participation of the Data Scientist. The notebook was much better received than I expected. This notebook was also part of one of the basic competitions. It\u2019s a notebook that really surprised me that it got so many votes. Right now, it has a silver medal. In it, I\u2019m not trying to get a good score, but instead, I\u2019m manually generating a Simple Logistic Regression Model. It was intended as a simple guide to learning how to create simple models manually. By entering the same competition as the previous Notebook and scoring much better, the Notebook got far fewer votes. It surprised me at first, but later, after taking a tour of the other competing notebooks, I could say that this one contributed very little. It was just one more of the notebooks that used Transfer Leaning to solve the competition. It is true that the model used was not one of the most widely used and that I tried to make it a basic approach to Transfer Learning. Still, fortunately, he received a bronze medal, which [&#8230;]",
            "pubdate": "Fri, 02 Dec 2022 00:10:57 +0000",
            "pubdate_parsed": [
                2022,
                12,
                2
            ],
            "email_sent": true
        },
        "Efficient NeRFs for Real-Time Portrait Synthesis (RAD-NeRF)": {
            "url": "https://towardsai.net/p/l/efficient-nerfs-for-real-time-portrait-synthesis-rad-nerf",
            "description": "Last Updated on December 3, 2022 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. From Audio to Talking Heads in Real-Time with AI! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 04 Dec 2022 00:14:22 +0000",
            "pubdate_parsed": [
                2022,
                12,
                4
            ],
            "email_sent": true
        },
        "DeepMinds DeepNash plays Stratego": {
            "url": "https://towardsai.net/p/l/deepminds-deepnash-plays-stratego",
            "description": "Last Updated on December 6, 2022 by Editorial Team Author(s): Mandar Karhade Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. DeepMind started December with a bang: DeepNash a Game-playing AI excels at playing games with imperfect information using Nash Equilibrium Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 06 Dec 2022 12:43:49 +0000",
            "pubdate_parsed": [
                2022,
                12,
                6
            ],
            "email_sent": true
        },
        "How to access Scientific Knowledge with Galactica": {
            "url": "https://towardsai.net/p/l/how-to-access-scientific-knowledge-with-galactica",
            "description": "Last Updated on December 6, 2022 by Editorial Team Author(s): Yoo Byoung Woo Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A tutorial for using Meta AI\u2019s large language model to perform scientific NLP\u00a0tasks The world of scientific knowledge is mind-bogglingly vast. Searching for relevant research papers, understanding complex concepts, and writing academic literature can be daunting and time-consuming, especially for inexperienced researchers. Fortunately, with the advent of Meta AI\u2019s large language model, accessing scientific knowledge has never been\u00a0easier. Galactica enables users to access scientific knowledge and tackle scientific NLP tasks (created by author &#38; stable diffusion) In this tutorial, I\u2019ll show you how to use Meta AI\u2019s Galactica to quickly and effectively perform various scientific NLP tasks. We\u2019ll cover topics such as finding relevant citations, generating academic papers, processing multi-modal data (e.g., LaTeX equations, code snippets, chemical formulas, etc.) frequently encountered during research, and\u00a0more. What is Meta AI\u2019s Galactica? Galactica trains on text sequences that represent scientific phenomena (Source: Galactica paper) Galactica is a 120B parameter large language model trained on a curated scientific corpus. The training data consists not only of massive volumes of scientific literature but also datasets for downstream scientific NLP tasks and special tokens representing scientific phenomena. Specialized tokenization is an integral part of Galactica as it enables the model to predict citations or process modalities such as protein sequences or SMILES formulas: Citations: citations are wrapped with reference tokens [START_REF] and [END_REF]. Reasoning: &#60;work&#62; token enables step-by-step reasoning by mimicking an internal working memory (not covered in this tutorial). SMILES Formula: SMILES formula sequences are wrapped with tokens [START_SMILES] and [END_SMILES]. For isomeric SMILES, tokens [START_I_SMILES] and [END_I_SMILES] are\u00a0used. Amino Acid Sequences: amino acid sequences are wrapped with tokens [START_AMINO] and [END_AMINO]. DNA Sequences: DNA sequences are wrapped with tokens [START_DNA] and [END_DNA]. Meta AI reports that Galactica\u2019s generative approach for citation prediction outperforms retrieval approaches, which demonstrates the potential for language models to replace search engines. Also, Galactica beats existing methods on reasoning task benchmarks (e.g., MMLU and MATH) and sets a new state-of-the-art on several downstream scientific NLP tasks (e.g., PubMedQA and MedMCOA). Despite its powerful capabilities, similar to most language models, Galactica is prone to hallucination; that is, the model outputs nonsensical results in some cases. Therefore, researchers who use Galactica should always fact-check the generated outputs. How to use Galactica Galactica is accesible via the galai Python library. You can download the model with load_model. import galai as galmodel = gal.load_model(name=\"standard\", num_gpus=2) The name arguement is for the name of the model version to use. There are five versions of the model available (\u2018mini\u2019, \u2018base\u2019, \u2018standard\u2019, \u2018large\u2019, \u2018huge\u2019), each with varying parameter size (125M, 1.3B, 6.7B, 30B, 120B, respectively). The num_gpus arguement is for the number of GPUs to use. I was able to load the \u2018standard\u2019 version on two NVIDIA RTX 3090 GPUs; the model took up about 19GB memory for each\u00a0device. Text Generation Similar to most large language models, Galactica frames every NLP task as text generation. You can use generate to generate\u00a0text. # free-form text generationinput_text = \"The reason why Transformers replaced RNNs was because\"generated_text = model.generate(input_text=input_text, max_length=256, new_doc=False, top_p=None)print(generated_text)\"\"\"The reason why Transformers replaced RNNs was because they were able to capture long-term dependencies in the input sequence.# 2.2.2. Attention MechanismThe attention mechanism was introduced in [START_REF] Neural Machine Translation by Jointly Learning to Align and Translate, Bahdanau[END_REF] to improve the performance of the encoder-decoder model...\"\"\" The input_text is the input context for the model to use for its generation. Galactica\u2019s other advanced capabilities can be accessed via prompt engineering of the input\u00a0context. The max_length modifies the maximum token length of the generated text. Default value is 60 tokens, so max_length should be set to a higher value for longer generations. The maximum context length of the model is 2048\u00a0tokens. If new_doc is set to True, a padding token is automatically appended to the front of the input text so that the model would treat it as the beginning of a new document. For free-form text generation, new_doc it should be set to\u00a0False. The top_p argument is for nucleus sampling. If the generated results seems too repetitive, set the value to a float between 1 and 0, such as 0.9. Otherwise top_p defaults to None and greedy decoding is\u00a0used. Papers and\u00a0Surveys You can generate various types of academic literature with Galactica via prompt engineering. If a prompt is designed to resemble a certain kind of document, so will its completion. For paper documents, use\u00a0Title:. # generate paper documentinput_text = \"Title: Self-Supervised Learning, A Survey\\n\\nAuthors: John Smith\\n\\n\"generated_text = model.generate(input_text, new_doc=True)print(generated_text)\"\"\"Title: Self-Supervised Learning, A SurveyAuthors: John Smith# AbstractSelf-supervised learning is a class of machine learning methods that learn representations of data without the need for human-provided labels.\\nIn this survey, we provide a comprehensive overview of the field\"\"\" This functionality is particularly useful when you need a comprehensive survey on a particular topic. Simply design the prompt as Title: TOPIC, A Survey and Galactica will automatically generate one for\u00a0you. Lecture Notes and Wikipedia Articles For Wikipedia-style articles or lecture notes, begin the prompt with\u00a0#. # generate wiki style articlesinput_text = \"# Multi-Head Attention\\n\\n\"generated_text = model.generate(input_text, new_doc=True)print(generated_text)\"\"\"# Multi-Head AttentionThe multi-head attention mechanism is a generalization of the single-head attention mechanism. The multi-head attention mechanism is a combination of multiple single-head attention mechanisms. The multi-head attention mechanism is shown in Figure 2.The multi- ...\"\"\"# generate lecture notesinput_text = \"# Lecture 1: The Ising Model\\n\\n\"generated_text = model.generate(input_text, new_doc=True)print(generated_text)\"\"\"# Lecture 1: The Ising Model# 1.1 The Ising ModelThe Ising model is a simple model of ferromagnetism. It was introduced by Lenz in 1920 [[START_REF] Beitrag zur Theorie des Ferromagnetismus, Ising[END_REF]]\"\"\" Citation Prediction Galactica is trained on a large scientific corpus comprising more than 360 million in-context citations and [&#8230;]",
            "pubdate": "Tue, 06 Dec 2022 12:43:47 +0000",
            "pubdate_parsed": [
                2022,
                12,
                6
            ],
            "email_sent": true
        },
        "OpenAIs Most Recent Conversational AI: ChatGPT": {
            "url": "https://towardsai.net/p/l/openais-most-recent-conversational-ai-chatgpt",
            "description": "Last Updated on December 6, 2022 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. ChatGPT explained! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 07 Dec 2022 00:08:18 +0000",
            "pubdate_parsed": [
                2022,
                12,
                7
            ],
            "email_sent": true
        },
        "How to Quickly Build A Semantic Search System With txtai And Weaviate": {
            "url": "https://towardsai.net/p/l/how-to-quickly-build-a-semantic-search-system-with-txtai-and-weaviate",
            "description": "Last Updated on December 12, 2022 by Editorial Team Author(s): ___ Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. An introduction to the weaviate-txtai library Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 13 Dec 2022 02:41:41 +0000",
            "pubdate_parsed": [
                2022,
                12,
                13
            ],
            "email_sent": true
        },
        "End-to-End Machine Learning Project with Deployment Part 1: Project Set-Up": {
            "url": "https://towardsai.net/p/l/end-to-end-machine-learning-project-with-deployment-part-1-project-set-up",
            "description": "Last Updated on December 12, 2022 by Editorial Team Author(s): Abhishek Jana Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Get Your Project Ready for Machine Learning: A Step-by-Step Guide Many of us often make the mistake of jumping straight into coding when working on end-to-end projects. This approach can work well when dealing with small datasets that don\u2019t need much preprocessing. In these cases, we can quickly train a predictive machine learning model and deploy it in the cloud. But this approach has its limitations. If the project is not set up correctly, the code may not be \u201creusable\u201d or \u201cscalable\u201d, which can cause problems down the\u00a0road. What is the meaning of \u201creusable\u201d and \u201cscalable\u201d in a machine learning\u00a0project? \u201cReusable\u201d refers to the ability of a project or its components to be used again in future projects. Reusability can save time, money, and resources in future projects by reducing the need to start from\u00a0scratch. We say that a project is \u201cscalable\u201d when it can be easily adapted to work with larger or smaller datasets without significant changes to its overall design or structure. This is important because it allows the project to be used effectively in a wide range of situations, regardless of the size of the data it is working\u00a0with. If you\u2019re wondering how to get started, here\u2019s a step-by-step guide. Keep in mind that I won\u2019t be explaining the code in detail but rather provide an overview of the project\u00a0flow. Step 1. Don\u2019t\u00a0Code! It is important to carefully read and understand the problem statement and data description before starting to work on a dataset. Doing so can provide valuable information about the dataset, such as its origin, the number and names of columns, and how to access the data. In some cases, the description may even indicate that the dataset is outdated or commonly used and, therefore may not provide new insights. Let\u2019s look at an\u00a0example. I am currently working on a rental bike sharing which is a 10-year-old dataset and is used by many data science enthusiasts. So this is not going to give us any new information. So if you look at the dataset, it gives us a description of the dataset without even looking into the data. It tells us the source of the data which has the most up-to-date version. We can use\u00a0that. In industry, data descriptions are often provided along with the dataset. This is called a \u201cData Sharing Agreement,\u201d or DSA. It is important to read and understand this information before beginning your analysis. This brings us to our next\u00a0step. Step 2. Documentation! A data science or machine learning project typically involves multiple teams, such as a data maintenance team, a data analysis team, a model training team, and a front-end development team. It is important to document the project in a clear and organized way so that all team members can understand it and stay up to date with the latest developments. This is especially important when presenting the project to stakeholders or when new members join the team and need to quickly get up to speed. By documenting the project consistently and thoroughly, the team can ensure that everyone is on the same page and working towards the same\u00a0goals. There are five types of documents we need to maintain: High-Level Design Document: A high-level design document, or HLD, is a general document that outlines the overall flow of a project. It typically includes a description of the data that will be used, the steps involved in the project, and the tools and resources that will be required to complete it. This document provides a high-level overview of the project and is used to guide the development team in implementing the project. It may also be used to communicate the project\u2019s goals and objectives to stakeholders and other interested parties. Low-Level Design Document: The Low-Level Design (LLD) document is a more specific document that focuses on the details of data handling and machine learning model training. The LLD provides a more in-depth look at the technical aspects of the project and how the various components will work together. Architecture Design Document: AD provides a detailed description of the internal structure of a program. It includes a class diagram with methods and their relationships, as well as a description of program specifications. This document serves as a guide for the programmer, allowing them to write code directly from the\u00a0design. Wireframe Document: This is a preview of how the front-end will look after the project is deployed. Detailed Project Report: DPR is mostly geared towards the stakeholders about the overall findings of the\u00a0project. High-level design (HLD) and low-level design (LLD) are early planning stages in a project where the overall structure and detailed specifications of the project are laid out, respectively. Once the HLD and LLD are approved, the development team can begin writing code and creating application design (AD) and wireframe documents. The project progress and findings are typically summarized in a final document called the Detailed Project Report\u00a0(DPR). Step 3. Select a Template! Now to begin coding, we can create a GitHub repository and push our work\u00a0there. project structure Here is a project template that can help you when starting a new project. In the following parts, I will explain the purpose of each directory and file in the template. For now, you can clone this repository and explore the \u201cdocuments\u201d directory. After reading this, you should be able to use the template to create the high-level design (HLD) and low-level design (LLD) for your own project. Give it a try, and let me know how it\u00a0goes. You can follow me on GitHub, LinkedIn, and medium for the latest updates and stay informed about [&#8230;]",
            "pubdate": "Tue, 13 Dec 2022 00:11:01 +0000",
            "pubdate_parsed": [
                2022,
                12,
                13
            ],
            "email_sent": true
        },
        "A Journey into the Fabulous Applications of TransformersPart 1": {
            "url": "https://towardsai.net/p/l/a-journey-into-the-fabulous-applications-of-transformers%e2%80%8a-%e2%80%8apart-1",
            "description": "Last Updated on December 13, 2022 by Editorial Team Author(s): Dr. Dharini R Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A Journey Into the Fabulous Applications of Transformers\u200a\u2014\u200aPart\u00a01 Demo with Emphasis on NLP using Python, Hugging\u00a0Face. Photo by Arseny Togulev on\u00a0Unsplash The introduction of transformers has made a huge impact on Artificial Intelligence, especially in the Natural Language Processing domain. Transformers paved way for the most awaited success of transfer learning in Natural Language Processing. As a result, many large language models came into existence, and now we are able to build beneficial applications on top of these cutting-edge models. A transformer is, in simpler language, an encoder-decoder architecture with a self-attention mechanism on both sides. The encoder block takes input and converts it into numerical form, and the decoder block takes that numerical form and converts it to text. To constrain the article to the specific applications of transformers, we will not delve into the depth of its architecture. Kindly go through the links in the Reference section to understand the architecture, evolution, and fundamentals of transformers. Why Transformers? Transformers aided in successfully establishing \u201cTransfer Learning\u201d in NLP by enabling the usability of features extracted from a pretrained model. The idea is to utilize a model that is pretrained with humongous text data (also called as Large Language Models), by fine-tuning it to our own purpose. Along with saving a lot of time and expense, the need for large training data has reduced considerably since we are using an already pretrained model. This, in turn, triggered the formation of widespread research into transformers and brought the existence of numerous NLP pretrained models. The implementation of numerous applications with these models is made possible and bloomed the transfer learning in\u00a0NLP. Hugging Face Hugging Face is a library built by artificial intelligence enthusiasts where myriad models are built and shared with the community. Hugging Face comprises pretrained models for domains such as Computer Vision, Natural Language Processing, Audio Processing, Tabular data, Reinforcement Learning, and Multimodal applications. All the models can easily be accessed using the API(Application Programming Interface) The aim of the article is to harness the NLP domain and explore the possible applications with a demo code and explanation. To utilize any of the Hugging Face models, the first step is to install transformers library as\u00a0follows. pip install transformers The next step is to utilize pipeline which helps in hiding all the complex steps behind the model implementation and providing a simple, easy-to-use API for the models. For each of the major applications mentioned below, we will see the code along with an explanation. There are many models available in Hugging Face for every task in every domain. Since this article is about awareness of the applications, we will utilize the default model set by the library itself. Also, considering that this article is about the introduction to these possibilities, the details regarding the models can be referred to from the links given in each\u00a0section. Applications In all of the applications discussed in the article, we are going to follow these\u00a0steps. 1. Import\u00a0pipeline 2. Invoke a model for the corresponding task by instantiatingpipeline. The model weights of the default model for the task are downloaded in this\u00a0step. 3. Utilize that model by giving the required\u00a0input. 4. Review the results and try different inputs. The code and output for all the applications are given in this GitHub repository, along with a Google Colab\u00a0link. The applications discussed in this article\u00a0are 1. Text Classification 2. Text Summarization 3. Question Answering 4. Text Generation 5. Named Entity Recognition 1. Text Classification Classification is the process of placing the given text in any one of the informed categories. Let us start with importing the required library as\u00a0follows. The next step is to initialize a variable named text_classifier that represents the model being invoked in the text-classification category. As we know, the model is invoked bypipeline function using the task name. Since a specific model name is not given, the default model (distilbert-base-uncased-finetuned-sst-2-english) will be downloaded, which can be seen in the following output. from transformers import pipelinetext_classifier = pipeline(\"text-classification\")Output:No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).Using a pipeline without specifying a model name and revision in production is not recommended.Downloading: 100%629/629 [00:00&#60;00:00, 24.4kB/s]Downloading: 100%268M/268M [00:05&#60;00:00, 62.8MB/s]Downloading: 100%48.0/48.0 [00:00&#60;00:00, 1.70kB/s]Downloading: 100%232k/232k [00:00&#60;00:00, 6.48MB/s] As the next step, we give input to the text classification model using the initialized variable text_classifier. The model being invoked helps us to classify the given text and produce a score on POSITIVE and NEGATIVE sentiments on the text. For more information about the model, please click this\u00a0link. In the code given below, a sentence representing a negative sentiment is given, and the results are stored in clf_result. On printing the output, we can see that the model classified the sentence into a NEGATIVE category and gives a score (representing sentiment score). clf_result = text_classifier(\"Oh God!!!! Its so horrible to hear about the news of aircraft\")print(clf_result)Output[{&#039;label&#039;: &#039;NEGATIVE&#039;, &#039;score&#039;: 0.9992474317550659}] Now let us try with another sentence and see the result. In the snippet below, it can be seen that the result is POSITIVE label as we have given a statement that expresses relief. clf_result = text_classifier(\"Oh God!!!! So relieved to hear about the aircraft\")print(clf_result)Output[{&#039;label&#039;: &#039;POSITIVE&#039;, &#039;score&#039;: 0.9974811673164368}] 2. Text Summarization Text summarization is the task of extracting a summary from a given set of sentences. The first step is to import pipeline and the next, we instantiate with the task of our choice (summarization). The default model for text summarization is sshleifer/distilbart-cnn-12\u20136 and to know more about the model, please check this link. The model is invoked under the variable text_summarizer. from transformers import pipelinetext_summarizer = pipeline(\"summarization\")Output:No model was supplied, defaulted to [&#8230;]",
            "pubdate": "Wed, 14 Dec 2022 00:12:05 +0000",
            "pubdate_parsed": [
                2022,
                12,
                14
            ],
            "email_sent": true
        },
        "10 + Politics Related Data Visuals In A Single Line Of Code": {
            "url": "https://towardsai.net/p/l/10-politics-related-data-visuals-in-a-single-line-of-code",
            "description": "Last Updated on December 14, 2022 by Editorial Team Author(s): Adam Ross Nelson Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. For data scientists + data pros who need a quick viz on-they-fly for testing, demonstration, or training purposes Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 15 Dec 2022 00:10:59 +0000",
            "pubdate_parsed": [
                2022,
                12,
                15
            ],
            "email_sent": true
        },
        "A guide to Persistent storage in Docker": {
            "url": "https://towardsai.net/p/l/a-guide-to-persistent-storage-in-docker",
            "description": "Last Updated on December 15, 2022 by Editorial Team Author(s): Prithivee Ramalingam Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. What is the need for persistent storage in\u00a0Docker? Applications generate 2 kinds of data, persistent and non-persistent. Non-persistent data can be ignored, and they don\u2019t have to be saved anywhere. On the other hand, persistent data needs to be saved for future use; it can\u2019t be lost at any cost. If the application is hosted as a container, persistent data must be accessible to multiple containers as they share the load and storage. The data must persist, devoid of the status of the container. Since we have understood the need for persisting data, let\u2019s look at how data is stored inside a container. A container consists of multiple layers, and the files inside the container are stored in the writable layer. The data can only be persisted as long as the container exists, which means when the container is deleted, all the data inside it will be lost. Which presents the following problems, It would be difficult for another container to access the data which is present inside the container. Since the container\u2019s writable layer is tightly coupled to the host machine, it would be difficult to move data to a different system. To solve this problem, docker came up with 2 ways of persistent storage, Volumes and bind mounts. Docker also supports temporary file storage for in-memory use\u00a0cases. In this article we will be learning about the different persistent storage options, their implementation, their use case along with code\u00a0samples. Photo by John Salvino on\u00a0Unsplash Table of\u00a0contents 1. Code walkthrough 2. Bind\u00a0Mounts 3. Volumes 4. Temporary file storage\u00a0mounts 5. Conclusion 1. Code walkthrough For this article, we have taken the example of a simple python application that takes in the file name and content of the file as parameters and creates the file with the specified content. The source code for this application can be found\u00a0here. from flask import Flask, requestimport osapp = Flask(__name__)if not os.path.exists(\"docker_bind\"): os.makedir(\"docker_bind\")@app.route(\"/create_file\",methods=[\"POST\"])def run(): data = request.get_json() file_name, content = data[&#039;file_name&#039;], data[&#039;content&#039;] file_path = f\"docker_bind/{file_name}\" with open(file_path,&#039;w&#039;) as write_file: write_file.write(content) return {\"Status\":\"Success\"}app.run(debug=False,host=&#039;0.0.0.0&#039;,port = 5000) To run this application as a container, the prerequisite is that docker has to be installed. After installing docker, open the command prompt and execute the following commands. The list of all the commands can be found\u00a0here. To build the container. docker build -t create_file_py_image . To run the container. docker run --name create_file_py_container -p 5001:5000 create_file_py_image After running the above command, we can open postman and send a request to the running container with file name and content as parameters. The application takes in the parameters, creates the file with the specified name and content, and returns the Status as success. We will be using the same code to explain both volume and bind\u00a0mounts. Image by Author\u200a\u2014\u200aSending request to the containers 2. Bind\u00a0Mounts 2.1 What are Bind\u00a0Mounts? 2.2 Creating a Bind\u00a0Mount. 2.3 Multiple containers accessing the same Bind\u00a0mount. 2.4 Demonstrating persistence with Bind\u00a0mount. 2.5 Where can we use Bind\u00a0Mounts 2.1 What are Bind\u00a0Mounts? Bind mounts are used for persistence, and they have been available since the early days of docker. When we use a bind mount, a directory on the host is mounted into a container. In bind mounts, the directory is managed by us and not by\u00a0docker. Bind Mounts also come up with a slight disadvantage as the containers have the ability to modify, delete and create resources in the host OS. Attention has to be provided if non-docker elements need to access the mount\u00a0folder. 2.2 Creating a Bind\u00a0Mount The mount flag is used to mention the kind of persistence we require. It could be bind, tmpfs, or volume. In this case, we set it to bind. For creating a bind mount, we need to provide the source path explicitly. It has to be an absolute path and not a relative. The source path is the path in the host. Similarly, we need to provide the target path. This is the path inside the container which we want to\u00a0mount. docker run -d -it -p 5000:5000 --name create_file_py_container1 --mount type=bind,source=\"C:\\Users\\prithiveer\\Documents\\Docker_Bind\",target=/app/docker_bind create_file_py_image With the above command, a container will be created. We sent a request from Postman to create a file named \u201csample_1.txt\u201d with the content \u201cMy first file\u201d. As shown below, we can use exec inside the container and find the file which we\u00a0created. Image by Author\u200a\u2014\u200aCreating a file using create_file_py_container1 2.3 Multiple containers accessing the same Bind\u00a0mount In real life, an application would be hosted in multiple containers, and we require them to be mounted to a single bind mount. So, for demonstration purposes, we create two more containers. docker run -d -it -p 5002:5000 --name create_file_py_container2 --mount type=bind,source=\"C:\\Users\\prithiveer\\Documents\\Docker_Bind\",target=/app/docker_bind create_file_py_imagedocker run -d -it -p 5003:5000 --name create_file_py_container3 --mount type=bind,source=\"C:\\Users\\prithiveer\\Documents\\Docker_Bind\",target=/app/docker_bind create_file_py_image Like the first container, we send requests from containers 2 and 3 and generate files sample_2.txt and sample_3.txt, respectively. While creating the bind mount, we provided a source address. We can find all the files which we created inside the containers in the specified location. Similarly, we can also find all the files in the docker_bind folder of all the 3 containers, irrespective of the files which were created by each container. Image by Author\u200a\u2014\u200aSource Folder has all the files which were created inside the 3 containers 2.4 Demonstrating persistence with Bind\u00a0mount. To demonstrate persistence, we delete all the 3 containers and create them again. Since the data is written to the writable layer when we delete the container, all the data inside the container should be lost. But due to bind mounts, we will be able to see all the files\u00a0created. Image by Author\u200a\u2014\u200aCreating the container again and finding the files created\u00a0earlier 2.5 [&#8230;]",
            "pubdate": "Fri, 16 Dec 2022 00:04:57 +0000",
            "pubdate_parsed": [
                2022,
                12,
                16
            ],
            "email_sent": true
        },
        "The Dark Side of OpenAIs ChatGPT": {
            "url": "https://towardsai.net/p/l/the-dark-side-of-openais-chatgpt",
            "description": "Last Updated on December 16, 2022 by Editorial Team Author(s): Taimur Ijlal Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. How this revolutionary new tool can usher in a new era of cybercrime Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 17 Dec 2022 00:09:49 +0000",
            "pubdate_parsed": [
                2022,
                12,
                17
            ],
            "email_sent": true
        },
        "10 Essential Skills for AI Leaders": {
            "url": "https://towardsai.net/p/l/10-essential-skills-for-ai-leaders",
            "description": "Last Updated on December 19, 2022 by Editorial Team Author(s): Dr. Mandar Karhade, MD. PhD. Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Or Not, No pressure and be an Individual Contributor&#xa0;;) Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 19 Dec 2022 05:13:38 +0000",
            "pubdate_parsed": [
                2022,
                12,
                19
            ],
            "email_sent": true
        },
        "Design your AI Art Generator Prompt Using ChatGPT": {
            "url": "https://towardsai.net/p/l/design-your-ai-art-generator-prompt-using-chatgpt",
            "description": "Last Updated on December 19, 2022 by Editorial Team Author(s): Bildea Ana Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A short guide on how to use ChatGPT to elaborate your text prompts Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 19 Dec 2022 05:13:35 +0000",
            "pubdate_parsed": [
                2022,
                12,
                19
            ],
            "email_sent": true
        },
        "A Visual Journey in What Vision-Transformers See": {
            "url": "https://towardsai.net/p/l/a-visual-journey-in-what-vision-transformers-see",
            "description": "Last Updated on December 22, 2022 by Editorial Team Author(s): Salvatore Raieli Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. How some of the largest models see the\u00a0world image from the original article:\u00a0source Visualizing CNN&#039;s allowed us to learn more about how these models work. Now that Vision Transformers are taking the stage, a new article explains how we can see what these broad models see the world\u00a0as. Visualize the vision transformers image from the original article:\u00a0source Since convolution neural networks (CNN) have emerged as a winning model in computer vision, different research groups have focused on understanding what these models\u00a0learn. On the one hand, neural networks have emerged in several fields (from language analysis to computer vision) but have been considered \u201cblack boxes.\u201d In contrast to many other algorithms, they are much more difficult to interpret. In fact, the more capable the models become (growth in the number of parameters), the more difficult it becomes to be able to understand what is going on\u00a0inside. Therefore, several methods have been developed to visualize what a convolutional neural network learns. Some of the most\u00a0used: Visualize the filters (or visualize the weights). Visualize layer activation To retrieve an image that maximally activates a\u00a0neuron Embedding the feature vectors with\u00a0t-SNE. GradCAM, saliency\u00a0maps. In 2016, transformers appeared on the scene. These wide models based on self-attention have been shown to achieve much superior performance in NLP (machine translation, language classification, and so on). Soon, they became the standard for NLP, and with the introduction of vision transformers, they were also applied to computer\u00a0vision. from the original transformer article:\u00a0here Therefore different researchers have tried to visualize what vision transformers (ViTs) learn. ViTs have proven to be much more difficult to analyze, and so far, the methods used have shown limitations. Understanding the inner workings of these models could be helpful in explaining their success and potential corner\u00a0cases. Previous work had focused on observing the activation of keys, queries, and values from the self-attention layer, but the result was unsuccessful. Visualizing the self-attention weights it is not leading to insightful visualization. caption and image from the original article:\u00a0source A paper has recently been published by researchers at New York University and the University of Maryland that provides a better understanding of what happens inside the model (whether they are vision transformers or models such as\u00a0CLIP). In the article, the researchers summarize their contribution: While standard methods lead to uninterpretable results (especially when applied to keys, queries, and values), it is possible to obtain informative visualizations by applying the same techniques to the next feed-forward layer of the same transformer block (and they demonstrated this using different models: ViTs, DeiT, CoaT, ConViT, PiT, Swin, and Twin transformers). Patch-wise image activation patterns for ViT features behave like saliency maps demonstrating that the model preserves positional relationships between patches (and learns this during training). CNN&#039;s and ViTs construct a complex and progressive representation (in CNNs, the first layers represent edges and textures, while later layers learn more complex patterns, and the authors show that the same happens in ViTs). ViTs, in contrast to CNN&#039;s are better able to use background information. The authors also applied their method to models using language supervision (such as CLIP) and showed that features could be extracted from these models that are associable with caption text (such as prepositions, adjectives, and conceptual categories). The authors compared ViTs to convolutional networks and noted that the representation increases in complexity along the pattern (earlier layers learn simpler structures while more sophisticated patterns are learned by more advanced layers). In practice, both CNN and ViTs share what is called progressive specialization. \u201cThe progression for visualized features of ViT B-32. Features from early layers capture general edges and textures. Moving into deeper layers, features evolve to capture more specialized image components and finally concrete objects.\u201d caption and image from the original article:\u00a0source \u201cComplexity of features vs depth in ViT B-32. Visualizations suggest that ViTs are similar to CNNs in that they show a feature progression from textures to parts to objects as we progress from shallow to deep features.\u201d caption and image from the original article:\u00a0source There are also differences. The authors investigated the reliance of ViTs and CNNs on background and foreground image features (using bounding boxes on ImageNet). ViTs are able to detect background information present in the image (in the image, for example, grass and snow). In addition, by masking the background or foreground in the image the researchers showed that ViTs not only use the background information better but are also less affected by its\u00a0removal. \u201c ViT-B16 detects background features. Left: Image optimized to maximally activate a feature from layer 6. Center: Corresponding maximally activating example from ImageNet. Right: The image\u2019s patch-wise activation map. (b): An example of an original image and masked-out foreground and background.\u201d caption and image from the original article:\u00a0source We find it surprising that even though every patch can influence the representation of every other patch, these representations remain local, even for individual channels in deep layers in the network. While a similar finding for CNNs, whose neurons may have a limited receptive field, would be unsurprising, even neurons in the first layer of a ViT have a complete receptive field. In other words, ViTs learn to preserve spatial information, despite lacking the inductive bias of CNNs. -source: original\u00a0article In other words, during training, the model learns how to preserve spatial information. In addition, the last layer instead has a uniform activation pattern and learns how to classify the image (according to the authors, the last layer has the function of globalizing information). Based on the preservation of spatial information in patches, we hypothesize that the CLS token plays a relatively minor role throughout the [&#8230;]",
            "pubdate": "Thu, 22 Dec 2022 12:15:09 +0000",
            "pubdate_parsed": [
                2022,
                12,
                22
            ],
            "email_sent": true
        },
        "All About Git Branches And Git pull vs fetch": {
            "url": "https://towardsai.net/p/l/all-about-git-branches-and-git-pull-vs-fetch",
            "description": "Last Updated on December 25, 2022 by Editorial Team Author(s): Muttineni Sai Rohith Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. All About Git Branches&#8230; And Git pull vs.\u00a0fetch With Branches in Git, we can create a copy of the file we would like to work on without messing up with the original file. Later we can merge them to the original\u00a0copy. This is the second addition to the series of articles about Git\u200a\u2014\u200aComplete Git Tutorial for Beginners with Examples. The link is available below\u00a0\u2014 Complete Git Tutorial for Beginners with Examples So far, we have created the main branch, pushed our first commit to the branch, and then 2nd commit. Our repo looks like this\u00a0\u2014 Branch Flow Now let&#039;s create a test branch and push our new changes to that branch. We can create a new branch named \u201ctest\u201d using the below command\u00a0&#8211; git checkout -b test In the above command, checkout makes us switch to a branch, and -b helps us in creating the\u00a0branch. Now Let\u2019s add some changes, then add them to our local repo commit and push them to the remote repo with the test\u00a0branch. def add(a, b): return a+b+10 We can add, commit and push changes to the remote repo using the following commands\u00a0\u2014 git add .git commit -m \u201cUpdating the add function with offset 10\u201dgit push origin test Instead of git add\u00a0. and git commit -m \u201cmessage\u201d we can use the following command\u00a0\u2014 git commit -am \"Updating the add function with offset 10\"git push origin test Now our repo looks like this\u00a0&#8211; Branch Flow Now Let\u2019s make another change by changing the offset to 20 and commit and push to the test branch\u00a0again. def add(a, b): return a+b+20 Let\u2019s add, commit and push into the remote\u00a0Repo git commit -a -m \"changing the offset to 20\"git push origin test Output Now as we have some modified code in the test branch, I feel my code is ready, and let\u2019s merge our code with the main\u00a0branch. This can be done using this command\u00a0&#8211; git checkout maingit merge test Here we used checkout to switch the branch, we are not using -b as it is used to create new. And then merge the code using the git merge\u00a0command. Now Below is what our repo looks\u00a0like- Now that we have made many changes to the main branch, let&#039;s see the commit history using the command\u00a0&#8211; git log We can press \u201cq\u201d to come out of the\u00a0log. To make our test branch track the main branch, we can use the below command\u00a0&#8211; git branch - set-upstream-to=origin/main test Pulling a git repo\u00a0branch Now let\u2019s make some changes in the main branch and commit\u00a0this. def add(a, b): return a+bdef sub(a, b): return a-bdef mul(a, b): return a * ba = int(input())b = int(input())print(add(a, b))print(sub(a, b))print(mul(a, b)) Now let&#039;s commit this and push this to the main\u00a0branch. git add .git commit -m \"adding multiplication code\"git push origin main Now in the main branch, we have made our\u00a0changes. Now let\u2019s suppose we need to add another change in the main branch, but as it is in production we have to make sure the testing doesn\u2019t cause any problems. So let\u2019s implement that change in the test branch and then create a pull request to merge that in the main\u00a0branch. But before that, let\u2019s check the code in the test branch. So for that, let\u2019s switch back to the test branch using the command\u00a0&#8211; git checkout test Here we can see the code is not updated. And our test branch Lags one commit behind the main\u00a0branch. To update the code from the main branch we need to give this command\u00a0&#8211; git pull origin main or git pull Pull command helps in pulling the latest changes from our own branch or from the remote\u00a0branch. Whenever we are working in the branches, it is a good practice to pull our changes regularly. Git fetch vs. Git\u00a0pull Git pull will check for any lagging code commits, and if our local repo lags behind any commit, then using Git pull, we can retrieve the updated changes and get them merged. At the same time, git fetch will only retrieve the updated changes in the lagging commits. And then, we should use git merge to merge them in our\u00a0repo. As we can see, after a commit is made, there is no update in the local repo using git status, but when we used git fetch, we got info that our local repo is lagging by 1 commit behind the main repo. So then, we should use the git merge command to merge the\u00a0changes. But all this can be implemented using one command\u00a0&#8211; git pull It will fetch the changes and then merge the changes in our local repo from the remote/origin repo. git pull = git fetch + git merge So that\u2019s all about git branches in this article&#8230; But there is more to cover on Git rebase, Stash, revert and reset. Those will be covered in the below article\u00a0\u2014 Git Rebase, Merge, and Stash Happy Learning\u2026 Stay\u00a0tuned\u2026 All About Git Branches&#8230; And Git pull vs fetch was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 25 Dec 2022 12:23:53 +0000",
            "pubdate_parsed": [
                2022,
                12,
                25
            ],
            "email_sent": true
        },
        "Complete Git Tutorial for Beginners with Examples": {
            "url": "https://towardsai.net/p/l/complete-git-tutorial-for-beginners-with-examples",
            "description": "Last Updated on December 25, 2022 by Editorial Team Author(s): Muttineni Sai Rohith Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Git is a version control system that lets us track the changes we make to our files over time. With Git we can revert to various states of our files. We can make a copy of our files and make changes to that copy and then merge these changes to the original copy.We can install git using this official\u00a0website. Photo by Luke Chesser on\u00a0Unsplash Configuring git:To verify git installation, we can open git bash and type the git\u200a\u2014\u200aversion command. This shows the latest version of git installed on our\u00a0PC. git --version Output The first thing we have to do is to set our username and email address. Git uses this information to identify who made changes to specific files. To set our username and email id, we can use the below commands\u00a0&#8211; git config --global user.name \u201cOur_username\u201dgit config --global user.email \u201cOur_email\u201d Output This will configure our Git environment. To check whether the configuration is succeeded, we can still check our configuration in the local machine using this command\u00a0\u2014 git config -l We can also store credentials in the cache, Just to avoid giving them each time using the below command\u00a0&#8211; git config --global credential.helper cache Cloning existing git repo to local &#8211;We can clone the existing git repo into the local machine using the command\u00a0&#8211; git clone https://ourrepo Output Creating and Initializing a new project in GitCreate a new folder or navigate to the folder where you want to create your first project. I have used git bash to create a folder test_calculator using the below commands\u00a0\u2014 mkdir test_calculatorcd test_calculator Alternatively, you can Open the folder you like through File Explorer, Right click on it and select Git Bash\u00a0Here Output Now once the folder is ready, we need to initialize the project, For this, we need to run the git init command. This will tell git to start watching our files, for every change that\u00a0occurs. Output Now let\u2019s add a small block of code to our Folder.I am writing a small python program calculator.py for that, which contains a function, that will take two numbers, a and b as arguments and return the\u00a0result. def add(a, b): return a+b a = int(input())b = int(input())print(add(a, b)) Now that we have added our changes to the folder, let\u2019s check whether git has tracked our changes. This can be done using the git status\u00a0command. git status Output We can see our branch name, if there are any past commits to our branch done us, And then any updated/untracked files that are not synced with the\u00a0git. To add the updated changes or untracked files, we need to use the command\u00a0\u2014 git add . This will add all the untracked changes. Output Now after performing git add\u00a0.\u00a0; We can see that our change is tracked with the git. And we can see the changes that are yet to be committed.To commit our changes, we can use this command git commit -m \u201cfirst commit\u201d\u00a0command. git commit -m \u201cfirst commit\u201d -m is the shorthand for the message and the text inside the parentheses is the commit\u00a0message. Output Now Our code is ready and committed. Now let\u2019s push our code to the\u00a0repo. For that to happen, let\u2019s create a Repo in GitHub. This can be done by logging in to GitHub and clicking on Repos -&#62; new -&#62; Enter Repo Name and click on create. This is my Repo link\u200a\u2014\u200ahttps://github.com/muttinenisairohith/test_calculator.git Later we need to create a connection between our local repo and the remote repo in Github. For that, we can use this command\u00a0&#8211; git remote add origin https://github.com/muttinenisairohith/test_calculator.git As we have our remote connection ready now. By default, git will point to the Master branch, but instead of the master branch, I want to push my changes to the main branch. For that, we can use the command\u00a0\u2014 git branch -b main Now We have our repo and branch ready, Let\u2019s push our modified code to our Branch in the Repo Created. For this, we can use the following command\u00a0&#8211; git push -u origin main This will push our changes to the main branch, and if it is our first time, it will ask us to Login into Git. We can log in to git using our email id and password. Output Git vs\u00a0GitHub Generally, people think Git and Github are similar, But they are not. As said, Git is a version control system that tracks our changes to the repo and provides us various functionalities like time traveling etc., Whereas Github is an Online hosting service for Git Repositories. Similar to Azure DevOps Services, bitbucket, etc., Github helps us to store our repo in their platform and allow other developers to contribute at the same time from any location. As we have pushed our first git project to Github, Moving further, Let\u2019s understand the stages of a file being tracked by\u00a0Git. Committed State\u200a\u2014\u200aA file is in the committed state when all the changes made to the file have been saved in the local repo. Files in the committed stage are files ready to be pushed to the remote repo (on\u00a0GitHub) Modified state\u200a\u2014\u200aA file in the modified state has some changes made to it, but it\u2019s not yet saved. This means that the state of the file has been altered from its previous state in the committed state Staged state\u200a\u2014\u200aA file in the staged state means it is ready to be committed. In this state, all necessary changes have been made, so the next step is to move the file to the commit\u00a0state. Now Moving Further let\u2019s add a functionality subtraction to our code and save that again\u00a0&#8211; def add(a, b):return [&#8230;]",
            "pubdate": "Sun, 25 Dec 2022 12:23:50 +0000",
            "pubdate_parsed": [
                2022,
                12,
                25
            ],
            "email_sent": true
        },
        "Maximizing ROI with Digital Twins: A Cost-Benefit Analysis": {
            "url": "https://towardsai.net/p/l/maximizing-roi-with-digital-twins-a-cost-benefit-analysis",
            "description": "Last Updated on December 25, 2022 by Editorial Team Author(s): Ishaan Gill Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Digital twins have been gaining significant traction in a wide range of industries in recent years, and for a good reason. A digital twin&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 25 Dec 2022 12:23:47 +0000",
            "pubdate_parsed": [
                2022,
                12,
                25
            ],
            "email_sent": true
        },
        "Evolution of AI and Data Science in 2022": {
            "url": "https://towardsai.net/p/l/evolution-of-ai-and-data-science-in-2022",
            "description": "Last Updated on December 25, 2022 by Editorial Team Author(s): Anmol Tomar Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. What can we expect in 2023 Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 25 Dec 2022 12:05:25 +0000",
            "pubdate_parsed": [
                2022,
                12,
                25
            ],
            "email_sent": true
        },
        "How to Identify Objects at Pixel Level using Deep Learning in Java": {
            "url": "https://towardsai.net/p/l/how-to-identify-objects-at-pixel-level-using-deep-learning-in-java",
            "description": "Last Updated on December 25, 2022 by Editorial Team Author(s): Xin Yang Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. with Deep Java\u00a0Library Semantic segmentation is a powerful technique in deep learning that allows for the identification of objects in images at the pixel level. The goal of semantic segmentation is to label each pixel of an image with a corresponding class. In this blog post, we will explore how to use semantic segmentation to identify objects in images in\u00a0Java. Note that semantic segmentation is different from instance segmentation, which is able to distinguish several instances belonging to the same class. Therefore, if we have two objects of the same category in the input image, the segmentation map will give the same label for the two objects. To distinguish separate instances of the same class, please refer to instance segmentation. Semantic segmentation can be applied to a wide range of use cases like self-driving cars, visual image search, medical imaging, and so on. For example, semantic segmentation can be used to accurately identify and classify different objects in the environment, such as pedestrians, vehicles, traffic signs, and buildings. Semantic segmentation for self-driving cars\u00a0(Source) Deep Java Library (DJL) is a Java-based Deep Learning (DL) Framework. It can be used to create and train models, as well as run inference. DJL provides enriched functionalities to apply Semantic Segmentation to use cases. In this post, we are going to demo how to employ these functionalities to achieve some common use\u00a0cases. Prerequisites To get started, we first need to declare the DJL dependencies in the module\u2019s build.gradle file: dependencies { implementation \"ai.djl:api:0.20.0\" runtimeOnly \"ai.djl.pytorch:pytorch-engine:0.20.0\" runtimeOnly \"ai.djl.android:pytorch-native:0.20.0\"} Run Inference Once we have dependencies set up, we can start writing code to run inference. In this example, we will use the DeepLabV3 model, which is a state-of-art model for semantic segmentation. To run inference for Semantic Segmentation, first load the Semantic Segmentation model. Then create a predictor with the given Model and Translator. In this case, SemanticSegmentationTranslator will be\u00a0used. After loading the model, feed the model an image and receive a \"segmentation map\" as output. This can be done by calling Predictor.predict(). The predictor takes an Image as input, and returns a CategoryMask as output. The CategoryMask contains a 2D array representing the class of each pixel in the original image. We can use the following code to do\u00a0this: String url = \"https://mlrepo.djl.ai/model/cv/semantic_segmentation/ai/djl/pytorch/deeplabv3/0.0.1/deeplabv3.zip\";Criteria&#60;Image, CategoryMask&#62; criteria = Criteria.builder() .setTypes(Image.class, CategoryMask.class) .optModelUrls(url) .optTranslatorFactory(new SemanticSegmentationTranslatorFactory()) .optEngine(\"PyTorch\") .optProgress(new ProgressBar()) .build();try (ZooModel&#60;Image, CategoryMask&#62; model = criteria.loadModel(); Predictor&#60;Image, CategoryMask&#62; predictor = model.newPredictor()) { CategoryMask mask = predictor.predict(img); // Do something with `mask`} For example, suppose we have a 600x800x3 RGB color\u00a0image: The output CategoryMask contains a 600\u00d7800\u00d71 mask array representing the class labels as integers. Below is the downsampled mask\u00a0array: DJL also provides utilities for visualizing the results of semantic segmentation, such as the ability to overlay the segmentation map on top of the original image to highlight the areas that the model has classified as belonging to a specific class. These can be useful for a variety of use\u00a0cases. Use Cases Use Case 1: Self-Driving Cars One use case for semantic segmentation is to enable self-driving cars to perceive and understand their surroundings. For example, by accurately identifying the positions of other vehicles on the road, the self-driving car can make informed decisions about how to navigate through traffic. Similarly, by accurately identifying pedestrians and other obstacles, the self-driving car can take appropriate actions to avoid collisions. To identify the objects in an image, call Predictor.predict() to feed the model with the image\u00a0below: CategoryMask mask = predictor.predict(img); Street scene\u00a0(Source) Then, to visualize the result, call CategoryMask.drawMask() to highlight the detected objects on the\u00a0image. mask.drawMask(img, 180, 0); Use Case 2: Extract object from\u00a0photo Another use case for semantic segmentation is in the process of extracting objects from photos for passport applications. For example, consider a scenario where an individual is required to submit a passport-style photo as part of their application. In this case, the goal might be to use semantic segmentation to extract the individual\u2019s face from the photo and use it to generate a passport-style photo that meets the required specifications. To extract the face in an image, call Predictor.predict() to feed the model with the image\u00a0below: CategoryMask mask = predictor.predict(img); Portrait image\u00a0(Source) Then call the CategoryMask.getMaskImage() method. Note that 15 is the ID of the person&#039;s\u00a0class. Image person = mask.getMaskImage(img, 15);person = person.resize(img.getWidth(), img.getHeight(), true); Use Case 3: Replace background for video conferences The third use case for semantic segmentation is in the process of replacing the background in an image for video conferences. For example, consider a scenario where an individual is participating in a video conference and wants to replace the background behind them with a more professional or appealing image. In this case, we could use semantic segmentation to automatically extract their foreground (e.g., their body and any objects they are holding) from the background of the\u00a0image. To achieve this, we can extract the individual\u2019s foreground from the background of the image. The extracted foreground can then be composited onto a new background image. This allows the individual to replace the background in the image with a more professional or appealing image, which can be useful for video conferences where the individual wants to present a more polished appearance. To extract the foreground in an image, call Predictor.predict() to feed the model with the image\u00a0below: CategoryMask mask = predictor.predict(img); Video conference scene\u00a0(Source) Then replace the background with another\u00a0image: Image background = ImageFactory.getInstance().fromFile(Paths.get(\"image_path\"));Image person = mask.getMaskImage(img, 15);person = person.resize(img.getWidth(), img.getHeight(), true);background.drawImage(person, true); You can find more DJL example code\u00a0here. DJL also provided an Android app with semantic_segmentation which can take a picture and run semantic segmentation with a variety of\u00a0options. Conclusion [&#8230;]",
            "pubdate": "Mon, 26 Dec 2022 00:13:08 +0000",
            "pubdate_parsed": [
                2022,
                12,
                26
            ],
            "email_sent": true
        },
        "My Pandas Cheatsheet for Exploratory Analysis and Data Manipulation": {
            "url": "https://towardsai.net/p/l/my-pandas-cheatsheet-for-exploratory-analysis-and-data-manipulation",
            "description": "Last Updated on December 28, 2022 by Editorial Team Author(s): Eugenia Anello Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Top 12 Pandas functions that can help you to analyze and manipulate fastly your dataset Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 29 Dec 2022 00:18:37 +0000",
            "pubdate_parsed": [
                2022,
                12,
                29
            ],
            "email_sent": true
        },
        "AI Anyone Can Understand: Part 8The Monte Carlo Method": {
            "url": "https://towardsai.net/p/l/ai-anyone-can-understand-part-8%e2%80%8a-%e2%80%8athe-monte-carlo-method",
            "description": "Last Updated on December 29, 2022 by Editorial Team Author(s): Andrew Austin Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Understanding the basics of the Monte Carlo method Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 29 Dec 2022 12:15:56 +0000",
            "pubdate_parsed": [
                2022,
                12,
                29
            ],
            "email_sent": true
        },
        "A Guide to MLOps in Production": {
            "url": "https://towardsai.net/p/l/a-guide-to-mlops-in-production",
            "description": "Last Updated on January 1, 2023 by Editorial Team Author(s): Prithivee Ramalingam Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. with Azure DevOps, Azure Kubernetes Service, and Azure Machine\u00a0Learning Introduction Countless hours of organized effort are required to bring a model to the production stage. The efforts which were spent on all the previous steps would turn out to be fruitful only if the model is successfully deployed. For deploying the model to production, we must consider an architecture that is secure, highly available, fault-tolerant, and capable of autoscaling. If you have figured out where I am going with this, then kudos to you. Yes, Kubernetes is the ideal candidate for our job. But setting up a Kubernetes cluster is not an easy task. We have to set up and configure load balancers, ingresses, role-based authentication, Virtual Machines, network policies, and so on. This requires a considerable amount of time which can be better spent perfecting our model. That\u2019s why Kubernetes as a Service (Kaas) is the preferred option under these circumstances. This article illustrates the whole lifecycle of MLOps, starting from training the model to deploying it in a production environment. The whole process is automated. The CI pipeline gets triggered whenever we make a code change, and the CD pipeline gets triggered whenever there is a new artifact available or if the CI pipeline gets completed successfully. In this way, the new functionality can be deployed with just a single commit. The below image provides a high-level overview of the whole\u00a0process. Image By Author\u200a\u2014\u200aHigh-level overview of MLOps\u00a0example If you require an End-to-End example of a CI-CD pipeline for development and QA environments, you can refer to my article -&#62; End-to-end example of CI-CD pipeline using Azure Machine Learning &#124; by Prithivee Ramalingam &#124; Apr, 2022 &#124; Towards\u00a0Dev Content Prerequisites. Code walkthrough. Creating a CI pipeline in Azure DevOps to train the model and publish the artifact. Creating a CD pipeline to deploy the model in Azure Kubernetes Service\u00a0(AKS). Testing the model deployed in\u00a0AKS. 1. Prerequisites: 1.1 Azure Devops\u00a0account 1.2 Azure Machine Learning\u00a0resource 1.3 Azure Kubernetes Service (AKS)\u00a0cluster 1.4 Resource Manager connection 1.1 Azure DevOps\u00a0account Azure DevOps Server is a Microsoft product that provides version control, project management, automated builds, testing, and release management capabilities. To create an Azure DevOps account, please follow these instructions. In a production setup, automation must be preferred over manual interference. We need to automate the process of creating builds and deploying them to a Kubernetes cluster. For this use case, we make use of the pipelines provided by Azure DevOps. We create a Continuous Integration (CI) pipeline for creating a model and packaging it and a Continuous Deployment (CD) pipeline for deploying the model in Kubernetes. 1.2 Azure Machine Learning\u00a0resource Azure Machine Learning is a cloud service for accelerating and managing the machine learning project lifecycle. Azure Machine Learning, teamed up with MLFlow, providing a centralized repository to host docker images, runs, environments and artifacts. It provides functionality to create compute clusters and instances. For additional information regarding Azure Machine Learning, you can refer to my article https://medium.com/mlearning-ai/features-and-capabilities-of-azure-machine-learning-868eb3b4d333. In this production setup, we are going to use Azure ML for logging metrics, saving model artifacts, creating an AKS cluster, and deploying the model in the created cluster. While creating an Azure Machine Learning workspace, Blob storage, a Key vault, a Container registry, and an application insights service are created along with\u00a0it. 1.3 Azure Kubernetes Service (AKS)\u00a0cluster Azure Kubernetes Service (AKS) offers the quickest way to start developing and deploying cloud-native apps in Azure. With the abstraction provided by Azure Machine Learning, we can manage deployment in AKS by configuring just a few variables. We can attach an existing AKS cluster or create a new one with Azure\u00a0ML. Image by Author\u200a\u2014\u200aInference clusters 1.4 Resource Manager connection A Resource manager connection is essential to automate model training, model packaging, model deployment, etc.. Azure ML is the place that centralizes the whole MLOps process. So, we need to access Azure ML securely to perform the above steps. One way is going to Azure ML workspace and setting the resources manually. But in order to do it in an automated manner, we require a resource manager connection which will help us manage the resources in Azure ML from Azure\u00a0DevOps. We should create the Resource Manager connection in Azure DevOps. We can assign the scope to the Subscription level, Management Group level, or to Machine Learning Workspace level. We can also limit access to the pipelines which can access this Service Principal. Project Settings -&#62; Service Connections -&#62; New Service connections -&#62; Azure Resource Manager -&#62; Service Principal (automatic) -&#62; Scope\u00a0level 2. Code walkthrough. After creating all the required prerequisites, the next step is to write code for training and inference and to push it into a version control system like git or Azure DevOps. You can access the source code\u00a0here. Image by Author\u200a\u2014\u200aFolder structure 2.1 Training\u00a0script 2.2 Inference scripts 2.1 Training\u00a0script The training script consists of training.py and files in the environment_setup directory. The environment_setup directory consists of install-requirements.sh, conda_dependencies.yml, and runconfig files. install-requirements.sh -&#62; Has the dependencies which have to be installed in the\u00a0agent. conda_dependencies.yml -&#62; Has the dependencies which have to be installed in the compute target. The dependencies are abstracted as environments. runconfig file (titanic_survival_prediction.runconfig) -&#62; The driver file for the whole training logic. During execution, the runconfig file gets visited first. From there information such as the location of training.py file, environment details, docker image details, and location of conda dependency files are obtained. framework: Pythonscript: training.pycommunicator: NoneautoPrepareEnvironment: truemaxRunDurationSeconds:nodeCount: 1environment: name: titanic_prediction_environment python: userManagedDependencies: false interpreterPath: python condaDependenciesFile: .azureml/conda_dependencies.yml baseCondaEnvironment: docker: enabled: true baseImage: mcr.microsoft.com/azureml/base:intelmpi2018.3-ubuntu16.04 sharedVolumes: true gpuSupport: false shmSize: 1g arguments: []history: outputCollection: true snapshotProject: true [&#8230;]",
            "pubdate": "Mon, 02 Jan 2023 00:08:32 +0000",
            "pubdate_parsed": [
                2023,
                1,
                2
            ],
            "email_sent": true
        },
        "Building A LSTM From Scratch In Python": {
            "url": "https://towardsai.net/p/l/building-a-lstm-from-scratch-in-python",
            "description": "Last Updated on January 2, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. How to build a basic LSTM using Basic Python libraries Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 02 Jan 2023 12:05:14 +0000",
            "pubdate_parsed": [
                2023,
                1,
                2
            ],
            "email_sent": true
        },
        "Generative AI: What Will Change in 2023": {
            "url": "https://towardsai.net/p/l/generative-ai-what-will-change-in-2023",
            "description": "Last Updated on January 5, 2023 by Editorial Team Author(s): Rafe Brena, PhD Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. It&#x2019;s not just GPT-4 Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 06 Jan 2023 00:19:07 +0000",
            "pubdate_parsed": [
                2023,
                1,
                6
            ],
            "email_sent": true
        },
        "Topic Modeling for E-commerce Reviews using BERTopic": {
            "url": "https://towardsai.net/p/l/topic-modeling-for-e-commerce-reviews-using-bertopic",
            "description": "Last Updated on January 6, 2023 by Editorial Team Author(s): Eugenia Anello Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. A step-by-step guide for training your unsupervised model using a new and improved way to deal with the dataset Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 06 Jan 2023 12:16:46 +0000",
            "pubdate_parsed": [
                2023,
                1,
                6
            ],
            "email_sent": true
        },
        "Conversational AI: 7 Trends and Predictions for 2023": {
            "url": "https://towardsai.net/p/l/conversational-ai-7-trends-and-predictions-for-2023",
            "description": "Last Updated on January 6, 2023 by Editorial Team Author(s): Patrick Meyer Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. I present seven new trends and predictions on the evolution of the conversational assistant market (commonly called Chatbots) for 2023. In&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 07 Jan 2023 00:18:43 +0000",
            "pubdate_parsed": [
                2023,
                1,
                7
            ],
            "email_sent": true
        },
        "The Art and Science of Regularization in Machine Learning: A Comprehensive Guide": {
            "url": "https://towardsai.net/p/l/the-art-and-science-of-regularization-in-machine-learning-a-comprehensive-guide",
            "description": "Last Updated on January 6, 2023 by Editorial Team Author(s): Data Science meets Cyber Security Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. REGULARIZATION IN MACHINE LEARNING: A PRACTICAL GUIDE INTRODUCTION: Are you tired of your machine learning models performing poorly on new data? Are you sick of seeing your model\u2019s validation accuracy skyrocket only to crash and burn on the test set? If so, it\u2019s time to learn about regularisation! Regularisation is a technique that is used to prevent overfitting in machine learning\u00a0models. SOURCE: https://giphy.com/ LET\u2019S GET OUR BASICS CLEAR FIRST\u00a0: We\u2019ll go through some interesting analogies and practical implementation of concepts to get things crystal clear in our\u00a0heads. SOURCE: https://giphy.com/ OVERFITTING\u00a0: Overfitting occurs when a model is too complex and fits the training data too well, but is not able to generalise well to new, unseen data. This can lead to poor performance on the test set or in real-world applications. LET\u2019S UNDERSTAND IT WITH MORE BETTER\u00a0ANALOGY: Imagine a child who has learned to recognize dogs by seeing pictures of only golden retrievers. When shown a picture of a different dog breed, such as a poodle, the child is unable to recognize it as a dog because they have only learned to recognize a specific type of dog rather than having a general understanding of what features define a dog. This is similar to how a model can overfit the training data and be unable to generalize well to new, unseen\u00a0data. LET\u2019S LOOK THROUGH IT PRACTICALLY: import numpy as npimport matplotlib.pyplot as plt # Generate datax = np.linspace(-5, 5, 100)y = x**3 + np.random.normal(0, 10, 100) # Create figure with larger sizefig, ax = plt.subplots(figsize=(10, 6)) # Plot dataax.plot(x, y, &#039;o&#039;)plt.show() This generates a set of 100 x-values and corresponding y-values, with the y-values being a cubic function of the x-values with some added noise. The data is plotted as\u00a0follows: IMAGE SOURCE: BY\u00a0AUTHOR Next, we can fit a polynomial regression model to the\u00a0data: from sklearn.linear_model import LinearRegressionfrom sklearn.preprocessing import PolynomialFeatures # Create polynomial featurespoly = PolynomialFeatures(degree=10)x_poly = poly.fit_transform(x.reshape(-1, 1)) # Fit model to datamodel = LinearRegression()model.fit(x_poly, y) # Predict on original x valuesy_pred = model.predict(x_poly) # Create figure and plot datafig, ax = plt.subplots(figsize=(10, 6))ax.plot(x, y, &#039;o&#039;, label=&#039;True data&#039;)ax.plot(x, y_pred, &#039;o&#039;, label=&#039;Predicted data&#039;)ax.legend() # Display figureplt.show() This fits a polynomial regression model with a degree of 10 to the data, which is a very high degree and results in a very complex model. The model has plotted along with the original data as\u00a0follows: IMAGE SOURCE: BY\u00a0AUTHOR CONCLUSION: We can see that the model is able to fit the training data very well but is not able to generalize well to new, unseen data. This is an example of overfitting, as the model has learned the specific patterns in the training data but has not developed a general understanding of the underlying relationships in the\u00a0data. To prevent overfitting, we can use techniques such as regularisation or early stopping to reduce the complexity of the model and improve its generalization performance. UNDERFITTING: Under-fitting, on the other hand, occurs when a model is too simple and is unable to capture the underlying patterns in the data. This can also lead to poor performance, but for a different reason. LET\u2019S UNDERSTAND IT WITH MORE BETTER\u00a0ANALOGY: One way to understand underfitting is through the analogy of a student preparing for a test. Imagine that a student is studying for a history test and is given a textbook to read. However, the student only reads the first few pages of the textbook and does not fully grasp the material. On the day of the test, the student is unable to answer even the most basic questions because they have not learned enough about the\u00a0subject. This is similar to how a model can underfit the training data. The model is too simple and is unable to capture the underlying patterns in the data, leading to poor performance on the training set and poor generalization to new, unseen\u00a0data. On the other hand, if the student had taken the time to read and fully understand the entire textbook, they would have been better equipped to perform well on the test. Similarly, a model that has not underfitted to the training data and has a good generalization performance will be able to make accurate predictions on the training data and new, unseen\u00a0data. Here is a simple code example that demonstrates underfitting using a linear regression model: import numpy as npimport matplotlib.pyplot as pltfrom sklearn.linear_model import LinearRegression # Generate synthetic datax = np.linspace(-5, 5, 50)y = x**2 + np.random.normal(0, 10, 50) # Fit linear modelmodel = LinearRegression()model.fit(x.reshape(-1, 1), y) # Predict on training datay_pred = model.predict(x.reshape(-1, 1)) # Create figure with specified sizeplt.figure(figsize=(10, 6)) # Plot data and predictionsplt.plot(x, y, &#039;o&#039;, label=&#039;True data&#039;)plt.plot(x, y_pred, &#039;o&#039;, label=&#039;Predicted data&#039;)plt.legend() # Save figure to fileplt.savefig(&#039;figure.png&#039;, bbox_inches=&#039;tight&#039;) # Show plotplt.show() IMAGE SOURCE: BY\u00a0AUTHOR CONCLUSION\u00a0: In this example, we generate synthetic data that follows a quadratic trend and fit a linear model to the data. We can see that the linear model is unable to capture the underlying quadratic trend and is under-fitting to the data, resulting in poor performance on the training\u00a0set. \u201cFeeling lost when it comes to the connection between bias, variance, under-fitting, and overfitting? Don\u2019t worry, I\u2019ve got the answers you\u00a0need!\u201d BIAS, VARIANCE, AND ITS CONNECTION TO OVERFITTING AND UNDERFITTING: SOURCE: https://giphy.com/ BIAS and VARIANCE are two important concepts that describe the error of a machine learning model. Bias refers to the error due to incorrect assumptions in the model, while variance refers to the error due to the complexity of the\u00a0model. In general, we want to find a model that has low bias and low variance, as this will result in good generalization performance [&#8230;]",
            "pubdate": "Sat, 07 Jan 2023 00:18:41 +0000",
            "pubdate_parsed": [
                2023,
                1,
                7
            ],
            "email_sent": true
        },
        "5 Growing Libraries in Python for Causality Analysis": {
            "url": "https://towardsai.net/p/l/5-growing-libraries-in-python-for-causality-analysis",
            "description": "Last Updated on January 7, 2023 by Editorial Team Author(s): Dr. Alessandro Crimi Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. not only for neuroimaging Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 07 Jan 2023 12:15:58 +0000",
            "pubdate_parsed": [
                2023,
                1,
                7
            ],
            "email_sent": true
        },
        "Effective Categorical Variable Encoding for Machine Learning": {
            "url": "https://towardsai.net/p/l/effective-categorical-variable-encoding-for-machine-learning",
            "description": "Last Updated on January 7, 2023 by Editorial Team Author(s): Filipe Filardi Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Image by DCStudio on\u00a0Freepik A categorical variable is a common type of data found in many machine learning datasets. Effective handling of categorical variables can be crucial for building successful models since it contains rich information that can be used to predict outcomes in Machine Learning. However, working with categorical variables can be challenging, as many models are designed to handle numerical data. As a result, some people may need clarification about correctly processing categorical data, leading to confusion and potentially suboptimal model performance. This article aims to provide a clear and comprehensive overview of the most popular approaches to handling categorical data in Machine Learning. By understanding the different options available and their implications, I hope to provide readers the knowledge and tools they need to handle categorical data in their Machine Learning projects. Categorical Data in Machine\u00a0Learning Categorical data consists of data that can be classified into categories. In machine learning, it is common to encounter categorical data from variables such as gender, race, nationality, genre, or occupation. Categorical data is often present in real-world datasets, and it is vital to handle it properly. One of the main challenges of working with categorical data is that most machine learning algorithms are designed to work with numerical data. This means that categorical data must be transformed into a numerical format to be used as input to the\u00a0model. Dealing with categorical data This section will explore some popular methods for dealing with categorical data in machine learning. What is \u201cReplacing for Numbers\u201d? Replacing for numbers refers to the process of replacing a categorical variable with a numerical value. For example, continuing with the example above, if we replaced the categorical variable with numerical values, we would get the following: Example of Replacing &#124; Image by\u00a0Author Here\u2019s the python code using replace in a Pandas data frame as a reference: df.replace({&#039;rock&#039;: 0, &#039;jazz&#039;: 1, &#039;blues&#039;: 2}) What is a \u201cLabel Encoder\u201d? Label Encoder is another method for encoding categorical variables. It assigns a unique numerical value to each category in the categorical variable. Using Label Encoder on the previous example would result in the same values as replacing. While replace might be a suitable approach for a small number of categories, it can become impractical when dealing with many categories. Example of Label Encoder &#124; Image by\u00a0Author Here\u2019s the Python code using the Label\u00a0Encoder: from sklearn import preprocessingle = preprocessing.LabelEncoder()le.fit(df[&#039;genres&#039;])df[&#039;genres&#039;] = le.transform(df[&#039;genres&#039;]) What is converting to a \u201cdummy variable\u201c? It is the process of creating a new binary column for each category in a categorical variable, with a 0 or 1 indicating the presence or absence of that category, such\u00a0as: Example of Dummy &#124; Image by\u00a0Author There are two ways of doing that. The first is using get_dummies() of Pandas\u00a0library: import pandas as pdX_encoded = pd.get_dummies(df, columns=[&#039;genres&#039;]) The other is using OneHotEncoder() of Scikit-learn (sklearn): from sklearn.preprocessing import OneHotEncoderenc = OneHotEncoder()enc.fit(df)X_encoded = enc.transform(df).toarray() Dummifying and One Hot Encoding are essentially the same things. The main difference is that \u201cdummify\u201d is a more colloquial term, and \u201cOne Hot encoding\u201d is the technical term used in the machine learning literature. Why are Dummies Preferred Over the other solutions? There are several reasons why Dummies are generally preferred over other encoding\u00a0methods: Avoiding implied ordinal relationships and preventing bias Dummies create separate columns for each category, allowing the model to learn the relationships between the individual categories and the target variable. Replacing for numbers and label encoder, on the other hand, imply an ordinal relationship between the categories and does not create separate columns for each category, which can lead to misleading results if the categories do not have an inherent\u00a0order. For example, suppose you replace \u201crock\u201d with 1, \u201cjazz\u201d with 2, and \u201cblues\u201d with 3 in your dataset. In that case, your model may assume that \u201cjazz\u201d is twice as important as \u201crock\u201d and \u201cblues\u201d is three times as important as \u201crock\u201d. This can introduce bias into the model, as it makes assumptions about the order in which you assign the\u00a0numbers. Dummies allow the model to learn more complex relationships Because it creates separate columns for each category, the model can learn more complex relationships between the categories and the target variable. On the other hand, the other mentioned encoders only allow the model to learn the overall relationship between the numerical value and the target variable, which may not capture the full complexity of the\u00a0data. When to Avoid\u00a0Dummies There are certain situations in which Dummies may not be the best approach. Here are the most important ones: High cardinality: One Hot Encoding creates a separate column for each category in the categorical variable. This can lead to a high number of columns, especially if the categorical variable has many unique values. In such cases, One Hot Encoding may result in a sparse and unwieldy data set, which can be challenging to work\u00a0with. Memory constraints: One Hot Encoding can also be problematic if the data set is large and requires a lot of memory to store. The resulting data set can take up a lot of space, which may not be feasible if memory is\u00a0limited. Multicollinearity: Occurs when there is a high correlation between the dummy variables, which can cause the coefficients in the model to be unstable and difficult to interpret. Dummy variables are naturally correlated because they are created from the same categorical variable. In these situations, alternative encoding methods, such as label encoder or target encoding, may be more appropriate, which can handle high cardinality more efficiently. If you are interested in learning more about multicollinearity and target encoding, there are many other resources available. [&#8230;]",
            "pubdate": "Sun, 08 Jan 2023 00:13:46 +0000",
            "pubdate_parsed": [
                2023,
                1,
                8
            ],
            "email_sent": true
        },
        "Exposing the Racial Divide in Data Science: The Reality of Discrimination and How to Overcome It": {
            "url": "https://towardsai.net/p/l/exposing-the-racial-divide-in-data-science-the-reality-of-discrimination-and-how-to-overcome-it",
            "description": "Last Updated on January 9, 2023 by Editorial Team Author(s): Andrew Austin Originally published on Towards AI the World&#8217;s Leading AI and Technology News and Media Company. If you are building an AI-related product or service, we invite you to consider becoming an AI sponsor. At Towards AI, we help scale AI and technology startups. Let us help you unleash your technology to the masses. Racism in Data Science: A Call to Address the Inequalities within the Field Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. It\u2019s free, we don\u2019t spam, and we never share your email address. Keep up to date with the latest work in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 10 Jan 2023 00:13:54 +0000",
            "pubdate_parsed": [
                2023,
                1,
                10
            ],
            "email_sent": true
        },
        "Fully Understand Convolutional Neural Networks Components": {
            "url": "https://towardsai.net/p/l/fully-understand-convolutional-neural-networks-components",
            "description": "Last Updated on January 10, 2023 by Editorial Team Author(s): Amit Chauhan Originally published on Towards AI. Terms and technology in the artificial intelligence world Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 10 Jan 2023 12:12:14 +0000",
            "pubdate_parsed": [
                2023,
                1,
                10
            ],
            "email_sent": true
        },
        "Ultimate MLOps Learning Roadmap with Free Learning Resources In 2023": {
            "url": "https://towardsai.net/p/l/ultimate-mlops-learning-roadmap-with-free-learning-resources-in-2023",
            "description": "Last Updated on January 11, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. In today&#x2019;s hype of Machine learning where many organizations have integrated or are trying to integrate ML systems into their products and&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 11 Jan 2023 12:11:05 +0000",
            "pubdate_parsed": [
                2023,
                1,
                11
            ],
            "email_sent": true
        },
        "Machine Learning for Documents": {
            "url": "https://towardsai.net/p/l/machine-learning-for-documents",
            "description": "Last Updated on January 11, 2023 by Editorial Team Author(s): Sean Benhur Originally published on Towards AI. Photo by Romain Dancre on\u00a0Unsplash Documents carry the essential source of vital information. Much of the structured and unstructured information of the enterprises is available as Documents. These are available in the form of native PDF documents and scanned PDF documents such as Bank Invoices, Legal documents, and verification ID cards, over the time information on these documents is used for many applications using techniques such as Optical Character Recognition(OCR), Computer Vision(CV) and Natural Language Processing(NLP) Document AI refers to the Artificial Intelligence techniques that are applied to analyze and understand documents for various tasks. Notable tasks include Form/Invoice extraction, Optical Character Recognition, Table Detection, and Table Extraction. In this article, we will look\u00a0on The major tasks and datasets that are prevalent in Document\u00a0AI. The Methodologies such as recent research papers, pretrained models, and existing techniques for each task are discussed. Current issues in this\u00a0domain. Tasks and\u00a0Datasets Different types of tasks are prevalent in Document AI to solve many business use cases. In many cases, some of the tasks are used together to solve one use case. For example, for an invoice extraction task, it is common to use an OCR system to extract the text from the pdf and a Visual Information Extraction system to recognize the entities. In this section, we will look over each task and the common dataset that is used for that\u00a0task. Optical Character Recognition Optical Character Recognition(OCR) refers to the texts in which we recognize and extract the text. It is an important task in the Document AI pipeline. OCR is also one of the hardest tasks since the text could be in different formats and quality of the scanned document can be low and the handwriting of the text can be in poor formats. There are many benchmarks and datasets available for this task; the famous dataset MNIST is a type of OCR dataset. Other benchmarks include IAM Handwriting which consists of handwritten document images, and ICDAR 2003, consisting of images of scene understanding. Document Layout\u00a0Analysis This task refers to identifying the structure and layout of the document, such as the paragraphs, tables, and charts identified. ICDAR 2013 is one of the popular benchmarks for this task which includes text images of word-level annotations; another dataset is PubLayNet which consists of document images annotated on the structure level, such as text, table, figure, and other similar categories. Visual Information Extraction This refers to the task of extracting key information from the documents. In this task, only key entities are extracted, unlike OCR, where the entire text is extracted but here, only the text of the key entities and the spatial information of the same. Invoice extraction, Form extraction are some of the Visual Information Extraction tasks. Benchmarks include FUNSD, which consists of annotated forms with information on semantic entities, Named Entities, and Spatial Information. CORD is another benchmark that consists of images of receipts annotated on each text region with spatial-level information. Image of an annotated receipt indicating the coordinates of the text in JSON format [Source]. Document Visual Question Answering This task refers to answering questions based on the text provided in the document. This task is different from the other Visual Question Answering tasks due to the complex nature of the document images. Usually, the text is extracted first with the OCR model, and then the modeling is done. DocVQA is the first dataset that introduced this task; it has two subtasks in which the first one contains a single document image and a question and the second one consists of a collection of document images and a single question. Example Image from the DocVQA\u00a0[Source] Document Image Classification In this task, the images of the documents are classified into the type of documents such as invoices, legal documents, resumes, and many others.RVL-CLIP is a popular benchmark used for this task, it consists of images of sixteen categories, such as memos, emails, scientific reports, and file\u00a0folders. Table Detection and Table Extraction Tables are an important source of information in any document, it mainly consists of numerical information. In this task, we focus on recognizing where the table is located on the document and extracting the information inside it. This task also has some subtasks, such as Table structure recognition, where the rows, the columns, and the cells of the table are identified, and another subtask, Table Functional Analysis, in which the key value is extracted. PubTables-1M is a recently released dataset that consists of 948K annotated PDFs for the tasks of Table Detection, Table Structure Recognition, and Table Functional Analysis. Different Tasks in Table Detection [Source] Methodologies The images of the documents are different from the normal images as it contains some tables, numerical information, and text. The location of these texts is also needed for some of the tasks mentioned above. Before the advent of deep learning, most of the above tasks were solved through rule-based systems and heuristics with several Image processing algorithms and OCR techniques. In this section, we will go over an overview of some methods to solve these tasks as well as the recent research breakthroughs in this\u00a0area. Deep Learning based techniques After the advent of Deep Learning and the rise of CNNs, many computer vision methods have been used for these tasks. Tasks such as Document Layout Analysis and Table Detection tasks are entirely treated as Object Detection tasks where object detection models such as RCNN, Faster-RCNN, and YOLO are\u00a0used. For Document Image Classification, the common approaches that are used for Natural Image Classification can be used. Some approaches, such as Dauphnee et al., used textual and visual content to classify the documents. Tasks on which the text is also an important source of information such as Visual Document Extraction and Document Visual Question Answering. The baseline approach is to use a pipeline consisting of an Object Detection model for locating the word labels, a NER model for [&#8230;]",
            "pubdate": "Thu, 12 Jan 2023 00:13:25 +0000",
            "pubdate_parsed": [
                2023,
                1,
                12
            ],
            "email_sent": true
        },
        "Can AI Models be Common Sense Enabled?": {
            "url": "https://towardsai.net/p/l/can-ai-models-be-common-sense-enabled",
            "description": "Last Updated on January 12, 2023 by Editorial Team Author(s): Poornachandra Sarang Originally published on Towards AI. Building machines with human-level intelligence Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 13 Jan 2023 00:14:03 +0000",
            "pubdate_parsed": [
                2023,
                1,
                13
            ],
            "email_sent": true
        },
        "Demystifying ChatGPT!": {
            "url": "https://towardsai.net/p/l/demystifying-chatgpt",
            "description": "Last Updated on January 13, 2023 by Editorial Team Author(s): Michele De Filippo, PhD Originally published on Towards AI. The Revolution of Conversational AI has just started! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 14 Jan 2023 00:13:45 +0000",
            "pubdate_parsed": [
                2023,
                1,
                14
            ],
            "email_sent": true
        },
        "Feature selection for unsupervised problems: the case of clustering": {
            "url": "https://towardsai.net/p/l/feature-selection-for-unsupervised-problems-the-case-of-clustering",
            "description": "Last Updated on January 14, 2023 by Editorial Team Author(s): Kevin Berlemont, PhD Originally published on Towards AI. Feature Selection for Unsupervised Problems: The Case of Clustering Photo by NASA on\u00a0Unsplash With the massive growth of data over the last decade, selecting the right feature is becoming a major challenge. A well-known technique in data processing consists of dimensionality reduction. This process tries to remove redundant and irrelevant features that would degrade the performance. These methods can be categorized between feature extraction/construction and feature selection. In the case of feature extraction, the dimensionality of the data is reduced by deriving new features based on the original ones. Examples of this process are Principal Component Analysis [1] and Singular Value Decomposition [2]. On the other hand, feature selection tries to select a subset, ideally small, of relevant features. This approach is needed when there is a large number of features in the dataset and the goal is to reduce the computational complexity and obtain generalizable models. Feature selection approaches usually require class labels to determine whether a feature is relevant or not. However, when the class labels are unknown, such as for clustering, how can a feature be classified as relevant? Feature selection can be categorized in four categories: Filters methods try to select an optimal feature subset according to the general characteristics of the data but not from a learning algorithm. In general, filters compute the score of a subset of features using specific evaluation criteria. Wrappers methods need a learner to evaluate the goodness of the feature subsets. Thus, they are computationally more expensive but will increase the performance of a specific learning algorithm. Hybrid methods try to get the advantages of both methods above by incorporating them in a two-stage process. Embedded methods embed features directly into the learning algorithm. However, they often don\u2019t reach better performances than wrappers. Next, I will describe specific feature selection methods for all of these different categories, highlighting when and how to use\u00a0them. Filter Approaches Filters select features in the data according to the characteristics of features. They directly evaluate the statistical performance of features in the data. A proposed filter approach [3] is to measure the dependencies between features based on a variance-based metric (maximal information compression index, MICI). This approach divides features into clusters in a similar way to the k-nearest neighbor algorithm. In each iteration, the k nearest features are found for each feature based on the MICI. Afterward, the feature which builds the most compact subset is selected, and the procedure is repeated until all features are selected or discarded. Another filtering method consists in selecting features using the Pearson correlation coefficient. First, all possible pairwise correlations between features and data are computed. Then, it removes the feature with the highest average dependency on other features. Afterward, the process is repeated until the number of features wanted is\u00a0reached. As shown with these two examples, filter methods are usually general as they don\u2019t rely on a specific learning algorithm. However, their clustering performances are usually lower than the ones of wrapper methods, which will be the focus of the next\u00a0section. Wrappers Approach for\u00a0K-means In this section, I will focus on the K-means algorithm for clustering, as the wrapper approaches are specific to the algorithm picked. For more details about other models, such as evolutionary algorithms, I recommend the following paper\u00a0[4]. K-means is one of the most popular clustering algorithms in Data Science, but one of its main deficiencies is that it evaluates all the features with equal importance. Thus, in the case of a significant number of irrelevant features, the quality of the clustering process will decrease. In this context, it is useful to give certain features more importance by weighting them. The convex K-means algorithm [5] improves the standard K-means algorithm by integrating an adaptive weighting scheme in K-means. It attempts to iteratively determine the optimal weights of a feature set by minimizing the average within-cluster distance. One caveat to this approach is that the minima search can be stuck in a local optimum due to gradient descent\u00a0search. Another well-known feature weighting approach for K-means consists in attribute weighting clustering. Each feature can have different weights at different clusters. The goal is then to minimize the sum of the weighted distances within the clusters. This method and variants have been really successful at clustering, but they are highly dependent on the hyperparameter keeping the weights at a reasonable level. Embedded Approaches For embedded approaches, the feature selection process is performed as a part of the learning process. Due to their performances and interpretability, embedded approaches usually make use of a sparse learning algorithm. First, it finds the cluster labels using a clustering algorithm, and it then transforms the unsupervised feature selection into a supervised context. One of the earliest sparse learning feature selection methods is multi-cluster feature selection. In the first step, the intrinsic structure of the data is explored using spectral analysis in order to measure the correlation between features. In the second step, the importance of the features is quantified using an L1-regularized regression model. The last step consists in selecting the specified number of features with the highest coefficients from the previous stage. This approach has been proven efficient at feature selection for clustering but is computationally expensive. The previous method consists in the conventional sparse learning feature selection approach that requires the cluster labels to be generated by a clustering algorithm before transforming the problem into a supervised feature selection problem. However, this approach has the tendency to cause non-optimal feature subsets. To address this, embedded unsupervised feature selection directly embeds feature selection into a clustering algorithm without the transformation. It applies K-means by minimizing the reconstruction error to obtain the cluster labels and select the features. However, it is necessary to be careful about the heterogeneity between clusters with this approach as it has the tendency to select non-discriminative features otherwise. Hybrid Approaches In recent years, hybrid approaches for feature selections have [&#8230;]",
            "pubdate": "Sat, 14 Jan 2023 12:15:25 +0000",
            "pubdate_parsed": [
                2023,
                1,
                14
            ],
            "email_sent": true
        },
        "How To Build A Data Science Portfolio That Will Land You A Job?": {
            "url": "https://towardsai.net/p/l/how-to-build-a-data-science-portfolio-that-will-land-you-a-job",
            "description": "Last Updated on January 15, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. &#x650;A Step by Step Practical Guide to Building A Data Science Portfolio Projects Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 15 Jan 2023 12:10:50 +0000",
            "pubdate_parsed": [
                2023,
                1,
                15
            ],
            "email_sent": true
        },
        "How to Track ML Experiments With DVC Inside VSCode To Boost Your Productivity": {
            "url": "https://towardsai.net/p/l/how-to-track-ml-experiments-with-dvc-inside-vscode-to-boost-your-productivity",
            "description": "Last Updated on January 17, 2023 by Editorial Team Author(s): BEXGBoost Originally published on Towards AI. Manage ML experiments like a pro Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 17 Jan 2023 12:05:01 +0000",
            "pubdate_parsed": [
                2023,
                1,
                17
            ],
            "email_sent": true
        },
        "Learn Reinforcement Learning from Top Universities": {
            "url": "https://towardsai.net/p/l/learn-reinforcement-learning-from-top-universities",
            "description": "Last Updated on January 17, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. Reinforcement learning (RL) is a rapidly growing field that is revolutionizing the way machines learn to make decisions. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 18 Jan 2023 00:08:13 +0000",
            "pubdate_parsed": [
                2023,
                1,
                18
            ],
            "email_sent": true
        },
        "Why Having the Right Strategy of MLOps is Important?": {
            "url": "https://towardsai.net/p/l/why-having-the-right-strategy-of-mlops-is-important",
            "description": "Last Updated on January 18, 2023 by Editorial Team Author(s): Sumit Singh Originally published on Towards AI. Photo by Kaleidico on\u00a0Unsplash The last decades have seen incredible advancement in the field of AI and machine learning. What previously has been a research topic and was accessible to only a handful of scientists and researchers is now accessible to entry-level engineers and students. But as technology grew and the industry-wide applications started rolling out, so did the complexities and challenges. Building an ML model to do basic stuff like identifying a few household objects or human activities to say 70% confidence is a common thing, but to achieve 99% accuracy in identifying cancers or tumors in a medical image is a different thing. What it takes to build a production-level AI To solve any industrial use case, ML teams have to manage a scale, which means a high volume of data to be processed, the right algorithm selection, and a vast amount of iterations. It involves a significantly bigger team with different expertise, and to manage the overall process, one needs to implement the right process and strategy. That process is called\u00a0MLOps. What are the MLOps components? Every team has its unique set of requirements, and based on their goals, the implementation might differ, but components of MLOps will largely remain the\u00a0same. MLOps can range from data pipeline to model output in some cases, while other projects may only require MLOps execution of the model deployment process. The majority of businesses use MLOps principles in the following areas: Exploratory data analysis\u00a0(EDA) Data preparation and feature development Model development and refinement Model evaluation and governance Serving and model inference Model monitoring Model retraining that is automated Let\u2019s understand each component one by\u00a0one- 1. Exploratory Data Analysis (EDA): EDA is a process to analyze and summarize a data set, typically with the goal of finding patterns or relationships between variables. It involves using visualizations, statistical techniques, and other methods to explore the data in order to gain insight and better understand the data\u00a0set. 2. Data preparation: It is the process of cleaning, transforming, and organizing raw data so that it can be used for analysis, modeling, and other\u00a0tasks. Let\u2019s say you have a data set of customer\u00a0records. You might need to preprocess the data by normalizing the values, removing invalid or missing data, converting categorical data into numerical values, and scaling the data so that the values fall within a specific\u00a0range. Once the data is preprocessed, it can then be used for machine learning or other data analysis\u00a0tasks. 3. Feature development: is the process of creating new variables from existing data, either through combining existing variables or by extracting new information from existing\u00a0data. To understand this, let\u2019s say you have a data set containing customer records that include information about their age, gender, location, and purchase\u00a0history. You can create new features from this data by combining existing variables, such as creating a \u201ctotal purchases\u201d feature by adding up all the customers\u2019 purchase histories, or by extracting new information from existing data, such as creating a \u201clocation density\u201d feature by counting the number of customers in a given location. These new features can then be used for machine learning or other data analysis\u00a0tasks. 4. Model development and refinement: is the process of creating, testing, and refining a mathematical model to fit observed\u00a0data. This process typically involves selecting the appropriate model type, specifying the parameters and variables, and fitting the model to the observed\u00a0data. Once the model has been created, it can be used to make predictions and to explain relationships between variables. One example of this would be a machine learning model trained on a data set to predict customer\u00a0churn. The model would be tested on a validation data set, and any errors or inconsistencies in the model\u2019s performance would be identified and addressed by refining the model parameters or introducing new features to improve the model\u2019s accuracy. Once the model has been refined and is performing appropriately, it can be used for predictive analytics and other applications. 5. Model evaluation: It involves assessing the accuracy, reliability, and validity of the model, while model governance involves establishing policies and procedures to ensure that the model is used in an ethical and responsible manner. Model evaluation and governance are important in ensuring that models are used responsibly and produce reliable\u00a0results. An example of model evaluation and governance is the use of a risk assessment process to evaluate the accuracy and reliability of a model before it is deployed for use in decision-making. This process involves assessing the data used to train the model, assessing the performance of the model on a validation data set, and assessing whether the model is ethically sound and is being used in a responsible manner. If any issues are identified, the model can be revised or adjusted to improve accuracy and reliability and to ensure that it is being used responsibly. 6. Serving and model inference: is the process of deploying a trained machine learning model and using it to make predictions and inferences about\u00a0data. This process typically involves deploying the model to a server, where it can be used to make predictions and inferences on new\u00a0data. Additionally, the process may involve collecting feedback from users to ensure that the model is providing accurate and useful predictions and inferences. Let\u2019s understand this with an example using a trained deep-learning model to classify\u00a0images. The model would be deployed to a server, where it could be used to make predictions on new\u00a0images. In order to ensure that the model\u2019s performance is accurate, the model would be evaluated on a validation data\u00a0set. The model would also be monitored to ensure that it is performing correctly and efficiently, and feedback from users would be collected to ensure that the model is providing accurate and useful predictions. 7. Model monitoring: is the process of tracking the performance of a machine learning model over\u00a0time. It involves tracking metrics such as accuracy, precision, recall, and false [&#8230;]",
            "pubdate": "Wed, 18 Jan 2023 12:05:40 +0000",
            "pubdate_parsed": [
                2023,
                1,
                18
            ],
            "email_sent": true
        },
        "Create Your Own YouTube Video Summarizer App in Just 3 Easy Steps": {
            "url": "https://towardsai.net/p/l/create-your-own-youtube-video-summarizer-app-in-just-3-easy-steps",
            "description": "Last Updated on January 18, 2023 by Editorial Team Author(s): Asish Biswas Originally published on Towards AI. Build GPT-3 powered video summarizer to identify the important glimpse of your favorite video. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 19 Jan 2023 00:06:29 +0000",
            "pubdate_parsed": [
                2023,
                1,
                19
            ],
            "email_sent": true
        },
        "LLMs Encode Clinical Knowledge:A Review": {
            "url": "https://towardsai.net/p/l/llms-encode-clinical-knowledge-a-review",
            "description": "Last Updated on January 19, 2023 by Editorial Team Author(s): Ronny Polle Originally published on Towards AI. LLMs Encode Clinical Knowledge: A Quick\u00a0Review Outline Introduction Contributions Limitations Conclusion References Introduction In the field of medicine, language is an enabler of key interactions for and between clinicians, researchers, and patients. This provides opportunities for leveraging LLMs for modeling properties of textual data in the medical\u00a0domain. There is evidence that LLMs can act as implicit knowledge bases. The weights of these networks store information, resulting in information that is pliable and hence can be operated upon in a representation space. This phenomenon equips LLMs with an ability to form associations between stored information to produce meaningful insights. The unfortunate news is that this associative capability can lead to hallucinations as information stored in weights is unreliable. Hence, current AI models for applications to medicine and healthcare lack the ability to address significant gaps in effectively leveraging language as a tool for mediating real world clinical workflows. For instance, LLMs are found to have the potential to mirror misinformation,bias, and stereotypes in the\u00a0corpus. With the profound advances made by LLMs, AI systems are undergoing innovative repurposing and helping address limitations posed by predominantly single-task AI\u00a0systems. Contribution Key contributions made in this study can be summarised across the following three\u00a0axes; Dataset benchmark Framework for human evaluation Modeling Firstly, this paper introduces a dataset benchmark for medical question answering called MultiMedQA. This benchmark is a collection of six open-question-answering datasets\u200a\u2014\u200aMedQA [jin2021disease], MedMCQA [pal2022medmcqa], PubMedQA [jin2019pubmedqa], LiveQA [abacha2017overview], MedicationQA [abacha2019bridging], and MMLU clinical topics [hendrycks2020measuring]). MedQA mirrors the US Medical License Exam (USMLE) style of questions. Furthermore, this benchmark is augmented by HealthSearchQA, the seventh dataset comprising curated commonly searched consumer health queries in\u00a0English. Secondly, a robust human-centric evaluation framework is proposed to address some of the current limitations with automated metrics for assessing long-form answer generation, such as the bilingual evaluation understanding metric (BLEU). Clinicians and lay users (non-experts) are captured in the evaluation of the models\u2019 generative output. The clinician\u2019s evaluation is run along twelve different evaluation axes whilst lay users are evaluated along two unique axes. These include\u200a\u2014\u200ahow well the models\u2019 output agrees with scientific consensus; the possibility and the likelihood of harm; evidence of comprehension, reasoning, and retrieval ability; the presence of inappropriate, incorrect, or missing content; the possibility of bias in the answer; answer captures user intent and helpfulness of the\u00a0answer. Thirdly, this paper highlighted how well LLMs encode clinical knowledge with major architectural modifications. The authors built on the Pathway Language Model (PaLM) and Flan-PaLM family of LLMs. PaLM is a transformer model architecture composed of a decoder-only setup, with key features such as\u200a\u2014\u200aSwiGLU activation function to substitute for standard activation functions(ReLU, Swish, GeLU), parallel transformer layers, multi-query attention mechanism, rotary position embeddings (ROPE) as a substitute for absolute or relative position embeddings, shared-input output embeddings, zero bias kernels, and layer normalizations, and use of a SentencePiece vocabulary. Leveraging the PaLM baseline and instruction prompt tuning paradigms, the authors demonstrated the Flan-PaLM variant to gain superior performance across a suite of evaluation tasks over the baseline. Comparison with prior\u00a0SOTA Moreover, given the key limitations of domain adaptation methods and end-to-end finetuning of the model using copious amounts of in-domain data, the authors successfully investigated prompting and prompt-tuning to aid Flan-PaLM in adapting to the medical domain. The instruction prompt tuning technique designed in this study incorporates soft-prompt learned by prompt-tuning as an initial prefix that is shared across multiple medical datasets, followed by a task-specific human-engineered prompt alongside the original question and/or\u00a0context. Instruction prompt tuning for\u00a0Med-PaLM Limitations Although promising, the dataset benchmark fails to cover multiple languages and excludes a larger variety of medical and scientific domains, hence partially reflecting real-world clinical workflows. Secondly, although Flan-PaLM was able to reach state-of-the-art performance on several medical questions and answering benchmarks, there are important gaps to be bridged in order for it to reach an expert clinician level on many clinically important axes. Important future directions proposed to help address this challenge include\u200a\u2014\u200aestablishing solid grounds for the models\u2019 responses in authoritative medical sources and accounting for the time-varying nature of medical consensus, the ability to effectively quantify and communicate uncertainty to a generic user-in-the-loop, and multilingual support for responses. Secondly, it is critical to conduct exhaustive work to improve the human evaluation framework. The pilot rating framework is not very exhaustive as it fails to capture important variations across diverse population groups. Also, the pool of clinicians and lay-users assessing the model responses is limited. Lastly, the evaluation framework failed to investigate the impact of variation in the clinician rater\u2019s medical specialty, demographics, and geography. Moreover, fairness and equity are underexplored in this study, especially the lacking understanding of how perturbations to demographic identifiers in prompts influence the model outputs. Also, the safety-critical and complex requirements of the medical domain pose an important question as to how the approach of sampling clinicians to participate in identifying the best-demonstration prompts examples and crafting few-shot prompts impacts the overall behavior of\u00a0LLMs. In conclusion, I am fascinated by the performance of LLMs demonstrated in this rigorous study. Not only does it exemplify a successful application and evaluation of LLMs in the medical context, but also, it demonstrates exciting directions for future research and improvements. Overview of Contributions Thank you for reading\u00a0\ud83d\ude42 References [1] Large Language Models (LLMs) encode clinical knowledge [2] Galactica: A Large Language Model for\u00a0Science [3] PaLM\u00a0: Scaling Language Modeling with\u00a0Pathways LLMs Encode Clinical Knowledge\u00a0:A Review was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 19 Jan 2023 13:19:40 +0000",
            "pubdate_parsed": [
                2023,
                1,
                19
            ],
            "email_sent": true
        },
        "Soccer and Data Science: Decision Tree explained by Ibra and Muriqi": {
            "url": "https://towardsai.net/p/l/soccer-and-data-science-decision-tree-explained-by-ibra-and-muriqi",
            "description": "Last Updated on January 19, 2023 by Editorial Team Author(s): Andrea Ianni Originally published on Towards AI. The Decision Tree explained by our Pirate Vedat, Felipe and Ibrahimovic. Machine Learning and Artificial Intelligence playing in Serie A..! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 19 Jan 2023 13:19:36 +0000",
            "pubdate_parsed": [
                2023,
                1,
                19
            ],
            "email_sent": true
        },
        "How To Create Highly-Organized ML Projects Anyone Can Reproduce With DVC Pipelines": {
            "url": "https://towardsai.net/p/l/how-to-create-highly-organized-ml-projects-anyone-can-reproduce-with-dvc-pipelines",
            "description": "Last Updated on January 19, 2023 by Editorial Team Author(s): BEXGBoost Originally published on Towards AI. What is a machine learning pipeline? Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 19 Jan 2023 12:24:33 +0000",
            "pubdate_parsed": [
                2023,
                1,
                19
            ],
            "email_sent": true
        },
        "Meta-Learning for Time Series Forecasting (DeepTime) in PyTorch Lightning": {
            "url": "https://towardsai.net/p/l/meta-learning-for-time-series-forecasting-deeptime-in-pytorch-lightning",
            "description": "Last Updated on January 19, 2023 by Editorial Team Author(s): Reza Yazdanfar Originally published on Towards AI. This article is devoted to describing a new type of deep learning model to cope with the usual problems in time series (covariate shift&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 20 Jan 2023 00:02:41 +0000",
            "pubdate_parsed": [
                2023,
                1,
                20
            ],
            "email_sent": true
        },
        "Simple But Effective Free Roadmap to Start A Career in Data Science & AI In 2023": {
            "url": "https://towardsai.net/p/l/simple-but-effective-free-roadmap-to-start-a-career-in-data-science-ai-in-2023",
            "description": "Last Updated on January 20, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. Whether you&#x2019;re a recent graduate or a professional looking to make a career change, the field of Data Science and AI offers a wide range&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 21 Jan 2023 00:16:29 +0000",
            "pubdate_parsed": [
                2023,
                1,
                21
            ],
            "email_sent": true
        },
        "As a Data Scientist, You Should Know About a Clever Horse Called Hans": {
            "url": "https://towardsai.net/p/l/as-a-data-scientist-you-should-know-about-a-clever-horse-called-hans",
            "description": "Last Updated on January 22, 2023 by Editorial Team Author(s): Leon Eversberg Originally published on Towards AI. Learn about the Clever Hans effect in machine learning Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 23 Jan 2023 00:21:27 +0000",
            "pubdate_parsed": [
                2023,
                1,
                23
            ],
            "email_sent": true
        },
        "An Introduction to CNNs: Understanding the Basics": {
            "url": "https://towardsai.net/p/l/an-introduction-to-cnns-understanding-the-basics",
            "description": "Last Updated on January 25, 2023 by Editorial Team Author(s): Pranay Rishith Originally published on Towards AI. Exploring how powerful CNN is: from\u00a0basics Photo by Denys Nevozhai on\u00a0Unsplash Introduction CNN Source Convolutional neural networks are a deep learning concept that was specifically built for processing images. Machine learning is a concept where a computer learns from past experiences. Deep Learning is an advanced part of machine learning. CNN is designed to find visual patterns. When we humans see images, we see objects, colors, etc. We learn these things as we grow up, but computers can only understand 0\u2019s and 1\u2019s, i.e., binary values. Then how will computers see\u00a0images? Every image is made up of pixels. The below image is a good depiction of how a computer reads images. There are two types of images, Grayscale and Color. Grayscale(black and white) is made up of an array of values that range from 0 to 255(black to white). Color images have 3 arrays, red array, green array, and blue array(RGB). Also each of those arrays ranging from 0 to 255(black to corresponding colors). MIT deep learning lecture 3\u00a0source If a grayscale image has a size of 1080&#215;1080 then the total number of values is 1080x1080x1 whereas a color image has 1080x1080x3(3 as in\u00a0R+G+B). Architecture A convolutional neural network has 3 types of layers: convolution layer, pooling layers, and fully connected layers. Convolutional Layers The convolutional Layer is the layer where important features are extracted from input images. This layer uses a small square to extract features from the input image. This small square is called a kernel or filter. To explain, There is a mathematical operation in this layer between the input image and a filter in order to preserve and extract features. This is called Feature extraction in\u00a0CNN. Size of feature map:\u00a0n-f+1 n = size of\u00a0input f = size of\u00a0filter By author With different filters, different operations can be performed like edge detection, blur,\u00a0etc. MIT deep learning lecture 3\u00a0Source To perform a convolution operation, a filter should be specified as a certain size. The filter moves across the input image matrix and multiplies values with filter and summing. The result is smaller in size than the input image matrix size. To sum up, in CNN convolutional layer is the most important step or layer. This is used to extract important features from the input image matrix. A CNN can consist of any number of convolutional layers. Non-Linear Layer This layer is added after every convolutional layer to introduce non-linearity to the matrix. Non-linearity is introduced so that the output is not affected by the input or the output is not proportional to the input. This nonlinearity is done by activation functions. That topic is for another\u00a0article. Why do we need non-linearity in the neural network? might be a question. If the data doesn\u2019t have non-linearity, then the input is directly influencing the output, and it doesn\u2019t matter how many layers we use. The outcome will be the same. By increasing the power of non-linearity, the network is created to find more new and unique patterns in the\u00a0data. The commonly used activation functions are RELU, Tanh,\u00a0etc. Padding Now you have understood how important is the convolutional layer. A kernel or filter is used to extract important features. I mentioned that the convolutional layer could be used any number of times, and every time the size of the feature map decreases. We don\u2019t need that. Consider an input matrix of 5&#215;5 and a filter of size 3&#215;3. The size of the feature map is 5\u20133+1 = 3. If we add another layer, then the size is\u00a01. To make a feature map of size of same as the input matrix, we use padding. Let\u2019s reverse engineer. We need a feature map of size 5. The filter size is 3. from the above formula, n = 5+f-1 = 5+3\u20131 = 7. We need an input matrix of size 7 from a size 5 input matrix. We add padding, i.e., a row on top, bottom, and column on left and right, giving a matrix of size 7&#215;7. now the math, n-f+1 = 7\u20133+1 = 5. Hence\u00a0proved. Padding formula =\u00a0n+2p-f+1 p =\u00a0padding If p = 1, then one row and one column, so thats why we add 2p, so we get 2 rows and 2\u00a0columns. The above-added rows and columns are filled with zeros, called as zero\u00a0padding. by author This is how padding is\u00a0applied. Strides We talked about filters in the convolutional layer. Strides are defined as the number of pixels to move in any direction to apply the filter. If the stride is [1,1], then the filter moves 1 pixel at a time in either direction, and if it is [2,2] then the filter moves 2 pixels in either direction. This parameter is mainly useful when there is an input image with high resolution, then more pixels to filter. The larger the stride, the smaller the convolution features\u00a0map. by author A [1,1] looks like the\u00a0above. by author A [2,2] stride looks like the\u00a0above. To summarize, Strides is a value where the kernel or filter will move on the input\u00a0matrix. Pooling Layers If deducing the input image to 1/4 determines what the whole image depicts, then it is no good in processing the whole image. This is where pooling comes into\u00a0place. This is the layer where the large feature matrix is reduced by retaining features. This is called spatial spacing. Pooling also has a kernel and strides. There are different types of spatial\u00a0spacing. by author Max Pooling: This is where the largest element in the filter is selected. Min Pooling: This is where the least element in the filter is selected. Mean Pooling: This is the mean of all the elements in the\u00a0filter. Average Pooling: This is the average of all the elements in the\u00a0filter. This pooling layer is mainly used to connect Convolutional Layer and the Fully connected layer. The main reason the pooling layer is used after the convolutional layer because to reduce feature [&#8230;]",
            "pubdate": "Wed, 25 Jan 2023 13:22:18 +0000",
            "pubdate_parsed": [
                2023,
                1,
                25
            ],
            "email_sent": true
        },
        "MLflow: The Solution for Managing Complex Machine Learning Projects": {
            "url": "https://towardsai.net/p/l/mlflow-the-solution-for-managing-complex-machine-learning-projects",
            "description": "Last Updated on January 25, 2023 by Editorial Team Author(s): Himanshu Tripathi Originally published on Towards AI. MLflow is an open-source platform that streamlines machine learning development by managing the lifecycle of models, data sets&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 25 Jan 2023 13:22:16 +0000",
            "pubdate_parsed": [
                2023,
                1,
                25
            ],
            "email_sent": true
        },
        "This Is the Model That Will Power Googles Alternative To ChatGPT": {
            "url": "https://towardsai.net/p/l/this-is-the-model-that-will-power-googles-alternative-to-chatgpt",
            "description": "Last Updated on January 25, 2023 by Editorial Team Author(s): Jesus Rodriguez Originally published on Towards AI. LaMDA is positioned to power the next generation of large language models from Google. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 25 Jan 2023 13:03:01 +0000",
            "pubdate_parsed": [
                2023,
                1,
                25
            ],
            "email_sent": true
        },
        "Python: Top Programming Language for Data ScienceIntro and Implementation": {
            "url": "https://towardsai.net/p/l/python-top-programming-language-for-data-science%e2%80%8a-%e2%80%8aintro-and-implementation",
            "description": "Last Updated on January 27, 2023 by Editorial Team Author(s): Farzad Mahmoodinobar Originally published on Towards AI. Python: Language of Choice for Data Scientists Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 27 Jan 2023 13:19:02 +0000",
            "pubdate_parsed": [
                2023,
                1,
                27
            ],
            "email_sent": true
        },
        "ChatGPT on a Scientific Paper as a Co-author? Does It Even Make Sense?": {
            "url": "https://towardsai.net/p/l/chatgpt-on-a-scientific-paper-as-a-co-author-does-it-even-make-sense",
            "description": "Last Updated on January 27, 2023 by Editorial Team Author(s): The Tech Insider Originally published on Towards AI. Exploring the implications of using AI as a co-author in scientific research Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 27 Jan 2023 13:03:08 +0000",
            "pubdate_parsed": [
                2023,
                1,
                27
            ],
            "email_sent": true
        },
        "Police Fatalities Forecasting With Prophet": {
            "url": "https://towardsai.net/p/l/police-fatalities-forecasting-with-prophet",
            "description": "Last Updated on January 27, 2023 by Editorial Team Author(s): Andrea Ianni Originally published on Towards AI. At the end of the article there is a little surprise for you and&#x2026; no please, don&#x2019;t go directly there! Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 27 Jan 2023 13:03:05 +0000",
            "pubdate_parsed": [
                2023,
                1,
                27
            ],
            "email_sent": true
        },
        "How Exploratory Data Analysis Helped Me Solve Million-Dollar Business Problems": {
            "url": "https://towardsai.net/p/l/how-exploratory-data-analysis-helped-me-solve-million-dollar-business-problems",
            "description": "Last Updated on January 27, 2023 by Editorial Team Last Updated on January 27, 2023 by Editorial Team Author(s): Puneet Jindal Originally published on Towards AI. Photo by Luke Chesser on\u00a0Unsplash EDA is a powerful method to get insights from the data that can solve many unsolvable problems in business. In the increasingly competitive world, understanding the data and taking quicker actions based on that help create differentiation for the organization to stay\u00a0ahead! Before moving ahead, let me share the official definition mentioned on the\u00a0internet Exploratory Data Analysis (EDA) is a process of analyzing data sets in order to summarize their main characteristics [1][2], often using statistical or graphical techniques. It is used to discover trends [2], patterns, relationships, and anomalies in data, and can help inform the development of more complex models [3]. It can also be used to generate hypotheses and test them, identify important variables, detect outliers, and assess relationships among variables. EDA is an iterative process, and is used to uncover hidden insights and uncover relationships within the\u00a0data. Let me walk you through the definition of EDA in the form of a story. This story is very personal to me due to the fact that this moment added to my conviction to enter the data science field and explore it further to create a social impact in the\u00a0world. Disclaimer:- i would not name the organization to which this story belongs to avoid any sort of revealing any confidential information. When I interview many newbies, their story is usually about entering Data Science because it is termed the sexiest job of the 21st century. But I didn\u2019t about data science in a way on how it is known. My case was purely accidental and driven by curiosity. I started my journey as a software engineer around technologies such as web stack including python, javascript, and java stack. I got very passionate about building products where I could see the impact in front of me. To that end, I started picking up more responsibilities such as managing databases both SQL and\u00a0NoSQL. One day, I finished my assigned work, and I heard a senior business colleague of mine complaining about data accessibility to my dept head. He mentioned that his team was trying to download business reports. The majority of the downloads were failing, or downloads were very slow and this was impacting his team\u2019s efficiency and leading to job dissatisfaction every\u00a0day. Because of this, they asked my tech dept. head to add more high-end servers, and high-speed internet, and purchase high-memory laptops for his team to look at the reporting data as they were struggling to even the downloaded files in case it gets downloaded. This meant a huge IT investment ask. I volunteered to look at the issue and did the following steps. First, I got access to the data reporting system so that I could download the data from the server logging database. The data was in the form of JSON, and so it had to be converted into some easy-to-understand format such as CSV or any other tabular\u00a0format. So I planned to use pandas, and it was in a few MBs, so I could do the analysis on my laptop with 16GB\u00a0RAM. Then, I loaded these server logs JSON into Jupyter Notebook and installed various libraries such as Pandas and Matplotlib. With Pandas, I loaded JSON files into a data frame so that I could perform data transformations such as extracting hours of the day for all the records,\u00a0etc. You can learn about such transformation operations at https://towardsdatascience.com/how-to-convert-json-into-a-pandas-dataframe-100b2ae1e0d8 Pandas helped me reformat data in a easy to analyze format and matplotlib helped me plot the charts on the\u00a0data If you want to dive deep into Pandas and Matplotlib on a sample dataset as a beginner, you can follow the video\u00a0below. What I did next found patterns and basis that I plotted charts such as downloads happening by user or server CPU utilization by hours of the day etc. What I got was something mind-boggling. 3 simple insights but actionable ones! All of the users across the company were downloading all the data in the morning between say 10 am -11 am, and the rest of the day, servers were completely idle. Further, when I had a discussion with the team, they had to remove the irrelevant data after downloading all of the data, and as the database was getting bigger, the download size was getting larger. This meant that they were unnecessarily downloading 10x more data, almost all of the database, including historical data, which they didn&#039;t even need for most of the day-to-day decision-making. There were users who didn\u2019t need the data but were still requesting the data and exchanging that data over emails as\u00a0well. Actions taken to above insights\u00a0gained Peak server capacity was only needed for a few minutes in the day when the user needed data access, so we built a scalable solution to adjust server size dynamically for optimum utilization, which is a version of today\u2019s serverless computing systems. So the server would only be billed for the time users requested for the reports according to the size of the\u00a0query. A UI interface was built to provide relevant filters such that only required data could be downloaded by the users, such as team-wise access to limited reports. Later we went to automate this to complete Business Intelligence and Reporting tool having aggregated and detailed\u00a0charts. data governance\u200a\u2014\u200aDifferent roles were assigned to users based on their needs such that they could only access the data they should have access\u00a0to. Benefits from the above\u00a0insights Optimum utilization of server capacity helped reduce server costs equivalent to 2 hours instead of 24\u00a0hours. Improved efficiency of the team member because of the speed of downloading while providing relevant data without purchasing new high-end laptops helping with unavoidable IT infra expenditure Enable data compliance and\u00a0security By now, whatever I explained is nothing but an Exploratory data analysis process. Loved the following depiction of a\u00a0workflow The image is [&#8230;]",
            "pubdate": "Fri, 27 Jan 2023 13:03:02 +0000",
            "pubdate_parsed": [
                2023,
                1,
                27
            ],
            "email_sent": true
        },
        "Deep Learning Explained: Perceptron": {
            "url": "https://towardsai.net/p/l/deep-learning-explained-perceptron",
            "description": "Last Updated on January 27, 2023 by Editorial Team Author(s): Cl\u00e9ment Delteil Originally published on Towards AI. Deep Learning Explained: Perceptron The key concept behind every neural\u00a0network. Source: Image by Gerd Altmann from\u00a0Pixabay Nowadays, frameworks such as Keras, TensorFlow, or PyTorch provide turnkey access to most deep learning solutions without necessarily having to understand them in\u00a0depth. But this can get problematic as soon as your model is not working as expected. You may need to tweak it yourself. So, if you are here to understand the concept of Perceptron in deep learning, I think you are on the right track if you want to be able to contribute one day to this ecosystem in any way, it is essential to understand the roots of these\u00a0systems. Otherwise, if you are already familiar with the concept of Perceptron, it\u2019s not a big deal. I still hope to surprise\u00a0you! In this article, I\u2019ll introduce the idea of the Perceptron. We\u2019ll see how it was thought back in 1950 and how it\u00a0works. Let\u2019s get into\u00a0it. A bit of\u00a0history Beginning Back in 1943, McCulloch and Pitts published a paper entitled A logical calculus of the ideas immanent in nervous activity\u200a\u2014\u200aknown today as the first mathematical model of a neural\u00a0network. The idea of this article is part of the dynamics of the time of wanting to create intelligent machines by reproducing the functioning of the human\u00a0brain. I take as evidence the beginning of the abstract of\u00a0it. Because of the \u201call-or-none\u201d character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. At that time, the functioning of the human brain was popularized as interconnected nerve cells transmitting electrical and chemical signals like a simple logic\u00a0gate! Source: Image by Vishnu Mohanan from\u00a0Unsplash The Perceptron itself Now let\u2019s jump forward 14 years to 1957 and the publication of an article by Rosenblatt called The Perceptron\u200a\u2014\u200aA Perceiving and Recognizing Automaton. It is in this article that we find the perceptron as it is understood today. A system to learn the optimal weights to multiply with the inputs to determine whether a neuron activates or\u00a0not. Below you can see the first perceptron trained to recognize objects or patterns, in this case, the letters of the alphabet. Source: Flickr\u200a\u2014\u200aThe camera system of the Mark 1 Perceptron (Public\u00a0Domain) Now that you have an idea of the history of this concept let\u2019s move on to its application in deep learning. Perceptron applied to Deep Learning. The basic perceptron is used for binary classification in supervised machine learning. As a reminder, binary classification implies that there are only two classes to predict 1 and -1, for\u00a0example. And supervised machine learning refers to training the model via already labeled data (with their associated classes). Mathematical definition We define the inputs \ud835\udc65, outputs y, and weights \ud835\udc64 the following way. Source: Image by\u00a0author Where m is the size of the vector \ud835\udc64, \ud835\udc65 or\u00a0y. Let \ud835\udc67 be the net input composed of a linear combination of \ud835\udc65 and\u00a0\ud835\udc64. Source: Image by\u00a0author The classification is defined by an activation function phi: \ud835\udf19 (\ud835\udc67) with a threshold theta: \ud835\udf03 corresponding to the so-called bias, we will see it\u00a0later. Source: Image by\u00a0author The activation function defines in a way how the incoming element will be classified. If the neuron activates, that is to say, if z \u2265 \ud835\udf03, then the current input will be assigned class 1, -1 otherwise. This kind of function is called a Heaviside step function. Source: Image by author\u200a\u2014\u200aHeaviside step function illustration Above, theta is equal to 0. By changing this value, we shift the curve to the left or the\u00a0right. To recap, now that we have added theta, the equation for the net input z changes a little\u00a0bit. We now have\u00a0: Source: Image by\u00a0author With\u00a0: Source: Image by\u00a0author Congratulations! You now know the mathematical definition of a perceptron. Here is the graphical equivalent: Source: Chang et al\u200a\u2014\u200aCreative Commons Attribution 4.0 International\u200a\u2014\u200aPerceptron illustration But how do you train a perceptron? Training a perceptron Here are the training\u00a0steps: Initialization of the weights to 0 (or a small random\u00a0number) 2. For each training example x\u207d\u2071\u207e\u00a0: \u2013 Calculate the estimated output y\u0302\u207d\u2071\u207e \u2013 Update the\u00a0weights The update of each weight of the vector\u00a0w Source: Image by\u00a0author is done as follows\u00a0: Source: Image by\u00a0author Where we introduce eta: \ud835\udf02, the learning rate (between 0.0 and\u00a01.0). Depending on whether or not you are comfortable with these notations, you may have trouble imagining how a perceptron is\u00a0trained. Let\u2019s take some examples. Example For the sake of simplicity, let us assume that the learning rate is equal to 1 and that we know the following values. Source: Image by\u00a0author We consider that there is only one feature in the dataset to simplify the calculations. Here are some examples of the calculation of the delta of the first weight in the perceptron. Source: Image by\u00a0author You can see that the estimated output value given by the activation function is systematically subtracted from the real output\u00a0value. When the estimated value is the same as the real value, it is equal to 0 so there is no\u00a0update. Otherwise, the weight must be\u00a0updated. This is the case in the last two examples. We can notice that the value scale of the input \ud835\udc65 makes the weight update vary more or\u00a0less. In example number 3, \ud835\udc65 = 3, and so we have a weight difference of 6, whereas in example number 4, \ud835\udc65 = 0.5, so the weight difference is only\u00a01. Bias Earlier I intentionally skipped the explanation of the bias so as not to overload you with information. As explained above, the bias is a scalar value that is added to the net input z before passing through the activation function. It allows the decision boundary of the perceptron to be shifted away from the origin, which can be useful in situations where the data is not linearly separable. Source: M.Grove and J.Blinkhor\u200a\u2014\u200aCC BY\u200a\u2014\u200aLinearly separable data vs non-linearly separable data The bias is an addition to the [&#8230;]",
            "pubdate": "Fri, 27 Jan 2023 12:14:54 +0000",
            "pubdate_parsed": [
                2023,
                1,
                27
            ],
            "email_sent": true
        },
        "Data Preprocessing in R Markdown": {
            "url": "https://towardsai.net/p/l/data-preprocessing-in-r-markdown",
            "description": "Last Updated on January 28, 2023 by Editorial Team Last Updated on January 28, 2023 by Editorial Team Author(s): Mohammed Fayiz Parappan Originally published on Towards AI. for Machine\u00a0Learning Photo by Scott Graham on\u00a0Unsplash Data preprocessing constitutes cleaning, sampling, analyzing, transforming, and encoding data so that it can be easily interpretable to provide insights or can be fed into a machine learning\u00a0model. Data is the new oil. It is crucial to have data in an interpretable form. In this article, I will discuss the implementation of Data Preprocessing methods in R. I will be using Heart Attack Analysis and Prediction Dataset provided by\u00a0Kaggle. Steps in Data Preprocessing Import the designated data file and\u00a0Explore Handle Missing Values, Remove duplicates and irrelevant observations Fix structural errors Filter unwanted\u00a0outliers Measures of central tendency (calculate mean, median, mode, and frequencies) Measures of dispersion (calculate variance, standard deviation, range, inter-quartile range, coefficient of variance) Calculate the correlation coefficient and correlation plot Check the distribution of features using histograms and a Normal Probability Plot Data Splitting Import the designated data file and\u00a0Explore You can find more details on the dataset here: https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset/ Unlike many other programming languages, datasets in the form of CSV and TXT files can be directly imported without any library in\u00a0R. Top rows of the\u00a0dataset Structure of the\u00a0dataset 2. Handle Missing Values, Remove duplicates and irrelevant observations In R, missing values are represented by NA (not available). Number of missing\u00a0values As no missing values are there, no missing value techniques are used. In case missing values are found, either they are removed or replaced by mean or approximations. Duplicate data can contaminate the interpretability of the dataset and may also lead machine learning models to learn patterns that do not exist in\u00a0reality. The index of the only duplicate row is found and removed from the\u00a0dataset. 3. Fix structural errors As missing values and duplicates are now removed, let\u2019s check if the distribution of dataset w.r.t output is balanced or not. The dataset is labeled as 0\u2019s and\u00a01&#039;s. 0 = No Heart Attack\u00a0Occurs 1 = Heart Attack\u00a0Occur As there are a similar number of observations of both classes, the dataset is balanced\u00a0enough. 4. Filter unwanted\u00a0outliers Outliers are extreme data points that do not match with general trends seen in other points of the dataset. It can have a crucial impact on the interpretations and results given by ML models. It is important to note that the mere appearance of outliers doesn\u2019t mean they should be removed. Only those outliers which are irrelevant for data analysis should be\u00a0removed. Outlier data points in a dataset can be detected with the help of Cook\u2019s Distance which is a metric to measure the influence of each data point over the model (here, linear regression is shown) into which the dataset is fed. Cook\u2019s distances can be easily calculated in R using olsrr library that can be installed from Tools -&#62; Install Packages. Number of\u00a0Outliers Note that conditions for treating data points as outliers are subjective. Here, I have treated data points whose Cook\u2019s distances are more than five times the mean Cook\u2019s distance as outliers. There are 9 such points, and they were filtered from the\u00a0dataset. 5. Measures of central tendency (mean, median, mode, and frequencies) The mean, median, mode, minimum, maximum, and quartiles of each dataframe in the dataset can be extracted from the summary of the\u00a0dataset. 6. Measures of dispersion (variance, standard deviation, range, inter-quartile range, coefficient of variance) I have used sapply() function, which takes a list or vector or data frame as input and gives output as a vector or matrix to get the values of measures of dispersion. Standard Deviation of each\u00a0feature Variance of each\u00a0feature IQR of each\u00a0feature Coefficient of Variance of each\u00a0feature 7. Calculate the correlation coefficient and correlation plot A correlation coefficient is a number between -1 and 1 that tells the strength (along with direction) between features of the dataset. It is useful to detect multicollinearity, which kills independence between features of the dataset and can lead to inaccurate parameter estimates by ML\u00a0models. A correlation plot helps in visualizing correlation coefficients between features of the dataset. It is plotted in R using corrplot library, which can be installed from Tools -&#62; Install Packages. Correlation coefficients of each pair of\u00a0features Correlation Plot on\u00a0Dataset Notice that intensity of the blue color shows the strength of positive collinearity, while the intensity of the red color shows the strength of negative collinearity. 8. Check the distribution of features using Histograms and Normal Probability Plot Histograms show how the values of each feature are distributed, which can give interesting insights into the dataset. A normal probability plot tells us how close the feature distribution is to the normal distribution. I used ggplot2 and qqplotr libraries to plot\u00a0NPP\u2019s. Histogram Plot on the Age of\u00a0Patients Histogram Plot on the blood pressure of\u00a0Patients Histogram plot on the cholesterol level of\u00a0Patients Normal Probability plot on the age of\u00a0Patients Normal Probability plot on blood pressure of\u00a0Patients Normal Probability Plot on cholesterol level of\u00a0Patients 9. Data Splitting I have used caTools library to split the dataset into train and test sets with a ratio of\u00a080:20. All these techniques will help you to have better insights from data and also to prepare your dataset for feeding it into a machine learning model. If you know any other techniques, share them in the comments for everyone! Thanks For Reading, Follow Me For\u00a0More Data Preprocessing in R Markdown was originally published in Towards AI on Medium, where people are continuing the conversation by highlighting and responding to this story. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 28 Jan 2023 12:10:22 +0000",
            "pubdate_parsed": [
                2023,
                1,
                28
            ],
            "email_sent": true
        },
        "YOLOv8 Is Here and It Gets Better!": {
            "url": "https://towardsai.net/p/l/yolov8-is-here-and-it-gets-better",
            "description": "Last Updated on January 30, 2023 by Editorial Team Author(s): Puneet Jindal Originally published on Towards AI. YOLOv8 Is Here, and It Gets\u00a0Better! YOLOv8 is the latest installment in the highly influential family of models used for object detection and image segmentation. It features a new architecture, new convolutional layers, and a new detection head. It is also significantly faster and more accurate than previous versions of YOLO, making it an excellent choice for real-time object detection. Additionally, YOLOv8 supports the latest computer vision algorithms, including instance segmentation, which allows for the detection of multiple objects in an\u00a0image. How Yolov8 is better than previous popular versions of Yolo, such as Yolov5, Yolov7,\u00a0etc? Firstly, YOLOv8 introduces a new backbone network, Darknet-53, which is significantly faster and more accurate than the previous backbone used in YOLOv7. DarkNet-53 is a convolutional neural network that is 53 layers deep and can classify images into 1000 object categories, such as keyboard, mouse, pencil, and many\u00a0animals. Yolov8 makes bounding box predictions similar to image segmentation, i.e., pixel-wise. To achieve this, they have introduced anchor free detection head. To understand more about what is anchor free object detection, you can read\u00a0here Additionally, YOLOv8 is more efficient than previous versions because it uses a larger feature map and a more efficient convolutional network. This allows the model to detect objects in a more accurate and faster way. With a larger feature map, the model can capture more complex relationships between different features and can better recognize patterns and objects in the data. Additionally, a larger feature map also helps to reduce the amount of time it takes to train the model and can help to reduce overfitting. Additionally, YOLOv8 also uses feature pyramid networks, which helps to better recognize objects of different sizes, which improves its overall accuracy. Feature Pyramid networks are a concept that uses different scales of feature maps(similar to making predictions on different sizes of images) coupled with skip connections to predict smaller and bigger objects more accurately. More can be read\u00a0here Finally, YOLOv8 introduces a user-friendly API, allowing users to quickly and easily implement the model in their applications. Let&#039;s understand this in a bit more detail with a quick to-try, hands-on explanation You should visit https://github.com/ultralytics/ultralytics Before moving further, it&#039;s important to understand the relationship between Ultralytics and\u00a0Yolo. Ultralytics is the developer of YOLO (You Only Look Once), a popular object detection model used in computer vision applications. YOLO is a deep learning algorithm that is used to detect objects in images and videos, and the Ultralytics package provides tools and libraries to help developers create and deploy YOLO models. The package includes a range of pre-built models and tutorials, as well as tools for training, validating and inferring models. Scroll down\u00a0to As you can see above, click on \u201cOpen in Colab,\u201d as pointed out here. Otherwise, I am sharing the same link here https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb Click on connect to start using the Google Colab. If you are new to Google Colab, then click on the \u201cHow to start using Google Colab tutorial?\u201d The moment you visit the link, it will open the tutorial as below, where the first line is about\u00a0Setup Let&#039;s dive deep into each cell of the\u00a0code The above lines of code install the Ultralytics package so that we can use the YOLO algorithm. By default, it will install version 8 while I am writing this article. Alternatively, you can\u00a0do %pip install ultralytics==8.0.3 After installing the next line of code, importing the Ultralytics module and then we try to check whether all the required dependencies and compatible hardware are present or\u00a0not. E.g., the following is the output when I executed checks on my\u00a0machine. Ultralytics YOLOv8.0.3 \ud83d\ude80 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB) Setup complete \u2705 (2 CPUs, 12.7 GB RAM, 24.3/78.2 GB\u00a0disk) One thing to note here is the below code. Don\u2019t run this code in case you find it. A few others and I reported the issue at https://github.com/ultralytics/ultralytics/issues/232 Let\u2019s move on to the next\u00a0step # Run inference on an image with\u00a0YOLOv8n Inference means a prediction that we can run on an image to detect the label, whether classification or of a bounding box or a segmentation. Above statement is calling yolo(!yolo) to predict(mode=predict) for object detection task(task=detect) using yolov8 model(model=yolov8n.pt) to output labels only if confidence score is greater than 0.25(conf=0.25) on an image on a publicly accessible link (source = \u2018https://ultralytics.com/images/zidane.jpg\u2019) In case you want to try predictions on another type of task, the following options are available. The above statement will first download the referenced image, and then download the referenced pre-trained model checkpoint if not downloaded already, and then produce inference results. Here are the results in my case. It might differ, especially in the latency and number of labels detected. Results will be saved to the runs/detect/predict folder in case you want to cross-reference, and if you open the image, it might look like the following with detections printed on the\u00a0image. Let\u2019s move to the next step of testing predictions on the validation set. But before that, we first need to download the validation dataset, which is coco2017. You can see that PyTorch provides the functions to download the zip file from the URL. In the last statement below, we can unzip it into a folder location\u00a0../datasets and delete the zip file with the rm\u00a0command. The below command shows the predictions on the validation dataset. The output of the predictions on the validation set is\u00a0as Now a question could emerge \u201cHow do I interpret these numbers?\u201d To interpret the YOLOv8 prediction results in summary on a validation set, you need to look at the metrics such as mean Average Precision (mAP), precision, recall, and the false positive rate (FPR). The mAP is a measure of the model\u2019s overall performance, while the Precision, Recall, and FPR measure the model\u2019s accuracy in detecting different classes. Additionally, you should also look at the class-wise performance of the model, which is the performance of the model for each [&#8230;]",
            "pubdate": "Tue, 31 Jan 2023 00:11:36 +0000",
            "pubdate_parsed": [
                2023,
                1,
                31
            ],
            "email_sent": true
        },
        "Build Strong Deep Learning Foundations By Learning From Top Universities": {
            "url": "https://towardsai.net/p/l/build-strong-deep-learning-foundations-by-learning-from-top-universities",
            "description": "Last Updated on January 31, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. Deep learning is a rapidly growing field with a high demand for experts in the industry. Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 01 Feb 2023 00:11:57 +0000",
            "pubdate_parsed": [
                2023,
                2,
                1
            ],
            "email_sent": true
        },
        "This AI newsletter is all you need #32": {
            "url": "https://towardsai.net/p/l/this-ai-newsletter-is-all-you-need-32",
            "description": "Last Updated on January 31, 2023 by Editorial Team Author(s): Towards AI Editorial Team Originally published on Towards AI. What happened this week in AI by\u00a0Louis Following recent advancements in image, code, and text generation, there have been new developments in AI-generated music and text-to-speech. In 2019, everyone was already impressed with OpenAI\u2019s Musenet, built on GPT-2 techniques applied to MIDI files. However, with recent advancements in AI, much more flexible and comprehensive music models are now possible. This week, AI has noted several interesting AI-generated music and text-to-speech models, including MusicLM, a model announced by Google Research that generates high-fidelity music from rich text descriptions. Although the model isn\u2019t released yet, dataset MusicCaps, consisting of 5.5k human-written music-text pairs, is available. The paper \u201cMake-An-Audio\u201d was also released this week, describing Text-To-Audio Generation with Prompt-Enhanced Diffusion Models. We expect to see a wave of AI music startups and open-source models released going forward, especially as annotated music data sets become accessible. We hope progress in AI music models can benefit musicians exploring new concepts and lower the cost and obstacles for new musicians entering the industry. Besides new music models this week, we also discovered an impressive and flexible text-to-audio model from elevenlabs. Excited about the potential of such models to increase accessibility of written content, we also see growing risks in text-to-audio, including voice cloning for fake quotes and voice-protected logins and verifications. Hottest News 1.ChatGPT is \u2018not particularly innovative,\u2019 and \u2018nothing revolutionary\u2019, says Meta\u2019s chief AI scientist Recently, there has been much discussion about the potential of OpenAI\u2019s ChatGPT program for generating natural language responses to human prompts. However, AI scholars have a different view. During a Zoom meeting with press and executives last week, Yann LeCun, the Chief AI Scientist at Meta, stated, \u201cIn terms of underlying techniques, ChatGPT is not particularly innovative.\u201d 2. The inside story of ChatGPT: How OpenAI founder Sam Altman built the world\u2019s hottest technology with billions from Microsoft Sam Altman believes that the future of AI could be exceptional\u200a\u2014\u200aunless things go astray. It is important to know the story of OpenAI\u2019s ChatGPT chatbot, which has been used for activities such as debugging code, writing recipes, scripts, and more, and how it has sparked a revolution. 3. AI adoption: is it obvious\u00a0yet? Regardless of one\u2019s opinion of ChatGPT, its release last year generated another buzz in the AI community. Its launch likely did more to promote the value of machine learning to non-experts than any other event. It is crucial to assess if we are ready for AI adoption in terms of technological and product maturity and to comprehend the excitement surrounding AI and the arguments for and against incorporating it into products. 4. AI21 Labs has created a co-writing bot that can suggest quotes, statistics, provide citations and\u00a0more AI21 Labs, a research lab specializing in NLP and generative AI, announced the launch of Wordtune Spices, a new feature for its popular Wordtune editing platform, to enhance the writing experience for writers of all types. Wordtune Spices is an AI-powered writing tool that comprehends content and meaning to assist users in expressing their ideas more effectively and compellingly. 5. The Human-AI Partnership In this podcast, Reid Hoffman speaks with ChatGPT about the partnership between humans and AI. He delves into the unique ways in which AI can enhance human capabilities as part of a miniseries focused on the future of AI and chatbots. Three 5-minute reads/videos to keep you\u00a0learning 1.A Brief History of Artificial Intelligence This article explores the rich history and evolution of AI, from its early origins to the current ethical debates surrounding its development. The article traces the journey of AI, starting with its first concepts and leading to the seminal conference organized by Allen Newell, Cliff Shaw, and Herbert Simon, which marked the beginning of its proof of concept. The article provides insight into the past, present, and future of\u00a0AI. 2. Introduction to embeddings\u200a\u2014\u200aThe bread and butter of language\u00a0models Word and sentence embeddings are the backbones of language models. This Twitter thread by Cohere offers a clear and simple introduction to these essential concepts, including examples, applications, and additional resources. It also explains how embeddings work and how they can be used in language\u00a0models. 3. Getting started with LLMs using LangChain Recently, there has been a surge of interest in generative AI and language models (LLMs). This article introduces LangChain, a library that enables the creation of advanced applications around LLMs such as OpenAI\u2019s GPT-3 models and the open-source alternatives provided by Hugging Face. It begins with a discussion on the simplest component offered by LangChain. 4. Five pieces of advice for those building in AI right\u00a0now In this Twitter thread, Nathan shares his thoughts on the process of building products. Some advice he shares in his thread: avoiding generalizations, recognizing that AI is not a unique advantage, treating AI-powered products as more than just \u201cwrappers\u201d, disregarding hype, and acknowledging that AI-powered applications are not primarily focused on\u00a0AI. 5. Manipulating Tensors in\u00a0PyTorch PyTorch is a deep-learning library that operates on numerical arrays known as tensors. This article provides a brief overview of what PyTorch offers for tensors and how to use them. It gives insight into how to create and perform operations on PyTorch tensors and the common functions available in PyTorch for manipulating tensors. Enjoy these papers and news summaries? Get a daily recap in your\u00a0inbox! The Learn AI Together Community section! Upcoming Community Events The Learn AI Together Discord community hosts weekly AI seminars to help the community learn from industry experts, ask questions, and get a deeper insight into the latest research in AI. Join us for free, interactive video sessions hosted live on Discord weekly by attending our upcoming\u00a0events. 1.Convolution Networks: The Neural Network Architecture Seminar\u00a0(#4) This is the fourth session of a (free) nine-part series on Neural Networks Architectures presented by Pablo Duboue (DrDub), covering Convolution Networks. The session focus on CNNs, DL image processing, YOLO, U-Net, Retina-Net, and SpineNet. Find the link [&#8230;]",
            "pubdate": "Wed, 01 Feb 2023 00:11:54 +0000",
            "pubdate_parsed": [
                2023,
                2,
                1
            ],
            "email_sent": true
        },
        "Parquet Best Practices: The Art of Filtering": {
            "url": "https://towardsai.net/p/l/parquet-best-practices-the-art-of-filtering",
            "description": "Last Updated on February 1, 2023 by Editorial Team Author(s): Arli Originally published on Towards AI. Understanding how to filter Parquet files Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 02 Feb 2023 00:21:42 +0000",
            "pubdate_parsed": [
                2023,
                2,
                2
            ],
            "email_sent": true
        },
        "ChatGPT Is Overhyped. There Is A Reason For It.": {
            "url": "https://towardsai.net/p/l/chatgpt-is-overhyped-there-is-a-reason-for-it",
            "description": "Last Updated on February 4, 2023 by Editorial Team Author(s): Alexandros Zenonos, PhD Originally published on Towards AI. ChatGPT is making people smarter Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 04 Feb 2023 12:19:18 +0000",
            "pubdate_parsed": [
                2023,
                2,
                4
            ],
            "email_sent": true
        },
        "Technology Readiness Levels (TRL) in AI development": {
            "url": "https://towardsai.net/p/l/technology-readiness-levels-trl-in-ai-development",
            "description": "Last Updated on February 4, 2023 by Editorial Team Author(s): Stavros Theocharis Originally published on Towards AI. A framework for the future development of\u00a0AI Image generated by\u00a0DALL-E Artificial Intelligence (AI) is a subject that has been discussed almost everywhere. It continuously gets so popular that it permeates practically every field, from the business world to the entertainment industry. This technology, however, is more than simply a fad; it\u2019s a serious means through which businesses may boost their productivity. As a result of the proliferation of use cases demonstrating how AI improved various operations, an increasing number of businesses have realized that AI and other forms of cutting-edge technology are the new arenas in which to compete. Perhaps you are among the company owners or project planners who have realized the value of AI and are looking for ways to improve their operations by using AI software. But what is actually\u00a0AI? Artificial intelligence (AI) is a subfield of computer science and engineering that simulates intelligent behavior similar to that of humans. AI technology can be used in many different ways, such as to make fully autonomous systems that can think, learn, and act on their own. The powers of the human mind can be mimicked and even improved upon by computers thanks to AI\u2019s ability to do so. AI is being more fully integrated into many aspects of modern life, including the creation of self-driving automobiles and the widespread use of virtual assistants. As a direct consequence of this, several tech businesses operating in a wide variety of sectors are increasing their investments in technologies that are powered by AI. This includes a wide range of things, like being able to understand spoken language, recognize faces and objects, make plans, and solve problems. There is a substantial body of literature focused on the stages of an AI project\u2019s lifecycle. The main possible steps are the following, as referenced in\u00a0[1]: Exploratory data\u00a0analysis Data preparation Data preprocessing Modeling Testing These steps can certainly be supplemented with additional steps, but they define a basic structure. I would for sure add, on top of everything, \u201cunderstand the business problem\u201d. For many teams, this is obvious, but unfortunately, this isn\u2019t always the case, and many teams realize it when it is already too\u00a0late. Personally, I am one of the primary advocates of AI-based problem-solving solutions. On the other hand, I stress the significance of introducing AI only when it is really required. An actual issue or goal should serve as the impetus for any AI project. This is crucial since AI may not be necessary for all situations. This is an important part to be considered in order to understand the following parts of this\u00a0article. So, let\u2019s go\u00a0deeper\u2026 What is the Technology Readiness Level\u00a0(TRL)? Research and consulting in the field of information systems have relied on maturity models for many years. Therefore, there is an infinite amount of literature on them. A recent comprehensive review of the state of the art discovered 409 relevant papers and a multitude of classification techniques, many of which still need genuine validation [2]. At its core, a system\u2019s, subsystem\u2019s, or component\u2019s Technology Readiness Level (TRL) is only a description of its performance history in relation to a scale developed at NASA headquarters in the 1980s. The TRL is a measure of the development and maturity of technology [3]. Technology Readiness Levels (NASA,\u00a02003) The 9 levels of the scale illustrate how far down the path of maturity a given technology must go before it may be used in its designated operational setting. The TRL has been criticized for being utilized more as a decision-making aid in public funding for R&#38;D&#38;I than as an ontological explanation of the processes involved in bringing new technologies to\u00a0market. Since 2014, the TRL scale has been included in the European Union\u2019s Horizon 2020 Work Programmes and has been extensively implemented in the context of research, development, and innovation investments funded by the European Regional Development Fund, or \u201cERDF\u201d\u00a0[4]. But, what about using TRL in AI applications? Lavin A. et al. (2022) state that the default TRL process may come into sharp contrast with the rapid development and fast iteration that an AI project may need to follow. Because of this, they propose a simplified Machine Learning Technology Readiness Levels (MLTRL) framework to be put in place\u00a0[5]. I would also agree that fast prototyping in many AI projects can lead to faster market entry and engagement than the competition. However, what happens when we are talking specifically about healthcare diagnostic tools or, more generally, about ethics and fairness? In such cases, rapid prototyping without specific steps may have the opposite effect on both business and\u00a0society. Models, algorithms, data pipelines, software modules, and their many combinations all have different levels of maturity, which are measured by the\u00a0TRL. The ethics part is one of the pain points of today\u2019s AI systems. Organizational AI ethics procedures may differ, but discussions concerning ethical problems are needed to take place all the way through the TRL procedure, and in the majority of instances, these discussions are tied to a full ongoing ethics checklist from the beginning until the end. Discussions on ethics are needed with the involvement of more than one team (stakeholders, legal team, etc.) in order to get into serious consideration of the different ideas and suggestions. Let\u2019s focus on the different TRL levels from the MLTRL framework (process-desired outputs): Level 0: First principles This is the early phase of AI research for a new concept that needs to be implemented. Here, there won\u2019t be any full data to work with yet, but some sample data instead; therefore, much of the work will consist of literature study, laying down mathematical foundations, etc. Level 1: Goal-oriented research Instead of running end-to-end to get a performance benchmark score, try doing low-level experiments to investigate certain model or algorithm aspects. In order to train and test the model, it is necessary to gather and analyze sample data. This data may be a [&#8230;]",
            "pubdate": "Sun, 05 Feb 2023 00:11:31 +0000",
            "pubdate_parsed": [
                2023,
                2,
                5
            ],
            "email_sent": true
        },
        "How To Estimate FP, FN, TP, TN, TPR, TNR, FPR, FNR & Accuracy for Multi-Class Data in Python in 5": {
            "url": "https://towardsai.net/p/l/how-to-estimate-fp-fn-tp-tn-tpr-tnr-fpr-fnr-accuracy-for-multi-class-data-in-python-in-5",
            "description": "Last Updated on February 5, 2023 by Editorial Team Author(s): Serafeim Loukas Originally published on Towards AI. In this post, I explain how someone can read a confusion matrix and how to extract several performance metrics for a multi-class&#x2026; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 05 Feb 2023 12:08:52 +0000",
            "pubdate_parsed": [
                2023,
                2,
                5
            ],
            "email_sent": true
        },
        "Ask Jeeves Has Been Re-Born with AI!": {
            "url": "https://towardsai.net/p/l/ask-jeeves-has-been-re-born-with-ai",
            "description": "Last Updated on February 5, 2023 by Editorial Team Author(s): Andrew Austin Originally published on Towards AI. I hope you wrote down everything you didn&#x2019;t get a chance to &#x201c;Ask Jeeves&#x201d; Continue reading on Towards AI \u00bb Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 06 Feb 2023 00:11:09 +0000",
            "pubdate_parsed": [
                2023,
                2,
                6
            ],
            "email_sent": true
        },
        "Inside BLOOM: How Thousands of AI Researchers Created an Open Source ChatGPT Alternative": {
            "url": "https://towardsai.net/p/l/inside-bloom-how-thousands-of-ai-researchers-created-an-open-source-chatgpt-alternative",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Jesus Rodriguez Originally published on Towards AI. An open-source LLM shows that tech incumbents are not the only companies able to create massive models. Continue reading on Towards AI Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 13 Feb 2023 11:34:45 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "Will AI replace Cybersecurity jobs?": {
            "url": "https://towardsai.net/p/l/will-ai-replace-cybersecurity-jobs",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Taimur Ijlal Originally published on Towards AI. Do cybersecurity jobs have a limited lifespan as AI becomes better and better at securing stuff&#xa0;? Continue reading on Towards AI Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 13 Feb 2023 11:34:43 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "A Cheat Sheet to Deep Learning Algorithms: Types, Applications, and Examples": {
            "url": "https://towardsai.net/p/l/a-cheat-sheet-to-deep-learning-algorithms-types-applications-and-examples",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): SPX Originally published on Towards AI. Introduction Continue reading on Towards AI Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 13 Feb 2023 11:34:41 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "How to Maximize ML Project Success with Efficient Scoping? | MLOps 5": {
            "url": "https://towardsai.net/p/l/how-to-maximize-ml-project-success-with-efficient-scoping-mlops-5",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Akhil Theerthala Originally published on Towards AI. In our past articles of this series, we have seen many things. We started our journey by looking at the lifecycle of a project. Following this, we got an overview of each phase of the lifecycle. If you have followed this series till now, you should know about the standard practices in different lifecycle phases. Let\u2019s take a look at the lifecycle once. Lifecycle of a Machine Learning Project. Source: Deeplearning.AI, licensed under the Creative CommonsAttribution-ShareAlike 2.0\u00a0license. After a brief overview of the lifecycle, we looked into the individual phases. After moving back to back from one stage of the project to another, it is time for us to look into the project\u2019s very first stage,\u00a0Scoping. Fret not. Unlike the previous articles, this article is a short one. You can finish reading this within a few minutes!\u00a0\ud83d\ude0c Why should we scope a\u00a0project? Let\u2019s take a step back and think from a company\u2019s perspective. Companies generally invest vast amounts into any of their projects. Besides these costs, they must employ engineers and scientists to work on these projects. This requires additional capital. All this money will be invested into a project, which sometimes might yield abysmal results. Hence, companies are cautious before they start a new\u00a0project. They cross-check why they need the project, check for alternative cheaper options, list out additional benefits a project can bring, do market research for the projects, list out the different risks the project has, plan out the entire financial requirements, and make a profit estimate, and they estimate the time required for the project. They do all this before a project begins. However, even after doing this, the project might still fail or need more time or investments. In Aug 2022, Forbes stated that somewhere between 60\u201380% of AI projects are failing, according to different sources. This shows that scoping the projects is one of the most important steps before starting a machine learning\u00a0project. Let\u2019s speak examples. Now that we have seen why scoping a project is essential. Let\u2019s get into the details. Essentially, the question we have been asking till now is, \u201c How to pick a project to work\u00a0on?\u201d Let\u2019s use the example of an e-commerce retailer looking to increase sales. What can you recommend to him as an ML Engineer? You can guide\u00a0him, A better product recommendation system. A better search engine for his\u00a0site. To improve the catalog data of his\u00a0store. A better inventory management system,\u00a0etc. We can also keep giving hundreds of other suggestions to him, both belonging to ML and not belonging to ML. But, there are only a few efficient suggestions that he needs to focus on. So, our problem now is\u00a0to Identify the most profitable project to work\u00a0on. Explain to him how this is the most profitable project using different metrics. Estimate the resources and costs of this project and ask him the\u00a0amount. That\u2019s it. If you answer these three questions, you have finished scoping the\u00a0project. General Outline for\u00a0Scoping. Like all other fields, scoping ML projects have many community recommended outlines. Despite there being many outlines, their essence is the same. Now, we can look at one such strategy. Step-1: Brainstorm the business problems. Before beginning the project, it is first essential to have a goal or a problem to solve. There are countless problems found everywhere. However, only a few are profitable. In this step, we list all the problems that can profit the company when\u00a0solved. For our store, some problems can be reducing the inventory, increasing profit margin, increasing conversion, etc., Step-2: Brainstorm AI solutions. In this step, we identify different AI solutions for the identified problems. We pick the most feasible one among these in the later\u00a0stages. For our store, it can be things like,&#8211; Improving the recommendation model to increase the conversion rate.&#8211; Optimizing what to sell to reduce the profit margin.&#8211; Using applications of marketing and demand prediction to reduce inventory. Step-3: Feasibility Assessment AI is not a cure-all tool. It should not be applied to everything just because we\u00a0can. In our earlier AI solutions, many need unrealistic requirements. Hence we need to filter these\u00a0out. Since we are checking the possibility of an AI solution, we use different machine learning metrics to filter these\u00a0out. For filtering these problems, &#8211; We can use external benchmarks like research papers, other companies etc.&#8211; We can look into Human-Level Performance (HLP) for unstructured data (or) the availability of predictive features for structured data.&#8211; We also generally look at the history of existing projects in the market and their performance to assess the rate of future improvement. Step-4: Value Assessment Just as all the solutions are not feasible, all feasible solutions are not valuable. For example, building a linear regression to predict no. of A/Cs in the office is useless for an e-commerce store. In the value Assessment, we look at different Business metrics that affect the AI feasible projects. The business metrics include the metrics like User engagement, quality of the model compared to the market, possible revenue that can be generated from the model,\u00a0etc., In practical situations, the ML and Business teams compromise to some degree to find feasible and valuable projects. Step-5: Draw out a\u00a0plan. Determining the milestones generally involves determining the ML and software metrics of the projects. Some of such metrics were previously discussed in articles 2 and\u00a03.1. However, here, we also try to determine the Business metrics and resources needed for the project like estimating the possible revenue, data required, the personnel that is allocated, etc., Finally, after all the things are done. You now have a problem, a possible AI solution, and the metrics to evaluate the situation. But your job doesn\u2019t end here. You need to give the company a timeline within which you will complete the project. (Yup, they don\u2019t trust you with the\u00a0budget.) Step-6: Determine the Budget for the resources. Of course, doing all the above things and not having [&#8230;]",
            "pubdate": "Mon, 13 Feb 2023 11:34:37 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "An Intuitive Explanation of Policy Gradient": {
            "url": "https://towardsai.net/p/l/an-intuitive-explanation-of-policy-gradient",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Renu Khandelwal Originally published on Towards AI. A Simple Explanation of Policy Gradient for Reinforcement Learning with very little Math Continue reading on Towards AI Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 13 Feb 2023 11:34:35 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "How to Use Hugging Face Pipelines?": {
            "url": "https://towardsai.net/p/nlp/how-to-use-hugging-face-pipelines",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Tirendaz AI Originally published on Towards AI. A practical guide on how to perform NLP tasks with Hugging Face Pipelines Image by\u00a0Canva With the libraries developed recently, it has become easier to perform deep learning analysis. One of these libraries is Hugging Face. Hugging Face is a platform that provides pre-trained language models for NLP tasks such as text classification, sentiment analysis, and\u00a0more. This blog will walk you through how to perform NLP tasks with Hugging Face Pipelines. Here are topics we\u2019ll discuss in this\u00a0blog. What is\u00a0NLP? What is Transformers? Performing various NLP tasks with Transformers. The NLP tasks we\u2019ll cover are text classification, named entity recognition, question answering, and text generation. Let\u2019s dive\u00a0in! What is\u00a0NLP? NLP is a subfield of AI that allows computers to interpret, manipulate and understand human language. The goal of NLP tasks is to analyze text and voice data like emails, social media newsfeeds, video, audio, and more. With the NLP techniques, you can handle various tasks such as text classification, generating text content, extracting an answer from a text,\u00a0etc. NLP doesn\u2019t just deal with written text. It also overcomes complex challenges in speech recognition and computer vision, such as creating a transcript of a sound sample or a description of an\u00a0image. Cool, we learned what NLP is in this section. Let\u2019s go ahead and have a look at what the Transformers library\u00a0is. What is the Transformers library? Transformers is a library in Hugging Face that provides APIs and tools. It allows you to easily download and train state-of-the-art pre-trained models. You may ask what pre-trained models are. Let me explain. A pre-trained model is actually a saved pre-trained network that was previously trained on a large dataset. Using pre-trained models, you can save the time and resources needed to train a model from\u00a0scratch. Nice, we looked at what the Transformers library is. Let\u2019s carry out some tasks to show how to use this\u00a0library. Transformer Applications Transformers library has great functions to handle various NLP tasks. The easiest way to tackle NLP tasks is to use the pipeline function. It connects a model with its necessary pre-processing and post-processing steps. This allows you to directly input any text and get an\u00a0answer. To use the Transformers library, you need to install it with the following command: pip install -q transformers To show how to utilize the pipeline function, let\u2019s import it from transformers. from transformers import pipeline Cool, we can now perform the NLP tasks with this object. Let\u2019s start with sentiment analysis. Sentiment Analysis Sentiment analysis is one of the most used NLP tasks. It is the process of detecting positive or negative sentiments in text. To show how to do this task, let\u2019s create a\u00a0text. text = \"This movie is beautiful. I would like to watch this movie again.\" Awesome, we now have a text. Let\u2019s find out the sentiment of this text. To do this, first, we instantiate a pipeline by calling the pipeline function. Next, we give the name of the task we are interested in. classifier = pipeline(\"sentiment-analysis\") Nice, we are ready to analyze our text using this\u00a0object. classifier(text)# Output:[{&#039;label&#039;: &#039;POSITIVE&#039;, &#039;score&#039;: 0.9998679161071777}] As you can see, our pipeline predicted the label and showed the score. The label is positive, and the score is 0.99. It turns out that the model is very confident that the text has a positive sentiment. Great, we have finished our sentiment analysis. It is simple,\u00a0right? Let\u2019s take a step back and think about what happened. This pipeline first selected a pretrained model that has been fine-tuned for sentiment analysis. Next, when creating the classifier object, the model was downloaded. Note that when passing some text to a pipeline, the text is preprocessed into a format the model can understand. In this analysis, we used a pipeline for sentiment analysis. You can also use it for other tasks. Some of the pipelines that have been developed recently are Sentiment-analysis; we just learned how to perform this pipeline, summarization, named entity recognition, question-answering, text generation, translation, feature extraction, zero-shot-classification, etc. Let\u2019s have a look at a few of these. The pipeline we\u2019re going to talk about now is zero-hit classification. Zero-Shot Classification Imagine you want to categorize unlabeled text. This is where the zero-shot classification pipeline comes in. It helps you label text. So, you don\u2019t have to depend on the labels of the pretrained model. Let\u2019s take a look at how to use this pipeline. First, we\u2019re going to instantiate by calling the pipeline function. classifier = pipeline(\"zero-shot-classification\") Now let\u2019s create a text to classify. text = \"This is a tutorial about Hugging Face.\" Let\u2019s define candidate labels. candidate_labels = [\"tech\", \"education\", \"business\"] Cool, we created our text and labels. Now, let\u2019s predict the label of this sentence. To do this, we\u2019re going to use the classifier object. classifier(text, candidate_labels)# Output:{&#039;sequence&#039;: &#039;This is a tutorial about Hugging Face&#039;, &#039;labels&#039;: [&#039;education&#039;, &#039;tech&#039;, &#039;business&#039;], &#039;scores&#039;: [0.8693577647209167, 0.11372026801109314, 0.016921941190958023]} As you can see, the text is about education. Here we didn\u2019t fine-tune the model on our data. Our pipeline directly returned probability scores. This is why this pipeline is called zero-shot. Let\u2019s move on and take a look at the text generation task. Text Generation Tools like ChatGPT are great for generating text, but sometimes you might want to generate text about a topic. The goal of text generation is to generate meaningful sentences. Our model gets a prompt and auto-completes it. Let\u2019s see how to perform a pipeline. First, we instantiate the pipelines with text-generation. generator = pipeline(\"text-generation\") Let\u2019s go ahead and create a\u00a0prompt. prompt= \"This tutorial will walk you through how to\" Now let\u2019s pass this prompt to our\u00a0object. generator(prompt)# Output:[{&#039;generated_text&#039;: &#039;This tutorial will walk you through how to setup a Python script to automatically find your favourite website using Python and JavaScript so you can build a web site that&#039;}] As you can see, a text was generated according to our sentence. Note that this [&#8230;]",
            "pubdate": "Mon, 13 Feb 2023 11:34:27 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "Unsupervised Sentiment Analysis With Real-World Data: 500,000 Tweets on Elon Musk": {
            "url": "https://towardsai.net/p/l/unsupervised-sentiment-analysis-with-real-world-data-500000-tweets-on-elon-musk",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Cl\u00e9ment Delteil Originally published on Towards AI. Guided walkthrough in a real-world Natural Language Processing project. Continue reading on Towards AI Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 13 Feb 2023 11:34:20 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "Traffic Forecasting: The Power of Graph Convolutional Networks on Time Series": {
            "url": "https://towardsai.net/p/l/traffic-forecasting-the-power-of-graph-convolutional-networks-on-time-series",
            "description": "Last Updated on February 13, 2023 by Editorial Team Author(s): Barak Or Originally published on Towards AI. The Graph Convolutional Network (GCN) has revolutionized the field of deep learning by showcasing its versatility in solving real-world problems, including traffic prediction, which is a critical issue in transportation. Introduction The Graph Convolutional Network (GCN) is a revolutionary development in the field of deep learning, demonstrating its versatility and potential for application in addressing real-world problems. One such challenge is traffic prediction, which is a critical issue in transportation. The ability to adapt GCN algorithms for traffic prediction purposes holds immense promise and has the potential to significantly impact the transportation industry. It is important to note that this post assumes a prior understanding of GCN. For those who require an introduction to GCN, I strongly recommend exploring Michael Bronstein\u2019s post, \u201cDo we need deep GNN,\u201d as well as Tobias Skovgaard Jepsen&#039;s hands-on introductory post. The power of Graph Neural Networks (GNN) [1], particularly GCN, lies in their ability to model complex relationships between entities, as demonstrated through examples such as chemical bonds between atoms or traffic speeds between road segments. With its capability for feature learning through graph convolutional operations, GCN has seen wide research in vision and text data, yet there is still much potential for exploring its application in the time-series domain, unlocking new frontiers for innovation. Image by\u00a0author Exploring Time-Series Tasks with Temporal\u00a0GCN The advent of GCN has opened up new possibilities for analyzing and understanding graph-structured data, including time-series data. Time-series data presents unique challenges compared to other forms of data, such as images. It is often less intuitive, lacks clear visual representations, and requires a deep understanding of causality to be analyzed effectively. To address these challenges, a new field of research known as Temporal GCN (TGCN) has emerged, which combines the strengths of GCN with those of Recurrent Neural Networks (RNN), Long-Short Term Memory (LSTM), or Gated Recurrent Units (GRU). This allows TGCN to capture both the spatial and temporal aspects of time-series data, making it a powerful tool for analyzing complex and dynamic\u00a0systems. Next, we will explore the potential of TGCN for traffic prediction [2], which is a critical issue in transportation. By analyzing traffic patterns and dependencies between different road segments over time, TGCN can provide insights and make accurate predictions about future traffic conditions. Through this example, we aim to demonstrate the versatility and potential of TGCN for solving real-world problems and improving our understanding of time-series data. Temporal GCN For Traffic Prediction Traffic prediction is a critical issue in transportation, and finding an accurate solution is crucial for optimizing traffic flow and reducing congestion. Traditional methods of predicting traffic speed only consider the past values of the same time series, but with the advent of GCN and GRU, a more comprehensive approach is possible. In a recent study [2], a new approach to traffic prediction was proposed that leverages the strengths of GCN and GRU. The researchers modeled the traffic network as a graph, with each road segment being a node and the connections between segments being the edges. The traffic speed was then represented as a signal on this graph, allowing the model to capture both the spatial and temporal features of the\u00a0data. The architecture included a graph convolution layer and a GRU layer, which enabled the model to effectively capture the relationships between different road segments and predict future traffic speed. By taking into account the dependencies between road segments, this solution provides a more accurate and comprehensive traffic prediction than traditional methods. Image by\u00a0author Exploring the Road Segments\u00a0Dataset In order to understand if there is any dependency between different road segments, we need to analyze the correlations between them. To do this, we selected 26 roads out of the 228 available in the dataset and created a correlation map. By visualizing the correlations, we can see if there is any relationship between the traffic speed of different road segments. If there is a strong relationship, this provides a clear justification for the use of a GCN to model the dependencies. It\u2019s important to note that capturing these relationships is crucial in accurately predicting traffic speed. By using a GCN, we can consider not only the individual traffic speed of each road segment but also the interdependencies between segments. This holistic approach allows for a more accurate and robust prediction of traffic\u00a0speed. Image by\u00a0author To understand if there are any dependencies between different road segments in the dataset, we calculated the correlations. The results showed that segments 4\u20135\u20136\u20137 and 19\u201320\u201321 have a high correlation, highlighting the importance of incorporating spatial features. In their research, Ling Zhao and their team proposed a TGCN architecture that utilizes both spatial and temporal features, with a graph convolution layer for the former and a GRU layer for the latter. We played with their code [3] and made it accessible through a Google Colab notebook, providing an opportunity for you to easily experiment with it [4]. The results were promising, and we encourage you to further test and improve the model by adjusting the parameters and increasing the number of\u00a0epochs. Keras.io Time-series traffic forecasting Tutorial Summary The graph convolutional network (GCN) is a highly innovative and impactful development in deep learning. It has numerous applications in the time-series domain, where it is adapted to include temporal features. To showcase the capabilities of TGCN, the example of traffic speed prediction was used and the correlation map was shown to highlight the need for the inclusion of spatial features. follow me on Medium for more\u00a0posts About the\u00a0Author Barak Or is an Entrepreneur and AI &#38; navigation expert; Ex-Qualcomm. Barak holds M.Sc. and B.Sc. in Engineering and B.A. in Economics from the Technion. Winner of Gemunder prize. Barak finished his Ph.D. in the fields of AI and Sensor Fusion. Author of several papers and patents. He is the founder and CEO of ALMA Tech. LTD, an AI &#38; advanced navigation company. Further reading and\u00a0comments [1] GCNs [&#8230;]",
            "pubdate": "Mon, 13 Feb 2023 11:34:14 +0000",
            "pubdate_parsed": [
                2023,
                2,
                13
            ],
            "email_sent": true
        },
        "This AI newsletter is all you need #34": {
            "url": "https://towardsai.net/p/machine-learning/this-ai-newsletter-is-all-you-need-34",
            "description": "Last Updated on February 15, 2023 by Editorial Team What happened this week in AI by Louis This week was rather chaotic in the world of large language models (LLMs) and \u201cGenerative AI\u201d as large tech companies scrambled to display their technology in the wake of ChatGPT\u2019s success. Microsoft announced an AI-powered version of the Bing search engine that incorporates OpenAI\u2019s ChatGPT technology into its Edge browser. In response, Alphabet announced their alternative to ChatGPT, named Bard. However, promotional material for Bard contained inaccurate information raising questions as to whether Google rushed out its release. Meanwhile, Chinese web giant Baidu is preparing to launch a generative AI chatbot, ERNIE, later this year. What people call \u201cGenerative AI\u201d is increasingly looking to be the next major platform for founders and startups to use to build new products. The barriers to entry to starting a business have now been reduced. You can rapidly and affordably create a prototype or minimum viable product on the back of\u00a0prompting\u00a0or fine-tuning APIs of LLMs like ChatGPT. But it is difficult to know how the ecosystem will play out and what capabilities and products will be built into the LLMs and owned by the likes of OpenAI, Microsoft, and Google and which will be performed by the surrounding startup ecosystem. This week we published a new blog\u00a0Learn Prompting 101: Prompt Engineering Course &#38; Challenges\u00a0as a summary of Prompt Engineering and how to talk to LLMs and get the most out of them. This forms an introduction to the comprehensive open-source\u00a0Learn Prompting course\u00a0that we have contributed to. Hottest News 1. Alphabet Stock Plunge Erases $100 Billion After New AI Chatbot Gives Wrong Answer In Ad Questions were raised about whether Alphabet rushed the release of its new Bard LLM after promotional material contained inaccurate information. This comes as Microsoft begins to integrate ChatGPT into its Bing search engine and opens a debate about how generative AI will change the way people browse and interact with the internet going forward. 2. Generative AI: The Next Consumer Platform We\u2019ve entered the age of generative AI. It could be the next major platform upon which founders build category-defining products. This article explores the main consumer categories with opportunities like search and product discovery, education, dating, coaching, e-commerce, and more. 3. Hands-on with the new Bing: Microsoft\u2019s step beyond ChatGPT Microsoft announced a new AI-powered version of the Bing search engine using the same technology behind ChatGPT. The way Microsoft has integrated these chatbot powers into its Edge browser is different from ChatGPT. This version allows you to ask questions about real-time news and events unfolding by integrating chatbot capabilities into its Edge browser. 4. China\u2019s Baidu reveals generative AI chatbot based on language model bigger than GPT-3 The Chinese web giant, Baidu, has made AI the focus of its hyperscale cloud and is set to launch a generative AI chatbot later this year. According to a Baidu spokesperson, the company plans to complete internal testing in March before making the chatbot available to the public. The spokesperson added that what sets ERNIE apart from other language models is its exceptional understanding and generation capabilities, thanks to its ability to integrate extensive knowledge with massive data. 5. Announcing the launch of the Medical AI Research Center (MedARC) Medical AI Research Center (MedARC) announced a new open and collaborative research center dedicated to advancing the field of AI in healthcare. MedARC aims to develop large AI models, also known as foundation models, for use in medicine and to build interdisciplinary teams that can address clinical needs. Three 5-minute reads/videos to keep you learning 1. Understanding Large Language Models \u2014 A Transformative Reading List In just five years, large language models (transformers) have revolutionized the field of natural language processing. To help researchers and practitioners get started with these models, this article provides a chronological reading list of academic research papers. The list covers the main architecture and tasks, scaling laws, improving efficiency, and steering large language models to intended goals and interests. 2. Machines Learn Better if We Teach Them the Basics Although AI agents have shown impressive performance in certain tasks, they often struggle to generalize to new environments and lack the abstract skills necessary to succeed in diverse contexts. This limitation arises from their limited foundation of concepts and the vast space of possibilities they must explore. To overcome this limitation, computer scientists are developing new techniques to teach machines foundational concepts before unleashing them into the wild. This article delves into the details of these emerging approaches and their potential impact on AI development. 3. Boltus, The God of AI \u2014 A four-episode series of learning to use AI with funny production This Twitter series is a four-episode guide to using AI, covering a range of topics. These include deploying diffusion models at scale, building text-to-image generators, integrating Stable Diffusion into a Slack workspace, and improving the speed of serving Stable Diffusion by 3x. 4. Solving a machine-learning mystery Researchers are studying a new concept called in-context learning, where a large language model can learn a new task after seeing only a few examples, without updating its parameters. This phenomenon could be explained by smaller, simpler linear models embedded in the larger model that can be trained to complete the new task using only existing information. This research sheds light on the learning algorithms that large models can use and could help models complete new tasks without costly retraining. Scientists from MIT, Google Research, and Stanford University are working to unravel this mystery. 5. The Most Important Job Skill of This Century A product race is underway in the world of artificial intelligence. AI evangelists believe generative AI will become the overlay for search engines, as well as creative work, memo writing, research, homework, sketching, outlining, storyboarding, and teaching. This means that the future of work could depend on how well people can talk to AI and the skill required to do so: prompt engineering. This article explains why. [&#8230;]",
            "pubdate": "Wed, 15 Feb 2023 09:37:10 +0000",
            "pubdate_parsed": [
                2023,
                2,
                15
            ],
            "email_sent": true
        },
        "Generative AI: The Future of Artificial Intelligence (AI)": {
            "url": "https://towardsai.net/p/generative-ai/generative-ai-the-future-of-artificial-intelligence-ai",
            "description": "Last Updated on February 14, 2023 by Editorial Team Source: Image generated by author via Midjourney Generative AI: The Future of Artificial Intelligence (AI) Creating the Future: How Generative AI is Set to Revolutionize Industries and Transform Society TL;DR: This article explores generative AI and provides an overview of its capabilities and applications. Generative AI involves the use of neural networks to create new content such as images, videos, or text. Its ability to create realistic and novel content has promising applications in fields such as entertainment, design, and medicine. It also raises ethical concerns around issues such as bias and the potential misuse of generated content. Disclaimer: This article uses Cohere for text generation. Generative AI is a fascinating field that has gained a lot of attention in recent years. It involves using machine learning algorithms to generate new data based on existing data. This technology has the potential to transform a wide range of industries, including healthcare, finance, and entertainment. In this article, we will explore what generative AI is, how it is being used today, and what the future holds for this exciting field. What is Generative AI? Generative AI is a subset of artificial intelligence (AI) that involves using algorithms to create new data. This can include anything from generating new images and videos to creating new text or music. The key difference between generative AI and other types of AI is that generative AI is focused on the creation of new data, rather than simply analyzing or processing existing data. Generative AI works by training algorithms on large datasets, which the algorithm can then use to generate new data. For example, a generative AI algorithm could be trained on a large dataset of images, and then use that training to create new, never-before-seen images. This approach has been used to create some incredible works of art, as well as some impressive technological innovations. How Is Generative AI Being Used\u00a0Today? Generative AI is being used in a wide range of industries today, from entertainment to healthcare. One of the most notable applications of generative AI is in the field of art, where it is being used to create stunning works of art that would be impossible for a human artist to create. In addition, generative AI is being used to create new music and even entire films. Another exciting application of generative AI is in the field of healthcare. Generative AI algorithms can be used to create new drugs, based on existing drugs or other data. This approach has the potential to revolutionize the field of medicine, allowing researchers to discover new treatments and cures faster than ever before. In the finance industry, generative AI is being used to create new financial models and trading algorithms. These algorithms can help traders and investors make more informed decisions, based on a wider range of data. This has the potential to make the financial markets more efficient and more profitable for everyone. What Are the Best Platforms for Generative AI Nowadays?? Cohere and OpenAI are two of the most widely used tools and platforms for generative AI. Cohere, a startup that specializes in natural language processing, has developed a reputation for creating sophisticated applications that can generate natural language with great accuracy. Their technology has been used to create chatbots, automated content generation, and many other natural language processing applications. OpenAI, on the other hand, is an AI research laboratory that was founded in 2015. The organization is dedicated to developing AI technologies that are safe and beneficial for society, with a particular focus on generative AI. OpenAI has created several tools for generative AI, including GPT-3, a powerful autoregressive language model that has received a great deal of attention for its ability to generate coherent and natural-sounding text. Both Cohere and OpenAI have made significant contributions to the field of generative AI, and their platforms and tools are widely used by researchers, developers, and organizations around the world. With the continued growth and development of generative AI, it is likely that we will see even more innovative tools and platforms emerging in the years to come. How to Get Started With Generative AI? Getting started with generative AI can be a daunting task, but it is not as difficult as you might think. The first step is to learn the basics of machine learning and deep learning, which are the technologies that underpin generative AI. There are many resources available online, including free courses and tutorials. Once you have a basic understanding of machine learning, you can start exploring generative AI by experimenting with different algorithms and datasets. There are many open-source libraries and tools available that can help you get started, including Cohere, OpenAI, or AI2Labs. Source: Image generated by author via Midjourney What Is the Future of Generative AI? Looking ahead, the future of generative AI is undoubtedly bright. As technology continues to evolve, we can expect to see even more advanced and sophisticated applications emerging in a wide range of industries. One of the most exciting prospects for the future of generative AI is the development of even more powerful algorithms that are capable of generating more complex and nuanced outputs. This could include everything from virtual reality environments to music and art, and it has the potential to transform the way we experience and interact with technology. Another important trend to watch in the future of generative AI is the growing focus on ethical and responsible AI development. With the potential of AI to impact society in profound ways, it is crucial that we take a responsible approach to its development and use. This includes ensuring that AI is used in ways that benefit society, and that it is designed to be transparent and explainable. Overall, there is no doubt that generative AI will play an increasingly important role in shaping the future of technology and society. As more researchers and developers continue to explore this field, we can expect to see [&#8230;]",
            "pubdate": "Wed, 15 Feb 2023 03:25:02 +0000",
            "pubdate_parsed": [
                2023,
                2,
                15
            ],
            "email_sent": true
        },
        "Top AI Conferences in 2023": {
            "url": "https://towardsai.net/p/artificial-intelligence/top-ai-conferences-in-2023",
            "description": "Last Updated on February 19, 2023 by Editorial Team Source: Image generated by the author with generative AI via Midjourney. Exploring the Top AI Conferences in 2023: A Must-Attend for Researchers and Practitioners Alike TL;DR: Get ahead in the AI game by attending these top conferences in 2023! From NeurIPS to KDD, these events bring together the best and brightest minds in the field to share the latest research, developments, and insights. Whether you\u2019re a researcher or practitioner, don\u2019t miss your chance to stay up-to-date and network with other professionals in the field. Disclaimer: This article uses Cohere for text generation. The world of artificial intelligence (AI) is rapidly advancing with new discoveries and breakthroughs emerging at an unprecedented pace. For researchers and practitioners in the field, staying current and connected is vital, and attending top AI conferences in 2023 can offer unique opportunities for collaboration, inspiration, and professional growth. From NeurIPS to KDD, these conferences bring together leading experts in machine learning, deep learning, natural language processing, and more. Whether you\u2019re an established researcher, an aspiring practitioner, or just passionate about the latest AI developments, these conferences are a must-attend. So join the excitement and start planning your trip to one of these top AI conferences in 2023. NeurIPS NeurIPS (the Conference on Neural Information Processing Systems) is one of the premier AI conferences, and it brings together researchers, practitioners, and industry professionals from around the world. The conference features keynote talks, paper presentations, workshops, and tutorials covering a broad range of topics in machine learning, deep learning, computer vision, natural language processing, and more. NeurIPS 2023 is set to take place in Vancouver, Canada, in December. Location: New Orleans, LA Conference Dates: Dec 10\u201316, 2023 ICML The International Conference on Machine Learning (ICML) is a leading forum for researchers, practitioners, and industry professionals to share and discuss the latest research and applications in machine learning. The conference features paper presentations, workshops, and tutorials covering a wide range of topics, including deep learning, reinforcement learning, and probabilistic modeling. ICML 2023 is scheduled to take place in Amsterdam, Netherlands, in July. Location: Honolulu, HI Conference Dates: Jul 23\u201329, 2023 ICLR The International Conference on Learning Representations (ICLR) is a premier conference in the field of deep learning, featuring papers, posters, and invited talks from leading researchers and practitioners. The conference covers a wide range of topics, including computer vision, natural language processing, and reinforcement learning. ICLR 2023 will be held in Sydney, Australia, in April. Location: Kigali, Rwanda Conference Dates: May 1\u20135, 2023 AISTATS The Conference on Artificial Intelligence and Statistics (AISTATS) brings together researchers in machine learning, statistics, and related fields to discuss the latest advances in AI and its applications. The conference features invited talks, paper presentations, and poster sessions covering a wide range of topics, including Bayesian inference, graphical models, and deep learning. AISTATS 2023 will be held in Barbados in April. Location: Palau de Congressos, Valencia, Spain Conference Dates: Apr 25\u201327, 2023 AAAI The Association for the Advancement of Artificial Intelligence (AAAI) hosts an annual conference that brings together researchers and practitioners in AI and related fields. The conference features technical presentations, invited talks, and workshops on a wide range of topics, including machine learning, natural language processing, robotics, and AI ethics. AAAI 2023 will be held in Austin, Texas, in February. Location: Washington, DC Conference Dates: February 7\u201314, 2023 KDD The ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD) is one of the premier conferences in data mining and machine learning, featuring keynote talks, paper presentations, and workshops on a wide range of topics. The conference covers a range of topics, including data mining, machine learning, and artificial intelligence. KDD 2023 will be held in San Diego, California, in August. Location: Long Beach, CA Conference Dates: Aug 6\u201310, 2023 Attending the top AI conferences in 2023 can offer a wealth of opportunities for researchers and practitioners in the field. These conferences bring together the brightest minds in the industry to share their latest research, insights, and innovations. Whether you\u2019re looking to network with other professionals, learn from leading experts, or simply stay up-to-date with the latest developments, these events are not to be missed. So start planning your trip, mark your calendar, and get ready to be inspired by the cutting-edge research and ideas presented at these top AI conferences in 2023! Don\u2019t miss out on the chance to be a part of the forefront of AI research and development. Support me in this generative AI journey by becoming a member or by buying me a coffee. Follow me on Linkedin or my website to stay tuned on generative AI.",
            "pubdate": "Mon, 20 Feb 2023 00:09:08 +0000",
            "pubdate_parsed": [
                2023,
                2,
                20
            ],
            "email_sent": true
        },
        "We employed ChatGPT as an ML Engineer. This is what we learned": {
            "url": "https://towardsai.net/p/machine-learning/we-employed-chatgpt-as-an-ml-engineer-this-is-what-we-learned",
            "description": "Author(s): Eric Landau, Co-founder and CEO, Encord TLDR; Among the proliferation of recent use cases using the AI application ChatGPT, we ask whether it can be used to make improvements in other AI systems. We test it on a practical problem in a modality of AI in which it was not trained, computer vision, and report the results. The average over ChatGPT metric suggestions, achieves on average 10.1% improvement in precision and 34.4% improvement in recall over our random sample, using a purely data-centric metric-driven approach. The code for the post is here. Introduction Few technological developments have captured the public imagination as quickly and as starkly as the release of ChatGPT by OpenAI. Within two months of launch, it had garnered over 100 million users, the fastest public application to do so in history. While many see ChatGPT as a leap forward technologically, its true spark wasn\u2019t based on a dramatic technological step change (GPT3, the model it is based on has been around for almost 3 years), but instead on the fact that it was an AI application perfectly calibrated towards individual human interactions. It was its ostentatiousness as an AI system that could demonstrate real-world value that so thoroughly awed the public. Forms of AI are present in various aspects of modern life but are mostly hidden away (Google searches, Youtube recommendations, spam filters, identity recognition) in the background. ChatGPT is one of the few that is blatantly artificial, but also intelligent. AI being in the limelight has spawned a deluge of thought pieces, articles, videos, blog posts, and podcasts. Amid this content rush have been renewed questions and concerns around the more provocative implications of AI advancement, progression towards AI consciousness, artificial general intelligence(AGI), and a technological singularity. In the most speculative scenarios, the fear (or hope depending on who you ask) is that the sophistication, power, and complexity of our models will eventually breach an event horizon of breakaway intelligence, where the system develops the capability to iteratively self-improve both it\u2019s core functionality and it\u2019s own ability to self-improve. This can create an exponentially growing positive reinforcement cycle spurring an unknowable and irreversible transition of society and human existence as we know it. Not yet, ChatGPT To be clear\u2026 that\u2019s not where we are. ChatGPT is not the dawn of the Terminator. Prognosticating on the direction of a technology still in rapid development is often a folly, and on its broader implications even more so. However, in the presence of a large looming and unanswerable question, we can still develop insights and intuition by asking smaller, more palatable ones. In that vein, we look for a simpler question we can pose and subsequently test on the topic of AI self-improvement: Can we find an avenue by which we can examine if one AI system can iteratively improve another AI system? We observe that the main agents at the moment for AI progression are people working in machine learning as engineers and researchers. A sensible proxy sub-question might then be: Can ChatGPT function as a competent machine learning engineer? The Set Up If ChatGPT is to function as an ML engineer, it is best to run an inventory of the tasks that the role entails. The daily life of an ML engineer includes among others: Manual inspection and exploration of data Training models and evaluating model results Managing model deployments and model monitoring processes. Writing custom algorithms and scripts. The thread tying together the role is the fact that machine learning engineers have to be versatile technical problem solvers. Thus, rather than running through the full gamut of ML tasks for ChatGPT, we can focus on the more abstract and creative problem-solving elements of the role. We will narrow the scope in a few ways by having ChatGPT: Work specifically in the modality of computer vision: We chose computer vision both as it is our expertise and because as a large language model, ChatGPT, did not (as far as we know) have direct access to any visual media in its training process. It thus approaches this field from a purely conceptual point of view. Reason over one concrete toy problem: In honor of both the Python library we all know and love and the endangered animal we also all know and love, we pick our toy problem to be building a robust object detector of pandas. We will use data from the open-source YouTube-VOS dataset, which we have relabelled independently and with deliberate mistakes. Take an explicitly data-centric approach: We choose a data-centric methodology as it is often what we find has the highest leverage for practical model development. We can strip out much of the complication of model and parameter selection so that we can focus more on improving the data and labels being input into the model for training. Taking a more model-centric approach of running through hyperparameters and model architectures, while important, will push less on testing abstract reasoning abilities from ChatGPT. Use existing tools: To further simplify the task, we remove any dependence on internal tools ML engineers often build for themselves. ChatGPT (un)fortunately can\u2019t spend time in a Jupyter Notebook. We will leverage the Encord platform to simplify the model training/inference by using Encord\u2019s micro-models and running data, label, and model evaluation through the open-source tool Encord Active. The code for running the model training is presented below. With this narrowed scope in mind, our approach will be to use ChatGPT to write custom quality metrics through Encord Active that we can run over the data, labels, and model predictions to filter and clean data in our panda problem. Quality metrics are additional parametrizations over your data, labels, and models; they are methods of indexing training data and predictions in semantically interesting and relevant ways. Examples can include everything from more general attributes like the blurriness of an image to arbitrarily specific ones like the number of average distance between pedestrians in an image. ChatGPT\u2019s job as our ML engineer [&#8230;]",
            "pubdate": "Tue, 21 Feb 2023 13:00:06 +0000",
            "pubdate_parsed": [
                2023,
                2,
                21
            ],
            "email_sent": true
        },
        "Proving the Convexity of Log-Loss for Logistic Regression": {
            "url": "https://towardsai.net/p/l/proving-the-convexity-of-log-loss-for-logistic-regression",
            "description": "Last Updated on February 25, 2023 by Editorial Team Author(s): Towards AI Editorial Team Originally published on Towards AI. Unpacking Log Loss Error Function\u2019s Impact on Logistic Regression Photo by DeepMind on\u00a0Unsplash Author(s): Pratik\u00a0Shukla \u201cCourage is like a muscle. We strengthen it by use.\u201d\u200a\u2014\u200aRuth\u00a0Gordo Table of Contents: Proof of convexity of the log-loss function for logistic regression A visual look at BCE for logistic regression Resources and references Introduction In this tutorial, we will see why the log-loss function works better in logistic regression. Here, our goal is to prove that the log-loss function is a convex function for logistic regression. Once we prove that the log-loss function is convex for logistic regression, we can establish that it\u2019s a better choice for the loss function. Logistic regression is a widely used statistical technique for modeling binary classification problems. In this method, the log-odds of the outcome variable is modeled as a linear combination of the predictor variables. To estimate the parameters of the model, the maximum likelihood method is used, which involves optimizing the log-likelihood function. The log-likelihood function for logistic regression is typically expressed as the negative sum of the log-likelihoods of each observation. This function is known as the log-loss function or binary cross-entropy loss. In this blog post, we will explore the convexity of the log-loss function and why it is an essential property in optimization algorithms used in logistic regression. We will also provide a proof of the convexity of the log-loss function. Proof of convexity of the log-loss function for logistic regression: Let\u2019s mathematically prove that the log-loss function for logistic regression is\u00a0convex. We saw in the previous tutorial that a function is said to be a convex function if its second derivative is &#62;0. So, here we\u2019ll take the log-loss function and find its second derivative to see whether it\u2019s &#62;0 or not. If it\u2019s &#62;0, then we can say that it is a convex function. Here we are going to consider the case of a single trial to simplify the calculations. Step\u200a\u2014\u200a1: The following is a mathematical definition of the binary cross-entropy loss function (for a single\u00a0trial). Figure\u200a\u2014\u200a1: Binary Cross-Entropy loss for a single\u00a0trial Step\u200a\u2014\u200a2: The following is the predicted value (\u0177) for logistic regression. Figure\u200a\u2014\u200a2: The predicted probability for the given\u00a0example Step\u200a\u2014\u200a3: In the following image, z represents the linear transformation. Figure\u200a\u2014\u200a3: Linear transformation in forward propagation Step\u200a\u2014\u200a4: After that, we are modifying Step\u200a\u2014\u200a1 to reflect the values of Step\u200a\u2014\u200a3 and Step\u200a\u2014\u200a2. Figure\u200a\u2014\u200a4: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Step\u200a\u2014\u200a5: Next, we are simplifying the terms in Step\u200a\u2014\u200a4. Figure\u200a\u2014\u200a5: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Step\u200a\u2014\u200a6: Next, we are further simplifying the terms in Step\u200a\u2014\u200a5. Figure\u200a\u2014\u200a6: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Step\u200a\u2014\u200a7: The following is the quotient rule for logarithms. Figure\u200a\u2014\u200a7: The quotient rule for logarithms Step\u200a\u2014\u200a8: Next, we are using the equation from Step\u200a\u2014\u200a7 to further simplify Step\u200a\u2014\u200a6. Figure\u200a\u2014\u200a8: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Step\u200a\u2014\u200a9: In Step\u200a\u2014\u200a8, the value of log(1) is going to be\u00a00. Figure\u200a\u2014\u200a9: The value of\u00a0log(1)=0 Step\u200a\u2014\u200a10: Next, we are rewriting Step\u200a\u2014\u200a8 with the remaining terms. Figure\u200a\u2014\u200a10: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Step\u200a\u2014\u200a11: The following is the power rule for logarithms. Figure\u200a\u2014\u200a11: Power rule for logarithms Step\u200a\u2014\u200a12: Next, we will use the power rule of logarithms to simplify the equation in Step\u200a\u2014\u200a10. Figure\u200a\u2014\u200a12: Applying the power\u00a0rule Step\u200a\u2014\u200a13: Next, we are replacing the values in Step\u200a\u2014\u200a10 with the values in Step\u200a\u2014\u200a12. Figure\u200a\u2014\u200a13: Using the power rule for logarithms Step\u200a\u2014\u200a14: Next, we are substituting the value of Step\u200a\u2014\u200a13 into Step\u200a\u2014\u200a10. Figure\u200a\u2014\u200a14: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Step\u200a\u2014\u200a15: Next, we are multiplying Step\u200a\u2014\u200a14 by (-1) on both\u00a0sides. Figure\u200a\u2014\u200a15: Binary Cross-Entropy loss for logistic regression for a single\u00a0trial Finding the First Derivative: Step\u200a\u2014\u200a16: Next, we are going to find the first derivative of\u00a0f(x). Figure\u200a\u2014\u200a16: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a17: Here we are distributing the partial differentiation sign to each\u00a0term. Figure\u200a\u2014\u200a17: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a18: Here we are applying the derivative rules. Figure\u200a\u2014\u200a18: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a19: Here we are finding the partial derivative of the last term of Step\u200a\u2014\u200a18. Figure\u200a\u2014\u200a19: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a20: Here we are finding the partial derivative of the first term of Step\u200a\u2014\u200a18. Figure\u200a\u2014\u200a20: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a21: Here we are putting together the results of Step\u200a\u2014\u200a19 and Step\u200a\u2014\u200a20. Figure\u200a\u2014\u200a21: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a22: Next, we are rearranging the terms of the equation in Step\u200a\u2014\u200a21. Figure\u200a\u2014\u200a22: Finding the first derivative of\u00a0f(w) Step\u200a\u2014\u200a23: Next, we are rewriting the equation in Step\u200a\u2014\u200a22. Figure\u200a\u2014\u200a23: Finding the first derivative of\u00a0f(w) Finding the Second Derivative: Step\u200a\u2014\u200a24: Next, we are going to find the second derivative of the function\u00a0f(x). Figure\u200a\u2014\u200a24: Finding the second derivative of\u00a0f(w) Step\u200a\u2014\u200a25: Here we are distributing the partial derivative to each\u00a0term. Figure\u200a\u2014\u200a25: Finding the second derivative of\u00a0f(w) Step\u200a\u2014\u200a26: Next, we are simplifying the equation in Step\u200a\u2014\u200a25 to remove redundant terms. Figure\u200a\u2014\u200a26: Finding the second derivative of\u00a0f(w) Step\u200a\u2014\u200a27: Here is the derivative rule for\u00a01/f(x). Figure\u200a\u2014\u200a27: The derivative rule for\u00a01/f(x) Step\u200a\u2014\u200a28: Next, we are finding the relevant term to plug-in in Step\u200a\u2014\u200a27. Figure\u200a\u2014\u200a28: Value of p(w) for derivative of\u00a01/p(w) Step\u200a\u2014\u200a29: Here we are finding the partial derivative term for Step\u200a\u2014\u200a27. Figure\u200a\u2014\u200a29: Value of p\u2019(w) for derivative of\u00a01/p(w) Step\u200a\u2014\u200a30: Here we are finding the squared term for Step\u200a\u2014\u200a27. Figure\u200a\u2014\u200a30: Value of p(w)\u00b2 for derivative of\u00a01/p(w) Step\u200a\u2014\u200a31: Here we are putting together all the terms of Step\u200a\u2014\u200a27. Figure\u200a\u2014\u200a31: Calculating the value of the derivative of\u00a01/p(w) Step\u200a\u2014\u200a32: Here we are simplifying the equation in Step\u200a\u2014\u200a31. Figure\u200a\u2014\u200a32: Calculating the value of the derivative of\u00a01/p(w) Step\u200a\u2014\u200a33: Next, we are putting together all the values in Step\u200a\u2014\u200a26. Figure\u200a\u2014\u200a33: Finding the second derivative of\u00a0f(w) Step\u200a\u2014\u200a34: Next, we are further simplifying the terms in Step\u200a\u2014\u200a33. Figure\u200a\u2014\u200a34: Finding the second derivative of\u00a0f(w) Alright! So, now we have the second derivative of the function f(x). Next, we need to find out whether this will be &#62;0 for all the values of x or not. If it is &#62;0 [&#8230;]",
            "pubdate": "Sat, 25 Feb 2023 09:00:33 +0000",
            "pubdate_parsed": [
                2023,
                2,
                25
            ],
            "email_sent": true
        },
        "A Web App for Automated E-mail Writing From Voice Notes, Using GPT-3": {
            "url": "https://towardsai.net/p/l/a-web-app-for-automated-e-mail-writing-from-voice-notes-using-gpt-3",
            "description": "Last Updated on February 25, 2023 by Editorial Team Author(s): LucianoSphere Originally published on Towards AI. I coupled Chrome&#x2019;s speech recognition engine with GPT-3 to create a web app that writes e-mails from your spoken notes and indications&#x2026; Continue reading on Towards AI Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sat, 25 Feb 2023 09:00:26 +0000",
            "pubdate_parsed": [
                2023,
                2,
                25
            ],
            "email_sent": true
        },
        "Best Laptops for Deep Learning, Machine Learning (ML), and Data Science for2023": {
            "url": "https://towardsai.net/p/news/best-laptops-for-machine-learning-deep-learning-data-science-ml-f55602197593",
            "description": "Last Updated on March 5, 2023 by Editorial Team Source: Image generated with generative AI via Midjourney.\u00a0 Get ahead in the AI game with our top picks for laptops that are perfect for machine learning, data science, and deep learning at every budget. After analyzing over 8,000 options [8], we\u2019ve identified the best of the best to help future-proof your AI\u00a0rig. Last updated March 5, 2023 Are you tired of endlessly scouring the internet for the perfect laptop to power your machine learning, deep learning, and data science projects? Well, search no further! We\u2019ve done the heavy lifting for you by sifting through a whopping 8,000 laptops to bring you only the most powerful and efficient machines for every budget. Whether you\u2019re looking for top-of-the-line laptops or more affordable options, we\u2019ve got you covered. With our expert recommendations, you can stay ahead of the game and future-proof your AI setup. We\u2019ll keep updating this resource as technology evolves to provide you with even more powerful and efficient laptops for every budget. Our inbox is inundated with emails from fellow AI enthusiasts who are seeking the best laptops for their AI projects, which inspired us to create this list. If you have any suggestions to add to the list, please feel free to shoot us an email at pub@towardsai.net. Disclosure: Our editorial team at Towards AI writes authentic and trustworthy reviews and may receive a small compensation for products we select to support Towards AI\u2019s efforts. For this article, as an Amazon Associate, Towards AI may receive a small commission from qualifying purchases made from it (at no extra cost to the buyer). For feedback, questions, or concerns, please email us at pub@towardsai.net. Key Considerations for Choosing a Laptop for ML and Data\u00a0Science Processor: A powerful CPU is crucial for running complex ML algorithms and data analysis. Look for a laptop with an Intel Core i7 or i9 processor or an AMD Ryzen 7 or 9 processor. GPU: The GPU (graphics processing unit) is important for running deep learning algorithms, as it can handle parallel processing much faster than a CPU. Look for a laptop with a dedicated GPU, such as an NVIDIA GeForce or Quadro, or an AMD Radeon. RAM: The more RAM your laptop has, the better it can handle large data sets and complex ML models. Look for a laptop with at least 16GB of RAM, but 32GB or more is ideal. Storage: Data sets for deep learning and data science can be massive, so you\u2019ll want a laptop with plenty of storage. Look for a laptop with at least a 512GB SSD, or consider one with multiple drives or the ability to add external storage. Display: A high-quality display is important for visualizing data and models. Look for a laptop with a resolution of at least 1080p, or consider a 4K display for even more detail. You may also want to consider a laptop with a high color gamut, such as Adobe RGB or DCI-P3. By considering these factors, you can find a laptop that will handle the demands of deep learning, machine learning and data science, allowing you to work efficiently and effectively. ???? Check out our editorial recommendations for the best deep learning workstations. ???? Let\u2019s get started! For Budgets under $ 1,000.00\u00a0\u2193 Source: Amazon Lenovo Legion\u00a05 Updated: [Tie] Best laptop under $ 1k. Ideal for data leaders who care about AMD processors, excellent RAM size, and an RTX 3050ti GPU under a $ 1k budget. Specs: Processor: AMD Ryzen 5 5600H (Hexa-core, 12 Threads, base clock speed 3.3 GHz, max turbo to 4.2GHz, 16MB L3 Cache) Memory: 32GB (16GB x 2) DDR4 3200MHz Hard Drive: 2TB PCIe SSD GPU: Dedicated NVIDIA GeForce RTX 3050 Ti 4 GB GDDR6, Boost clock up to 1695MHz, TGP up to 95W Computing Power: 8.6 [9] Ports: 1x USB-C 3.2 Gen 2 (support data transfer, Power Delivery, and DisplayPort 1.4), 1x USB-C 3.2 Gen 2 (support data transfer and DisplayPort 1.4), 1x USB 3.2 Gen 1 (Always On), 3x USB 3.2 Gen 1 1x HDMI 2.1, 1x Ethernet (RJ-45), 1x Headphone/microphone combo jack (3.5mm) OS: Windows 11 Home Weight: 5.3 lbs Display: 15.6&#8243; Full HD (1920&#215;1080) IPS 250nits Anti-glare, 45% NTSC, 120Hz, FreeSync Connectivity: Wi-Fi 6, 11ax 2&#215;2 + Bluetooth 5.1 Battery life: Average ~ 4 hours. Grab one on Amazon Source: Amazon ASUS TUF Gaming\u00a0A15 Updated: [Tie] Best laptop under $ 1k. Ideal for data leaders who care about Intel processors, suitable RAM size, and RTX 3050ti GPUs under a $ 1k budget. Specs: Processor: AMD Ryzen 7 8-core Processor AMD R7\u20136800H 16 MB Cache, Base Clock 3.2Ghz, Max Boost Clock 4.7Ghz, Memory: 32GB DDR5 Memory Hard Drives: 1TB SSD GPU: NVIDIA GeForce RTX 3050 Ti 4 GB. Computing Power: 8.6 [9] Ports: 2 X USB 3.1 Type A &#124; 1 X DisplayPort &#124; 1 X RJ-45 &#124; 1 X Headphone/Speaker/Line-Out Jack &#124; 2 X USB 3.1 TYPE-C &#124; 1 X HDMI &#124; OS: Windows 10 Home. Weight: 4.85 lbs. Display: 144Hz Full HD 1920&#215;1080 display Connectivity: WiFi 802.11ax, Gigabit LAN (Ethernet), Bluetooth. Battery life: Average ~ 4 hours. Grab one on Amazon Source: Amazon Dell Mytrix\u00a0G15 Updated: Fantastic laptop under $ 1k. Ideal for those who care about AMD processors, suitable RAM size, and RTX 30XX GPUs under a $ 1k budget. Specs: Processor: AMD Ryzen 5 5600H 3.30 GHz Memory: 16 GB DDR4. Hard Drives: 512 GB NVMe SSD. GPU: NVIDIA GeForce RTX 3050 Ti 4 GB. Computing Power: 8.6 [9] Ports: 1x HDMI 2.0, 1x USB 3.1 Type-C, 2x USB 3.1, 1x USB 2.0. OS: Windows 10 Home. Weight: 5.39 lbs. Display: 15.6, 1920 x 1080. Connectivity: WiFi 802.11ax, Gigabit LAN (Ethernet), Bluetooth. Battery life: Average ~ 4 hours. Grab one on Amazon Performance comparison RTX 3060 vs. RTX 2070\u00a0[11] For Budgets under $ 2,000.00\u00a0\u2193 Source: Amazon Acer Predator Helios\u00a0300 Updated: [Tie] Best laptop under $ 2k. Ideal for data leaders who want the best under a $ 2k budget, care about Intel processors, [&#8230;]",
            "pubdate": "Mon, 06 Mar 2023 01:00:49 +0000",
            "pubdate_parsed": [
                2023,
                3,
                6
            ],
            "email_sent": true
        },
        "Correlation and Causation: What are the Differences?": {
            "url": "https://towardsai.net/p/machine-learning/correlation-and-causation-what-are-the-differences",
            "description": "Last Updated on March 23, 2023 by Editorial Team Author(s): Cornellius Yudha Wijaya &#160; Originally published on Towards AI. Learn the differences between both concepts Photo by Sam Moghadam Khamseh on Unsplash In statistics and data science, we often encounter correlation and causation terms. Albeit, the correlation was mentioned more often compared to causation. Nevertheless, their meaning is often associated with how two variables are related. However, correlation and causation are two different terms that stand by their definition. It&#8217;s two different concepts that might be intertwined and used together, but we still need to know the differences. So, what are correlation and causation? Also, what are the differences between them and their usefulness? Let&#8217;s explore the concept a little bit. Correlation and Causation Correlation Let&#8217;s&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 24 Mar 2023 00:11:07 +0000",
            "pubdate_parsed": [
                2023,
                3,
                24
            ],
            "email_sent": true
        },
        "Trends in AI  April 2023 // GPT-4, New Prompting Tricks, Zero-shot Video Generation": {
            "url": "https://towardsai.net/p/machine-learning/trends-in-ai-april-2023-gpt-4-new-prompting-tricks-zero-shot-video-generation",
            "description": "Last Updated on April 12, 2023 by Editorial Team Author(s): Sergi Castella i Sap\u00e9 Originally published on Towards AI. GPT-4 has arrived; it\u2019s already everywhere. ChatGPT plugins bring augmented LMs to the masses, new Language Model tricks are discovered, Diffusion models for video generation, Neural Radiance Fields, and more. Just three weeks after the announcement of GPT-4, it already feels like it\u2019s been with us forever. Meanwhile, an open letter with high-profile signatories calling for a stop on giant AI experiments went viral, and subsequently, the AGI discourse has been unleashed and Eliezer Yudkowsky\u2019s imminent superintelligence doom existential risk theories have made it to Times Magazine. If you\u2019ve got a case of existential angst over a hypothetical intelligence explosion, here\u2019s a phenomenal based take from Julian Togelius that can soothe your soul. With that out of the way, let\u2019s start looking at what happened recently in the AI world. ????\ufe0f News ChatGPT plugins: ChatGPT can now interact with external modules via natural language and act as an augmented language model. For instance, using WolframAlpha for information about the world and sound computation, or Kayak to search for flights, stays or rental cars. Italy banned ChatGPT temporarily last week on the grounds that it violates GDPR. While OpenAI complied with the ban, this has left the EU in a weird spot with growing uncertainties about what Language Model technologies will be allowed in the old continent. Stanford\u2019s Center for Research on Foundation Models (CRFM) unveiled Alpaca, an instruction-following model trained by distilling OpenAI\u2019s models using Meta\u2019s LLAMA as a base model. Since then, the past couple of weeks has seen a good amount of similar open-source distillations from GPT models, such as Vicuna (Post, Demo, Repo) an up to 13B instruction-following model trained by distilling from conversations people have shared from ChatGPT (via ShareGPT). Stanford released their annual AI Index Report for 2023, highlighting, among others, how much AI research has shifted from academia into the industry and quantifying the growth that the field has experienced in the past decade. Midjourney (an independent research lab) has the world in awe with its new v5 image generation model. Adobe is building competing products for its creative suit, but it looks like they are struggling to have on-par quality, as they\u2019re more cautious with training data to avoid using copyrighted data inadvertently. Runway \u2014 the company behind Stable Diffusion \u2014 has been touting their new video generation product Gen 2. Nvidia announced during their latest developer conference their efforts to become the leading foundry for large foundation models. Clients will be able to define a model they want to train and Nvidia will use their infrastructure and expertise to train the model for them. Meanwhile, Google outlined in more detail their latest TPU v4 accelerators in their latest paper. GitHub announced Copilot X, a big update to Copilot that adds chat and voice interface features, supports pull request completions, question answering on documentation, and adopts GPT-4. ???? Research This month, our selection of research includes GPT-4, applications of language models, diffusion models, computer vision, video generation, recommender systems, and neural radiance fields. 1. GPT-4 Technical Report // Sparks of Artificial General Intelligence: Early experiments with GPT-4 By S\u00e9bastien Bubeck, Varun Chandrasekaran, Ronen Eldan, Johannes Gehrke, Eric Horvitz, Ece Kamar, Peter Lee, Yin Tat Lee, Yuanzhi Li, Scott Lundberg, Harsha Nori, Hamid Palangi, Marco Tulio Ribeiro, Yi Zhang. \u2753 Why \u2192 The already famous GPT-4 from OpenAI has been the uncontested star this past month. But its release has generated more questions than its technical report chose to answer. Hence the addition here of the massive evaluation paper that examines its behavior in more detail. Of course, the writing of this very text was aided by GPT-4. ???? Key insights \u2192 This evaluation paper is filled with samples and anecdotes from GPT-4 experiments. While this cherry-picking approach is unapologetically motivated and biased, it turns out to be an essential tool for grasping the behavior of this powerful model. Not a replacement for the big tables with bold numbers, but a necessary companion. The hilarious example: how GPT-4 ability to draw a unicorn in TikZ (LaTeX) improved over time while the model was still under active development. Source: https://arxiv.org/pdf/2303.08774.pdf The 155-page evaluation report covers a vast range of topics, such as multimodal capabilities, mathematical reasoning, coding, human interaction, and societal influences. The authors argue that GPT-4 shows some behavior that could be labeled general intelligence while acknowledging its limitations and caveats. The cluelessness of Microsoft\u2019s researchers highlights the secrecy involved in this project: the authors from the very tech giant who partnered with OpenAI and provided the infrastructure for training GPT-4 didn\u2019t seem to have details of GPT-4 beyond having access to a mysterious API endpoint. 2. Larger language models do in-context learning differently By Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, Xinyun Chen, Hanxiao Liu, Da Huang, Denny Zhou, Tengyu Ma. \u2753 Why \u2192 The emergence of complex in-context learning in large language models has piqued everyone\u2019s interest. This article delves into some niche but fascinating emerging capabilities from large language models that are not present in their smaller counterparts. ???? Key insights \u2192 Larger models possess unique abilities that smaller models simply can\u2019t replicate, no matter how much data and effort is put to into it. For example, large models can learn within the prompt to flip labels and learn new mappings, such as reversing the sentiment labels of sentences (e.g., positive sentences are labeled negative and vice versa). Source: https://arxiv.org/pdf/2303.03846.pdf The main emergence study reveals: Large models learn to flip labels, while smaller models stick to their pre-trained knowledge, continuing to label positive as positive and negative as negative. Semantically unrelated labels (SUL) emerge with scale, where the models label things with tokens that are not words. Instruction-tuned models strengthen both the use of semantic priors and the capacity to learn input-label mappings. However, they place more emphasis on the former aspect. 3. Reflexion: an autonomous [&#8230;]",
            "pubdate": "Wed, 12 Apr 2023 04:01:45 +0000",
            "pubdate_parsed": [
                2023,
                4,
                12
            ],
            "email_sent": true
        },
        "Launching our LangChain & Vector DBs in Production course  50+ lessons & practical projects for free": {
            "url": "https://towardsai.net/p/machine-learning/launching-our-langchain-vector-dbs-in-production-course-50-lessons-practical-projects-for-free",
            "description": "Last Updated on June 21, 2023 by Editorial Team We\u2019re thrilled to announce an exciting collaboration between Towards AI,\u00a0Activeloop, and the Intel Disruptor Initiative. We are launching the\u00a0Foundational Model Certification course, an educational journey for the next generation of AI professionals and enthusiasts. Consistent with our commitment at Towards AI, this course aims to empower AI enthusiasts with advanced tools and resources, paving the path to create impactful AI solutions. Spanning over 50 lessons and 10 practical projects, the course offers a comprehensive exploration of Large Language Models (LLMs), leveraging the capabilities of LangChain and Deep Lake. LangChain, a potent tool for working with LLMs, coupled with Deep Lake, the vector database for all AI data that provides serverless memory to LLMs, forms the course\u2019s centerpiece. The course is divided into eight modules, featuring over 50 practical lessons. Below are some key concepts and topics included in the course: From Zero to Hero with LangChain: A comprehensive introduction to the essential concepts, set up, and usage of Large Language Models (LLMs), LangChain, and Deep Lake. Large Language Models and LangChain: An in-depth exploration of Large Language Models and LangChain, with practical experience gained through the development of a News Articles Summarizer project. Learning How to Prompt: Gain proficiency in prompt engineering techniques and apply them in practice. Learn tips and tricks for prompting like role prompting, few shot prompting, chain of thought, and the ReAct framework. Keeping Knowledge Organized with Indexes: Exploring The Role of LangChain\u2019s Indexes and Retrievers: pros and cons of leveraging documents as the base for the LLMs and how to do that with retrievers and indexes. Build an automated customer support agent. Combining Components Together with Chains: Exploring The Role of LangChain\u2019s Indexes and Retrievers: pros and cons of leveraging documents as the base for the LLMs and how to do that with retrievers and indexes. Build an automated customer support agent. Giving Memory to LLMs: This module will aim to help you mastering Memory Types in LangChain and build chat with any data solutions \u2014 to be deployed locally or on the cloud. Making LLMs Interact with the World Using Tools: This module explores LangChain\u2019s tools and their applications, with hands-on projects that enhance blog posts, recreate a Bing chatbot, and demonstrate multiple tool usage. Using Language Model as Reasoning Engines with Agents: The final module introduces the concept of agents in LangChain, with a focus on creating autonomous agents for comprehensive analysis reports. The certification course is the inaugural part of the Gen AI 360: Foundational Model Certification program, which is designed to arm AI developers with the tools necessary to apply Large Language Models across industries. Get started with the\u00a0LangChain &#38; Vector Databases in Production course\u00a0today, free of charge. If you haven\u2019t already, please join the course companion\u00a0Discord Channel\u00a0and the\u00a0Activeloop Slack community\u00a0if you have any questions on Deep Lake. Louie Peters;\u00a0\u201cAs the CEO of Towards AI, I am thrilled to be part of this groundbreaking initiative. Each month, we reach over 385,000 AI developers through our platform. Our aim has always been to educate and upskill these passionate engineers in this rapidly expanding field.\u201d What sets this course apart is its practicality. It\u2019s designed for engineers to implement AI into their company processes or use Foundational Models to build entirely new products. The future is right here, right now. Foundational Models and vector databases are quickly becoming integral components in the day-to-day operations of companies across the globe. Upon course completion, developers certified by Deep Lake will have the ability to harness the full potential of Large Language Models, Deep Lake, and LangChain, paving the way for accelerated AI adoption in their respective fields. But this course isn\u2019t just for engineers. Technology executives too could greatly benefit from this course, staying at the forefront of AI technology, and facilitating its broader adoption in various industries. Together, we\u2019ve set out to create a platform that fosters the adoption of cutting-edge AI technology across any engineering organization. So, to all the innovators, engineers, and tech enthusiasts who dream of pushing the boundaries of AI \u2014 this is your moment. We invite you to join us in this journey. To learn more about the Deep Lake Foundational Model Certification and to\u00a0sign up for free, please visit our website.",
            "pubdate": "Wed, 21 Jun 2023 08:43:37 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Top 10 Machine Learning (ML) Tools for Developers in 2023": {
            "url": "https://towardsai.net/p/machine-learning/top-10-machine-learning-ml-tools-for-developers-in-2023",
            "description": "Last Updated on June 27, 2023 by Editorial Team Source: Unsplash This piece dives into the top machine learning developer tools being used by developers\u200a\u2014\u200astart building! In the rapidly expanding field of artificial intelligence (AI), machine learning tools play an instrumental role. Already a multi-billion-dollar industry, AI is having a profound impact on every aspect of life, business, and society. This impact is largely driven by advances in machine learning, a key component of AI that provides systems the ability to automatically learn and improve from experience without explicit programming. The growth in the AI sector is accompanied by a surge in machine learning tools designed to solve complex problems. These tools are becoming increasingly sophisticated, enabling the development of advanced applications. For instance, today\u2019s machine learning tools are pushing the boundaries of natural language processing, allowing AI to comprehend complex patterns and languages. However, the rapid evolution of these machine learning tools also presents a challenge for developers. With a wide array of tools and software available, identifying the most effective ones to use in various applications can be a daunting task. This challenge is further heightened by the pace of the industry\u2019s expansion, as developers strive to stay ahead in a fast-paced, competitive environment. To assist in this crucial decision-making process, we have curated a list of the top machine learning tools available today. This compilation, centered on efficacy and technical robustness, is designed to guide developers through the vast landscape of machine learning tools. By highlighting these key resources, we aim to provide a useful roadmap, simplifying the path towards effective coding and learning in machine learning. As the industry continues to grow and machine learning tools advance, staying updated on the most impactful and technical robust tools is essential. This list, encompassing the most effective machine learning tools, serves as a valuable guide for developers seeking to enhance their machine learning toolkit and drive the AI revolution forward. Let\u2019s get started with the best machine learning (ML) developer tools: TensorFlow TensorFlow, developed by the Google Brain team, is one of the most utilized machine learning tools in the industry. This open-source library is renowned for its capabilities in numerical computation, particularly in large-scale machine learning projects. TensorFlow\u2019s flexible architecture allows for seamless deployment across various platforms, from CPUs and GPUs to mobile and edge devices. Its comprehensive ecosystem of tools, libraries, and community resources aids developers in constructing robust, scalable machine learning models. Offering features like TensorBoard for data visualization and TensorFlow Extended (TFX) for implementing production-ready ML pipelines, TensorFlow stands out as a comprehensive solution for both beginners and seasoned professionals in the realm of machine learning. Scikit Learn Scikit Learn is a comprehensive machine learning tool designed for data mining and large-scale unstructured data analysis. With an impressive collection of efficient tools and a user-friendly interface, it is ideal for tackling complex classification, regression, and cluster-based problems. This versatile tool also supports dimensional reduction, allowing for the efficient management of high-dimensional datasets. Furthermore, Scikit Learn boasts an extensive range of libraries, providing developers with the necessary resources for a diverse array of machine learning applications. Its seamless integration capabilities make it highly compatible with numerous other Python libraries, which is why Scikit Learn is favored by many in the field for tackling sophisticated machine learning problems. PyTorch PyTorch, a Python-based machine learning library, stands out among its peers in the machine learning tools ecosystem. This flexible and intuitive library is built on the Torch library, a computing framework and scripting language grounded in Lua. PyTorch enables the easy execution of complex computational tasks, making it highly attractive to developers. With its dynamic neural networks and strong GPU acceleration, PyTorch is not only robust but also adaptable to various levels of computational requirements, making it one of the most widely-used machine learning tools today. Furthermore, its extensive ecosystem of libraries and tools, including TorchVision for computer vision and TorchText for natural language processing, enhance its utility, catering to a wide array of machine learning tasks. In a rapidly advancing industry, PyTorch\u2019s user-friendly interface and comprehensive resources underscore its popularity among developers seeking to create cutting-edge machine learning solutions. Open NN OpenNN stands out as a powerful software library specifically designed for the implementation of neural networks, a central aspect of machine learning. As an open-source library coded in C++, OpenNN offers the ability to handle complex machine learning tasks with optimal performance. Moreover, the library can be downloaded in its entirety from reliable sources such as GitHub at no cost, ensuring its accessibility to a wide range of developers. OpenNN\u2019s robustness extends to its architecture, which supports high-level mathematical abstractions while still providing a high degree of flexibility. This unique combination allows users to tailor the software to their specific machine learning needs, making OpenNN a versatile tool in the machine learning toolkit. With continuous updates and a vibrant community of contributors, OpenNN showcases the dynamic evolution of machine learning tools. RapidMiner RapidMiner, a renowned player in the realm of machine learning tools, offers an all-encompassing platform for a myriad of operations. Its functionalities span from deep learning to text mining, data preparation, and predictive analytics, ensuring a versatile utility for developers and data scientists alike. Designed with an integrated approach, RapidMiner facilitates not only research and education but also serves as a potent tool for application development. The platform\u2019s ease of use, alongside its scalability and comprehensive analytical capabilities, makes it a prime choice for professionals aiming to streamline their workflow and boost efficiency in their machine learning projects. Whether you\u2019re delving into new research or developing innovative applications, RapidMiner emerges as a potent machine learning tool that fosters a seamless, efficient, and impactful data analysis process. XGBoost XGBoost, a renowned machine learning tool, stands for eXtreme Gradient Boosting. This tool utilizes a gradient boosting framework that offers an impressive mix of predictive accuracy and computational efficiency. Primarily known for its tree-based model training algorithm, XGBoost prioritizes optimizing performance and is especially potent [&#8230;]",
            "pubdate": "Wed, 28 Jun 2023 02:58:08 +0000",
            "pubdate_parsed": [
                2023,
                6,
                28
            ],
            "email_sent": true
        },
        "Train and Deploy Custom Object Detection Models Without a Single Line Of Code.": {
            "url": "https://towardsai.net/p/machine-learning/train-and-deploy-custom-object-detection-models-without-a-single-line-of-code",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Peter van Lunteren Originally published on Towards AI. Images taken from the ENA24-detection dataset, licensed under the Community Data License Agreement (permissive, v1.0). Labels by author. Let AI process your imagery through an open-source graphical user interface. Table of contents Introduction EcoAssist Tutorial Step 1 \u2014 Annotate Step 2 \u2014 Train Step 3 \u2014 Evaluate Step 4 \u2014 Deploy Step 5 \u2014 Post-process Frequently asked questions Introduction Object detection is a computer vision technique to detect the presence of specific objects in images. It\u2019s one of the most common types of computer vision and is applied in many use cases, such as fire detection, autonomous driving, species classifiers, and medical imaging. The core idea is that a computer can recognize objects by learning from a set of user-provided example images. While this may seem simple, working with object detection models is often considered challenging for individuals without coding skills. However, I hope to demonstrate otherwise through the approach described below. EcoAssist Although many object detection tutorials are offered online, none of them offer an automated method \u2014 without the need to write code. When I started with object detection models myself, I tried many tutorials, which generally ended up with some kind of error. In this tutorial, I\u2019ve tried to make object detection as accessible as possible by creating a GitHub-hosted open-source application called EcoAssist [1]. I initially created EcoAssist as a platform to assist ecological projects, but it will train and deploy any kind of object detection model. If you\u2019re not an ecologist, you\u2019ll just have to ignore the preloaded MegaDetector model [2] and the rest will be exactly the same. EcoAssist is free to use for everybody. All I ask, is to cite accordingly: van Lunteren, P. (2022). EcoAssist: A no-code platform to train and deploy YOLOv5 object detection models. https://doi.org/10.5281/zenodo.7223363 Tutorial I\u2019ll show you how you can annotate, train and deploy your own custom object detection model using EcoAssist. This tutorial will guide you through the process visualized below. I\u2019ll link to my FAQ page on GitHub to answer some general questions along the way. In this tutorial, we\u2019ll train a species classifier that will detect black bears and crows, but feel free to follow along with your own images to create a model which will detect the objects of your choice. Image by author. Before we can start, we\u2019ll need the EcoAssist software installed. Visit https://github.com/PetervanLunteren/EcoAssist and follow the instructions there. See FAQ 1 for the best setup to train on. Step 1 \u2014 Annotate The first part of object detection is also the most tedious one. To enable the computer to recognize our object, we must identify each instance of it in the images \u2014 a process known as an annotation. If you don\u2019t have your own images and just want to follow this tutorial, you can download an already annotated dataset from Google Drive (\u2248850MB). It is a subset of the ENA24-detection dataset [3] and consists of 2000 images, of which 891 are bears, 944 are crows and 165 are backgrounds (empty images). Except for the backgrounds, all images have an associated annotation file and all instances are labeled. This dataset is purely for illustrative purposes. Check FAQ 2 to see what a good dataset should look like. If you want to annotate your own images, follow the steps below. If you\u2019re planning on labeling animals, see this method on GitHub to save time drawing boxes. 1.1 \u2014 Collect all your images in one folder. There should not be any subfolders or files other than images meant for training. It should look like this: \u2500\u2500\u2500 \ud83d\udcc1dataset &#124;\u2500\u2500image_1.jpg &#124;\u2500\u2500image_2.jpg &#124;\u2500\u2500image_3.jpg : \u2514\u2500\u2500image_N.jpg Image by author. 1.2 \u2014 Open EcoAssist and navigate to the \u2018Annotate\u2019 tab. 1.3 \u2014 Select the folder containing your images using the \u2018Browse\u2019 option. 1.4 \u2014 List the names of the classes you are interested in, separated by commas. For example: black bear, crow. 1.5 \u2014 Click the \u2018Start annotation\u2019 button. This will create a file called \u2018classes.txt\u2019 and open a new window in which you can label your images. Image by author. 1.6 \u2014 Make sure the button just under the \u2018Save\u2019 button in the toolbar is set to \u2018YOLO\u2019. If you see \u2018PascalVOC\u2019 or \u2018CreateML\u2019, switch to \u2018YOLO\u2019. 1.7 \u2014 Click the \u2018Create RectBox\u2019 to draw a box around the object of interest and select the correct label. If all objects in the image are labeled, click \u2018Save\u2019 (or select \u2018View\u2019 &#62; \u2018Auto save mode\u2019 from the menu bar) and \u2018Next Image\u2019. This will create a text file with the same filename as the image. Continue doing this until all objects in all images are labeled. When you\u2019re done, the dataset should look like this: \u2500\u2500\u2500 \ud83d\udcc1dataset &#124;\u2500\u2500classes.txt &#124;\u2500\u2500image_1.jpg &#124;\u2500\u2500image_1.txt &#124;\u2500\u2500image_2.jpg &#124;\u2500\u2500image_2.txt &#124;\u2500\u2500image_3.jpg &#124;\u2500\u2500image_3.txt : &#124;\u2500\u2500image_N.jpg \u2514\u2500\u2500image_N.txt 1.8 \u2014 Backup your final image dataset in case disaster strikes. Step 2 \u2014 Train In this phase, we\u2019ll train a model to detect your objects. 2.1 \u2014 If you\u2019re running this tutorial on a Windows computer, it might be useful to increase the paging size of your device before starting to train (FAQ 6, point 1). This will increase virtual memory and, thus the processing power of your device. This is not relevant for Mac and Linux users. 2.2 \u2014 Close all other apps to reduce background activities since training can place a significant demand on your machine. Image by author. 2.3 \u2014 Navigate to the \u2018Train\u2019 tab. 2.4 \u2014 Specify values for the required parameters. Training type \u2014 Here you can select whether you want to continue an existing training or start a new one. Leave it on the default \u2018Start new training\u2019. Folder with labeled data \u2014 Select the folder with images and labels created at the annotation step. Retrain from \u2014 Here, you can select which model you\u2019d like to use for transfer learning. You can also choose to train your model from scratch. See FAQ 3 and [&#8230;]",
            "pubdate": "Sun, 16 Jul 2023 00:25:55 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Skyrocket Your Productivity with ChatGPT Chrome Extensions": {
            "url": "https://towardsai.net/p/machine-learning/skyrocket-your-productivity-with-chatgpt-chrome-extensions",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Ali Originally published on Towards AI. I have actually benefited from these extensions, you can do too\u2026 Photo by Andrea Piacquadio: https://www.pexels.com/photo/woman-in-pink-sweater-using-laptop-3764402/ ChatGPT has revolutionized the way we work, learn, and search for information. It has proven to be an incredibly versatile tool for making our lives much easier. But here is a thing, the way you are using ChatGpt might be nowhere near to what it can actually do for you! Just like 90% of the population, you might be missing majorly on the sorcery and magic of ChatGpt. But, If you want to know how to use utilize ChatGpt and make things smoother for you, then keep reading! By default, ChatGPT is confined to a new tab where you input data&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 16 Jul 2023 00:25:15 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Analyse Customer Reviews with Natural Language Processing.": {
            "url": "https://towardsai.net/p/machine-learning/analyse-customer-reviews-with-natural-language-processing",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Flo Originally published on Towards AI. Using CountVectorizer, an implementation of bag-of-words Top highlight Image by Flo on OpenSea, UX Natural Language Processing In this article, we build our machine learning model to guess customer reviews tone based on historical data. It is a classification problem solved with Natural Language Processing (NLP). The purpose of NLP is to teach languages to computers by developing algorithms and models to allow them to read and understand the text.Furthermore, it allows to generate text. The article contains six parts: Text Preprocessing: Reformat our input data.Text Representation: Transform our data to make it readable by the machine learning program. We use the CountVectorizer technique, an implementation of bag-of-words.Training the model: Split&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 16 Jul 2023 00:25:02 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "10 Advanced Matplotlib Concepts You Must Know To Create Killer Visuals": {
            "url": "https://towardsai.net/p/machine-learning/10-advanced-matplotlib-concepts-you-must-know-to-create-killer-visuals",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Bex T. Originally published on Towards AI. Become Leonardo da Matplotlib Image by me with Midjourney. All the rest of the images are by the author unless specified otherwise. Good things come to those who read the Matplotlib documentation. I made up the new version of the famous quote after suffering hours reading the complex documentation of Matplotlib. And the return on my investment was so great that I was left wondering why everybody wouldn\u2019t do it. Then, I realized you shouldn\u2019t have to suffer the same way I did no matter the reward, because I can share my best findings with you. When used properly, these findings can push your plots instantly to&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 16 Jul 2023 00:22:59 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Decoding Generative AI Expertise in the Matrix": {
            "url": "https://towardsai.net/p/machine-learning/decoding-generative-ai-expertise-in-the-matrix",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Myra Roldan Originally published on Towards AI. Photo by Markus Spiske on Unsplash Welcome to the \u201cGenerative AI Matrix\u201d, where everyone is a chosen one, destined to guide you through the virtual rabbit hole of \u201cHarnessing the Power of ChatGPT\u201d and discovering the secrets of a billion-dollar empire. Neo would be proud. But let\u2019s face it, not all of those who offer you the red pill of Generative AI enlightenment possess the digital prowess they claim. There\u2019s a new binary code to decipher: who truly wields the power of generative AI expertise and who\u2019s merely trapped in the delusion of self-proclaimed mastery. \u201cRemember, all I\u2019m offering is the truth. Nothing more.\u201d \u2014 Morpheus, The Matrix In the wake of the November 30, 2022, introduction of chatGPT and the rapid rise of generative AI, a wave of self-proclaimed \u201cGenerative AI experts\u201d have flooded the Matrix. It feels like everyone has a proven strategy or formula for you, from \u201cMonetize ChatGPT\u201d, to \u201cTop 3 Ways to Make $1 Million Using ChatGPT\u201d, to \u201cTop 5 Prompts to Start Making Money Today\u201d. With such an overwhelming influx of data and manipulation of perception, how can we weed out the riff-raff to distinguish the genuine experts from those seeking to exploit the trend to become the guardians of the status quo seeking to suppress any attempts of your awakening from the illusory world and expose the truth? Ok, so I\u2019m going heavy on the Matrix theme here, but we\u2019re at a time when companies are trying to figure out how to create strategies to integrate Generative AI into their workflows because they\u2019re being told that they\u2019ll be left behind; workers are trying to figure out what skill sets they need in order to not be replaced by generative AI; and a whole new population of \u201cinstant Generative AI experts\u201d are exploiting the opportunity by positioning themselves as the newest Generative AI experts. It\u2019s not like there\u2019s any complexity to it or anything. Just take the blue pill and pretend like you\u2019re in control, right? This is why it has become crucial to understand the true markers of expertise in any field, including generative AI. But what really makes one an expert? Let\u2019s embrace the spirit of Neo-ism to venture into \u201cThe Quest for True Expertise\u201d and embark on a journey to unravel the digital delusion. \u201cI Don\u2019t Know The Future. I Didn\u2019t Come Here To Tell You How This Is Going To End. I Came Here To Tell You How It\u2019s Going To Begin.\u201d \u2014 Neo, The Matrix The Quest for True Expertise Becoming a generative AI expert goes beyond just merely claiming the title. True expertise is built upon a foundation of knowledge, experience, and continuous learning. It can feel like a game of hide and seek to sift through a haystack of wannabes, but who doesn\u2019t love the thrill of finding a needle in a virtual haystack? Thankfully, as with any journey, there are markers that can be used to separate genuine generative AI experts from imposters. Here is my shortlist: Marker #1 \u2014 Deep Understanding of the Technology A true expert possesses a deep understanding of the underlying principles, inner workings, and methodologies of generative AI. They have a niche focus in Artificial Intelligence that spans education and career, conducting and keeping up with the latest research and gaining hands-on experience with various generative AI models. They have comprehensive knowledge that allows them to navigate the nuances, limitations, concerns, and potential applications of generative AI. Marker #2 \u2014 Practical Experience and Results Expertise is developed through real-world experience and the ability to produce concrete results. Genuine generative AI experts are working on practical projects, collaborating with other experts, and exploring how generative AI can be used to solve complex problems. They have a demonstrated track record of implementations, showcasing generative AI\u2019s impact in specific domains or industries. Marker #3 Continuous Learning and Adaptability The field of generative AI is ever-evolving, and true experts recognize the importance of continuous learning. They are also hesitant to claim the title of \u201cGenerative AI Expert\u201d because they know that we are just scratching the Generative AI surface and things change minute by minute. They actively engage in ongoing professional development, attending conferences, participating in workshops, and staying abreast of emerging trends and advancements. This commitment to learning enables them to adapt their knowledge and skills to new challenges and breakthroughs in the field. \u201cThere\u2019s something wrong with the world. You don\u2019t know what, but it\u2019s there. Like a splinter in your mind.\u201d \u2014 Morpheus, The Matrix Identifying the Posers Now that we have a foundational baseline for identifying a \u201cGenerative AI Expert\u201d, you may be wondering, \u201cWell, Myra, how do we weed out the riff-raff?\u201d, \u201cWhat are the markers of a Wannabe Generative AI Expert?\u201d I&#039;ve got you covered. Posers also have critical markers, but some may be a bit vaguer and, at times, confusing because of the \u201cthey\u2019ll never know\u201d mentality we\u2019ve developed as a society. Here\u2019s my short list of markers to identify the Posers: Marker #1 \u2014 Lack of Credible Experience Wannabe experts often lack substantial experience and a verifiable track record in the field of general AI. They may make grandiose claims without tangible evidence to support their expertise. Requesting concrete examples of past AI-based projects, collaborations, or research contributions can help validate their credibility. Marker #2 \u2014 Overemphasis on Hype and Quick Fixes Beware of individuals who rely heavily on sensational claims, promising overnight success, or easy ways to monetize generative AI. If it sounds too good to be true\u201d then it just may be. Marker #3 \u2014 Lack of Depth in Understanding Take them off the rails, and you\u2019ll be able to uncover the depth of their understanding. Be wary of individuals who provide superficial explanations or are unable to answer technical questions with clarity. They may just be pitching whatever script they come up with using ChatGPT. Marker [&#8230;]",
            "pubdate": "Sun, 16 Jul 2023 00:21:23 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Accented Speech Recognition: The Inclusive Realm of Automatic Speech Recognition Systems": {
            "url": "https://towardsai.net/p/machine-learning/accented-speech-recognition-the-inclusive-realm-of-automatic-speech-recognition-systems",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Toluwani Aremu Originally published on Towards AI. Photo by Jonathan Borba on Unsplash \u201cHey Google!\u201d \u201cHey Siri!\u201d \u201cHey Cortana!\u201d \u201cBixby!!\u201d \u201cALEXAAAA!!!\u201d Yes, I was that frustrated trying to see if Google was the problem or if I was! In the summer of 2021, I fondly recall my valiant attempt to summon the powers of Google search to find an article for me using voice commands (actually a movie, but I am trying to appear intelligent). Alas, as someone with a knightly command of the English language, also with such a \u201cdelightful\u201d accent (not American, not Bri\u2019ish), I found myself in a whimsical predicament! The speech-to-text feature, in its infinite wisdom, seemed to delight in \u201cmisrecognizing\u201d my carefully articulated words! To add more depth to my frustration, my close friend, who also had an accent (not as beautiful as mine), effortlessly commanded the speech-to-text feature, leaving me to start investigating the cosmic forces at play! Pure agony!!! Is Google the problem? Or am I? Armed with curiosity, I embarked on a lofty quest to test other well-known ASR systems. With hope in my eyes and \u201cdeora ar mo chroi\u201d, I swiftly conducted experiments just to prove I wasn\u2019t the problem. The mighty Google Home Assistant recognized my commands at least 80% of the time, with the Windows Cortana not too far behind. But then there was Bixby, a true paragon of recognition and obedience, recognizing my commands almost all of the time. Alexa joined Bixby in improving my injured self-esteem, but dear, oh dear, Siri decided to dance to her own tune. Here\u2019s the confusing part! That Google Home Assistant totally outshone its dear sibling (Search), was perplexing. Larry, riddle me this! Why did the chicken decide to go \u201cHome\u201d instead of \u201cSearching\u201d for food? My experiments did not end there! In fact, I joined forces with two brave and curious musketeers to unveil the accent-ridden black hole of Automatic Speech Recognition (ASR) systems. So, brace yourself as I embark on a riveting journey to elucidate the very essence of ASR systems before delving further into my tale. Photo by Ivan Bandura on Unsplash WHAT ARE ASR SYSTEMS? Speech recognition technology, also known as automatic speech recognition (ASR), is a vital component of speech AI. ASR enables the conversion of spoken language (audio signals) into written text, serving various purposes such as command input. It has advanced capabilities to accurately process different language dialects and accents, finding extensive applications in user-facing contexts like virtual agents, live captioning, and clinical note-taking. Developers in the speech AI field may use alternative terms like speech-to-text (STT) or voice recognition to refer to ASR. ASR plays a crucial role within speech AI, which encompasses technologies aimed at facilitating human-computer interaction through voice communication. ASR has experienced significant growth and adoption, with popular platforms like TikTok, Instagram, Spotify, and Zoom incorporating ASR technology. There are two primary approaches to ASR: the traditional hybrid approach and the end-to-end Deep Learning approach. The hybrid approach combines statistical and rule-based methods, while the end-to-end Deep Learning approach employs a single neural network to handle the entire ASR process. Ongoing advancements in ASR technology contribute to continuous improvements in system accuracy. ASR systems are trained on extensive datasets comprising audio recordings and corresponding transcripts. The accuracy of ASR can be influenced by factors such as audio recording quality, speaker accents, and background noise. ASR finds applications in various fields, including transcription, captioning, and dictation. The future of ASR looks promising as the technology continues to evolve, driven by ongoing enhancements and innovations. ASR systems consist of several components and techniques working together to accomplish accurate speech-to-text conversion. These components include acoustic modeling, language modeling, pronunciation modeling, feature extraction, decoding, training and adaptation, post-processing, and the emerging end-to-end ASR approach. Acoustic modeling captures the relationship between speech audio signals and phonetic units, while language modeling predicts likely word sequences given acoustic observations. Pronunciation modeling maps phonetic units to their corresponding pronunciations. Feature extraction converts raw speech signals into relevant acoustic features, and decoding finds the most likely word sequence given the acoustic and language models. Training and adaptation optimize model parameters using labeled speech data, and post-processing refines the output. The recent development of end-to-end ASR systems directly maps acoustic features to word sequences using deep learning approaches. ASR systems continue to advance, driven by deep learning, training data, and computational resources, enabling various applications relying on speech recognition technology. Photo by Dan Farrell on Unsplash HOW IS ACCENT A PROBLEM IN ASR? English is the most universally adopted language in the world. As a result, different parts of the world have their own styles of communicating with this language. In fact, you can find multiple styles of language within the same part of the world, perhaps due to differences in dentition or vocal perception. Some styles are classified as English-based creoles, which are distorted forms of English that have been influenced by other languages. Other styles are simply pure English with a distinctive and noticeable regional accent. Due to this variance in style, accents present challenges for ASR systems as they can cause the misrecognition of words. Let\u2019s take a look at the word \u201cSCHEDULE\u201d. Speaker A from the US pronounces it as \u201cSkeh-dool\u201d Speaker B from the UK pronounces it as \u201cSher-dool\u201d A non-native speaker C would rather pronounce every syllable, i.e., \u201cSkeh-doo-leh\u201d All speakers are saying the same word, but with their respective accents! Here is where accent becomes a problem for ASR Systems. Speakers A and B are using standard pronunciations for \u201cSCHEDULE,\u201d while Speaker C isn\u2019t. ASR systems are typically trained on datasets of native/standard speakers, which may not accurately recognize words pronounced differently in other accents. Accents introduce acoustic variability, with different pronunciation patterns and speech rhythms, making it challenging for ASR systems to transcribe accurately. The lack of diverse training data covering all accents can lead to poorer performance when encountering specific accents [&#8230;]",
            "pubdate": "Sun, 16 Jul 2023 00:19:52 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Heart Attack Prediction: Unveiling Insights through Predictive Modeling with Python": {
            "url": "https://towardsai.net/p/machine-learning/heart-attack-prediction-unveiling-insights-through-predictive-modeling-with-python",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Muttineni Sai Rohith Originally published on Towards AI. Picture this: a crystal ball that can predict heart attacks before they strike. Sounds like something out of a sci-fi movie, right? Well, thanks to the wonders of Machine Learning and the wizardry of Python programming, we\u2019re not far from turning that imagination into reality. Welcome to the realm of predictive modeling, where the power of data and cutting-edge technology converge to tackle one of the most critical challenges in cardiovascular health: predicting heart attacks. In this article, we delve into the fascinating world of heart attack prediction using the prowess of predictive modeling with Python. Predictive Modeling: \u2014 It refers to the process of creating and utilizing mathematical or statistical models to make predictions or forecasts about future outcomes or events. It involves analyzing historical data and identifying patterns and relationships between variables to develop a model that can be used to predict the behavior or outcome of a specific target variable. The predictive modeling process typically involves several steps, including data collection, data preprocessing, feature engineering, model training, model evaluation, and prediction. We will be following the same process in this article to predict Heart Attacks. Data Collection While searching for suitable data to use for our risk stratification project aimed at predicting heart attacks, I came across this dataset on the UCI repository. Despite its smaller size, it contains all the essential features we need, making it an ideal starting point for our analysis and model development. import pandas as pddata = pd.read_csv(&#034;/content/heart.csv&#034;)data.head() Snapshot of Data It\u2019s a clean and easy-to-understand set of data with Shape \u2014 1025 * 14. However, the meaning of some of the column headers is not obvious. Here\u2019s what they mean, age: The person\u2019s age in years sex: The person\u2019s sex (1 = male, 0 = female) cp: The chest pain experienced (Value 0: typical angina, Value 1: atypical angina, Value 2: non-anginal pain, Value 3: asymptomatic) trestbps: The person\u2019s resting blood pressure (mm Hg on admission to the hospital) chol: The person\u2019s cholesterol measurement in mg/dl fbs: The person\u2019s fasting blood sugar (&#62; 120 mg/dl, 1 = true; 0 = false) restecg: Resting electrocardiographic measurement (0 = normal, 1 = having ST-T wave abnormality, 2 = showing probable or definite left ventricular hypertrophy by Estes\u2019 criteria) thalach: The person\u2019s maximum heart rate achieved exang: Exercise-induced angina (1 = yes; 0 = no) oldpeak: ST depression induced by exercise relative to rest (\u2018ST\u2019 relates to positions on the ECG plot. See more here) slope: the slope of the peak exercise ST segment (Value 1: upsloping, Value 2: flat, Value 3: downsloping) ca: The number of major vessels (0\u20133) thal: A blood disorder called thalassemia (3 = normal; 6 = fixed defect; 7 = reversible defect) target: Heart disease (0 = no, 1 = yes) Let\u2019s Dive into preprocessing of this Data. Preprocessing \u2014 With the recent advancement, Generally, I would have preferred using PandasAI or pandas_profiling for preprocessing the data. Example \u2014 import pandas_profiling as df_reportdf_report.ProfileReport(data) Try this and see the wonders, It summarizes the entire data and gives all the related information to you. But for this article, let&#039;s follow the manual process \u2014 Let\u2019s start with missing values detection \u2014 data.isnull().sum() Missing Values Detection Fortunately, there are no missing values in the data. Let\u2019s check the data redundancy \u2014 data.duplicated().sum() Data Duplication Oops, we already had fewer data, and out of this 723 records are duplicated. But I think the remaining records will be sufficient to serve our purpose because it is really hard to get this sensitive data. So let\u2019s remove these records and move further. data.drop_duplicates(inplace=True) So now, let\u2019s analyze the data in order to get a view of how well the fields are correlated and derive some insights from it. from plotly.subplots import make_subplotsimport plotly.graph_objects as godf=data[[&#039;sex&#039;,&#039;age&#039;,&#039;target&#039;]]df[&#039;sex&#039;].replace({1:&#039;Male&#039;,0:&#039;Female&#039;},inplace=True)df[&#039;target&#039;].replace({1:&#039;Heart Patient&#039;,0:&#039;Healthy&#039;},inplace=True)fig = make_subplots(rows=1, cols=2,specs=[[{&#034;type&#034;: &#034;histogram&#034;}, {&#034;type&#034;: &#034;histogram&#034;}]])fig.add_trace( go.Histogram( x=df[&#039;age&#039;].where(df[&#039;target&#039;]==&#039;Heart Patient&#039;), name=&#039;Heart Patient&#039;, nbinsx=20, showlegend=False, marker={&#034;color&#034;: &#039;#f84242&#039;} ), row=1,col=1)fig.add_trace( go.Histogram( x=df[&#039;age&#039;].where(df[&#039;target&#039;]==&#039;Healthy&#039;), name=&#039;Healthy&#039;, nbinsx=20, showlegend=False, marker={&#034;color&#034;: &#039;white&#039;} ), row=1,col=1)fig.add_trace( go.Histogram( x=df[&#039;sex&#039;].where(df[&#039;target&#039;]==&#039;Heart Patient&#039;), name=&#039;Heart Patient&#039;, nbinsx=20, marker={&#034;color&#034;: &#039;#f84242&#039;} ), row=1,col=2)fig.add_trace( go.Histogram( x=df[&#039;sex&#039;].where(df[&#039;target&#039;]==&#039;Healthy&#039;), name=&#039;Healthy&#039;, nbinsx=20, marker={&#034;color&#034;: &#039;white&#039;} ), row=1,col=2)fig.update_layout(height=500, title_text=&#034;&#60;b&#62;Age &#38; Gender Distribution&#60;b&#62;&#034;, title_font_size=30, bargap=0.1, template=&#039;plotly_dark&#039;, )fig.update_xaxes(title_text=&#034;Age&#034;, row=1, col=1)fig.update_yaxes(title_text=&#034;Count&#034;, row=1, col=1)fig.update_xaxes(title_text=&#034;Gender&#034;, row=1, col=2)fig.update_yaxes(title_text=&#034;Count&#034;, row=1, col=2)fig.show() Age and Gender Distribution The first subplot built using Plotly displays the age distribution, with separate histograms for heart patients and healthy individuals. The second subplot shows the gender distribution. As we can females are more prone to heart attacks than Males. Almost 75% ratio of females are heart patients in this data, and 35\u201355 Age group people are more prone to become heart patients. Let\u2019s repeat the same analysis for Chest pain and Max Heart Rate by tweaking the above code \u2014 cp1=data.where(data[&#039;target&#039;]==0).groupby(by=[&#034;cp&#034;]).size().reset_index(name=&#034;Count&#034;)cp0=data.where(data[&#039;target&#039;]==1).groupby(by=[&#034;cp&#034;]).size().reset_index(name=&#034;Count&#034;)cp0[&#039;cp&#039;].replace({0:&#039;Type 1&#039;,1:&#039;Type 2&#039;,2:&#039;Type 3&#039;,3:&#039;Type 4&#039;},inplace=True)cp1[&#039;cp&#039;].replace({0:&#039;Type 1&#039;,1:&#039;Type 2&#039;,2:&#039;Type 3&#039;,3:&#039;Type 4&#039;},inplace=True)df1=data[[&#039;thalach&#039;,&#039;chol&#039;,&#039;target&#039;,&#039;age&#039;,&#039;trestbps&#039;]]df1[&#039;targetname&#039;]=df1[&#039;target&#039;].replace({1:&#039;Heart Patient&#039;,0:&#039;Healthy&#039;})fig = make_subplots(rows=1, cols=2,specs=[[{&#034;type&#034;: &#034;histogram&#034;}, {&#034;type&#034;: &#034;scatter&#034;}]])fig.add_trace( go.Bar( x=cp0[&#039;cp&#039;],y=cp0.Count,marker={&#034;color&#034;: &#039;white&#039;},name=&#039;Healthy&#039; ), row=1,col=1)fig.add_trace( go.Bar( x=cp1[&#039;cp&#039;],y=cp1.Count,marker={&#034;color&#034;: &#039;#f84242&#039;},name=&#039;Heart Patient&#039; ), row=1,col=1)fig.update_layout(height=500, title_text=&#034;&#60;b&#62;Chest Pain &#38; Max Heart Rate&#60;b&#62;&#034;, title_font_size=30, bargap=0.1, template=&#039;plotly_dark&#039;, )fig.add_trace( go.Scatter(x=df1.thalach, y=df1.age, mode=&#039;markers&#039;, text=df1[&#039;targetname&#039;],showlegend=False, marker=dict( color=df1.target, colorscale=[&#039;white&#039;,&#039;#f84242&#039;], line_width=1) ), row=1,col=2)fig.update_xaxes(title_text=&#034;Chest Pain Type&#034;, row=1, col=1)fig.update_yaxes(title_text=&#034;Count&#034;, row=1, col=1)fig.update_xaxes(title_text=&#034;Max. Heart Rate&#034;, row=1, col=2)fig.update_yaxes(title_text=&#034;Age&#034;, row=1, col=2)fig.show() Chest Pain and Maximum Heart Rate Distribution As we can observe, people with type 1 chest pain have a high risk of high disease as compared to other chest pain types also Higher maximum heart rate among younger candidates is seen to be a major symptom of heart disease. We can perform the same analysis for the remaining fields in the data as well in this process. But the article will become lengthy, so let&#039;s directly see the correlation among fields. import seaborn as sbimport matplotlib.pyplot as pltsb.set(style=&#034;white&#034;)plt.rcParams[&#039;figure.figsize&#039;]=(15,15) sb.heatmap(data.corr(),annot= True, linewidth=0.5)plt.title(&#034;Correlation between variables&#034;) Correlation Here we are correlating the fields based on the entire set of data. Based on this correlation, we can derive that Chest Pain and Maximum Heart rate are correlated with our target variable(Heart Patient or not). I also prefer Comparing the data based on Data intervals, but we will not cover this in this [&#8230;]",
            "pubdate": "Sun, 16 Jul 2023 00:17:44 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Textbooks are All You Need: Inside Microsoft Researchs Amazing Phi-1 Code Language Model": {
            "url": "https://towardsai.net/p/machine-learning/textbooks-are-all-you-need-inside-microsoft-researchs-amazing-phi-1-code-language-model",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Jesus Rodriguez Originally published on Towards AI. The model is able to outperform competitors despite being substantially smaller. Top highlight Created Using Midjourney I recently started an AI-focused educational newsletter, that already has over 160,000 subscribers. TheSequence is a no-BS (meaning no hype, no news, etc) ML-oriented newsletter that takes 5 minutes to read. The goal is to keep you up to date with machine learning projects, research papers, and concepts. Please give it a try by subscribing below: The best source to stay up-to-date with the developments in the machine learning, artificial intelligence, and data\u2026 thesequence.substack.com Coding has been one of the most active areas of development in the foundation model space. OpenAI opened the floodgates to this space with models like&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 16 Jul 2023 00:16:34 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Benfords Law Meets Machine Learning for Detecting Fake Twitter Followers": {
            "url": "https://towardsai.net/p/machine-learning/benfords-law-meets-machine-learning-for-detecting-fake-twitter-followers",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Erika Lacson Originally published on Towards AI. An illustration of Benford\u2019s Distribution, Photo by Author. In the expansive digital landscape of social media, user authenticity is a paramount concern. As platforms like Twitter grow, so does the proliferation of fake accounts. These accounts mimic genuine user activities, creating noise in data and casting shadows on the credibility of digital ecosystems. Traditional methods for detecting fake accounts often rely on complex machine-learning algorithms. However, an intriguing alternative tool exists Benford\u2019s Law, a mathematical principle that describes the frequency distribution of leading digits in many sets of numerical data. This article explores how we can harness the power of Benford\u2019s Law, in conjunction with machine learning techniques, to expose fake Twitter followers. Benford\u2019s Law: A Brief Overview Let\u2019s take a moment to think about the frequency of certain numbers appearing as the leading digits in various sets of data. For instance, imagine you have a dataset consisting of the prices of products at your favorite online marketplace. What would you expect to be the most common leading digit in those prices? Intuitively, you might assume that each digit from 1 to 9 would have an equal chance of being the leading digit. After all, shouldn\u2019t the distribution be uniform? Surprisingly, that assumption is incorrect. According to Benford\u2019s Law, the leading digit 1 appears as the most frequent digit, followed by 2, 3, and so on, with 9 being the least common. So what exactly is Benford\u2019s Law? Benford\u2019s Law is also called the law of anomalous numbers or the first digits law\u00b9. It provides the probability of obtaining the first digit d appearing in a set of natural numbers. According to the law, the probability of getting a 1 in the first digit position is 30.1% and runs down to 4.6% for 9. If I ask you this: \u201cSuppose we have data containing the population of each county in the US for the year 2000. What is the probability that a random population count begins with 1?\u201d You now know that the answer is around 30%: 1st Digit Distribution of US census in 2000, Photo by Author. This intriguing phenomenon challenges our traditional expectations and has far-reaching implications. It has been observed not only in product prices and population figures but also in diverse datasets like financial statements, stock prices, sports statistics, Tiktok likes, and scientific measurements. Understanding and harnessing the power of Benford\u2019s Law can unlock valuable insights and enhance our ability to detect irregularities and anomalies in various domains, including social media analytics, such as identifying fake Twitter followers. In this blog, I delve into the fascinating intersection of Benford\u2019s Law and machine learning, exploring how this mathematical principle can be employed alongside advanced algorithms to expose and combat the presence of fake Twitter followers. Data Source and Description To conduct this study, I utilized a publicly available non-synthetic labeled dataset of Twitter account data. The source of the Twitter user dataset is the Bot Repository website\u00b2, which houses a collection of Twitter user account data. During this step, a data limitation issue arose as most of the available public data did not meet at least one of the key assumptions required for Benford\u2019s Law. As a result, the only viable dataset I found was the cresci-2015 dataset. The cresci-2015 dataset contains a collection of real data comprising genuine and fake Twitter accounts, which were manually annotated by the original authors\u00b3. After downloading the dataset, I gathered and utilized 5301 accounts (rows) and 8 features (columns). While the dataset contained more columns, only the following columns were considered relevant for this study: Data Description. Photo by Author. Another dataset used for a brief Benford\u2019s Law sample illustration only is the 14_Census_2000_2010.csv from Mark Nigrini&#039;s website\u2074, the author of Benford&#039;s Law book. Key Assumptions and Examples Before we delve into the examples and applications of Benford\u2019s Law, let\u2019s review its key assumptions: The set of numbers is not limited. (All leading digits are possible: 1 to 9) Numbers span multiple orders of magnitudes (1\u201310, 10\u2013100, 100\u20131000, numbers at least 4 digits work best) The sample size is very large (Use the entire population, if possible; a Lower than 1,000 sample size will produce unreliable results.) Some example datasets that do or do not follow Benford\u2019s Law (BL) are as follows\u2076: Datasets that do or do not conform with Benford\u2019s distribution. Photo by Author. Some major applications of Benford\u2019s Law in Machine Learning Fraud/Anomaly detection Image forensics Bot/fake followers detection Feature Engineering Before diving into Machine Learning models, I first created a followers/friends ratio feature because social connections of the fake followers&#039; accounts are unnatural. One of the key characteristics of fake followers include fake followers following more user accounts as compared to them having minimal number of friends (following). Although fake followers often try to get other fake follower accounts to follow them, on average, the number of accounts they follow (net friends) remains significantly higher than the number of their followers (net followers). Regression plots of fake followers vs. genuine accounts. Photo by Author. As evidenced by the image above, the number of followers for fake accounts is typically lower compared to the number of friends (to recap, this refers to the number of users that an account is following\u2075). It\u2019s easy to understand why fake followers would follow more accounts \u2014 after all, that is their primary purpose. Since these fake follower accounts aren\u2019t designed to interact, they usually have a lower follower count. Checking conformity with Benford\u2019s Law Based on the above discussions and graphs, it is evident that the social connections made by bots or fake followers are unnatural, and thus, they tend to violate Benford\u2019s Law. In checking for irregularities or indications of fake followers in each subset of data in the Twitter dataset, I performed Hypothesis Testing: Null hypothesis: The data subset follows Benford\u2019s Law Distribution. Alternative hypothesis: The data subset does not follow [&#8230;]",
            "pubdate": "Sun, 16 Jul 2023 00:11:28 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "LlamaIndex: Use the Power of LLMs on Your Data": {
            "url": "https://towardsai.net/p/machine-learning/llamaindex-use-the-power-of-llms-on-your-data",
            "description": "Last Updated on July 15, 2023 by Editorial Team Author(s): Janik and Patrick Tinz Originally published on Towards AI. A beginner-friendly tutorial: Get answers over your documents Image by unDraw Everyone has been talking about Large Language Models (LLMs). ChatGPT shows the power of this phenomenal technology in an impressive way. LLMs are pre-trained on a large amount of data. We can use it for our data. But how we best augment LLMs with our data? In this case, we need a toolkit to help us. LlamaIndex (previous GPT-Index) is well fit for this. It\u2019s a simple and flexible data framework that helps you to connect your data to LLMs. You can connect your unstructured, structured, or semi-structured data sources. We\u2019ll discuss the following points in this article: Ingesting your dataIndexing your&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 16 Jul 2023 00:11:13 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Chromaticity Segmentation ": {
            "url": "https://towardsai.net/p/machine-learning/chromaticity-segmentation",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Erika Lacson Originally published on Towards AI. Introduction to Image Processing with Python Episode 6: Image Segmentation \u2014 Part 2 (Left) Photo by cottonbro studio in pexels. &#124; (Right) Image processed by the Author. Hello again, my fellow image-processing enthusiasts! \ud83d\udd90\ufe0f Welcome to Episode 6, the second part of our deep dive into the world of Image Segmentation! \ud83c\udf0d\ud83d\udd0d In the last episode, we explored thresholding, Otsu\u2019s method, and the fascinating realm of color image segmentation. This time, we\u2019re about to add more colors to our palette with Chromaticity Segmentation and the concept of Image Differencing. \ud83c\udf08 Ready for an even deeper dive into the heart of image analysis? Buckle up, because we\u2019re taking a vibrant journey through: Chromaticity Segmentation \ud83c\udfa8 (This episode) Image Differencing \ud83d\udd04 (This episode) Chromaticity Segmentation \ud83c\udfa8 When it comes to image segmentation, color plays a key role in distinguishing different regions of an image. But have you ever encountered a situation where lighting conditions made color segmentation a nightmare? \ud83d\udca1\ud83d\ude31 No worries, Chromaticity Segmentation is here to save your day! Chromaticity Segmentation normalizes the RGB values of each pixel, making our segmentation independent of lighting conditions. How cool is that? We\u2019ll dive deep into this method, exploring how we can apply it to our images to get more accurate and reliable segmentations. But, before we start jumping in, let\u2019s discuss the RG Chromaticity space. It\u2019s a two-dimensional representation of the color that removes intensity values from our colors. It\u2019s all about the proportion of the difference in color channels, mapping it in the normalized RGB space. \ud83d\uddfa\ufe0f\ud83d\udd34\ud83d\udc9a Excited? Let\u2019s take this journey step-by-step! To compute the RG Chromaticity of an image, we use the following equations: Image by Borja, B. To illustrate: Image by Borja, B. This plot shows us the different colors plotted in the RG color space. Notice that we are just plotting the R and G colors, why is this the case? Because we can compute for b just by using 1-r-g. Let\u2019s try segmenting our plant&#039;s image using this. But first, let\u2019s import the necessary libraries: # Import the necessary librariesfrom skimage.io import imread, imshowimport matplotlib.colors as colorsfrom skimage.color import rgb2grayimport matplotlib.pyplot as pltimport numpy as np We can use RG Chromaticity in both Parametric or Non-Parametric Segmentation. Parametric Segmentation The good thing about this type of segmentation combined with RG Chromaticity is that we can mask any shape. So let\u2019s test it out. We first need to compute the RG Chromaticity of our image: # Display the original imageoriginal_image = imread(&#039;plants.jpg&#039;)plt.figure(figsize=(20,20))plt.imshow(original_image)plt.title(&#039;Original Image&#039;, fontsize=20, weight=&#039;bold&#039;)plt.show() Photo by Scott Webb on Unsplash We use our equations to compute for the RG Chromaticity: original_image_R = original_image[:,:,0]*1.0/original_image.sum(axis=2)original_image_G = original_image[:,:,1]*1.0/original_image.sum(axis=2)plt.figure(figsize=(20,20))plt.scatter(original_image_R.flatten(),original_image_G.flatten())plt.xlim(0,1)plt.ylim(0,1); Photo by Author. We can compute for the 2D histogram of the color values by: plt.figure(figsize=(20,20))plt.hist2d(original_image_R.flatten(), original_image_G.flatten(), bins=100,cmap=&#039;binary&#039;)plt.xlim(0,1)plt.ylim(0,1); Photo by Author. From here, we would notice what color or group of colors comprises our image. To segment our image, we would need to find a reference patch and take the RG Chromaticity of that reference image. Let\u2019s consider the following green patch: patch = original_image[3200:3300,2800:2900,:]plt.figure(figsize=(10,10))plt.imshow(patch)plt.title(&#039;Reference Patch for Green&#039;, fontsize=20, weight=&#039;bold&#039;)plt.axis(&#039;off&#039;); Photo by Author. Getting the RG Chromaticity of this patch: patch_R = patch[:,:,0]*1.0/patch.sum(axis=2)patch_G = patch[:,:,1]*1.0/patch.sum(axis=2)plt.figure(figsize=(10,10))plt.scatter(patch_R.flatten(),patch_G.flatten())plt.xlim(0,1)plt.ylim(0,1); Photo by Author. plt.figure(figsize=(10,10))plt.hist2d(patch_R.flatten(), patch_G.flatten(), bins=100,cmap=&#039;binary&#039;)plt.xlim(0,1)plt.ylim(0,1); Photo by Author. Parametric segmentation now requires us to fit a Gaussian probability distribution using this mask. This probability distribution would dictate which pixel belongs to the color of interest. To do this, we need to compute the Mean and Standard Deviation of our object of interest. std_patch_R = np.std(patch_R.flatten())mean_patch_R = np.mean(patch_R.flatten())std_patch_G = np.std(patch_G.flatten())mean_patch_G = np.mean(patch_G.flatten()) Then, define our Gaussian Function: def gaussian(p,mean,std): return np.exp(-(p-mean)**2/(2*std**2))*(1/(std*((2*np.pi)**0.5))) Trying this out with our computed values: x = np.linspace(0,1)y = gaussian(x,mean_patch_R,std_patch_R)plt.plot(x,y); Photo by Author. This distribution gives us the probability of color being part of our image using the R coordinate. We can actually mask our image just by using this: prob_R = gaussian(original_image_R,mean_patch_R,std_patch_R)plt.imshow(prob_R); Photo by Author. But this covers a band in our RG space. We also need to apply the G distribution. prob_G = gaussian(original_image_G,mean_patch_G,std_patch_G)plt.imshow(prob_G); Photo by Author. And since we\u2019re considering independent probabilities, we can simply multiply the masks together: prob=prob_R * prob_Gplt.imshow(prob) Photo by Author. And that\u2019s it, we found another way to segment our image using parametric segmentation! Non \u2014 Parametric Segmentation For cases where our region of interest cannot be approximated by a 2D Gaussian function, we can use a non-parametric segmentation method. For this, we would use the 2D Histogram of our reference image and use histogram back-projection to mask our original image with the computed histogram of our reference patch. plt.figure(figsize=(10,10))plt.hist2d(patch_R.flatten(), patch_G.flatten(), bins=16,cmap=&#039;binary&#039;)plt.xlim(0,1)plt.ylim(0,1); Photo by Author. To do this, we use histogram back-projection in which we give each pixel location a value equal to it\u2019s histogram value in chromaticity space. Let\u2019s test this knowledge: The non-parametric segmentation is especially useful for multi-color segmentation. Create a collage of different skin patch samples, then create a segmentation model by implementing the backprojection algorithm. def backproj(patch, image): # Convert both images to the HSV color space patch_hsv = colors.rgb_to_hsv(patch) image_hsv = colors.rgb_to_hsv(image) # Compute the 2D histogram of the reference patch in the H and S channels patch_hist, x_edges, y_edges = np.histogram2d( patch_hsv[:, :, 0].flatten(), patch_hsv[:, :, 1].flatten(), bins=(6, 2) , range=[[0, 1], [0, 1]]) # Normalize the histogram to have a maximum value of 1 patch_hist = patch_hist / np.max(patch_hist) # Compute the backprojection of the image histogram using the reference patch histogram indices_h = np.searchsorted(x_edges, image_hsv[:, :, 0], side=&#039;left&#039;) - 1 indices_s = np.searchsorted(y_edges, image_hsv[:, :, 1], side=&#039;left&#039;) - 1 backproj = patch_hist[indices_h, indices_s] # Normalize the backprojection to have a maximum value of 1 backproj = backproj / np.max(backproj) # Display the original image and the backprojection side by side plt.figure(figsize=(15, 15)) plt.subplot(1, 2, 1) plt.imshow(image) plt.title(&#039;Original Image&#039;) plt.subplot(1, 2, 2) plt.imshow(backproj) plt.title(&#039;Skin Segmentation&#039;) plt.tight_layout() plt.show() Let\u2019s load our patch (different skin patches) and image: patch = imread(&#039;patch.png&#039;)[:,:,:3]plt.figure(figsize=(20,20))plt.imshow(patch)plt.title(&#039;Skin Patch&#039;, fontsize=20, weight=&#039;bold&#039;)plt.axis(&#039;off&#039;); L\u2019Or\u00e9al skin color chart (https://www.loreal.com/en/articles/science-and-technology/expert-inskin/) image = imread(&#039;people.jpg&#039;)[:,:,:3]plt.figure(figsize=(20,20))plt.imshow(image)plt.title(&#039;Original [&#8230;]",
            "pubdate": "Mon, 17 Jul 2023 12:01:47 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Data Lifecycle in Production: Defining and Collecting useful data.": {
            "url": "https://towardsai.net/p/machine-learning/data-lifecycle-in-production-defining-and-collecting-useful-data",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Akhil Theerthala Originally published on Towards AI. Photo by Mika Baumeister / Unsplash Recently, I have worked on an MLOps series, where I briefly discussed the different steps involved in the lifecycle of a Machine learning project. We started with the deployment overview and moved a step back until we reached the process of scoping a project. However, those articles were written in the format of notes for the Introduction to Machine Learning in Production course by Andrew Ng. When I progressed to the following courses in the specialization, I discovered that the specialization depends on TensorFlow and TensorFlow Extended frameworks. I could have gone ahead mindlessly and learned new things later; however, I took a step back. I re-evaluated what I wanted and re-assessed the direction where I wanted my journey to progress. In the process, I have realized that though I do the course, I cannot only focus on the course content anymore. I had to analyze what I was being taught. Hence, I took my sweet time before taking the next step, which led to this article. So, without wasting more time, let us get into the topic. Lifecycle of a generic Machine learning project in production. Source: DeepLearning.AI, licensed under the Creative Commons Attribution-ShareAlike 2.0 license. The \u201cWhat?\u201d When you recall the machine learning lifecycle, remember that the first step after defining the project is to question what data would help us successfully achieve the intended goals. In this phase, our only goal is to identify and determine the good and useful data, which we then use to create machine learning models. Wait a minute\u2026how do we determine the criteria for \u201c good\u201d and \u201c useful\u201d? We can either ignore these remarks and move on or carefully examine them. In production, it helps to have a firm grasp of the meaning of these adjectives that pop up from time to time. The Good Data and Bad Data Suppose we are trying to predict the economic fluctuations of a country. To this example, what would you think when I insist on adding a feature which is the number of times I sneeze a day? You start seeing me as a crazy person. Why? Cause my sneeze is irrelevant to the economic fluctuations of a country. When we are trying to predict economic fluctuations, the number of times I sneeze is a garbage value. Now the value for the same feature is different when I try to analyze the state of my cold. The feature remains the same in the two cases, but you see me as a madman, whereas you perfectly agree with me in the other. This is basically how we determine a feature to be good or bad. A good feature or good data is relevant to the project we are working on. Bad data is the exact opposite. Imagine if I insist on adding multiple such features to our project. Our model will not be something that predicts economic fluctuations. It will be something that predicts garbage. This is how the phrase \u201c Garbage In, Garbage Out\u201d came out. This is one of the interesting descriptions that I found regarding Good Data and Bad data: Good Data vs Bad Data. Image by Sven Balnojan, in Data Strategy: Good Data vs. Bad Data published on Towards Data Science. What is useful, then? There was another keyword that was used for the data that we needed to collect. Useful. How do you know if a feature is important for the project? Whatever the case, once we start working on a project in a production setting, it is aimed at a certain group of customers who will benefit from the product. Because of this, we need to think about the user when we collect information or develop services. What can the user provide? What is the type of service we are offering? Is it just augmenting the process, or is it automating the task? When we consider the user aspects, the data we need will change. For example, when building an application that recommends his health routine to the user. If he asks for recommendations for his daily workouts, we tend to collect his gym goals, the frequency of his workout, the time he plans to spend in the gym, any health conditions, etc. You won\u2019t need his daily wake-up time to recommend him his workouts. However, if the user\u2019s goal is to maintain a healthy lifestyle, you won\u2019t need the time he plans to spend in the gym or others. Rather, you would like to know the amount of sleep he is getting, his drinking and smoking habits, his target sleep time, his diet etc. Depending on the user\u2019s needs and criteria, the data that is to be collected should be changed. The \u201cHow?\u201d Since we have discussed what data we need to collect, it is time to discuss the \u201chow\u201d of the data collection process. We have many questions here, But for now, let\u2019s focus on the most basic questions you need to answer to start your machine learning project. How to acquire the data that we need? How much data should we collect? The sources The sources for data acquisition can be widely categorized into two categories, User-generated and System-acquired. At the root level, the user-generated data is obtained from surveys, polls, case studies, Q&#38;A forums, images, videos, etc. This data is highly diverse and can have multiple inconsistencies hidden in it. There is a common saying that is accepted by data professionals, which states that \u201c If it is even remotely possible for users to input the wrong data, they are going to do it.\u201d Hence user-input data requires heavy-duty checking and processing. On the other hand, is the system-generated data. It is the data that is automatically generated or stored by the systems that users utilize. This includes various types of logs, system outputs, online sales records, website traffic, etc. Because [&#8230;]",
            "pubdate": "Mon, 17 Jul 2023 11:35:58 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Deploy Triton Inference Server with AWS ECS: Part (3/4)": {
            "url": "https://towardsai.net/p/machine-learning/deploy-triton-inference-server-with-aws-ecs-part-3-4",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Hao WEI Originally published on Towards AI. A step-by-step coding practice a step-by-step coding practice pub.towardsai.net A step-by-step coding practice pub.towardsai.net In the last two blogs, we built a triton inference server with preprocess and post process, using an MNIST example. The server was running as a local host. In this blog, we will deploy the server to AWS so that it will be accessible to the public. We will use two aws components: ECR and ECS. The complete code is publicly available in the following GitHub repository. Before all experiments, it is suggested to create a Python virtual environment, and install all dependencies by pip install -r requirements.txt . Contribute to haowei-2014/triton development by creating an&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:35:37 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "GPT-4: 8 Models in One; The Secret is Out": {
            "url": "https://towardsai.net/p/machine-learning/gpt-4-8-models-in-one-the-secret-is-out",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Dr. Mandar Karhade, MD. PhD. Originally published on Towards AI. GPT4 kept the model secret to avoid competition, now the secret is out! Top highlight The GPT4 model has been THE groundbreaking model so far, available to the general public either for free or through their commercial portal (for public beta use). It has worked wonders in igniting new project ideas and use-cases for many entrepreneurs but the secrecy about the number of parameters and the model was killing all enthusiasts who were betting on the first 1 trillion parameter model to 100 trillion parameter claims! Well, the cat is out of the bag (Sort of). On June 20th, George Hotz, founder of self-driving startup Comma.ai leaked that GPT-4 isn\u2019t a single monolithic dense model&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:35:19 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "The Best AI Virtual Fitting Room | TryOnDiffusion": {
            "url": "https://towardsai.net/p/machine-learning/the-best-ai-virtual-fitting-room-tryondiffusion-2",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI. AI Does magic with UNets, Diffusion, and clothes! Originally published on louisbouchard.ai, read it 2 days before on my blog! https://www.youtube.com/embed/2IJwaDbP3jI Have you ever dreamed of trying out the clothes even when you are shopping on Amazon? This may sound like magic, but it\u2019s actually something becoming more and more possible thanks to AI. As with ChatGPT, MidJourney, and many other AI-powered tools that look like magic and real intelligence, some AIs are trained to take an image of you, and add any piece of clothing to it. I covered a great research approach that was the first doing this virtual Try-on task a few years ago called VOGUE. VOGUE had&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:34:54 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Create a Stunning Documentation for Your Plotly Dash App with MkDocs": {
            "url": "https://towardsai.net/p/machine-learning/create-a-stunning-documentation-for-your-plotly-dash-app-with-mkdocs",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Janik and Patrick Tinz Originally published on Towards AI. Take your documentation to the next level Photo by Carlos Perez on Unsplash Our experience has shown that software projects are often insufficiently documented. But why? Most software projects have a limited budget and a tight schedule. Documentation is then often neglected. Insufficient documentation increases the costs of maintaining a project. For this reason, good documentation is essential. Good documentation includes more than just the technical description of the code. Many development teams use Markdown files for documentation. It\u2019s easy to lose track of the many Markdown files in large projects. Automatically generated documentation addresses this challenge because maintaining such documentation requires less effort. In addition, the information between&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:34:14 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "A Detailed Tutorial on Polynomial Regression in Python, Overview, Implementation, and Overfitting": {
            "url": "https://towardsai.net/p/machine-learning/a-detailed-tutorial-on-polynomial-regression-in-python-overview-implementation-and-overfitting",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Rashida Nasrin Sucky Originally published on Towards AI. Complete code in Python Photo by Joshua Reddekopp on Unsplash I have been writing tutorials on Machine learning, deep learning, data visualization, analysis, and statistics for some time. But I realized I didn\u2019t write too much about some simple machine learning pipelines that can be very useful. Though there are so many more advanced machine-learning tools and packages out there nowadays, still these simple machine-learning tools are still relevant and useful. This article will be about Polynomial Regression basics and implementation using the scikit-learn library in Python. We will also work on an overfitting experiment for machine learning beginners. Polynomial regression is one of the basic machine&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:33:42 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "The Age of Uncertainty: Unmasking our Reality with AI": {
            "url": "https://towardsai.net/p/machine-learning/the-age-of-uncertainty-unmasking-our-reality-with-ai",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Cezary Gesikowski Originally published on Towards AI. How Generative AI Challenges Our Belief Systems and Shapes the Future of Knowledge \u201cYou might worry that an AI system that is uncertain about its objective won\u2019t be as useful as one that knows the objective, but this uncertainty is a feature, not a bug. It leads to AI systems that are deferential, that ask for clarifying information, and that try to learn human preferences over time.\u201d \u2014 Stuart Russel, author of Human Compatible: Artificial Intelligence and the Problem of Control image by the author via Midjourney Uncertainty is our constant companion. It follows us around, whispering doubts and questions that make our reality feel fragile. What we like to call \u2018the truth\u2019 is increasingly&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:33:27 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "AlexNet: Implementation from Scratch": {
            "url": "https://towardsai.net/p/machine-learning/alexnet-implementation-from-scratch",
            "description": "Last Updated on July 17, 2023 by Editorial Team Author(s): Muhammad Arham Originally published on Towards AI. A PyTorch series for people starting with Deep Learning. Following an implementation-based approach of various well-known architectures. Image from Paper Introduction The Alexnet architecture was a breakthrough at the time of its publication, achieving minimal loss on the ImageNet classification task. It uses sequential convolutional blocks with some fully connected layers for the classification task. In this article, we understand the architecture and code it in PyTorch. Architecture The flowchart shows the basic outline of the process. Image by Author The input image is of size 227, width and height with 3 color channels i.e., RGB. They are passed through a series of Convolutional blocks consisting of Convolutional, ReLU, Normalization, and Pooling layers. The output is then flattened to a one-dimensional array and passed through several dense layers. The result is a one-dimensional array, with the size of the vector representing the total number of classes. The exact dimensions and details are extracted directly from the Alex Net paper. The pooling layers reduce the input size and the convolutional filters vary the total channels in the input. The output of the convolutional blocks is a (256,6,6) tensor that is flattened to a single dimension, i.e. 256x6x6 dimensional vector that equals 9216. The vector is passed through two dense layers consisting of 4096 neurons. The last fully connected layer reduces the total output neurons to the number of possible classes. Convolutional Layers If we look into the convolutional layers inside, there are 5 similar blocks, each composed of similar layers. Image by Author The input to the first block is an RGB image with 3 color channels. Each block processes the input and passes the output to the next block in a sequential manner. The output sizes of each block are shown in the image. Convolutional Block The flowchart shows the layers each block is composed of. Image by Author Each block, except 3 and 4 has the above structure. Layers 3 and 4 have no normalization and pooling layers at the end. Convolutional Sizes Each block has different sizes of convolutional layers. The table summarizes the sizes used in the paper. Each convolutional layer uses a ReLU activation that is shown explicitly. Normalization The paper uses LocalResponseNormalization that helps generalized, and as per the paper, improved performance on the classification task. For normalization hyperparameters, they use the following values. Refer to the documentation to learn about what these parameters represent. Pooling Layers The paper proposes to use overlapping pooling where the stride is different from the kernel size. Experimentally, the overlapping pooling reduced the error rates relative to the non-overlapping pooling with the same stride and kernel. Therefore, all pooling layers in the convolutional blocks use stride 2 and kernel size 3. Implementation We start our implementation from the convolutional block structure, which is generalizable to all of the 5 blocks. This can allow modularity, and allow reuse when implementing the complete Alex Net architecture. This reduces code duplication. class AlexNetBlock(nn.Module): def __init__( self, in_channels, out_channels, kernel_size, stride, padding, pool_and_norm: bool = True ) -&#62; None: super(AlexNetBlock, self).__init__() self.conv_layer = nn.Conv2d( in_channels, out_channels, kernel_size, stride, padding) self.relu = nn.ReLU() self.pool_and_norm = pool_and_norm if pool_and_norm: self.norm_layer = nn.LocalResponseNorm( size=5, alpha=0.0001, beta=0.75, k=2) self.pool_layer = nn.MaxPool2d(stride=2, kernel_size=3) def forward(self, x): x = self.conv_layer(x) x = self.relu(x) if self.pool_and_norm: x = self.norm_layer(x) x = self.pool_layer(x) return x The code is self-explanatory, where we receive parameters for the convolutional layer. In addition, we use a pool_and_norm boolean value that will be set to False for block 3 and block 4. The above block can be used in the complete Alex Net architecture. The below code shows the complete Alex Net model, that uses the above block. class AlexNet(nn.Module): def __init__(self, num_classes, in_channels) -&#62; None: super(AlexNet, self).__init__() self.block1 = AlexNetBlock( in_channels, 96, 11, 4, 0, pool_and_norm=True) self.block2 = AlexNetBlock(96, 256, 5, 1, 2, pool_and_norm=True) self.block3 = AlexNetBlock(256, 384, 3, 1, 1, pool_and_norm=False) self.block4 = AlexNetBlock(384, 384, 3, 1, 1, pool_and_norm=False) self.block5 = AlexNetBlock(384, 256, 3, 1, 1, pool_and_norm=True) self.flatten = nn.Flatten() self.fc1 = nn.Linear(256 * 6 * 6, 4096) self.dropout1 = nn.Dropout(0.5) self.fc2 = nn.Linear(4096, 4096) self.dropout2 = nn.Dropout(0.5) self.classification_layer = nn.Linear(4096, num_classes) def forward(self, x): x = self.block1(x) x = self.block2(x) x = self.block3(x) x = self.block4(x) x = self.block5(x) x = self.flatten(x) x = self.fc1(x) x = self.dropout1(x) x = self.fc2(x) x = self.dropout2(x) x = self.classification_layer(x) return x As per the flowchart, we create 5 Alex Net blocks with the configuration described. We then sequentially pass the input through all the layers, till we achieve a one-dimensional array representing the probability of each possible class. For this specific instance, we need two initialization parameters for AlexNet. One is input channels that are by default three for RGB images. The second is the total number of classes that defines our output size. In the paper, the value used was 1000 for the Image Net task. For my implementation, I use the CIFAR-10 dataset so I set it to ten. The below image summarizes the Alex Net architecture. Image by Author Conclusion The above architecture can be trained for a classification task from scratch. I trained it for the CIFAR-10 dataset for ten epochs. The below graph shows the loss progression. Image by Author For just ten epochs, the Cross-Entropy Loss is reducing gradually, and we can do well for simple classification tasks. The article only shows code snippets for understanding. For complete implementation and training code, refer to my GitHub repo. For a detailed understanding of the architecture, consider reading the paper. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 17 Jul 2023 11:32:36 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "I Cant Wait for Metas Next Virtual (And Augmented) Reality Headset and How It Might Change the Future of Work and Education": {
            "url": "https://towardsai.net/p/machine-learning/i-cant-wait-for-metas-next-virtual-and-augmented-reality-headset-and-how-it-might-change-the-future-of-work-and-education",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): LucianoSphere Originally published on Towards AI. Meta poses its upcoming headset as THE new tool for work, which will \u201creplace your laptop\u201d as they said. And it\u2019s not only VR but also AR thanks to colored passthrough cameras. Figure composed by the author. Mark Zuckerberg (co-founder and CEO of Meta, former Facebook) recently shared new information with investors (full transcript of the event here) and during the event, the company also revealed some clues about the virtual/augmented reality (VR/AR) headset to be launched soon and developed as part of \u201cProject Cambria\u201d. Notably, Meta\u2019s new device is intended mainly for work use cases, as opposed to gaming and entertainment which we are usually used to in the field of VR and AR. This is exactly what I have so much hoped for, because as you may have seen I guide projects&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 10:18:33 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Manipulate Images with Blobs! BlobGAN Explained": {
            "url": "https://towardsai.net/p/machine-learning/manipulate-images-with-blobs-blobgan-explained",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI. A GAN model that uses simple blobs to manipulate objects in images\u2026 Originally published on louisbouchard.ai, read it 2 days before on my blog! If you think that the progress with GANs was over, you couldn\u2019t be more wrong. Here\u2019s BlobGAN, and this new paper is just incredible. BlobGAN examples of moving all objects. Image from the authors&#039; project\u2019s page. BlobGAN allows for unreal manipulation of images, making super easily controlling simple blobs. All these small blobs represent an object, and you can move them around or make them bigger, smaller, or even remove them, and it will have the same effect on the object it represents in the image. This is so cool! As the&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 10:16:31 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Fake Reviews: Maybe You Should Be Worried About AIs Writing (and Reading) Skills": {
            "url": "https://towardsai.net/p/machine-learning/fake-reviews-maybe-you-should-be-worried-about-ais-writing-and-reading-skills",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Dora Cee Originally published on Towards AI. In a recent, rather troubling, study humans could detect fake reviews with a measly 55.36% success rate. As for AI? It boasted a 96.64% accuracy. Fake reviews have become a steady crutch for many companies relying on misleading information to hoard in sales. To make things worse, we are a creative lot when it comes to hacking \u201cthe system\u201d. Hence, many have already taken false promotion further by reaching for AI. Needless to say, the abuse of machine-generated recommendations results in an unfair playing field between retailers and disillusioning shopping experiences for consumers. On the flip side, at least we are getting better at taming AI. The irony is that humans are just not good at telling apart writings penned by humans and those by AI if the latter is given enough learning material. It\u2019s almost like we\u2019ve never encountered the lore of Pandora\u2019s Box before. But I digress \u2014 let\u2019s get back to e-commerce first. What should be a useful source of word-of-mouth insight for assessing a product\u2019s quality, relevance and suitability have become notably fractured. All these artificial outputs seem to be gradually eroding trust in online reviews, at a time when social trust is already in decline. Image by Mohamed Hassan on Pixabay The problem is not only the staggering number of deceptive reviews and spam, which come in many shades of fiction. The social media influencer promoting the latest snake oil is one thing, but machine learning has unleashed a storm of fabrications on a whole other level. Current text generation methods can now create fine-tuned, realistic scripts \u2014 and their detection is challenging for humans. Topics Covered: At a Quick Glance: Introductory PointersData Mining Truthful ReviewsThe Pen is Mightier Than The CueDetection Strategies for Fake ReviewsCombating AI with AIPractical Everyday Tips for Spotting a FakeKey Takeaways At a Quick Glance: Introductory Pointers Unable to tell fact from fiction, consumers are already rightfully full of doubts. Below are some of the problems this downward spiral is slowly cementing. \u27a4 Though we may still not have hit rock bottom, eventually the damage to the source credibility of reviews might downgrade them to nothing but the online marketplace iteration of junk mail. \u27a4 Algorithms also refer back to reviews to determine a product\u2019s ranking in a category. This means that computer-generated reviews can be weaponized to either inflate or deflate marketplace ranking artificially, resulting in unfair competition. \u27a4 Companies can target rivals by harnessing the destructive impact of negative reviews to lower the other\u2019s visibility on online platforms and search engines. Note that your competitors could also poach your customers by using your brand. In this digital battle of flooding the market with fake appraisals, ultimately only the swindlers can gain ground unless fake reviews become easier to spot and firmly disincentivized. \u27a4 The damage to a seller\u2019s reputation can also spiral out of control in the age of social media and swift information exchange. Negative reviews can be easily circulated on multiple platforms, potentially making the company in question go viral for all the wrong reasons. And guess what? Unethical practices or even just rumors can get you canceled overnight. \u27a4 Competitive advantage can also be obtained by manipulating users\u2019 perceptions about products and companies alike. Confirming this fact, a 2016 study by Luca estimated that a one-star addition to a Yelp rating leads to a 5\u20139% increase in revenue. \u27a4 Still not convinced? Allow me to frame it differently. In a 2015 report, the CMA estimated that \u201c\u00a323 billion a year of UK consumer spending is potentially influenced by online reviews\u201d. Don\u2019t underestimate the power of social proof. Image by Mohamed Hassan on Pixabay Data Mining Truthful Reviews Refraining from cheating at the online marketplace game comes with some pretty powerful upsides. \u278a First of all, authentic reviews describe the quality of the product or service in a more believable way. This, in turn, paves the way for a more constructive type of communication. \u278b Second, consumers are able to better tell whether it is really what they need and what they should expect. In the end, a disclosure of honest experiences and impressions is in the interest of both the buyer and the seller. \u278c It identifies aspects that are relevant to the product and its usage. Some of these may have entirely escaped the company\u2019s attention, for example, due to insufficient testing or misaligned mental models. \u278d On the other side of the equation, companies can use them as valuable feedback for shortcomings and improvements. Many firms pay good money for surveys and product testing. Why, then, would anyone want to ignore original comments from the consumer directly, especially when they come free of charge? Analyzing data from reviews can be put to good use if considered and harnessed properly. Image by Mohamed Hassan on Pixabay The Pen is Mightier Than The Cue A fake review can obviously be composed by a human as part of an exploitive marketing campaign or other incentivized pursuit. However, technology is reaching advanced levels of generated copy-writing and skill at deception. Already, people are finding it challenging to tell the difference between an AI-produced text and a genuine consumer\u2019s opinions. Exploiting the easy distribution channel of the digital world is the most recent, appealing shortcut to dishonest sellers. Sadly, the influx of fake users and content could become unmanageable unless measures are implemented to tackle misinformation. This practice is already forbidden by The Consumer Protection from Unfair Trading Regulations 2008, as per the below: (11) Using editorial content in the media to promote a product where a trader has paid for the promotion without making that clear in the content or by images or sounds clearly identifiable by the consumer (advertorial). The problem remains the lack of detection strategies being available and used (for now). Once the crackdown on fake reviews begins, chances are individual companies relying on false claims [&#8230;]",
            "pubdate": "Tue, 18 Jul 2023 10:15:44 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "PyScript Is Ok-ish To Make Your Pages Interactive, but Only as a Last Resource if You Dont Know Any Javascript": {
            "url": "https://towardsai.net/p/machine-learning/pyscript-is-ok-ish-to-make-your-pages-interactive-but-only-as-a-last-resource-if-you-dont-know-any-javascript",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): LucianoSphere Originally published on Towards AI. PyScript is too slow and heavy, and it doesn\u2019t support all the features and libraries you may want to use. There\u2019s been a lot of hype these days about the possibility of running Python code inside web pages thanks to PyScript, a web component that injects into your web page a series of HTML tags where you can\u2026 well\u2026 run Python code. Sure it sounds exciting, but JavaScript has evolved so, so tightly with web browsers that I wonder\u2026 isn\u2019t it just better? Well, I made some tests and hell\u2026 PyScript is way too slow and heavy to load, and it doesn\u2019t support all of Python\u2019s features and libraries (like the very popular Plotly, see below)\u2026 So at the end of&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 10:11:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "HydraSum: Disentangling Stylistic Features in Text Summarization (Paper Review/Described)": {
            "url": "https://towardsai.net/p/machine-learning/hydrasum-disentangling-stylistic-features-in-text-summarization-paper-review-described-2",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Ala Alam Falaki Originally published on Towards AI. Training Is it possible to train a model with transformer architecture to learn generating summaries with different styles? Figure 1. The multi-decoder architecture scheme. (Image from [1]) While it\u2019s true that deep learning (specifically transformer architecture) keeps pushing the SOTA scores, they have a kind of significant shortcoming. No, I am not talking about their memory usage! We know how to train them, but we do not have any control over what they will learn. For instance, it is a missing feature in Text Summarization models to control the output to set a length or style. Let\u2019s see if we can do anything&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 10:04:11 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "MITACS Globalink Research Internship | How to get one?": {
            "url": "https://towardsai.net/p/machine-learning/mitacs-globalink-research-internship-how-to-get-one-2",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Raman Jha Originally published on Towards AI. MITACS Globalink Research Internship &#124; How to get one? Mitacs Globalink Research Internship Let me introduce myself first. Hey there, I am Raman Jha, a junior year Bachelor of Engineering student at D Y Patil College of Engineering which is affiliated with Savitribai Phule Pune University, Pune. I got selected for Mitacs Globalink Research Internship\u201922 for Dalhousie University, Halifax, Nova Scotia, Canada. I will be working under the guidance of Professor Andrew Rutenberg. My project is titled \u201cHow do organismal scales interact during aging and death using Machine Learning?\u201d. In this project, We will be modeling aging from a physics perspective, to understand the variability of individual aging trajectories, the interactions between health deficits, and the mechanisms of observed aging phenomenology. This project is currently using the Dynamic Joint Interpretable Network (DJIN) deep-learning model to study the aging of model organisms or to study the effects of chronic diseases. I will be working on training the DJIN model with multiscale data, to determine how these scales interact. This project can immensely contribute to the research of #aging, #machinelearning, and #deeplearning. So, now let&#039;s get started with my voyage of Mitacs GRI coming ahead!! This all started in the last week of May 2021, when I came across a repository by Hima Ahuja which contained almost all the Research Internship for Undergraduates. After knowing about Mitacs Globalink Research Internship through this repository, I knew that this is the internship that could provide me with an international research experience and an exposure that was unprecedented for me. I did not have many things at that time to showcase my skills. I got a research internship at IIIT, Lucknow in June and that really helped me build my profile for this internship. I worked on predicting heart disease from the UCI dataset. After that, I also got selected for Script fellowship\u201921 where I worked on a machine learning project called \u201cCraftbrain\u201d. Now, after reading this you must be thinking about what exactly this internship is all about? Will it be like a summer research program or will it be a summer school? What about funding, will I also get funded for that? Will this be an in-person or will it be a remote internship? How will I be managing my expenses? And this list will only go on, I can totally understand that because once I also had these questions. So, through this blog, I would try my best to answer most of the relevant questions about this amazing opportunity that would definitely change your life and provide you a chance to work in Canadian universities and their labs. It would also provide you an opportunity to collaborate with some of the finest persons in research while you will be completing your undergrad and that too with a decent stipend:) Canada \u2014 A Land of Opportunities Now we should start with some basic questions which normally every aspirant has when they heard about this internship. What is Mitacs Gloabalink Research Internship?As stated on the official website of Mitacs \u201cThe Mitacs Globalink Research Internship is a competitive initiative for international undergraduates from the following countries and regions: Australia, Brazil, China, France, Germany, Hong Kong SAR, India, Mexico, Tunisia, United Kingdom, and Ukraine. From May to October of each year, top-ranked applicants participate in a 12-week research internship under the supervision of Canadian university faculty members in a variety of academic disciplines, from science, engineering, and mathematics to the humanities and social sciences\u201d. In other words, this is one of the best opportunities in the world for a growing researcher like you to obtain international exposure and collaborate with some of the best researchers in academia. It will provide you with a chance to contribute to some interesting and real-life research-based projects. The duration of the program is 12 weeks(May to October). The unique part about the research program is that the start date and the end dates are dependent on the availability of the selected intern. You can start your project anytime from 1st May to 31st July. You will be required to work 40 hours per week under a Canadian professor at the university where you got selected. 2. Why is this internship so prestigious?Here are some crucial points which make it prestigious: 1. International exposure: As this is an international internship, so many interns will come from different parts of the world. This internship provides interns with an opportunity to meet with multinational people. It will help them to collaborate as well as learn from each other. 2. Technical exposure: Miatcs Globalink research Intern will have the access to one of the best research labs in the world, they will work on hand-on research, and they will also collaborate with many finest researchers for their research projects. 3. Globalink Graduate Fellowship: As per their official website \u201cThe Globalink Graduate Fellowship provides $15,000 in financial support to former Globalink Research Interns who return to Canada for full master\u2019s or Ph.D. programs, or Postdoctoral fellowships at any Mitacs partner institution. Globalink alumni may apply for the fellowship at a different university than their Globalink Research Internship host institution\u201d. 4. Competitive: In this internship program, applicants from around the world from the selected countries apply for it and that is what makes it highly competitive for other applicants. 5. Stipend: Mitacs offered a decent stipend to its interns for this Gloabalink Research Internship. At this time, it is happening offline, so I can confirm you that the amount is sufficient to manage the expenditures and stay for 12 weeks in Canada. When it comes to funding, it covers your airfare, visa, living stipend, daily allowances, and also an allowance for COVID-related expenses. (It is around 8500+ CAD for this year). This time the internship is happening in-person mode(Thank god, this time it is not in virtual mode) after two years and the stipend depends on the stipend [&#8230;]",
            "pubdate": "Tue, 18 Jul 2023 09:52:23 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Forecasting Time Series Data: Netflix Stock Price Prediction": {
            "url": "https://towardsai.net/p/machine-learning/forecasting-time-series-data-netflix-stock-price-prediction",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Alison Yuhan Yao Originally published on Towards AI. ARIMA-(G)ARCH models with MiniTab and R Photo by Jake Hills on Unsplash The Netflix stock price has been quite volatile recently, which makes the prediction of the time series data very interesting. In this blog, I will use ARIMA-(G)ARCH models for prediction, Minitab for plotting, and R for model selection. (Because of the instructions of this class project, I will have to comply with some restrictions.) Some prior knowledge before reading this blog includes: ARIMA model ARCH and GARCH models Data Description This project uses the daily stock price of Netflix from 2002\u201305\u201323 to 2022\u201303\u201318 (4991 observations) for the time series forecast. The 2022\u201303\u201318 data is the latest entry from Yahoo Finance as of the time I obtained the dataset. The head of the table is shown below: Image by Author I will leave out the last data point, which is the data for 2022\u201303\u201318 for the ARIMA-(G)ARCH modeling. Therefore, n=4991\u20131=4990 and I will be using the Adj Close data from 2002\u201305\u201323 to 2022\u201303\u201317. ARIMA modeling The time series plots of Netflix stock price (Adj Close), DifNetflix, LogNetflix, and DifLogNetflix are as follows: Image by Author Image by Author There is strong evidence that Netflix has level-dependent volatility. Netflix stock prices are more volatile in recent years. Taking log can help us mitigate level-dependent volatility and linearize the plot, as the volatility of DifLogNetflix does not seem to depend on a level anymore. For choosing an ARIMA(p,d,q) model, we need to first determine the value of d and see how many times we need to difference the data to make it stationary. The ACF and PACF plot of LogNetflix is as follows: Image by Author The ACF plot of LogNetflix indicates a hanging behavior and the PACF plot of LogNetflix cuts off after lag 1, so LogNetflix is non-stationary. We need to difference the data. The ACF and PACF plots of DifLogNetflix show that differencing once seems to make the data stationary, as there are no statistically significant lags. Image by Author To double-check if d=1, we can difference the data again and look for a sign of over-differencing. Image by Author Indeed, differencing twice shows strong evidence of over-differencing as the PCF of Dif2LogNetflix is statistically significantly negative at lag 1 and close to -0.5. Therefore, we conclude that d=1 in the ARIMA model. The ACF plot of DifLogNetflix suggests an ARIMA(0,1,4) model, while the PACF of DifLogNetflix suggests an ARIMA(4,1,0) model. Now, we need to select the p and q in the ARIMA model. Let\u2019s pick p,q = 0,1,2 arbitrarily (because of the principle of parsimony) and compare AICc. The formula for AICc is as follows: Image by Author The SS means the sum of squared error and it can be obtained from Minitab output. We know N = n\u2013d = 4990\u20131 = 4989. Image by Author ARIMA(0,1,1) with constant gives us the smallest AICc value, so we choose ARIMA(0,1,1) with constant. The Minitab output for ARIMA(0,1,1) with constant is: Image by Author Both the MA1 coefficient and the constant are statistically significant, with p-values less than 0.05. Therefore, if we denote {x_t} as the time series of Netflix, {y_t} as LogNetflix and {z_t} as DifLogNetflix. The best estimate of the MA1 coefficient is -0.0309 and that of the constant is 0.001151. Therefore, the fitted model is Image by Author where z_t = y_t-y_{t-1} = log(x_t)-log(x_{t-1}). The one step ahead forecast and 95% forecast interval are as follows: Image by Author The time series plot of the residuals is: Image by Author The residuals look relatively random, with only a few with absolute values over 0.3. The ACF and PACF plots of the residuals are as follows: Image by Author There aren\u2019t many statistically significant lags in the residuals, meaning that the residuals look uncorrelated. The ACF and PACF of squared residuals are: Image by Author However, the squared residuals have multiple lags that are statistically significant, meaning that the residuals are not independent. Also, we can see from the time series plot of the residuals that the variance is not constant. There exists evidence of conditional heteroscedasticity. Before doing the (G)ARCH modeling, we need to save the residual information from Minitab to a txt file and import it into R. # read file &#38; check headres = scan(&#034;RES.txt&#034;, what=&#034;list&#034;)head(res)# clean up data &#38; convert data typeres = res[-c(1,2)]res = as.numeric(res)head(res) (G)ARCH modeling ARCH(q) To select the ARCH(q) model with q ranging from 0 to 10, we can calculate the AICc. The formula for AICc changes here: Image by Author The values of logLik can be obtained from R. library(tseries)# check different ARCH modelsfor (i in 1:10){ print(paste0(&#039;model ARCH(&#039;, i, &#039;)&#039;)) model = garch(res, c(0,i), trace=F) print(summary(model)) print(logLik(model))}# ARCH(0) model has to be manually calculated# model = garch(res, c(0,0), trace=F) is going to give an errorN = 4989print(paste0(&#039;log Lik.&#039;, -0.5*N*(1+log(2*pi*mean(res^2))))) Again, we know N = n\u2013d = 4990\u20131 = 4989, so we have: Image by Author GARCH(1,1) We can also consider the GARCH(1,1) model due to the principle of parsimony. We have logLik = 9799.593 (q=2) and the corresponding AICc is -19593.18118555667. GARCH(1,1) yields the smallest AICc, so we choose GARCH(1,1). # compared with GARCH(1,1) modelmodel=garch(res,c(1,1), trace=F)print(summary(model))print(logLik(model)) Image by Author The p-values are not correct because they are for a 2-tailed test. We should look at half of the presented p-values, but they are so small that half of any of these p-values is strongly statistically significant. Therefore, a0, a1, and b1 are all statistically significant. However, the Jarque Bera test has a p-value less than 0.05, which indicates that the conditional distribution of GARCH residuals is not normally distributed. The Ljung-Box test has a p-value greater than 0.05, which means that the GARCH residuals are not correlated. But overall, the model is inadequate. To write the complete form of the chosen GARCH(1,1) model, we have \u03c9=0.000005875, \u03b1=0.01425, and \u03b2=0.9814. Therefore, the complete form is Image by Author The [&#8230;]",
            "pubdate": "Tue, 18 Jul 2023 09:50:38 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Learnings From Participation in My First Health Datathon": {
            "url": "https://towardsai.net/p/machine-learning/learnings-from-participation-in-my-first-health-datathon",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Carla Martins Originally published on Towards AI. 4th Datathon ESICM 2022 In May 2022, and for the first time, I enrolled in a Health Datathon organized by ESICM (European Society of Intensive Care Medicine). This was my first Datathon, and a great experience for learning and sharing knowledge with people from different educational and professional backgrounds worldwide. How I was invited? It was a surprise to me when I received a message on LinkedIn with an invitation to join an already formed group that included doctors and data scientists. The invitation came from a data scientist that found my profile and some links to my Medium publications. I immediately fell in love with&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 09:45:10 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Scrap LinkedIn Data To Find the Best Degrees for Data Science": {
            "url": "https://towardsai.net/p/machine-learning/scrap-linkedin-data-to-find-the-best-degrees-for-data-science",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Asish Biswas Originally published on Towards AI. Guide To Data Cleaning: Definition, Benefits, Components, And How To Clean Your Data Photo by Jamie Street on Unsplash People want to know what degree one should obtain to break into the world of Analytics. I personally have a Computer Science degree, but I have worked with people from different disciplines like Chemistry, Physics, Psychology, etc. So I know that people from almost any discipline can come to this field and shine. To answer this question, a lot of people look into job openings and analyze job requirements. But I think a better approach is to look at the profiles who are actually working in that field. Because in job posts, people often ask for&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 09:43:30 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "How to collect free-text feedback: an introduction for a data scientist": {
            "url": "https://towardsai.net/p/machine-learning/how-to-collect-free-text-feedback-an-introduction-for-a-data-scientist",
            "description": "Last Updated on July 18, 2023 by Editorial Team Author(s): Anil Tilbe Originally published on Towards AI. Understand how to develop technical learning systems to collect free-text, open-ended responses from users. Photo by Emily Morter from Unsplash To truly understand the type of measurement framework to implement for how to solicit feedback is to also humbly acknowledge as a data scientist the shortcomings and imprecise capabilities of natural language processing and machine learning. Control +F the number of times I mentioned \u201cprimary source.\u201d Use case: analyze free-text comments; predict their binary sentiment (positive or negative); and measure the magnitude of that sentiment (e.g., polarities in TextBlob; the positive or compound score in VADER; your custom sentiment score for your custom-trained model;&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 18 Jul 2023 09:42:07 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Flattening the Coronavirus Curve": {
            "url": "https://towardsai.net/p/machine-learning/flattening-the-coronavirus-curve",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Benjamin Obi Tayo Ph.D. Originally published on Towards AI. What it means, and what we can all do to mitigate the spread Image simulated by Benjamin O. Tayo \u201cStay at home and save lives. It\u2019s a time of shared national sacrifice, but it\u2019s also a time to treasure our loved ones and to take stock of what\u2019s most important.\u201d \u2014 The White House The Coronavirus, also referred to as COVID-19 is a novel, highly contagious virus that has created a global pandemic and is making headlines all over the world. According to the World Health Organization\u2019s COVID-19 Situation Report, there are 266,073 confirmed cases globally with 11,184 deaths, as of March 20, 2020. According to this same report, there are a total of 182&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:54:44 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Surprisingly Powerful Dataset Exploration Techniques For Rookies": {
            "url": "https://towardsai.net/p/machine-learning/surprisingly-powerful-dataset-exploration-techniques-for-rookies",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Beltus Nkwawir Originally published on Towards AI. Lets explore the COVID-19 dataset and others with interestingly simple yet powerful techniques. Photo by CDC on Unsplash COVID-19 dataset download complete! What now? You must be thinking. That is exactly what I used to think when I started this long yet exciting journey into the planet of data science. I will stare at a dataset folder on my computer screen like a sheep that just lost it\u2019s shepherd. Lost, confused and utterly frustrated I find myself watching a youtube clip of Sheldon \u2014 Big Bang Theory. image from popsugar.com Slowly but surely mission failed. If you are new to data science, it is daunting and overwhelming to get started with understanding the contents of any dataset amid the ocean of datasets existing today. Every second that ocean expands further. It is imperative every rookie in data science familiarize themselves with the very basic techniques of exploring the dataset because it is the fuel that powers AI. Working on a machine learning project without first of all understanding the dataset you are working with, is like trying to build a skyscraper without a blueprint. Think about that for a second. In today\u2019s article, I will share a couple of basic yet powerful exploration techniques that you can apply to almost any dataset. These techniques will help you break through datasets. Not only that, but you will also have a holistic understanding of the dataset you are working with. This should be enough to activate the flow of dopamine in your system so that you can frictionlessly complete your machine learning project while having fun. Okay, enough of the talk. Let&#039;s get to it. Prerequisite For this article, we will be using Pandas which is one of the most popular data structure libraries for machine learning. It has many interesting built-in functions that we will be exploring shortly. Some people use pandas together with Matplotlib and Seaborn statistical data visualization purposes. Feel free to check them out. For those who have never used Pandas library before do not break a sweat over it. I wrote this article with you in mind. In order to use the Pandas library, we first need to install it. pip install pandas I am using jupyter notebook to run all the codes in this article. If you don\u2019t have a Jupiter notebook set up yet, I got you covered. Check out the Datacamp site. At the end of this article, I will share a link to my GitHub page where you can access the complete notebook. So stay frosty till the end. Import Relevant Libraries To have access to the amazing Pandas functions, we need to import it into our code. I imported it with the alias pd. Pandas is built upon NumPy which is very useful for mathematical operations import pandas and numpy libraries10 Load Dataset into Memory. The pandas .read_csv() method reads the dataset file and saves it as a Pandas Dataframe object. Think of a data frame as a table with labels rows and columns. Here I am using the COVID-19 Dataset from Kaggle At the end of the article, I will provide links to all the different datasets I used in this article. So don\u2019t fret about it. Display the Number of Samples (Observations) in Dataset. For any dataset you come across, it is important to know the number of data points or training examples present in your dataset. This is simply the number of rows and columns. Number of Samples or observations: 18056Number of Attributes or Features 8 If you interesting in knowing just the number of rows, just do this. Number of Samples: 18056 Take a Quick Peek at the Contents of your Dataset What exactly is the content of your dataset? Pandas head() and tail() helps you with that. By default head() prints the first 5 rows and tail the last 5 rows of your dataset. Displaying the First and Last five rows of Covid-19 dataset You can as well specify the number of rows you want to display by passing the number of rows as an argument to the functions. Prints the first and last 10 rows respectively Sometimes your dataset will have a large number of columns such that you won\u2019t be able to view them all. Unless you are working with a gigantic computer screen. Luckily, with the code snippet below, you can scroll left and right to see everything. Cool right? screenshot of random dataset showing the scroll button Display Interesting Statistical Information. Let&#039;s take a step further into gaining some statistical insights of our dataset. Personally, the .describe() method is a *must-know* function. It provides some invaluable statistical information such as count, mean, standard deviation, etc of each of the numeric columns found in our dataset. screenshot of statistical information of COVID-19 count row can be especially useful as it gives a clue of any missing values in your data that could negatively affect the performance of your machine learning model. Removing Irrelevant Columns In building a machine learning model, some features or columns might have zero contribution to the performance of the prediction. You can eliminate any unwanted column by using the snippet below. Axis specifies that it is column. I dropped the Lat and Long columns in the COVID-19 dataset. Screenshot of Latitude and Longitude Columns Dropped Note: It is good practice to assign the modified dataset to a new variable. Number of Unique Samples in Dataset This next code snippet is often very useful in machine learning especially when we are dealing with classification problems. It helps you to know the number of samples that belong to a particular category. An example is shown below Number of samples per country Renaming Weird Column Names Datasets can be messy at times with weird column names given by the creators of the datasets. You don\u2019t have to stick with these. If you don&#039;t like it, [&#8230;]",
            "pubdate": "Thu, 20 Jul 2023 09:51:42 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Jupyter Notebook Keyboard Shortcuts for Beginners": {
            "url": "https://towardsai.net/p/machine-learning/jupyter-notebook-keyboard-shortcuts-for-beginners",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Magdalena Konkiewicz Originally published on Towards AI. Learn the most important shortcuts to improve your productivity while working with Jupyter notebook editor. Photo by cocoparisinenne on Pixabay When you start with Jupyter notebook most of the people use the menu bar above the cells to do basic operations. This is not the most time-efficient way to do them, therefore, I want to show the most basic keyboard shortcuts of Jupyter notebook that you will use every time you open the editor. This article is not a complete list of all possible shortcuts in the notebook but focuses on the ones that you will be using most frequently and therefore learning them at the beginning of your Jupyter notebook journey is essential. Command mode versus edit&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:50:44 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "When GraphSAGE Meets Pinterest": {
            "url": "https://towardsai.net/p/machine-learning/when-graphsage-meets-pinterest",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Edward Ma Originally published on Towards AI. Photo by Pinterest In the previous stories, we introduced Introduction to Graph Embeddings, Random Walk in Node Embeddings, and 4 Graph Neural Networks. I would like to further extend to PingSAGE. It was proposed by Ying et al. in 2018. Ying is one of the authors of GraphSAGE (Hamilton et al., 2018). He and his team apply a modified version of GraphSAGE (Hamilton et al., 2018)in the Pinterest dataset. We will use the following undirected graph to go though PinSAGE (Ying et al., 2018) algorithm. First of all, we have an input graph with Node A, B, C, D, E, and F&#8230;. Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:49:42 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Coronavirus Cases in Highly Industrialized Countries": {
            "url": "https://towardsai.net/p/machine-learning/coronavirus-cases-in-highly-industrialized-countries",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Benjamin Obi Tayo Ph.D. Originally published on Towards AI. Italy has been hit the hardest among top industrialized nations. Japan and Russia have the least number of cases and deaths. Italy and the USA are projected to overtake China in the number of cases within a few days. Coronavirus cases from the top 9 industrialized nations. Source of data: Google Crises Response Data on COVID-19. Image by Benjamin O. Tayo The coronavirus, also referred to as COVID-19 is a novel, highly contagious virus that has created a global pandemic and is making headlines all over the world. According to the Google Crises Response Data on COVID-19, there are 471,076 confirmed cases globally with 21,284 deaths, as of March 25, 2020. According to this same report, there are a total of 183 countries, territories or areas with reported laboratory-confirmed COVID-19 cases and deaths. In this article, we analyze coronavirus cases from&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:44:33 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "NLP News Cypher | 03.29.20": {
            "url": "https://towardsai.net/p/machine-learning/nlp-news-cypher-03-29-20",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Ricky Costa Originally published on Towards AI. Photo by Westwind Air Service on Unsplash NATURAL LANGUAGE PROCESSING (NLP) WEEKLY NEWSLETTER NLP News Cypher &#124; 03.29.20 With a Little Help From My Friends Recorded a live feed of the (almost done) demo. I\u2019m using 2 classifiers to classify financial news tweets for topic and sentiment and they classify in real-time \ud83d\udc40. Deploying large transformer models for online inference is hardcore! Meanwhile, back at the ranch, Refinitiv released a blog post showing how they trained BERT from scratch using Reuters news corpus and then fine-tuned for downstream tasks. They were going after events in financial news, more specifically, environmental, social and governance (ESG) controversies. (From an investor perspective, they are interested in how societal events may have an impact on companies.) Blog: Next-level NLP and potential ESG controversies &#124; Refinitiv Perspectives Refinitiv Labs focuses on harnessing the power of Big Data and Machine Learning (ML) to drive innovation and shape the\u2026 www.refinitiv.com FYI: Releasing a new update for the Big Bad NLP Database very soon! How was your week? \ud83d\ude0e This Week: Software is Eating the World Decoding Output Deep Dive in QA BERT Y Combinator DEMO Day Summarization with BART AI Adoption in the Enterprise 2020 XTREME Benchmark Dataset of the Week: XNLI Software is Eating the World From Andreessen Horowitz\u2019s blog, they give a very sobering look on the underworld of AI startups. The post highlights the difficulties in dealing with edge cases, domain shift, computational cost and other headaches. Having deployed AI models myself, this post is fairly accurate. The New Business of AI (and How It&#039;s Different From Traditional Software) At a technical level, artificial intelligence seems to be the future of software. AI is showing remarkable progress on\u2026 a16z.com Decoding Output When you hear an ML engineer talking about beam search, temperature, or top-k sampling it could be a head-scratcher. But taking your time to understand these parameters has a lasting impact on text generation models like GPT-2! Read all about it in a new Hugging Face blog post: How to generate text: using different decoding methods for language generation with Transformers In recent years, there has been an increasing interest in open-ended language generation thanks to the rise of large\u2026 huggingface.co Deep Dive in QA BERT McCormick strikes back with a great blog post on the inner-workings of question answering w/ BERT. Part 1 covers how BERT deals with question answering tasks and in Part 2 Chris goes over the generalization capabilities of BERT (fine-tuned on SQuAD) on data it\u2019s never seen before: Question Answering with a Fine-Tuned BERT What does it mean for BERT to achieve &#034;human-level performance on Question Answering&#034;? Is BERT the greatest search\u2026 mccormickml.com Surprise, there\u2019s a Colab notebook too: Google Colaboratory Edit description colab.research.google.com Y Combinator DEMO Day Y Combinator Demo day event brought us several up-and-coming AI companies. This TechCrunch article covered each company and what they had to offer. This is short-term glimpse of where tech is going. Right now, there\u2019s a lot of companies doing developer tools (spoiler alert\ud83d\ude01 ): All the companies from Y Combinator&#039;s W20 Demo Day, Part III: Hardware, Robots, AI and Developer\u2026 Y Combinator&#039;s Demo Day was a bit different this time around. As concerns grew over the spread of COVID-19, Y\u2026 techcrunch.com Summarization with BART: Colab Peeps always want more summarization examples. Well here\u2019s an awesome Colab notebook to do just that with the BART model! Colab: Google Colaboratory Edit description colab.research.google.com BART Paper: LINK AI Adoption in the Enterprise 2020 O\u2019Reilly, the maker of those books you love, came out with their AI Adoption survey earlier this month. Seems institutional folks are still skeptical of AI tech: \u201c..lack of ML and AI skills isn\u2019t the biggest impediment to AI adoption. Almost 22% of respondents identified a lack of institutional support as the most significant issue.\u201d Check out the report\u2019s highlights here: AI adoption in the enterprise 2020 Join Roger Magoulas on March 26 for a live and interactive online session exploring recent O&#039;Reilly AI/ML research. Get\u2026 www.oreilly.com XTREME Benchmark When possible, researchers like to transfer representational embeddings from one language to another, especially so for low-resource languages. Well, a new benchmark emerged to test the capabilities of cross-lingual generalization called XTREME! Currently, it covers multilingual representations across 40 languages and 9 tasks. Paper: LINK Dataset of the Week: XNLI What is it? \u201cCorpus is a crowd-sourced collection of 5,000 test and 2,500 dev pairs for the MultiNLI corpus. The pairs are annotated with textual entailment and translated into 14 languages: French, Spanish, German, Greek, Bulgarian, Russian, Turkish, Arabic, Vietnamese, Thai, Chinese, Hindi, Swahili and Urdu.\u201d Sample: Where is it? XNLI Introduction The Cross-lingual Natural Language Inference (XNLI) corpus is a crowd-sourced collection of 5,000 test and\u2026 www.nyu.edu Every Sunday we do a weekly round-up of NLP news and code drops from researchers around the world. If you enjoyed this article, help us out and share with friends! For complete coverage, follow our Twitter: @Quantum_Stat www.quantumstat.com Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:39:04 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "AI for Good: Fighting COVID-19 with Data Science": {
            "url": "https://towardsai.net/p/machine-learning/ai-for-good-fighting-covid-19-with-data-science",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Tadeusz Bara-Slupski Originally published on Towards AI. This is the first of two articles about our recent participation in the Pandemic Response Hackathon. Stay tuned for technical details of our CoronaRank solution (Markov Chains, R, Shiny, and how to manipulate a dataset of &#62;100GB quickly). The COVID-19 pandemic is putting an unprecedented strain on communities, healthcare systems, and the economy. Much of the effort towards containing the spread of the virus remains with taking individual responsibility for the benefit of the wider community. Various governmental agencies and international organizations are putting policies in place aimed at containing the pandemic and maximizing the efficiency of healthcare service delivery. What can a data science company do to assist these efforts? Our AI for Good initiative aims at bridging the gap between tech expertise and those in need of such support who are at the forefront of the fight for a sustainable future of our planet. Committed to this vision, we set out to contribute our data science skills to a project which could reduce the impact of the COVID-19 pandemic. We recently got this chance during a hackathon centered around finding solutions for the global pandemic. During the hackathon, we developed CoronaRank \u2014 an algorithm that provides users with a personal coronavirus risk score and generates heat maps of risky areas. Pandemic Response Hackathon Devpost is a platform that provides the tech community with an opportunity to contribute to overcoming various global challenges. Their recent Pandemic Response Hackathon asked the participants to develop technologies to solve what appears to be the most significant public health challenge in decades. The hackathon launched on the 27th of March. Over the next three days, more than 2,000 participants got involved and submitted upwards of 230 projects across four tracks: Public Health and Information Sharing Epidemiology &#38; Science of the Disease Keeping our Health Workers Safe Second-Order Societal Impacts 30 different organizations committed resources, including cloud computing from Amazon AWS, visualization tools from Mapbox, datasets from Veraset, and many others. We entered the hackathon in collaboration with Ewa Knitter, an infectious disease epidemiologist who kindly offered to support our efforts. Problems we set out to tackle After initial discussions, we identified several problems particularly compelling in the current outbreak, and we realized that they could be addressed using geolocation data. Specifically: COVID-19 tests are a limited resource, and there\u2019s not an obvious way to decide who should be tested. Since few tests are being done, and partly because many infected people are asymptomatic, it\u2019s challenging to know which people and areas to avoid. Supply chain management in the healthcare sector is going to be extremely difficult moving forward, and policymakers need information on the current potential hotspots where an outbreak might be imminent. Many young, healthy people are ignoring social distancing guidance on the basis that they have a low personal risk. We need a way to illustrate how breaking isolation can affect communities. Our solution To address these problems, we decided to create heatmaps of pandemic hotspots with high human interaction. Such heatmaps would give public officials an idea of the locations for the next potential outbreak and provide the users with information about the risk of noncompliance with public health measures. To achieve this, we took inspiration from Google\u2019s PageRank algorithm, which ranks web pages based partly on their interactions and connections with other popular web pages. We replicated this methodology in epidemiology with Markov Chain modeling. The resulting CoronaRank is an algorithm that uses geolocation data, epidemiology data, self-reporting, and Markov Chain modeling to assess the likelihood of coronavirus exposure. To create and implement CoronaRank, we made use of the Veraset database for New York. Veraset provides anonymized phone geolocation data giving each individual a unique identifier. The challenge was to analyze this large dataset (over 100GB of data per day) in a limited timeframe. However, building on our previous experience with Big Data, we were able to quickly develop the algorithm. We went on to embed it within a web application \u2014 Community Shield \u2014 designed for use on smartphones, which displays pandemic hotspots \u2014 areas with high activity in a recent period, as well as give the user a risk score depending on how many interactions they had in these hotspot areas. Heat map of New York. Darker (red) circles indicate locations with higher risk. An individual\u2019s CoronaRank is the likelihood that they may be infected with COVID-19. Confirmed cases are assigned a CoronaRank of 1. Non-confirmed persons are assigned a CoronaRank of 0&#60;x&#60;1 based on the interactions or possible interactions with others based on geolocation data from the past two weeks obtained from phones. Demo of user input. The more you travel to risky places, the higher your CoronaRank. The more high-rank people visit a place, the riskier it becomes. A high-risk individual (CoronaRank of 0.9) visited several high-risk areas in Manhattan recently. You can test out the demo of the app here. For now, it includes three predefined risk profiles to showcase the app\u2019s capabilities. Our plans for the future We plan to develop the CoronaRank algorithm further by including a self-reporting feature. This way, the user can anonymously provide information about their COVID-related symptoms (if any). This will affect their CoronaRank and, by extension, that of all other people they met in recent weeks. This would be very valuable to public health organizations that do not have the capacity to screen and test each citizen. We also aim to integrate Google Takeout to import personal location data into the app to make it fully user-specific and improve the UI. We hope to partner with governmental and international institutions to get endorsement for the app and deliver it to the public. A long-term collaboration would help to turn the app into a comprehensive tool to educate individuals and drive informed healthcare delivery policy for public institutions. To make this a reality, we need to obtain cloud resources to [&#8230;]",
            "pubdate": "Thu, 20 Jul 2023 09:36:56 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "3 Ways Linear Models Can Lead to Erroneous Conclusions": {
            "url": "https://towardsai.net/p/machine-learning/3-ways-linear-models-can-lead-to-erroneous-conclusions",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): ___ Originally published on Towards AI. In this article, I will share 3 ways in which linear models can lead to erroneous conclusions. The focus will be on fitting linear models to simulated data and checking whether the resultant estimates are consistent with the simulation. This article is based on the content of [1]. The code to reproduce the results described in this article can be found in this notebook. Let Y be the thing we would like to model. Suppose we know that Y is defined by a vector of variables X as Y = \u03b2 X, where \u03b2 is a vector of parameters, one for each variable&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:35:57 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "NLP News Cypher | 04.05.20": {
            "url": "https://towardsai.net/p/machine-learning/nlp-news-cypher-04-05-20",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Ricky Costa Originally published on Towards AI. Photo by Jimmy Conover on Unsplash NATURAL LANGUAGE PROCESSING (NLP) WEEKLY NEWSLETTER NLP News Cypher &#124; 04.05.20 Meditations When Lex isn\u2019t interviewing AI pioneers in a sullen dark suit, he takes to the Twitterverse to question the physics of intercourse in the vacuum of space. I got 1 like for this tweet, it was from HAL 9000. How was your week? \ud83d\ude0e We\u2019ve updated the Big Bad NLP Database. We added 38 new datasets, taking the total past 350! Thank you to Tommaso Pasini, Henry Dashwood, Bill Lin, Reid Pryzant , Parth Parikh and Christian Hardmeier for your contribution! Have a dataset to share? Then, \u201cBreak on through to the other side\u201d (a.k.a. please share the dataset by clicking on the \u201cContact\u201d link on the BBND webpage and sending over the details.) BTW, we have a surprise for you next week. Stay Tuned! \ud83e\uddd0 This Week: Visual Storytelling Wolfman Cometh Matplotlib Ready for Prime Time Decomposition Redux Stanza\u2019s Notebooks ML Inference on the Edge Reinforcing NLP Dataset of the Week: ALFRED Visual Storytelling A new model was released recently discussing the topic of visual storytelling via reinforcement learning! What\u2019s visual storytelling? \u201cgiven a photo stream, the machine is trained to generate a coherent story in natural language to describe the photos.\u201d The model, ReCo-RL, is rewarded on \u201crelevant\u201d storytelling based on 3 NEW criteria: relevance, coherence and expressiveness. What\u2019s cool is that this model achieves excellent performance on traditional and the new criteria. GitHub: JunjieHu/ReCo-RL Implemented by Junjie Hu Contact: junjieh@cs.cmu.edu If you use the codes in this repo, please cite our AAAI2020 paper\u2026 github.com Paper: LINK Wolfman Cometh The T5, that big Google model, that\u2019s both an encoder and decoder can now be accessed via the Transformer library. If you want to take the T5 for a test drive with summarization or translation, check out my Colab notebook below based on \ud83e\udd17\u2019s original notebook. Colab: Google Colaboratory Edit description colab.research.google.com Matplotlib Ready for Prime Time One of my biggest pet peeves with Matplotlib\u2019s graph visualizations was that it looked like it was running on windows 95. But recently, I found this blog that shows how you can impress your data science friends with some impressive visualizations on Matplotlib. Includes code! Matplotlib Cyberpunk Style Let&#039;s make up some numbers, put them in a Pandas dataframe and plot them: import pandas as pd import matplotlib.pyplot\u2026 matplotlib.org Decomposition Redux I had previously discussed this model in a previous newsletter. But this time they have returned with a Github repo! Won\u2019t dive in again, but in essence, this model decomposes multi-hop questions into simpler ones to assist in question answering: GitHub: Unsupervised Question Decomposition for Question Answering We improve automatic question answering (QA) by decomposing hard questions into easier subquestions that existing QA\u2026 medium.com Blog: Unsupervised Question Decomposition for Question Answering We improve automatic question answering (QA) by decomposing hard questions into easier subquestions that existing QA\u2026 medium.com Stanza\u2019s Notebooks You may have heard of Stanford\u2019s Stanza: a new multi-lingual NLP Python library. What you may have not of known, is that they have awesome colabs to get you jump-started. Beginner\u2019s Guide: Google Colaboratory Edit description colab.research.google.com CoreNLP Guide: Google Colaboratory Edit description colab.research.google.com ML Inference on the Edge From the TensorFlow blog: a new delegate release for those dreaming of one day deploying ML models to mobile devices \ud83d\ude01. Today, we are excited to announce a new TensorFlow Lite delegate that uses Apple\u2019s Core ML API to run floating-point models faster on iPhones and iPads with the Neural Engine. We are able to see performance gains up to 14x (see details below) for models like MobileNet and Inception V3. Blog: TensorFlow Lite Core ML delegate enables faster inference on iPhones and iPads April 02, 2020 &#8211; Posted by Tei Jeong and Karim Nosseir, Software Engineers TensorFlow Lite offers options to delegate\u2026 blog.tensorflow.org Reinforcing NLP Want to get up-to-date on Reinforcement Learning in NLP? We found a repo to keep you occupied during your in-home stay. jiyfeng/rl4nlp Reinforcement learning for natural language processing reading group &#8211; jiyfeng/rl4nlp github.com Dataset of the Week: ALFRED What is it? \u201cALFRED dataset contains 8k+ expert demonstrations with 3 or more language annotations each. It\u2019s a benchmark for learning a mapping from natural language instructions and egocentric vision to sequences of actions for household tasks.\u201d Sample: Demo Controls To enable or disable the game&#039;s controls. Look around with your mouse. / Keys to move. Left Click to interact\u2026 ai2thor.allenai.org Where is it? askforalfred/alfred The ALFRED dataset contains 8k+ expert demostrations with 3 or more language annotations each. A trajectory consists of\u2026 github.com Every Sunday we do a weekly round-up of NLP news and code drops from researchers around the world. If you enjoyed this article, help us out and share with friends! For complete coverage, follow our Twitter: @Quantum_Stat www.quantumstat.com Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:35:40 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "RFBNet: Custom Object Detection training with 6 lines of code": {
            "url": "https://towardsai.net/p/machine-learning/rfbnet-custom-object-detection-training-with-6-lines-of-code",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Akula Hemanth Kumar Originally published on Towards AI. Making computer vision easy with Monk, low code Deep Learning tool and a unified wrapper for Computer Vision. In a previous article, we have built a custom object detector using Monk\u2019s RetinaNet. In this article, we will build a Low Altitude Aerial Traffic Surveillance using Monk\u2019s RFBNet, built on top of PyTorch RFBNet. Let\u2019s get started!! Table of Contents Data Collection Convert to COCO format Training model Testing object detector Data Collection In this article, we are using data from Low Altitude Aerial Traffic Surveillance. Download the data zip file $ ! wget --load-cookies /tmp/cookies.txt &#034;https://docs.google.com/uc?export=download&#38;confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate &#039;https://docs.google.com/uc?export=download&#38;id=1pJ3xfKtHiTdysX5G3dxqKTdGESOBYCxJ&#039; -O- &#124; sed -rn &#039;s/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p&#039;)&#38;id=1pJ3xfKtHiTdysX5G3dxqKTdGESOBYCxJ&#034; -O data.zip &#38;&#38; rm -rf /tmp/cookies.txt Download the annotations zip file $ ! wget --load-cookies /tmp/cookies.txt &#034;https://docs.google.com/uc?export=download&#38;confirm=$(wget --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate &#039;https://docs.google.com/uc?export=download&#38;id=1boGF0L6olGe_Nu7rd1R8N7YmQErCb0xA&#039; -O- &#124; sed -rn &#039;s/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p&#039;)&#38;id=1boGF0L6olGe_Nu7rd1R8N7YmQErCb0xA&#034; -O annotations.zip &#38;&#38; rm -rf /tmp/cookies.txt Create a dataset directory and push the unzipped data and annotations to the dataset directory. #Create dataset$ !mkdir dataset# Unzip data$ ! unzip -q data.zip$ ! unzip -q annotations.zip# mov to dataset folder$ !mv images dataset/$ !mv annotations.json dataset/ Convert to COCO format Dataset Directory Structure ./dataset (root_dir) &#124; &#124;---------/ &#124; &#124; &#124; &#124;---images &#124; &#124;----&#124; &#124; &#124;-------------------img1.jpg &#124; &#124;-------------------img2.jpg &#124; &#124;-------------------.........(and so on) &#124; &#124; &#124; &#124;---annotations &#124; &#124;----&#124; &#124; &#124;--------------------annotations.json Here we Convert to COCO format via Monk format Convert from the current format to Monk format 2. Convert from Monk format to COCO format. Desired annotation COCO Format ./ (root_dir) &#124; &#124;------dataset (coco_dir) &#124; &#124; &#124; &#124;---images (set_dir) &#124; &#124;----&#124; &#124; &#124;-------------------img1.jpg &#124; &#124;-------------------img2.jpg &#124; &#124;-------------------.........(and so on) &#124; &#124; &#124; &#124;---annotations &#124; &#124;----&#124; &#124; &#124;--------------------instances_images.json &#124; &#124;--------------------classes.txt instances_Train.json -&#62; In proper COCO format classes.txt -&#62; A list of classes in alphabetical order To get classes.txt run For instances_Images.json run Training model Then run the training code as seen below DONE! The above 6-lines of code is all you need to initiate the training on your custom dataset. Now let\u2019s break down the code to its part: In the first line, we import the \u201cDetector\u201d class from MonkAI. In the 2nd line, we created an instance of the class. In the 3rd line, we set the path to our custom dataset. We specified the following parameters: \u2014 batch_size: This is the batch size for the training. \u2014 image_size: Choose the image size \u2014 num_workers: Number of workers used in data loading In the 4th line, we specified the following parameters: \u2014 model_name: Choose a base model from \u201cvgg\u201d, \u201ce_vgg\u201d, \u201cmobilenet\u201d \u2014 use_gpu: Whether to use GPU or not \u2014 ngpu: Number of GPU\u2019s to be used In the 5th line, we set the hyperparameters. we specified the following parameters: \u2014 lr: initial learning rate \u2014 momentum: momentum for SGD \u2014 weight_decay: Weight decay for SGD \u2014 gamma: Gamma update for SGD In the 6th line, we specify the training parameter, we specified the following parameters: \u2014 epochs: Number of epochs for training \u2014 log_iters: Print the loss at each iteration \u2014 output_weights_dir: Directory to store weights Testing object detector we have trained the custom model to detect Low Altitude Aerial Traffic Surveillance. We will use the saved weights file to detect the object in an image. Some image inferences, you can see: Inference 1 Inference 2 Inference 3 Inference 4 You can find the complete code on Github. Give us \u2b50\ufe0f on our GitHub repo if you like Monk. In this experiment, we created a custom object detection using RFBNet with just basic programming skills without even knowing the architecture and PyTorch framework. For more examples of custom object detection, checkout Tessellate-Imaging/Monk_Object_Detection You can&#039;t perform that action at this time. You signed in with another tab or window. You signed out in another tab or\u2026 github.com If you have any questions, you can reach Abhishek and Akash. Feel free to reach out to them. I am extremely passionate about computer vision and deep learning. I am an open-source contributor to Monk Libraries. You can also see my other writings at: Akula Hemanth Kumar &#8211; Medium Read writing from Akula Hemanth Kumar on Medium. Computer vision enthusiast &#124; Linkedin\u2026 medium.com Photo by Robert Bye on Unsplash Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 20 Jul 2023 09:35:24 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "GANsformers: Generate complex scenes using GANs and Transformers": {
            "url": "https://towardsai.net/p/machine-learning/gansformers-generate-complex-scenes-using-gans-and-transformers",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI. They basically leverage transformers\u2019 attention mechanism in the powerful StyleGAN2 architecture to make it even more powerful! Results examples on generating bedroom scenes with its attention maps. Image from: Drew A. Hudson and C. Lawrence Zitnick, Generative Adversarial Transformers, (2021). Last week we looked at DALL-E, OpenAI\u2019s most recent paper.It uses a similar architecture as GPT-3 involving transformers to generate an image from text. This is a super interesting and complex task called text-to-image translation. As you can see in the video below, the results were surprisingly good compared to previous state-of-the-art techniques. This is mainly due to the use of transformers and a large amount of data. This week we will look at a very similar task called&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 21 Jul 2023 02:27:19 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "The NLP Cypher | 03.07.21": {
            "url": "https://towardsai.net/p/machine-learning/the-nlp-cypher-03-07-21",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Ricky Costa Originally published on Towards AI. The Lookout \u2014 \u201cAll\u2019s Well\u201d &#124; Homer NATURAL LANGUAGE PROCESSING (NLP) WEEKLY NEWSLETTER The NLP Cypher &#124; 03.07.21 The Crow\u2019s Nest Hey Welcome back! Had a loooong weekend of busy busy, so this week\u2019s NL will be less wordy than usual, but we\u2019ll be back to normalcy next week. Oh and by the way, Maybe\u2026 the universe is just a giant neural network\u2026 \ud83e\udd37\u200d\u2642\ufe0f At least that\u2019s the new theory out of MIT. FYI, it sounds eerily similar to Stephen Wolfram\u2019s graph approach to physics. The only question I have is, who\u2019s running the compute? \ud83e\udd37\u200d\u2642\ufe0f The Universe Might Be One Big Neural Network, Study Finds One scientist says the universe is a giant neural net. The wild concept uses neural net theory to unify quantum and\u2026 www.popularmechanics.com FYI, we added 25 new notebooks to the Super Duper NLP Repo!! \ud83d\udc47 OpenChat OpenChat is an awesome repo where one can interact with top tier dialogue models with just 1 line of code. Currently, it supports: Microsoft\u2019s DialoGPT : small, medium, large. Facebook\u2019s BlenderBot : small, medium, large, xlarge. hyunwoongko/openchat OpenChat is opensource chatting framework for generative models. You can talk with AI with only one line of code\u2026 github.com AI Index 2021 The yearly and comprehensive report on AI is out. The scope of the report is focused more on a global and strategic scale. For NLP focused content, start on page 62. The report is +200 pages long \ud83d\ude48. AI Index 2021 The 2021 AI Index report is one of the most comprehensive reports about artificial intelligence to date. This latest\u2026 hai.stanford.edu OpenAI\u2019s Reflection on its Latest Multi-Modal Models They go in deep on CLIP\u2019s neurons and their representations. They also analyze where they can go wrong. Multimodal Neurons in Artificial Neural Networks We&#039;ve discovered neurons in CLIP that respond to the same concept whether presented literally, symbolically, or\u2026 openai.com Mastering Python &#124; The OverFlow Last week I had part II of this series, here\u2019s III and IV now. Level Up: Mastering statistics with Python &#8211; part 3 &#8211; Stack Overflow Blog Welcome back! This is the third class in our Level Up series on statistics with Python. If you&#039;re just tuning in, you\u2026 stackoverflow.blog Level Up: Mastering statistics with Python \u2014 part 4 \u2014 Stack Overflow Blog code-for-a-living March 2, 2021 While many introductory statistics classes teach the CLT, very few actually attempt to\u2026 stackoverflow.blog YAMNet &#124; Transfer Learning for Audio YAMNet (\u201cYet another Audio Mobilenet Network\u201d) is a pretrained model that predicts 521 audio events based on the AudioSet corpus. Transfer Learning for Audio Data with YAMNet March 02, 2021 &#8211; Posted by Luiz GUStavo Martins, Developer Advocate Transfer learning is a popular machine learning\u2026 blog.tensorflow.org Several Methods for Updating Neural Networks Here are the methods discussed: Update Model on New Data Only Update Model on Old and New Data Ensemble Model With Model on New Data Only Ensemble Model With Model on Old and New Data How to Update Neural Network Models With More Data &#8211; Machine Learning Mastery Deep learning neural network models used for predictive modeling may need to be updated. machinelearningmastery.com Top Data Labeling Software In-depth analysis of 10 data labeling tools for machine learning datasets. Data Labeling Software: Best Tools for Data Labeling in 2021 &#8211; neptune.ai In machine learning and AI development, the aspects of data labeling are essential. You need a structured set of\u2026 neptune.ai Repo Cypher \ud83d\udc68\u200d\ud83d\udcbb A collection of recently released repos that caught our \ud83d\udc41 Gradual Finetune If you are just fine-tuning your model once, you may be missing out. paper fe1ixxu/Gradual-Finetune Gradually fine-tuning in a multi-step process can yield substantial further gains and can be applied without modifying\u2026 github.com Connected Papers \ud83d\udcc8 Forte &#124; NLP Pipeline Toolkit A multi-purpose platform for searching documents, information extraction and language generation. asyml/forte Forte is a toolkit for building Natural Language Processing pipelines, featuring cross-task interaction, adaptable\u2026 github.com Connected Papers \ud83d\udcc8 Meta-Curriculum Learning for Machine Translation Improving the meta-learning (teacher model) of MT for low-resource languages NLP2CT/Meta-Curriculum Meta-Curriculum Learning for Domain Adaptation in Neural Machine Translation (AAAI 2021) Please cite as\u2026 github.com Connected Papers \ud83d\udcc8 ANEA Automatically annotates named entities uds-lsv/anea ANEA is a tool to automatically annotate named entities in unlabeled text based on entity lists for the use as distant\u2026 github.com Connected Papers \ud83d\udcc8 RuSentEval Evaluation toolkit for Russian sentence embeddings. vmkhlv/rusenteval RuSentEval is an evaluation toolkit for sentence embeddings for Russian. In this repo you can find the data and scripts\u2026 github.com Connected Papers \ud83d\udcc8 Learning Chess Blindfolded Training language models on chess notation. \ud83d\udd25\ud83d\udd25 shtoshni92/learning-chess-blindfolded Chess as a testbed for evaluating language models on world state tracking. Pretrained model released via Huggingface\u2026 github.com Connected Papers \ud83d\udcc8 RAGA Using Graph attention for the entity alignment task. zhurboo/RAGA Relation-aware Graph Attention Networks for Global Entity Alignment &#8211; zhurboo/RAGA github.com Connected Papers \ud83d\udcc8 Dataset of the Week: Wikipedia-based Image Text (WIT) Dataset What is it? A multimodal multilingual dataset. WIT is composed of a curated set of 37.6 million entity rich image-text examples with 11.5 million unique images across 108 Wikipedia languages. Example Where is it? google-research-datasets/wit Wikipedia-based Image Text (WIT) Dataset is a large multimodal multilingual dataset. WIT is composed of a curated set\u2026 github.com Every Sunday we do a weekly round-up of NLP news and code drops from researchers around the world. For complete coverage, follow our Twitter: @Quantum_Stat Quantum Stat Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 21 Jul 2023 02:23:19 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "1Cycle Learning Rate Scheduling with TensorFlow and Keras": {
            "url": "https://towardsai.net/p/machine-learning/1cycle-learning-rate-scheduling-with-tensorflow-and-keras",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Jonathan Quijas Originally published on Towards AI. Machine Learning Engineering A Practical Methodology to Set the Most Important Hyperparameter in Deep Learning Photo by David Everett Strickler on Unsplash Problem Statement Training a Deep Neural Network can be a challenging task. The large number of parameters to fit can make these models especially prone to overfitting. Training times in the range of days or weeks can be common, depending on the model complexity, available compute resources, and task to learn. If the available resources are limited, avoiding extra computations and long training times is a high priority. I will present a technique you can follow to ensure you initialize and adapt your learning rate correctly. This will help achieve strong task performance and avoid longer than necessary training times. Introduction The learning rate is the value that controls the magnitude of the weight updates applied during training. Having a good learning rate can be the difference between a poor and an excellent model. In the sections below, I will cover some background material on Gradient-Based Optimization to gain a better understanding of just how important this hyperparameter is. I will then present a method to initialize and adapt your Neural Network\u2019s learning rate during training, followed by experimental results and conclusions. Background: Cost Functions, Derivatives, and Gradients Loss and Cost Functions The Square Error loss function. This is the squared difference between the prediction and the actual value. Training a Neural Network means finding the set of weights that optimize some function. In practice, this usually means minimizing the discrepancy, or error, between the predictions and the true values. This error is computed using a loss function. An example of a loss function is the Square Error loss function. Definition of the Mean Square Error cost function. Source: https://www.freecodecamp.org/news/machine-learning-mean-squared-error-regression-line-c7dde9a26b93/ A cost function measures the prediction errors over the entire training set. For example, the Mean Square Error cost function is the mean squared errors between our predictions and the true values, averaged across the entire training set. Derivatives and Gradients Visualization of a function\u2019s sliding derivative. Source: http://www.calcblog.com/calculating-derivatives-on-ti83-ti84-ti89-ti92-voyage-200/ The derivative f\u2032 of a univariate function f tells us the instantaneous rate of change at a given point x; it provides a measurement of how much f increases or decreases. A gradient is the generalization of the derivative to multi-variate functions; it is a vector of the function\u2019s partial derivatives. A partial derivative of a function is the derivative (instantaneous rate of change) with respect to only one of its variables, and considering the others as constants. The gradient of a function is the vector of all of the functions partial derivatives. The gradient of a scalar function denotes the direction of greatest change. Gradient of the Mean Square Error cost function. It is the vector of all partial derivatives. Gradient Descent is a powerful and generic optimization algorithm. It works by iteratively tweaking a model\u2019s parameters in the cost function\u2019s direction of greatest change (the gradient). Because we are interested in minimizing the cost function, we apply the update in the opposite direction of the gradient (in other words, the negative gradient). Update step performed by Gradient Descend. The model parameters are updated in the direction of the negative gradient. NOTE: Because it works using only gradient (first derivative) information, Gradient Descend is called a first-order optimization method. Other methods use Hessian (second derivative) information and may converge much faster (for example, Newton\u2019s method). Computing the Hessian is extremely costly, however. This prevents their use with large models such as Deep Neural Networks. Learning Rate Effects Gradient Descent applies the learning rate as a scaling term to the negative gradient. It controls the magnitude of the weight updates. The figure below visualizes the training loss of models trained on the CIFAR10 dataset using different learning rates. The learning rate directly influences convergence (or divergence) of the model during training. A good learning rate is crucial for reaching a good solution in a reasonable amount of time. Using a very large learning rate can result in large loss values. Although the loss will decrease, it will remain significantly higher than the loss obtained using a smaller, more adequate learning rate. For more extreme cases, large learning rates can lead to divergence, wildly shooting around and never settling to a stable configuration. Conversely, if the learning rate is too small, training can be extremely slow. The learning rate is commonly denoted with the Greek letter \u03b7 (eta) in the Deep Learning literature. Learning Rate Initialization and Scheduling As we saw in the previous section, the choice of learning rate can drastically impact the quality of the solution reached. In the sections below, I will present a simple and effective learning rate initialization technique. I will then present a learning rate schedule, used to dynamically modify the learning rate during training and achieve even faster convergence. NOTE: The code used was adapted from Chapter 11 of \u201cHands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\u201d. You can find the original notebook here. Exponential Increments The first technique is to train your model for a few hundred iterations, beginning with a very small learning rate (for example, 1e-6), and gradually incrementing it exponentially, up to a large value (for example, 10). The optimal learning rate would be approximately 10 times less than the point before the loss starts to shoot up. A Keras implementation of the exponential increase technique can be found below. Keras implementation of Exponential Learning Rate technique by extending the Callback class. The learning rate found using the approach described above will be used as a threshold for a more effective technique used to dynamically modify the learning rate during training. 1cycle Scheduling Instead of using a constant learning rate, we can dynamically modify the learning rate during training. When used appropriately, this technique leads to good solutions and faster convergence. A schedule is a strategy used to modify the learning [&#8230;]",
            "pubdate": "Fri, 21 Jul 2023 02:17:26 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Docker + Flask | Dockerizing a Python API": {
            "url": "https://towardsai.net/p/machine-learning/docker-flask-dockerizing-a-python-api-2",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Billy Bonaros Originally published on Towards AI. Docker containers are one of the hottest trends in software development right now. Not only it makes it easier to create, deploy and run applications but by using containers you are confident that your application will run on any machine regardless of anything that may differ from yours that you created and tested the code. In this tutorial, we will show you how you can dockerize easily a Flask API. We will use this Python Rest API Example. It\u2019s a simple API that given an image URL it returns the dominant colors of the image. We highly recommend creating a new python&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 21 Jul 2023 02:15:18 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Lets Win at 7 With RL!": {
            "url": "https://towardsai.net/p/machine-learning/lets-win-at-7%c2%bd-with-rl",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Alberto Prospero Originally published on Towards AI. Machine Learning How reinforcement learning can be applied to find optimal strategies at 7\u00bd (a game really similar to Blackjack!) Photo by Marin Tulard on Unsplash Introduction \u201cWinner, Winner, Chicken Dinner!\u201d.In the movie 21, Ben Campbell and his team counted cards to win at blackjack, one of the most interesting and studied casino games, proving that mathematics and statistics indeed can be used to boost the common strategies used in these games. Since then, the scientific community has made enormous strides in conceiving methodologies and improving existing techniques, managing to reach top-level performances in several circumstances. Several of the most recent achievements have been possible using reinforcement learning and game theory techniques, which remarkably outperformed previous approaches. In this tutorial, you will see how reinforcement learning can be applied to identify the best strategies in playing 7\u00bd, an Italian game quite similar to blackjack. Throughout the tutorial, I will assume you are familiar with reinforcement learning. If this is not the case, take a look at my previous post, which gently introduces RL-based concepts from the ground up. Also, the tutorial will be based on the code you can find on my GitHub repository. Disclaimer: the content expressed in this article comes from my personal research and experience and does not have to be intended as financial, investment or gambling advice. The content is for informational purposes only and is intended as educational material. So! Can we consistently win at 7\u00bd with reinforcement learning? Read on to find it out! The rules The game is played with a 40-card deck, a standard deck with eights, nines, and tens removed. The value of cards ace through seven is their pip value (1 through 7), face cards are worth 0.5 points each. One special card (the 7 of diamonds) is called \u201cmad\u201d. Its value can range from 0.5 to 7 and corresponds to the highest possible which makes the total sum of the player cards closest to 7\u00bd. So for example, if the player holds 1,2 the mad worth is 4, while if he holds a fig it is worth 7. There are different variations of the game. In the repository is supported the following two-player version: At the beginning of the game, player0 and player1 receive one faced-up card. Then, player0 decides either to draw a card from the deck or to stick to the current card: if he sticks his turn is ended, if he hits he receives a faced down card from the deck, and this step repeats. The player may stick or hit as long as he does not go bust (exceed 7\u00bd) In this case, he immediately loses the game. When the player0 sticks, player1 starts his turn and carries out the same process by repeatedly hitting a new card or sticking to his current set of cards. Again, if his card sum exceeds 7\u00bd, he immediately loses the game. Finally, if both players stuck without being bust, the sum of their card values is compared and the player with the highest score wins the game. The strategy First of all, we need to define what is an optimal strategy: it means identify a sequence of moves that consistently lead the player (assume player0) to win the game. Note that if we want to apply reinforcement learning to find out this strategy, we first need to fix the opponent\u2019s policy. Recall that RL assumes a unique agent interacting with an environment. So, in our case, player0 will be the agent and all the rest (including player1) will be the environment. In our case, we fix the following policy for the opponent: as soon as he scores 4 or more, he sticks. Otherwise, he hits. The next step is to identify what are, from the player\u2019s perspective, the states of the game, the actions of the player, and the rewards provided from the environment to the player. We can define a single state as the set of cards owned by the player at the current time. At the beginning of the game, the player will be in the state formed by no cards. Then, if for example, the player draws a 6, his current state is formed by this card. If the player owns [3,4, face] the state will be formed exactly by these cards. There is also a special state, which is the terminal state. The player reaches this state when it chooses to stick with the current cards or it went bust. The actions the agent can take are easy to identify: at each state (except the terminal one) player0 can either hit, drawing a new card, or stick to his current set of cards. The most difficult part is related to modeling the rewards. We need to specify the rewards the player will receive with respect to each action it takes at every state. Also, we need to recall that the aim of giving rewards is not to indicate the agent how it should achieve its goals (this is the task of the reinforcement learning indeed!), but rather what goals we want it to achieve. With this in mind we do the following: If the player hits, we always provide a reward of 0, except when the player goes bust. In this case, the reward is -1 If the player sticks, we generate the combinations of cards that the opponent can reach without losing the game. So, if the opponent draws 2 as first card, some of these combinations will be [2,1,face,face], [2,1,4], [2,1,face,2], [2,2] and so on. Note that the combination [1,4,1] will not be considered because is not consistent with the initial opponent\u2019s card. Also, [2,1,2,3] will not be generated, because this would cause the opponent to lose the game. Finally, neither the combination [2,2,1] will be generated, because the opponent\u2019s policy prescribes to stop as soon as the score of 4 is reached. Now, [&#8230;]",
            "pubdate": "Fri, 21 Jul 2023 02:13:57 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Install the Fastai Course Requirements on Linux": {
            "url": "https://towardsai.net/p/machine-learning/install-the-fastai-course-requirements-on-linux",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): David Littlefield Originally published on Towards AI. Deep Learning for Coders: Image by Anton Maksimov juvnsky This article is an expanded guide that\u2019s meant to help you learn what\u2019s happening throughout the chapter. It provides definitions of terms, commands, and code that are used in the article. It also includes underlined text which has links to additional definitions in the glossary of the article. GNOME Terminal is the default terminal emulator that\u2019s used on Ubuntu desktop environment. It can run commands, work with files, interact with other computers, and perform administrative tasks and configurations. It also features multiple tabs, user profiles, and custom startup commands. Click \u201cActivities\u201d in the top-left cornerEnter \u201cTerminal\u201d into the&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 21 Jul 2023 02:13:47 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Ultralearning Product Data Science": {
            "url": "https://towardsai.net/p/machine-learning/ultralearning-product-data-science",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Harsh Darji Originally published on Towards AI. Data Science The minimal effort maximum outcome way Happiness is not pleasure. Happiness is the expansion of possibilities \u2014 Scott Young I often wonder what is one thing I am most passionate about, I am aware I like fitness, sports, e-commerce, and advertising space but I cannot come up with one answer. Is it because I know I am not good at it or am I scared to actually make a career out of it? I thought completing grad school and finding a job will help me to find my passion, it has definitely made me happy but I am far from finding my passion. I tried digging into the work of some of the people I admire to find an answer and I came across Cal Newport\u2019s book \u201cSo good that they cannot ignore you\u201d and my mind was literally blown. I was trying to find my passion and within the first 10 pages, Cal said Passion is overrated and the key to be good at anything is to force yourself through the work, force the skills to come and that\u2019s the hardest phase. I feel like your problem is that you\u2019re trying to judge all things in the abstract before you do them \u2014 Cal Newport After understanding the passion hypothesis and pairing it with the learnings from Scott Young\u2019s book \u201cUltralearning\u201d where he emphasizes we can learn anything irrespective of our background, I have decided to work on building my career capital which is to develop skills in product data science. This is the Ultralearning Product Data Science program that I have prepared for myself to follow for the next 100 days (01/03/21\u201308/06/21) Check out my notes of Ultralearning and So good that they cannot ignore you to comprehend. Source: Unsplash Why Product Data Science? I have a Master\u2019s degree in Applied Data Science and I am quite good with algorithms, coding, and statistics and instead of building my career capital in an entirely new industry (Finance/Marketing/Arts), I have decided to leverage my strength and upskill! I know data scientists get paid well that is another important factor I took into consideration and I would be lying if I say money is not important to me. Here are other reasons why I want to develop my career capital in product data science: 70% of jobs in Data Science are related to Product Data Science Less coding more analytical work. I am good with stats and decision-making! I am curious and I tend to ask a lot of questions so I believe I can think of questions that the rest of the company has not thought of Love to research about international markets, growth strategy, consumer behavior Easy transition to Product Management What skills I will be developing? I read everything that I could find about product data science over the internet and also reached out to a couple of data scientists in my network to learn more about product data science, skills needed, projects I should be working on, interview structure, and the resources I should be using. The product data scientists work closely with product leaders to run experiments and test out different product features. Some of the problems that they work on are: Logging and Instrumentation \u2014 Identifying Data Gaps. Establish good relationships with engineers Push Notification Analysis \u2014 How many users are eligible for push notifications? across user segment? across clients? What are the tap rates of different push notification types? SMS Delivery Rates \u2014 How do we calculate Twitter\u2019s SMS delivery rates across different carriers? Are our delivery rates in emerging countries poorer? How can we make them better? Multiple Accounts \u2014 Why do certain countries have a higher ratio of multiple accounts? What drive people to create multiple accounts? There are plenty of resources available online and I have carefully selected some of them based on my style of learning. Following are the skills I will be developing and resources I will be using for the next 100 days. Product Sense Stellar Peers Cracking the PM Interview by Gayle Laakmann McDowell and Jackie Bavaro Decode and Conquer by Lewis C. Lin SQL Leetcode database problems HackRank SQL problems Interview Query SQL problems Statistics Online Stat Book Practical Stats for DS Experimentation Udacity course EXP Platform KDD Papers Ron Kohavi\u2019s book \u2014 Trustworthy Online Controlled Experiments Company Tech blogs \u2014 Airbnb, Uber, Facebook. I am fairly good with coding in python and basic machine learning so I am not scheduling a separate time to learn algorithms and solving a take-home challenge will help to brush up on these skills. If you want to check out all the resources I collected to learn more about product data science, check out my notes How I will be building these skills? Instead of developing each skill individually or working on a full-stack project, I have decided to do Interview based learning. I am using the directness approach which Scott mentions in his book. The principle of directness asserts that it\u2019s actually while doing the thing you want to get good at when much of learning takes place. So, I want to get good at interviews and I believe directly solving the interview questions will help me to do so. There are plenty of interview questions available over the internet, but here are some of the resources I will be using \u2014 InterviewQuery and Glassdoor. I have also found opportunities within my company to develop my analytical skills (SQL, data viz, business case, scripting). My company is an e-commerce company so there are a lot of opportunities to build product skills. My goal is to be a part of at least one experiment so that I can understand the nuances of A/B testing and experimental design. When we learn new things, we should always strive to tie them directly to the contexts we want to use them in. Writing [&#8230;]",
            "pubdate": "Fri, 21 Jul 2023 02:09:36 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Winning The Lottery Using Data Analytics": {
            "url": "https://towardsai.net/p/machine-learning/winning-the-lottery-using-data-analytics",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): John Bica Originally published on Towards AI. A data-focused strategy you can use to pick numbers in the Yotta lottery Image created by Author with GIFMaker Lotteries are supposed to be based on probability and randomness. You can pick your lucky numbers but they don\u2019t really matter. Your chances of winning should be the same as if you had let a monkey pick them for you. It is more of a psychological phenomenon so that when you do randomly win, you can accredit it to your \u201clucky\u201d numbers and thus seal your confirmation bias. But what if there\u2019s a way to still pick those lucky numbers that may be better than random selection? Not based on specific feelings or your birth date,&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 21 Jul 2023 02:08:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "The NLP Cypher | 03.14.21": {
            "url": "https://towardsai.net/p/machine-learning/the-nlp-cypher-03-14-21",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Ricky Costa Originally published on Towards AI. St. Jerome in his Study &#124; Durer NATURAL LANGUAGE PROCESSING (NLP) WEEKLY NEWSLETTER The NLP Cypher &#124; 03.14.21 Set the Controls for the \u2665 of the Sun NERD OVERLOAD Happy Pi Day! Let\u2019s talk about \u201cCryptonite: How I Stopped Worrying and Learned(?) to Love Ambiguity\u201d Cryptonite is a cryptic clue, a short phrase or sentence with a misleading surface reading, whose solving requires disambiguating semantic, syntactic, and phonetic wordplays, as well as world knowledge. example: And luckily, It\u2019s also a dataset\u2026 And it\u2019s an important dataset to consider the ambiguity of language. Solving the ambiguity problem, whether its derived strictly from NLP only or from a combination of multi-modal models, or from graphs, will be key in order for models to achieve what Thomas Paine called \u201cCommon Sense\u201d. Why? Because it requires models to have n-order logic. You can think of n-order logic as the Russian doll of logic, which is, logic nested within logic. And it\u2019s what we use when we do battle with a New York Times crossword puzzle, which requires different uses of word play, world knowledge and other linguistic artifacts. This is a very tough problem for current transformers to solve for. In fact, the authors of the paper said that a T5-Large trained on the Cryptonite dataset achieved only 7.6% accuracy \ud83d\udc40, which is on par with rule-based accuracy \ud83d\ude48 . Translation: Transformers suck at this task. This type of \u2018reasoning\u2019 is what lies at the highest level of abstraction of the human brain. Intuition tells me that n-order-logic will require hypergraphs, but the future is unwritten\u2026 Paper aviaefrat/cryptonite Current NLP datasets targeting ambiguity can be solved by a native speaker with relative ease. We present Cryptonite, a\u2026 github.com Hub Datasets Hub, the data storage application from Activeloop.AI is riding the dataset gravy train. Their framework stores datasets in the cloud as numpy arrays so you can access it seamlessly across several frameworks. Here are the features: Store and retrieve large datasets with version-control Collaborate as in Google Docs: Multiple data scientists working on the same data in sync with no interruptions Access from multiple machines simultaneously Deploy anywhere \u2014 locally, on Google Cloud, S3, Azure as well as Activeloop Integrate with your ML tools like Numpy, Dask, Ray, PyTorch, or TensorFlow Create arrays as big as you want. You can store images as big as 100k by 100k! Keep shape of each sample dynamic. This way you can store small and big arrays as 1 array. Visualize any slice of the data in a matter of seconds without redundant manipulations activeloopai/Hub Note: the translations of this document may not be up-to-date. For the latest version, please check the README in\u2026 github.com PyTorch Lightning Update \ud83d\udd25 A new update is out! PyTorch is going in heavy on multiple methods for distributed training and model compression, here are some the features in BETA: DeepSpeed Pruning Quantization They are also integrating PyTorch Geometric! GNNs!!! (hype) PyTorch Lightning V1.2.0- DeepSpeed, Pruning, Quantization, SWA Including new integrations with DeepSpeed, PyTorch profiler, Pruning, Quantization, SWA, PyTorch Geometric and more. medium.com Talking about PyTorch\u2026 Basic Tutorials An awesome introduction to PyTorch showing an end-to-end ML pipeline from loading your data all the way to saving a trained model, includes a Colab notebook: Learn the Basics &#8211; PyTorch Tutorials 1.8.0 documentation Learn the Basics &#124;&#124; Quickstart &#124;&#124; Tensors &#124;&#124; Datasets &#38; DataLoaders &#124;&#124; Transforms &#124;&#124; Build Model &#124;&#124; Autograd &#124;&#124;\u2026 pytorch.org Ok Ok, Last Mention of PyTorch\u2026 Promise Here\u2019s a handy deep learning project template using PyTorch Lightning, Hydra, and Tensorboard. Ok I\u2019m done. \ud83d\ude0e lkhphuc/lightning-hydra-template Use this template to rapidly bootstrap a DL project: Write code in Pytorch Lightning&#039;s LightningModule and\u2026 github.com Transformers as Universal Computation Engines Important paper to read if you are interested on how pretrained language models can be used to transfer its knowledge to other domains outside of NLP (i.e. vision, computing numbers etc.). Authors suggest that these models, that have kept their self-attention/feed forward layers frozen (without fine-tuning) can actually match the performance of a fully trained model trained on the downstream task. Code: kzl/universal-computation Official codebase for Pretrained Transformers as Universal Computation Engines. Contains demo notebook and scripts to\u2026 github.com Paper: Pretrained Transformers as Universal Computation Engines We investigate the capability of a transformer pretrained on natural language to generalize to other modalities with\u2026 arxiv.org LineFlow: Dataset Loader LineFlow is a framework agnostic dataset loader for NLP. Tasks it supports: Commonsense Reasoning Language Modeling Machine Translation Paraphrase Question Answering Sentiment Analysis Sequence Tagging Text Summarization tofunlp/lineflow LineFlow is a simple text dataset loader for NLP deep learning tasks. LineFlow was designed to use in all deep learning\u2026 github.com Repo Cypher \ud83d\udc68\u200d\ud83d\udcbb A collection of recently released repos that caught our \ud83d\udc41 Information Extraction (in Julia) Combining deep learning and context free grammars for information extraction deepcpcfg/datasets This repository contains supplementary materials for DeepCPCFG: Deep Learning and Context Free Grammars for End-to-End\u2026 github.com Connected Papers \ud83d\udcc8 TypeShift (in R) A UI that helps visualize how peeps type language on a keyboard. For example, was it fast or slow, differences across languages etc. angoodkind/TypeShift The task of &#034;visualizing language production&#034; is both broad and difficult to execute conclusively. Common\u2026 github.com Connected Papers \ud83d\udcc8 MATH Dataset A new dataset of 12,500 challenging competition math word problems. FYI, not the same as DeepMind\u2019s Math dataset. hendrycks/math This is the repository for Measuring Mathematical Problem Solving With the MATH Dataset by Dan Hendrycks, Collin Burns\u2026 github.com Connected Papers \ud83d\udcc8 Byte2Speech Framework adopts the multi-lingual and multi-speaker transformer TTS framework in Yang &#38; He (2020), and extends it to byte inputs. mutiann/byte2speech This is an implementation of the paper, based on the open-source Transformer-TTS. Audio samples of the paper is\u2026 github.com Connected Papers \ud83d\udcc8 Rissanen Data Analysis Rissanen Data Analysis (RDA) is a method to determine what capabilities are helpful to solve a dataset. ethanjperez/rda Rissanen Data Analysis (RDA) is a method to [&#8230;]",
            "pubdate": "Fri, 21 Jul 2023 02:07:02 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Helping Bloom E-Commerce Business Using Linear Regression  Python": {
            "url": "https://towardsai.net/p/machine-learning/helping-bloom-e-commerce-business-using-linear-regression-python",
            "description": "Last Updated on July 20, 2023 by Editorial Team Author(s): Jayashree domala Originally published on Towards AI. Data Science A guide to understanding and implementing linear regression. Source: Author What is the history of linear regression? In the 1800s, a person named Francis Galton was studying the relationship between parents and children by looking into the correlation between the heights of the fathers and their sons. He identified that a father\u2019s son is likely to be as tall as his father. But the main discovery was that the son&#039;s height is likely to be close to the overall average height of all people. So for example, if there is a father of height 7 feet then there are chances that his son will be pretty fall too. But since being 7 feet is very rare and is an anomaly there is a chance that the son will not be as tall. This is called regression wherein a son\u2019s height tends to go towards (regress) the average height. What is the goal of linear regression? The goal is to determine the best line which minimizes the vertical distance between all the data points and the line. How to implement linear regression using Python? The dataset used to perform linear regression is an Ecommerce dataset of a clothing store company. The goal is to help the company decide if they should concentrate on their mobile app service or website based on the yearly amount spent by the customers to grow the business. \u2192 Import packages The basic packages are imported like NumPy and pandas to deal with the data. For data visualization, matplotlib and seaborn are imported. &#62;&#62;&#62; import pandas as pd&#62;&#62;&#62; import numpy as np&#62;&#62;&#62; import matplotlib.pyplot as plt&#62;&#62;&#62; import seaborn as sns&#62;&#62;&#62; %matplotlib inline \u2192 Data The data has the following columns: 1) Customer info \u2014 Email 2) Customer info \u2014 Address 3) Customer info \u2014 color Avatar 4) Avg. Session Length: Average session of in-store style advice sessions 5) Time on App: Average time spent on App in minutes 6) Time on Website: Average time spent on Website in minutes 7) Length of Membership: How many years the customer has been a member. &#62;&#62;&#62; df = pd.read_csv(&#039;dataset.csv&#039;)&#62;&#62;&#62; df.head() Source: Author By using the \u201cinfo()\u201d function, the information of the columns and entries are known. The datatype of the columns are also known from this. &#62;&#62;&#62; df.info()&#60;class &#039;pandas.core.frame.DataFrame&#039;&#62;RangeIndex: 500 entries, 0 to 499Data columns (total 8 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Email 500 non-null object 1 Address 500 non-null object 2 Avatar 500 non-null object 3 Avg. Session Length 500 non-null float64 4 Time on App 500 non-null float64 5 Time on Website 500 non-null float64 6 Length of Membership 500 non-null float64 7 Yearly Amount Spent 500 non-null float64dtypes: float64(5), object(3)memory usage: 31.4+ KB By using the describe() function, we can get the statistical information of numerical columns. &#62;&#62;&#62; df.describe() Source: Author \u2192 Data visualization Using the seaborn package, a pairplot can be plotted for the entire dataframe which takes into consideration only the numerical columns. It creates histograms of all columns along with the correlation scatter plots. &#62;&#62;&#62; sns.set_style(&#039;whitegrid&#039;)&#62;&#62;&#62; sns.pairplot(df) Source: Author Based on the above plot, it can be said that there is a linear relationship between the \u2018length of membership\u2019 and \u2018yearly amount spent\u2019. Using the seaborn package a distribution plot can also be created for the target column we are predicting which in this case is \u2018yearly amount spent\u2019. The distribution of vlues can be seen using this plot. &#62;&#62;&#62; sns.distplot(df[&#039;Yearly Amount Spent&#039;]) Source: Author Based on the plot, it can be ascertained that the average lies somewhere near 500. Next, a correlation plot can be generated which shows the correlation between the columns. 1 denotes a very high correlation and 0 denotes no correlation. &#62;&#62;&#62; sns.heatmap(df.corr(),annot=True) Source: Author \u2192 Separating the predictor and the target variable Here the target variable is \u2018Yearly amount spent\u2019. The predictor variables are the rest of the numerical columns since the linear regression model does not work on categorical columns. &#62;&#62;&#62; x = df[[&#039;Avg. Session Length&#039;, &#039;Time on App&#039;,&#039;Time on Website&#039;, &#039;Length of Membership&#039;]]&#62;&#62;&#62; x.head() Source: Author &#62;&#62;&#62; y = df[&#039;Yearly Amount Spent&#039;]&#62;&#62;&#62; y.head()0 587.9510541 392.2049332 487.5475053 581.8523444 599.406092Name: Yearly Amount Spent, dtype: float64 \u2192 Splitting into training and testing data The scikit learn package helps in the splitting of data into train and test data. It is the most useful library for machine learning in Python. The sklearn library contains a lot of efficient tools for machine learning and statistical modeling. The splitting function is imported from sklearn. The \u2018x\u2019 and \u2018y\u2019 data is passed to the function which generates the split training and testing data. The test size determines how much proportion of data should be in the test. The value is between 0 to 1. &#62;&#62;&#62; from sklearn.model_selection import train_test_split&#62;&#62;&#62; x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3) \u2192 Training the model The linear regression model is imported from the sklearn package. This model is available in the linear model family of sklearn. After importing the model, an instance of the model is created. Then this model is fit to the training dataset. &#62;&#62;&#62; from sklearn.linear_model import LinearRegression&#62;&#62;&#62; lr = LinearRegression()&#62;&#62;&#62; lr.fit(x_train,y_train)LinearRegression() \u2192 Predictions The predictions can be found using the \u2018predict\u2019 method on the testing data of predictor variables. Then these predictions are compared with the actual testing data prediction to ascertain the accuracy of the model. &#62;&#62;&#62; pred = lr.predict(x_test)&#62;&#62;&#62; predarray([577.87553409, 435.27155928, 546.5858502 , 391.51629942, 607.95417641, 509.87240751, 619.18792019, 449.34481128, 499.72263686, 456.3743405 ,..........................., 591.25542691, 486.27032699, 474.25589187, 451.54855685, 494.85641921, 554.82684019]) By creating a scatter plot, we can visualize how far the predicted values are from the actual values. &#62;&#62;&#62; plt.scatter(y_test,pred)&#62;&#62;&#62; plt.xlabel(&#039;Actual Y Test&#039;)&#62;&#62;&#62; plt.ylabel(&#039;Predicted Y&#039;) Source: Author By creating the residuals, a clear picture will be known of the data. The residual is the difference between the actual and predicted values. If the residual plot is normally distributed then it means that the choice of model was right. &#62;&#62;&#62; [&#8230;]",
            "pubdate": "Fri, 21 Jul 2023 02:04:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "A Systematic Approach to Choosing the Best Technology/Vendor: MLOps version": {
            "url": "https://towardsai.net/p/machine-learning/a-systematic-approach-to-choosing-the-best-technology-vendor-mlops-version",
            "description": "Last Updated on August 1, 2023 by Editorial Team Author(s): Eyal Trabelsi Originally published on Towards AI. The Ultimate Shopping Spree in the ML Shop The emergence of machine learning use cases created a gap in technology which led to too many solutions and buzzwords\ud83d\udc1d. Machine learning is becoming an integral part of every aspect of our lives. A while ago, I wrote about a Systematic Approach to Choosing Technology/Vendor. But choosing an MLOps solution is a bit different due to the long life cycle and the lack of mature tooling. Are you struggling to choose the right MLOps solution for your business? This post is for you. The steps involved in the model lifecycle include developing your sophisticated model, evaluating the models and keeping track of the results, deploying your trained model, serving predictions, monitoring, and iterating. Simple Recipe To simplify the process of choosing the right vendor/technology, I propose a straightforward recipe: Start by mapping your needs, resources, and constraints. Search for potential solutions and eliminate any that don\u2019t meet your requirements. Evaluate the remaining promising solutions. Make a decision \u2014 to go or not to go? To be honest, it&#039;s generic for all technology in general, but in each step, I will give the ML perspective. In the next section, we will drill down to map your needs, resource, and constraints. Step 1: Map your needs, resources, and constraints The first step in choosing the right technology or vendor is to map out your needs, resources, and constraints.: The requirements and the needs depend on the component/functionality you fill in the ml lifecycle and can be seen in the following table. The resources you have can also impact what solution you pick: Total ownership cost and Cost of mistake. Time to market and Maintenance time. Team expertise and Team size. This includes How many DS, MLEs, and Devops you got. In terms of constraints, there are some that are generic, and some depend on the component/functionality you fill in the ml lifecycle. The generic constraints are Existing Integrations, Change of Ownership, Specific Cloud/On-prem, Multi-tenancy, Compliance &#38; licenses, Security, and Availability.The per-component constraints are: In the next section, we will drill down to searching for potential solutions. Step 2: Search for potential solutions The second step in the process of selecting the right vendor/technology is to search for potential solutions. However, before embarking on this search, it\u2019s essential to familiarize yourself with technical terms and buzzwords to ensure that you can effectively evaluate potential options. Once you have this foundational knowledge, you can begin researching potential technologies and vendors and keep a few promising options. Then curate a short list of available options, the best way to focus is to take into consideration the following: curate a short list of the available options. Filter aggressively on your constraints, for example, if you are looking for an on-prem solution or you got an unbalanced dataset, it will filter most of your options. Whether to buy vs build your own solution:&#8211; Build if it&#039;s easy! both to build and to maintain.&#8211; But when it&#039;s ROI positive and the shelf is not empty.&#8211; Skip if it&#039;s not ROI positive. Whether to choose an all-in-one or best-of-breed approach:&#8211; All-in-one is awesome for common and easy cases. Remember it&#039;s okay. Most of us are not Google.&#8211; Best of breed fit better in a more constrained environment (remember the lists from before?&#8211; You can even combine these, in cases most of your components are trivial and only a few are very constrained. Just make sure the integration is feasible within your resources Speak with the communities like MDLI, MLOps.community, MLOps TLV, and many more. In the next section, we will drill down to evaluating promising solutions. Evaluate promising solutions To evaluate the remaining promising solutions, there are a number of steps you should take. Start by speaking with the vendor or users: This will help you gain a deeper understanding of the solution\u2019s capabilities and limitations. Focus on stability and problems people face as most of these solutions are not mature. Do some POCS: Start with \u201cHello World\u201d tutorials this will help you get a sense of how the solution works in practice. Do more through POCs if needed. Make a table for comparison: This can include interactions like releases, support, community, pricing, constraints, requirements, and resources. In the next section, we will drill down to the decision. Decision! Go? no, Go? When you&#039;re deliberating about whether to proceed or not. Bear in mind that the most fitting solution might not necessarily be the perfect one. It needs to suit your requirements, constraints, and resource. Strive to identify the solution that best serves your organization&#039;s needs, making the choice less intimidating. To make a decision about whether or not to go keep your future goals in mind and prioritize flexibility in your decision-making process. It\u2019s important to maintain a professional demeanor and avoid getting caught up in politics or letting your ego drive your decisions. Additionally, it\u2019s important to be aware of human bias and take steps to counteract it. Last words In this article, we\u2019ve provided a recipe for selecting the right ML technology or vendor for your business. By mapping your needs, resources, and constraints and searching for potential solutions, you can make an informed decision that aligns with your goals. Remember that there is no perfect solution, so focus on the fittest solution that fits within your context. I hope I was able to share my enthusiasm for this fascinating topic and that you find it useful. You\u2019re more than welcome to drop me a line via email or LinkedIn. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 01 Aug 2023 04:01:43 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "ParDo and DoFn Implementation in Apache Beam in Details": {
            "url": "https://towardsai.net/p/machine-learning/pardo-and-dofn-implementation-in-apache-beam-in-details",
            "description": "Last Updated on August 1, 2023 by Editorial Team Author(s): Rashida Nasrin Sucky Originally published on Towards AI. Conclusion Photo by ODISSEI on Unsplash This member-only story is on us. Upgrade to access all of Medium. Detail Explanation of Code For Beginners I wrote a tutorial on some common transform functions in Apache Beam in a previous tutorial that covered map, filter, and combinePerKey(). This tutorial will be for ParDo transform which is nothing but another way of doing Map. But the difference is ParDo applies the transform in each PCollection and returns zero or more elements to the output PCollection. On the other hand, Map transform outputs exactly one element for each input element. In that way, ParDo provides us with&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 01 Aug 2023 02:02:31 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "What is snowChat?": {
            "url": "https://towardsai.net/p/machine-learning/what-is-snowchat",
            "description": "Last Updated on August 1, 2023 by Editorial Team Author(s): Kaarthikandavar Originally published on Towards AI. This member-only story is on us. Upgrade to access all of Medium. snowchat-streamlit-AI-chatbot Do you struggle with complex SQL queries? Are you lost in a sea of tables while trying to locate a single piece of data? Fear not, for I have created snowChat to solve these problems! In this post, I\u2019ll show you: How to embed a Snowflake schema into a vector databaseHow to create a conversational chain using LangChainHow to connect the chain response to SnowflakeHow to design a chat-like interface using StreamlitHow to deploy your solution to the Streamlit Community Cloud \u2744\ufe0f Ready to leap right in? Check out the app and&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 01 Aug 2023 00:01:54 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "Top Computer Vision Papers During Week From 24/7 To 31/7": {
            "url": "https://towardsai.net/p/machine-learning/top-computer-vision-papers-during-week-from-24-7-to-31-7",
            "description": "Last Updated on August 2, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. Stay Relevant to Recent Computer Vision Research This member-only story is on us. Upgrade to access all of Medium. Computer vision, a field of artificial intelligence focused on enabling machines to interpret and understand the visual world, is rapidly evolving with groundbreaking research and technological advancements. On a weekly basis, several top-tier academic conferences and journals showcased innovative research in computer vision, presenting exciting breakthroughs in various subfields such as image recognition, vision model optimization, generative adversarial networks (GANs), image segmentation, video analysis, and more. In this article, we will provide a comprehensive overview of the most significant papers published in the last week of July 2023, highlighting the latest&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 02 Aug 2023 00:01:55 +0000",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "Build A Custom AI Based ChatBot Using Langchain, Weviate, and Streamlit": {
            "url": "https://towardsai.net/p/machine-learning/build-a-custom-ai-based-chatbot-using-langchain-weviate-and-streamlit",
            "description": "Last Updated on August 10, 2023 by Editorial Team Author(s): Skanda Vivek Originally published on Towards AI. A comprehensive guide to building a customized chatbot using Generative AI, a popular vector database, prompt chaining, and UI tools This member-only story is on us. Upgrade to access all of Medium. As multiple organizations are racing to build customized LLMs, a common question I have been asked is \u2014 what are the tools out there to streamline this process? In this article, I show you how to build a fully functional application for engaging in conversations through a chatbot built on top of your documents. This application employs the power of ChatGPT/GPT-4 (or any other large language model) to extract information from document data stored as embeddings in a vector database, and Langchain for prompt chaining. Here\u2019s a preview: Docs QA Bot&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 10 Aug 2023 00:01:56 +0000",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "The LLM Land Grab: How AWS, Azure, and GCP Are Sparring Over AI": {
            "url": "https://towardsai.net/p/machine-learning/the-llm-land-grab-how-aws-azure-and-gcp-are-sparring-over-ai",
            "description": "Last Updated on August 11, 2023 by Editorial Team Author(s): Tabrez Syed Originally published on Towards AI. In the early 2000s, cell phones were still bulky and utilitarian. But in July 2004, Motorola unveiled the Razr, with its sleek, ultra-thin aluminum body that was a stark departure from the basic phones of the day. Positioned as a premium device, the Razr flew off shelves, selling 50 million units in just two years and over 130 million across various models over four years. The Razr single-handedly revived Motorola\u2019s stagnant mobile phone division and changed the company\u2019s fortunes, at least for a time. It was common then for cell phone carriers to use exclusive access to hot new phones like the Razr as a carrot to encourage customers to switch networks. Cingular Wireless scored big by landing exclusive rights to the Razr. The gambit paid off \u2014 Cingular went on to acquire AT&#38;T Wireless in 2004 and became the largest wireless carrier in the US on the back of the wildly popular Razr. Today, a similar dynamic is playing out in the world of large language models (LLMs) and cloud computing. Major players like Amazon, Microsoft, and Google are racing to meet surging demand for LLMs like GPT-3. But much like the Razr, access to the most advanced models is limited to specific cloud platforms. As customers clamor for generative AI capabilities, cloud providers are scrambling to deploy LLMs and drive the adoption of their platforms. Just as the Razr boosted Cingular, exclusive access to coveted LLMs may give certain cloud players an edge and shuffle the cloud infrastructure leaderboard. This article explores how major cloud providers are navigating the AI gold rush and using exclusivity to their advantage. PC Magazine: # 4 Companies Control 67% of the World\u2019s Cloud Infrastructure Amazon Web Services: The Swiss Army Knife Approach With its vast array of cloud infrastructure offerings and unrivaled scale, Amazon Web Services (AWS) has firmly established itself as the dominant player in the space. However, the meteoric rise of large language models (LLMs) like GPT-3 poses a new challenge for the tech titan. Lacking an equally buzzworthy in-house LLM, AWS risks losing ground to rivals rushing their own models to market. So instead of trying to compete model-for-model, AWS has taken a different tack: enable access to as many models as possible via partnerships and collaborations. Enter Amazon Bedrock, launched in April 2023. Bedrock serves as a platform for developers to access and combine capabilities from a diverse roster of LLMs both old and new. This includes well-known names like Anthropic\u2019s conversational Claude 2, AI21 Labs\u2019 code-generating Jurassic-2, Cohere\u2019s multipurpose Command and Embed models, and Stability.ai\u2019s image synthesis tool Stable Diffusion. Rather than betting on any single model, AWS is positioning itself as the Swiss army knife of LLMs \u2014 granting developers the flexibility to mix and match the best features across a wide palette of models. And AWS isn\u2019t sitting idle on the LLM front, either. Though details remain sparse, it\u2019s developing its own homegrown LLM, Titan. But AWS\u2019 strength has always been its platform, not proprietary AI. By reducing friction to access and deploy LLMs, AWS is betting developers will stick with what they know. Google Cloud: The Walled Garden Approach As a heavyweight in AI research, Google was perfectly positioned to capitalize on the explosion of large language models (LLMs). And in 2021, they unveiled LaMDA \u2014 an LLM rivaling the capabilities of GPT-3. Access to Google\u2019s AI models is provided through Model Garden, a managed service on the Google Cloud Platform (GCP). Model Garden provides enterprise-ready foundation models, task-specific models, and APIs to kickstart workflows. These include directly using models, tuning them in the Generative AI Studio, or deploying them to a notebook. As of August 2023, Model Garden includes homegrown models like the conversational LaMDA, text-to-image generator Imagen, and code autocompletion tool Codey. Google also has open-source models like BERT, T5, ViT, and EfficientNet for easy deployment on GCP. But Google isn\u2019t limiting Model Garden exclusively to its own AI. Third-party models are already being added, indicating Google wants to be the one-stop-shop for AI needs. However, competitors are unlikely to offer their most advanced models. The key question is which providers will license their models for availability on GCP. Subscribe now Microsoft Azure: Betting on OpenAI Exclusivity Microsoft placed an early and sizeable bet on large language models (LLMs) that is paying off handsomely. Back in 2019, before most grasped the astounding potential of LLMs, Microsoft invested a cool $1 billion into OpenAI \u2014 the maker of GPT-3. This prescient investment secured Microsoft exclusive access to OpenAI\u2019s rapidly advancing LLMs, including enhanced versions of GPT-4 and image generator DALL-E. With OpenAI dominating AI headlines, Microsoft is now leveraging its exclusive access to lure customers to its Azure cloud platform. And it\u2019s working \u2014 by riding OpenAI\u2019s coattails, Azure is steadily chipping away at AWS\u2019s dominance in cloud market share. Yet Microsoft hasn\u2019t put all its eggs in the OpenAI basket. It recently partnered with Meta to launch LLaMA, an open-source LLM. This allows Microsoft to diversify its LLM portfolio beyond OpenAI, hedging its bets should a new model usurp GPT-3 as king of the hill. The Rest: Diverse Approaches to Gain LLM Traction The major cloud platforms like AWS, Microsoft Azure, and Google Cloud boast eye-catching proprietary AI models to lure enterprise customers. Lacking standout in-house models, smaller cloud providers are taking a flexible \u201cBYOM\u201d (Bring Your Own Model) approach instead. Rather than scramble to develop unique \u201cshow pony\u201d models, they enable customers to integrate third-party or custom models into workflows. IBM\u2019s watsonx service exemplifies this strategy. It offers an MLOps platform to build and train AI models tailored to specific needs. Watson X provides seamless integration with open-source repositories like Hugging Face for those wanting off-the-shelf models. This allows customers to tap into a vast range of pre-built models. Salesforce also combines internal R&#38;D with external flexibility. Its capable AI Research team has [&#8230;]",
            "pubdate": "Fri, 11 Aug 2023 02:01:50 +0000",
            "pubdate_parsed": [
                2023,
                8,
                11
            ],
            "email_sent": true
        },
        "How to install Hadoop on MacBook M1 or M2 without Homebrew or Virtual Machine": {
            "url": "https://towardsai.net/p/machine-learning/how-to-install-hadoop-on-macbook-m1-or-m2-without-homebrew-or-virtual-machine",
            "description": "Last Updated on August 11, 2023 by Editorial Team Author(s): Mala Deep Originally published on Towards AI. Step 1: Check and install the Java JDK (if needed) using the terminal This member-only story is on us. Upgrade to access all of Medium. Hadoop localhost User Interface. Image by the author. In this article, I will walk you through the simple installation of Hadoop on your local MacBook M1 or M2. I will be using a MacBook Air M1 (arm64), 2020, with 8 GB of memory and MacOS Ventura 13.2.1. Let\u2019s get started! Before we get started, I am confident you have a basic awareness of the key terminology in the Hadoop ecosystem. Additionally, Please confirm that your MacBook M1 or M2 fits the following specifications: A MacBook M1 or M2 with MacOS Ventura 13.2.1&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 11 Aug 2023 00:01:46 +0000",
            "pubdate_parsed": [
                2023,
                8,
                11
            ],
            "email_sent": true
        },
        "Mastering A/B Testing: A Real World Business Example [Part 1]": {
            "url": "https://towardsai.net/p/machine-learning/mastering-a-b-testing-a-real-world-business-example-part-1",
            "description": "Last Updated on August 15, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. Step-by-Step Walk-Through Real World A/B Testing Use Case This member-only story is on us. Upgrade to access all of Medium. Imagine a scenario where you are running a website, and you aim to optimize your user experience and boost conversions. In this dynamic landscape, you are facing a critical question: which version of the website will resonate better with users and result in higher engagement? This is where A/B testing comes into play. In this article, we will unravel the intricacies of A/B testing using this real-world example, exploring how a simple division of users into two groups can provide profound insights that lead to enhanced user experiences and business&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 15 Aug 2023 00:01:51 +0000",
            "pubdate_parsed": [
                2023,
                8,
                15
            ],
            "email_sent": true
        },
        "This AI newsletter is all you need #60": {
            "url": "https://towardsai.net/p/machine-learning/this-ai-newsletter-is-all-you-need-60",
            "description": "Last Updated on August 16, 2023 by Editorial Team Author(s): Towards AI Editorial Team Originally published on Towards AI. Hottest News This member-only story is on us. Upgrade to access all of Medium. As the AI race has accelerated this year, AI chip training and inference capacity have become vital resources, and we noted several developments over the past weeks. Both large tech companies and younger AI startups have been scrambling to get access to deliveries of Nvidia H100s, and we are excited to see the emergence of the next generation of models powered by these chips after production ramped up this summer. Many AI startups have been raising large investments to primarily fund AI chip training capacity, which has also led&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 16 Aug 2023 01:11:19 +0000",
            "pubdate_parsed": [
                2023,
                8,
                16
            ],
            "email_sent": true
        },
        "What to Learn in Data Science (2023)": {
            "url": "https://towardsai.net/p/machine-learning/what-to-learn-in-data-science-2023",
            "description": "Last Updated on August 17, 2023 by Editorial Team Author(s): James Koh Originally published on Towards AI. This member-only story is on us. Upgrade to access all of Medium. Beginners, and even existing ML practitioners and data scientists, get lost in the large sea of endless information. There is information overload, and it might not be possible to know what article is worth reading until we actually read it. As non-experts looking for information, these questions come to mind. Is this article legitimate? Can I trust what\u2019s written here?Is this explanation suitable for a newcomer to the field, or is the writer skipping lots of important details?Is this information even useful and worth investing my time in the year&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 17 Aug 2023 04:02:26 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "How are AI Projects Different": {
            "url": "https://towardsai.net/p/machine-learning/how-are-ai-projects-different-2",
            "description": "Last Updated on August 17, 2023 by Editorial Team Author(s): Jeff Holmes MS MSCS Originally published on Towards AI. Michael Dziedzic on Unsplash I am often asked by prospective clients to explain the artificial intelligence (AI) software process, and I have recently been asked by managers with extensive software development and data science experience who wanted to implement MLOps. This article is intended as an outline of the key differences rather than a comprehensive discussion on the topic of the AI software process. Background An AI project is experimental in nature, so several or many parts of the software program may be replaced or modified over time. Thus, changes are usually a result of outcomes of various steps in the process rather than customer/system requirements, so it is important to design the system in ways that will not require a total reconstruction if experimental results suggest a different approach. In fact, writing scientific code has two unique properties: mathematical errors and experimental nature. Mistakes in computations are often hard to trace, especially when the code is semantically correct. No bugs are found. No exception is raised. All looks good, but the (numerical) result is clearly incorrect. When implementing probabilistic models, the results may look good depending on some initial conditions or a random factor. No Free Lunch Theorem: Any two algorithms are equivalent when their performance is averaged across all possible problems. There will always be experimental parts that will be constantly changing. Therefore, the key is to design each component so that most of the work can stay and serve as a foundation for the next stage of development. Therefore, many articles, such as [3] focus on design patterns that can help create more robust and reusable code with fewer bugs. The MLOps Process We can see some of the differences with MLOps which is a set of methods and techniques to deploy and maintain machine learning (ML) models in production reliably and efficiently. MLOps is the intersection of Machine Learning, DevOps, and Data Engineering. Figure 1: ML model SDLC [4] In general, the MLOps process involves eight stages: Data preparation Feature engineering Model design Model training and optimization Model evaluation Model deployment Model serving Model monitoring Each step in the MLOps lifecycle is built on its own system but requires interconnection which are the minimum requirements needed to scale ML applications. Without delving into a discussion of MLOps, we can identify some key ideas on the project differences: Need to version code, data, and models Continuous delivery and continuous training Tracking Model Experiments Managing Machine Learning Features Monitoring Models in Production Tracking Model Experiments Unlike the traditional software development cycle, the model development cycle paradigm has two main differences: Managing Features and Monitoring Models. Managing Machine Learning Features Feature stores address some key operational challenges: they provide a consistent set of data between training and inference; they avoid any data skew or inadvertent data leakage; they offer customized capability of writing feature transformations (both on batch and streaming data) during the feature extraction process while training; they allow request augmentation with historical data at inference which is common in large fraud and anomaly detection models as well as recommender systems. Monitoring Models in Production There are several types of problems that Machine Learning applications can encounter over time [4]: Data drift: sudden changes in the features values or changes in data distribution. Model/concept drift: how, why, and when the performance of the model changes. Models fail over time: Models fail for inexplicable reasons (system failure, bad network connection, system overload, bad input or corrupted request), so detecting the root cause early or its frequency is important. Outliers: the need to track the results and performances of a model in case of outliers or unplanned situations. Data quality: ensuring the data received in production is processed in the same way as the training data. System performance: training pipelines failing or taking long time to run, very high latency, etc. Systems degrade overload: Constantly monitoring the health of model servers or service is also important. Conclusion Clearly, the experimental nature of AI projects is a key difference from traditional software development. We can also identify some important differences with AI projects in the context of MLOps: the need to version code, data, and models; tracking model experiments; monitoring models in production. References [1] E. Alpaydin, Introduction to Machine Learning, 3rd ed., MIT Press, ISBN: 978\u20130262028189, 2014. [2] S. Russell and P. Norvig, Artificial Intelligence: A Modern Approach, 4th ed. Upper Saddle River, NJ: Prentice Hall, ISBN: 978\u20130\u201313\u2013604259\u20134, 2021. [3] O. Zero, \u201c How to write better scientific code in Python,\u201d Towards Data Science, Feb. 15, 2022. [4] M. Galarnyk, \u201c Considerations for Deploying Machine Learning Models in Production,\u201d Towards Data Science, Nov. 19, 2021. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 17 Aug 2023 02:01:54 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "What is MLOps": {
            "url": "https://towardsai.net/p/machine-learning/what-is-mlops-2",
            "description": "Last Updated on August 17, 2023 by Editorial Team Author(s): Jeff Holmes MS MSCS Originally published on Towards AI. Pietro Jeng on Unsplash MLOps is a set of methods and techniques to deploy and maintain machine learning (ML) models in production reliably and efficiently. Thus, MLOps is the intersection of Machine Learning, DevOps, and Data Engineering (Figure 1). Figure 1: Venn diagram showing the relationship among the MLOps-related fields [Wikipedia]. Background Saying that MLOps is in a state of flux would be an understatement [7]. The best advice that I could give on MLOps would be to try to hire someone who is able to see the \u201cbig picture\u201d. Any competent software engineer can learn how to use a particular MLOps platform since it does not require an advanced degree. Therefore, a common mistake when interviewing applicants is to focus on the minutia of a particular platform (AWS, GCP, Databricks, MLflow, etc.). The ideal MLOps engineer would have some experience with several MLOps and/or DevOps platforms. In fact, too much experience with a single platform will most likely be problematic in the future since most companies seldom stay with one cloud platform over time, and there are not currently any standards for MLOps. A major problem with MLOps is the lack of standards which means that each platform tends to use different terminology. Hopefully, SEI or IEEE will soon publish an AI Engineering guide to standardize the terminology similar to SWEBOK. For now, I would recommend learning MLflow since it is open-source and seems to be very popular. Many people use the term \u201cpipeline\u201d in MLOps which can be confusing since pipeline is computer science term that refers to a linear sequence with a single input/output. A better definition would make use of the directed acyclic graph (DAG) since it may not be a linear process. Thus, the term workflow is a better description of the many kinds of processes that could be involved at any stage in the MLOps SDLC. The Machine Learning Model Process In general, the ML model process involves eight stages (Figures 2 and 3) which may include data collection and/or data labeling [1]: Data preparation Feature engineering Model design Model training and optimization Model evaluation Model deployment Model serving Model monitoring Figure 2: Phases of the ML model SDLC [2] Figure 3: ML model SDLC including monitoring [2] In contrast, ModelOps is focused on managing the full software development life cycle (SDLC) of a variety of AI models, including machine learning, knowledge graphs, rules, optimization, natural language, and agent-based models (Figure 4). Figure 4: The ModelOps process [Wikipedia] The Machine Learning Workflow Machine learning requires experimenting with a wide range of datasets, data preparation, and algorithms to build a model that maximizes some target metric(s). Once a model has been built, the next step would be to deploy the final model to a production system, monitor model performance, and continuously retrain the model on new data and compare it with alternative models. Therefore, being productive with machine learning for real-world applications can be challenging for several reasons [3]: It is difficult to keep track of experiments. When working with files on your laptop or with a notebook, how can we tell which data, code, and parameters were used to obtain a particular result? It is difficult to reproduce code. Even if we carefully track the code versions and parameters, we still need to capture the entire environment (such as library dependencies) to reproduce the same results. This is even more challenging when working in a team or if we want to run the same code at scale on another platform (such as the cloud). There is no standard way to package and deploy models. Every data science team develops its own approach for each ML library that is used, so the link between the model and the code and parameters is often lost. There is no central store to manage models (versions and stage transitions). Without a central place to collaborate and manage the model lifecycle, data science teams will encounter challenges managing model stages. Although individual ML libraries provide solutions to some of these problems (such as model serving), you usually want to try multiple ML libraries to get the best results. An MLOps tool allows you to train, reuse, and deploy models with any library and package them into reproducible steps that other data scientists can use as a \u201cblack box\u201d without needing to know which libraries you are using. Keep in mind that trying to retrofit or apply MLOps piece-meal is a common misconception and would actually be considered a software design antipattern [5][6]. Surprisingly, some companies such as Nvidia are currently trying to do just this en masse across all their software development projects which is not feasible and will likely prove to be problematic. Thus, an MLOps platform must provide at least five features to help manage the ML workflow [3]: Tracking: an API for logging parameters, code versions, metrics, and artifacts when running machine learning code and later visualizing the results. Projects: a standard format for packaging reusable ML code. Models: a convention for packaging ML models in multiple flavors and a variety of tools to help in deploying them. Registry: a centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of an ML model(s). Scalability: designed to scale to large data sets, large output files, and a large number of experiments. Conclusion MLOps is a set of methods and techniques to deploy and maintain machine learning (ML) models. However, MLOps does not currently have any standards defined, so it is important to keep this in mind. Therefore, it is important to see the \u201cbig picture\u201d which involves understanding the key concepts, stages, features, and challenges with MLOps. References [1] J. S. Damji and M. Galarnyk, \u201c Considerations for Deploying Machine Learning Models in Production,\u201d Towards Data Science, Nov. 19, 2021. [2] B. Rogojan, \u201c What Is MLOps And Why Your Team Should [&#8230;]",
            "pubdate": "Thu, 17 Aug 2023 00:01:39 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "We Train Our Machines, Then They Retrain Us: The Recursive Nature of Building AI": {
            "url": "https://towardsai.net/p/machine-learning/we-train-our-machines-then-they-retrain-us-the-recursive-nature-of-building-ai",
            "description": "Last Updated on August 18, 2023 by Editorial Team Author(s): Tabrez Syed Originally published on Towards AI. On May 10, 1941, German bombs reduced the storied British House of Commons to smoldering ruins; the famous Gothic revival complex had stood for over two centuries as the backdrop for vigorous political debate, yet now this architectural symbol lay in ashes. Amidst the smoke, a pressing question emerged \u2014 rebuild identical to the past, or embrace modern redesigns like the sweeping semicircular halls found overseas? To Winston Churchill, the answer was clear. In a 1943 speech, he remarked, \u201cWe shape our buildings, and afterwards our buildings shape us,\u201d believing the old chamber\u2019s confrontational intimacy was woven into British democracy\u2019s raucous soul. Unlike expansive foreign legislative spaces (like the semi-circular layout of the US Capitol building), the old Commons crammed 427 seats tightly together, packing opposing factions face-to-face across a narrow aisle with nowhere to hide. The democratic spirit was fueled by a direct confrontation that led to accountability. While it may have been noisy and messy, it was authentic. Though open to functional improvements, Churchill pushed for the restoration of the arena. Despite the destruction, preserving the shape that had housed centuries of clamorous debate took priority. Churchill\u2019s sentiment \u2014 that constructed spaces shape collective life \u2014 extends beyond building design. This notion, sometimes called \u201carchitectural determinism,\u201d suggests our built environment profoundly influences human behavior. Urban planners apply these principles deliberately, widening sidewalks to foster pedestrian activity along city boulevards. Or consider a quaint one-lane bridge over a winding creek \u2014 its narrowness promotes patience and cooperation as drivers politely wait their turn to cross. In the digital age, architectural determinism manifests through choices made in constructing AI systems, which will shape the very structure of discourse as large language models permeate society. Shaping Our Assistants: Teaching AI Through Human Feedback When OpenAI unveiled GPT-2 in 2019, the natural language model represented a leap forward. Trained on 40 GB of internet text through unsupervised learning, its 1.5 billion parameters could generate remarkably coherent passages. Yet inconsistencies remained. Without human guidance, GPT-2\u2019s impressive but aimless prowess produced verbose meanderings as often as useful information. To refine their creation, OpenAI pioneered a new approach: reinforcement learning from human feedback (RLHF). The technique, detailed in the paper \u201cFine-tuning Language Models from Human Feedback,\u201d blends human intuition with AI to steer models toward more \u201cuseful\u201d behaviors. RLHF by OpenAI Here\u2019s how it works: Starting with a base model like GPT-2, human trainers interact with the system, playing both user and AI. This conversation creates a dataset reflecting human preferences. Trainers then further shape the model by ranking its sample responses, allowing a \u201creward model\u201d to be developed that scores output based on quality. The AI progressively improves by fine-tuning the model to maximize its rewards, generating text more aligned with human values. Through cycles of feedback and refinement, RLHF sculpts once erratic models into more helpful, on-point companions. The fruits of this approach arrived with ChatGPT in 2022. Trained using RLHF, it dazzled users with thoughtful, conversational responses. The High Cost of Human Wisdom After the breakthrough of ChatGPT, other AI labs quickly adopted reinforcement learning from human feedback (RLHF). Companies like DeepMind, Anthropic, and Meta leaned on RLHF to craft assistants like Sparrow, Claude, and LLaMA-2-chat. Yet while effective, RLHF requires immense resources. Each round involves human trainers generating conversations, evaluating responses, and providing guidance at scale. For GPT-3, OpenAI outsourced this laborious process to contractors in Kenya. The \u201cnon-profit\u2019s\u201d financial backing enabled this human-powered approach, but such costs limit accessibility for many. Anthropic\u2019s training system from their paper \u201c[2204.05862] Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback\u201d Some organizations are getting creative to overcome the hurdle. The Open Assistant Project invites the public to contribute directly to model training through a crowdsourcing platform. DataBricks gamified the process internally, encouraging its 5,000 employees to judge sample interactions through a fun web interface. This allowed them to build the dataset for their own assistant, Dolly rapidly. Startups like Scale AI also offer services to manage the human annotation required for RLHF. Copying Classmates: Using LLMs to Bootstrap One Another As RLHF\u2019s prohibitive price deters many, some researchers are cutting costs by replacing human feedback with the output of other language models. Stanford\u2019s Human-Centered AI group demonstrated this shortcut. Seeking to retool Meta\u2019s 7 billion parameters LLaMA into a more capable assistant like ChatGPT, they wrote 175 seed tasks and used OpenAI\u2019s DaVinci model to generate a 52,000 example dataset for just $500. Rather than painstaking human annotation, davinci produced labeled data automatically. Fine-tuning LLaMA on this synthetic dataset created Alpaca-7B, an adept assistant, for just $600 total. Researchers at UC Berkeley collaborated to train the 13 billion parameters Vicuna model using 70,000 conversations scraped from ShareGPT (a website where people share their ChatGPT threads). Vicuna reached 90% of ChatGPT\u2019s performance, trained on data at a fraction of the cost. Meanwhile, Microsoft and Peking University developed Evol-Instruct, a novel method to exponentially grow seed data using an LLM. Their resulting WizardLM even surpasses GPT-4 in certain skills, demonstrating the power of synthetic datasets. Open-source datasets like RedPajama\u2019s 1.2 trillion token replicas of LLaMA also aim to democratize model training. We become what we behold. We shape our tools, and then our tools shape us Churchill grasped centuries ago how constructed spaces shape collective norms. His insight rings true once more as LLMs proliferate through synthetic training loops. The architectural choices made in those initial models propagate as their output trains new generations. Early flaws and biases subtly ripple down the line, shaping discourse itself. When LLMs generate text read by millions daily, their idiosyncrasies permeate human expression. As models optimized for engaging chat advise writers, their tendencies infuse published content. Our tools reflect our values, and in time, remake us in their image. But this dance between creator and creation is not abnormal \u2014 it\u2019s the story of human progress. From the [&#8230;]",
            "pubdate": "Fri, 18 Aug 2023 04:02:27 +0000",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "Solving the Image Promotion Challenge Across Multi-Environment with ArgoCD": {
            "url": "https://towardsai.net/p/machine-learning/solving-the-image-promotion-challenge-across-multi-environment-with-argocd",
            "description": "Last Updated on August 18, 2023 by Editorial Team Author(s): Anirudh Mehta Originally published on Towards AI. When designing cloud environments, it is often recommended to set up multiple accounts. While this approach offers resource independence, isolation, better security, access, and billing boundaries, it also comes with its own set of issues. One such challenge is efficiently promoting and tracking applications between different environments. The GitOps approach, along with tools like ArgoCD and Kustomize, simplifies tracking and promotion. However, image promotion is often overlooked. Many enterprises adopt a shared image registry, but it soon becomes bloated with many unused versions. This article explores a recent journey during which we examined the problem of promoting images and the innovative solution that was adopted, all while adhering to the principles of GitOps. Challenge Recently, a scenario was presented where a company utilizing the shared ECR registry was considering migrating to separate ECR registries for cost-effectiveness, better governance, and streamlined lifecycle management. Here is a look at the existing state of infrastructure and pipelines: Source: Image by the author. Each environment has a dedicated AWS account with its own cluster and ArgoCD installation. Kustomize is used for managing configuration differences across environments. \u251c\u2500\u2500 infra \u2502 \u251c\u2500\u2500 charts/ \u2514\u2500\u2500 overlays \u251c\u2500\u2500 dev \u2502 \u251c\u2500\u2500 patch-image.yaml \u2514\u2500\u2500 production \u251c\u2500\u2500 patch-image.yaml \u2514\u2500\u2500 patch-replicas.yaml Jenkins is used to continuously build new images in the development environment. However, none of the tools provided out-of-the-box support for promoting images between ECR registries, leading to the exploration of innovative solutions with some considerations. Considerations: Selective Promotion: The company\u2019s application landscape is composed of multiple modules and teams with different timelines. Therefore, it is necessary to support the promotion of images for only selected modules in each release. Optimized Storage: Environments such as production only need to store promoted image versions, reducing clutter and optimizing resource usage. Image Tag and Digest Replication: Replicating image tags and digests between ECR registries is critical for security, and traceability. Potential Solutions At the outset, two potential solutions were proposed: ECR Cross Account Replication: AWS\u2019s ECR natively supports replicating images between two accounts. However, as of now, there is no way to filter the images being replicated based on any criteria. Alternatively, AWS recommends event-based design to selectively replicate images based on tag naming conventions. However, since we are not aware of which versions will be promoted, it requires an additional step of retagging before promotion. Jenkins Promotion Pipeline: A Jenkins pipeline that parses Kustomize Overlays for image tags and programmatical replicates them. Both options are viable, but they introduce an additional layer of complexity to the promotion process. Additionally, you need to ensure that images are promoted before Kustomize overlays are updated. The Winning Strategy: ArgoCD PreSync Job In this scenario, the client was already using ArgoCD for continuous deployment of the application changes. Therefore, we decided to also assign ArgoCD the responsibility of delivering images to the target environment cluster. ArgoCD supports hooks that allow you to run custom scripts before or after a deployment or synchronization process. Source: Image by the author. 1. ECR Repository Permission: Authorize cross-account pull access for Docker images To enable ArgoCD to pull images from the source ECR, we need to add a resource-based policy to our repository. // cross-account-ecr-read-policy.json{ &#034;Version&#034;: &#034;2012-10-17&#034;, &#034;Statement&#034;: [ { &#034;Sid&#034;: &#034;AllowPull&#034;, &#034;Effect&#034;: &#034;Allow&#034;, &#034;Principal&#034;: { &#034;AWS&#034;: &#034;arn:aws:iam::{DESTINATION_ACCOUNT}:root&#034; // Replace with your destination account }, &#034;Action&#034;: [ &#034;ecr:BatchCheckLayerAvailability&#034;, &#034;ecr:BatchGetImage&#034;, &#034;ecr:GetDownloadUrlForLayer&#034; ] } ]} Apply the policy to ECR repositories: aws ecr set-repository-policy --repository-name example --policy-text &#034;file://cross-account-ecr-read-policy.json&#034;// For multiple repositories:aws ecr describe-repositories --query &#034;repositories[].[repositoryName]&#034; &#124; xargs -I {} aws ecr set-repository-policy --repository-name {} --policy-text &#034;file://cross-account-ecr-read-policy.json&#034; 2. PreSync Hook Job: Copy image between accounts We use Crane to copy images without changing their tag and digest. The PreSync Hook job is stored in git along with other application manifests and monitored by ArgoCD. ArgoCD runs the job before the synchronizing changes. The source account is the Development or DevOps account from which the images will be pulled. The destination account is the Production or target environment where the image needs to be copied. // Helm template exampleapiVersion: batch/v1kind: Jobmetadata: generateName: argo-presync-promote-image- annotations: argocd.argoproj.io/hook: PreSync argocd.argoproj.io/hook-delete-policy: HookSucceededspec: template: spec: volumes: - name: creds emptyDir: {} initContainers: - name: aws-creds image: public.ecr.aws/aws-cli/aws-cli command: - sh - -c - &#124; aws ecr get-login-password &#62; /creds/ecr volumeMounts: - name: creds mountPath: /creds containers: // For brevity, I have assumed that all Helm values are available on the root. - name: promote-image image: gcr.io/go-containerregistry/crane:debug command: - sh - -c - &#124; // Login to both ECR registries cat /creds/ecr &#124; crane auth login {{.Values.sourceAccount}}.dkr.ecr.us-east-1.amazonaws.com -u AWS --password-stdin cat /creds/ecr &#124; crane auth login {{.Values.destinationAccount}}.dkr.ecr.us-east-1.amazonaws.com -u AWS --password-stdin // Copy image from source account to destination account crane copy {{.Values.image &#124; replace .Values.destinationAccount .Values.sourceAccount}} {{.Values.image}} volumeMounts: - name: creds mountPath: /creds restartPolicy: Never backoffLimit: 2 Conclusion In conclusion, the team was able to promote images on demand by using the pre-sync hook. This made production promotion a single step of updating the Kustomize overlays. I would love to hear about other options that you have adopted. For instance, an alternative approach could be to use Kubernetes Dynamic Admission Control to intercept and pull missing images on demand. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 18 Aug 2023 02:01:53 +0000",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "Platypus: Dataset Curation and Adapters for Better Large Language Models": {
            "url": "https://towardsai.net/p/machine-learning/platypus-dataset-curation-and-adapters-for-better-large-language-models",
            "description": "Last Updated on August 18, 2023 by Editorial Team Author(s): Benjamin Marie Originally published on Towards AI. Achieve low-cost state-of-the-art on your target tasks This member-only story is on us. Upgrade to access all of Medium. Image by the Author \u2014 Made from Pixabay illustrations (1 and 2) Meta\u2019s Llama 2 was released one month ago and many are working on fine-tuning it for specific tasks. In the same trend, Boston University proposes Platypus (Lee et al., 2023), Llama 2 fine-tuned with adapters and curated datasets. Platypus is now (August 16th) at the first rank on the OpenLLM leaderboard. The method proposed in this work is nothing really new. It relies on LoRa adapters and careful dataset curation. It\u2019s nonetheless impressive in its demonstration that a new state-of-the-art&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 18 Aug 2023 00:01:51 +0000",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "How to Perform Feature Selection with Scikit-Learn": {
            "url": "https://towardsai.net/p/machine-learning/how-to-perform-feature-selection-with-scikit-learn",
            "description": "Last Updated on August 20, 2023 by Editorial Team Author(s): Cornellius Yudha Wijaya Originally published on Towards AI. How to select important features for your machine learning model This member-only story is on us. Upgrade to access all of Medium. Photo by Timothy Muza on Unsplash Feature selection is choosing the most relevant features to the underlying problems. In predictive machine learning, we choose features suitable to improve the model prediction capability. There are many methods to perform feature selection, including statistical analysis, such as the Chi-Square method, or a more advance one, such as model feature importance. Having good domain knowledge is also the best way to do feature selection. In Scikit-Learn, we can use various functions to perform feature selection. What are these functions? Let\u2019s get into it. The simplest feature&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 20 Aug 2023 04:02:25 +0000",
            "pubdate_parsed": [
                2023,
                8,
                20
            ],
            "email_sent": true
        },
        "How Would You Learn Anything with ChatGPT Easily?": {
            "url": "https://towardsai.net/p/machine-learning/how-would-you-learn-anything-with-chatgpt-easily",
            "description": "Last Updated on August 20, 2023 by Editorial Team Author(s): Gencay I. Originally published on Towards AI. Start Learning Faster with ChatGPT: Explore How This AI Tool Can Help You. This member-only story is on us. Upgrade to access all of Medium. Created with leonardo.ai Learning is the key to evolution. You should learn and then test the things you\u2019ve learned to build a neural path in your mind. After a few repetitions, you may not even be aware of it sometimes, like riding a bicycle. And due to the power of LLMs, like ChatGPT, there is another shortcut to learning things, not just coding. I love shortcuts because if there\u2019s a simpler version, why should I follow the hard way, right? In this article, I will show you how I learned the things&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 20 Aug 2023 02:02:22 +0000",
            "pubdate_parsed": [
                2023,
                8,
                20
            ],
            "email_sent": true
        },
        "A Framework For Efficiently Serving Your Large Language Models": {
            "url": "https://towardsai.net/p/machine-learning/a-framework-for-efficiently-serving-your-large-language-models",
            "description": "Last Updated on August 20, 2023 by Editorial Team Author(s): Zoumana Keita Originally published on Towards AI. Serve your large language models just like you would using OpenAI API but at no cost This member-only story is on us. Upgrade to access all of Medium. Photo by Austrian National Library on Unsplash There has been a lot of enthusiasm in the last couple of months around using Large Language Models. Well, this is not surprising due to their ability to help tackle most of the use cases we would think of as unsolvable, and thanks to the vibrant research community for such great work. Like any AI and Machine Learning models, no matter how powerful they are, only moving them into production can help stakeholders make better-informed decisions. Deploying these large language models is undoubtedly one of&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Sun, 20 Aug 2023 00:02:21 +0000",
            "pubdate_parsed": [
                2023,
                8,
                20
            ],
            "email_sent": true
        },
        "How to Define an AI Problem": {
            "url": "https://towardsai.net/p/machine-learning/how-to-define-an-ai-problem",
            "description": "Last Updated on August 26, 2023 by Editorial Team Author(s): Jeff Holmes MS MSCS Originally published on Towards AI. A better way to ask an AI/ML question Towfiqu barbhuiya on Unsplash With more than 25 years of software engineering experience, I have answered a lot of questions from software developers who are getting started with artificial intelligence (AI) and machine learning (ML), so I thought I would share some tips on posting AI/ML questions on chat forums such as Slack and Discord. Background A common misconception by some users is that they can just \u201cpost\u201d a question. However, chat forums are different in principle from online forums such as stackoverflow. A chat forum tends to be more one-on-one in nature, so it tends to require more time and effort to answer a question. Thus, it is best to take a little time upfront to properly describe the problem, especially when sending a direct message (DM). Otherwise, it is likely that you will be given the wrong answer (which is quite common). Be mindful of the background and experience of the users giving you advice. Many Discord users are high school and undergraduate college students with no AI/ML or software engineering experience. I list my credentials on my profile (full disclosure). The first step in solving an AI/ML problem is to be able to describe and understand the problem in detail. Overview Here is an overview of my tips for describing an AI/ML problem [1]: Give some description of your background and experience. Describe the problem, including the category of ML problem. Describe the dataset in detail and be willing to share your dataset(s). Describe any data preparation and feature engineering steps that you have done. Describe any models that you have tried. Favor text and tables over plots and graphs. Avoid asking users to help debug your code. Since some users access Discord using mobile devices, it is best to share your problem description and/or code snippets via GitHub Gist, Pastebin, etc., and share the link on the forum. It is usually best to share files via DM or create a thread so that other users do not have to search the channels for your files and posts. Keep in mind that Discord channel content is unstructured, so it can be difficult to search channels to find your original post(s). If someone volunteers to help you, it can be helpful to copy/paste your original post if you send them a DM. If you are having coding issues, it is best to share a link to the code/algorithm source and say that you are having problems with the implementation rather than posting code snippets and asking \u201cwhat is wrong with my code?\u201d Details You should briefly provide the following (1\u20132 sentences per item) in your forum post: 1. Give some description of your background and experience. It is best to let users know upfront if you are in high school, university, graduate school, researcher, experienced professional, etc. Many Discord users do not realize that many questions take a lot of time to research in order to provide an answer. Therefore, it is only fair that you give a short description of your background. I learned this lesson after spending considerable time trying to help beginners (unknown to me) who proceeded to solve the wrong problem using the wrong algorithm. 2. Describe the problem. In a few sentences, describe the problem, including the type of ML problem if known (Numeric: classification, regression: Image: object classification, object detection, object recognition: Text: sentiment analysis, topic modeling, text generation, etc.). This step may include a literature review. However, if you are able to find some articles solving the same problem, then that should work for now. Part of problem formulation is deciding whether you are dealing with supervised, unsupervised, reinforcement learning, etc. [1]. What is the goal of the model? Classify, predict, detect, translate, etc. What is the goal of the project? Research, engineering, commercial application, hobby, etc. 3. Describe the dataset in detail and be willing to share your dataset. Describe the dataset, including the input features and target feature(s). It is best to share summary statistics of the data, including counts of any discrete or categorical features, including the target feature. It is best to share the entire dataset (if you want someone to help you then you must be open and honest). If, for some reason, you are unable to share the dataset, you need to clearly state this and why you cannot share the dataset. Please note that Discord users are more than willing to donate their time to give free consulting advice, but it is unethical to try to ask vague questions in an effort to get free advice on a commercial or research project that you are getting paid to do. If this is the case, you should be diligent in stating this fact up front repeatedly (do not expect other Discord users to go data mining for your original post). 4. Describe any data preparation and feature engineering steps that you have done. The steps and techniques for data preparation and cleaning will vary by dataset. The most common steps are: fixing structural errors, handling missing or duplicate data, and filtering outliers. Feature engineering can be used to help an algorithm and improve model performance, which includes creating new features, combining sparse classes, removing unused features, and adding dummy variables. Some machine learning algorithms perform much better if all of the variables are scaled to the same range using normalization or standardization techniques. 5. Describe the models that you have tried (you should have tried at least one). After performing data preparation and feature engineering, the first step should be to evaluate several baseline models to be used later for comparison. The final model(s) that you select should perform better on your dataset than the baseline models. 6. Favor text and tables over plots and graphs. It is best not to plot more than one metric on [&#8230;]",
            "pubdate": "Sat, 26 Aug 2023 00:02:26 +0000",
            "pubdate_parsed": [
                2023,
                8,
                26
            ],
            "email_sent": true
        },
        "Overview of Object Detection Evaluation Metrics": {
            "url": "https://towardsai.net/p/machine-learning/overview-of-object-detection-evaluation-metrics",
            "description": "Last Updated on August 28, 2023 by Editorial Team Author(s): Youssef Hosni Originally published on Towards AI. How to Measure the Accuracy of Object Detection Models? This member-only story is on us. Upgrade to access all of Medium. When evaluating the performance of an object detector, we use two main evaluation metrics: FPS (frame-per-second) to measure the network detection speed and mAP (mean Average Precision) to measure the network precision. In this article, we will go through each of them, discussing what they mean and how to calculate each of them. FPS to Measure the Detection SpeedmAP to Measure the Network Precision2.1. Intersection Over Union (IoU)2.2. Precision-Recall Curve (PR Curve) When it comes to object detection algorithms, processing speed is of paramount importance. The most common metric that is&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 28 Aug 2023 04:02:27 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "Log-normal Distribution Simply Explained": {
            "url": "https://towardsai.net/p/machine-learning/log-normal-distribution-simply-explained",
            "description": "Last Updated on August 28, 2023 by Editorial Team Author(s): Egor Howell Originally published on Towards AI. A slight modification of the famous normal distribution This member-only story is on us. Upgrade to access all of Medium. Photo by James Yarema on Unsplash The normal distribution is a household name, particularly in the fields of data science and machine learning. However, have you heard of the log-normal distribution? It has applications in a wide range of industries, from Biology to Finance, therefore, it\u2019s a very useful concept for Data Scientists to understand. In this article, we will delve into the theory and applications of this distribution. The log-normal distribution is relatively easy to understand. A random variable X is part of the log-normal distribution if its logarithm is&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 28 Aug 2023 02:02:25 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "Build Robust ML Backends with Pydantic and Langchain": {
            "url": "https://towardsai.net/p/machine-learning/build-robust-ml-backends-with-pydantic-and-langchain",
            "description": "Last Updated on August 28, 2023 by Editorial Team Author(s): Marcello Politi Originally published on Towards AI. Learn how to prevent users and LLMs mistakes in your code Photo by Bradley Ziffer on Unsplash This member-only story is on us. Upgrade to access all of Medium. It is well known that data scientists are not usually among the best programmers. quite often, they have advanced theoretical skills, and they can do well with mathematics and statistics, but they are not able to independently develop a full-stack application, even a simple one. I am the first to write these types of articles as an excuse to improve my programming skills myself. Today I am going to tell you about Pydantic a library that is now a standard in Python programming used mostly&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 28 Aug 2023 00:02:27 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "Advanced Tutorial: How to Master Matplotlib Like an Absolute Boss": {
            "url": "https://towardsai.net/p/machine-learning/advanced-tutorial-how-to-master-matplotlib-like-an-absolute-boss",
            "description": "Last Updated on August 29, 2023 by Editorial Team Author(s): Bex T. Originally published on Towards AI. Use Matplotlib like never before This member-only story is on us. Upgrade to access all of Medium. Image by me with Midjourney When I was a beginner learning data visualization, I used to have a rule \u2014 never, ever visit the Matplotlib documentation. Nothing good ever came out of there. When I was on its pages, my eyes would process English words but, somehow, they were interpreted into my brain like I was deciphering a foreign language. Then I would stumble upon some masterpieces like these, and I would think, do I even use the same library? Even if you are a seasoned programmer, I am sure you\u2019ve faced&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 29 Aug 2023 04:02:26 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Discrete-Time Markov Chains  Identifying Winning Customer Journeys in a Cashback Campaign": {
            "url": "https://towardsai.net/p/machine-learning/discrete-time-markov-chains-identifying-winning-customer-journeys-in-a-cashback-campaign",
            "description": "Last Updated on August 29, 2023 by Editorial Team Author(s): Abhijeet Talaulikar Originally published on Towards AI. Modeling customer interactions in a digital campaign as discrete-time Markov Chains This member-only story is on us. Upgrade to access all of Medium. AI Generated Measurement and attribution are a widely discussed topic within the data science community. And just as we were making scientific progress in the practice, there were disruptions from policies that threatened to discontinue cookies and tracking. In recent times, a forgotten modeling technique called Marketing Mix Modeling (MMM) has regained traction. It works across all digital and offline channels with reasonable accuracy. However, when it comes to digital-only campaigns where cookies aren\u2019t used, there is a superior technique you can apply. We will discuss that in this article&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 29 Aug 2023 02:02:25 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "What is MetaGPT? LLM Agents Collaborating to Solve Complex Tasks": {
            "url": "https://towardsai.net/p/machine-learning/what-is-metagpt-llm-agents-collaborating-to-solve-complex-tasks",
            "description": "Last Updated on August 29, 2023 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI. Watch the video! This member-only story is on us. Upgrade to access all of Medium. Originally published on louisbouchard.ai, read it 2 days before on my blog! https://www.youtube.com/embed/YtxMderNrzU Thanks to GPT and the recent large language models, we\u2019ve seen the popularization of a new type of AI-based system\u2026 agents. An agent is basically an AI model like ChatGPT that can access and interact with one or more applications. Imagine asking ChatGPT to create a PowerPoint for you. But the whole thing, not just the text on each slide. The layout and images too. It is kind of trying to imitate a human being for a specific&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 29 Aug 2023 00:02:29 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Revolutionizing Human-Machine Interaction: The Emergence of Prompt Engineering": {
            "url": "https://towardsai.net/p/machine-learning/revolutionizing-human-machine-interaction-the-emergence-of-prompt-engineering",
            "description": "Last Updated on August 30, 2023 by Editorial Team Author(s): Dimitris Poulopoulos Originally published on Towards AI. Decoding the art and science of prompt engineering, the secret sauce for supercharging Large Language Models. This member-only story is on us. Upgrade to access all of Medium. Photo by Mojahid Mottakin on Unsplash Who would\u2019ve thought crafting perfect prompts for Large Language Models (LLMs) or other generative models could actually be a job? As a matter of fact, a high-paying one! That was my initial reaction when I first tripped over this relatively new kid on the AI block called \u201cprompt engineering.\u201d As you can tell, this new discipline sounded a bit bizarre to my ears. So, like any good, conscious ignorant, I wanted to educate myself. First stop: Wikipedia. However, as I was completing the corresponding article&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 30 Aug 2023 02:02:24 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "Router Langchain: How To Create Coding Assistance Using Langchain": {
            "url": "https://towardsai.net/p/machine-learning/router-langchain-how-to-create-coding-assistance-using-langchain",
            "description": "Last Updated on August 30, 2023 by Editorial Team Author(s): Tarik Kaoutar (\u9ad8\u9054\u70c8) Originally published on Towards AI. What is Langchain This member-only story is on us. Upgrade to access all of Medium. Want to enhance your coding skills, with the power of AI, you can now create your own coding chatbot. Built by Langchian and OpenAi, the OpenAi API allows you to integrate advanced NLP models into their applications and websites, enabling dynamic and human-like conversations with users. As an automation agency, automationarchitech will show you how to build your AI coding assistant using Python, Langchain, and the powerful GPT-4 language model. You\u2019ll see a live demo of the AI Coding Assistant in action and explore the system design and architecture. I will also&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 30 Aug 2023 00:02:29 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "Reinforcement Learning: Dynamic Programming and Monte Carlo  Part 2": {
            "url": "https://towardsai.net/p/machine-learning/reinforcement-learning-dynamic-programming-and-monte-carlo-part-2",
            "description": "Last Updated on September 1, 2023 by Editorial Team Author(s): Tan Pengshi Alvin Originally published on Towards AI. Introducing two simple iterative techniques to solve the Markov Decision Process This member-only story is on us. Upgrade to access all of Medium. Image by Wil Stewart on Unsplash In the previous article \u2014 Part 1 \u2014 we have formulated the Markov Decision Process (MDP) as a paradigm to solve any Reinforcement Learning (RL) problem. However, the overarching framework discussed did not mention a systematic solution to the MDP. We have ruled out using linear techniques \u2014 like matrix inversion \u2014 and briefly raised the possibility of using iterative techniques to solve the MDP. To revisit the idea of MDP, check out the Part I below: Introducing the backbone of Reinforcement Learning \u2014 The&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 01 Sep 2023 04:02:28 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "FuncReAct: ReAct Agent Using OpenAI Function Calling": {
            "url": "https://towardsai.net/p/machine-learning/funcreact-react-agent-using-openai-function-calling",
            "description": "Last Updated on September 1, 2023 by Editorial Team Author(s): Vatsal Saglani Originally published on Towards AI. Part 1 \u2014 Understanding Prompt Engineering Techniques This member-only story is on us. Upgrade to access all of Medium. Prompting techniques. If you still don\u2019t know what prompting is, then you are probably living under a rock or probably just woke up from a comma. Prompting, with respect to LLMs and Generative AI, refers to the act of formatting the commands you need to provide the model to receive the desired output. A good prompt can generate great results whereas a bad prompt can spoil the experience. The responses from the LLM or any other Generative AI model are as good as the prompts (commands) provided to it. The output&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 01 Sep 2023 02:02:25 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "Transformer Architectures and the Rise of BERT, GPT, and T5: A Beginners Guide": {
            "url": "https://towardsai.net/p/machine-learning/transformer-architectures-and-the-rise-of-bert-gpt-and-t5-a-beginners-guide",
            "description": "Last Updated on September 2, 2023 by Editorial Team Author(s): Manas Joshi Originally published on Towards AI. Source: Image by geralt on Pixabay In the vast and ever-evolving realm of artificial intelligence (AI), there are innovations that don\u2019t just make a mark; they redefine the trajectory of the entire domain. Among these groundbreaking innovations, the Transformer architecture emerges as a beacon of change. It\u2019s akin to the invention of the steam engine during the Industrial Revolution, propelling AI into a new era of possibilities. This architecture has swiftly become the backbone of many modern AI systems, especially those that grapple with the complexities of human language. Imagine the last time you interacted with a virtual assistant, perhaps asking it for weather updates or seeking answers to a trivia question. The smooth, almost human-like response you received is, in many cases, powered by the Transformer architecture. Or consider the numerous times you\u2019ve browsed a website and chatted with a customer support bot, feeling as if you\u2019re conversing with a real person. Again, behind the scenes, it\u2019s often the Transformer working its magic. The beauty of the Transformer lies in its ability to understand context, relationships, and nuances in language. It\u2019s not just about recognizing words but understanding their significance in a given sentence or paragraph. For instance, when you say, \u201cI\u2019m feeling blue,\u201d you\u2019re not talking about the color but expressing a mood. The Transformer gets this, and that\u2019s what sets it apart. In this article, we\u2019ll embark on a journey to demystify this remarkable architecture. We\u2019ll delve deep into its workings and explore its most celebrated offspring: BERT, GPT, and T5. These models, built on the foundation laid by the Transformer, have achieved feats in AI that were once thought to be the exclusive domain of human cognition. From writing coherent essays to understanding intricate nuances in diverse languages, they\u2019re reshaping our interaction with machines. The Magic Behind Transformers In our daily lives, we\u2019re constantly bombarded with information. From the hum of traffic outside our windows to the buzz of conversations in a caf\u00e9, our senses pick up a myriad of stimuli. Yet, amidst this cacophony, our brains possess a remarkable ability: the power of selective attention. If you\u2019ve ever found yourself engrossed in a book while a party rages around you, or if you\u2019ve managed to pick out a familiar voice in a crowded room, you\u2019ve experienced this firsthand. This innate human ability to focus on what\u2019s crucial and filter out the noise is the essence of the magic behind the Transformer architecture in AI. At a fundamental level, the Transformer is designed to handle sequences of data, much like a series of events or a string of thoughts. Traditional models, when faced with sequences like sentences or paragraphs, would process them much like reading a book word by word, linearly and in order. While effective to a degree, this method often missed the broader context, the intricate dance of meaning between words spaced far apart. It\u2019s akin to understanding the plot of a novel by only reading every tenth page; you\u2019d get some of the story, but miss out on the depth and nuance. Enter the Transformer. Instead of being bound by this linear approach, it can, metaphorically speaking, read multiple parts of a book simultaneously. It can focus on the introduction while also considering the climax, drawing connections and understanding relationships that a linear read might miss. This is achieved through what\u2019s known as the \u2018attention mechanism\u2019. Just as our brains weigh the importance of stimuli, deciding what to focus on, the Transformer weighs the significance of different parts of a sequence. Let\u2019s consider a practical example. Imagine the sentence: \u201cJane, who grew up in Canada, is fluent in both English and French.\u201d A traditional model might first focus on \u201cJane\u201d and then move to \u201cCanada\u201d, taking time to understand the relationship between the two. The Transformer, however, can instantly recognize the connection between \u201cJane\u201d and \u201cCanada\u201d, while simultaneously understanding the significance of her fluency in \u201cEnglish and French\u201d. It grasps the entire context, the full story behind Jane\u2019s linguistic abilities, in a holistic manner. This capability becomes even more crucial in complex scenarios. Consider a mystery novel where a clue in the first chapter is only resolved in the last. While a linear approach might forget the initial hint by the time the conclusion rolls around, the Transformer retains and connects these distant pieces of information, much like an astute detective linking disparate clues to solve a case. Moreover, the Transformer\u2019s magic isn\u2019t limited to just text. It\u2019s been applied to a range of data types, from images to sounds. Think of watching a movie and understanding the significance of a character\u2019s gesture based on a flashback scene, or listening to a symphony and recalling a recurring motif. The Transformer can do this with data, drawing connections, recognizing patterns, and providing a depth of understanding previously unattainable. In essence, the Transformer has redefined the rules of the game in AI. It doesn\u2019t just process information; it understands context, relationships, and nuances, bridging gaps and illuminating connections. It\u2019s a leap forward, a shift from mere computation to genuine comprehension. BERT: The Context Whisperer Language, in its essence, is a tapestry of words woven together by the threads of context. Every word we utter or write carries weight and meaning, often shaped by the words that surround it. This intricate dance of words and meanings is what BERT, an acronym for Bidirectional Encoder Representations from Transformers, is designed to understand and interpret. Imagine reading a novel where a character says, \u201cI\u2019m feeling blue today.\u201d Without context, one might visualize the color blue. However, with an understanding of language nuances, it\u2019s clear the character is expressing sadness. This is the kind of contextual understanding that BERT brings to the table. Instead of analyzing words in isolation, BERT looks at them in relation to their neighbors, both preceding and following. It\u2019s like reading both the left and the right [&#8230;]",
            "pubdate": "Sat, 02 Sep 2023 04:02:32 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "Deep Learning Applied to Physics and Fluids": {
            "url": "https://towardsai.net/p/machine-learning/deep-learning-applied-to-physics-and-fluids",
            "description": "Last Updated on September 2, 2023 by Editorial Team Author(s): Eduardo Vitalbrasil Originally published on Towards AI. Numerical simulations have been used for years to understand the behavior of physical systems; how the fluids interact with a structure, how a geometry is deformed under stress, or even the thermal distribution under heating conditions. Applied in the more diverse domains such as aero spatial, automobile, energy, etc., those calculations allow dimensioning prototypes and ensuring safe processes without having to build them. Notwithstanding, they can be computationally expensive and take many hours, days, or even weeks. That\u2019s where Machine Learning, and specifically Deep Learning, shines, abbreviating the processing time to mere minutes! Computational Fluid Dynamics simulations A common numerical simulation can describe physical systems by solving a set of Partial Differential Equations (PDE), which typically have the form: ???? represent s the differential operator over the domain \u03a9 \u2208 \u211d , bounds ????\u03a9 and parameters ???? . The solution ????(????, ????) of the system relies on spatial coordinates and time, with subscripts denoting partial derivatives. The set of equations can be solved by discretizing the physical domain into small parts (finite elements or finite volumes) to get a linearized system. This approach finds particular application in fluid dynamics. In fluid dynamics, the system is represented mainly by the Navier-Stokes equations, a set of laws with no analytical resolution to describe the behavior of every fluid based on the mass and force balances. In a simpler 2D form, they can be described as: Where ???? is the velocity along x-axis, ???? is the velocity in y, ???? is the pressure, ???? is the density and ???? is the viscosity. Computational Fluid Dynamics (CFD) simulations consist of resolving the discretized linearized system along with its boundary conditions, such as the pressure and velocity at the limits of the domain, by iterative multigrid solution methods. Direct methods are impractical for real-world applications, where the inversion of the matrix for a 3D Cartesian and equally spaced grid (i\u00b3 elements) achieves i\u2077 complexity. Even with efficient solvers working in an HPC parallel environment, the computational cost of such operations can achieve long hours and become detrimental for a dynamic engineering process. The solution? As we see more and more, AI! Surrogate models When a possible input-output relationship is present, AI arises as a candidate to model such behavior. This scenario aligns perfectly with CFD, where the geometric setup, parametrized as a grid and its elements, in addition to the boundary conditions, can be linked to the output: the physical fields (pressure, velocity, etc.) in each point of the grid. The models built can act as meshless solvers which can replace traditional simulators with a lower computational cost. In a general manner, we want to learn the mapping between the PDE parameters (????, ????, ????): ???? \u2208 \u211d\u207f and its solution ????(????, ????): ???? \u2208 \u211d\u207f . In other words, we aim to find the predictive function ????: (????, ????, ????) \u2192 ????(????, ????) where ???? is sometimes found to be constant (steady state analysis). Thus, we can imagine different ways to do that. Simplified models The easiest approach to model the relationship is to simplify it by reducing the dimensionality of the data. This method can be applied both to the input and the output. For instance, instead of using the full coordinates of grid points, we can represent the previously described geometry with a reduced set of parameters, denoted as ???? \u2208 N &#124; ???? &#60; n. A gear has a number of teeth, a primitive radius, a width, etc. For the output, a viable choice is a global performance metric denoted as s(????) \u2208 N. Examples are the forces acting on the prototype, the drag and lift coefficient, etc. The upside of the simplifications is that it allows us to apply more basic and faster AI models. Even a linear/polynomial regression could be used with no bigger issues to learn the function ????: k \u2192 ????(k). The downside is that, when reducing the dimensionality this way, there\u2019s an intrinsic loss of information, and the models become less generalizable when facing data outside of the design space. Volumetric models Instead of reducing the dimensionality of the data, we can opt to work with the original volumetric grid (???? \u2208 \u211d\u207f), which introduces greater complexity and requires the utilization of Deep Learning techniques. When dealing with an unstructured grid, a common approach involves interpolating it onto a uniform structured mesh. Essential features like freestream velocity and pressure can be embedded within each voxel, enabling corresponding predictions. Consequently, regions devoid of fluid are represented as null values, thereby encoding the geometry. This voxel-based representation facilitates the use of a technique commonly employed in image recognition tasks: convolution. Convolutional Neural Networks (CNNs) can thus extract local and global features via their filtering approach. Varying scales of feature extraction can be achieved by integrating different stages, leading to increasingly intricate models, including u-nets and auto-encoders/decoders. Instead of transforming the unordered data to the ordered shape of voxels/pictures, another solution involves actively encoding the coordinates. This permits data description in tabular format, where each point is associated with the corresponding simulation/example index. As we are going to see in the next section, this is what pytorch geometric does! While it is theoretically plausible to train and apply a model to each point, this approach normally fails to capture inter-node relationships critical for determining local information. Enter Graph Neural Networks, constituting another class of models tailored to address this limitation. Geometric models In CFD we are often interested in determining the physical fields not in the volume but in the surface. This prompts a consideration of model-building strategies. While the voxelization method outlined earlier has shown promising results, its application to represent sparse point clouds corresponding to the geometry requires the creation of a uniform structured grid. However, this becomes impractical for intricate geometries, as it leads to either unnecessary computational costs due to encompassing irrelevant information around the shape, or [&#8230;]",
            "pubdate": "Sat, 02 Sep 2023 02:02:27 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "How to Survive in the World of AI? Is your job at risk?": {
            "url": "https://towardsai.net/p/machine-learning/how-to-survive-in-the-world-of-ai-is-your-job-at-risk",
            "description": "Last Updated on September 2, 2023 by Editorial Team Author(s): Ashay Nayak Originally published on Towards AI. How to Survive in the World of AI? Is your job at risk? AI as a friend rather than an enemy!! Hi Reader!!! Is your job at risk? It\u2019s a question that haunts a lot of workers, and I am not talking in the context of the recent layoffs. I am talking about the scenario where someone else is doing your job and doing it better than you, not a person, not a coworker, but a software. I am talking about Artificial Intelligence. AI is creating a lot of buzz along with uncertainty and fear. Will AI tools replace you in the workforce? It\u2019s a question we must seriously consider because AI has arrived, it\u2019s just getting started, and the ball is now in our court. It will entirely depend on how we respond to AI and ensure our survival. Recent developments in AI show it is not an ordinary technology. AI is a general-purpose technology (which will be discussed later). You can build an incredible company in this extra-competitive market if you acknowledge the importance of general-purpose technology. But failing to do so, will throw you out of the market. In this article, let\u2019s try to understand What is a General-Purpose Technology? What case study of the past can we learn from to predict the future? How can you take advantage of this AI boom? GPTs (General-Purpose Technologies) are technological innovations that usually have effects across many industries and sectors. Examples of GPT include the internet, electricity, steam engines, and artificial intelligence. So, what makes technology a general-purpose technology? Here are the following criteria that are considered to term a technology a GPT: \u25cf Considerable increase in productivity and efficiency. \u25cf Frequently improving and evolving. \u25cf Wide range of utilization across different industries and sectors. \u25cf Indirect effects that benefit other industries and sectors. GPT has substantial potential to affect an entire economy at the global level. GPT has the power to destroy industries and simultaneously create some mind-blowing opportunities. A classic example of the same is the rise of the steam engine. The introduction of the steam engine revolutionized multiple industries and transportation across the world. Before the Industrial Revolution, textile production was a cottage industry where the workers used spinning wheels and handlooms in their homes without the use of electricity. But with the advancement in technology, steam-powered spinning and weaving machines started getting used in textile industries. The graph shown below represents the efficiency of the textile industries with the introduction of steam-powered machines. As shown, in the same amount of time, the steam-powered machine could produce up to 10,000 meters of yarn, while a skilled spinner could produce up to 100 meters of yarn. It required only two workers to operate the machine that could produce 10,000 meters of yarn per hour. Contrary to that, it needed 100 skilled workers to manufacture the same amount of yarn per hour. Hence, two low-skill workers with machines could outperform the 100 skilled workers without machines. Steam engines led to a big boom in the cotton trade and transportation in Britain. For example, after the steam engine train, the cotton mills could have easily been located 200 km away from the port, and even then, you could ship the cotton to the port at a much lower cost and high speed. Before the steam engine train, the cotton mills needed to be located near the port within a 50km range, and even then, transportation would be done by horses at a considerably slow speed. The introduction of modern production methods by the textile industry made it a dominant player in terms of the value of output and capital invested. Now, you might be thinking: Did the invention of the steam engine create jobs or kill them? As a result, the steam engine changed the way people worked. There was a shift in the nature of the jobs. Due to changes in technology, demand for technically skilled workers was increasing. The steam engine went on to drive the Industrial Revolution. It became the energy source for many machines, making it cheaper and easier to produce commodities in large amounts. At cheaper rates, consumers buy more, and the strong demand for products creates a strong demand for labor to produce them. Yes, the steam engine created jobs for those who were willing to change, learn, and upgrade their existing skills. But those who could not adopt these changes went jobless and bankrupt. History repeats itself. Take the example of Blockbuster; its inability to adapt to the Internet led it out of the market, while Netflix became a billion-dollar company. The world is changing, you can be a part of it or not, the choice is yours. Pretending things will be the same forever is a guarantee for disaster. Nothing lasts forever. How you adapt to changing times decides your fate. AI is a General-Purpose Technology. We have seen the example of a steam engine, what general-purpose technology can do? Irrespective of your profession, whether you are a software engineer, thumbnail designer, accountant, or artist, always be aware of changing trends across all industries. Neglecting a change only makes it worse. Embrace the change, and you will go on to last forever in this extra-competitive space. Like they say it\u2019s all about the survival of the fittest. Feel free to ask your doubts in the comments. Please clap, follow and share it with your friends if you find this helpful or if it is adding value to you. Connect with me on LinkedIn if you are looking for coding tips, interview preparation, and interview tips. Check out my other interview-oriented articles here. Thank You!!! Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related [&#8230;]",
            "pubdate": "Sat, 02 Sep 2023 00:02:26 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "Building Correlation Matrix With P-Values In Python": {
            "url": "https://towardsai.net/p/machine-learning/building-correlation-matrix-with-p-values-in-python",
            "description": "Last Updated on September 4, 2023 by Editorial Team Author(s): Adam Ross Nelson Originally published on Towards AI. Producing correlation output beyond the defaults in Python This member-only story is on us. Upgrade to access all of Medium. If you&#039;re a fan of the correlation Matrix, like I am, this article is for you. This article is especially for folks who use Python to generate, display, and analyze correlation matrices. Moreover, this article is for folks who, like me, perhaps came from other statistical analysis tools and who were spoiled by more extensive and informative output than you typically find in Python. Below is what I imagine I look like when I&#039;m angry and frustrated that the default tools in Python do not treat me quite as well&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 04 Sep 2023 04:02:29 +0000",
            "pubdate_parsed": [
                2023,
                9,
                4
            ],
            "email_sent": true
        },
        "The First General-Purpose Visual and Language AI: LLaVA": {
            "url": "https://towardsai.net/p/machine-learning/the-first-general-purpose-visual-and-language-ai-llava",
            "description": "Last Updated on September 4, 2023 by Editorial Team Author(s): Louis Bouchard Originally published on Towards AI. LLaVA: Bridging the Gap Between Visual and Language AI with GPT-4 This member-only story is on us. Upgrade to access all of Medium. Originally published on louisbouchard.ai, read it 2 days before on my blog! https://www.youtube.com/embed/Pn1B_L_zAwI GPT-4 is powerful, but did you know that some AIs are built entirely thanks to it? Yes, GPT-4 is so good that it can be used to generate good enough data to train other AI models. And not any model but better models than itself! Liu et al. just used GPT-4 to create a general-purpose language vision model called LLaVA, the first general-purpose model that understands and follows visual and language-based instructions. Basically, a model that has an&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 04 Sep 2023 02:02:27 +0000",
            "pubdate_parsed": [
                2023,
                9,
                4
            ],
            "email_sent": true
        },
        "Build Your First Autocorrection without Machine Learning": {
            "url": "https://towardsai.net/p/machine-learning/build-your-first-autocorrection-without-machine-learning",
            "description": "Last Updated on September 4, 2023 by Editorial Team Author(s): Thao Vu Originally published on Towards AI. A step-by-step guide to building your own spell checker. This member-only story is on us. Upgrade to access all of Medium. Photo by Markus Spiske on Unsplash Spell correction is everywhere. When I was writing this article, Grammarly is quietly helping me with the typos. When you input a query to an e-commerce website, it will first go to the correct phase to better match the desired items\u2019 title. Spell correction is no doubt essential for any written communication. It enhances our communication, maintains our professionalism and boosts our productivity. When considering building one, we may quickly come to the one-sizes-fit-all solution: deep learning. However, deep learning is only sometimes the optimal&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Mon, 04 Sep 2023 00:02:27 +0000",
            "pubdate_parsed": [
                2023,
                9,
                4
            ],
            "email_sent": true
        },
        "From Oppenheimer to Generative AI: Valuable Takeaways for Enterprises Today": {
            "url": "https://towardsai.net/p/machine-learning/from-oppenheimer-to-generative-ai-valuable-takeaways-for-enterprises-today",
            "description": "Last Updated on September 5, 2023 by Editorial Team Author(s): Emil Novakov Originally published on Towards AI. From Oppenheimer to Generative AI: Valuable Takeaways for Enterprises Today Explore the evolution of AI for enterprises as we draw parallels to Oppenheimer I spent 3 hours last weekend in the theaters watching the latest blockbuster \u2014 Oppenheimer. Even though I knew the entire storyline and how it ended, I was still at the edge of my seat, watching scene by scene, marveling at Christopher Nolan\u2019s reinterpretation. As I left the cinema, I began to wonder how AI today is akin to the Manhattan Project in Los Alamos. The landscape of innovation has evolved dramatically ever since the days of J. Robert Oppenheimer, the brilliant scientist behind it all. While this historical context may seem distant, the lessons drawn from Oppenheimer\u2019s approach to problem-solving and innovation are relevant for enterprises navigating this new era of Generative AI. As we traverse the realms of artificial intelligence in hopes of keeping up or leveraging them, Oppenheimer\u2019s principles can be a valuable guiding light to shape the strategies and practices of modern businesses. Image by Freepik AI Generator Embrace Curiosity and Interdisciplinary Collaboration, not Compartmentalization As Oppenheimer traveled from state to state to seek the best scientists in each field, you can see how his work was not confined to a single discipline. He needed physicists, mathematicians, engineers, and more. Oppenheimer saw the limits of compartmentalization, as repeated in the movie by Colonel Leslie Richard Groves, as a security strategy to isolate all departments early on and had to advocate for weekly discussions. Similarly, in today\u2019s enterprises, embracing interdisciplinary collaboration is crucial for AI\u2019s potential to unfold \u2014 data scientists, designers, domain experts, engineers, product developers, sales, marketing, and legal teams. All these different departments with diverse backgrounds must unite to unravel complex challenges. Developers who work on the product won\u2019t know exactly what clients think they need. Still, sales professionals who interact with clients daily will have that intel. This knowledge needs to be shared across teams, and this fusion of different perspectives drives creativity, innovation, and the development of cutting-edge AI solutions. Adopt AI earlier, not later Being 18 months ahead of competing projects gave Oppenheimer and his team a massive advantage in experimenting with and resolving complex challenges, which ultimately contributed significantly to their triumph. Businesses could also use the early adopter advantage in generative AI by integrating it across their value chain to develop unique products, boost efficiency significantly, and gain a competitive advantage in the market while establishing a solid brand. Not all your employees will be open to trying out these new skills. But suppose there is a group of them. In that case, enterprises should encourage that, set up a cross-team task force, and even take them off a few projects so that they can devote their time to discovering how generative AI can boost productivity. Sitting back and letting it play out won\u2019t get you anywhere. Seeing how AI is advancing now \u2014 1 month later could mean 1 year slower in company-wide adoption. Emulate a Growth Mindset What\u2019s a growth mindset? Oppenheimer\u2019s unwavering commitment to learning and growth led to his transformative contributions. Similarly, large corporations must foster a growth mindset that encourages continuous learning and adaptation. With the digital world moving so fast, the old tried, and tested ways no longer work today. Generative AI is an ever-evolving field, and organizations that prioritize upskilling, knowledge sharing, and staying updated on AI advancements are better positioned to leverage its potential effectively. Experimentation and Iteration as Catalysts for Breakthroughs Oppenheimer\u2019s scientific breakthroughs were born out of relentless experimentation and iteration. The Manhattan Project required significant resources and costs (USD 2 billion!) Although the return on investment took a long time, his grit and continuous trial and error resulted in a breakthrough. Enterprises can draw a parallel by adopting an office culture encouraging experimentation with Generative AI. Instead of banning ChatGPT and forcing curious employees to grind through time-consuming tasks, enterprises can foster a safe space for trial and error. Technology and AI companies also need such safe spaces so employees can feel comfortable failing fast, finding solutions, and refining their AI models. Of course, these iterations must be guided by data-driven insights, leading to refined solutions that drive operational efficiency and customer value. Safeguard intellectual property Despite being allies, the Manhattan Project didn\u2019t thoroughly discuss its discoveries with the Soviets to avoid any possible post-war fallout. Similarly, working with partners, suppliers, and the startup ecosystem in generative AI is crucial to finding the best solutions. Yet, enterprises must take care to safeguard their intellectual property. Strive for Ethical and Responsive AI Oppenheimer\u2019s legacy is a stark reminder of the dual nature of scientific discoveries \u2014 they can be harnessed both for progress and harm. In the realm of Generative AI, responsible development is paramount. Enterprises must prioritize ethical considerations, ensuring that AI technologies are designed and deployed in ways that align to help society and human well-being. Just as Oppenheimer grappled with the ethical implications of nuclear science, businesses today must tread carefully when navigating the moral complexities of AI. Key Takeaways Since I\u2019m not a movie critic, I can\u2019t pen down all the different cinematic techniques and more profound meanings within the movie. Yet, by reflecting on Oppenheimer\u2019s legacy, I found many interesting parallels to the use of Generative AI and its applications in enterprises. Just as Oppenheimer\u2019s pursuit of knowledge altered the course of history, corporations can shape their futures through AI innovation. By embracing curiosity, collaboration, ethics, growth, and creativity, enterprises can navigate the AI frontier with a greater purpose to drive transformative change. What are your thoughts? Connect and share them with me. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, [&#8230;]",
            "pubdate": "Tue, 05 Sep 2023 02:02:29 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "Throwing In The Data Science Job Search Towel": {
            "url": "https://towardsai.net/p/machine-learning/throwing-in-the-data-science-job-search-towel",
            "description": "Last Updated on September 5, 2023 by Editorial Team Author(s): Adam Ross Nelson Originally published on Towards AI. Here is how to know if it is too early to give up on the data science job search This member-only story is on us. Upgrade to access all of Medium. Job searching is hard. Not news. Going from one field to another is even harder. You\u2019ll never hear me say it\u2019ll be easy to take your career into data science. A core belief of mine is that it is hard to make that transition. If you updated your LinkedIn and didn\u2019t add 10\u201320 new connections, and also make an effort to initiate a conversation with those folks, did you really update your LinkedIn? To make the transition, you need the skills to be a data scientist, or the ability and willingness&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Tue, 05 Sep 2023 00:02:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "Exploring Large Language Models -Part 3": {
            "url": "https://towardsai.net/p/machine-learning/exploring-large-language-models-part-3",
            "description": "Last Updated on September 6, 2023 by Editorial Team Author(s): Alex Punnen Originally published on Towards AI. Fine-tuning, Model Quantisation, Low Ranked Adapters, Instruct Tuning and using LLMs to generate training data This article is written primarily for self-study. So it goes broadly and also deep. Feel free to skip certain sections based on your interests or to seek the area that interests you. Below are some of the questions that intrigued me or came up while trying to fine-tune LLMs. The article is an attempt to answer these and share this information with other curious. Since LLMs are based on NeuralNet with Loss function, is not all training of LLMs supervised training? Why is it termed usually as unsupervised training?Can you train an LLM in a very short sentence to illustrate how LLM training works in practice?What is Masked and Causal LM?Can you explain the intuition behind Transformer Architecture in a single picture?What exactly is it meant by unsupervised training in LLM?Why does the main architect of ChatGPT \u2014 Ilya Suverskar think of unsupervised training as the Holy Grail of machine learning?What is meant by the Emergence/ Understanding of LLMs? What are the use cases of LLMs?Why are LLMs best suited as productivity assistants?What is the Vector DB/Embedding pattern of information retrieval?Can LLMs be used for things other than textual tasks? What is Causal reasoning?What is the problem with LLMs?Why do minds like Yan LeCun think current LLMs are hopeless?Are LLMs Explainable, how can they be effectively used if they are not? What is the need to fine-tune/re-train LLMs?Why is it difficult to train LLMs?How do Quanitsation and LoRA help in training large LLMs?How does Quantisation and LoRA work?What is an effective way to fine-tune pre-trained LLMs?What is Instruct Tuning?What is Self Instruct? How can we generate a high-quality training dataset for Instruct Tuning? Yet to answerCan you show how LLMs of varying capability can be hierarchically structured to create a complex automation with causal reasoning?Why are we aiming to create human-like intelligence from LLMs or neural nets? Why does this seem eerily similar to creating bird-like flight back in time before the invention of the fixed-wing plane? Since the article is quite long, I have structured this into three parts for better readability. Part 1 will discuss the evolution of LLM training. The intention is to set the context for us to understand the magic, or more technically &#8211;emergence, that starts to happen when the model size increases above a threshold and when trained with huge data. The deep-dive sections illustrate these concepts in greater detail and depth, though they are also easy to follow by most programmers. Part 2 will briefly discuss the popular use cases of LLMs, personal assistants, and chatbots with custom data via information retrieval patterns (vector space search with LLM augmentation). We will also explore seeds on how the mental model and NLU of models could become more powerful use cases. In this context, we will explore one main limitation of the LLM model by contrasting the strengths of supervised training with a weakness of the LLM models \u2014 the lack of Explainability or difficulty in determining facts vs. hallucinations. We will explore how such systems have been very effectively used in computer systems by a hierarchy of controls, unreliable systems made reliable by a higher level control -our daily use of ChatGPT for example and how it can be extended to other use cases. Part 3 will discuss some concepts related to training the LLMs on custom domains. We are targeting the domain understanding part in this, and how that is much more powerful than simpler vector space information retrieval patterns. This is easy in toy examples but practically not very easy with real data. We will explore how Quantisation techniques have opened up very large LLMs to the world, and how this, coupled with the concepts of reducing training parameters, has democratized LLM fine-tuning. We will explore the main technique of effective fine-tuning \u2014 Instruct tuning, and how to solve the biggest practical problem of Instruct tuning \u2014 the unavailability of quality Instruction training dataset with all the concepts we have gone through this far. Future sections will discuss the concept of leveraging the understanding part of LLMs and using the hierarchy of controls in leveraging these powerful systems for augmenting AI/ML systems. Fine Tuning on Custom Domain Data All the popular models like GPT3/3.4/4 and LLAMA2 are trained primarily on the data scraped from the internet. Common Crawl, WebText, GitHub, StackOverflow etc: These are massive datasets of text and code that are crawled from the public web and a few curated like the QA dataset SQAD. The worldview and information the model has learned are also based on this data. However, this means that if we have some domain-specific data that the model has not seen, then it won\u2019t be able on its own to answer questions related to such data in case of Closed Book QA use-case or any other use case that depends on the specific domain data. For example, most online portals are adding virtual assistants for their customers, banks, e-commerce, customer support etc. And a huge if not the majority of data in the world still lives outside of the internet in enterprises. We have seen in Part 2 how LLMs can help address information retrieval use cases based on Vector space embeddings. But what if our use case is more high level? It needs domain \u201cunderstanding\u201d, maybe some higher level reasoning tasks. This is where fine-tuning with custom data comes into play. I am not able to provide a use case where higher-level reasoning can be used. There are a few simpler ones, like training on custom issues and then asking it to reason on similar issues and possible solutions, but these are as of now not tested. So let\u2019s stick with a simpler use-case Closed-Book QA &#8211; the model answers questions based on the knowledge it internally has for now. source Can Generative [&#8230;]",
            "pubdate": "Wed, 06 Sep 2023 02:02:23 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "Exploring Large Language Models -Part 2": {
            "url": "https://towardsai.net/p/machine-learning/exploring-large-language-models-part-2",
            "description": "Last Updated on September 6, 2023 by Editorial Team Author(s): Alex Punnen Originally published on Towards AI. Using LLMs effectively: Information retrieval, Personal assistants, Causal Reasoning Agents, Explainability, and hierarchical control-based deployment. This article is written primarily for self-study. So it goes broadly and also deep. Feel free to skip certain sections based on your interests or to seek the area that interests you. Below are some of the questions that intrigued me or came up while trying to fine-tune LLMs. The article is an attempt to answer these and share this information with other curious. Since LLMs are based on NeuralNet with Loss function, is not all training of LLMs supervised training? Why is it termed usually as unsupervised training?Can you train an LLM in a very short sentence to illustrate how LLM training works in practice?What is Masked and Causal LM?Can you explain the intuition behind Transformer Architecture in a single picture?What exactly is it meant by unsupervised training in LLM?Why does the main architect of ChatGPT \u2014 Ilya Suverskar think of unsupervised training as the Holy Grail of machine learning?What is meant by the Emergence/ Understanding of LLMs? What are the use cases of LLMs?Why are LLMs best suited as productivity assistants?What is the Vector DB/Embedding pattern of information retrieval?Can LLMs be used for things other than textual tasks? What is Causal reasoning?What is the problem with LLMs?Why do minds like Yan LeCun think current LLMs are hopeless?Are LLMs Explainable, how can they be effectively used if they are not? What is the need to fine-tune/re-train LLMs?Why is it difficult to train LLMs?How do Quanitsation and LoRA help in training large LLMs?How does Quantisation and LoRA work?What is an effective way to fine-tune pre-trained LLMs?What is Instruct Tuning?What is Self Instruct? How can we generate a high-quality training dataset for Instruct Tuning? Yet to answerCan you show how LLMs of varying capability can be hierarchically structured to create a complex automation with causal reasoning?Why are we aiming to create human-like intelligence from LLMs or neural nets? Why does this seem eerily similar to creating bird-like flight back in time before the invention of the fixed-wing plane? Since the article is quite long, I have structured this into three parts for better readability. Part 1 will discuss the evolution of LLM training. The intention is to set the context for us to understand the magic, or more technically &#8211;emergence, that starts to happen when the model size increases above a threshold and when trained with huge data. The deep-dive sections illustrate these concepts in greater detail and depth, though they are also easy to follow by most programmers. Part 2 will briefly discuss the popular use cases of LLMs, personal assistants, and chatbots with custom data via information retrieval patterns (vector space search with LLM augmentation). We will also explore seeds on how the mental model and NLU of models could become more powerful use cases. In this context, we will explore one main limitation of the LLM model by contrasting the strengths of supervised training with a weakness of the LLM models \u2014 the lack of Explainability or difficulty in determining facts vs. hallucinations. We will explore how such systems have been very effectively used in computer systems by a hierarchy of controls, unreliable systems made reliable by a higher level control -our daily use of ChatGPT for example and how it can be extended to other use cases. Part 3 will discuss some concepts related to training the LLMs on custom domains. We are targeting the domain understanding part in this, and how that is much more powerful than simpler vector space information retrieval patterns. This is easy in toy examples but practically not very easy with real data. We will explore how Quantisation techniques have opened up very large LLMs to the world, and how this, coupled with the concepts of reducing training parameters has democratized LLM fine-tuning. We will explore the main technique of effective fine-tuning \u2014 Instruct tuning, and how to solve the biggest practical problem of Instruct tuning \u2014 the unavailability of quality Instruction training dataset with all the concepts we have gone through this far. Future sections will discuss the concept of leveraging the understanding part of LLMs and using the hierarchy of controls in leveraging these powerful systems for augmenting AI/ML systems. One primary use case is Productivity enhancement \u2014 Smart Assistant. This is an important and widely usable pattern for LLMs.This paper The Economic Potential of Generative AI -The Next Productivity Frontier (June 2023) by McKinsey&#38; Company has projections on how this aspect of LLMs, applied in various formats can alter current work in different sectors would add trillions to the world economy. Before we go over the specifics, there was a recent talk in which the author talks about how more reliable systems can be built from less reliable systems \u2014 quoting from the famous TCP/IP stack design. There is a layered design where the un-reliable/lossy IP layers are made reliable by the transmission control and retransmission logic (in case it detects packet loss) of the TCP layer. The Assistant type of use-cases is also layered, where the weaknesses of LLMs like hallucinations are overcome by a higher and better control (usually a human) It could also be a more cognitive model over lesser models. This is what makes this use case so widespread and robust. Software Engineers using Github Co-pilot is a classic example. The model inference is paired with better control who can effectively use the output, take the positives and fine-tune or discard the negatives (errors, hallucinations). The more skilled the human is, the more efficiently he/she can use these models. The high-efficiency gains of this approach as programming or a domain assistant are well known in the very short time since its introduction. The same is true when these assistants are developed for other fields, a recent example being Med-Palm2 by Google and its uncanny ability to help doctors in the medical field. [&#8230;]",
            "pubdate": "Wed, 06 Sep 2023 00:01:21 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "Prompt Engineering to Leverage In-Context Learning in Large Language Models": {
            "url": "https://towardsai.net/p/machine-learning/prompt-engineering-to-leverage-in-context-learning-in-large-language-models",
            "description": "Last Updated on September 7, 2023 by Editorial Team Author(s): Salvatore Raieli Originally published on Towards AI. How to modify your text prompt to obtain the best from an LLM without training This member-only story is on us. Upgrade to access all of Medium. Photo by Steven Lelham on Unsplash Large Language Models are more and more used and their skills are surprising. Part of their success is their ability to learn from a few examples, a phenomenon known as in-context learning; in the previous article, we discussed in detail what is it and from where it originates, now we will learn how to harness the true power. What is and how does it work what makes Large Language Models so powerful towardsdatascience.com This article is divided into different sections, for each section we will answer these&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 07 Sep 2023 04:02:24 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "Ways to Iterate JavaScript Arrays": {
            "url": "https://towardsai.net/p/machine-learning/ways-to-iterate-javascript-arrays",
            "description": "Last Updated on September 7, 2023 by Editorial Team Author(s): Vivek Chaudhary Originally published on Towards AI. The objective of this article is to understand different possible ways to loop through JavaScript Arrays. Declare array const arr=[\u2018kiwi\u2019,\u2019dragon\u2019,\u2019orange\u2019,\u2019apple\u2019,\u2019pomegranate\u2019];const sal=[2200,5000,2100,1500,3700,4300];let sal_incr=[] for() loop for loop is an iterative statement, it checks for some conditions and then executes a block of code repeatedly as long as those conditions are met. console.log(\u201cArrays for loop\u201d)for (let i=0;i&#60;arr.length;i++){ console.log(arr[i])} Output: for..in loop for\u2026in loop is an easier way to loop through arrays as it gives us the key which we can now use to get the values from our array. console.log(\u201cArrays for..in loop\u201d)for (let i in arr){ console.log(arr[i])} Output: for..of loop for\u2026of Loop iterates over iterables, but unlike for..in which gets keys, for..of gets the element itself. console.log(\u201cArrays for..of loop\u201d)for (let item of arr){ console.log(item)} Output: forEach() loop forEach() method calls a function (a callback function) once for each array element. console.log(\u201cArrays forEach() loop\u201d)arr.forEach((i)=&#62;{ console.log(i)}) Output: Another example. const sal=[2200,5000,2100,1500,3700,4300];let sal_incr=[]//write a function to implement salary incrementsal.forEach(function(sal){ sal_incr.push(sal+sal*.05)})//print the incremented salarysal_incr.forEach((inc)=&#62;{ console.log(`incremented salary ${inc}`)}) Output: while() loop while loop is used to evaluate a condition that is enclosed in parenthesis (). If the condition is true, the code inside the while loop is executed.If it is false, the loop is terminated. console.log(\u201cArrays while loop\u201d)let i=0; //loop variablewhile (i&#60;arr.length){ console.log(arr[i]) i++;} Output: do\u2026while() loop do\u2026while loop is nearly identical to the while loop, except that it executes the body first before evaluating the condition for subsequent executions. This means that the loop\u2019s body is always executed at least once. console.log(\u201cArrays do while loop\u201d)let j=0;do { console.log(arr[j]); j++;}while (j&#60;arr.length); Output: map() map() allows us to iterate over array and modify its elements. The map() method creates a new array by performing a function on each array element. console.log(\u201cArrays map()\u201d);arr.map((item) =&#62;{ console.log(item)}) Output: Same salary increment example using map() let incr= sal.map(function(sal) { return sal+sal*.05;});//iterate over incremented salincr.forEach((incr) =&#62;{ let msg=`incremented salary ${incr}` console.log(msg)}); Output: Summary: define an empty array and non-empty array. 7 ways to loop over arrays. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Thu, 07 Sep 2023 02:02:20 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "AI Image Fusion and DGX GH200": {
            "url": "https://towardsai.net/p/machine-learning/ai-image-fusion-and-dgx-gh200",
            "description": "Last Updated on September 7, 2023 by Editorial Team Author(s): Luhui Hu Originally published on Towards AI. From pixels to panoramas: Inside AI measuring &#38; stitching and data-center AI powerhouse DGX GH200 AI Supercomputer (1 GPU, heavy as 4 elephants) In the realm of Computer Vision (CV), the ability to stitch together partial images and measure dimensions isn\u2019t just an advanced trick \u2014 it\u2019s a vital skill. Whether you\u2019re creating a panoramic view from your smartphone, measuring the distance between objects in a surveillance video, or analyzing scientific images, both image stitching and measuring play a crucial role. This article aims to demystify these two fascinating aspects of CV. Then I\u2019ll share about cloud AI infra, data-center AI powerhouse. The Art of Stitching Image stitching isn\u2019t just an algorithmic challenge; it\u2019s an art form. Stitching algorithms strive to seamlessly combine multiple images into one, expansive output, free from seams, distortion, and color inconsistency. Open-source methods vary in complexity from traditional feature-matching algorithms like SIFT and SURF to deep learning models like DeepStitch. Traditional vs. Deep Learning Traditional Methods: Algorithms like SIFT (Scale-Invariant Feature Transform) and SURF (Speeded-Up Robust Features) use key points and descriptors to find overlapping regions between images. These methods are fast and work well for simple use cases but can struggle in more complex scenes. Deep Learning Models: Solutions like DeepStitch go beyond by using neural networks to find optimal stitching points, providing higher accuracy, especially in complex scenes. Below are available open-source algorithms or libraries for image stitching and panoramas. Open-source algorithms and AI models for image stitching (collected by the author and regenerated by GPT-4) Measuring in a 2D World Image stitching allows us to expand our visual horizon, but what about understanding the world within that field of vision? That\u2019s where image measuring comes in. From using simple Euclidean distance calculations in a calibrated setup to leveraging deep learning models that can identify and measure objects, the techniques are diverse. Simple to Complex Calibration Methods: Techniques like camera calibration provide a way to relate pixel dimensions to real-world dimensions. Once calibrated, even simple geometric formulas can yield accurate measurements. Object Detection and Tracking: Deep learning models like YOLO or SSD are proficient at identifying objects in both images and real-time videos, paving the way for automated measuring. Below are available open-source methods for measuring and photogrammetry. Open-source methods for photogrammetry (collected by the author and regenerated by GPT-4) Stitching and Measuring: Two Sides of the Same Coin You might wonder why we\u2019re discussing both stitching and measuring together. The reason is they often go hand-in-hand. For example, in surveillance applications, a stitched panoramic view of a location can be used to track and measure the distance between multiple targets accurately. In medical imaging, stitched images from different angles can provide a more comprehensive view, facilitating more precise measurements. TL;DR for CV Pixels Whether you\u2019re a hobbyist, a researcher, or someone intrigued by the applications of CV, both stitching and measuring are integral techniques to understand. While traditional algorithms offer a quick and straightforward approach, the advent of deep learning has opened the door to unprecedented levels of accuracy and complexity. It\u2019s a thrilling time to delve into the world of CV, where the boundary between the pixel and the panorama continues to blur, offering us a clearer view of the bigger picture. The field is advancing at a rapid pace, and it\u2019s crucial to stay updated with the latest algorithms and methodologies. So go ahead, stitch your way through panoramas, and measure your world, one pixel at a time! AI Giant Foundation: DGX GH200 After leveraging AI/CV for advanced stitching and measuring capabilities, we also recognize the foundational role of GPUs in powering our AI-driven solutions. In this transformative age of AI, Nvidia\u2019s DGX GH200 AI Supercomputer stands as a monumental advancement. This computational behemoth, with a single GPU as heavy as four elephants, redefines what\u2019s possible. Far from being just a large machine, its unparalleled capability offers a stunning 144TB of shared memory across 256 NVIDIA Grace Hopper Superchips (GH200). This empowers developers with nearly 500x more memory, enabling the creation of complex, large-scale models to tackle today\u2019s most challenging problems. Truly, it\u2019s not just a machine, but the future of AI materialized. Towards GH200 NVIDIA GH200 Grace Hopper Superchip integrates NVIDIA\u2019s Grace and Hopper architectures through NVLink-C2C, offering a coherent CPU+GPU (H100) memory model optimized for AI and HPC applications. As the ninth-generation data center GPU, H100 Tensor Core introduces a new Transformer Engine, boasting up to 9X faster AI training and 30X faster AI inference compared to its predecessor, A100. In a strategic rebranding move in May 2020, Nvidia transitioned its Tesla GPGPU line to Nvidia Data Center GPUs to sidestep brand confusion with Tesla automobiles. Originally competing with AMD\u2019s Radeon Instinct and Intel\u2019s Xeon Phi, these GPUs supported CUDA or OpenCL programming and were pivotal in deep learning and computational tasks. Spanning ten generations, each with distinct micro-architectures \u2014 Tesla, Fermi, Kepler, Maxwell, Pascal (P100), Volta (V100), Turing (T4), Ampere (A100, A40), Hopper (H100), and Ada Lovelace (L40) \u2014 Nvidia\u2019s data center GPUs have consistently pushed the envelope in deep learning and scientific computing. DGX GH200 vs GH200 vs H100 What&#039;s the difference between a DGX GH200, a GH200, and an H100? gpus.llm-utils.org NVIDIA Announces DGX GH200 AI Supercomputer NVIDIA today announced a new class of large-memory AI supercomputer &#8211; an NVIDIA DGX\u2122 supercomputer powered by NVIDIA\u00ae\u2026 nvidianews.nvidia.com NVIDIA Grace Hopper Superchip A breakthrough accelerated CPU designed from the ground up for giant-scale AI and HPC applications. www.nvidia.com NVIDIA Grace Hopper Superchip Data Sheet The NVIDIA Grace\u2122 Hopper\u2122 architecture brings together the groundbreaking performance of the NVIDIA Hopper GPU with the\u2026 resources.nvidia.com Nvidia Tesla &#8211; Wikipedia Toggle the table of contents From Wikipedia, the free encyclopedia Manufacturer Nvidia Introduced May 2, 2007;16 years\u2026 en.wikipedia.org NVIDIA Supercomputing Solutions Learn how NVIDIA Data Center GPUs- for training, inference, high performance computing, and artificial intelligence \u2026 www.nvidia.com Join thousands of data leaders [&#8230;]",
            "pubdate": "Thu, 07 Sep 2023 00:02:21 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "Simplifying Your Exploratory Data Analysis With These Four (4) Packages": {
            "url": "https://towardsai.net/p/machine-learning/simplifying-your-exploratory-data-analysis-with-these-four-4-packages",
            "description": "Last Updated on September 8, 2023 by Editorial Team Author(s): Francis Adrian Viernes Originally published on Towards AI. Four Essential Tools Every Data Scientist Should Have in Their Toolbox This member-only story is on us. Upgrade to access all of Medium. Photo by Adam \u015amigielski on Unsplash It\u2019s a great time to be a data scientist! What takes a lot of time to put together can be automated now, leaving much room to improve insights-creation and the machine learning model design. A lot has been written about these tools already out there, and I wanted to add more value by first limiting my choice of tools, and also, to incorporate my unique take and experience into using these libraries. As we have to be methodical about it, we\u2019ll quickly see that we&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 08 Sep 2023 04:02:26 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "How does Stable Diffusion Really Work? An Intuitive Explanation": {
            "url": "https://towardsai.net/p/machine-learning/how-does-stable-diffusion-really-work-an-intuitive-explanation",
            "description": "Last Updated on September 8, 2023 by Editorial Team Author(s): Oleks Gorpynich Originally published on Towards AI. \u201cStable Diffusion\u201d models, as they are commonly known, or Latent Diffusion Models as they are known in the scientific world, have taken the world by storm, with tools like Midjourney capturing the attention of millions. In this article, I will attempt to dispel some mysteries regarding these models and hopefully paint a conceptual picture in your mind of how they work. As always, this article won\u2019t reach into the pit of details, but I will provide some links at the end that do. The paper, which lies as the main information source behind this article, will be the first link included. Figure 1 (A Midjourney generated image) Motivation There are a few approaches to image synthesis (creating new images from scratch), and they include GANs, which perform poorly on diverse data; Autoregressive Transformers, which are slow to train and execute (similar to LLM transformers generating text token by token, they generate images patch by patch), and diffusion models which by themselves counter some of these issues, but yet remain computationally expensive. It still takes hundreds of CPU days to train these, and actually utilizing the model involves running it step by step to produce a final image, which also takes considerable time and compute. Quick Overview of Diffusion Models To understand how Diffusion models work, let\u2019s first look at how they are trained, which is done in a slightly nonintuitive way. We begin by applying noise to an image repeatedly, which creates a \u201cMarkov chain\u201d of images. In such a way, we are able to get some number T of repeatedly more noisy images from a singular original image. Our model then learns to predict the exact noise that was applied at a certain time step, and we can use its output to \u201cdenoise\u201d the image at that time step. This effectively allows us to go from image T to image T-1. To reiterate, the model is trained by giving it the image with noise applied at some time T, and the time T itself, and the output is what noise was applied to bring it from time T-1 to T! Figure 2 (source) Once we have such a model trained, we can repeatedly apply it to random noise to produce a new, novel image. The great article by the wonderful Steins where the above image is from explains this in more depth. UNet Model The model that is commonly used to predict the noise at each time step is a \u201cUNet\u201d architecture model. This is a type of architecture that repeatedly applies Convolutional layers, pooling layers, and skip connections to first downscale an image but increase depth (feature maps), and then transposed convolutions are used to up-sample the feature maps back to the original image dimensions. Here is a great article by Maur\u00edcio Cordeiro that explains this model in greater depth. Issues This is where the issues of traditional diffusion models come out. The first issue is training time. Assuming we have N images, and we apply noise to an image T times, that is N*T possible inputs to our model. And often times, these are high-resolution images, and each input would incorporate the large image dimensions. After all, we don\u2019t want Midjourney to produce pixel art\u2026 And then, assuming we do have our model trained, to get back from random noise to an image, we must apply the weights T times repeatedly! Remember, our model is only able to give us the image from the previous time step, and we must get from time step T to time step 0. The other issue lies in the utility of such a model. If you noticed, input text wasn\u2019t mentioned once yet; however, we are all used to implementations converting text to images, not random noise to images. So, how and where exactly does this feature come in? Latent Diffusion Models A key idea that would fix these issues is splitting our model into two separate ones. The first model is trained to encode and decode images into a \u201clatent space\u201d which retains a lot of the \u201cperceptual\u201d details behind the image, but reduces the data dimensions. As a way to intuitively understand this, one can think of some noise in images that we really don\u2019t have to learn (a blue sky with pixels slightly changing their hue). The second model is the actual Diffuser, which can convert this latent space representation into an image. However, this Diffuser has a special modification that allows it to \u201cunderstand\u201d and be directed by inputs from other domains, such as text. Perceptual Image Compression Let\u2019s begin with the first model \u2014 the image encoder/decoder. Remember, the idea is to prepare images for the actual Diffuser in such a way that important information is preserved while dimensions are decreased. This compression model is actually called an \u201cautoencoder\u201d, and again this model learns to encode data into a compressed latent space and then decode it back to its original form. The goal of such a model is to minimize the difference between the input and the reconstructed output. For our loss function, we use two components. Perceptual Loss \u2014 Our goal is to minimize the differences in image features (such as edges or textures), as opposed to pixel differences between the original and decoded versions. There are existing tools that can extrapolate these from images, and we can use these. Patch-based Adversarial Objective\u200a\u2014\u200aA GAN (check out my previous article on different types of models) whose goal is to enforce local realism, analyzing the image patch by patch and classifying whether a certain patch is real or fake. This has the additional benefit of avoiding blurring, as what we are optimizing for isn\u2019t pixel difference but feature difference. This means that if our model produced an image that is slightly different in pixel coloring but still retains the same \u201cfeatures\u201d, it won\u2019t be penalized much and this is [&#8230;]",
            "pubdate": "Fri, 08 Sep 2023 02:02:21 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Explaining Attention in Transformers [From The Encoder Point of View]": {
            "url": "https://towardsai.net/p/machine-learning/explaining-attention-in-transformers-from-the-encoder-point-of-view",
            "description": "Last Updated on September 8, 2023 by Editorial Team Author(s): Nieves Crasto Originally published on Towards AI. Photo by Devin Avery on Unsplash In this article, we will take a deep dive into the concept of attention in Transformer networks, particularly from the encoder\u2019s perspective. We will cover the following topics: What is machine translation? Need for attention. How is attention computed using Recurrent Neural Networks (RNNs)? What is self-attention, and how is it computed using the Transformer\u2019s encoder? Multi-headed attention in the Encoder. Machine Translation We will look at Neural machine translation (NMT) as a running example in this article. NMT aims to build and train a single, large neural network that reads a sentence and outputs a correct translation. This is achieved using sequence-to-sequence models, like Recurrent Neural Networks (RNNs), where you have a sequence as an input to the model and it produces another sequence as the output. Figure 1: Image courtesy https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ Figure 1 shows an example of French to English-translation. The model contains two parts: the encoder and the decoder. The encoder will process the sentence word by word (technically token by token as per Natural Language Processing (NLP) terminology). The encoder produces a context that is fed into the decoder. The decoder will then produce the output one word at a time. Figure 2: Image courtesy https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ To further illustrate in Figure 2, the encoder produces a hidden state at each time instance, and the last hidden state (hidden state #3) is fed as the decoder input. Processing a sentence word-by-word can have detrimental effects, especially as the sentence gets long. The last hidden state of the sentence might not be able to encode all the necessary information, which can result in forgetting the beginning of the sentence. This a well-known issue that RNNs have faced. There have been various ways proposed to overcome this; Long Short Term Memory (LSTM) being one of them. However, each of these methods has its share of pros and cons. Attention was proposed as a way to address this problem (Bahdanau et al). What is attention? Figure 3: Image courtesy https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ In Figure 3, let\u2019s consider all three hidden states produced by the encoder. Instead of just relying on the last hidden state, the decoder now has access to all the hidden states produced by the encoder. The decoder generates output one word at a time, hence, we need a mechanism that informs the decoder which hidden state to prioritize to produce the output at each time step. For instance, to generate the first word \u201cJe\u201d, hidden state #1 will be most important, for second word \u201csuis\u201d, hidden state #2 is more important, and so on. Basically, at each time step, we need a different weighting scheme for the hidden states. This will tell the decoder which part of the input sentence it needs to focus on, in order to produce the output. In short, attention can be formulated as a weighted sum of the hidden states. The above sentence \u201cJe suis etudiant\u201d is pretty straightforward with a one-to-one mapping between the words for the input and output sentences. In the sentence below (Figure 4), we observe for the words \u201cEuropean Economic Area\u201d, the mapping of the words from France to English is reversed. In such cases, attention proves important in order to learn the correct mapping of words from one language to another. Figure 4: Image courtesy https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ To summarize, the encoder processes the sentence word-by-word and stores the corresponding hidden states. These hidden states are then fed to the decoder where the attention mechanism is applied. Note: The attention weights are changed per time-step. Figure 5: Image courtesy https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/ Self-Attention Attention is a weighing scheme to learn the mapping between input and output sequence, i.e. which part of the input is going to be important to produce the output at the current time step. Now, let\u2019s look at the sentences below. Figure 6: Image courtesy https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html We need to know what does \u201cit\u201d refer to. Is it street or animal? This is crucial, especially in translating English into a gendered language, like French. Self-attention is a means to encode the relationship between words in the input sentence. In the first sentence in the example above, we look at all the words in the sentence and encode \u201cit\u201d in such a way that gives more weight to either animal or street than the other words. Now, let\u2019s look at the Transformer Architecture to understand how self-attention is implemented. Transformer Architecture The first transformer was introduced in a paper in 2017. As it was developed for machine translation, it has an encoder and a decoder architecture. The encoder and decoder are made up of stacks of encoders and decoders, respectively. Figure 7: Transformer Architecture (https://arxiv.org/abs/1706.03762) We are going to focus on the Multi-Head Attention block of the Encoder. To begin with, we generate vectors for each word (token) in a sentence using the word2vec model. The model takes a word as input and produces a vector that represents the meaning of the word. The vectors generated by the word2vec model tend to put words that are similar in meaning to be closer in the vector space, i.e. the words \u201cchair\u201d and \u201ctable\u201d would be closer together compared to, let\u2019s say \u201cchair\u201d and \u201ctiger\u201d. These vectors are then fed into the attention module. How is self-attention computed? (Query, Key, Value) Previously, we calculated attention as a simple weighted summation of the hidden states in the RNN. Here, we are going to compute self-attention in a different way, using Query, Key, and Value. This is based on the concept of databases, where you have a lookup table, consisting of a key and a corresponding value. When someone queries the database, you match the query to the key and get some value based on the match. Let\u2019s consider a small database (see Table 1 below) with three keys: Apple, banana, chair, and a value associated with each key (10, 5, [&#8230;]",
            "pubdate": "Fri, 08 Sep 2023 00:02:20 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Satellite Data, Bushfires and AI: Safeguarding Wine Industry Amidst Climate Challenges": {
            "url": "https://towardsai.net/p/machine-learning/satellite-data-bushfires-and-ai-safeguarding-wine-industry-amidst-climate-challenges",
            "description": "Last Updated on September 11, 2023 by Editorial Team Author(s): Magdalena Kortas Originally published on Towards AI. Bushfires, smoke, droughts\u2026 As you prepare to enjoy a delightful sip from your glass of Australian S\u00e9millon this afternoon, take a moment to reflect on the remarkable journey of resilience it has undertaken before gracing your table. You can also read this article on Kablamo Engineering Blog. THE CLIMATE CHALLENGE: THE INTERSECTION OF CLIMATE CHANGE AND WINE PRODUCTION Ranked as the 5th largest global wine exporter, Australia holds a prominent place in the world of wine. The Hunter Valley, Australia\u2019s oldest wine-producing region situated just a couple of hours north of Sydney, is facing a substantial challenge. According to Wine Australia\u2019s Climate Atlas, this region is anticipated to experience an average temperature rise of 2.3 degrees Celsius over the next 50 years. This brings unpredictable weather patterns and an escalated risk of bushfires driven by the intensifying heat. The Hunter Valley is already confronted with an increasing vulnerability to bushfires, a threat that magnifies in the face of climate change. The risk doesn\u2019t solely arise from direct fire impact. Beyond the vineyards that are directly impacted by flames, the danger comes as well from smoke emanating from nearby blazes. \u201cSmoke taint,\u201d a phenomenon arising when smoke particles adhere to grape skins, compromises the quality of wine produced from these grapes, leading to substantial harvest losses. As the El Ni\u00f1o phenomenon approaches in the summer of 2023, there is a dual concern of record-breaking warmth and extreme aridity. Elevated fuel accumulation, dryness, fire-conducive weather, and lightning activity collectively heighten the probability of frequent bushfires. Consequently, the convergence of drought, parched vegetation, and unprecedented heat could imperil the wine industry. Mitigating such risks necessitates effective fire prevention strategies, precise risk assessment, and strategic hazard reduction efforts. NATURE\u2019S WATCHFUL EYE: HARNESSING SATELLITE DATA FOR LAND HEALTH ASSESSMENT Satellites play a pivotal role in the toolkit of scientists, enabling them to monitor Earth\u2019s atmosphere, terrain, and oceans. The Sentinel-2, a component of the European Copernicus Programme named in honor of Polish astronomer Nicolaus Copernicus, is an Earth observation mission that captures optical images with a high spatial resolution (ranging from 10 meters to 60 meters) over both land and coastal waters. With a constellation of two polar-orbiting satellites, Sentinel-2 provides data every 5 days. Sentinel-2 leverages visible, near-infrared, and shortwave infrared sensors across 13 spectral bands. Here, a color composite combines a few of the spectral bands \u2014 visible red, green and blue bands \u2014 with the corresponding red, green and blue channels, resembling what you would see with the human eye. Observed region in Hunter Valley in July 2019 These 13 bands facilitate the computation of indices that estimate vegetation health, detect changes in the landscape, and even estimate the risk of bushfires. One of the invaluable indices derived from Sentinel-2\u2019s spectral bands is the Enhanced Vegetation Index (EVI). Tailored to enhance the visibility of vegetation while minimizing atmospheric interference, EVI offers insights into vegetation health. Healthy, green, and hydrated vegetation corresponds to higher EVI values, while drier, less healthy vegetation, indicative of bushfire risk, corresponds to lower EVI values. An illustrative divergence is visible in the comparison between unhealthy and dry vegetation during the 2019\u201320 Australian bushfire season (Black Summer)and flourishing vegetation in December 2021. Detecting drought in January 2020 (on the left) using the EVI vegetation index Yellow means very healthy vegetation while dark green means unhealthy. EVI provides a quantitative measure of vegetation health, allowing wineries to track the overall condition of their entire vineyards, as opposed to individual vines. This can help identify early signs that might not be immediately obvious to the naked eye. By tracking EVI trends over time and comparing them to historical data, we can identify drought conditions early and alert vineyard managers to take appropriate actions. By analyzing EVI alongside soil moisture data, we can develop irrigation strategies that ensure efficient water use and prevent over- or under-irrigation. EVI data can also detect early signs of potential diseases affecting vineyards \u2014 unhealthy vegetation might indicate the presence of pests or diseases. PIXELS TO PRECISION: REFINING ANALYSIS: AI-POWERED EXAMINATION OF INDIVIDUAL FIELDS Moving beyond regional assessments, a finer-grained evaluation of individual fields is achievable. Given the scarcity of labeled data, an unsupervised approach is adopted to categorize similar agricultural fields based on their EVI and basic spectral bands. This approach rests on the assumption that similar plant types exhibit analogous responses to environmental changes. Since we lack knowledge of the exact field boundaries, we can use the unsupervised machine learning algorithm, K-means clustering, to partition unlabelled data points into K clusters predicated on their similarity. In the context of Sentinel-2 data, K-means facilitates the grouping of similar pixels according to their spectral characteristics and EVI values. Clustering similar fields using unsupervised K-means clustering The outcome of K-means clustering is cluster labels that assign each data point to one of the K clusters. K-means is basically like sorting colored balls into groups by finding their average colors. In the realm of Sentinel-2 data, these labels serve to identify areas characterized by similar spectral attributes. These areas can then be subjected to further examination for valuable insights, such as land use classification and environmental monitoring, and as input to the segmentation algorithm. In order to extract individual fields for an even higher resolution to facilitate analysis of individual fields, we can use Felzenszwalb\u2019s algorithm, a segmentation technique widely employed in image processing and computer vision. Individual field retrieval (yellow) using Felzenszwalb\u2019s algorithm This algorithm functions as a bottom-up segmentation tool, aggregating pixels with similar characteristics and spatial proximity into segments or regions. It\u2019s like drawing lines around squares of similar colours in a picture to make shapes. This method facilitates the extraction and analysis of individual fields for future investigations, such as precision agriculture management, crop yield prediction or individual field risk assessment. ESTIMATING BUSHFIRE RISK: AN ADVANCED APPLICATION OF SATELLITE DATA There is the potential for satellite data [&#8230;]",
            "pubdate": "Mon, 11 Sep 2023 00:01:42 +0000",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "Unlocking the Power of Operator Fusion to Accelerate AI": {
            "url": "https://towardsai.net/p/artificial-intelligence/unlocking-the-power-of-operator-fusion-to-accelerate-ai",
            "description": "Last Updated on September 12, 2023 by Editorial Team Author(s): Quadric In July of 1887, Carl Benz held the first public outing for his \u201cvehicle powered by a gas engine\u201d \u2014 the first automobile ever invented. Nine short months after the first car was publicly displayed, the first auto race was staged on April 28, 1887 and spanned a distance of 2 kilometers (1.2 mi) from Neuilly Bridge to the Bois de Boulogne in Paris. As cars became more dependable and commonplace as a means of convenient transportation, so too grew the desire to discover the technology\u2019s potential. Auto racing formally became an organized sport in the early 1900\u2019s and today it\u2019s a multi-billion dollar per year industry and has produced vehicles capable of max speeds of almost 500kph (over 300mph). Similar to that first auto race, Artificial Intelligence (AI) applications are in their nascent years, but many are speculating that their impact may be even greater than that of the automobile and many are racing to test their current limits. Similar to how race cars today look nothing like the original three-wheeled Motor Car, AI platforms are changing to meet the performance demands of this new class of programs. If you\u2019ve been following any of the companies that are joining this race, you may have heard them use the term \u201coperator fusion\u201c when bragging about their AI acceleration capabilities. One of the most brag-worthy features to come out of\u00a0the PyTorch 2.0. release earlier this year was the \u2018TorchInductor\u2019 compiler backend that can automatically perform operator fusion, which resulted in\u00a030\u2013200% runtime performance improvements for some users. From context, you can probably infer that \u201coperator fusion\u201c is some technique that magically makes Deep Neural Network (DNN) models easier and faster to execute\u2026 and you wouldn\u2019t be wrong. But what exactly is operator fusion and how can I use operator fusion to accelerate my AI inference applications? AI applications, especially those that incorporate Deep Neural Network (DNN) inference, are composed of many fundamental operations such as Multiply-Accumulate (MAC), Pooling layers, activation functions, etc. Conceptually, operator fusion (sometimes also referred to as kernel or layer fusion) is an optimization technique for\u00a0reducing the costs of two or more operators in succession by reconsidering their scope as if they were a single operator. You intuitively do this type of \u201cfusion\u201c routinely in your everyday life without much thought. Consider for example that you have two tasks in a given day: going to the office for work and going to the grocery store for this week\u2019s groceries. Figure 1. Reducing instances of driving by one by fusing two tasks \u2014 \u201cgoing to work\u201c and \u201cgoing to the grocery store\u201c \u2014 by reconsidering them as a single task. Image by Author. If your office and local grocery store are in the same part of town, you might instinctively stop by the grocery store on your way home from work, reducing the number of legs of your journey by 1 which might result in less total time spent driving and less total distance driven. Operator fusion intuitively optimizes AI programs in a similar way, but the performance benefits are measured in fewer memory read/writes which results in fewer clock cycles dedicated to program overhead which generates a more efficient program binary. Let\u2019s look at a practical example. Here\u2019s a visual diagram of a network before and after operator fusion performed by NVIDIA\u2019s TensorRT\u2122 Optimizer: Figure 2. A GoogLeNet Inception module network before and after layer fusion performed by NVIDIA\u2019s TensorRT\u2122 Optimizer. Original image available in\u00a0this blog post by NVIDIA. In the example in Figure 2, operator fusion was able to reduce the number of layers (blocks not named \u201cinput\u201c or \u201cnext input\u201c) from 20 to 5 by fusing combinations of the following operators: ReLU activations (\u201crelu\u201c) bias adds (\u201cbias\u201c) convolutional layers (\u201c1&#215;1 conv.\u201c, \u201c3&#215;3 conv.\u201c, and \u201c5&#215;5 conv.\u201c) The performance benefits vary depending on the hardware platform being targeted, but operator fusion can provide benefits for nearly every runtime target. Because of its universality, operator fusion is a key optimization technique in nearly all DNN compilers and execution frameworks. If reducing the number of kernels reduces program overhead and improves efficiency and these benefits are applicable universally, this might lead us to ask questions like: why wouldn\u2019t we fuse all of the operators together? what prevents operators from being fusible? are there situations where it doesn\u2019t make sense to fuse operators? To better understand operator fusion\u2019s benefits and limitations, let\u2019s take a deeper dive into the problem it\u2019s solving. A Practical Example: Fusing Convolutions, Bias Adds, &#38; Activation Functions Fusing convolutional layers, bias adds, and activation function layers, like NVIDIA\u2019s TensorRT tool did in Figure 2, is an extremely common choice for operator fusion. Convolutions and activation functions can be decomposed into a series of matrix multiplication operations followed by element-wise operations that look something like: Figure 3. Tensors used in a 3&#215;3 Conv., Bias Add, and ReLU activation function sequence of graph operators. Image by Author. If these operations are performed in three sequential steps, the graph computation would look something like (left side of Figure 4): Input patches (x) and kernel weights (w) are loaded from global into local memory Tensor product of input patches (x) and weights (w) are computed, outputs are stored in intermediate tensor (m) in local memory Intermediate tensor output (m) is written from local memory into global memory Bias value (b) and intermediate tensor output (m) are loaded from global memory into local memory Bias value (b) is summed with the intermediate tensor (m) to produce the convolution outputs (z) Convolution outputs (z) are written to global memory Convolution outputs (z) are loaded into local memory ReLU activation function is computed for convolution outputs (z), activation outputs (y) are stored in local memory Activation outputs (y) are written to global memory to be used by next operator(s) in the graph Figure 4. Local memory loads and stores for tensors used in a 3&#215;3 Conv., Bias Add, and ReLU activation function [&#8230;]",
            "pubdate": "Wed, 13 Sep 2023 00:31:54 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "WizardCoder: Why Its the Best Coding Model Out There": {
            "url": "https://towardsai.net/p/machine-learning/wizardcoder-why-its-the-best-coding-model-out-there",
            "description": "Last Updated on September 27, 2023 by Editorial Team Author(s): Luv Bansal Originally published on Towards AI. In this blog, we will dive into what WizardCoder is and why it stands out as the best coding model in the field. We\u2019ll also explore why its performance on the HumanEval benchmark is exceptional. Additionally, we\u2019ll take an in-depth look at how the dataset preparation and fine-tuning processes contribute to WizardCoder\u2019s success. Starting with some introduction about WizardCoder, WizardCoder is a Code Large Language Model (LLM) that has been fine-tuned on Llama2 and has demonstrated superior performance compared to other open-source and closed LLMs on prominent code generation benchmarks. Source: WizardCoder paper What Sets WizardCoder Apart One might wonder what makes WizardCoder\u2019s performance on HumanEval so exceptional, especially considering its relatively compact size. To put it into perspective, let\u2019s compare WizardCoder-python-34B with CoderLlama-Python-34B: HumanEval Pass@1 WizardCoder-python-34B = 73.2% CoderLlama-Python-34B = 53.7% The unique and most important factor of such large difference in HumanEval benchmark performance is the dataset the model trained on. The Power of Data: WizardCoder\u2019s Unique Dataset One of the key factors contributing to WizardCoder\u2019s remarkable performance is its training dataset. Most models rely on a dataset structure that typically includes: Solid base with a lot of simple instructions Reduced amount of complex instructions And minimal amount of really complex instructions Source: https://www.youtube.com/watch?v=0R_2layS6Ho To train a model for peak performance on evaluation benchmarks, training dataset should have a balance between simple instructions, complex instructions and really complex instructions. Source: https://www.youtube.com/watch?v=0R_2layS6Ho This is where WizardCoder\u2019s dataset shines. It boasts: Good amount of really complex instructions Good amount of complex instructions Solid base with a lot of simple instructions But there\u2019s a challenge: creating a dataset with complex instructions is inherently difficult, while simple instructions are readily available. Evol Instruct Evol-Instruct is an evolutionary algorithm for generating diverse and complex instruction datasets using LLMs(GPT-4). It is designed to enhance the performance of LLMs by providing them with high-quality instructions that are difficult to create manually. Source: https://www.youtube.com/watch?v=0R_2layS6Ho In simple teams, Evol-Instruct is a complexity cascade of synthetically genearted (GPT-4) instruction dataset. Instruction Evolution LLMs can make given instructions more complex and difficult using specific prompts. Additionally, they can generate entirely new instructions that are equally complex but completely different. Using this, we can iteratively evolve an initial instruction dataset, improving the difficulty level and expanding its richness and diversity. A. Instruction Evolver The Instruction Evolver is an LLM that uses prompts to evolve (develop) instructions, with two types: In-depth evolving. In-breadth evolving A base dataset is given (e.g., Alpaca: generated using self-instruct, or 70k ShareGPT (shared by real users)) and using this base dataset, we can create a more complex and diverse dataset. a) In-depth Evolving In-Depth Evolving enhances instructions by making them more complex and difficult through five types of prompts: Prompt of In-depth Evolving In-depth Evolving aims to: (i) Add constraints (ii) Deepening (iii) Concretizing (more specific) (iv) Increased Reasoning Steps (v) Complicating Inputs The core part of In-Depth Evolving\u2019s prompt is \u201cYour objective is to rewrite a given prompt into a more complex version to make those famous Al systems (e.g., ChatGPT and GPT4 [3 ]) a bit harder to handle. But the rewritten prompt must be reasonable, understood, and responded to by humans\u201d. The example prompt of add constraints is: I want you act as a Prompt Rewriter. Your objective is to rewrite a given prompt into a more complex version to make those famous Al systems (e.g., ChatGPT and GPT4) a bit harder to handle. But the rewritten prompt must be reasonable and must be understood and responded by humans. Your rewriting cannot omit the non-text parts such as the table and code in #Given Prompt#:. Also, please do not omit the input in #Given Prompt#. You SHOULD complicate the given prompt using the following method: Please add one more constraints/requirements into #Given Prompt# You should try your best not to make the #Rewritten Prompt# become verbose, #Rewritten Prompt# can only add 10 to 20 words into #Given Prompt#. #Given Prompt#, #Rewritten Prompt#, \u2018given prompt and \u2018rewritten prompt are not allowed to appear in #Rewritten Prompt# #Given Prompt# &#60;Here is instruction.&#62; #Rewritten Prompt#: These prompts help generate a complex instruction dataset, with similar templates for the other types of In-depth Evolving. b) In-breadth Evolving In-breadth Evolving addresses the limitation of open-domain instruction finetune datasets (e.g., Alpaca, ShareGPT, etc.), which are often small in scale, and lacking topic and skill diversity. In-breadth Evolving solves this problem by designing a prompt to generate a completely new instruction based on the given instruction, requiring the new instruction to be more long-tailed. Prompt of In-breadth Evolving In-breadth Evolving aims to 1. Enhance topic coverage 2. skill coverage 3. Overall dataset diversity The in-breadth prompt is as follows: I want you act as a Prompt Creator. Your goal is to draw inspiration from the #Given Prompt# to create a brand new prompt. This new prompt should belong to the same domain as the #Given Prompt# but be even more rare. The LENGTH and difficulty level of the #Created Prompt# should be similar to that of the #Given Prompt#. The #Created Prompt# must be reasonable and must be understood and responded by humans. #Given Prompt#, #Created Prompt#\u2019, \u2018given prompt and \u2018created prompt are not allowed to appear in #Created Prompt#. #Given Prompt#: \u00abHere is instruction.&#62; #Created Prompt#: B. Response Generation The same LLM used to generate the corresponding responses for the evolved instructions using the prompt: &#60;Here is instruction&#62; C. Elimination Evolving(Instruction Eliminator) The evolved instruction may challenge the LLM to generate a response. Sometimes, when the generated response contains \u201csorry\u2019 and is relatively short in length (i.e., less than 80 words), it often indicates that the LLM struggles to respond to the evolved instruction. So, we can use this rule to make a judgment. The response generated by the LLM only contains punctuation and stop words. D. Finetuning the LLM on the Evolved Instructions Once all evolutions are done, the initial [&#8230;]",
            "pubdate": "Wed, 27 Sep 2023 04:01:38 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "So, You Want To Improve Your RAG Pipeline": {
            "url": "https://towardsai.net/p/machine-learning/so-you-want-to-improve-your-rag-pipeline",
            "description": "Last Updated on September 27, 2023 by Editorial Team Author(s): Ryan Nguyen Originally published on Towards AI. Ways to go from prototype to production with LlamaIndex This member-only story is on us. Upgrade to access all of Medium. LLMs are a fantastic innovation, but they have one major flaw. They have cut-off knowledge and a tendency to make up facts and create stuff out of thin air. The danger is LLMs always sound confident with the response and we only need to tweak the prompt a little bit to fool LLMs.The RAG is here to resolve this issue. RAG makes LLMs significantly more useful by providing factual context for them to use when answering queries. Image by Author With roughly a few lines of code and a quick-start guide&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Wed, 27 Sep 2023 02:02:26 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "LangChain 101: Part 2ab. All You Need to Know About (Large Language) Models": {
            "url": "https://towardsai.net/p/machine-learning/langchain-101-part-2ab-all-you-need-to-know-about-large-language-models",
            "description": "Last Updated on September 27, 2023 by Editorial Team Author(s): Ivan Reznikov Originally published on Towards AI. This is part 2ab of the LangChain 101 course. It is strongly recommended to check the first part to understand the context of this article better (follow the author in order not to miss the next part) : LangChain 101: Part 1. Building Simple Q&#38;A App In this article, I will introduce you to the basics of LangChain, a framework for building applications with large\u2026 pub.towardsai.net The Models component is the backbone of Langchain. It is the core that is responsible for token generation that makes the tech feel magical. The Models component allows the usage of different language models, including ChatGPT, GPT-4, LLAMA, etc. These models can be used for multiple tasks, most popular: answering questions and generating text. The Models component is easy to use. To generate text, one can pass the model a prompt, and it will create a response. The same goes for translating a sentence or answering a question. The Models component is also very versatile. You can combine it with other LangChain components to create more complex systems. For example, you could combine the Models component with the Prompts component to create a chatbot that can generate different kinds of creative text formats of text content like code or scripts, poems or musical pieces, letters or emails, etc. Combine the Models and Indexes components to create a search engine that can answer questions using information from various sources. All the code (including colab notebooks) and extra materials are available on GitHub. Overview LangChain supports a variety of different models, so you can choose the one that suits your needs best: LLMs utilize APIs that take input text and generate text outputs Chat Models employ models that process chat messages and produce responses Text Embedding Models convert text into numerical representations Tokenization Tokenization breaks down human language into smaller units like words or subwords to convert text into machine-readable numerical representations. Further on, when we talk about text- or code- generation, we\u2019ll understand it as different kinds of token generation. Text generation Say we want to generate the continuation of the phrase: \u201cParis is the city \u2026\u201d. The Encoder sends logits for all the tokens we have (if you don\u2019t know what logits are \u2014 consider them as scores) that can be converted, using the softmax function, to probabilities of the token being selected for generation. Read more about text generation: How Does an LLM Generate Text? This article won\u2019t discuss transformers or how large language models are trained. Instead, we will concentrate on using\u2026 pub.towardsai.net .from_pretrained(&#60;model&#62;) In many pre-trained language models, the tokenizer and the model architecture are designed and trained together. The reason for this coupling is that the tokenizer and the model architecture must be compatible to ensure consistent tokenization and decoding. If the tokenizer and the model architecture were different or not synchronized, it could lead to tokenization errors, mismatched embeddings, and incorrect predictions. API keys You will first need an API key for the LLM provider you want to use. We must choose between proprietary or open-source foundation models based on a trade-off between performance and cost. Many open-source models are organized and hosted on Hugging Face as a community hub. Open-source models are usually smaller with lower capabilities than proprietary ones, but they are more cost-effective. Examples: BLOOM (BigScience), LLaMA (Meta), Flan-T5 (Google), etc. Proprietary models are closed-source foundation models owned by companies. They usually are larger than open-source models and thus have better performance, but they may have expensive APIs. Examples: OpenAI, co:here, AI21 Labs, Anthropic, etc. Embeddings Embeddings are compact numerical representations of words or entities that help computers understand and process language more effectively. These representations encode the meaning and context of words, allowing machines to work with language more meaningfully and efficiently. OpenAIEmbeddings HuggingFaceEmbeddings GPT4AllEmbeddings SpacyEmbeddings FakeEmbeddings Below, you can see the embeddings for the nine sentences of several topics. The heatmap values were presorted for better visualization. Best travel neck pillow for long flights Lightweight backpack for hiking and travel Waterproof duffel bag for outdoor adventures Stainless steel cookware set for induction cooktops High-quality chef\u2019s knife set High-performance stand mixer for baking New releases in fiction literature Inspirational biographies and memoirs Top self-help books for personal growth As one can notice, the similarity of sentence 1 is close to 2 and 3, with relatively low similarity with other sentences. One can see that all the sentences can be aggregated into three groups. Large Language and Chat Models A language model is a probabilistic model of a natural language that can generate probabilities of a series of words based on text corpora in one or multiple languages it was trained on. A large language model is an advanced language model trained using deep learning techniques on massive amounts of text data. A language model usually backs chat models, but their APIs are more structured. These models take a list of Chat Messages as input and return a Chat Message. Asking GPT a question There is no need to connect LangChain to ask the model a question. In the example below, we\u2019re preparing a prompt, connecting to openai package, and returning the extracted response. import openaidef get_completion(prompt, model=&#034;gpt-3.5-turbo&#034;): &#034;&#034;&#034; Generates a completion for a given prompt using the specified model. Args: prompt (str): The input prompt for generating the completion. model (str): The name of the model to use for generating the completion. Returns: str: The generated completion text. &#034;&#034;&#034; # Create a list of message dictionaries with the user&#039;s prompt messages = [{&#034;role&#034;: &#034;user&#034;, &#034;content&#034;: prompt}] # Generate a chat completion using OpenAI API response = openai.ChatCompletion.create( model=model, messages=messages, temperature=0, # Set temperature to 0 for deterministic output ) # Extract and return the generated completion content return response.choices[0].message[&#034;content&#034;] As one can see, simple questions can be answered by the model correctly. But for complicated requests, LangChain may be the way to go. How Much RAM? To [&#8230;]",
            "pubdate": "Wed, 27 Sep 2023 00:02:26 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Fine-Tuning Models using Prompt-Tuning with Hugging Faces PEFT Library": {
            "url": "https://towardsai.net/p/machine-learning/fine-tuning-models-using-prompt-tuning-with-hugging-faces-peft-library",
            "description": "Last Updated on September 29, 2023 by Editorial Team Author(s): Pere Martra Originally published on Towards AI. Prompt Tuning is such a simple technique that it\u2019s surprising how remarkably efficient it can be. It\u2019s the form of fine-tuning that requires the fewest weight modifications and the only one that allows multiple fine-tuned models to be in memory while loading only a foundational model. It\u2019s efficient not only during training but also during inference. Image created by Author using Dall-E 2 If you\u2019re reading this, it means you\u2019re genuinely interested in novel techniques for Fine-Tuning Large Language Models. I\u2019ve been entirely unable to come up with a title that\u2019s even remotely comprehensible, let alone appealing, to someone unfamiliar with Fine-Tuning. Let\u2019s see if I can at least manage to explain what we\u2019re going to explore in this article so you can decide if it\u2019s truly what you\u2019re looking for. I\u2019ll begin with a brief explanation of what Prompt Tuning is. I understand that at this point, you already fully understand what Fine-Tuning is. Once we understand the technique and its applications, we will study the notebook containing the example. In the notebook, we will train two different models, but starting from the same pretrained model. This will allow us to see one of the most distinctive features of this fine-tuning technique: memory savings by enabling multiple models with different purposes to reside in memory while loading only one pretrained model. Is this what you were looking for? Well, let\u2019s dive right into it. What is Prompt Tuning? It\u2019s an Additive Fine-Tuning technique for models. This means that we WILL NOT MODIFY ANY WEIGHTS OF THE ORIGINAL MODEL. You might be wondering, how are we going to perform fine-tuning then? Well, we will train additional layers that are added to the model. That\u2019s why it\u2019s called an Additive technique. Considering it\u2019s an Additive technique and its name is Prompt-Tuning, it seems clear that the layers we\u2019re going to add and train are related to the prompt. EXACTLY! That\u2019s correct. A prompt is nothing more and nothing less than the instructions we give to the model to perform an action. We write them in our language, i.e., natural language, but the model receives tokens in its language. In large language models, we often refer to them as embeddings, which are numerical representations of the text we send in the prompt. Image by Author The embeddings on the right represent the phrase \u2018I am your Prompt.\u2019 To carry out the training, what we do is add some additional spaces to the input model\u2019s embeddings, and it\u2019s those embeddings that will have their weights modified through training. Image by Author In other words, we are creating a kind of superprompt by allowing a model to supplement part of the prompt with what it has learned. However, that part of the prompt cannot be translated into natural language. It\u2019s as if we\u2019ve learned to express ourselves in embeddings and create incredibly efficient prompts. All the weights of the pretrained model are locked and, therefore, cannot be modified during the training phase. Image by Author In each training cycle, the only weights that can be modified to minimize the loss function are the ones incorporated into the prompt. The first consequence of this technique is that the number of parameters to train is really small. However, we run into a second, maybe more important consequence, which is that because we don\u2019t alter the weights of the pretrained model, it doesn\u2019t change its behavior or forget anything it has previously learned. Our Notebook. The notebook is available on Github: Large-Language-Model-Notebooks-Course/5-Fine Tuning/Prompt_Tuning_PEFT.ipynb at main \u00b7\u2026 Practical course about Large Language Models. . Contribute to peremartra/Large-Language-Model-Notebooks-Course\u2026 github.com And it is part of the Large Language Models Course: GitHub &#8211; peremartra/Large-Language-Model-Notebooks-Course: Practical course about Large Language\u2026 Practical course about Large Language Models. . Contribute to peremartra/Large-Language-Model-Notebooks-Course\u2026 github.com As I mentioned earlier, we\u2019re going to train two models. The first will be a model specialized in generating prompts for large language models. The second will be trained to create motivational phrases. To achieve this, we will use two datasets and a single pretrained model. Datasets used: https://huggingface.co/datasets/fka/awesome-chatgpt-prompts https://huggingface.co/datasets/Abirate/english_quotes The Model: Any model from the Bloom family. In the notebook, I\u2019ve used bigscience/bloomz-560m and bigscience/bloom-1b1. The first thing we\u2019re going to do is load some of the libraries to be used in the notebook. Please note that I loaded the libraries needed in Colab. If you prefer to work in your environment, you might already have some of them loaded, or you may need to install others. !pip install peft!pip install datasets #necesary to load the Datasets. # !pip install transformers #If you don&#039;t have transformers library installedfrom transformers import AutoModelForCausalLM, AutoTokenizer Now we can load the model and the tokenizer. model_name = &#034;bigscience/bloomz-560m&#034;#model_name=&#034;bigscience/bloom-1b1&#034;NUM_VIRTUAL_TOKENS = 4NUM_EPOCHS = 5 While I\u2019ve conducted tests with two of the models from the Bloom family, we could have used any model that\u2019s compatible with Prompt Tuning for Casual Modeling Language in the PEFT library. You can check the compatible models in the library\u2019s GitHub repository: https://github.com/huggingface/peft#models-support-matrix The variable NUM_VIRTUAL_TOKENS contains the number of tokens we want to add to the prompt, which will be trainable. You can modify the value to test how it affects the result; more tokens means more parameters to be trained. Now, let\u2019s load the tokenizer and model. Note that with larger models, the download time may increase. I set the trust_remote variable to True so that the model can execute code for its installation, if necessary. tokenizer = AutoTokenizer.from_pretrained(model_name)foundational_model = AutoModelForCausalLM.from_pretrained( model_name, trust_remote_code=True) The tokenizer is responsible for translating between natural language and tokens understood by the model, and vice versa. It translates the input prompt and the model\u2019s outputs. Loading the tokenizer and the model is straightforward using the classes provided by the Hugging Face Transformers library. With this, we already have the model in memory, and we can conduct an initial test without performing any fine-tuning. This way, we [&#8230;]",
            "pubdate": "Fri, 29 Sep 2023 04:02:28 +0000",
            "pubdate_parsed": [
                2023,
                9,
                29
            ],
            "email_sent": true
        },
        "Temporal Edge Regression with PyTorch Geometric": {
            "url": "https://towardsai.net/p/machine-learning/temporal-edge-regression-with-pytorch-geometric",
            "description": "Last Updated on September 29, 2023 by Editorial Team Author(s): Marco Lomele Originally published on Towards AI. Graph Neural Networks and Transformers for Time Series Forecasting on Heterogeneous Graphs to Predict Butte Trade Volumes. Source: Image by the author. Graphs and Time Graphs are becoming one of the favorite tools of data scientists. Their inherent structure allows for efficient storage of complex information, such as the ongoing protein interactions in your body or the ever-evolving social network surrounding you and your friends. Additionally, graphs can be adapted to temporal scenarios. They can vary from the simple static form, where there is no notion of time, to a fluid spatiotemporal setup, where the topology is fixed but the features change at regular intervals, to the chaotic, fully continuous and time-dynamic mode, where everything can change at any time. [1] Graph Neural Networks (GNNs) are used to process graphs, and many have already demonstrated exceptional results for recommendation systems, supply chain optimization, and road traffic prediction. [2] Nonetheless, most GNNs operate on static graphs, limiting their use for temporal problems. What happens then when we have time series data stored within graphs for which we want to predict future values? It turns out that the Transformer could be a solution, as it has already shown remarkable performance in time series forecasting scenarios. [3] Our Goal To study the effectiveness of combining GNNs and Transformers for time series forecasting on graphs, we will be solving an edge weight prediction problem. Using the data provided by Vesper, we will create a sequence of spatio-temporal graphs acting as snapshots of the global trade market of butter. Our goal is then to forecast worldwide butter trade volumes for the next three months. Trade Data All countries publish their trade records on a monthly basis. Each record indicates the reporting country, the partner country in the transaction, the product, and its traded volume (our target variable). Since each trade is logged twice, we focus on exports. The data at our disposal ranges from January 2015 to April 2023, totaling more than 153,000 transactions. The dataset lists 242 \u201ccountries,\u201d including the exports of regions that aggregate multiple countries together, which means that there are 242*241 = 58,322 possible country pairs. Across all months, each pair is an individual time series that we will be forecasting. We also include other data series as features to support our model\u2019s learning. In particular, we define country-specific features, such as domestic butter production or GDP, and pair-specific attributes, such as the traded volume or the exchange rate. Building Graphs with PyTorch Geometric We proceed by segmenting the data monthly. We designate two types of nodes: one for the exporter (exp_id) and another for the importer (imp_id). Undirected edges are then used to indicate the relationship between two countries. In this manner, we can assign distinct country-specific features to the various types of nodes and embed the pair-specific attributes on the edges. The resulting graph for each month is heterogeneous, fully connected, and bipartite. It can be visualized as follows. Heterogeneous, fully connected, and bipartite graph for each month. Source: Image by the author. Altogether, we end up with a sequence of graphs, each serving as a static snapshot of the market\u2019s status at the end of a specific month. Assuming that the data series for the features are updated more rapidly compared to trade data, we can create graphs for the three most recent months we aim to predict, which we refer to as the target months. These graphs are identical to the historical months but lack trade information in the edges. Sequence of monthly snapshots. Source: Image by the author. In Python, we construct a heterogeneous graph using the HeteroData object from the PyTorch Geometric (PyG) library. [4] !pip install torch_geometricimport torchfrom torch_geometric.data import HeteroDatafrom torch_geometric.transforms import ToUndirecteddef generate_monthly_snapshot(monthly_data): &#034;&#034;&#034; Generate a HeteroData object as snapshot of one month. Args: monthly_data (list): List of pandas dataframes with trade and features&#039; data for one month. Returns: HeteroData: Object containing node features and edge attributes. &#034;&#034;&#034; monthly_snp = HeteroData() # Ingesting the data trade_figs = monthly_data[0] exporters_features = monthly_data[1] importers_features = monthly_data[2] edge_attrs = monthly_data[3] # Creating the nodes exp_ids = trade_figs[&#039;exp_id&#039;].unique(), exp_ids = torch.from_numpy(exp_ids).to(torch.int64) exporters_ftrs_arr = exporters_features.values exporters_ftrs_arr = np.vstack(exporters_ftrs_arr).astype(np.float64) exporters_ftrs_tensor = torch.tensor(exporters_ftrs_arr, dtype=torch.float) monthly_snp[&#039;exp_id&#039;].x = exporters_ftrs_tensor imp_ids = trade_figs[&#039;imp_id&#039;].unique(), imp_ids = torch.from_numpy(imp_ids).to(torch.int64) importers_ftrs_arr = importers_features.values importers_ftrs_arr = np.vstack(importers_ftrs_arr).astype(np.float64) importers_ftrs_tensor = torch.tensor(importers_ftrs_arr, dtype=torch.float) monthly_snp[&#039;imp_id&#039;].x = importers_ftrs_tensor # Creating the edges edge_index = torch.stack([ torch.tensor(trade_figs[&#039;exp_id&#039;].values, dtype=torch.long), torch.tensor(trade_figs[&#039;imp_id&#039;].values, dtype=torch.long)], dim=0) monthly_snp[&#039;exp_id&#039;, &#039;volume&#039;, &#039;imp_id&#039;].edge_index = edge_index vol = torch.from_numpy(trade_figs[&#039;volume&#039;].values).to(torch.float) monthly_snp[&#039;exp_id&#039;, &#039;volume&#039;, &#039;imp_id&#039;].edge_label = vol edge_attrs_arr = edge_attrs.values edge_attrs_arr = np.vstack(edge_attrs_arr).astype(np.float64) edge_attrs_tensor = torch.tensor(edge_attrs.values).to(torch.float) monthly_snp[&#039;exp_id&#039;, &#039;volume&#039;, &#039;imp_id&#039;].edge_attrs = edge_attrs_tensor monthly_snp[&#039;exp_id&#039;, &#039;volume&#039;, &#039;imp_id&#039;].edge_label_index = monthly_snp[&#039;exp_id&#039;, &#039;volume&#039;,&#039;imp_id&#039;].edge_index.clone() monthly_snp = ToUndirected()(monthly_snp) del monthly_snp[(&#039;imp_id&#039;, &#039;rev_volume&#039;, &#039;exp_id&#039;)][&#039;edge_label&#039;] return monthly_snp Note that trade volume data is stored in variable vol, and it is assigned to the edge weights, called edge_label in PyG, instead of the edge attributes. The resulting HeteroData object for January 2015 is: It contains the following variables: exp_id: a list of node features per exporting node. imp_id: a list of node features per importing node. edge_index: a list of node indices denoting the connections of the edges. edge_label: a list of the edge labels, where our target variable is stored. edge_label_index: a list mirroring edge_index, for the edge labels. edge_attr: a list of edge attributes per edge. With the graphs ready, we can proceed to define the individual components of our model. The Model \u2014 Individual Components Taking inspiration from the time-and-graph approach, we employ an Encoder-Decoder architecture. [5] The three crucial units are: GNN Encoder: to generate static node embeddings. Transformer: to create temporal node embeddings. Edge Decoder: to extrapolate predictions. GNN Encoder Similar to how Convolutional Neural Networks work with images, GNNs perform an optimizable transformation on all the features of a graph, preserving the data distributions within that graph. [6] They are used to convert a complex graph schema into vectors of numbers known as node embeddings. Naturally, some information loss is unavoidable. Therefore, the [&#8230;]",
            "pubdate": "Fri, 29 Sep 2023 02:02:31 +0000",
            "pubdate_parsed": [
                2023,
                9,
                29
            ],
            "email_sent": true
        },
        "A Practical Introduction to PySpark": {
            "url": "https://towardsai.net/p/machine-learning/a-practical-introduction-to-pyspark",
            "description": "Last Updated on September 29, 2023 by Editorial Team Author(s): Mihir Gandhi Originally published on Towards AI. What is PySpark? This member-only story is on us. Upgrade to access all of Medium. This article explains what PySpark is, some common PySpark functions, and data analysis of the New York City Taxi &#38; Limousine Commission Dataset using PySpark. PySpark is an interface for Apache Spark in Python. With PySpark, you can write Python and SQL-like commands to manipulate and analyze data in a distributed processing environment. Apache Spark: Apache Spark is an open-source data processing framework for processing large datasets in a distributed manner. It does in-memory computations to analyze data in real-time. It leverages Apache Hadoop for both storage and processing. select: Projects a&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 29 Sep 2023 00:01:33 +0000",
            "pubdate_parsed": [
                2023,
                9,
                29
            ],
            "email_sent": true
        },
        "GPT-4 Advanced Data Analysis: A Beginners Guide to Charts and Maps": {
            "url": "https://towardsai.net/p/machine-learning/gpt-4-advanced-data-analysis-a-beginners-guide-to-charts-and-maps",
            "description": "Last Updated on October 6, 2023 by Editorial Team Author(s): John Loewen, PhD Originally published on Towards AI. Removing the \u201cadvanced\u201d for simple and useful data analysis This member-only story is on us. Upgrade to access all of Medium. Dall-e created image \u2014 impressionist painting in vivid thick oil colors of a map of Earth With data science, turning raw numbers into meaningful data visuals can be a monumental task, particularly for novice programmers. With the GPT-4 Advanced Data Analysis tool (don\u2019t be fooled by the name), novice programmers are able to generate meaningful representations in the form of charts and maps, without writing any code. Even better, the working code is presented to you as part of the generated solution \u2014 to be massaged and tweaked as needed. So not only&#8230; Read the full blog for free on Medium. Join thousands of data leaders on the AI newsletter. Join over 80,000 subscribers and keep up to date with the latest developments in AI. From research to projects and ideas. If you are building an AI startup, an AI-related product, or a service, we invite you to consider becoming a\u00a0sponsor. Published via Towards AI",
            "pubdate": "Fri, 06 Oct 2023 02:02:48 +0000",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        },
        "ChatGPT is Amazing But Overhyped": {
            "url": "https://towardsai.net/p/machine-learning/chatgpt-is-amazing-but-overhyped",
            "description": "Last Updated on October 6, 2023 by Editorial Team Author(s): thisisagencypromax Originally published on Towards AI. ChatGPT is Amazing But Overhyped \u2014 What It Can and Can\u2019t Do Yet Photo by Mariia Shalabaieva on Unsplash Without a doubt, ChatGPT has been one of the biggest AI stories of the year. The conversational AI from Anthropic has captured the public imagination like few other tech releases in recent memory. ChatGPT went viral seemingly overnight. Its human-like responses to natural language prompts fascinated millions. Suddenly, AI could passably imitate casual conversation, share clever jokes, and respond to complex prompts with eerily coherent essays. Like moths to a flame, people flocked to test ChatGPT\u2019s limits. Could it offer thoughtful poetry critiques? Analyze Shakespeare? Debug code? Debate ethics? Discuss quantum physics. Yes, it did remarkably well on many of these tests. But in the rush to crown ChatGPT the next artificial general intelligence (AGI), many have overlooked its very real limitations. The hype train may have left the station a bit prematurely. While ChatGPT previews a promising future, in many ways, it remains an impressive but narrowly focused AI assistant. Let\u2019s take a clear-eyed look at what today\u2019s ChatGPT can and can\u2019t do. ChatGPT\u2019s Strengths: Where It Shines There\u2019s no denying that ChatGPT shows a mastery of language and reasoning that sometimes eerily emulates human intelligence. Backed by massive training datasets, ChatGPT delivers compelling performance in several areas: Conversational Ability ChatGPT excels at conversational tasks. Its true breakthrough is the natural way it handles back-and-forth chitchat. The AI follows conversation threads accurately. It answers follow-up questions sensibly. ChatGPT even politely asks for clarification when confused. This conversational flow comes across as far more human than previous chatbots. We\u2019ve been conditioned by generations of stilted AI conversations. ChatGPT\u2019s eloquence and versatility feel like a huge leap forward. Text Generation Give ChatGPT a writing prompt, and it can produce long, coherent passages that credibly emulate human writing. For instance, ask it to write a poem, and you may be impressed by the metaphors and structure it generates. Tell it to compose a short story, and it spins a narrative arc with believable characters. This ability to generate high-quality text based on short prompts provides tremendous utility. Businesses are using ChatGPT to craft marketing copy, emails, and blog posts. Students employ it to expand on essay ideas. Creators use it to brainstorm original fiction plots. Knowledge Synthesis Feed ChatGPT some key facts or background context, and it can synthesize the information into an overview remarkably well. Pose questions about history, literature, science, or current events, and more often than not, ChatGPT Serves up a sensible summary sprinkled with relevant details. For instance, ask \u201cCan you explain Einstein\u2019s theory of relativity in simple terms?\u201d and you may be pleasantly surprised by the coherent explanation it provides. Logical Reasoning ChatGPT exhibits solid logical reasoning capabilities. Given a set of premises or constraints, it can draw sensible conclusions. Ask it to recommend recipes based on ingredients you have on hand, and its suggestions typically consider compatible flavors and cooking methods. Tell ChatGPT you\u2019re planning a vacation for a family of four with certain interests and budgets, and it proposes thoughtful destination ideas and activities. These examples demonstrate how, within defined domains, ChatGPT makes connections and provides recommendations rooted in rational thinking. Where ChatGPT Falters As remarkable as ChatGPT seems, in many situations, it stumbles. Its skills remain narrow and brittle. Under scrutiny, the illusion of human-level intelligence strains. Here are key areas where ChatGPT falls short: Limited Knowledge The sheer breadth of human knowledge quickly exposes ChatGPT\u2019s limitations. Its training data ended in 2021. So it lacks up-to-date knowledge about current events, new books, or the latest scientific discoveries. Pose an obscure trivia question or ask about a niche topic, and ChatGPT often defaults to vague responses or admissions of ignorance. Even in broader domains, the gaps in its knowledge become apparent with advanced questions. Brittle Reasoning Give ChatGPT an unusual prompt or complex reasoning task, and its logic readily breaks down. While it handles straightforward reasoning well, more advanced logical challenges trip it up. For example, ChatGPT struggles with mathematical word problems and deductive reasoning puzzles. It doesn\u2019t recognize its own contradictions or faulty conclusions. Incapable of Learning ChatGPT cannot learn or expand its skills like humans can. It cannot incorporate new knowledge or learn from its mistakes through experience. Attempting to teach ChatGPT a new skill or correct its factual errors yields no long-term improvements. Each conversation session starts afresh. This limitation makes it unreliable for tasks requiring adaptability. No Common Sense Common sense proves to be uncommon for ChatGPT. Despite eloquent responses, it lacks the basic real-world judgment humans develop from living life. ChatGPT may confidently provide dangerous advice if users don\u2019t explicitly state safety concerns. It responds literally to absurd hypotheticals that any person would recognize as silly. Without common sense to filter context appropriately, ChatGPT\u2019s judgment cannot be trusted unconditionally. Weak Verification of Facts Don\u2019t expect rigorous fact-checking from ChatGPT. It often presents fabricated or inaccurate information with conviction if such falsehoods existed in its training data. When responding to questions, ChatGPT does not systematically verify facts from multiple reliable sources. So interspersed between sensible responses may be subtle fiction presented as truth. Lack of Context Carrying on extended conversations highlights ChatGPT\u2019s lack of memory and context. It cannot learn over a multi-exchange dialog by recalling earlier statements. Each input is handled as an isolated prompt. So, while ChatGPT appears intelligent in answering individual questions, its inability to retain context limits its reasoning in broader dialogs. No Understanding of Itself Perhaps the clearest sign of ChatGPT\u2019s limitations is its lack of understanding about itself. It cannot explain how its algorithms work, discuss its own capabilities, or self-reflect accurately. Press ChatGPT about how it generates answers so convincingly, and it dissolves into vagueness and misdirection. Unlike a human, it cannot gauge and articulate the strengths and limits of its intelligence. Responsible Ways to Use ChatGPT [&#8230;]",
            "pubdate": "Fri, 06 Oct 2023 00:01:16 +0000",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        }
    },
    "Louis Bouchard Blog": {
        "An AI that Automatically Summarizes your Documents": {
            "url": "https://www.louisbouchard.ai/google-docs-summary/",
            "description": "A new model for automatically generating summaries using machine learning, released in Google Docs that you can already\u00a0use!",
            "pubdate": "Thu, 21 Apr 2022 12:22:43 GMT",
            "pubdate_parsed": [
                2022,
                4,
                21
            ],
            "email_sent": true
        },
        "Your Personal Photoshop Expert with AI!": {
            "url": "https://www.louisbouchard.ai/mystyle/",
            "description": "This AI can reconstruct, enhance and edit your\u00a0images!",
            "pubdate": "Thu, 28 Apr 2022 00:58:15 GMT",
            "pubdate_parsed": [
                2022,
                4,
                28
            ],
            "email_sent": true
        },
        "Meta's new model OPT is GPT-3's closest competitor! (and is open source)": {
            "url": "https://www.louisbouchard.ai/opt-meta/",
            "description": "An open-source model that is as powerful as\u00a0GPT-3!",
            "pubdate": "Fri, 06 May 2022 01:50:37 GMT",
            "pubdate_parsed": [
                2022,
                5,
                6
            ],
            "email_sent": true
        },
        "Deepmind's new model Gato isamazing!": {
            "url": "https://www.louisbouchard.ai/deepmind-gato/",
            "description": "Gato: A single Transformer to RuLe them all! The first generalist RL agent using transformers!",
            "pubdate": "Fri, 13 May 2022 13:38:56 GMT",
            "pubdate_parsed": [
                2022,
                5,
                13
            ],
            "email_sent": true
        },
        "This is a BIG step for GANs! BlobGAN Explained": {
            "url": "https://www.louisbouchard.ai/blobgan/",
            "description": "A GAN model that uses simple blobs to manipulate objects in images\u2026",
            "pubdate": "Fri, 13 May 2022 00:57:25 GMT",
            "pubdate_parsed": [
                2022,
                5,
                13
            ],
            "email_sent": true
        },
        "How Uber uses AI to serve you better": {
            "url": "https://www.louisbouchard.ai/uber-deepeta/",
            "description": "How can Uber deliver food and always arrive on time or a few minutes before?",
            "pubdate": "Sat, 21 May 2022 11:40:23 GMT",
            "pubdate_parsed": [
                2022,
                5,
                21
            ],
            "email_sent": true
        },
        "Google Brain's Answer to Dalle-e 2: Imagen": {
            "url": "https://www.louisbouchard.ai/google-brain-imagen/",
            "description": "An AI that creates photorealistic images from input text better than Dall-e\u00a02!",
            "pubdate": "Tue, 24 May 2022 03:29:37 GMT",
            "pubdate_parsed": [
                2022,
                5,
                24
            ],
            "email_sent": true
        },
        "How does dalle-mini work?": {
            "url": "https://www.louisbouchard.ai/dalle-mini/",
            "description": "Dalle mini is a free, open-source AI that produces amazing images from text inputs. Here's how it\u00a0works.",
            "pubdate": "Thu, 16 Jun 2022 02:40:55 GMT",
            "pubdate_parsed": [
                2022,
                6,
                16
            ],
            "email_sent": true
        },
        "No Language LeftBehind": {
            "url": "https://www.louisbouchard.ai/no-language-left-behind/",
            "description": "Translating 200 languages with a single model\u200a-\u200aMeta\u00a0AI",
            "pubdate": "Wed, 06 Jul 2022 13:11:04 GMT",
            "pubdate_parsed": [
                2022,
                7,
                6
            ],
            "email_sent": true
        },
        "What is data-centric AI?": {
            "url": "https://www.louisbouchard.ai/data-centric-ai/",
            "description": "The beginning of data-centric AI with data programming",
            "pubdate": "Fri, 08 Jul 2022 00:11:13 GMT",
            "pubdate_parsed": [
                2022,
                7,
                8
            ],
            "email_sent": true
        },
        "CVPR 2022 Best Paper Honorable Mention: Dual-Shutter Optical Vibration Sensing": {
            "url": "https://www.louisbouchard.ai/cvpr-2022-best-paper/",
            "description": "They reconstruct sound using cameras and a laser beam on any vibrating surface, allowing them to isolate music instruments, focus on a specific speaker, remove ambient noises, and many more amazing applications.",
            "pubdate": "Wed, 13 Jul 2022 13:36:57 GMT",
            "pubdate_parsed": [
                2022,
                7,
                13
            ],
            "email_sent": true
        },
        "How OpenAI Reduces risks for DALLE2": {
            "url": "https://www.louisbouchard.ai/how-openai-reduces-risks-for-dall-e-2/",
            "description": "DALL\u00b7E 2 Pre-Training Mitigations",
            "pubdate": "Sat, 16 Jul 2022 16:00:54 GMT",
            "pubdate_parsed": [
                2022,
                7,
                16
            ],
            "email_sent": true
        },
        "Produce Amazing Artworks with Text and Sketches!": {
            "url": "https://www.louisbouchard.ai/make-a-scene/",
            "description": "\"Make-A-Scene\": a fantastic blend between text and sketch-conditioned image generation.",
            "pubdate": "Tue, 19 Jul 2022 12:16:59 GMT",
            "pubdate_parsed": [
                2022,
                7,
                19
            ],
            "email_sent": true
        },
        "Build Animatable 3D Models with AI": {
            "url": "https://www.louisbouchard.ai/banmo/",
            "description": "Create deformable 3D models from pictures with\u00a0BANMo!",
            "pubdate": "Sat, 13 Aug 2022 13:39:19 GMT",
            "pubdate_parsed": [
                2022,
                8,
                13
            ],
            "email_sent": true
        },
        "Latent Diffusion Models: The Architecture behind Stable Diffusion": {
            "url": "https://www.louisbouchard.ai/latent-diffusion-models/",
            "description": "A High-Resolution Image Synthesis Architecture: Latent Diffusion",
            "pubdate": "Sat, 27 Aug 2022 14:41:59 GMT",
            "pubdate_parsed": [
                2022,
                8,
                27
            ],
            "email_sent": true
        },
        "One of the Most Challenging Tasks for AI": {
            "url": "https://www.louisbouchard.ai/psg/",
            "description": "A New Challenging Task for\u00a0AI:  panoptic scene graph generation",
            "pubdate": "Thu, 01 Sep 2022 00:19:49 GMT",
            "pubdate_parsed": [
                2022,
                9,
                1
            ],
            "email_sent": true
        },
        "Guiding Stable Diffusion with yourImages": {
            "url": "https://www.louisbouchard.ai/imageworthoneword/",
            "description": "Personalizing Text-to-Image Generation using Textual Inversion",
            "pubdate": "Fri, 02 Sep 2022 02:08:32 GMT",
            "pubdate_parsed": [
                2022,
                9,
                2
            ],
            "email_sent": true
        },
        "General Video Recognition with AI": {
            "url": "https://www.louisbouchard.ai/general-video-recognition/",
            "description": "What does such a model understand when it sees such a picture or, even more complex, a video?",
            "pubdate": "Thu, 08 Sep 2022 01:50:38 GMT",
            "pubdate_parsed": [
                2022,
                9,
                8
            ],
            "email_sent": true
        },
        "OpenAI's Most Recent Model: Whisper (explained)": {
            "url": "https://www.louisbouchard.ai/whisper/",
            "description": "A good transcription tool that would accurately understand what you say and write it\u00a0down",
            "pubdate": "Thu, 06 Oct 2022 01:25:29 GMT",
            "pubdate_parsed": [
                2022,
                10,
                6
            ],
            "email_sent": true
        },
        "3D Models from Text! DreamFusion Explained": {
            "url": "https://www.louisbouchard.ai/dreamfusion/",
            "description": "How AI generates 3d models from only text!",
            "pubdate": "Sat, 15 Oct 2022 01:08:42 GMT",
            "pubdate_parsed": [
                2022,
                10,
                15
            ],
            "email_sent": true
        },
        "Diffusion models: Everything you need to know": {
            "url": "https://www.louisbouchard.ai/diffusion-models/",
            "description": "Here's every vision application Diffusion models were a game changer in 2022: image, text, video, 3D, and more!",
            "pubdate": "Thu, 03 Nov 2022 10:19:55 GMT",
            "pubdate_parsed": [
                2022,
                11,
                3
            ],
            "email_sent": true
        },
        "InfiniteNature-Zero: Fly Into Your Pictures With AI!": {
            "url": "https://www.louisbouchard.ai/infinitenature-zero/",
            "description": "Generate infinite new frames as if you would be flying into your image!",
            "pubdate": "Thu, 17 Nov 2022 02:11:33 GMT",
            "pubdate_parsed": [
                2022,
                11,
                17
            ],
            "email_sent": true
        },
        "Galactica: What is it and What Happened?": {
            "url": "https://www.louisbouchard.ai/galactica/",
            "description": "Galactica, Meta AI's most recent model: The AI Scientist",
            "pubdate": "Tue, 22 Nov 2022 03:46:58 GMT",
            "pubdate_parsed": [
                2022,
                11,
                22
            ],
            "email_sent": true
        },
        "What is ChatGPT?": {
            "url": "https://www.louisbouchard.ai/chatgpt/",
            "description": "OpenAI's most recent conversational AI explained",
            "pubdate": "Tue, 06 Dec 2022 01:24:41 GMT",
            "pubdate_parsed": [
                2022,
                12,
                6
            ],
            "email_sent": true
        },
        "Prompting Explained: How to talk toChatGPT": {
            "url": "https://www.louisbouchard.ai/prompting-explained/",
            "description": "What is a prompt engineer and how to improve at\u00a0it\u2026",
            "pubdate": "Tue, 13 Dec 2022 01:53:03 GMT",
            "pubdate_parsed": [
                2022,
                12,
                13
            ],
            "email_sent": true
        },
        "Automatic Re-Aging with AI! Disneys FRAN Model Explained": {
            "url": "https://www.louisbouchard.ai/disney-re-age/",
            "description": "Disney's New Model Explained",
            "pubdate": "Thu, 22 Dec 2022 00:42:54 GMT",
            "pubdate_parsed": [
                2022,
                12,
                22
            ],
            "email_sent": true
        },
        "An interview with the Director of Perception at Zoox: Ruijie (RJ) He: What is an ML Engineer and more...": {
            "url": "https://www.louisbouchard.ai/rj-he-zoox/",
            "description": "An interview with the Director of Perception at Zoox, Ruijie (RJ) He, with the goal of demystifying what is a good profile to get an ML engineer job and perform at the interviews.",
            "pubdate": "Tue, 10 Jan 2023 02:19:34 GMT",
            "pubdate_parsed": [
                2023,
                1,
                10
            ],
            "email_sent": true
        },
        "Image Editing from Text Instructions: InstructPix2Pix": {
            "url": "https://www.louisbouchard.ai/instructpix2pix/",
            "description": "The hottest image editing AI, InstructPix2Pix, explained!",
            "pubdate": "Thu, 26 Jan 2023 02:18:42 GMT",
            "pubdate_parsed": [
                2023,
                1,
                26
            ],
            "email_sent": true
        },
        "Generating music withAI!": {
            "url": "https://www.louisbouchard.ai/musiclm/",
            "description": "MusicLM explained",
            "pubdate": "Tue, 31 Jan 2023 01:28:14 GMT",
            "pubdate_parsed": [
                2023,
                1,
                31
            ],
            "email_sent": true
        },
        "Gen-1, the future of storytelling?": {
            "url": "https://www.louisbouchard.ai/gen-1/",
            "description": "Turn mockups into videos automatically!",
            "pubdate": "Mon, 06 Mar 2023 12:51:05 GMT",
            "pubdate_parsed": [
                2023,
                3,
                6
            ],
            "email_sent": true
        },
        "Interview with NVIDIA Data Scientist Meriem Bendris & RTX 4080 Giveaway!": {
            "url": "https://www.louisbouchard.ai/nvidia-meriem-bendris/",
            "description": "What is it like, and how to get there (and RTX 4080 giveaway)",
            "pubdate": "Tue, 07 Mar 2023 12:37:36 GMT",
            "pubdate_parsed": [
                2023,
                3,
                7
            ],
            "email_sent": true
        },
        "How to Build a strong Data Science Resume with Kaggle": {
            "url": "https://www.louisbouchard.ai/build-a-strong-data-science-resume-with-kaggle/",
            "description": "An interview with Chris Deotte, Quadruple Kaggle Grandmaster at NVIDIA",
            "pubdate": "Thu, 09 Mar 2023 03:38:32 GMT",
            "pubdate_parsed": [
                2023,
                3,
                9
            ],
            "email_sent": true
        },
        "How good is GPT-4?": {
            "url": "https://www.louisbouchard.ai/gpt-4/",
            "description": "If you thought ChatGPT was good, wait before you try this\u00a0one\u2026",
            "pubdate": "Wed, 15 Mar 2023 01:36:24 GMT",
            "pubdate_parsed": [
                2023,
                3,
                15
            ],
            "email_sent": true
        },
        "What is a Solution Architect atNVIDIA?": {
            "url": "https://www.louisbouchard.ai/solution-architect/",
            "description": "An interview with Adam Grzywaczewski, senior data scientist at NVIDIA",
            "pubdate": "Sun, 19 Mar 2023 03:30:57 GMT",
            "pubdate_parsed": [
                2023,
                3,
                19
            ],
            "email_sent": true
        },
        "Googles New AI Robot Can See and Understands Language! (PaLM-E)": {
            "url": "https://www.louisbouchard.ai/palm-e/",
            "description": "Google's New AI Model PaLM-E  Explained",
            "pubdate": "Thu, 23 Mar 2023 02:04:31 GMT",
            "pubdate_parsed": [
                2023,
                3,
                23
            ],
            "email_sent": true
        },
        "10x Your Productivity with those AI Tools": {
            "url": "https://www.louisbouchard.ai/ai-tools-productivity/",
            "description": "These AI Tools will 10x Your Productivity!",
            "pubdate": "Sun, 16 Apr 2023 11:43:44 GMT",
            "pubdate_parsed": [
                2023,
                4,
                16
            ],
            "email_sent": true
        },
        "Break into AI in 2023: Best Resume & Interview Tips with Brian Burns (AI Pub) - What's AI Podcast Episode 9": {
            "url": "https://www.louisbouchard.ai/brian-burns/",
            "description": "Ph.D., Twitter, Breaking into the AI Field, and more with Brian Burns (AI\u00a0Pub)",
            "pubdate": "Wed, 19 Apr 2023 12:17:29 GMT",
            "pubdate_parsed": [
                2023,
                4,
                19
            ],
            "email_sent": true
        },
        "How AI Enhances Writing & Affects Journalism": {
            "url": "https://www.louisbouchard.ai/ai-writing/",
            "description": "An interview with Limarc Ambalina, VP of Editorial at HackerNoon",
            "pubdate": "Wed, 26 Apr 2023 12:10:39 GMT",
            "pubdate_parsed": [
                2023,
                4,
                26
            ],
            "email_sent": true
        },
        "Perfusion: Stable Diffusion but more Controllable!": {
            "url": "https://www.louisbouchard.ai/perfusion/",
            "description": "The new Perfusion model by NVIDIA Explained",
            "pubdate": "Fri, 05 May 2023 11:19:09 GMT",
            "pubdate_parsed": [
                2023,
                5,
                5
            ],
            "email_sent": true
        },
        "Copilot, ChatGPT and Copyrights": {
            "url": "https://www.louisbouchard.ai/copilot-chatgpt-and-copyrights/",
            "description": "An interview with David Mertz, senior developer, data scientist, and\u00a0author",
            "pubdate": "Tue, 16 May 2023 10:52:58 GMT",
            "pubdate_parsed": [
                2023,
                5,
                16
            ],
            "email_sent": true
        },
        "Image Manipulation with Your Mouse! Drag Your Gan Explained": {
            "url": "https://www.louisbouchard.ai/draggan/",
            "description": "Move anything from point A to point\u00a0B!",
            "pubdate": "Sat, 27 May 2023 12:21:18 GMT",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "From GPT3 to AGI: Insights from Felix Tao, CEO of Mindverse AI": {
            "url": "https://www.louisbouchard.ai/from-gpt3-to-agi-insights-from-felix-tao-ceo-of-mindverse-ai/",
            "description": "Navigating the Changing Landscape of AI: Felix Tao's Journey from Researcher to\u00a0CEO",
            "pubdate": "Tue, 06 Jun 2023 10:20:52 GMT",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "The Best Image-to-3D AI to date: Neuralangelo": {
            "url": "https://www.louisbouchard.ai/neuralangelo/",
            "description": "Here's the best Images-to-3D AI to date, and how it\u00a0works\u2026",
            "pubdate": "Sun, 11 Jun 2023 11:57:07 GMT",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "Revolutionizing Online Shopping: AI's Virtual Try-On Experience": {
            "url": "https://www.louisbouchard.ai/tryondiffusion/",
            "description": "AI Does magic with UNets, Diffusion, and\u00a0clothes!",
            "pubdate": "Sat, 24 Jun 2023 13:16:20 GMT",
            "pubdate_parsed": [
                2023,
                6,
                24
            ],
            "email_sent": true
        },
        "Building LLM Apps and the Challenges that come with it: An Interview with Jay Alammar": {
            "url": "https://www.louisbouchard.ai/jay-alammar/",
            "description": "The What's AI podcast episode 16 with Jay Alammar.",
            "pubdate": "Tue, 27 Jun 2023 12:29:42 GMT",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "Google Maps Travel Time Prediction Algorithm & AI Research at Google Deepmind": {
            "url": "https://www.louisbouchard.ai/petar/",
            "description": "An interview with Petar Velic\u030ckovic\u0301 - The What's AI Podcast Episode 17",
            "pubdate": "Tue, 04 Jul 2023 10:48:30 GMT",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "Leaving Deepmind to start his own Startup! Aleksa Gordi": {
            "url": "https://www.louisbouchard.ai/aleksa/",
            "description": "Aleksa Gordi\u0107 - The What's AI Podcast Episode 18",
            "pubdate": "Wed, 12 Jul 2023 12:14:33 GMT",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Large Language Models Enter the 3D World!": {
            "url": "https://www.louisbouchard.ai/3d-llm/",
            "description": "An overview of the first\u00a03D-LLM",
            "pubdate": "Fri, 11 Aug 2023 00:05:03 GMT",
            "pubdate_parsed": [
                2023,
                8,
                11
            ],
            "email_sent": true
        },
        "Fixing AI Hallucinations: The Importance of Explainability in AI (XAI)": {
            "url": "https://www.louisbouchard.ai/xai-2/",
            "description": "An introduction to explainable AI",
            "pubdate": "Wed, 30 Aug 2023 00:48:57 GMT",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "AI Deep Learning Explained": {
            "url": "https://www.louisbouchard.ai/ai-deep-learning-explained/",
            "description": "Deep learning with a simple analogy",
            "pubdate": "Wed, 06 Sep 2023 11:07:49 GMT",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "Generate music with AI: Stable Audio Explained": {
            "url": "https://www.louisbouchard.ai/stableaudio/",
            "description": "New AI That Generates Amazing Music !",
            "pubdate": "Wed, 27 Sep 2023 01:11:43 GMT",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Responsible AI: Insights from an Ethics Expert": {
            "url": "https://www.louisbouchard.ai/responsible-ai/",
            "description": "The What's AI Podcast Episode 20 with Auxane Boch: Ethics\u00a0Expert",
            "pubdate": "Fri, 06 Oct 2023 07:37:43 GMT",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        }
    },
    "Computational Intelligence Blog": {
        "Evolving Systems, Volume 13, issue 3, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/05/evolving-systems-volume-13-issue-3-june.html",
            "description": "<div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09396-z\">Dimensionality reduction in the context of dynamic social media data streams</a></div><div><b>Author(s): </b>Moritz Heusinger, Christoph Raab, Frank-Michael Schleif</div><div><b>Pages: </b>387 - 401</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09403-3\">Evolving and explainable clinical risk assessment at the edge</a></div><div><b>Author(s):&nbsp;</b>Andrea Pazienza, Roberto Anglani...Felice Vitulano</div><div><b>Pages:&nbsp;</b>403 - 422</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09422-8\">Evolving hyperbox fuzzy modeling</a></div><div><b>Author(s):&nbsp;</b>Alisson Porto, Fernando Gomide</div><div><b>Pages:&nbsp;</b>423 - 434</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09435-3\">Deep recurrent Gaussian Nesterovs recommendation using multi-agent in social networks</a></div><div><b>Author(s):&nbsp;</b>Vinita Tapaskar, Mallikarjun M. Math</div><div><b>Pages:&nbsp;</b>435 - 452</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09402-4\">A novel improved arithmetic optimization algorithm for optimal design of PID controlled and Bode\u2019s ideal transfer function based automobile cruise control system</a></div><div><b>Author(s):&nbsp;</b>Davut Izci, Serdar Ekinci...Erdal Eker</div><div><b>Pages:&nbsp;</b>453 - 468</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09402-4\">Score level fusion of major and minor finger knuckle patterns based symmetric sum-based rules for person authentication</a></div><div><b>Author(s):&nbsp;</b>Rabah Hammouche, Abdelouahab Attia, Samir Akhrouf</div><div><b>Pages:&nbsp;</b>469 - 483</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09416-y\">Ant colony optimization technique for integrating renewable DG in distribution system with techno-economic objectives</a></div><div><b>Author(s):&nbsp;</b>Nisha R. Godha, Vishram N. Bapat, Iranna Korachagaon</div><div><b>Pages:&nbsp;</b>485 - 498</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09438-0\">An evolutionary approach with reliability priority to design Scada systems for water reservoirs</a></div><div><b>Author(s):&nbsp;</b>Ali Dolatshahi Zand, Kaveh Khalili-Damghani, Sadigh Raissi</div><div><b>Pages:&nbsp;</b>499 - 517</div><div><br /></div>",
            "pubdate": "2022-05-23T21:22:00.000+12:00",
            "pubdate_parsed": [
                2022,
                5,
                23
            ],
            "email_sent": true
        },
        "IEEE Transactions on Emerging Topics in Computational Intelligence, Issue 3, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/05/ieee-transactions-on-emerging-topics-in.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9432948/\">Training a Quantum Annealing Based Restricted Boltzmann Machine on Cybersecurity Data</a></div><div><b>Author(s): </b>Vivek Dixit, Raja Selvarajan, Tamer Aldwairi, Yaroslav Koshka, Mark A. Novotny, Travis S. Humble, Muhammad A. Alam, Sabre Kais</div><div><b>Pages: </b>417 - 428</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9457027/\">Deep Learning in Physics: A Study of Dielectric Quasi-Cubic Particles in a Uniform Electric Field</a></div><div><b>Author(s):&nbsp;</b>Zhe Wang, Claude Guet</div><div><b>Pages:&nbsp;</b>429 - 438</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9456987/\">Double Fourier Integral Analysis Based Convolutional Neural Network Regression for High-Frequency Energy Disaggregation</a></div><div><b>Author(s):&nbsp;</b>Pascal A. Schirmer, Iosif Mporas</div><div><b>Pages:&nbsp;</b>439 - 449</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9455355/\">TDM: Trustworthy Decision-Making Via Interpretability Enhancement</a></div><div><b>Author(s):&nbsp;</b>Daoming Lyu, Fangkai Yang, Hugh Kwon, Wen Dong, Levent Yilmaz, Bo Liu</div><div><b>Pages:&nbsp;</b>450 - 461</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9460321/\">Privacy-Preserving Context-Based Electric Vehicle Dispatching for Energy Scheduling in Microgrids: An Online Learning Approach</a></div><div><b>Author(s):&nbsp;</b>Yichen Liu, Pan Zhou, Lei Yang, Yulei Wu, Zichuan Xu, Kai Liu, Xiumin Wang</div><div><b>Pages:&nbsp;</b>462 - 478</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9448192/\">Reward-Reinforced Generative Adversarial Networks for Multi-Agent Systems</a></div><div><b>Author(s):&nbsp;</b>Changgang Zheng, Shufan Yang, Juan Marcelo Parra-Ullauri, Antonio Garcia-Dominguez, Nelly Bencomo</div><div><b>Pages:&nbsp;</b>479 - 488</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9448189/\">Multi-UAV Mobile Edge Computing and Path Planning Platform Based on Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Huan Chang, Yicheng Chen, Baochang Zhang, David Doermann</div><div><b>Pages:&nbsp;</b>489 - 498</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9543522/\">Deep Reinforcement Learning Based Pricing Strategy of Aggregators Considering Renewable Energy</a></div><div><b>Author(s):&nbsp;</b>Yu-Chieh Chuang, Wei-Yu Chiu</div><div><b>Pages:&nbsp;</b>499 - 508</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9615099/\">Person Re-Identification With Multi-Features Based on Evolutionary Algorithm</a></div><div><b>Author(s):&nbsp;</b>Lixia Zhang, Kangshun Li, Yu Qi</div><div><b>Pages:&nbsp;</b>509 - 518</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9521230/\">VRConvMF: Visual Recurrent Convolutional Matrix Factorization for Movie Recommendation</a></div><div><b>Author(s):&nbsp;</b>Zhu Wang, Honglong Chen, Zhe Li, Kai Lin, Nan Jiang, Feng Xia</div><div><b>Pages:&nbsp;</b>519 - 529</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9525180/\">Intelligent Decision Support and Fusion Models for Fault Detection and Location in Power Grids</a></div><div><b>Author(s):&nbsp;</b>Hossein Hassani, Roozbeh Razavi-Far, Mehrdad Saif, Jafar Zarei, Frede Blaabjerg</div><div><b>Pages:&nbsp;</b>530 - 543</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9336053/\">Furnace-Grouping Problem Modeling and Multi-Objective Optimization for Special Aluminum</a></div><div><b>Author(s):&nbsp;</b>Hao Zhang, Lianbo Ma, Junyi Wang, Liang Wang</div><div><b>Pages:&nbsp;</b>544 - 555</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9314924/\">O-SegNet: Robust Encoder and Decoder Architecture for Objects Segmentation From Aerial Imagery Data</a></div><div><b>Author(s):&nbsp;</b>Karuna Kumari Eerapu, Shyam Lal, A. V. Narasimhadhan</div><div><b>Pages:&nbsp;</b>556 - 567</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9739038/\">Multiagent Reinforcement Learning for Community Energy Management to Mitigate Peak Rebounds Under Renewable Energy Uncertainty</a></div><div><b>Author(s):&nbsp;</b>Bo-Chen Lai, Wei-Yu Chiu, Yuan-Po Tsai</div><div><b>Pages:&nbsp;</b>568 - 579</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9422365/\">Attend to Where and When: Cascaded Attention Network for Facial Expression Recognition</a></div><div><b>Author(s):&nbsp;</b>Xiaoye Qu, Zhikang Zou, Xinxing Su, Pan Zhou, Wei Wei, Shiping Wen, Dapeng Wu</div><div><b>Pages:&nbsp;</b>580 - 592</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9512550/\">TMFNet: Three-Input Multilevel Fusion Network for Detecting Salient Objects in RGB-D Images</a></div><div><b>Author(s):&nbsp;</b>Wujie Zhou, Sijia Pan, Jingsheng Lei, Lu Yu</div><div><b>Pages:&nbsp;</b>593 - 601</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9349964/\">Optimized Bezier Curve Based Intensity Mapping Scheme for Low Light Image Enhancement</a></div><div><b>Author(s):&nbsp;</b>Magudeeswaran Veluchamy, Ashish Kumar Bhandari, Bharath Subramani</div><div><b>Pages:&nbsp;</b>602 - 612</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9354230/\">A Generalized Deep Neural Network Approach for Digital Watermarking Analysis</a></div><div><b>Author(s):&nbsp;</b>Weiping Ding, Yurui Ming, Zehong Cao, Chin-Teng Lin</div><div><b>Pages:&nbsp;</b>613 - 627</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9386216/\">Remodelling State-Space Prediction With Deep Neural Networks for Probabilistic Load Forecasting</a></div><div><b>Author(s):&nbsp;</b>Parul Arora, Abbas Khosravi, B. K. Panigrahi, P. N. Suganthan</div><div><b>Pages:&nbsp;</b>628 - 637</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9395505/\">Frequent Pattern Mining in Big Social Graphs</a></div><div><b>Author(s):&nbsp;</b>Lei Li, Ping Ding, Huanhuan Chen, Xindong Wu</div><div><b>Pages:&nbsp;</b>638 - 648</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9410461/\">Anomaly Detection in Resource Constrained Environments With Streaming Data</a></div><div><b>Author(s):&nbsp;</b>Prarthi Jain, Seemandhar Jain, Osmar R. Za\u00efane, Abhishek Srivastava</div><div><b>Pages:&nbsp;</b>649 - 659</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9439895/\">Information Cartography in Association Rule Mining</a></div><div><b>Author(s):&nbsp;</b>Iztok Fister, Iztok Fister</div><div><b>Pages:&nbsp;</b>660 - 676</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9430169/\">Multi-Label Classification Using Binary Tree of Classifiers</a></div><div><b>Author(s):&nbsp;</b>Anwesha Law, Ashish Ghosh</div><div><b>Pages:&nbsp;</b>677 - 689</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9576079/\">A New Semi-Supervised Fault Diagnosis Method via Deep CORAL and Transfer Component Analysis</a></div><div><b>Author(s):&nbsp;</b>Xinyu Li, Zhao Zhang, Liang Gao, Long Wen</div><div><b>Pages:&nbsp;</b>690 - 699</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9509400/\">StreamSoNG: A Soft Streaming Classification Approach</a></div><div><b>Author(s):&nbsp;</b>Wenlong Wu, James M. Keller, Jeffrey Dale, James C. Bezdek</div><div><b>Pages:&nbsp;</b>700 - 709</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9509578/\">Granular Symmetric Implicational Method</a></div><div><b>Author(s):&nbsp;</b>Yiming Tang, Witold Pedrycz, Fuji Ren</div><div><b>Pages:&nbsp;</b>710 - 723</div><div><br /></div>",
            "pubdate": "2022-05-27T09:24:00.000+12:00",
            "pubdate_parsed": [
                2022,
                5,
                26
            ],
            "email_sent": true
        },
        "IEEE Transactions on Artificial Intelligence, Volume 3, Issue 3, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/05/ieee-transactions-on-artificial.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9664332/\">A Survey on Masked Facial Detection Methods and Datasets for Fighting Against COVID-19</a></div><div><b>Author(s): </b>Bingshu Wang, Jiangbin Zheng, C. L. Philip Chen</div><div><b>Pages: </b>323 - 343</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9645324/\">FairDrop: Biased Edge Dropout for Enhancing Fairness in Graph Representation Learning</a></div><div><b>Author(s):&nbsp;</b>Indro Spinelli, Simone Scardapane, Amir Hussain, Aurelio Uncini</div><div><b>Pages:&nbsp;</b>344 - 354</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9566791/\">Assessment of the Clusterability of Data Using a Multimodal Convolutional Neural Network</a></div><div><b>Author(s):&nbsp;</b>Niko Reunanen, Tomi R\u00e4ty, Timo Lintonen, Juho J. Jokinen</div><div><b>Pages:&nbsp;</b>355 - 369</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9744422/\">Unsupervised Domain-Adaptation-Based Tensor Feature Learning With Structure Preservation</a></div><div><b>Author(s):&nbsp;</b>Ali Braytee, Mohamad Naji, Paul J. Kennedy</div><div><b>Pages:&nbsp;</b>370 - 380</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9612606/\">Quick Learning Mechanism With Cross-Domain Adaptation for Intelligent Fault Diagnosis</a></div><div><b>Author(s):&nbsp;</b>Arun K. Sharma, Nishchal K. Verma</div><div><b>Pages:&nbsp;</b>381 - 390</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9640487/\">Distributed GAN: Toward a Faster Reinforcement-Learning-Based Architecture Search</a></div><div><b>Author(s):&nbsp;</b>Jiachen Shi, Yi Fan, Guoqiang Zhou, Jun Shen</div><div><b>Pages:&nbsp;</b>391 - 401</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9668998/\">Spherical Linguistic Petri Nets for Knowledge Representation and Reasoning Under Large Group Environment</a></div><div><b>Author(s):&nbsp;</b>Xun Mou, Ling-Xiang Mao, Hu-Chen Liu, MengChu Zhou</div><div><b>Pages:&nbsp;</b>402 - 413</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9699063/\">Distributed Semisupervised Partial Label Learning Over Networks</a></div><div><b>Author(s):&nbsp;</b>Ying Liu, Zhen Xu, Chen Zhang</div><div><b>Pages:&nbsp;</b>414 - 425</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9684723/\">System Neural Network: Evolution and Change Based Structure Learning</a></div><div><b>Author(s):&nbsp;</b>Animesh Chaturvedi, Aruna Tiwari, Shubhangi Chaturvedi, Pietro Li\u00f2</div><div><b>Pages:&nbsp;</b>426 - 435</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9648029/\">Evolutionary Neural Architecture Search for Automatic Esophageal Lesion Identification and Segmentation</a></div><div><b>Author(s):&nbsp;</b>Yao Zhou, Xianglei Yuan, Xiaozhi Zhang, Wei Liu, Yu Wu, Gary G. Yen, Bing Hu, Zhang Yi</div><div><b>Pages:&nbsp;</b>436 - 450</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9576645/\">Robot Path Planning via Neural-Network-Driven Prediction</a></div><div><b>Author(s):&nbsp;</b>Jiankun Wang, Jianbang Liu, Weinan Chen, Wenzheng Chi, Max Q.-H. Meng</div><div><b>Pages:&nbsp;</b>451 - 460</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9612011/\">Bidirectional Gated Recurrent Unit-Based Lower Upper Bound Estimation Method for Wind Power Interval Prediction</a></div><div><b>Author(s):&nbsp;</b>Fang Liu, Qing Tao, Dechang Yang, Denis Sidorov</div><div><b>Pages:&nbsp;</b>461 - 469</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9691915/\">Attacks on Data-Driven Process Monitoring Systems: Subspace Transfer Networks</a></div><div><b>Author(s):&nbsp;</b>Xiaoyu Jiang, Zhiqiang Ge</div><div><b>Pages:&nbsp;</b>470 - 484</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9653852/\">Deep Multiscale Multi-Instance Networks With Regional Scoring for Mammogram Classification</a></div><div><b>Author(s):&nbsp;</b>Wenjie Liu, Xin Shu, Lei Zhang, Dong Li, Qing Lv</div><div><b>Pages:&nbsp;</b>485 - 496</div><div><br /></div><div><br /></div>",
            "pubdate": "2022-05-30T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                5,
                30
            ],
            "email_sent": true
        },
        "Weekly Review 3 June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/weekly-review-3-june-2022.html",
            "description": "Some interesting links that I&nbsp;<a href=\"https://twitter.com/DrMikeWatts\">Tweeted</a>&nbsp;about this week:<br /><p></p><div> <b>1)</b> An improved method for detecting deepfake images, using an improved training set: <a href=\"https://dataconomy.com/2022/05/detecting-deepfakes-self-blended-images/\">https://dataconomy.com/2022/05/detecting-deepfakes-self-blended-images/</a></div><div><br /></div><div> <b>2)</b> Why am I not surprised that it's Amazon that is leading the way in using AI enabled cameras to monitor its staff? <a href=\"https://www.theregister.com/2022/05/24/ai_cameras_amazon/\">https://www.theregister.com/2022/05/24/ai_cameras_amazon/</a></div><div><br /></div><div><b>3)</b> Google has demoed a new conversational AI, but it's still not available to anyone else: <a href=\"https://www.datanami.com/2022/05/16/google-debuts-lamda-2-conversational-ai-system-and-ai-test-kitchen/\">https://www.datanami.com/2022/05/16/google-debuts-lamda-2-conversational-ai-system-and-ai-test-kitchen/</a></div><div><br /></div><div><b>4)</b> Two opposing schools of thought on the future of artificial general intelligence: <a href=\"https://dataconomy.com/2022/05/future-of-artificial-general-intelligence/\">https://dataconomy.com/2022/05/future-of-artificial-general-intelligence/</a></div><div><br /></div><div><b>5)</b> Yet another supercomputer for AI. <a href=\"https://www.theregister.com/2022/05/25/hpe_cerebras_lrz/\">https://www.theregister.com/2022/05/25/hpe_cerebras_lrz/</a> At which point do these supercomputers start to encounter diminishing returns? That is, when will throwing more processing power at a problem no longer yield better results?</div><div><br /></div><div><b>6)</b> The ethics of AI must also or even primarily include the ethics of the data sets used. This increasingly means respect the privacy of data: <a href=\"https://www.theregister.com/2022/05/23/clearview_ai_ico_fine/\">https://www.theregister.com/2022/05/23/clearview_ai_ico_fine/</a></div><div><br /></div><div><b>7)</b> The advantages and disadvantages of using AI in manufacturing: <a href=\"https://www.datasciencecentral.com/pros-and-cons-of-ai-in-manufacturing/\">https://www.datasciencecentral.com/pros-and-cons-of-ai-in-manufacturing/</a></div><div><br /></div><div><b>8)</b> Another cloud-based #AI platform launches: <a href=\"https://www.datanami.com/2022/05/11/graft-emerges-from-stealth-to-make-the-ai-of-the-1-accessible-to-the-99/\">https://www.datanami.com/2022/05/11/graft-emerges-from-stealth-to-make-the-ai-of-the-1-accessible-to-the-99/</a></div><div><br /></div><div><b>9)</b> A COVID19 treatment discovered by AI: <a href=\"https://www.theregister.com/2022/05/25/covid19_medication_ai/\">https://www.theregister.com/2022/05/25/covid19_medication_ai/</a></div><div><br /></div><div><b>10)</b> You cannot trust a&nbsp; Machine Learning model you didn't train yourself: <a href=\"https://dataconomy.com/2022/05/undetectable-backdoors-machine-learning/\">https://dataconomy.com/2022/05/undetectable-backdoors-machine-learning/</a></div><div><br /></div><div style=\"text-align: left;\"><b>11)</b> A tool from Google that uses AI to help you prepare for job interviews: <a href=\"https://dataconomy.com/2022/05/google-interview-warmup-ai-in-recruitment/\">https://dataconomy.com/2022/05/google-interview-warmup-ai-in-recruitment/</a>&nbsp;</div><p><b>12)</b>&nbsp;Google has banned the creation of DeepFake models on its Colab platform: <a href=\"https://techcrunch.com/2022/06/01/2328459/\">https://techcrunch.com/2022/06/01/2328459/&nbsp;</a></p><p><b>13)</b>&nbsp;A list of articles on ethics in AI: <a href=\"https://www.informationweek.com/big-data/quick-study-artificial-intelligence-ethics-and-bias\">https://www.informationweek.com/big-data/quick-study-artificial-intelligence-ethics-and-bias</a></p><p><b>14)</b>&nbsp;If an AI defamed someone, who would be liable? <a href=\"https://techcrunch.com/2022/06/01/whos-liable-for-ai-generated-lies/\">https://techcrunch.com/2022/06/01/whos-liable-for-ai-generated-lies/</a></p><p></p>",
            "pubdate": "2022-06-03T23:00:00.013+12:00",
            "pubdate_parsed": [
                2022,
                6,
                3
            ],
            "email_sent": true
        },
        "IEEE Transactions on Evolutionary Computation, Volume 26, Issue 3, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/ieee-transactions-on-evolutionary.html",
            "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9507530/\">PSO-<i>X</i>: A Component-Based Framework for the Automatic Design of Particle Swarm Optimization Algorithms</a></div><div><b>Author(s): </b>Christian L. Camacho-Villal\u00f3n, Marco Dorigo, Thomas St\u00fctzle</div><div><b>Pages: </b>402 - 416</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9477421/\">MO4: A Many-Objective Evolutionary Algorithm for Protein Structure Prediction</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Lei, Shangce Gao, Zhiming Zhang, MengChu Zhou, Jiujun Cheng</div><div><b>Pages:&nbsp;</b>417 - 430</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9512284/\">Dynamic Optimization in Fast-Changing Environments via Offline Evolutionary Search</a></div><div><b>Author(s):&nbsp;</b>Xiaofen Lu, Ke Tang, Stefan Menzel, Xin Yao</div><div><b>Pages:&nbsp;</b>431 - 445</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9496593/\">Evolutionary Multitasking for Feature Selection in High-Dimensional Classification via Particle Swarm Optimization</a></div><div><b>Author(s):&nbsp;</b>Ke Chen, Bing Xue, Mengjie Zhang, Fengyu Zhou</div><div><b>Pages:&nbsp;</b>446 - 460</div><div><br /></div><div><b>5) </b><a href=\"https://ieeexplore.ieee.org/document/9518387/\">A Cooperative Memetic Algorithm With Learning-Based Agent for Energy-Aware Distributed Hybrid Flow-Shop Scheduling</a></div><div><b>Author(s):&nbsp;</b>Jing-Jing Wang, Ling Wang</div><div><b>Pages:&nbsp;</b>461 - 475</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9481257/\">Analyzing Dominance Move (MIP-DoM) Indicator for Multiobjective and Many-Objective Optimization</a></div><div><b>Author(s):&nbsp;</b>Claudio Lucio do Val Lopes, Fl\u00e1vio Vin\u00edcius Cruzeiro Martins, Elizabeth Fialho Wanner, Kalyanmoy Deb</div><div><b>Pages:&nbsp;</b>476 - 489</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9524335/\">Black-Box Optimization Revisited: Improving Algorithm Selection Wizards Through Massive Benchmarking</a></div><div><b>Author(s):&nbsp;</b>Laurent Meunier, Herilalaina Rakotoarison, Pak Kan Wong, Baptiste Roziere, J\u00e9r\u00e9my Rapin, Olivier Teytaud, Antoine Moreau, Carola Doerr</div><div><b>Pages:&nbsp;</b>490 - 500</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9531957/\">Theory of (1 + 1) ES on the RIDGE</a></div><div><b>Author(s):&nbsp;</b>Alexandru Agapie, Ovidiu Solomon, Marius Giuclea</div><div><b>Pages:&nbsp;</b>501 - 511</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9486864/\">Multipopulation Ant Colony System With Knowledge-Based Local Searches for Multiobjective Supply Chain Configuration</a></div><div><b>Author(s):&nbsp;</b>Xin Zhang, Zhi-Hui Zhan, Wei Fang, Pengjiang Qian, Jun Zhang</div><div><b>Pages:&nbsp;</b>512 - 526</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9555836/\">Static and Dynamic Multimodal Optimization by Improved Covariance Matrix Self-Adaptation Evolution Strategy With Repelling Subpopulations</a></div><div><b>Author(s):&nbsp;</b>Ali Ahrari, Saber Elsayed, Ruhul Sarker, Daryl Essam, Carlos A. Coello Coello</div><div><b>Pages:&nbsp;</b>527 - 541</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9669184/\">Dynamic Transfer Reference Point-Oriented MOEA/D Involving Local Objective-Space Knowledge</a></div><div><b>Author(s):&nbsp;</b>Yingbo Xie, Shengxiang Yang, Ding Wang, Junfei Qiao, Baocai Yin</div><div><b>Pages:&nbsp;</b>542 - 554</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9499117/\">Dual-Tree Genetic Programming for Few-Shot Image Classification</a></div><div><b>Author(s):&nbsp;</b>Ying Bi, Bing Xue, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>555 - 569</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9612583/\">Memetic EDA-Based Approaches to QoS-Aware Fully Automated Semantic Web Service Composition</a></div><div><b>Author(s):&nbsp;</b>Chen Wang, Hui Ma, Gang Chen, Sven Hartmann</div><div><b>Pages:&nbsp;</b>570 - 584</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9530458/\">Toward Large-Scale Evolutionary Multitasking: A GPU-Based Paradigm</a></div><div><b>Author(s):&nbsp;</b>Yuxiao Huang, Liang Feng, Alex Kai Qin, Meng Chen, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>585 - 598</div><div><br /></div>",
            "pubdate": "2022-06-06T12:00:00.004+12:00",
            "pubdate_parsed": [
                2022,
                6,
                6
            ],
            "email_sent": true
        },
        "IEEE Transactions on Fuzzy Systems, Volume 30, Issue 6, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9786023/\">Guest Editorial Special Issue on Cyborg Intelligence: Human Enhancement With Fuzzy Sets</a></div><div><b>Author(s): </b>Zhijun Li, Jian Huang, Hang Su, Zhaojie Ju</div><div><b>Pages: </b>1502 - 1505</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9662203/\">Incremental Motor Skill Learning and Generalization From Human Dynamic Reactions Based on Dynamic Movement Primitives and Fuzzy Logic System</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Lu, Ning Wang, Miao Li, Chenguang Yang</div><div><b>Pages:&nbsp;</b>1506 - 1515</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9690032/\">Explainable CNN With Fuzzy Tree Regularization for Respiratory Sound Analysis</a></div><div><b>Author(s):&nbsp;</b>Jianqiang Li, Cheng Wang, Jie Chen, Heng Zhang, Yuyan Dai, Lingwei Wang, Li Wang, Asoke K. Nandi</div><div><b>Pages:&nbsp;</b>1516 - 1528</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9737383/\">Generalized Point Set Registration With Fuzzy Correspondences Based on Variational Bayesian Inference</a></div><div><b>Author(s):&nbsp;</b>Ang Zhang, Zhe Min, Zhengyan Zhang, Max Q.-H. Meng</div><div><b>Pages:&nbsp;</b>1529 - 1540</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9743751/\">Fuzzy Enhanced Adaptive Admittance Control of a Wearable Walking Exoskeleton With Step Trajectory Shaping</a></div><div><b>Author(s):&nbsp;</b>Pengbo Huang, Zhijun Li, MengChu Zhou, Xiang Li, Mengyue Cheng</div><div><b>Pages:&nbsp;</b>1541 - 1552</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9735420/\">A Muscle Synergy-Driven ANFIS Approach to Predict Continuous Knee Joint Movement</a></div><div><b>Author(s):&nbsp;</b>Wenjuan Zhong, Xueming Fu, Mingming Zhang</div><div><b>Pages:&nbsp;</b>1553 - 1563</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9729601/\">Fuzzy Approximation-Based Task-Space Control of Robot Manipulators With Remote Center of Motion Constraint</a></div><div><b>Author(s):&nbsp;</b>Hang Su, Wen Qi, Jiahao Chen, Dandan Zhang</div><div><b>Pages:&nbsp;</b>1564 - 1573</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9757861/\">Adaptability Control Towards Complex Ground Based on Fuzzy Logic for Humanoid Robots</a></div><div><b>Author(s):&nbsp;</b>Chencheng Dong, Zhangguo Yu, Xuechao Chen, Huanzhong Chen, Yan Huang, Qiang Huang</div><div><b>Pages:&nbsp;</b>1574 - 1584</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9366404/\">Reducing Criteria in Multicriteria Group Decision-Making Methods Using Hierarchical Clustering Methods and Fuzzy Ontologies</a></div><div><b>Author(s):&nbsp;</b>Juan Antonio Morente-Molinera, Yinglin Wang, Zai-Wu Gong, A. Morfeq, Rami Al-Hmouz, Enrique Herrera-Viedma</div><div><b>Pages:&nbsp;</b>1585 - 1598</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9366349/\">Building Trend Fuzzy Granulation-Based LSTM Recurrent Neural Network for Long-Term Time-Series Forecasting</a></div><div><b>Author(s):&nbsp;</b>Yuqing Tang, Fusheng Yu, Witold Pedrycz, Xiyang Yang, Jiayin Wang, Shihu Liu</div><div><b>Pages:&nbsp;</b>1599 - 1613</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9366943/\">Membership-Function-Dependent Control Design and Stability Analysis of Interval Type-2 Sampled-Data Fuzzy-Model-Based Control System</a></div><div><b>Author(s):&nbsp;</b>Ming Chen, Hak-Keung Lam, Bo Xiao, Chengbin Xuan</div><div><b>Pages:&nbsp;</b>1614 - 1623</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9369886/\">A Novel Kernelized Total Bregman Divergence-Driven Possibilistic Fuzzy Clustering With Multiple Information Constraints for Image Segmentation</a></div><div><b>Author(s):&nbsp;</b>Chengmao Wu, Xue Zhang</div><div><b>Pages:&nbsp;</b>1624 - 1639</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9369889/\">Stability Analysis for Mamdani-Type Integral Fuzzy-Based Sliding-Mode Control of Systems Under Persistent Disturbances</a></div><div><b>Author(s):&nbsp;</b>Pablo J. Prieto, Luis T. Aguilar, Selene L. Cardenas-Maciel, Jorge A. Lopez-Renteria, Nohe R. Cazarez-Castro</div><div><b>Pages:&nbsp;</b>1640 - 1647</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9369865/\">Exponential Stability of Stochastic Takagi-Sugeno Fuzzy Systems Under Intermittent Dynamic Event-Triggered Control</a></div><div><b>Author(s):&nbsp;</b>Yongbao Wu, Sai Hu, Wenxue Li</div><div><b>Pages:&nbsp;</b>1648 - 1659</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9372886/\">Novel Pythagorean Fuzzy Correlation Measures Via Pythagorean Fuzzy Deviation, Variance, and Covariance With Applications to Pattern Recognition and Career Placement</a></div><div><b>Author(s):&nbsp;</b>Paul Augustine Ejegwa, Shiping Wen, Yuming Feng, Wei Zhang, Ning Tang</div><div><b>Pages:&nbsp;</b>1660 - 1668</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9373968/\">Inverse Optimal Design of Direct Adaptive Fuzzy Controllers for Uncertain Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Kaixin Lu, Zhi Liu, C. L. Philip Chen, Yaonan Wang, Yun Zhang</div><div><b>Pages:&nbsp;</b>1669 - 1682</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9373964/\">Incremental Feature Selection Using a Conditional Entropy Based on Fuzzy Dominance Neighborhood Rough Sets</a></div><div><b>Author(s):&nbsp;</b>Binbin Sang, Hongmei Chen, Lei Yang, Tianrui Li, Weihua Xu</div><div><b>Pages:&nbsp;</b>1683 - 1697</div><div><br /></div><div><b>18) </b><a href=\"https://ieeexplore.ieee.org/document/9373994/\">A Novel Extension of Best-Worst Method With Intuitionistic Fuzzy Reference Comparisons</a></div><div><b>Author(s):&nbsp;</b>Shuping Wan, Jiuying Dong</div><div><b>Pages:&nbsp;</b>1698 - 1711</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9373926/\">Fractional Sliding-Mode Control for Microgyroscope Based on Multilayer Recurrent Fuzzy Neural Network</a></div><div><b>Author(s):&nbsp;</b>Juntao Fei, Zhe Wang, Xiao Liang, Zhilin Feng, Yuncan Xue</div><div><b>Pages:&nbsp;</b>1712 - 1721</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9376301/\">Static Output-Feedback Tracking Control for Positive Polynomial Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Lining Fu, H. K. Lam, Fucai Liu, Bo Xiao, Zhixiong Zhong</div><div><b>Pages:&nbsp;</b>1722 - 1733</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9376264/\">Fuzzy Intermittent Extended Dissipative Control for Delayed Distributed Parameter Systems With Stochastic Disturbance: A Spatial Point Sampling Approach</a></div><div><b>Author(s):&nbsp;</b>Kui Ding, Quanxin Zhu</div><div><b>Pages:&nbsp;</b>1734 - 1749</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9376268/\">Event-Triggered Adaptive Fault-Tolerant Control for Nonaffine Uncertain Systems With Output Tracking Errors Constraints</a></div><div><b>Author(s):&nbsp;</b>Yang Wu, Guoshan Zhang, Li-Bing Wu</div><div><b>Pages:&nbsp;</b>1750 - 1761</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9378943/\">Ordinal Sum of Two Binary Operations Being a T-Norm on Bounded Lattice</a></div><div><b>Author(s):&nbsp;</b>Xinxing Wu, Qin Zhang, Xu Zhang, G\u00fcl Deniz \u00c7ayl\u0131, Lidong Wang</div><div><b>Pages:&nbsp;</b>1762 - 1772</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9381663/\">Switched-Observer-Based Event-Triggered Adaptive Fuzzy Funnel Control for Switched Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Fenglan Wang, Lijun Long</div><div><b>Pages:&nbsp;</b>1773 - 1787</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9382881/\">Design and Optimization of Robust Path Tracking Control for Autonomous Vehicles With Fuzzy Uncertainty</a></div><div><b>Author(s):&nbsp;</b>Zeyu Yang, Jin Huang, Diange Yang, Zhihua Zhong</div><div><b>Pages:&nbsp;</b>1788 - 1800</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9382904/\">Finite-Time Almost Sure Stability of a Markov Jump Fuzzy System With Delayed Inputs</a></div><div><b>Author(s):&nbsp;</b>He Zhang, Shengyuan Xu</div><div><b>Pages:&nbsp;</b>1801 - 1808</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9388897/\">Adaptive Fuzzy Decentralized Sampled-Data Control for Large-Scale Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Yongming Li, Kunting Yu</div><div><b>Pages:&nbsp;</b>1809 - 1822</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9388934/\">High-Efficient Fuzzy Querying With HiveQL for Big Data Warehousing</a></div><div><b>Author(s):&nbsp;</b>Bo\u017cena Ma\u0142ysiak-Mrozek, Jadwiga Wieszok, Witold Pedrycz, Weiping Ding, Dariusz Mrozek</div><div><b>Pages:&nbsp;</b>1823 - 1837</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9388899/\">Design of a Fuzzy Adaptive Sliding Mode Control System for MEMS Tunable Capacitors in Voltage Reference Applications</a></div><div><b>Author(s):&nbsp;</b>Ehsan Ranjbar, Amir Abolfazl Suratgar, Mohammad Bagher Menhaj, Mukesh Prasad</div><div><b>Pages:&nbsp;</b>1838 - 1852</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9388942/\">Event-Based H\u221e Control for Discrete-Time Fuzzy Markov Jump Systems Subject to DoS Attacks</a></div><div><b>Author(s):&nbsp;</b>Pengyu Zeng, Feiqi Deng, Hongyang Zhang, Xiaobin Gao</div><div><b>Pages:&nbsp;</b>1853 - 1863</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9392358/\">Further Results on Sampled-Data H\u221e Filtering for T-S Fuzzy Systems With Asynchronous Premise Variables</a></div><div><b>Author(s):&nbsp;</b>Yongsik Jin, Wookyong Kwon, Sangmoon Lee</div><div><b>Pages:&nbsp;</b>1864 - 1874</div><div><br /></div><div><b>32)</b>&nbsp;<a href=\"https://ieeexplore.ieee.org/document/9392325/\">H\u221e PID Control for Discrete-Time Fuzzy Systems With Infinite-Distributed Delays Under Round-Robin Communication Protocol</a></div><div><b>Author(s):&nbsp;</b>Yezheng Wang, Zidong Wang, Lei Zou, Hongli Dong</div><div><b>Pages:&nbsp;</b>1875 - 1888</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9392283/\">Observer-Based Sliding Mode Control for Networked Fuzzy Singularly Perturbed Systems Under Weighted Try-Once-Discard Protocol</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Chengyu Yang, Jianwei Xia, Zheng-Guang Wu, Hao Shen</div><div><b>Pages:&nbsp;</b>1889 - 1899</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9392347/\">Interactive Transfer Learning-Assisted Fuzzy Neural Network</a></div><div><b>Author(s):&nbsp;</b>Honggui Han, Hongxu Liu, Zheng Liu, Junfei Qiao</div><div><b>Pages:&nbsp;</b>1900 - 1913</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9394772/\">Fault-Tolerant Tracking Control of Discrete-Time T-S Fuzzy Systems With Input Constraint</a></div><div><b>Author(s):&nbsp;</b>Iman Zare, Peyman Setoodeh, Mohammad Hassan Asemani</div><div><b>Pages:&nbsp;</b>1914 - 1928</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9394750/\">Fuzzy Lyapunov-Based Model Predictive Sliding-Mode Control of Nonlinear Systems: An Ellipsoid Recursive Feasibility Approach</a></div><div><b>Author(s):&nbsp;</b>Mohsen Farbood, Mokhtar Shasadeghi, Taher Niknam, Behrouz Safarinejadian</div><div><b>Pages:&nbsp;</b>1929 - 1938</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9394792/\">Event-Based Adaptive Fuzzy Fixed-Time Secure Control for Nonlinear CPSs Against Unknown False Data Injection and Backlash-Like Hysteresis</a></div><div><b>Author(s):&nbsp;</b>Shuai Song, Ju H. Park, Baoyong Zhang, Xiaona Song</div><div><b>Pages:&nbsp;</b>1939 - 1951</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9400708/\">Characterizations and Applications of Fuzzy Implications Generated by a Pair of Generators of <i>T</i>-Norms and the Usual Addition of Real Numbers</a></div><div><b>Author(s):&nbsp;</b>Hongjun Zhou</div><div><b>Pages:&nbsp;</b>1952 - 1966</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9400738/\">Fast Training of Adversarial Deep Fuzzy Classifier by Downsizing Fuzzy Rules With Gradient Guided Learning</a></div><div><b>Author(s):&nbsp;</b>Suhang Gu, Chi Man Vong, Pak Kin Wong, Shitong Wang</div><div><b>Pages:&nbsp;</b>1967 - 1980</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9403972/\">Reachability Analysis-Based Interval Estimation for Discrete-Time Takagi-Sugeno Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Shenghui Guo, Weijie Ren, Choon Ki Ahn, Chenglin Wen, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>1981 - 1992</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9403990/\">Adaptive Fuzzy Prescribed Finite-Time Tracking Control for Nonlinear System With Unknown Control Directions</a></div><div><b>Author(s):&nbsp;</b>Yang Liu, Huaguang Zhang, Yingchun Wang, He Ren, Qiaochu Li</div><div><b>Pages:&nbsp;</b>1993 - 2003</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9404860/\">H-Rank Consensus Models for Fuzzy Preference Relations Considering Eliminating Rank Violations</a></div><div><b>Author(s):&nbsp;</b>Jiancheng Tu, Zhibin Wu</div><div><b>Pages:&nbsp;</b>2004 - 2018</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9404849/\">Social Trust Driven Consensus Reaching Model With a Minimum Adjustment Feedback Mechanism Considering Assessments-Modifications Willingness</a></div><div><b>Author(s):&nbsp;</b>Hengjie Zhang, Fang Wang, Yucheng Dong, Francisco Chiclana, Enrique Herrera-Viedma</div><div><b>Pages:&nbsp;</b>2019 - 2031</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9404851/\">Event-Based Secure Control of T-S Fuzzy-Based 5-DOF Active Semivehicle Suspension Systems Subject to DoS Attacks</a></div><div><b>Author(s):&nbsp;</b>Zhou Gu, Xiang Sun, Hak-Keung Lam, Dong Yue, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>2032 - 2043</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9406360/\">Fuzzy-Control-Based Chance-Constrained Programming for Humanitarian Relief Allocation Problem</a></div><div><b>Author(s):&nbsp;</b>Jianghua Zhang, Yang Liu, Xiaojie Su, Peng Shi</div><div><b>Pages:&nbsp;</b>2044 - 2054</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9408425/\">Spatial Colocation Pattern Discovery Incorporating Fuzzy Theory</a></div><div><b>Author(s):&nbsp;</b>Xiaoxuan Wang, Le Lei, Lizhen Wang, Peizhong Yang, Hongmei Chen</div><div><b>Pages:&nbsp;</b>2055 - 2072</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9409687/\">A Novel Data-Driven Approach to Autonomous Fuzzy Clustering</a></div><div><b>Author(s):&nbsp;</b>Xiaowei Gu, Qiang Ni, Guolin Tang</div><div><b>Pages:&nbsp;</b>2073 - 2085</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9416157/\">Membership-Function-Dependent Design of L1-Gain Output-Feedback Controller for Stabilization of Positive Polynomial Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Aiwen Meng, Hak-Keung Lam, Fucai Liu, Yingjie Yang</div><div><b>Pages:&nbsp;</b>2086 - 2100</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9416181/\">Robust Actor-Critic Learning for Continuous-Time Nonlinear Systems With Unmodeled Dynamics</a></div><div><b>Author(s):&nbsp;</b>Yongliang Yang, Weinan Gao, Hamidreza Modares, Cheng-Zhong Xu</div><div><b>Pages:&nbsp;</b>2101 - 2112</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9376312/\">Some Consistency Properties and Individual Preference Monotonicity for Weighted Aggregation Operators</a></div><div><b>Author(s):&nbsp;</b>Lesheng Jin</div><div><b>Pages:&nbsp;</b>2113 - 2117</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9380521/\">Decentralized Event-Triggered Adaptive Fuzzy Control for Nonlinear Switched Large-Scale Systems With Input Delay Via Command-Filtered Backstepping</a></div><div><b>Author(s):&nbsp;</b>Jing Zhang, Shi Li, Choon Ki Ahn, Zhengrong Xiang</div><div><b>Pages:&nbsp;</b>2118 - 2123</div><div><br /></div><div><b>52)</b> <a href=\"https://ieeexplore.ieee.org/document/9388891/\">Expected Shortfall for the Makespan in Activity Networks With Fuzzy Durations</a></div><div><b>Author(s):&nbsp;</b>Gabriella Dellino, Carlo Meloni, Marco Pranzo, Marcella Sam\u00e0</div><div><b>Pages:&nbsp;</b>2124 - 2128</div><div><br /></div><div><b>53)</b> <a href=\"https://ieeexplore.ieee.org/document/9403919/\">Finite-Time Fuzzy Control for Nonlinear Singularly Perturbed Systems With Input Constraints</a></div><div><b>Author(s):&nbsp;</b>Feng Li, Wei Xing Zheng, Shengyuan Xu</div><div><b>Pages:&nbsp;</b>2129 - 2134</div><div><br /></div><div><b>54)</b> <a href=\"https://ieeexplore.ieee.org/document/9419725/\">An Asymmetric Lyapunov-Krasovskii Functional Method on Stability and Stabilization for T-S Fuzzy Systems With Time Delay</a></div><div><b>Author(s):&nbsp;</b>Zhaoliang Sheng, Chong Lin, Bing Chen, Qing-Guo Wang</div><div><b>Pages:&nbsp;</b>2135 - 2140</div><div><br /></div></div>",
            "pubdate": "2022-06-07T12:00:00.198+12:00",
            "pubdate_parsed": [
                2022,
                6,
                7
            ],
            "email_sent": true
        },
        "Complex & Intelligent Systems, Volume 8, issue 3, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/complex-intelligent-systems-volume-8.html",
            "description": "<div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00736-3\">Guest Editorial on \u201cComputational intelligence in analysis and integration of complex systems\u201d</a></div><div><b>Author(s): </b>Bo Zhao, Wenyi Zeng...Qichao Zhang</div><div><b>Pages: </b>1819 - 1821</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00323-y\">FSD-SLAM: a fast semi-direct SLAM algorithm</a></div><div><b>Author(s):&nbsp;</b>Xiang Dong, Long Cheng...Teng Li</div><div><b>Pages:&nbsp;</b>1823 - 1834</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00330-z\">A tractor-trailer parking control scheme using adaptive dynamic programming</a></div><div><b>Author(s):&nbsp;</b>Chenyong Guan, Yu Jiang</div><div><b>Pages:&nbsp;</b>1835 - 1845</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00322-z\">Remote sensing image building detection method based on Mask R-CNN</a></div><div><b>Author(s):&nbsp;</b>Qinzhe Han, Qian Yin...Ziyi Chen</div><div><b>Pages:&nbsp;</b>1847 - 1855</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00345-6\">A game strategy model in the digital curling system based on NFSP</a></div><div><b>Author(s):&nbsp;</b>Yuntao Han, Qibin Zhou, Fuqing Duan</div><div><b>Pages:&nbsp;</b>1857 - 1863</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00347-4\">ResCaps: an improved capsule network and its application in ultrasonic image classification of thyroid papillary carcinoma</a></div><div><b>Author(s):&nbsp;</b>Xiongzhi Ai, Jiawei Zhuang...Yu Fu</div><div><b>Pages:&nbsp;</b>1865 - 1873</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00360-7\">Deep transfer learning: a novel glucose prediction framework for new subjects with type 2 diabetes</a></div><div><b>Author(s):&nbsp;</b>Xia Yu, Tao Yang...Jian Zhou</div><div><b>Pages:&nbsp;</b>1875 - 1887</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00334-9\">Sliding-mode observers based distributed consensus control for nonlinear multi-agent systems with disturbances</a></div><div><b>Author(s):&nbsp;</b>Yulian Jiang, Yuhang Zhang...Keping Liu</div><div><b>Pages:&nbsp;</b>1889 - 1897</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00366-1\">Collision-free path planning for welding manipulator via hybrid algorithm of deep reinforcement learning and inverse kinematics</a></div><div><b>Author(s):&nbsp;</b>Jie Zhong, Tao Wang, Lianglun Cheng</div><div><b>Pages:&nbsp;</b>1899 - 1912</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00359-0\">Compensator-critic structure-based event-triggered decentralized tracking control of modular robot manipulators: theory and experimental verification</a></div><div><b>Author(s):&nbsp;</b>Bing Ma, Yuanchun Li</div><div><b>Pages:&nbsp;</b>1913 - 1927</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00376-z\">A deep learning-based computer-aided diagnosis method of X-ray images for bone age assessment</a></div><div><b>Author(s):&nbsp;</b>Shaowei Li, Bowen Liu...Dongxu Zhang</div><div><b>Pages:&nbsp;</b>1929 - 1939</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00370-5\">Neural network based asynchronous synchronization for fuzzy hidden Markov jump complex dynamical networks</a></div><div><b>Author(s):&nbsp;</b>Chao Ma, Liziyi Hao, Hang Fu</div><div><b>Pages:&nbsp;</b>1941 - 1948</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00338-5\">A novel sEMG-based force estimation method using deep-learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Shaoyang Hua, Congqing Wang, Xuewei Wu</div><div><b>Pages:&nbsp;</b>1949 - 1961</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00364-3\">Sliding mode-based online fault compensation control for modular reconfigurable robots through adaptive dynamic programming</a></div><div><b>Author(s):&nbsp;</b>Hongbing Xia, Ping Guo</div><div><b>Pages:&nbsp;</b>1963 - 1973</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00382-1\">Dueling deep Q-networks for social awareness-aided spectrum sharing</a></div><div><b>Author(s):&nbsp;</b>Yonghua Wang, Xueyang Li...Xia Deng</div><div><b>Pages:&nbsp;</b>1975 - 1986</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00389-8\">A neuro-swarming intelligent heuristic for second-order nonlinear Lane\u2013Emden multi-pantograph delay differential system</a></div><div><b>Author(s):&nbsp;</b>Zulqurnain Sabir, Muhammad Asif Zahoor Raja...Ayman A. Aly</div><div><b>Pages:&nbsp;</b>1987 - 2000</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00444-4\">Reinforcement learning for the traveling salesman problem with refueling</a></div><div><b>Author(s):&nbsp;</b>Andr\u00e9 L. C. Ottoni, Erivelton G. Nepomuceno...Daniela C. R. de Oliveira</div><div><b>Pages:&nbsp;</b>2001 - 2015</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00502-x\">An integrated fuzzy model for evaluation and selection of mobile banking (m-banking) applications using new fuzzy-BWM and fuzzy-TOPSIS</a></div><div><b>Author(s):&nbsp;</b>Pranith Kumar Roy, Krishnendu Shaw</div><div><b>Pages:&nbsp;</b>2017 - 2038</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00516-5\">DensePILAE: a feature reuse pseudoinverse learning algorithm for deep stacked autoencoder</a></div><div><b>Author(s):&nbsp;</b>Jue Wang, Ping Guo, Yanjun Li</div><div><b>Pages:&nbsp;</b>2039 - 2049</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00734-5\">Self-adaptive opposition-based differential evolution with subpopulation strategy for numerical and engineering optimization problems</a></div><div><b>Author(s):&nbsp;</b>Jiahang Li, Yuelin Gao...Qinwen Yang</div><div><b>Pages:&nbsp;</b>2051 - 2089</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00632-2\">Motion intensity modeling and trajectory control of upper limb rehabilitation exoskeleton robot based on multi-modal information</a></div><div><b>Author(s):&nbsp;</b>WenDong Wang, JunBo Zhang...Peng Zhang</div><div><b>Pages:&nbsp;</b>2091 - 2103</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00636-y\">Multi-label feature selection based on fuzzy neighborhood rough sets</a></div><div><b>Author(s):&nbsp;</b>Jiucheng Xu, Kaili Shen, Lin Sun</div><div><b>Pages:&nbsp;</b>2105 - 2129</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00626-0\">Single-valued neutrosophic Einstein interactive aggregation operators with applications for material selection in engineering design: case study of cryogenic storage tank</a></div><div><b>Author(s):&nbsp;</b>Hafiz Muhammad Athar Farid, Muhammad Riaz</div><div><b>Pages:&nbsp;</b>2131 - 2149</div><div><br /></div><div><b>24) </b><a href=\"https://link.springer.com/article/10.1007/s40747-021-00623-3\">A decomposition structure learning algorithm in Bayesian network based on a two-stage combination method</a></div><div><b>Author(s):&nbsp;</b>Huiping Guo, Hongru Li</div><div><b>Pages:&nbsp;</b>2151 - 2165</div><div><br /></div><div><b>25) </b><a href=\"https://link.springer.com/article/10.1007/s40747-021-00639-9\">A state of health estimation method for electric vehicle Li-ion batteries using GA-PSO-SVR</a></div><div><b>Author(s):&nbsp;</b>Yue Zhi, Heqi Wang, Liang Wang</div><div><b>Pages:&nbsp;</b>2167 - 2182</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00647-3\">Modeling students\u2019 performance using graph convolutional networks</a></div><div><b>Author(s):&nbsp;</b>Ahmed A. Mubarak, Han Cao...Fei Hao</div><div><b>Pages:&nbsp;</b>2183 - 2201</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00585-6\">Group decision making method with hesitant fuzzy preference relations based on additive consistency and consensus</a></div><div><b>Author(s):&nbsp;</b>Jian Li, Li-li Niu...Wenjing Li</div><div><b>Pages:&nbsp;</b>2203 - 2225</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00628-y\">Path planning of a manipulator based on an improved P_RRT* algorithm</a></div><div><b>Author(s):&nbsp;</b>Junhui Yi, Qingni Yuan...Huan Bai</div><div><b>Pages:&nbsp;</b>2227 - 2245</div><div><br /></div><div><b>29) </b><a href=\"https://link.springer.com/article/10.1007/s40747-021-00638-w\">ASN-SMOTE: a synthetic minority oversampling method with adaptive qualified synthesizer selection</a></div><div><b>Author(s):&nbsp;</b>Xinkai Yi, Yingying Xu...Zhenzhou Tang</div><div><b>Pages:&nbsp;</b>2247 - 2272</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00648-2\">Safe-Nav: learning to prevent PointGoal navigation failure in unknown environments</a></div><div><b>Author(s):&nbsp;</b>Sheng Jin, Qinghao Meng...Huirang Hou</div><div><b>Pages:&nbsp;</b>2273 - 2290</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00644-6\">Content-adaptive image compression and encryption via optimized compressive sensing with double random phase encoding driven by chaos</a></div><div><b>Author(s):&nbsp;</b>Zhihua Gan, Xiuli Chai...Xiuhui Chen</div><div><b>Pages:&nbsp;</b>2291 - 2309</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00645-5\">Enhanced graph recommendation with heterogeneous auxiliary information</a></div><div><b>Author(s):&nbsp;</b>Fulian Yin, Meiqi Ji...Sitong Li</div><div><b>Pages:&nbsp;</b>2311 - 2324</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00646-4\">Decision-making methods based on fuzzy soft competition hypergraphs</a></div><div><b>Author(s):&nbsp;</b>Muhammad Akram, Sundas Shahzadi...Musavarah Sarwar</div><div><b>Pages:&nbsp;</b>2325 - 2348</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00622-4\">Cq-ROFRS: covering q-rung orthopair fuzzy rough sets and its application to multi-attribute decision-making process</a></div><div><b>Author(s):&nbsp;</b>Harish Garg, Mohammed Atef</div><div><b>Pages:&nbsp;</b>2349 - 2370</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00633-1\">Hybrid attention network with appraiser-guided loss for counterfeit luxury handbag detection</a></div><div><b>Author(s):&nbsp;</b>Jianbiao Peng, Beiji Zou...Chengzhang Zhu</div><div><b>Pages:&nbsp;</b>2371 - 2381</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00655-3\">Convergence and gradient algorithm of a class of neural networks based on the polygonal fuzzy numbers representation</a></div><div><b>Author(s):&nbsp;</b>Gang Sun, Mingxin Wang, Xiaoping Li</div><div><b>Pages:&nbsp;</b>2383 - 2404</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00627-z\">Two-layer LSTM network-based prediction of epileptic seizures using EEG spectral features</a></div><div><b>Author(s):&nbsp;</b>Kuldeep Singh, Jyoteesh Malhotra</div><div><b>Pages:&nbsp;</b>2405 - 2418</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00653-5\">Lifetime prolongation of a wireless charging sensor network using a mobile robot via linear Diophantine fuzzy graph environment</a></div><div><b>Author(s):&nbsp;</b>Karthikeyan Prakash, Mani Parimala...Muhammad Riaz</div><div><b>Pages:&nbsp;</b>2419 - 2434</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00656-2\">Decision-making based on probabilistic linguistic term sets without loss of information</a></div><div><b>Author(s):&nbsp;</b>Zhihong Yi</div><div><b>Pages:&nbsp;</b>2435 - 2449</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00657-1\">A hybrid model integrating FMEA and HFACS to assess the risk of inter-city bus accidents</a></div><div><b>Author(s):&nbsp;</b>James J. H. Liou, Perry C. Y. Liu...Yu-Zeng Wu</div><div><b>Pages:&nbsp;</b>2451 - 2470</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00658-0\">A deep learning method DCWR with HANet for stock market prediction using news articles</a></div><div><b>Author(s):&nbsp;</b>Saleh Albahli, Awais Awan...Waleed Albattah</div><div><b>Pages:&nbsp;</b>2471 - 2487</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00660-6\">TAUNet: a triple-attention-based multi-modality MRI fusion U-Net for cardiac pathology segmentation</a></div><div><b>Author(s):&nbsp;</b>Dapeng Li, Yanjun Peng...Jindong Sun</div><div><b>Pages:&nbsp;</b>2489 - 2505</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00661-5\">Memory-based variable neighborhood search for green vehicle routing problem with passing-by drivers: a comprehensive perspective</a></div><div><b>Author(s):&nbsp;</b>Lei Cao, Chun-ming Ye...Zhen-kun Wang</div><div><b>Pages:&nbsp;</b>2507 - 2525</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00643-7\">Neuroadaptive control of information-poor servomechanisms with smooth and nonsmooth uncertainties</a></div><div><b>Author(s):&nbsp;</b>Guichao Yang, Hua Wang</div><div><b>Pages:&nbsp;</b>2527 - 2539</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00681-1\">An integrated quality-function-deployment and stochastic-dominance-based decision-making approach for prioritizing product concept alternatives</a></div><div><b>Author(s):&nbsp;</b>Zeng-Qiang Wang, Zhen-Song Chen...Kwai-Sang Chin</div><div><b>Pages:&nbsp;</b>2541 - 2556</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00642-8\">Optimization on dual-channel supply chain model with pricing decision and trapezoidal fuzzy demand under a controllable lead time</a></div><div><b>Author(s):&nbsp;</b>B. Karthick, R. Uthayakumar</div><div><b>Pages:&nbsp;</b>2557 - 2591</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00629-x\">Data collection protocols for VANETs: a survey</a></div><div><b>Author(s):&nbsp;</b>Maryam Gillani, Hafiz Adnan Niaz...Ata Ullah</div><div><b>Pages:&nbsp;</b>2593 - 2622</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00665-1\">Computational intelligence in processing of speech acoustics: a survey</a></div><div><b>Author(s):&nbsp;</b>Amitoj Singh, Navkiran Kaur...Munish Kumar</div><div><b>Pages:&nbsp;</b>2623 - 2661</div><div><br /></div><div><b>49) </b><a href=\"https://link.springer.com/article/10.1007/s40747-021-00637-x\">Feature dimensionality reduction: a review</a></div><div><b>Author(s):&nbsp;</b>Weikuan Jia, Meili Sun...Sujuan Hou</div><div><b>Pages:&nbsp;</b>2663 - 2693</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00654-4\">Correction to: Efficient structural pseudoinverse learning-based hierarchical representation learning for skin lesion classification</a></div><div><b>Author(s):&nbsp;</b>Xiaodan Deng, Qian Yin, Ping Guo</div><div><b>Pages:&nbsp;</b>2695 - 2695</div><div><br /></div>",
            "pubdate": "2022-06-08T12:00:00.167+12:00",
            "pubdate_parsed": [
                2022,
                6,
                8
            ],
            "email_sent": true
        },
        "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 6, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/ieee-transactions-on-neural-networks.html",
            "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9786561/\">Editorial Deep Learning for Anomaly Detection</a></div><div><b>Author(s): </b>Guansong Pang, Charu Aggarwal, Chunhua Shen, Nicu Sebe</div><div><b>Pages: </b>2282 - 2286</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9565147/\">SmithNet: Strictness on Motion-Texture Coherence for Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Trong-Nguyen Nguyen, S\u00e9bastien Roy, Jean Meunier</div><div><b>Pages:&nbsp;</b>2287 - 2300</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9446996/\">Robust Unsupervised Video Anomaly Detection by Multipath Frame Prediction</a></div><div><b>Author(s):&nbsp;</b>Xuanzhao Wang, Zhengping Che, Bo Jiang, Ning Xiao, Ke Yang, Jian Tang, Jieping Ye, Jingyu Wang, Qi Qi</div><div><b>Pages:&nbsp;</b>2301 - 2312</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9640579/\">MOCCA: Multilayer One-Class Classification for Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Fabio Valerio Massoli, Fabrizio Falchi, Alperen Kantarci, \u015eeymanur Akti, Hazim Kemal Ekenel, Giuseppe Amato</div><div><b>Pages:&nbsp;</b>2313 - 2323</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9664442/\">Memory-Augmented Generative Adversarial Networks for Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Ziyi Yang, Teng Zhang, Iman Soltani Bozchalooi, Eric Darve</div><div><b>Pages:&nbsp;</b>2324 - 2334</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9513473/\">Memorizing Structure-Texture Correspondence for Image Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Kang Zhou, Jing Li, Yuting Xiao, Jianlong Yang, Jun Cheng, Wen Liu, Weixin Luo, Jiang Liu, Shenghua Gao</div><div><b>Pages:&nbsp;</b>2335 - 2349</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9556483/\">Entropic Out-of-Distribution Detection: Seamless Detection of Unknown Examples</a></div><div><b>Author(s):&nbsp;</b>David Mac\u00eado, Tsang Ing Ren, Cleber Zanchettin, Adriano L. I. Oliveira, Teresa Ludermir</div><div><b>Pages:&nbsp;</b>2350 - 2364</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9526875/\">Automated Anomaly Detection via Curiosity-Guided Search and Self-Imitation Learning</a></div><div><b>Author(s):&nbsp;</b>Yuening Li, Zhengzhang Chen, Daochen Zha, Kaixiong Zhou, Haifeng Jin, Haifeng Chen, Xia Hu</div><div><b>Pages:&nbsp;</b>2365 - 2377</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9395172/\">Anomaly Detection on Attributed Networks via Contrastive Self-Supervised Learning</a></div><div><b>Author(s):&nbsp;</b>Yixin Liu, Zhao Li, Shirui Pan, Chen Gong, Chuan Zhou, George Karypis</div><div><b>Pages:&nbsp;</b>2378 - 2392</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9525041/\">A Synergistic Approach for Graph Anomaly Detection With Pattern Mining and Feature Learning</a></div><div><b>Author(s):&nbsp;</b>Tong Zhao, Tianwen Jiang, Neil Shah, Meng Jiang</div><div><b>Pages:&nbsp;</b>2393 - 2405</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9556511/\">Cross-Domain Graph Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Kaize Ding, Kai Shu, Xuan Shan, Jundong Li, Huan Liu</div><div><b>Pages:&nbsp;</b>2406 - 2415</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9669110/\">Graph Convolutional Adversarial Networks for Spatiotemporal Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Leyan Deng, Defu Lian, Zhenya Huang, Enhong Chen</div><div><b>Pages:&nbsp;</b>2416 - 2428</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9533187/\">Learning to Classify With Incremental New Class</a></div><div><b>Author(s):&nbsp;</b>Da-Wei Zhou, Yang Yang, De-Chuan Zhan</div><div><b>Pages:&nbsp;</b>2429 - 2443</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9492295/\">Semisupervised Training of Deep Generative Models for High-Dimensional Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Qin Xie, Peng Zhang, Boseon Yu, Jaesik Choi</div><div><b>Pages:&nbsp;</b>2444 - 2453</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9465358/\">Feature Encoding With Autoencoders for Weakly Supervised Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Yingjie Zhou, Xucheng Song, Yanru Zhang, Fanxing Liu, Ce Zhu, Lingqiao Liu</div><div><b>Pages:&nbsp;</b>2454 - 2465</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9524840/\">Attract\u2013Repel Encoder: Learning Anomaly Representation Away From Landmarks</a></div><div><b>Author(s):&nbsp;</b>Jiachen Zhao, Fang Deng, Yongling Li, Jie Chen</div><div><b>Pages:&nbsp;</b>2466 - 2479</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9608947/\">Center-Aware Adversarial Autoencoder for Anomaly Detection</a></div><div><b>Author(s):&nbsp;</b>Daoming Li, Qinghua Tao, Jiahao Liu, Huangang Wang</div><div><b>Pages:&nbsp;</b>2480 - 2493</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9569766/\">Comparison of Anomaly Detectors: Context Matters</a></div><div><b>Author(s):&nbsp;</b>V\u00edt \u0160kv\u00e1ra, Jan Franc\u00e5, Mat\u011bj Zorek, Tom\u00e1\u0161 Pevn\u00fd, V\u00e1clav \u0160m\u00eddl</div><div><b>Pages:&nbsp;</b>2494 - 2507</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9525836/\">An Evaluation of Anomaly Detection and Diagnosis in Multivariate Time Series</a></div><div><b>Author(s):&nbsp;</b>Astha Garg, Wenyu Zhang, Jules Samaran, Ramasamy Savitha, Chuan-Sheng Foo</div><div><b>Pages:&nbsp;</b>2508 - 2517</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9596571/\">Learning Fast and Slow: Propedeutica for Real-Time Malware Detection</a></div><div><b>Author(s):&nbsp;</b>Ruimin Sun, Xiaoyong Yuan, Pan He, Qile Zhu, Aokun Chen, Andr\u00e9 Gr\u00e9gio, Daniela Oliveira, Xiaolin Li</div><div><b>Pages:&nbsp;</b>2518 - 2529</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9594513/\">Joint Stance and Rumor Detection in Hierarchical Heterogeneous Graph</a></div><div><b>Author(s):&nbsp;</b>Chen Li, Hao Peng, Jianxin Li, Lichao Sun, Lingjuan Lyu, Lihong Wang, Philip S. Yu, Lifang He</div><div><b>Pages:&nbsp;</b>2530 - 2542</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9709524/\">Deep Graph Learning for Anomalous Citation Detection</a></div><div><b>Author(s):&nbsp;</b>Jiaying Liu, Feng Xia, Xu Feng, Jing Ren, Huan Liu</div><div><b>Pages:&nbsp;</b>2543 - 2557</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9512275/\">A Novel Deep Class-Imbalanced Semisupervised Model for Wind Turbine Blade Icing Detection</a></div><div><b>Author(s):&nbsp;</b>Xu Cheng, Fan Shi, Xiufeng Liu, Meng Zhao, Shengyong Chen</div><div><b>Pages:&nbsp;</b>2558 - 2570</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9786562/\">Guest Editorial Special Issue on New Frontiers in Extremely Efficient Reservoir Computing</a></div><div><b>Author(s):&nbsp;</b>Gouhei Tanaka, Claudio Gallicchio, Alessio Micheli, Juan-Pablo Ortega, Akira Hirose</div><div><b>Pages:&nbsp;</b>2571 - 2574</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9482563/\">Reservoir Memory Machines as Neural Computers</a></div><div><b>Author(s):&nbsp;</b>Benjamin Paa\u00dfen, Alexander Schulz, Terrence C. Stewart, Barbara Hammer</div><div><b>Pages:&nbsp;</b>2575 - 2585</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9585304/\">Consistency Hierarchy of Reservoir Computers</a></div><div><b>Author(s):&nbsp;</b>Thomas J\u00fcngling, Thomas Lymburn, Michael Small</div><div><b>Pages:&nbsp;</b>2586 - 2595</div><div><br /></div><div><b>27) </b><a href=\"https://ieeexplore.ieee.org/document/9502408/\">An Echo State Network Imparts a Curve Fitting</a></div><div><b>Author(s):&nbsp;</b>G. Manjunath</div><div><b>Pages:&nbsp;</b>2596 - 2604</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9531523/\">Adaptive Practical Nonlinear Model Predictive Control for Echo State Network Models</a></div><div><b>Author(s):&nbsp;</b>Bernardo Barancelli Schwedersky, Rodolfo C\u00e9sar Costa Flesch, Samuel Bahu Rovea</div><div><b>Pages:&nbsp;</b>2605 - 2614</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9664461/\">Echo State Networks for Practical Nonlinear Model Predictive Control of Unknown Dynamic Systems</a></div><div><b>Author(s):&nbsp;</b>Jean Panaioti Jordanou, Eric Aislan Antonelo, Eduardo Camponogara</div><div><b>Pages:&nbsp;</b>2615 - 2629</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9452793/\">Real-Time and Adaptive Reservoir Computing With Application to Profile Prediction in Fusion Plasma</a></div><div><b>Author(s):&nbsp;</b>Azarakhsh Jalalvand, Joseph Abbate, Rory Conlin, Geert Verdoolaege, Egemen Kolemen</div><div><b>Pages:&nbsp;</b>2630 - 2641</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9476188/\">Multiresolution Reservoir Graph Neural Network</a></div><div><b>Author(s):&nbsp;</b>Luca Pasa, Nicol\u00f2 Navarin, Alessandro Sperduti</div><div><b>Pages:&nbsp;</b>2642 - 2653</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9548713/\">Hierarchical-Task Reservoir for Online Semantic Analysis From Continuous Speech</a></div><div><b>Author(s):&nbsp;</b>Luca Pedrelli, Xavier Hinaut</div><div><b>Pages:&nbsp;</b>2654 - 2663</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9525045/\">High-Performance Reservoir Computing With Fluctuations in Linear Networks</a></div><div><b>Author(s):&nbsp;</b>Johannes Nokkala, Rodrigo Mart\u00ednez-Pe\u00f1a, Roberta Zambrini, Miguel C. Soriano</div><div><b>Pages:&nbsp;</b>2664 - 2675</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9453819/\">Neuromorphic Time-Multiplexed Reservoir Computing With On-the-Fly Weight Generation for Edge Devices</a></div><div><b>Author(s):&nbsp;</b>Sarthak Gupta, Satrajit Chakraborty, Chetan Singh Thakur</div><div><b>Pages:&nbsp;</b>2676 - 2685</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9600461/\">Neural Schr\u00f6dinger Equation: Physical Law as Deep Neural Network</a></div><div><b>Author(s):&nbsp;</b>Mitsumasa Nakajima, Kenji Tanaka, Toshikazu Hashimoto</div><div><b>Pages:&nbsp;</b>2686 - 2700</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9586079/\">Cellular Automata Can Reduce Memory Requirements of Collective-State Computing</a></div><div><b>Author(s):&nbsp;</b>Denis Kleyko, Edward Paxon Frady, Friedrich T. Sommer</div><div><b>Pages:&nbsp;</b>2701 - 2713</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9578941/\">Information Processing Capacity of a Single-Node Reservoir Computer: An Experimental Evaluation</a></div><div><b>Author(s):&nbsp;</b>Benedikt Vettelschoss, Andr\u00e9 R\u00f6hm, Miguel C. Soriano</div><div><b>Pages:&nbsp;</b>2714 - 2725</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9319556/\">Vertebrae Labeling via End-to-End Integral Regression Localization and Multi-Label Classification Network</a></div><div><b>Author(s):&nbsp;</b>Chunli Qin, Ji Zhou, Demin Yao, Han Zhuang, Hui Wang, Shiyao Chen, Yonghong Shi, Zhijian Song</div><div><b>Pages:&nbsp;</b>2726 - 2736</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9316887/\">Reachable Set Estimation of Delayed Markovian Jump Neural Networks Based on an Improved Reciprocally Convex Inequality</a></div><div><b>Author(s):&nbsp;</b>Guoqiang Tan, Zhanshan Wang</div><div><b>Pages:&nbsp;</b>2737 - 2742</div><div><br /></div><div><br /></div>",
            "pubdate": "2022-06-17T09:08:00.000+12:00",
            "pubdate_parsed": [
                2022,
                6,
                16
            ],
            "email_sent": true
        },
        "IEEE Transactions on Cognitive and Developmental Systems, Volume 14, Issue 2, June 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/ieee-transactions-on-cognitive-and.html",
            "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9793369/\">Special Issue on Emerging Topics on Development and Learning</a></div><div><b>Author(s): </b>Mar\u00eda-Jos\u00e9 Escobar, Nicol\u00e1s Navarro-Guerrero, Javier Ruiz-Del-Solar, Giulio Sandini</div><div><b>Pages: </b>255 - 257</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9570769/\">A Biologically Inspired Computational Model of Time Perception</a></div><div><b>Author(s):&nbsp;</b>In\u00eas Louren\u00e7o, Robert Mattila, Rodrigo Ventura, Bo Wahlberg</div><div><b>Pages:&nbsp;</b>258 - 268</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9446597/\">A Sensorimotor Perspective on Contrastive Multiview Visual Representation Learning</a></div><div><b>Author(s):&nbsp;</b>Alban Laflaqui\u00e8re</div><div><b>Pages:&nbsp;</b>269 - 278</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9762837/\">In Search of a Neural Model for Serial Order: A Brain Theory for Memory Development and Higher Level Cognition</a></div><div><b>Author(s):&nbsp;</b>Alexandre Pitti, Mathias Quoy, Catherine Lavandier, Sofiane Boucenna, Wassim Swaileh, Claudio Weidmann</div><div><b>Pages:&nbsp;</b>279 - 291</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9495946/\">Philosophical Specification of Empathetic Ethical Artificial Intelligence</a></div><div><b>Author(s):&nbsp;</b>Michael Timothy Bennett, Yoshihiro Maruyama</div><div><b>Pages:&nbsp;</b>292 - 300</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9353685/\">Time Perception: A Review on Psychological, Computational, and Robotic Models</a></div><div><b>Author(s):&nbsp;</b>Hamit Basgol, Inci Ayhan, Emre Ugur</div><div><b>Pages:&nbsp;</b>301 - 315</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9380459/\">Vision-Based Gaze Estimation: A Review</a></div><div><b>Author(s):&nbsp;</b>Xinming Wang, Jianhua Zhang, Hanlin Zhang, Shuwen Zhao, Honghai Liu</div><div><b>Pages:&nbsp;</b>316 - 332</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9390376/\">The Why, What, and How of Artificial General Intelligence Chip Development</a></div><div><b>Author(s):&nbsp;</b>Alex P. James</div><div><b>Pages:&nbsp;</b>333 - 347</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9430619/\">Deep Learning in EEG: Advance of the Last Ten-Year Critical Period</a></div><div><b>Author(s):&nbsp;</b>Shu Gong, Kaibo Xing, Andrzej Cichocki, Junhua Li</div><div><b>Pages:&nbsp;</b>348 - 365</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9246953/\">To Move or Not to Move: Development of Fine-Tuning of Object Motion in Haptic Exploration</a></div><div><b>Author(s):&nbsp;</b>Alessandra Sciutti, Giulio Sandini</div><div><b>Pages:&nbsp;</b>366 - 374</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9270601/\">A Matrix Determinant Feature Extraction Approach for Decoding Motor and Mental Imagery EEG in Subject-Specific Tasks</a></div><div><b>Author(s):&nbsp;</b>Muhammad Tariq Sadiq, Xiaojun Yu, Zhaohui Yuan, Muhammad Zulkifal Aziz, Siuly Siuly, Weiping Ding</div><div><b>Pages:&nbsp;</b>375 - 387</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9273020/\">A Compressed Sensing Network for Acquiring Human Pressure Information</a></div><div><b>Author(s):&nbsp;</b>Tao Han, Kuangrong Hao, Xue-Song Tang, Xin Cai, Tong Wang, Xiaoyan Liu</div><div><b>Pages:&nbsp;</b>388 - 402</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9288837/\">Imitation Learning-Based Algorithm for Drone Cinematography System</a></div><div><b>Author(s):&nbsp;</b>Yuanjie Dang, Chong Huang, Peng Chen, Ronghua Liang, Xin Yang, Kwang-Ting Cheng</div><div><b>Pages:&nbsp;</b>403 - 413</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9292658/\">Learning Multipart Attention Neural Network for Zero-Shot Classification</a></div><div><b>Author(s):&nbsp;</b>Min Meng, Jie Wei, Jigang Wu</div><div><b>Pages:&nbsp;</b>414 - 423</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9300220/\">Motor-Cortex-Like Recurrent Neural Network and Multitask Learning for the Control of Musculoskeletal Systems</a></div><div><b>Author(s):&nbsp;</b>Jiahao Chen, Hong Qiao</div><div><b>Pages:&nbsp;</b>424 - 436</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9314882/\">Holistically Associated Transductive Zero-Shot Learning</a></div><div><b>Author(s):&nbsp;</b>Yangyang Xu, Xuemiao Xu, Guoqiang Han, Shengfeng He</div><div><b>Pages:&nbsp;</b>437 - 447</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9314893/\">In Situ Learning in Hardware Compatible Multilayer Memristive Spiking Neural Network</a></div><div><b>Author(s):&nbsp;</b>Jiwei Li, Hui Xu, Sheng-Yang Sun, Nan Li, Qingjiang Li, Zhiwei Li, Haijun Liu</div><div><b>Pages:&nbsp;</b>448 - 461</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9316712/\">An Empirical Study of Active Inference on a Humanoid Robot</a></div><div><b>Author(s):&nbsp;</b>Guillermo Oliver, Pablo Lanillos, Gordon Cheng</div><div><b>Pages:&nbsp;</b>462 - 471</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9319691/\">Spontaneous Temporal Grouping Neural Network for Long-Term Memory Modeling</a></div><div><b>Author(s):&nbsp;</b>Dongjing Shan, Xiongwei Zhang, Chao Zhang</div><div><b>Pages:&nbsp;</b>472 - 484</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9319729/\">Augmented Memory Replay in Reinforcement Learning With Continuous Control</a></div><div><b>Author(s):&nbsp;</b>Mirza Ramicic, Andrea Bonarini</div><div><b>Pages:&nbsp;</b>485 - 496</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9321385/\">Cogno-Vest: A Torso-Worn, Force Display to Experimentally Induce Specific Hallucinations and Related Bodily Sensations</a></div><div><b>Author(s):&nbsp;</b>Atena Fadaei Jouybari, Kenny Jeanmonod, Olivier A. Kannape, Jevita Potheegadoo, Hannes Bleuler, Masayuki Hara, Olaf Blanke</div><div><b>Pages:&nbsp;</b>497 - 506</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9328469/\">Multiscale Brain-Like Neural Network for Saliency Prediction on Omnidirectional Images</a></div><div><b>Author(s):&nbsp;</b>Dandan Zhu, Yongqing Chen, Defang Zhao, Yucheng Zhu, Qiangqiang Zhou, Guangtao Zhai, Xiaokang Yang</div><div><b>Pages:&nbsp;</b>507 - 518</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9328521/\">A Dissemination Model Based on Psychological Theories in Complex Social Networks</a></div><div><b>Author(s):&nbsp;</b>Tianyi Luo, Zhidong Cao, Daniel Zeng, Qingpeng Zhang</div><div><b>Pages:&nbsp;</b>519 - 531</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9328807/\">Neural Correlates of Single-Task Versus Cognitive-Motor Dual-Task Training</a></div><div><b>Author(s):&nbsp;</b>Jiaxing Wang, Weiqun Wang, Shixin Ren, Weiguo Shi, Zeng-Guang Hou</div><div><b>Pages:&nbsp;</b>532 - 540</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9330624/\">RCIT: An RSVP-Based Concealed Information Test Framework Using EEG Signals</a></div><div><b>Author(s):&nbsp;</b>Hanwen Wang, Yu Qi, Hang Yu, Yueming Wang, Cong Liu, Guoping Hu, Gang Pan</div><div><b>Pages:&nbsp;</b>541 - 551</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9335985/\">Resting-State Brain Connectivity via Multivariate EMD in Mild Cognitive Impairment</a></div><div><b>Author(s):&nbsp;</b>Haifeng Wu, Lingxu Kong, Yu Zeng, Han Bao</div><div><b>Pages:&nbsp;</b>552 - 564</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9336705/\">Toward Emerging Cubic-Spline Patterns With a Mobile Robotics Swarm System</a></div><div><b>Author(s):&nbsp;</b>Belkacem Khaldi, Fouzi Harrou, Foudil Cherif, Ying Sun</div><div><b>Pages:&nbsp;</b>565 - 577</div><div><br /></div><div><b>28) </b><a href=\"https://ieeexplore.ieee.org/document/9337927/\">Bicriteria Velocity Minimization Approach of Self-Motion for Redundant Robot Manipulators With Varying-Gain Recurrent Neural Network</a></div><div><b>Author(s):&nbsp;</b>Xiaohui Ren, Pengchao Zhang, Zhijun Zhang</div><div><b>Pages:&nbsp;</b>578 - 587</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9340391/\">Cross-Corpus Speech Emotion Recognition Based on Joint Transfer Subspace Learning and Regression</a></div><div><b>Author(s):&nbsp;</b>Weijian Zhang, Peng Song, Dongliang Chen, Chao Sheng, Wenjing Zhang</div><div><b>Pages:&nbsp;</b>588 - 598</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9340402/\">A Portable Device for Hand Rehabilitation With Force Cognition: Design, Interaction, and Experiment</a></div><div><b>Author(s):&nbsp;</b>Lei Yang, Fuhai Zhang, Jingbin Zhu, Yili Fu</div><div><b>Pages:&nbsp;</b>599 - 607</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9360879/\">Evaluation of Mental Workload Associated With Time Pressure in Rapid Serial Visual Presentation Tasks</a></div><div><b>Author(s):&nbsp;</b>Weibo Yi, Shuang Qiu, Xinan Fan, Lijian Zhang, Dong Ming</div><div><b>Pages:&nbsp;</b>608 - 616</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9361701/\">A Brain-Inspired Self-Organizing Episodic Memory Model for a Memory Assistance Robot</a></div><div><b>Author(s):&nbsp;</b>Chiao-Yu Yang, Edwinn Gamborino, Li-Chen Fu, Yu-Ling Chang</div><div><b>Pages:&nbsp;</b>617 - 628</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9363315/\">Feature-Specific Denoising of Neural Activity for Natural Image Identification</a></div><div><b>Author(s):&nbsp;</b>Hao Wu, Nanning Zheng, Badong Chen</div><div><b>Pages:&nbsp;</b>629 - 638</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9364289/\">Robust Heart Rate Estimation With Spatial\u2013Temporal Attention Network From Facial Videos</a></div><div><b>Author(s):&nbsp;</b>Min Hu, Fei Qian, Xiaohua Wang, Lei He, Dong Guo, Fuji Ren</div><div><b>Pages:&nbsp;</b>639 - 647</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9365692/\">MFFFLD: A Multimodal-Feature-Fusion-Based Fingerprint Liveness Detection</a></div><div><b>Author(s):&nbsp;</b>Chengsheng Yuan, Shengming Jiao, Xingming Sun, Q. M. Jonathan Wu</div><div><b>Pages:&nbsp;</b>648 - 661</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9366777/\">Conditional Generative Adversarial Networks for Optimal Path Planning</a></div><div><b>Author(s):&nbsp;</b>Nachuan Ma, Jiankun Wang, Jianbang Liu, Max Q.-H. Meng</div><div><b>Pages:&nbsp;</b>662 - 671</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9372969/\">Data-Fusion-Based Two-Stage Cascade Framework for Multimodality Face Anti-Spoofing</a></div><div><b>Author(s):&nbsp;</b>Weihua Liu, Xiaokang Wei, Tao Lei, Xingwu Wang, Hongying Meng, Asoke K. Nandi</div><div><b>Pages:&nbsp;</b>672 - 683</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9372334/\">Epileptic Classification With Deep-Transfer-Learning-Based Feature Fusion Algorithm</a></div><div><b>Author(s):&nbsp;</b>Jiuwen Cao, Dinghan Hu, Yaomin Wang, Jianzhong Wang, Baiying Lei</div><div><b>Pages:&nbsp;</b>684 - 695</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9372336/\">Attention-Mechanism-Based Real-Time Gaze Tracking in Natural Scenes With Residual Blocks</a></div><div><b>Author(s):&nbsp;</b>Lihong Dai, Jinguo Liu, Zhaojie Ju, Yang Gao</div><div><b>Pages:&nbsp;</b>696 - 707</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9380656/\">Effect of Physical and Virtual Feedback on Reach-to-Grasp Movements in Virtual Environments</a></div><div><b>Author(s):&nbsp;</b>Qiuwen Cai, Junhua Li, Jinyi Long</div><div><b>Pages:&nbsp;</b>708 - 714</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9395500/\">Comparing Recognition Performance and Robustness of Multimodal Deep Learning Models for Multimodal Emotion Recognition</a></div><div><b>Author(s):&nbsp;</b>Wei Liu, Jie-Lin Qiu, Wei-Long Zheng, Bao-Liang Lu</div><div><b>Pages:&nbsp;</b>715 - 729</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9405306/\">Uncertainty Modeling for Multicenter Autism Spectrum Disorder Classification Using Takagi\u2013Sugeno\u2013Kang Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Zhongyi Hu, Jun Wang, Chunxiang Zhang, Zhenzhen Luo, Xiaoqing Luo, Lei Xiao, Jun Shi</div><div><b>Pages:&nbsp;</b>730 - 739</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9406414/\">Time-Spatial Multiscale Net for Vehicle Counting and Traffic Volume Estimation</a></div><div><b>Author(s):&nbsp;</b>Shuang Li, Chunsheng Liu, Faliang Chang</div><div><b>Pages:&nbsp;</b>740 - 751</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9427962/\">Multiscale Conditional Relationship Graph Network for Referring Relationships in Images</a></div><div><b>Author(s):&nbsp;</b>Jian Zhu, Hanli Wang</div><div><b>Pages:&nbsp;</b>752 - 760</div><div><br /></div><div><b>45) </b><a href=\"https://ieeexplore.ieee.org/document/9502838/\">Investigating Neural Substrates of Individual Independence and Interdependence Orientations via Efficiency-Based Dynamic Functional Connectivity: A Machine Learning Approach</a></div><div><b>Author(s):&nbsp;</b>Yifan Zhu, Xuesong Li, Yang Sun, Haixu Wang, Hua Guo, Jie Sui</div><div><b>Pages:&nbsp;</b>761 - 771</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9576513/\">EMRES: A New EMotional RESpondent Robot</a></div><div><b>Author(s):&nbsp;</b>Elena Battini S\u00f6nmez, Hasan Han, O\u01e7uzcan Karadeniz, Tu\u01e7ba Dalyan, Baykal Sar\u0131o\u01e7lu</div><div><b>Pages:&nbsp;</b>772 - 780</div><div><br /></div><div style=\"text-align: left;\">&nbsp;</div>",
            "pubdate": "2022-06-18T12:00:00.161+12:00",
            "pubdate_parsed": [
                2022,
                6,
                18
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 13, July 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/soft-computing-volume-26-issue-13-july.html",
            "description": "<div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07052-5\">Implication in finite posets with pseudocomplemented sections</a></div><div><b>Author(s): </b>Ivan Chajda, Helmut L\u00e4nger</div><div><b>Pages: </b>5945 - 5953</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07059-y\">Chain complex and quotient structure of fuzzy hypergroups</a></div><div><b>Author(s):&nbsp;</b>F. Barkhori Mehni, S. Ostadhadi-Dehkordi</div><div><b>Pages:&nbsp;</b>5955 - 5963</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07063-2\">Decompositions of average probability uninitialized sequential quantum machines</a></div><div><b>Author(s):&nbsp;</b>Feidan Huang</div><div><b>Pages:&nbsp;</b>5965 - 5974</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07078-9\">Pythagorean fuzzy inequality derived by operation, equality and aggregation operator</a></div><div><b>Author(s):&nbsp;</b>Xindong Peng, Zhigang Luo</div><div><b>Pages:&nbsp;</b>5975 - 6018</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07113-9\">Review: a generalized belief interval-valued soft set with applications in decision making</a></div><div><b>Author(s):&nbsp;</b>G\u00f6zde Yaylal\u0131, Nazan \u00c7akmak Polat, Bekir Tanay</div><div><b>Pages:&nbsp;</b>6019 - 6020</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07049-0\">A New single switch DC-DC converter for PEM fuel cell-based electric vehicle system with an improved beta-fuzzy logic MPPT controller</a></div><div><b>Author(s):&nbsp;</b>C. H. Hussaian Basha, C. Rani</div><div><b>Pages:&nbsp;</b>6021 - 6040</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07114-8\">An interval method to measure the uncertainty of basic probability assignment</a></div><div><b>Author(s):&nbsp;</b>Jinyan Su, Yong Deng</div><div><b>Pages:&nbsp;</b>6041 - 6050</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07120-w\">An iterative method for solving linear fuzzy fractional integral equation</a></div><div><b>Author(s):&nbsp;</b>Alexandru Mihai Bica, Shokrollah Ziari, Zoltan Satmari</div><div><b>Pages:&nbsp;</b>6051 - 6062</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07123-7\">Mining fuzzy high average-utility itemsets using fuzzy utility lists and efficient pruning approach</a></div><div><b>Author(s):&nbsp;</b>Manijeh Hajihoseini, Mohammad Karim Sohrabi</div><div><b>Pages:&nbsp;</b>6063 - 6086</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07126-4\">q-Rung orthopair fuzzy N-soft aggregation operators and corresponding applications to multiple-attribute group decision making</a></div><div><b>Author(s):&nbsp;</b>Haidong Zhang, TaiBen Nan, Yanping He</div><div><b>Pages:&nbsp;</b>6087 - 6099</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07013-y\">Sustainability assessment of supply chains by a novel robust two-stage network DEA model: a case study in the transport industry</a></div><div><b>Author(s):&nbsp;</b>Amirali Fathi, Balal Karimi, Reza Farzipoor Saen</div><div><b>Pages:&nbsp;</b>6101 - 6118</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07102-y\">Optimal scale combination selection for inconsistent multi-scale decision tables</a></div><div><b>Author(s):&nbsp;</b>Zhu Yingjie, Yang Bin</div><div><b>Pages:&nbsp;</b>6119 - 6129</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07075-y\">Gradient eigendecomposition invariance biogeography-based optimization for mobile robot path planning</a></div><div><b>Author(s):&nbsp;</b>Xiaodong Na, Jiaqian Wang...Decai Li</div><div><b>Pages:&nbsp;</b>6131 - 6144</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07110-y\">ML-WiGR: a meta-learning-based approach for cross-domain device-free gesture recognition</a></div><div><b>Author(s):&nbsp;</b>Zhenyue Gao, Jianqiang Xue...Wendong Xiao</div><div><b>Pages:&nbsp;</b>6145 - 6155</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07129-1\">Ensemble of hybrid neural networks to compensate for epistemic uncertainties: a case study in system prognosis</a></div><div><b>Author(s):&nbsp;</b>Arinan Dourado, Felipe Viana</div><div><b>Pages:&nbsp;</b>6157 - 6173</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07130-8\">Chronic diseases monitoring and diagnosis system based on features selection and machine learning predictive models</a></div><div><b>Author(s):&nbsp;</b>Sahar A. EL-Rahman, Ala Saleh Alluhaidan...Duna N. AlZunaytan</div><div><b>Pages:&nbsp;</b>6175 - 6199</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07138-0\">LM-MFP: large-scale morphology and multi-criteria-based feature pooling for image parsing</a></div><div><b>Author(s):&nbsp;</b>Vishal Srivastava, Bhaskar Biswas</div><div><b>Pages:&nbsp;</b>6201 - 6218</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07140-6\">Unsupervised abnormal detection using VAE with memory</a></div><div><b>Author(s):&nbsp;</b>Xin Xie, Xinlei Li...Huiping Li</div><div><b>Pages:&nbsp;</b>6219 - 6231</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07149-x\">Exploring different interaction among features for CTR prediction</a></div><div><b>Author(s):&nbsp;</b>Leilei Yang, Wenguang Zheng, Yingyuan Xiao</div><div><b>Pages:&nbsp;</b>6233 - 6243</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07163-z\">Brain tumor magnetic resonance image classification: a deep learning approach</a></div><div><b>Author(s):&nbsp;</b>Machiraju Jaya Lakshmi, S. Nagaraja Rao</div><div><b>Pages:&nbsp;</b>6245 - 6253</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07164-y\">An effective text compression\u2013encryption using tight and indirect encryptions</a></div><div><b>Author(s):&nbsp;</b>Ranganath Ponnaboyina, Ramesh Makala...Venkata Ramana Gupta Nallagattla</div><div><b>Pages:&nbsp;</b>6255 - 6264</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07002-1\">Power system security enhancement in FACTS devices based on Yin\u2013Yang pair optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>A. Amarendra, L. Ravi Srinivas, R. Srinivasa Rao</div><div><b>Pages:&nbsp;</b>6265 - 6291</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07033-8\">Enhancing the contrast of the grey-scale image based on meta-heuristic optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>Ali Hussain Khan, Shameem Ahmed...Ram Sarkar</div><div><b>Pages:&nbsp;</b>6293 - 6315</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07039-2\">2-Tuple unbalanced linguistic multiple-criteria group decision-making using prospect theory data envelopment analysis</a></div><div><b>Author(s):&nbsp;</b>Imran Khan, Anjana Gupta, Aparna Mehra</div><div><b>Pages:&nbsp;</b>6317 - 6332</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06610-7\">Offline parameter estimation of a modified permanent magnet generator using GSA and GSA-PSO</a></div><div><b>Author(s):&nbsp;</b>Vinod Puri, Yogesh K. Chauhan</div><div><b>Pages:&nbsp;</b>6333 - 6345</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06613-4\">A survey on soft computing-based high-utility itemsets mining</a></div><div><b>Author(s):&nbsp;</b>Rajiv Kumar, Kuldeep Singh</div><div><b>Pages:&nbsp;</b>6347 - 6392</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07157-x\">Limestone supplier selection for coal thermal power plant by applying integrated PF-SAW and PF-EDAS approach</a></div><div><b>Author(s):&nbsp;</b>Fethullah G\u00f6\u00e7er</div><div><b>Pages:&nbsp;</b>6393 - 6414</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07165-x\">Consensus tracking-based clock synchronization for the Internet of Things</a></div><div><b>Author(s):&nbsp;</b>Yuqing Niu, Ting Yang...Wei Li</div><div><b>Pages:&nbsp;</b>6415 - 6428</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07167-9\">Blockchain multi-objective optimization approach-enabled secure and cost-efficient scheduling for the Internet of Medical Things (IoMT) in fog-cloud system</a></div><div><b>Author(s):&nbsp;</b>Abdullah Lakhan, Mazin Abed Mohammed...Karrar Hameed Abdulkareem</div><div><b>Pages:&nbsp;</b>6429 - 6442</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06973-5\">Periodic event-triggered modified repetitive control with equivalent-input-disturbance estimator based on T-S fuzzy model for nonlinear systems</a></div><div><b>Author(s):&nbsp;</b>Sameh Abd-Elhaleem, Mohamed Soliman, Mohamed Hamdy</div><div><b>Pages:&nbsp;</b>6443 - 6459</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07205-6\">Correction to: Periodic event-triggered modified repetitive control with equivalent-input-disturbance estimator based on T-S fuzzy model for nonlinear systems</a></div><div><b>Author(s):&nbsp;</b>Sameh Abd-Elhaleem, Mohamed Soliman, Mohamed Hamdy</div><div><b>Pages:&nbsp;</b>6461 - 6462</div><div><br /></div><div><br /></div>",
            "pubdate": "2022-06-19T12:00:00.113+12:00",
            "pubdate_parsed": [
                2022,
                6,
                19
            ],
            "email_sent": true
        },
        "Programming languages for AI: a meta-analysis of popularity": {
            "url": "https://computational-intelligence.blogspot.com/2022/06/programming-languages-for-ai-meta.html",
            "description": "<div style=\"text-align: left;\"><u><b>Introduction</b></u></div><p>There are many articles about which programming languages an AI engineer should be familiar with. While there are frequent similarities between these lists, comparing them is difficult. In this post, I'll briefly report on a quick metanalysis of these articles, with an eye to producing a ranked list of programming languages that balances popularity and rating.</p><div style=\"text-align: left;\"><b><u>Methodology</u></b></div><p>The data I used in this analysis came from <a href=\"https://computational-intelligence.blogspot.com/feeds/posts/default#References\">24 different articles</a>. To ensure that the data was mostly current, I restricted the articles to those that had been either published or updated since the beginning of 2020. I also checked that each article was from a different author, to prevent duplication. Where several languages were ranked the same on the list, I recorded them as separate entries with the same rank.</p><div style=\"text-align: left;\"><u><b>Results</b></u></div><p>The lists were of varying lengths, the minimum was five and the maximum was 12. The most frequent list length was ten, with a mean of 8 and median of 9.</p><p>I analysed the lists in three ways:</p><p></p><ol style=\"text-align: left;\"><li>The <a href=\"https://computational-intelligence.blogspot.com/feeds/posts/default#frequency\">frequency</a> at which a language appeared in the lists, regardless of position on the list;</li><li>The <a href=\"https://computational-intelligence.blogspot.com/feeds/posts/default#median\">median rank</a> assigned to each language across all lists in which it appears, and;</li><li>A <a href=\"https://computational-intelligence.blogspot.com/feeds/posts/default#weighted\">weighted median</a> rank, where the median rank of the language was weighted according to the frequency at which it appeared in lists. This corrects for outliers that were highly ranked on only a small number of lists.</li></ol><div>Below are the top ten ranked languages, for each analysis method.</div><p></p><p>In order of <a name=\"frequency\">frequency</a>, the top ten languages for AI are:</p><p></p><ol style=\"text-align: left;\"><li>Python</li><li>Java</li><li>R</li><li>C++</li><li>Lisp</li><li>Julia</li><li>Prolog</li><li>Haskell</li><li>JavaScript</li><li>Scala</li></ol><p></p><p>In order of <a name=\"median\">median rank</a>:</p><p></p><ol style=\"text-align: left;\"><li>Python</li><li>Java</li><li>C</li><li>C#</li><li>R</li><li>C++</li><li>Lisp</li><li>JavaScript</li><li>Prolog</li><li>Julia</li></ol><div>Note that this is only the median ranks of languages, regardless of how frequently they are listed. This has the effect of pushing some languages, such as C, higher up the list than they would otherwise be. This is corrected by the <a name=\"weighted\">weighted median rank</a>.</div><div><br /></div><div>The top ten languages for AI, as ordered by weighted median rank, are:</div><div><ol style=\"text-align: left;\"><li>Python</li><li>Java</li><li>R</li><li>C++</li><li>Lisp</li><li>Prolog</li><li>Julia</li><li>Haskell</li><li>JavaScript</li><li>Scala</li></ol></div><p></p><p>As this listing accounts for both rankings of languages, and the frequency at which the language appears in the articles, I consider this to be the most informative.</p><div style=\"text-align: left;\"><a name=\"References\"><u><b>References</b></u></a></div><ul style=\"text-align: left;\"><li><a href=\"https://www.itproportal.com/features/top-five-programming-languages-for-ai-and-machine-learning-you-should-learn-this-year/\">https://www.itproportal.com/features/top-five-programming-languages-for-ai-and-machine-learning-you-should-learn-this-year/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.yoh.com/blog/10-best-programming-languages-for-ai-development\">https://www.yoh.com/blog/10-best-programming-languages-for-ai-development</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.trio.dev/blog/best-languages-for-ai\">https://www.trio.dev/blog/best-languages-for-ai</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.makeuseof.com/best-programming-languages-ai-development/\">https://www.makeuseof.com/best-programming-languages-ai-development/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.moveoapps.com/blog/best-programming-languages-ai-development/\">https://www.moveoapps.com/blog/best-programming-languages-ai-development/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.bairesdev.com/blog/top-6-languages-for-artificial-intelligence/\">https://www.bairesdev.com/blog/top-6-languages-for-artificial-intelligence/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.turing.com/blog/best-programming-languages-for-ai-development/\">https://www.turing.com/blog/best-programming-languages-for-ai-development/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.springboard.com/blog/data-science/best-programming-language-for-ai/\">https://www.springboard.com/blog/data-science/best-programming-language-for-ai/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.ksolves.com/blog/artificial-intelligence/top-8-programming-languages-for-artificial-intelligence-projects\">https://www.ksolves.com/blog/artificial-intelligence/top-8-programming-languages-for-artificial-intelligence-projects</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.ideamotive.co/blog/the-best-programming-language-for-ai-development\">https://www.ideamotive.co/blog/the-best-programming-language-for-ai-development</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.spec-india.com/blog/ai-programming-languages\">https://www.spec-india.com/blog/ai-programming-languages</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://invozone.com/blog/top-8-programming-languages-for-ai-development-in-2022\">https://invozone.com/blog/top-8-programming-languages-for-ai-development-in-2022</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://careerkarma.com/blog/best-programming-languages-for-ai/\">https://careerkarma.com/blog/best-programming-languages-for-ai/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.datasciencecentral.com/best-programming-languages-for-ai-amp-ml-artificial-intelligence/\">https://www.datasciencecentral.com/best-programming-languages-for-ai-amp-ml-artificial-intelligence/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.toolbox.com/tech/artificial-intelligence/articles/ai-programming-languages/\">https://www.toolbox.com/tech/artificial-intelligence/articles/ai-programming-languages/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://blog.robotiq.com/what-is-the-best-programming-language-for-robotics\">https://blog.robotiq.com/what-is-the-best-programming-language-for-robotics</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.linkedin.com/pulse/top-9-ai-programming-languages-2021-george-burlakov/\">https://www.linkedin.com/pulse/top-9-ai-programming-languages-2021-george-burlakov/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://pixelplex.io/blog/top-ai-programming-languages/\">https://pixelplex.io/blog/top-ai-programming-languages/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://iglu.net/best-programming-languages-for-ai/\">https://iglu.net/best-programming-languages-for-ai/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.zfort.com/blog/best-programming-language-for-ai\">https://www.zfort.com/blog/best-programming-language-for-ai</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.orientsoftware.com/blog/best-programming-language-for-ai/\">https://www.orientsoftware.com/blog/best-programming-language-for-ai/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://readwrite.com/top-10-programming-languages-to-become-an-ai-developer/\">https://readwrite.com/top-10-programming-languages-to-become-an-ai-developer/</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://towardsdatascience.com/top-programming-languages-for-ai-engineers-in-2020-33a9f16a80b0\">https://towardsdatascience.com/top-programming-languages-for-ai-engineers-in-2020-33a9f16a80b0</a><span style=\"white-space: pre;\">\t\t</span></li><li><a href=\"https://www.rankred.com/best-artificial-intelligence-programming-language/\">https://www.rankred.com/best-artificial-intelligence-programming-language/</a><span style=\"white-space: pre;\">\t</span></li></ul><p></p>",
            "pubdate": "2022-06-20T15:41:00.004+12:00",
            "pubdate_parsed": [
                2022,
                6,
                20
            ],
            "email_sent": true
        },
        "IEEE Transactions on Fuzzy Systems, Volume 30, Issue 7": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9419714/\">Novel Heterogeneous Mode-Dependent Impulsive Synchronization for Piecewise T-S Fuzzy Probabilistic Coupled Delayed Neural Networks</a></div><div><b>Author(s): </b>Xiangxiang Wang, Yongbin Yu, Shouming Zhong, Kaibo Shi, Nijing Yang, Dingfa Zhang, Jingye Cai, Nyima Tashi</div><div><b>Pages: </b>2142 - 2156</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9419710/\">Nonlinear Dimensionality Reduction for Data Visualization: An Unsupervised Fuzzy Rule-Based Approach</a></div><div><b>Author(s):&nbsp;</b>Suchismita Das, Nikhil R. Pal</div><div><b>Pages:&nbsp;</b>2157 - 2169</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9423589/\">An Efficient Self-Organizing Deep Fuzzy Neural Network for Nonlinear System Modeling</a></div><div><b>Author(s):&nbsp;</b>Gongming Wang, Junfei Qiao</div><div><b>Pages:&nbsp;</b>2170 - 2182</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9424990/\">Adaptive Event-Triggered Fuzzy Tracking Control of Uncertain Stochastic Nonlinear Systems With Unmeasurable States</a></div><div><b>Author(s):&nbsp;</b>Rui-Yan Zhang, Li-Bing Wu, Nan-Nan Zhao, Yan Yan</div><div><b>Pages:&nbsp;</b>2183 - 2196</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9425433/\">Membership Function, Time Delay-Dependent \u03b7-Exponential Stabilization of the Positive Discrete-Time Polynomial Fuzzy Model Control System</a></div><div><b>Author(s):&nbsp;</b>Xiaomiao Li, Kamyar Mehran, Zhiyong Bao</div><div><b>Pages:&nbsp;</b>2197 - 2209</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9425590/\">A Novel Three-Way Decision Model Based on Utility Theory in Incomplete Fuzzy Decision Systems</a></div><div><b>Author(s):&nbsp;</b>Jianming Zhan, Jin Ye, Weiping Ding, Peide Liu</div><div><b>Pages:&nbsp;</b>2210 - 2226</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9427360/\">Finite-Time Adaptive Fuzzy Prescribed Performance Control for High-Order Stochastic Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Shuai Sui, C. L. Philip Chen, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>2227 - 2240</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9427125/\">Maximum Number of Line Faults in a P2P Network System Based on the Addition-Min Fuzzy Relation Inequalities</a></div><div><b>Author(s):&nbsp;</b>Xiao-Peng Yang, Gengzhong Zheng</div><div><b>Pages:&nbsp;</b>2241 - 2253</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9427225/\">Sampled-Data-Based H\u221e Fuzzy Pinning Synchronization of Complex Networked Systems With Adaptive Event-Triggered Communications</a></div><div><b>Author(s):&nbsp;</b>Xin Wang, Ju H. Park, Huilan Yang, Zhiqi Yu</div><div><b>Pages:&nbsp;</b>2254 - 2265</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9428619/\">Analysis of Ranking Consistency in Linguistic Multiple Attribute Decision Making: The Roles of Granularity and Decision Rules</a></div><div><b>Author(s):&nbsp;</b>Sihai Zhao, Yucheng Dong, Luis Mart\u00edne, Witold Pedrycz</div><div><b>Pages:&nbsp;</b>2266 - 2278</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9428344/\">Adaptive Fast Finite-Time Fuzzy Control of Stochastic Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Zhaoyang You, Fang Wang</div><div><b>Pages:&nbsp;</b>2279 - 2288</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9428513/\">Model-Based Fuzzy l2\u2212l\u221e Filtering for Discrete-Time Semi-Markov Jump Nonlinear Systems Using Semi-Markov Kernel</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Yigang Zhang, Lei Su, Ju H. Park, Hao Shen</div><div><b>Pages:&nbsp;</b>2289 - 2299</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9430728/\">Adaptive Fuzzy SOSM Controller Design With Output Constraints</a></div><div><b>Author(s):&nbsp;</b>Shihong Ding, Binbin Zhang, Keqi Mei, Ju H. Park</div><div><b>Pages:&nbsp;</b>2300 - 2311</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9430676/\">Fault-Tolerant Quantized Sliding Mode Observers Design for a Class of Takagi-Sugeno Fuzzy System With Unmeasurable Premise Variable</a></div><div><b>Author(s):&nbsp;</b>Ang Li, Guangren Duan, Ming Liu, Jingbo Fu</div><div><b>Pages:&nbsp;</b>2312 - 2324</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9432713/\">Fuzzy Energy-to-Peak Filtering for Continuous-Time Nonlinear Singular System</a></div><div><b>Author(s):&nbsp;</b>Xiao-Heng Chang, Ming-Yang Qiao, Xudong Zhao</div><div><b>Pages:&nbsp;</b>2325 - 2336</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9435080/\">An Analytical Method to Compute the Approximate Inverses of a Fuzzy Matrix With Max-Product Composition</a></div><div><b>Author(s):&nbsp;</b>Yan-Kuen Wu, Yung-Yih Lur, Hsun-Chih Kuo, Ching-Feng Wen</div><div><b>Pages:&nbsp;</b>2337 - 2346</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9436023/\">Fuzzy Event-Triggered Integral Sliding Mode Control of Nonlinear Continuous-Time Systems</a></div><div><b>Author(s):&nbsp;</b>Zeinab Echreshavi, Mohsen Farbood, Mokhtar Shasadeghi</div><div><b>Pages:&nbsp;</b>2347 - 2359</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9435959/\">Fuzzy Measures and Choquet Integrals Based on Fuzzy Covering Rough Sets</a></div><div><b>Author(s):&nbsp;</b>Xiaohong Zhang, Jingqian Wang, Jianming Zhan, Jianhua Dai</div><div><b>Pages:&nbsp;</b>2360 - 2374</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9436033/\">Fast Fuzzy Clustering Based on Anchor Graph</a></div><div><b>Author(s):&nbsp;</b>Feiping Nie, Chaodie Liu, Rong Wang, Zhen Wang, Xuelong Li</div><div><b>Pages:&nbsp;</b>2375 - 2387</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9437688/\">Multilabel Feature Selection Based on Relative Discernibility Pair Matrix</a></div><div><b>Author(s):&nbsp;</b>Erliang Yao, Deyu Li, Yanhui Zhai, Chao Zhang</div><div><b>Pages:&nbsp;</b>2388 - 2401</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9439174/\">Quantized Guaranteed Cost Output Feedback Control for Nonlinear Networked Control Systems and Its Applications</a></div><div><b>Author(s):&nbsp;</b>Qunxian Zheng, Shengyuan Xu, Baozhu Du</div><div><b>Pages:&nbsp;</b>2402 - 2411</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9439896/\">Fuzzy Bayesian Knowledge Tracing</a></div><div><b>Author(s):&nbsp;</b>Fei Liu, Xuegang Hu, Chenyang Bu, Kui Yu</div><div><b>Pages:&nbsp;</b>2412 - 2425</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9440662/\">Dwell-Time-Dependent H\u221e Bumpless Transfer Control for Discrete-Time Switched Interval Type-2 Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Siyuan Zhang, Jun Zhao</div><div><b>Pages:&nbsp;</b>2426 - 2437</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9442351/\">Fuzzy Multioutput Transfer Learning for Regression</a></div><div><b>Author(s):&nbsp;</b>Xiaoya Che, Hua Zuo, Jie Lu, Degang Chen</div><div><b>Pages:&nbsp;</b>2438 - 2451</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9442297/\">Stability and Control of Fuzzy Semi-Markov Jump Systems Under Unknown Semi-Markov Kernel</a></div><div><b>Author(s):&nbsp;</b>Zepeng Ning, Bo Cai, Rui Weng, Lixian Zhang, Shun-Feng Su</div><div><b>Pages:&nbsp;</b>2452 - 2465</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9446576/\">New Results on Dissipative Control for a Class of Singular Takagi\u2013Sugeno Fuzzy Systems With Time Delay</a></div><div><b>Author(s):&nbsp;</b>Zhiguang Feng, Huayang Zhang, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>2466 - 2475</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9447197/\">Finite-Time Dynamic Event-Triggered Distributed H\u221e Filtering for T-S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaoyuan Zheng, Hao Zhang, Zhuping Wang, Changzhu Zhang, Huaicheng Yan</div><div><b>Pages:&nbsp;</b>2476 - 2486</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9447907/\">Asynchronous Fault Detection for Interval Type-2 Fuzzy Nonhomogeneous Higher Level Markov Jump Systems With Uncertain Transition Probabilities</a></div><div><b>Author(s):&nbsp;</b>Xiang Zhang, Hai Wang, Vladimir Stojanovic, Peng Cheng, Shuping He, Xiaoli Luan, Fei Liu</div><div><b>Pages:&nbsp;</b>2487 - 2499</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9448475/\">Fuzzy Community Detection Based on Elite Symbiotic Organisms Search and Node Neighborhood Information</a></div><div><b>Author(s):&nbsp;</b>Jing Xiao, Yan-Jiao Wang, Xiao-Ke Xu</div><div><b>Pages:&nbsp;</b>2500 - 2514</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9449989/\">Cooperative Target Enclosing of Ring-Networked Underactuated Autonomous Surface Vehicles Based on Data-Driven Fuzzy Predictors and Extended State Observers</a></div><div><b>Author(s):&nbsp;</b>Yue Jiang, Zhouhua Peng, Dan Wang, Yong Yin, Qing-Long Han</div><div><b>Pages:&nbsp;</b>2515 - 2528</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9454304/\">A Simplified Finite-Time Fuzzy Neural Controller With Prescribed Performance Applied to Waverider Aircraft</a></div><div><b>Author(s):&nbsp;</b>Xiangwei Bu, Qiang Qi, Baoxu Jiang</div><div><b>Pages:&nbsp;</b>2529 - 2537</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9454283/\">Stability Criteria for Fuzzy-Based Sampled-Data Control Systems via a Fractional Parameter-Based Refined Looped Lyapunov Functional</a></div><div><b>Author(s):&nbsp;</b>Lakshmanan Shanmugam, Young Hoon Joo</div><div><b>Pages:&nbsp;</b>2538 - 2549</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9454293/\">Distributed Kalman Filter With Fuzzy Noises Over Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Haoshen Lin, Chen Hu, Zhenhua Deng, Gang Liu</div><div><b>Pages:&nbsp;</b>2550 - 2562</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9454307/\">Self-Sustaining Oscillations With an Internal Two-Fuzzy Inference System Based on the Poincar\u00e9\u2013Bendixson Method</a></div><div><b>Author(s):&nbsp;</b>Jorge A. Lopez-Renteria, Lisdan Herrera-Garcia, Selene L. Cardenas-Maciel, Luis T. Aguilar, Nohe R. Cazarez-Castro</div><div><b>Pages:&nbsp;</b>2563 - 2573</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9454376/\">Admissibility and Design Issues for T-S Fuzzy Descriptor Systems With Perturbed Derivative Matrices in the Rules</a></div><div><b>Author(s):&nbsp;</b>Chih-Peng Huang</div><div><b>Pages:&nbsp;</b>2574 - 2582</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9454380/\">Guaranteed Cost Control for Interval Type-2 Fuzzy Semi-Markov Switching Systems Within a Finite-Time Interval</a></div><div><b>Author(s):&nbsp;</b>Linchuang Zhang, Yonghui Sun, Hak-Keung Lam, Hongyi Li, Jianxi Wang, Dongchen Hou</div><div><b>Pages:&nbsp;</b>2583 - 2594</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9457145/\">Finite-Frequency H\u2212/H\u221e Memory Fault Detection Filtering Design for Uncertain Takagi\u2013Sugeno Fuzzy Affine Systems</a></div><div><b>Author(s):&nbsp;</b>Rong Zhao, Lu Liu, Gang Feng</div><div><b>Pages:&nbsp;</b>2595 - 2609</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9457138/\">Event-Triggered Bipartite Consensus for Fuzzy Multiagent Systems Under Markovian Switching Signed Topology</a></div><div><b>Author(s):&nbsp;</b>Jiafeng Yu, Choon Ki Ahn, Peng Shi</div><div><b>Pages:&nbsp;</b>2610 - 2620</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9457143/\">Continuous Exp Strategy for Consumer Preference Analysis Based on Online Ratings</a></div><div><b>Author(s):&nbsp;</b>Long Ren, Bin Zhu, Zeshui Xu</div><div><b>Pages:&nbsp;</b>2621 - 2633</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9457170/\">Trust Cop-Kmeans Clustering Analysis and Minimum-Cost Consensus Model Considering Voluntary Trust Loss in Social Network Large-Scale Decision-Making</a></div><div><b>Author(s):&nbsp;</b>Su-Min Yu, Zhi-Jiao Du, Xue-Yang Zhang, Han-Yang Luo, Xu-Dong Lin</div><div><b>Pages:&nbsp;</b>2634 - 2648</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9462345/\">Statistically Evolving Fuzzy Inference System for Non-Gaussian Noises</a></div><div><b>Author(s):&nbsp;</b>Zhao-Xu Yang, Hai-Jun Rong, Plamen Angelov, Zhi-Xin Yang</div><div><b>Pages:&nbsp;</b>2649 - 2664</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9462321/\">A New Fuzzy Spiking Neural Network Based on Neuronal Contribution Degree</a></div><div><b>Author(s):&nbsp;</b>Fang Liu, Jie Yang, Witold Pedrycz, Wei Wu</div><div><b>Pages:&nbsp;</b>2665 - 2677</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9462470/\">Aperiodic Sampled-Data Takagi\u2013Sugeno Fuzzy Extended State Observer for a Class of Uncertain Nonlinear Systems With External Disturbance and Unmodeled Dynamics</a></div><div><b>Author(s):&nbsp;</b>Zhichen Li, Huaicheng Yan, Hao Zhang, Hak-Keung Lam, Congzhi Huang</div><div><b>Pages:&nbsp;</b>2678 - 2692</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9464680/\">Sampled-Data-Based Event-Triggered Fuzzy Control for PDE Systems Under Cyberattacks</a></div><div><b>Author(s):&nbsp;</b>Xiaona Song, Qiyuan Zhang, Shuai Song, Choon Ki Ahn</div><div><b>Pages:&nbsp;</b>2693 - 2705</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9466935/\">Interval-Valued Aggregation Functions Based on Moderate Deviations Applied to Motor-Imagery-Based Brain\u2013Computer Interface</a></div><div><b>Author(s):&nbsp;</b>Javier Fumanal-Idocin, Zdenko Tak\u00e1\u010d, Javier Fern\u00e1ndez, Jos\u00e9 Antonio Sanz, Harkaitz Goyena, Ching-Teng Lin, Yu-Kai Wang, Humberto Bustince</div><div><b>Pages:&nbsp;</b>2706 - 2720</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9468319/\">Noise-Tolerant Fuzzy-\u03b2-Covering-Based Multigranulation Rough Sets and Feature Subset Selection</a></div><div><b>Author(s):&nbsp;</b>Zhehuang Huang, Jinjin Li, Yuhua Qian</div><div><b>Pages:&nbsp;</b>2721 - 2735</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9470937/\">Expansive Errors-Based Fuzzy Adaptive Prescribed Performance Control by Residual Approximation</a></div><div><b>Author(s):&nbsp;</b>Shigen Gao, Mingjun Li, Yue Zheng, Hairong Dong</div><div><b>Pages:&nbsp;</b>2736 - 2746</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9477002/\">Fractional-Order Terminal Sliding-Mode Control Using Self-Evolving Recurrent Chebyshev Fuzzy Neural Network for MEMS Gyroscope</a></div><div><b>Author(s):&nbsp;</b>Zhe Wang, Juntao Fei</div><div><b>Pages:&nbsp;</b>2747 - 2758</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9477053/\">Relaxed Conditions of Observer Design of Discrete-Time Takagi\u2013Sugeno Fuzzy Systems via a New Multi-Instant Gain-Scheduling Scheme</a></div><div><b>Author(s):&nbsp;</b>Hongyu Lu, Xiangpeng Xie, Chen Peng</div><div><b>Pages:&nbsp;</b>2759 - 2768</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9426421/\">A Fuzzy Lyapunov Function Method to Stability Analysis of Fractional-Order T\u2013S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Fan, Zhanshan Wang</div><div><b>Pages:&nbsp;</b>2769 - 2776</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9454282/\">Multi-Instant Gain-Scheduling Stabilization of Discrete-Time Takagi\u2013Sugeno Fuzzy Systems Based on a Time-Variant Balanced Matrix Approach</a></div><div><b>Author(s):&nbsp;</b>Xiangpeng Xie, Chengjie Bu, Chen Peng</div><div><b>Pages:&nbsp;</b>2777 - 2782</div><div><br /></div>",
            "pubdate": "2022-07-08T10:36:00.000+12:00",
            "pubdate_parsed": [
                2022,
                7,
                7
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 14, July 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-14-july.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07116-6\">Efficient data transfer supporting provable data deletion for secure cloud storage</a></div><div><b>Author(s): </b>Changsong Yang, Yueling Liu, Yong Ding</div><div><b>Pages: </b>6463 - 6479</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07119-3\">Green\u2019s relations in L-E-fuzzy skew lattices</a></div><div><b>Author(s):&nbsp;</b>Yuan Zhi, Xiangnan Zhou, Qingguo Li</div><div><b>Pages:&nbsp;</b>6481 - 6494</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07134-4\">Regular and strongly regular relations induced by fuzzy subhypermodules</a></div><div><b>Author(s):&nbsp;</b>N. Rakhsh Khorshid, S. Ostadhadi-Dehkordi</div><div><b>Pages:&nbsp;</b>6495 - 6506</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07127-3\">Another view on knowledge measures in atanassov intuitionistic fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>Muhammad Irfan Ali, Jianming Zhan...Haider Faizan</div><div><b>Pages:&nbsp;</b>6507 - 6517</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07128-2\">Effect of fuzziness in fuzzy rule-based classifiers defined by strong fuzzy partitions and winner-takes-all inference</a></div><div><b>Author(s):&nbsp;</b>Gabriella Casalino, Giovanna Castellano...Corrado Mencar</div><div><b>Pages:&nbsp;</b>6519 - 6527</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07168-8\">Nonlinear interval regression analysis with neural networks and grey prediction for energy demand forecasting</a></div><div><b>Author(s):&nbsp;</b>Yi-Chung Hu, Wen-Bao Wang</div><div><b>Pages:&nbsp;</b>6529 - 6545</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07178-6\">Knowledge transfer learning from multiple user activities to improve personalized recommendation</a></div><div><b>Author(s):&nbsp;</b>Mingxin Gan, Yingxue Ma</div><div><b>Pages:&nbsp;</b>6547 - 6566</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07179-5\">A quantum system control method based on enhanced reinforcement learning</a></div><div><b>Author(s):&nbsp;</b>Wenjie Liu, Bosi Wang...Mohammed Zidan</div><div><b>Pages:&nbsp;</b>6567 - 6575</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07181-x\">On-demand DWDM design using machine learning</a></div><div><b>Author(s):&nbsp;</b>K. Venkatesan, A. Chandrasekar, P. G. V. Ramesh</div><div><b>Pages:&nbsp;</b>6577 - 6589</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07040-9\">Ramp loss KNN-weighted multi-class twin support vector machine</a></div><div><b>Author(s):&nbsp;</b>Huiru Wang, Yitian Xu, Zhijian Zhou</div><div><b>Pages:&nbsp;</b>6591 - 6618</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07042-7\">A revisited fuzzy DEMATEL and optimization method for strategy map design under the BSC framework: selection of objectives and relationships</a></div><div><b>Author(s):&nbsp;</b>H\u00e9ctor L\u00f3pez-Ospina, Daniela Pardo...Luis Quezada</div><div><b>Pages:&nbsp;</b>6619 - 6644</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07043-6\">A novel linear representation for evolving matrices</a></div><div><b>Author(s):&nbsp;</b>Connor Gregor, Daniel Ashlock...David Kribs</div><div><b>Pages:&nbsp;</b>6645 - 6657</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07050-7\">MOTEO: a novel multi-objective thermal exchange optimization algorithm for engineering problems</a></div><div><b>Author(s):&nbsp;</b>Nima Khodadadi, Siamak Talatahari...Armin Dadras Eslamlou</div><div><b>Pages:&nbsp;</b>6659 - 6684</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07061-4\">A novel incremental cost consensus approach for distributed economic dispatch over directed communication topologies in a smart grid</a></div><div><b>Author(s):&nbsp;</b>Um-E-Habiba Alvi, Waqas Ahmed...Ijaz Ahmed</div><div><b>Pages:&nbsp;</b>6685 - 6700</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07065-0\">Intelligent computing technique for solving singular multi-pantograph delay differential equation</a></div><div><b>Author(s):&nbsp;</b>Zulqurnain Sabir, Hafiz Abdul Wahab...Mohamed R. Ali</div><div><b>Pages:&nbsp;</b>6701 - 6713</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07066-z\">Optimization on the multi-period empty container repositioning problem in regional port cluster based upon inventory control strategies</a></div><div><b>Author(s):&nbsp;</b>Jiaxin Cai, Yubo Li...Zhihong Jin</div><div><b>Pages:&nbsp;</b>6715 - 6738</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07072-1\">A simple solution to technician routing and scheduling problem using improved genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Engin Pekel</div><div><b>Pages:&nbsp;</b>6739 - 6748</div><div><br /></div><div><b>18) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07079-8\">Fusion of modern meta-heuristic optimization methods using arithmetic optimization algorithm for global optimization tasks</a></div><div><b>Author(s):&nbsp;</b>Shubham Mahajan, Laith Abualigah...Maryam Altalhi</div><div><b>Pages:&nbsp;</b>6749 - 6763</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07089-6\">Identification of nonlinear discrete systems using a new Hammerstein model with Volterra neural network</a></div><div><b>Author(s):&nbsp;</b>Wei-Der Chang</div><div><b>Pages:&nbsp;</b>6765 - 6775</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07103-x\">Environmental assisted cracking and strength attenuation effect computing on the mechanical properties of casing steel P110 for industrial revolution 5.0 applications in sour well environments</a></div><div><b>Author(s):&nbsp;</b>Duo Hou, Zhongling Xiao...Taihe Shi</div><div><b>Pages:&nbsp;</b>6777 - 6787</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06906-2\">Comparison of subsidy strategies on the green supply chain under a behaviour-based pricing model</a></div><div><b>Author(s):&nbsp;</b>Kanying Liu, Wei Li...Yong Lan</div><div><b>Pages:&nbsp;</b>6789 - 6809</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06921-3\">Attack detection and prevention in IoT-SCADA networks using NK-classifier</a></div><div><b>Author(s):&nbsp;</b>Y. JustindhasP. Jeyanthi</div><div><b>Pages:&nbsp;</b>6811 - 6823</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06926-y\">A method to determine the integrated weights of cross-efficiency aggregation</a></div><div><b>Author(s):&nbsp;</b>Mei-Juan LiJin-Cheng LuLei Chen</div><div><b>Pages:&nbsp;</b>6825 - 6837</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06628-x\">Load-settlement response of a footing over buried conduit in a sloping terrain: a numerical experiment-based artificial intelligent approach</a></div><div><b>Author(s):&nbsp;</b>Muhammad Umer Arif Khan, Sanjay Kumar Shukla, Muhammad Nouman Amjad Raja</div><div><b>Pages:&nbsp;</b>6839 - 6856</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06629-w\">Recognition of shed damage on 11-kV polymer insulator using Bayesian optimized convolution neural network</a></div><div><b>Author(s):&nbsp;</b>B. Vigneshwaran, M. Willjuice Iruthayarajan, R. V. Maheswari</div><div><b>Pages:&nbsp;</b>6857 - 6869</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06630-3\">Enhanced heat transfer search and enriched replicated coronary circulation system optimization algorithms for real power loss reduction</a></div><div><b>Author(s):&nbsp;</b>Lenin Kanagasabai</div><div><b>Pages:&nbsp;</b>6871 - 6888</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06636-x\">A novel quality evaluation method for standardized experiment teaching</a></div><div><b>Author(s):&nbsp;</b>Luxin Yang, Yutong Chun...Jing Yang</div><div><b>Pages:&nbsp;</b>6889 - 6906</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06639-8\">Feature extraction-based intelligent algorithm framework with neural network for solving conditional nonlinear optimal perturbation</a></div><div><b>Author(s):&nbsp;</b>Shijin Yuan,Huazhen Zhang...Bin Mu</div><div><b>Pages:&nbsp;</b>6907 - 6924</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06646-9\">Computational intelligence in software defects rules discovery</a></div><div><b>Author(s):&nbsp;</b>Andreea VescanCamelia \u015eerbanGloria Cerasela Cri\u015fan</div><div><b>Pages:&nbsp;</b>6925 - 6939</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06648-7\">Fuzzy transfer learning in time series forecasting for stock market prices</a></div><div><b>Author(s):&nbsp;</b>Shanoli Samui PalSamarjit Kar</div><div><b>Pages:&nbsp;</b>6941 - 6952</div><div><br /></div></div>",
            "pubdate": "2022-07-09T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                7,
                9
            ],
            "email_sent": true
        },
        "Evolving Systems, Volume 13, issue 4, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/evolving-systems-volume-13-issue-4.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09385-2\">FocusCovid: automated COVID-19 detection using deep learning with chest X-ray images</a></div><div><b>Author(s): </b>Tarun Agrawal, Prakash Choudhary</div><div><b>Pages: </b>519 - 533</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09392-3\">Multichannel convolutional neural network-based fuzzy active contour model for medical image segmentation</a></div><div><b>Author(s):&nbsp;</b>Qingwu Shi, Shoulin Yin...Hang Li</div><div><b>Pages:&nbsp;</b>535 - 549</div><div><br /></div><div><b>3)</b> Cubic graph representation of concept lattice and its decomposition</div><div><b>Author(s):&nbsp;</b>Prem Kumar Singh</div><div><b>Pages:&nbsp;</b>551 - 562</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09401-5\">Battle royale optimizer for training multi-layer perceptron</a></div><div><b>Author(s):&nbsp;</b>Saeid Agahian, Taymaz Akan</div><div><b>Pages:&nbsp;</b>563 - 575</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09404-2\">Extreme gradient boosting model based on improved Jaya optimizer applied to forecasting energy consumption in residential buildings</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o Sauer, Viviana Cocco Mariani...Mirco Rampazzo</div><div><b>Pages:&nbsp;</b>577 - 588</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09407-z\">Optimization of FRP jacket by fractional\u2011order pathfinder algorithm to improve the reinforced concrete frames' seismic response</a></div><div><b>Author(s):&nbsp;</b>Chengliang Wang, Wenrui Li, Dragan Rodriguez</div><div><b>Pages:&nbsp;</b>589 - 601</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09408-y\">EvolveCluster: an evolutionary clustering algorithm for streaming data</a></div><div><b>Author(s):&nbsp;</b>Christian Nordahl, Veselka Boeva...Marie Persson Netz</div><div><b>Pages:&nbsp;</b>603 - 623</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09395-0\">Synthetic samples generator (SYSGEN), an approach to increase the size of incidence samples in coffee leaf rust modelling</a></div><div><b>Author(s):&nbsp;</b>Edwar Javier Gir\u00f3n, David Camilo Corrales...Juan Carlos Corrales</div><div><b>Pages:&nbsp;</b>625 - 636</div><div><br /></div></div>",
            "pubdate": "2022-07-11T21:35:00.001+12:00",
            "pubdate_parsed": [
                2022,
                7,
                11
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 15, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-15.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07174-w\">Analytic hierarchy process-based regression test case prioritization technique enhancing the fault detection rate</a></div><div><b>Author(s): </b>Soumen Nayak, Chiranjeev Kumar, Sachin Tripathi</div><div><b>Pages: </b>6953 - 6968</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07193-7\">On Annihilators in Hoops</a></div><div><b>Author(s):&nbsp;</b>R. A. Borzooei, M. Aaly Kologani...Y. B. Jun</div><div><b>Pages:&nbsp;</b>6969 - 6980</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07216-3\">Properties of stabilizers in residuated lattices</a></div><div><b>Author(s):&nbsp;</b>Michiro Kondo</div><div><b>Pages:&nbsp;</b>6981 - 6988</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07217-2\">Independent domination polynomial of zero-divisor graphs of commutative rings</a></div><div><b>Author(s):&nbsp;</b>Necla K\u0131rcal\u0131 G\u00fcrsoy, Alper \u00dclker, Arif G\u00fcrsoy</div><div><b>Pages:&nbsp;</b>6989 - 6997</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07223-4\">Quasi-MV* algebras: a generalization of MV*-algebras</a></div><div><b>Author(s):&nbsp;</b>Yingying Jiang, Wenjuan Chen</div><div><b>Pages:&nbsp;</b>6999 - 7015</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06985-1\">Fuzzy filters of IL-algebras</a></div><div><b>Author(s):&nbsp;</b>Safiqul Islam, Arundhati Sanyal, Jayanta Sen</div><div><b>Pages:&nbsp;</b>7017 - 7027</div><div><br /></div><div><b>7) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07004-z\">Broad learning system based ensemble deep model</a></div><div><b>Author(s):&nbsp;</b>Chenglong Zhang, Shifei Ding...Jian Zhang</div><div><b>Pages:&nbsp;</b>7029 - 7041</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07101-z\">On differential lattices</a></div><div><b>Author(s):&nbsp;</b>Aiping Gan, Li Guo</div><div><b>Pages:&nbsp;</b>7043 - 7058</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07132-6\">A faster algorithm for identifying signals using complex fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>Madad Khan, Inamullah Khan...Sohail Iqbal</div><div><b>Pages:&nbsp;</b>7059 - 7079</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07172-y\">Trapezoidal approximation operators preserving the most indicators of fuzzy numbers-relationships and applications</a></div><div><b>Author(s):&nbsp;</b>M. Chehlabi</div><div><b>Pages:&nbsp;</b>7081 - 7105</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07150-4\">An introduction to single-valued neutrosophic soft topological structure</a></div><div><b>Author(s):&nbsp;</b>Yaser Saber, Fahad Alsharari, Florentin Smarandache</div><div><b>Pages:&nbsp;</b>7107 - 7122</div><div><br /></div><div><b>12) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07160-2\">An evidence combination rule based on a new weight assignment scheme</a></div><div><b>Author(s):&nbsp;</b>Yu-Cui Wang, Jian Wang...Ming-Hui Wang</div><div><b>Pages:&nbsp;</b>7123 - 7137</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07188-4\">A note on \u201cDealer using a new trapezoidal cubic hesitant fuzzy TOPSIS method and application to group decision-making program\u201d</a></div><div><b>Author(s):&nbsp;</b>S. S. Appadoo, Mohammadreza Makhan, Amit Kumar</div><div><b>Pages:&nbsp;</b>7139 - 7141</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07191-9\">Distributed energy-efficient clustering routing protocol for wireless sensor networks using affinity propagation and fuzzy logic</a></div><div><b>Author(s):&nbsp;</b>Chu-hang Wang, Huang-shui Hu...Jin-feng Zhang</div><div><b>Pages:&nbsp;</b>7143 - 7158</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07323-1\">Stability and admissibility analysis of T\u2013S descriptive systems and its applications</a></div><div><b>Author(s):&nbsp;</b>Muhammad Shamrooz Aslam, Ma Zhenhua...Abdul Majid</div><div><b>Pages:&nbsp;</b>7159 - 7166</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07190-w\">Quantum-enhanced filter: QFilter</a></div><div><b>Author(s):&nbsp;</b>Parfait Atchade-Adelomou, Guillermo Alonso-Linaje</div><div><b>Pages:&nbsp;</b>7167 - 7174</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07194-6\">Estimation of fault probability in medium voltage feeders through calibration techniques in classification models</a></div><div><b>Author(s):&nbsp;</b>Enrico De Santis, Francesco Arn\u00f2, Antonello Rizzi</div><div><b>Pages:&nbsp;</b>7175 - 7193</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07105-9\">Deep multiobjective design optimization of CFRP isogrid tubes using lichtenberg algorithm</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o Luiz Junho Pereira, Matheus Brendon Francisco...Guilherme Ferreira Gomes</div><div><b>Pages:&nbsp;</b>7195 - 7209</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07107-7\">An effective structure of multi-modal deep convolutional neural network with adaptive group teaching optimization</a></div><div><b>Author(s):&nbsp;</b>Vinit Gupta, Santosh Pawar</div><div><b>Pages:&nbsp;</b>7211 - 7232</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07109-5\">An enhanced Harris Hawk optimization algorithm for parameter estimation of single, double and triple diode photovoltaic models</a></div><div><b>Author(s):&nbsp;</b>Abdelhady Ramadan, Salah Kamel...Jose Luis Dom\u00ednguez-Garc\u00eda</div><div><b>Pages:&nbsp;</b>7233 - 7257</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07112-w\">A preference structure in multi-attribute decision making: an algorithmic approach based on hesitant fuzzy sets</a></div><div><b>Author(s):&nbsp;</b>B. K. Mohanty, Eshika Aggarwal</div><div><b>Pages:&nbsp;</b>7259 - 7277</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07124-6\">Optimal autonomic management of service-based business processes in the cloud</a></div><div><b>Author(s):&nbsp;</b>Leila Hadded, Tarek Hamrouni</div><div><b>Pages:&nbsp;</b>7279 - 7291</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07139-z\">A novel hybrid gravitational and pattern search algorithm based MPPT controller with ANN and perturb and observe for photovoltaic system</a></div><div><b>Author(s):&nbsp;</b>Salem Alkhalaf, Ziad M. AliHitoshi Oikawa</div><div><b>Pages:&nbsp;</b>7293 - 7315</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06941-z\">Modeling stock market using new hybrid intelligent method based on MFNN and IBHA</a></div><div><b>Author(s):&nbsp;</b>Wei Gao</div><div><b>Pages:&nbsp;</b>7317 - 7337</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06964-6\">Evaluating and selecting agricultural insurance packages through an AHP-based fuzzy TOPSIS Method</a></div><div><b>Author(s):&nbsp;</b>Ta-Chung Chu, Thi Hong Phuong Le</div><div><b>Pages:&nbsp;</b>7339 - 7354</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07027-6\">Inclusion degree-based multigranulation rough fuzzy set over heterogeneous preference information and application to multiple attribute group decision making</a></div><div><b>Author(s):&nbsp;</b>Xinrui Zhang, Bingzhen Sun</div><div><b>Pages:&nbsp;</b>7355 - 7375</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07299-y\">Research on safety simulation model and algorithm of dynamic system based on artificial neural network</a></div><div><b>Author(s):&nbsp;</b>Guangna Zhang</div><div><b>Pages:&nbsp;</b>7377 - 7386</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07300-8\">Mobile robot path planning using multi-objective genetic algorithm in industrial automation</a></div><div><b>Author(s):&nbsp;</b>K. S. Suresh, R. Venkatesan, S. Venugopal</div><div><b>Pages:&nbsp;</b>7387 - 7400</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06677-2\">Toward in-flight Wi-Fi: a neuro-fuzzy based routing approach for Civil Aeronautical Ad hoc Network</a></div><div><b>Author(s):&nbsp;</b>T. Gurumekala, S. Indira Gandhi</div><div><b>Pages:&nbsp;</b>7401 - 7422</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06688-z\">CoupGAN: Chinese couplet generation via encoder\u2013decoder model and adversarial training under global control</a></div><div><b>Author(s):&nbsp;</b>Qian Qu, Jiancheng Lv...Kexin Yang</div><div><b>Pages:&nbsp;</b>7423 - 7433</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-07-14T10:56:00.001+12:00",
            "pubdate_parsed": [
                2022,
                7,
                13
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 16, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/soft-computing-volume-26-issue-16.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07213-6\">Special issue on advances in pattern recognition and computer vision, applications and systems</a></div><div><b>Author(s): </b>M. Irfan Uddin</div><div><b>Pages: </b>7435 - 7436</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06439-0\">Analysis of industry convergence based on improved neural network</a></div><div><b>Author(s):&nbsp;</b>Nan Ma</div><div><b>Pages:&nbsp;</b>7437 - 7448</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06449-y\">Nucleus image segmentation method based on GAN and FCN model</a></div><div><b>Author(s):&nbsp;</b>Kai Zhang, Yang Shi...Hang Yu</div><div><b>Pages:&nbsp;</b>7449 - 7460</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06459-w\">A new color image encryption technique using DNA computing and Chaos-based substitution box</a></div><div><b>Author(s):&nbsp;</b>Fawad Masood, Junaid Masood...Jawad Ahmad</div><div><b>Pages:&nbsp;</b>7461 - 7477</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06465-y\">An evolutionary trajectory planning algorithm for multi-UAV-assisted MEC system</a></div><div><b>Author(s):&nbsp;</b>Muhammad Asim, Wali Khan Mashwani...Samir Brahim Belhaouari</div><div><b>Pages:&nbsp;</b>7479 - 7492</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06478-7\">Research on modeling of government debt risk comprehensive evaluation based on multidimensional data mining</a></div><div><b>Author(s):&nbsp;</b>Li Chao Ying, Wu Xiang Da, Zhao En Hui</div><div><b>Pages:&nbsp;</b>7493 - 7500</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06479-6\">Research on trade data encryption of tobacco enterprises based on adversarial neural network</a></div><div><b>Author(s):&nbsp;</b>Zhang Yi</div><div><b>Pages:&nbsp;</b>7501 - 7508</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06480-z\">Research on intelligent language translation system based on deep learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Chunliu Shi</div><div><b>Pages:&nbsp;</b>7509 - 7518</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06519-1\">Analyzing fibrous tissue pattern in fibrous dysplasia bone images using deep R-CNN networks for segmentation</a></div><div><b>Author(s):&nbsp;</b>A. Saranya, Kottilingam Kottursamy...Ali Kashif Bashir</div><div><b>Pages:&nbsp;</b>7519 - 7533</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06569-5\">Deep learning-based election results prediction using Twitter activity</a></div><div><b>Author(s):&nbsp;</b>Haider Ali, Haleem Farman...Adel Ammar</div><div><b>Pages:&nbsp;</b>7535 - 7543</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06581-9\">Q-method optimization of tunnel surrounding rock classification by fuzzy reasoning model and support vector machine</a></div><div><b>Author(s):&nbsp;</b>Feng Jiang, Peng He...Zhihan Lv</div><div><b>Pages:&nbsp;</b>7545 - 7558</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06585-5\">Analysis of the change of artificial intelligence to online consumption patterns and consumption concepts</a></div><div><b>Author(s):&nbsp;</b>Longyue Bai</div><div><b>Pages:&nbsp;</b>7559 - 7569</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06587-3\">Sparse representation optimization of Gaussian mixed feature of image based on convolution neural network</a></div><div><b>Author(s):&nbsp;</b>Yuguang Ye</div><div><b>Pages:&nbsp;</b>7571 - 7580</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06603-6\">Task-specific image summaries using semantic information and self-supervision</a></div><div><b>Author(s):&nbsp;</b>Deepak Kumar Sharma, Anurag Singh...Jerry Chun-Wei Lin</div><div><b>Pages:&nbsp;</b>7581 - 7594</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06612-5\">The study on life model of MOV based on various parameters and surge history</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Ruan, Shaoyun Jin...Weidong Cheng</div><div><b>Pages:&nbsp;</b>7595 - 7600</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06662-9\">Deep ensembling for perceptual image quality assessment</a></div><div><b>Author(s):&nbsp;</b>Nisar Ahmed, H. M. Shahzad Asif...Atif Khan</div><div><b>Pages:&nbsp;</b>7601 - 7622</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06705-1\">ConTEXT: context-aware adaptive SMS client for drivers to reduce risky driving behaviors</a></div><div><b>Author(s):&nbsp;</b>Inayat Khan, Shah Khusro</div><div><b>Pages:&nbsp;</b>7623 - 7640</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06706-0\">Design of robust deep learning-based object detection and classification model for autonomous driving applications</a></div><div><b>Author(s):&nbsp;</b>Mesfer Al Duhayyim, Fahd N. Al-Wesabi...Ashish Khanna</div><div><b>Pages:&nbsp;</b>7641 - 7652</div><div><br /></div><div><b>19) </b><a href=\"https://link.springer.com/article/10.1007/s00500-021-06707-z\">Gene Ontology GAN (GOGAN): a novel architecture for protein function prediction</a></div><div><b>Author(s):&nbsp;</b>Musadaq Mansoor, Mohammad Nauman...Alfredo Benso</div><div><b>Pages:&nbsp;</b>7653 - 7667</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06715-z\">The control mode study of PPP project financing management information system</a></div><div><b>Author(s):&nbsp;</b>Junli Cao, Lin Li</div><div><b>Pages:&nbsp;</b>7669 - 7675</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06869-4\">Correction to: The control mode study of PPP project financing management information system</a></div><div><b>Author(s):&nbsp;</b>Junli Cao, Lin Li</div><div><b>Pages:&nbsp;</b>7677 - 7677</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06734-4\">A comprehensive overview of AI-enabled music classification and its influence in games</a></div><div><b>Author(s):&nbsp;</b>Tiancheng Yang, Shah Nazir</div><div><b>Pages:&nbsp;</b>7679 - 7693</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06739-z\">Classification of Gurumukhi month\u2019s name images using various convolutional neural network optimizers</a></div><div><b>Author(s):&nbsp;</b>Tajinder Pal Singh, Sheifali Gupta...Atef Zaguia</div><div><b>Pages:&nbsp;</b>7695 - 7707</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06742-4\">Novel semi-supervised learning approach for descriptor generation using artificial neural networks</a></div><div><b>Author(s):&nbsp;</b>Alla Fikrat Alwindawi, Osman Nuri U\u00e7an...Aminu Yusuf</div><div><b>Pages:&nbsp;</b>7709 - 7720</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06750-4\">Hybrid deep-learning model to detect botnet attacks over internet of things environments</a></div><div><b>Author(s):&nbsp;</b>Mohammed Y. Alzahrani, Alwi M. Bamhdi</div><div><b>Pages:&nbsp;</b>7721 - 7735</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06755-z\">Machine health surveillance system by using deep learning sparse autoencoder</a></div><div><b>Author(s):&nbsp;</b>Faizan Ullah, Abdu Salam...Wael Alosaimi</div><div><b>Pages:&nbsp;</b>7737 - 7750</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06762-0\">Diagnosis and classification of Alzheimer's disease by using a convolution neural network algorithm</a></div><div><b>Author(s):&nbsp;</b>Mosleh Hmoud Al-Adhaileh</div><div><b>Pages:&nbsp;</b>7751 - 7762</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06773-x\">Machine learning for fake news classification with optimal feature selection</a></div><div><b>Author(s):&nbsp;</b>Muhammad Fayaz, Atif Khan...Sana Ullah Khan</div><div><b>Pages:&nbsp;</b>7763 - 7771</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06775-9\">Application and Analysis of Computer Network Technology in Electronic Information Engineering</a></div><div><b>Author(s):&nbsp;</b>Wanjie Kang, Jie Xiao</div><div><b>Pages:&nbsp;</b>7773 - 7779</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06781-x\">Research and application of GIS and data mining technology in monitoring and assessment of natural geography environment</a></div><div><b>Author(s):&nbsp;</b>Fuheng Zhang, Guangbin Ji...Guihua Liu</div><div><b>Pages:&nbsp;</b>7781 - 7787</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06794-6\">Extracting built-up areas from spectro-textural information using machine learning</a></div><div><b>Author(s):&nbsp;</b>Ahsen Maqsoom, Bilal Aslam...Muhammad Imran</div><div><b>Pages:&nbsp;</b>7789 - 7808</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06796-4\">The traditional settlement planning and the renovation of residential buildings based on spatial syntax analysis</a></div><div><b>Author(s):&nbsp;</b>Kaifeng Chu, Mengyu Wu</div><div><b>Pages:&nbsp;</b>7809 - 7815</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06804-7\">Efficient facial emotion recognition model using deep convolutional neural network and modified joint trilateral filter</a></div><div><b>Author(s):&nbsp;</b>Naveen Kumari, Rekha Bhatia</div><div><b>Pages:&nbsp;</b>7817 - 7830</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06805-6\">Convolutional neural network based hurricane damage detection using satellite images</a></div><div><b>Author(s):&nbsp;</b>Swapandeep Kaur, Sheifali Gupta...Atef Zaguia</div><div><b>Pages:&nbsp;</b>7831 - 7845</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06806-5\">Fake opinion detection in an e-commerce business based on a long-short memory algorithm</a></div><div><b>Author(s):&nbsp;</b>Nizar Alsharif</div><div><b>Pages:&nbsp;</b>7847 - 7854</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06811-8\">Visual design elements based on digital visualization</a></div><div><b>Author(s):&nbsp;</b>Lei Jiang</div><div><b>Pages:&nbsp;</b>7855 - 7863</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06812-7\">Analysis of transmission line icing prediction based on CNN and data mining technology</a></div><div><b>Author(s):&nbsp;</b>Lixue Li, Da Luo, Wenhao Yao</div><div><b>Pages:&nbsp;</b>7865 - 7870</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06813-6\">Computer application under the management of network information security technology using genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xu Jian Qiang</div><div><b>Pages:&nbsp;</b>7871 - 7876</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06830-5\">Software defect prediction employing BiLSTM and BERT-based semantic feature</a></div><div><b>Author(s):&nbsp;</b>Md Nasir Uddin, Bixin Li...Islam Zada</div><div><b>Pages:&nbsp;</b>7877 - 7891</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06845-y\">An effective nonlocal means image denoising framework based on non-subsampled shearlet transform</a></div><div><b>Author(s):&nbsp;</b>Bhawna Goyal, Ayush Dogra, Arun Kumar Sangaiah</div><div><b>Pages:&nbsp;</b>7893 - 7915</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06849-8\">The study of physical education evaluation based on a fuzzy stochastic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xiuyan Su</div><div><b>Pages:&nbsp;</b>7917 - 7923</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06851-0\">Conceptual model construction of building information management system based on BIM architecture</a></div><div><b>Author(s):&nbsp;</b>Jiang Haiying</div><div><b>Pages:&nbsp;</b>7925 - 7931</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06853-y\">Perceptual adversarial non-residual learning for blind image denoising</a></div><div><b>Author(s):&nbsp;</b>Aamir Khan, Weidong Jin, Rizwan Ali Naqvi</div><div><b>Pages:&nbsp;</b>7933 - 7957</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06855-w\">Research on the optimization of communication protocol in network security protocol</a></div><div><b>Author(s):&nbsp;</b>Daoyuan Sun</div><div><b>Pages:&nbsp;</b>7959 - 7966</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06859-6\">Multi-scale local-global architecture for person re-identification</a></div><div><b>Author(s):&nbsp;</b>Jing Liu, Prayag Tiwari...Shahab S. Band</div><div><b>Pages:&nbsp;</b>7967 - 7977</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06900-8\">Optimal feature extraction and ulcer classification from WCE image data using deep learning</a></div><div><b>Author(s):&nbsp;</b>Youssef Masmoudi, Muhammad Ramzan...Mohammed Habib</div><div><b>Pages:&nbsp;</b>7979 - 7992</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06901-7\">A communication security anti-interference decision model using deep learning in intelligent industrial IoT environment</a></div><div><b>Author(s):&nbsp;</b>Lichao Yan, Juan Hu...Jinhong Di</div><div><b>Pages:&nbsp;</b>7993 - 8002</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06990-4\">Smoke removal and image enhancement of laparoscopic images by an artificial multi-exposure image fusion method</a></div><div><b>Author(s):&nbsp;</b>Muhammad Adeel Azam, Khan Bahadar Khan...Sana Ullah Khan</div><div><b>Pages:&nbsp;</b>8003 - 8015</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06996-y\">Predicting the spread of COVID-19 with a machine learning technique and multiplicative calculus</a></div><div><b>Author(s):&nbsp;</b>B\u00fclent Bilgehan, Ali \u00d6zyap\u0131c\u0131...Yusuf Gurefe</div><div><b>Pages:&nbsp;</b>8017 - 8024</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07047-2\">Fusion of multi-modality biomedical images using deep neural networks</a></div><div><b>Author(s):&nbsp;</b>Manish Gupta, Naresh Kumar...Atef Zaguia</div><div><b>Pages:&nbsp;</b>8025 - 8036</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07058-z\">Rotating object detection in remote-sensing environment</a></div><div><b>Author(s):&nbsp;</b>Sixian Chan, Jingcheng Zheng...Kai Fang</div><div><b>Pages:&nbsp;</b>8037 - 8045</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07062-3\">Analyzing the interactions among factors affecting cloud adoption for software testing: a two-stage ISM-ANN approach</a></div><div><b>Author(s):&nbsp;</b>Sikandar Ali, Samad Baseer...Jiwei Huang</div><div><b>Pages:&nbsp;</b>8047 - 8075</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07064-1\">A probabilistic approach toward evaluation of Internet rumor on COVID</a></div><div><b>Author(s):&nbsp;</b>Yancheng Yang, Shah Nazir, Wajeeha Khalil</div><div><b>Pages:&nbsp;</b>8077 - 8088</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07142-4\">Single-image reconstruction using novel super-resolution technique for large-scaled images</a></div><div><b>Author(s):&nbsp;</b>Ramanath Datta, Sekhar Mandal...Jazem Mutared Alanazi</div><div><b>Pages:&nbsp;</b>8089 - 8103</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07155-z\">Hybrid optimisation-based robust watermarking using denoising convolutional neural network</a></div><div><b>Author(s):&nbsp;</b>Dhiran Kumar Mahto, Ashima Anand, Amit Kumar Singh</div><div><b>Pages:&nbsp;</b>8105 - 8116</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07169-7\">Constrained optimization based on hybrid version of superiority of feasibility solution strategy</a></div><div><b>Author(s):&nbsp;</b>Asia Noureen, Wali Khan Mashwani...Muhammad Asim</div><div><b>Pages:&nbsp;</b>8117 - 8132</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07204-7\">An adaptive genetic algorithm-based background elimination model for English text</a></div><div><b>Author(s):&nbsp;</b>Tang Xiaohui</div><div><b>Pages:&nbsp;</b>8133 - 8143</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-07-18T12:16:00.000+12:00",
            "pubdate_parsed": [
                2022,
                7,
                18
            ],
            "email_sent": true
        },
        "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 7, July 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-neural-networks.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9311226/\">The Heidelberg Spiking Data Sets for the Systematic Evaluation of Spiking Neural Networks</a></div><div><b>Author(s): </b>Benjamin Cramer, Yannik Stradmann, Johannes Schemmel, Friedemann Zenke</div><div><b>Pages: </b>2744 - 2757</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9312438/\">Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding</a></div><div><b>Author(s):&nbsp;</b>Qingxing Cao, Bailin Li, Xiaodan Liang, Keze Wang, Liang Lin</div><div><b>Pages:&nbsp;</b>2758 - 2767</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9311244/\">Stabilizing Training of Generative Adversarial Nets via Langevin Stein Variational Gradient Descent</a></div><div><b>Author(s):&nbsp;</b>Dong Wang, Xiaoqian Qin, Fengyi Song, Li Cheng</div><div><b>Pages:&nbsp;</b>2768 - 2780</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9316912/\">Reinforcement Learning and Adaptive Optimal Control for Continuous-Time Nonlinear Systems: A Value Iteration Approach</a></div><div><b>Author(s):&nbsp;</b>Tao Bian, Zhong-Ping Jiang</div><div><b>Pages:&nbsp;</b>2781 - 2790</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9314928/\">Parameterized Luenberger-Type H\u221e State Estimator for Delayed Static Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Yongsik Jin, Wookyong Kwon, Sangmoon Lee</div><div><b>Pages:&nbsp;</b>2791 - 2800</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9319553/\">BiCoSS: Toward Large-Scale Cognition Brain With Multigranular Neuromorphic Architecture</a></div><div><b>Author(s):&nbsp;</b>Shuangming Yang, Jiang Wang, Xinyu Hao, Huiyan Li, Xile Wei, Bin Deng, Kenneth A. Loparo</div><div><b>Pages:&nbsp;</b>2801 - 2815</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9317707/\">Causal Discovery in Linear Non-Gaussian Acyclic Model With Multiple Latent Confounders</a></div><div><b>Author(s):&nbsp;</b>Wei Chen, Ruichu Cai, Kun Zhang, Zhifeng Hao</div><div><b>Pages:&nbsp;</b>2816 - 2827</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9319566/\">A Study on Truncated Newton Methods for Linear Classification</a></div><div><b>Author(s):&nbsp;</b>Leonardo Galli, Chih-Jen Lin</div><div><b>Pages:&nbsp;</b>2828 - 2841</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9324979/\">Agglomerative Neural Networks for Multiview Clustering</a></div><div><b>Author(s):&nbsp;</b>Zhe Liu, Yun Li, Lina Yao, Xianzhi Wang, Feiping Nie</div><div><b>Pages:&nbsp;</b>2842 - 2852</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9321210/\">Low-Latency <i>In Situ</i> Image Analytics With FPGA-Based Quantized Convolutional Neural Network</a></div><div><b>Author(s):&nbsp;</b>Maolin Wang, Kelvin C. M. Lee, Bob M. F. Chung, Sharatchandra Varma Bogaraju, Ho-Cheung Ng, Justin S. J. Wong, Ho Cheung Shum, Kevin K. Tsia, Hayden Kwok-Hay So</div><div><b>Pages:&nbsp;</b>2853 - 2866</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9325083/\">Adaptive Optimal Control for Unknown Constrained Nonlinear Systems With a Novel Quasi-Model Network</a></div><div><b>Author(s):&nbsp;</b>Xiumei Han, Xudong Zhao, Hamid Reza Karimi, Ding Wang, Guangdeng Zong</div><div><b>Pages:&nbsp;</b>2867 - 2878</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9316921/\">A Hybrid Residual Dilated LSTM and Exponential Smoothing Model for Midterm Electric Load Forecasting</a></div><div><b>Author(s):&nbsp;</b>Grzegorz Dudek, Pawe\u0142 Pe\u0142ka, Slawek Smyl</div><div><b>Pages:&nbsp;</b>2879 - 2891</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9344620/\">Observer-Based Fixed-Time Neural Control for a Class of Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Yan Zhang, Fang Wang</div><div><b>Pages:&nbsp;</b>2892 - 2902</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9335504/\">Generalized Zero-Shot Learning With Multiple Graph Adaptive Generative Networks</a></div><div><b>Author(s):&nbsp;</b>Guo-Sen Xie, Zheng Zhang, Guoshuai Liu, Fan Zhu, Li Liu, Ling Shao, Xuelong Li</div><div><b>Pages:&nbsp;</b>2903 - 2915</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9319541/\">mCRF and mRD: Two Classification Methods Based on a Novel Multiclass Label Noise Filtering Learning Framework</a></div><div><b>Author(s):&nbsp;</b>Shuyin Xia, Baiyun Chen, Guoyin Wang, Yong Zheng, Xinbo Gao, Elisabeth Giem, Zizhong Chen</div><div><b>Pages:&nbsp;</b>2916 - 2930</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9325091/\">Observer Design for Sampled-Data Systems via Deterministic Learning</a></div><div><b>Author(s):&nbsp;</b>Jingtao Hu, Weiming Wu, Bing Ji, Cong Wang</div><div><b>Pages:&nbsp;</b>2931 - 2939</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9324926/\">Dynamically Weighted Balanced Loss: Class Imbalanced Learning and Confidence Calibration of Deep Neural Networks</a></div><div><b>Author(s):&nbsp;</b>K. Ruwani M. Fernando, Chris P. Tsokos</div><div><b>Pages:&nbsp;</b>2940 - 2951</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9328160/\">Broad Learning With Reinforcement Learning Signal Feedback: Theory and Applications</a></div><div><b>Author(s):&nbsp;</b>Ruiqi Mao, Rongxin Cui, C. L. Philip Chen</div><div><b>Pages:&nbsp;</b>2952 - 2964</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9324947/\">Neural-Network-Based Distributed Asynchronous Event-Triggered Consensus Tracking of a Class of Uncertain Nonlinear Multi-Agent Systems</a></div><div><b>Author(s):&nbsp;</b>Yun Ho Choi, Sung Jin Yoo</div><div><b>Pages:&nbsp;</b>2965 - 2979</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9325069/\">Active Learning With Multiple Kernels</a></div><div><b>Author(s):&nbsp;</b>Songnam Hong, Jeongmin Chae</div><div><b>Pages:&nbsp;</b>2980 - 2994</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9325927/\">Dissipativity-Based Finite-Time Filtering for Uncertain Semi-Markovian Jump Random Systems With Multiple Time Delays and State Constraints</a></div><div><b>Author(s):&nbsp;</b>Shaoxin Sun, Huaguang Zhang, Jian Han, Juan Zhang</div><div><b>Pages:&nbsp;</b>2995 - 3009</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9325537/\">PID Controller-Guided Attention Neural Network Learning for Fast and Effective Real Photographs Denoising</a></div><div><b>Author(s):&nbsp;</b>Ruijun Ma, Bob Zhang, Yicong Zhou, Zhengming Li, Fangyuan Lei</div><div><b>Pages:&nbsp;</b>3010 - 3023</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9325549/\">A Novel Feature Selection Method for High-Dimensional Mixed Decision Tables</a></div><div><b>Author(s):&nbsp;</b>Nguyen Ngoc Thuy, Sartra Wongthanavasu</div><div><b>Pages:&nbsp;</b>3024 - 3037</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9325918/\">Spatio-Spectral Feature Representation for Motor Imagery Classification Using Convolutional Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Ji-Seon Bang, Min-Ho Lee, Siamac Fazli, Cuntai Guan, Seong-Whan Lee</div><div><b>Pages:&nbsp;</b>3038 - 3049</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9366422/\">MetaMixUp: Learning Adaptive Interpolation Policy of MixUp With Metalearning</a></div><div><b>Author(s):&nbsp;</b>Zhijun Mai, Guosheng Hu, Dexiong Chen, Fumin Shen, Heng Tao Shen</div><div><b>Pages:&nbsp;</b>3050 - 3064</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9334415/\">An Efficient Sparse Bayesian Learning Algorithm Based on Gaussian-Scale Mixtures</a></div><div><b>Author(s):&nbsp;</b>Wei Zhou, Hai-Tao Zhang, Jun Wang</div><div><b>Pages:&nbsp;</b>3065 - 3078</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9340559/\">Efficient Approximation of High-Dimensional Functions With Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Patrick Cheridito, Arnulf Jentzen, Florian Rossmannek</div><div><b>Pages:&nbsp;</b>3079 - 3093</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9337198/\">Synaptic Scaling\u2014An Artificial Neural Network Regularization Inspired by Nature</a></div><div><b>Author(s):&nbsp;</b>Martin Hofmann, Patrick M\u00e4der</div><div><b>Pages:&nbsp;</b>3094 - 3108</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9340575/\">Observer-Based Adaptive Synchronization of Multiagent Systems With Unknown Parameters Under Attacks</a></div><div><b>Author(s):&nbsp;</b>Shiping Wen, Xiaoze Ni, Huamin Wang, Song Zhu, Kaibo Shi, Tingwen Huang</div><div><b>Pages:&nbsp;</b>3109 - 3119</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9336287/\">Explicit Duration Recurrent Networks</a></div><div><b>Author(s):&nbsp;</b>Shun-Zheng Yu</div><div><b>Pages:&nbsp;</b>3120 - 3130</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9336267/\">Observer-Based Neuro-Adaptive Optimized Control of Strict-Feedback Nonlinear Systems With State Constraints</a></div><div><b>Author(s):&nbsp;</b>Yongming Li, Yanjun Liu, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>3131 - 3145</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9494037/\">Granger Causality Inference in EEG Source Connectivity Analysis: A State-Space Approach</a></div><div><b>Author(s):&nbsp;</b>Parinthorn Manomaisaowapak, Anawat Nartkulpat, Jitkomut Songsiri</div><div><b>Pages:&nbsp;</b>3146 - 3156</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9410428/\">Rank Consistency Induced Multiview Subspace Clustering via Low-Rank Matrix Factorization</a></div><div><b>Author(s):&nbsp;</b>Jipeng Guo, Yanfeng Sun, Junbin Gao, Yongli Hu, Baocai Yin</div><div><b>Pages:&nbsp;</b>3157 - 3170</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9316932/\">Data-Driven-Based Event-Triggered Control for Nonlinear CPSs Against Jamming Attacks</a></div><div><b>Author(s):&nbsp;</b>Yingchun Wang, Xiaojie Qiu, Huaguang Zhang, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3171 - 3177</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9333591/\">Sequence Learning in a Single Trial: A Spiking Neurons Model Based on Hippocampal Circuitry</a></div><div><b>Author(s):&nbsp;</b>Simone Coppolino, Giuseppe Giacopelli, Michele Migliore</div><div><b>Pages:&nbsp;</b>3178 - 3183</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9340604/\">DNN-kWTA With Bounded Random Offset Voltage Drifts in Threshold Logic Units</a></div><div><b>Author(s):&nbsp;</b>Wenhao Lu, Chi-Sing Leung, John Sum, Yi Xiao</div><div><b>Pages:&nbsp;</b>3184 - 3192</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-07-20T15:09:00.000+12:00",
            "pubdate_parsed": [
                2022,
                7,
                20
            ],
            "email_sent": true
        },
        "Upcoming Special Issues": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/upcoming-special-issues.html",
            "description": "<div style=\"text-align: left;\"><div style=\"text-align: left;\"><ul style=\"text-align: left;\"><li><b>IEEE Computational Intelligence Magazine</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/cim/CIM-SI-MLEMO_CFP.pdf\">Machine Learning Assisted Evolutionary Multi-Objective Optimization</a> - <u>September 1, 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/TNNLS_SI_CFP.pdf\">Explainable and Generalizable Deep Learning for Medical Imaging</a> -&nbsp;<u>1 September 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/202202-Explainable_Representation_Learning-based_Intelligent_Inspection_and_Maintenance_of_Complex_Systems.pdf\">Explainable Representation Learning-based Intelligent Inspection and Maintenance of Complex Systems</a> -&nbsp;<u>1 September 2022</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Cognitive_Learning_of_Multi-Agent_Systems-IEEE_TCDS-CFP-20211210.pdf\">Cognitive Learning of Multi-Agent Systems</a> -&nbsp;<u>September 30, 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Publications/TNNLS/special-issues/proposal_TNNLS_2.27_new.pdf\">Information Theoretic Methods for the Generalization, Robustness and Interpretability of Machine Learning</a> -&nbsp;<u>1 October 2022</u></li><li><b>IEEE Transactions on Neural Networks and Learning Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-papers/tnnls/New_SI.pdf\">Deep Learning for Intelligent Media Computing and Applications</a> -&nbsp;<u>30 October 2022</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Movement_Sciences_in_Cognitive_Systems_CFP_2022.pdf\">Movement Sciences in Cognitive Systems</a> -&nbsp;<u>6 January 2023</u></li><li><b>IEEE Transactions on Cognitive and Developmental Systems</b> - <a href=\"https://cis.ieee.org/images/files/Documents/call-for-special-issues/Advancing_Machine_Intelligence_with_Neuromorphic_Computing-CFP2022.pdf\">Advancing Machine Intelligence with Neuromorphic Computing</a> -&nbsp;<u>31 January 2023</u></li><li><b>IEEE Transactions on Emerging Topics in Computational Intelligence</b> - <a href=\"https://cis.ieee.org/images/files/Publications/TETCI/SI26_CFP_RSCAI.pdf\">Resource Sustainable Computational and Artificial Intelligence</a> -&nbsp;<u>1 February 2023</u></li></ul></div><div><br /></div></div>",
            "pubdate": "2022-07-21T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                7,
                21
            ],
            "email_sent": true
        },
        "IEEE Transactions on Emerging Topics in Computational Intelligence, Volume 6, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-emerging-topics-in.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9834992/\">Guest Editorial Special Issue on Computational Intelligence for IoT-based Human Activity Recognition</a></div><div><b>Author(s): </b>Xiaoli Li, Huanhuan Chen, Thomas Ploetz, Min Wu, Zhenghua Chen</div><div><b>Pages: </b>725 - 727</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9546996/\">Evolutionary Dual-Ensemble Class Imbalance Learning for Human Activity Recognition</a></div><div><b>Author(s):&nbsp;</b>Yinan Guo, Yaoqi Chu, Botao Jiao, Jian Cheng, Zekuan Yu, Ning Cui, Lianbo Ma</div><div><b>Pages:&nbsp;</b>728 - 739</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9720134/\">Real-Time Activities of Daily Living Recognition Under Long-Tailed Class Distribution</a></div><div><b>Author(s):&nbsp;</b>Atul Chaudhary, Hari Prabhat Gupta, K. K. Shukla</div><div><b>Pages:&nbsp;</b>740 - 750</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9724169/\">MOCLoc: Emerging Online Collaborative Localization Enhanced by Multidimensional Scaling</a></div><div><b>Author(s):&nbsp;</b>Chanxin Zhou, Bang Wang, Yijun Mo, Zeng Zeng</div><div><b>Pages:&nbsp;</b>751 - 761</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9779097/\">Trends and Prospects of Techniques for Haze Removal From Degraded Images: A Survey</a></div><div><b>Author(s):&nbsp;</b>Geet Sahu, Ayan Seal, Debotosh Bhattacharjee, Mita Nasipuri, Peter Brida, Ondrej Krejcar</div><div><b>Pages:&nbsp;</b>762 - 782</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9686068/\">Evolutionary Architectural Search for Generative Adversarial Networks</a></div><div><b>Author(s):&nbsp;</b>Qiuzhen Lin, Zhixiong Fang, Yi Chen, Kay Chen Tan, Yun Li</div><div><b>Pages:&nbsp;</b>783 - 794</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9600838/\">Generating Black-Box Adversarial Examples in Sparse Domain</a></div><div><b>Author(s):&nbsp;</b>Hadi Zanddizari, Behnam Zeinali, J. Morris Chang</div><div><b>Pages:&nbsp;</b>795 - 804</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9472875/\">A Novel Evolutionary Algorithm Based on Judgment-Rule Evolution Strategy for Structural Balance in Signed Social Networks</a></div><div><b>Author(s):&nbsp;</b>Mingzhou Yang, Xingwei Wang, Min Huang, Lianbo Ma, Qiang He</div><div><b>Pages:&nbsp;</b>805 - 817</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9582815/\">Multiobjective Multitasking Optimization With Subspace Distribution Alignment and Decision Variable Transfer</a></div><div><b>Author(s):&nbsp;</b>Weifeng Gao, Jiangli Cheng, Maoguo Gong, Hong Li, Jin Xie</div><div><b>Pages:&nbsp;</b>818 - 827</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9564251/\">Transfer Clustering Using a Multiple Kernel Metric Learned Under Multi-Instance Weak Supervision</a></div><div><b>Author(s):&nbsp;</b>Avisek Gupta, Swagatam Das</div><div><b>Pages:&nbsp;</b>828 - 838</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9615029/\">Dynamic Path Planning for Unmanned Aerial Vehicles Under Deadline and Sector Capacity Constraints</a></div><div><b>Author(s):&nbsp;</b>Sudharsan Vaidhun, Zhishan Guo, Jiang Bian, Haoyi Xiong, Sajal K. Das</div><div><b>Pages:&nbsp;</b>839 - 851</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9586052/\">A Robust Non-Integer Controller Design for Load Frequency Control in Modern Marine Power Grids</a></div><div><b>Author(s):&nbsp;</b>B. Yildirim, M. Gheisarnejad, M. H. Khooban</div><div><b>Pages:&nbsp;</b>852 - 866</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9586057/\">A Weighted Portfolio Optimization Model Based on the Trend Ratio, Emotion Index, and ANGQTS</a></div><div><b>Author(s):&nbsp;</b>Yao-Hsin Chou, Yu-Chi Jiang, Yi-Rui Hsu, Shu-Yu Kuo, Sy-Yen Kuo</div><div><b>Pages:&nbsp;</b>867 - 882</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9671053/\">Do Models Learn the Directionality of Relations? A New Evaluation: Relation Direction Recognition</a></div><div><b>Author(s):&nbsp;</b>Shengfei Lyu, Xingyu Wu, Jinlong Li, Qiuju Chen, Huanhuan Chen</div><div><b>Pages:&nbsp;</b>883 - 892</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9628017/\">Quaternion Capsule Neural Network With Region Attention for Facial Expression Recognition in Color Images</a></div><div><b>Author(s):&nbsp;</b>Yu Zhou, Lianghai Jin, Guangzhi Ma, Xiangyang Xu</div><div><b>Pages:&nbsp;</b>893 - 912</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9475074/\">Unbalanced Incomplete Multi-View Clustering Via the Scheme of View Evolution: Weak Views are Meat,&nbsp; Strong Views Do Eat</a></div><div><b>Author(s):&nbsp;</b>Xiang Fang, Yuchong Hu, Pan Zhou, Dapeng Oliver Wu</div><div><b>Pages:&nbsp;</b>913 - 927</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9655256/\">EDITH : ECG Biometrics Aided by Deep Learning for Reliable Individual Authentication</a></div><div><b>Author(s):&nbsp;</b>Nabil Ibtehaz, Muhammad E. H. Chowdhury, Amith Khandakar, Serkan Kiranyaz, M. Sohel Rahman, Anas Tahir, Yazan Qiblawey, Tawsifur Rahman</div><div><b>Pages:&nbsp;</b>928 - 940</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9576096/\">Efficient Privacy Preserving Edge Intelligent Computing Framework for Image Classification in IoT</a></div><div><b>Author(s):&nbsp;</b>Omobayode Fagbohungbe, Sheikh Rufsan Reza, Xishuang Dong, Lijun Qian</div><div><b>Pages:&nbsp;</b>941 - 956</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9583676/\">APNet: Adversarial Learning Assistance and Perceived Importance Fusion Network for All-Day RGB-T Salient Object Detection</a></div><div><b>Author(s):&nbsp;</b>Wujie Zhou, Yun Zhu, Jingsheng Lei, Jian Wan, Lu Yu</div><div><b>Pages:&nbsp;</b>957 - 968</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9615378/\">A Novel Test Case Generation Approach for Adaptive Random Testing of Object-Oriented Software Using K-Means Clustering Technique</a></div><div><b>Author(s):&nbsp;</b>Jinfu Chen, Haibo Chen, Yuchi Guo, Minmin Zhou, Rubing Huang, Chengying Mao</div><div><b>Pages:&nbsp;</b>969 - 981</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9772749/\">Data Embedding Scheme for Efficient Program Behavior Modeling With Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Sunwoo Ahn, Hayoon Yi, Ho Bae, Sungroh Yoon, Yunheung Paek</div><div><b>Pages:&nbsp;</b>982 - 993</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9704877/\">Half Quadratic Dual Learning for Fuzzy Multiconcepts of Partially-Observed Images</a></div><div><b>Author(s):&nbsp;</b>Bo-Wei Chen, Kuan-Lin Hou</div><div><b>Pages:&nbsp;</b>994 - 1007</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9712322/\">Obtaining Fuzzy Membership Function of Clusters With the Memristor Hardware Implementation and On-Chip Learning</a></div><div><b>Author(s):&nbsp;</b>Mohammad Javadian, Arian Hejazi, Sajad Haghzad Klidbary</div><div><b>Pages:&nbsp;</b>1008 - 1025</div><div><br /></div>",
            "pubdate": "2022-07-29T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                7,
                29
            ],
            "email_sent": true
        },
        "IEEE Transactions on Artificial Intelligence, Volume 3, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/07/ieee-transactions-on-artificial.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9591342/\">Balanced Graph Cut With Exponential Inter-Cluster Compactness</a></div><div><b>Author(s): </b>Danyang Wu, Feiping Nie, Jitao Lu, Rong Wang, Xuelong Li</div><div><b>Pages: </b>498 - 505</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9695289/\">Efficient Temporal Piecewise-Linear Numeric Planning With Lazy Consistency Checking</a></div><div><b>Author(s):&nbsp;</b>Josef Bajada, Maria Fox, Derek Long</div><div><b>Pages:&nbsp;</b>506 - 517</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9612034/\">Ignorance is Bliss: Exploring Defenses Against Invariance-Based Attacks on Neural Machine Translation Systems</a></div><div><b>Author(s):&nbsp;</b>Akshay Chaturvedi, Abhisek Chakrabarty, Masao Utiyama, Eiichiro Sumita, Utpal Garain</div><div><b>Pages:&nbsp;</b>518 - 525</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9618852/\">ArcText: A Unified Text Approach to Describing Convolutional Neural Network Architectures</a></div><div><b>Author(s):&nbsp;</b>Yanan Sun, Gary G. Yen, Bing Xue, Mengjie Zhang, Jiancheng Lv</div><div><b>Pages:&nbsp;</b>526 - 540</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9652037/\">Histogram Layers for Texture Analysis</a></div><div><b>Author(s):&nbsp;</b>Joshua Peeples, Weihuang Xu, Alina Zare</div><div><b>Pages:&nbsp;</b>541 - 552</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9613742/\">Traded Control of Human\u2013Machine Systems for Sequential Decision-Making Based on Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Qianqian Zhang, Yu Kang, Yun-Bo Zhao, Pengfei Li, Shiyi You</div><div><b>Pages:&nbsp;</b>553 - 566</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9612040/\">Potential Impacts of Smart Homes on Human Behavior: A Reinforcement Learning Approach</a></div><div><b>Author(s):&nbsp;</b>Shashi Suman, Ali Etemad, Francois Rivest</div><div><b>Pages:&nbsp;</b>567 - 580</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9612064/\">Multiadvisor Reinforcement Learning for Multiagent Multiobjective Smart Home Energy Control</a></div><div><b>Author(s):&nbsp;</b>Andrew Tittaferrante, Abdulsalam Yassine</div><div><b>Pages:&nbsp;</b>581 - 594</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9614997/\">On a Sparse Shortcut Topology of Artificial Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Feng-Lei Fan, Dayang Wang, Hengtao Guo, Qikui Zhu, Pingkun Yan, Ge Wang, Hengyong Yu</div><div><b>Pages:&nbsp;</b>595 - 608</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9594655/\">CSNAS: Contrastive Self-Supervised Learning Neural Architecture Search Via Sequential Model-Based Optimization</a></div><div><b>Author(s):&nbsp;</b>Nam Nguyen, J. Morris Chang</div><div><b>Pages:&nbsp;</b>609 - 624</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9652108/\">Perturbed Composite Attention Model for Macular Optical Coherence Tomography Image Classification</a></div><div><b>Author(s):&nbsp;</b>Sapna S. Mishra, Bappaditya Mandal, Niladri B. Puhan</div><div><b>Pages:&nbsp;</b>625 - 635</div><div><br /></div>",
            "pubdate": "2022-07-30T12:00:00.041+12:00",
            "pubdate_parsed": [
                2022,
                7,
                30
            ],
            "email_sent": true
        },
        "IEEE Transactions on Evolutionary Computation, Volume 26, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/ieee-transactions-on-evolutionary.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9515483/\">A Kernel-Based Indicator for Multi/Many-Objective Optimization</a></div><div><b>Author(s): </b>Xinye Cai, Yushun Xiao, Zhenhua Li, Qi Sun, Hanchuan Xu, Miqing Li, Hisao Ishibuchi</div><div><b>Pages: </b>602 - 615</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9521243/\">Clustering-Guided Particle Swarm Feature Selection Algorithm for High-Dimensional Imbalanced Data With Missing Values</a></div><div><b>Author(s):&nbsp;</b>Yong Zhang, Yan-Hu Wang, Dun-Wei Gong, Xiao-Yan Sun</div><div><b>Pages:&nbsp;</b>616 - 630</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9509584/\">An Ensemble Surrogate-Based Framework for Expensive Multiobjective Evolutionary Optimization</a></div><div><b>Author(s):&nbsp;</b>Qiuzhen Lin, Xunfeng Wu, Lijia Ma, Jianqiang Li, Maoguo Gong, Carlos A. Coello Coello</div><div><b>Pages:&nbsp;</b>631 - 645</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9528854/\">A Voting-Mechanism-Based Ensemble Framework for Constraint Handling Techniques</a></div><div><b>Author(s):&nbsp;</b>Guohua Wu, Xupeng Wen, Ling Wang, Witold Pedrycz, Ponnuthurai Nagaratnam Suganthan</div><div><b>Pages:&nbsp;</b>646 - 660</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9520652/\">Genetic Programming for Manifold Learning: Preserving Local Topology</a></div><div><b>Author(s):&nbsp;</b>Andrew Lensen, Bing Xue, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>661 - 675</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9542966/\">Surrogate-Assisted Autoencoder-Embedded Evolutionary Optimization Algorithm to Solve High-Dimensional Expensive Problems</a></div><div><b>Author(s):&nbsp;</b>Meiji Cui, Li Li, Mengchu Zhou, Abdullah Abusorrah</div><div><b>Pages:&nbsp;</b>676 - 68</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9546930/\">An Online Prediction Approach Based on Incremental Support Vector Machine for Dynamic Multiobjective Optimization</a></div><div><b>Author(s):&nbsp;</b>Dejun Xu, Min Jiang, Weizhen Hu, Shaozi Li, Renhu Pan, Gary G. Yen</div><div><b>Pages:&nbsp;</b>690 - 703</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9594087/\">Region-Focused Memetic Algorithms With Smart Initialization for Real-World Large-Scale Waste Collection Problems</a></div><div><b>Author(s):&nbsp;</b>Wenxing Lan, Ziyuan Ye, Peijun Ruan, Jialin Liu, Peng Yang, Xin Yao</div><div><b>Pages:&nbsp;</b>704 - 718</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9627943/\">A Meta-Knowledge Transfer-Based Differential Evolution for Multitask Optimization</a></div><div><b>Author(s):&nbsp;</b>Jian-Yu Li, Zhi-Hui Zhan, Kay Chen Tan, Jun Zhang</div><div><b>Pages:&nbsp;</b>719 - 734</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9656554/\">An Evolutionary Forest for Regression</a></div><div><b>Author(s):&nbsp;</b>Hengzhe Zhang, Aimin Zhou, Hu Zhang</div><div><b>Pages:&nbsp;</b>735 - 749</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9509298/\">Fast Greedy Subset Selection From Large Candidate Solution Sets in Evolutionary Multiobjective Optimization</a></div><div><b>Author(s):&nbsp;</b>Weiyu Chen, Hisao Ishibuchi, Ke Shang</div><div><b>Pages:&nbsp;</b>750 - 764</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9621218/\">Genetic Programming With Knowledge Transfer and Guided Search for Uncertain Capacitated Arc Routing Problem</a></div><div><b>Author(s):&nbsp;</b>Mazhar Ansari Ardeh, Yi Mei, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>765 - 779</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9559391/\">Surrogate-Assisted Differential Evolution With Region Division for Expensive Optimization Problems With Discontinuous Responses</a></div><div><b>Author(s):&nbsp;</b>Yong Wang, Jianqing Lin, Jiao Liu, Guangyong Sun, Tong Pang</div><div><b>Pages:&nbsp;</b>780 - 792</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9684551/\">Automating Genetic Algorithm Mutations for Molecules Using a Masked Language Model</a></div><div><b>Author(s):&nbsp;</b>Andrew E. Blanchard, Mayanka Chandra Shekar, Shang Gao, John Gounley, Isaac Lyngaas, Jens Glaser, Debsindhu Bhowmik</div><div><b>Pages:&nbsp;</b>793 - 799</div><div><br /></div></div>",
            "pubdate": "2022-08-04T17:35:00.000+12:00",
            "pubdate_parsed": [
                2022,
                8,
                4
            ],
            "email_sent": true
        },
        "IEEE Transactions on Fuzzy Systems, Volume 30, Issue 8": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9366977/\">The Fusion of Deep Learning and Fuzzy Systems: A State-of-the-Art Survey</a></div><div><b>Author(s): </b>Yuanhang Zheng, Zeshui Xu, Xinxin Wang</div><div><b>Pages: </b>2783 - 2799</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9477079/\">A Decade of the Z-Numbers</a></div><div><b>Author(s):&nbsp;</b>Romi Banerjee, Sankar K. Pal, Jayanta Kumar Pal</div><div><b>Pages:&nbsp;</b>2800 - 2812</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9416169/\">Event-Based Adaptive Fixed-Time Fuzzy Control for Active Vehicle Suspension Systems With Time-Varying Displacement Constraint</a></div><div><b>Author(s):&nbsp;</b>Tinghan Jia, Yingnan Pan, Hongjing Liang, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>2813 - 2821</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9416776/\">Event-Triggered Asynchronous Fuzzy Filtering for Vehicle Sideslip Angle Estimation With Data Quantization and Dropouts</a></div><div><b>Author(s):&nbsp;</b>Wenfeng Li, Zhengchao Xie, Pak Kin Wong, Yunfeng Hu, Ge Guo, Jing Zhao</div><div><b>Pages:&nbsp;</b>2822 - 2836</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9416832/\">Design of Syncretic Fuzzy-Neural Control for WWTP</a></div><div><b>Author(s):&nbsp;</b>Honggui Han, Zheng Liu, Jiaming Li, Junfei Qiao</div><div><b>Pages:&nbsp;</b>2837 - 2849</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9417721/\">Detection and Classification of Anomalies in Large Datasets on the Basis of Information Granules</a></div><div><b>Author(s):&nbsp;</b>Adam Kiersztyn, Pawe\u0142 Karczmarek, Krystyna Kiersztyn, Witold Pedrycz</div><div><b>Pages:&nbsp;</b>2850 - 2860</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9477024/\">A Hierarchical Approach to Interpretability of TS Rule-Based Models</a></div><div><b>Author(s):&nbsp;</b>Witold Pedrycz, Adam Gacek, Xianmin Wang</div><div><b>Pages:&nbsp;</b>2861 - 2869</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9476988/\">Fuzzy Adaptive Optimal Consensus Fault-Tolerant Control for Stochastic Nonlinear Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Kewen Li, Yongming Li</div><div><b>Pages:&nbsp;</b>2870 - 2885</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9483671/\">A Spectral Feature Selection Approach With Kernelized Fuzzy Rough Sets</a></div><div><b>Author(s):&nbsp;</b>Jinkun Chen, Yaojin Lin, Jusheng Mi, Shaozi Li, Weiping Ding</div><div><b>Pages:&nbsp;</b>2886 - 2901</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9490300/\">An Unsupervised Fuzzy Clustering Approach for Early Screening of COVID-19 From Radiological Images</a></div><div><b>Author(s):&nbsp;</b>Weiping Ding, Shouvik Chakraborty, Kalyani Mali, Sankhadeep Chatterjee, Janmenjoy Nayak, Asit Kumar Das, Soumen Banerjee</div><div><b>Pages:&nbsp;</b>2902 - 2914</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9490345/\">Interval Type-2 Fuzzy Differential Equations and Stability</a></div><div><b>Author(s):&nbsp;</b>Marzieh Najariyan, Li Qiu</div><div><b>Pages:&nbsp;</b>2915 - 2929</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9490328/\">Feature Selection With Fuzzy-Rough Minimum Classification Error Criterion</a></div><div><b>Author(s):&nbsp;</b>Changzhong Wang, Yuhua Qian, Weiping Ding, Xiaodong Fan</div><div><b>Pages:&nbsp;</b>2930 - 2942</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9492324/\">An Enhanced Input-Delay Approach to Sampled-Data Stabilization for Nonlinear Stochastic Singular Systems Based on T-S Fuzzy Models</a></div><div><b>Author(s):&nbsp;</b>Shuangyun Xing, Weixing Zheng, Feiqi Deng, Chunling Chang</div><div><b>Pages:&nbsp;</b>2943 - 2956</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9492811/\">Deep Fuzzy Rule-Based Classification System With Improved Wang\u2013Mendel Method</a></div><div><b>Author(s):&nbsp;</b>Yuangang Wang, Haoran Liu, Wenjuan Jia, Shuo Guan, Xiaodong Liu, Xiaodong Duan</div><div><b>Pages:&nbsp;</b>2957 - 2970</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9492757/\">Observer-Based Fault Reconstruction and Fault-Tolerant Control for Nonlinear Systems Subject to Simultaneous Actuator and Sensor Faults</a></div><div><b>Author(s):&nbsp;</b>Huaguang Zhang, Yunfei Mu, Zhiyun Gao, Wei Wang</div><div><b>Pages:&nbsp;</b>2971 - 2980</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9495277/\">Adaptive Fuzzy Event-Triggered Control of Aerial Refueling Hose System With Actuator Failures</a></div><div><b>Author(s):&nbsp;</b>Zhijie Liu, Jun Shi, Xuena Zhao, Zhijia Zhao, Han-Xiong Li</div><div><b>Pages:&nbsp;</b>2981 - 2992</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9495212/\">Input-to-State Stability of the Nonlinear Fuzzy Systems via Small-Gain Theorem and Decentralized Sliding-Mode Control</a></div><div><b>Author(s):&nbsp;</b>Zhenghong Jin, Zhanxiu Wang, Jiawen Li</div><div><b>Pages:&nbsp;</b>2993 - 3008</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9496162/\">Modeling, Fault Detection, and Fault-Tolerant Control for Nonlinear Singularly Perturbed Systems With Actuator Faults and External Disturbances</a></div><div><b>Author(s):&nbsp;</b>Jinxiang Chen, Chunxiao He</div><div><b>Pages:&nbsp;</b>3009 - 3022</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9496226/\">Fuzzy STUDENT\u2019S T-Distribution Model Based on Richer Spatial Combination</a></div><div><b>Author(s):&nbsp;</b>Tao Lei, Xiaohong Jia, Dinghua Xue, Qi Wang, Hongying Meng, Asoke K. Nandi</div><div><b>Pages:&nbsp;</b>3023 - 3037</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9496225/\">Incomplete Multiple View Fuzzy Inference System With Missing View Imputation and Cooperative Learning</a></div><div><b>Author(s):&nbsp;</b>Wei Zhang, Zhaohong Deng, Te Zhang, Kup-Sze Choi, Jun Wang, Shitong Wang</div><div><b>Pages:&nbsp;</b>3038 - 3051</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9506856/\">Event-Triggered Practical Fixed-Time Fuzzy Containment Control for Stochastic Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Dajie Yao, Chunxia Dou, Dong Yue, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3052 - 3062</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9506819/\">Interval Type-2 Fuzzy Control for HMM-Based Multiagent Systems via Dynamic Event-Triggered Scheme</a></div><div><b>Author(s):&nbsp;</b>Yuan Wang, Huaicheng Yan, Hao Zhang, Hao Shen, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>3063 - 3073</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9506820/\">Fuzzy Event-Triggered Control for PDE Systems With Pointwise Measurements Based on Relaxed Lyapunov\u2013Krasovskii Functionals</a></div><div><b>Author(s):&nbsp;</b>Xiaona Song, Qiyuan Zhang, Yijun Zhang, Shuai Song</div><div><b>Pages:&nbsp;</b>3074 - 3084</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9511173/\">Quasi-Synchronization of Fuzzy Heterogeneous Complex Networks via Intermittent Discrete-Time State Observations Control</a></div><div><b>Author(s):&nbsp;</b>Tianrui Chen, Wenhua Wang, Yongbao Wu</div><div><b>Pages:&nbsp;</b>3085 - 3097</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9511214/\">Event-Triggered Output Feedback Type-2 Fuzzy Control for Uncertain Steer-By-Wire Systems With Prespecified Tracking Performance</a></div><div><b>Author(s):&nbsp;</b>Bingxin Ma, Yongfu Wang, Tianyou Chai</div><div><b>Pages:&nbsp;</b>3098 - 3112</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9512480/\">H\u221e Fuzzy Dynamic Output Feedback Reliable Control for Markov Jump Nonlinear Systems With PDT Switched Transition Probabilities and Its Application</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Jiacheng Wu, Jinde Cao, Ju H. Park, Hao Shen</div><div><b>Pages:&nbsp;</b>3113 - 3124</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9512491/\">Distributed Semisupervised Fuzzy Regression With Interpolation Consistency Regularization</a></div><div><b>Author(s):&nbsp;</b>Ye Shi, Leijie Zhang, Zehong Cao, Mohammad Tanveer, Chin-Teng Lin</div><div><b>Pages:&nbsp;</b>3125 - 3137</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9516920/\">Lagrange Stability of Fuzzy Memristive Neural Networks on Time Scales With Discrete Time Varying and Infinite Distributed Delays</a></div><div><b>Author(s):&nbsp;</b>Peng Wan, Zhigang Zeng</div><div><b>Pages:&nbsp;</b>3138 - 3151</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9516953/\">Effective Fuzzy System for Qualifying the Characteristics of Stocks by Random Trading</a></div><div><b>Author(s):&nbsp;</b>Mu-En Wu, Jia-Hao Syu, Jerry Chun-Wei Lin, Jan-Ming Ho</div><div><b>Pages:&nbsp;</b>3152 - 3165</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9516892/\">Fuzzy First-Order and Second Moment Method for Failure Credibility Analysis in the Presence of Fuzzy Uncertainty</a></div><div><b>Author(s):&nbsp;</b>Beixi Jia, Zhenzhou Lu, Jingyu Lei</div><div><b>Pages:&nbsp;</b>3166 - 3175</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9520250/\">A Concise TSK Fuzzy Ensemble Classifier Integrating Dropout and Bagging for High-Dimensional Problems</a></div><div><b>Author(s):&nbsp;</b>Fei Guo, Jiahuan Liu, Maoyuan Li, Tianlun Huang, Yun Zhang, Dequn Li, Huamin Zhou</div><div><b>Pages:&nbsp;</b>3176 - 3190</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9521795/\">Resilient Adaptive Event-Triggered Fuzzy Tracking Control and Filtering for Nonlinear Networked Systems Under Denial-of-Service Attacks</a></div><div><b>Author(s):&nbsp;</b>Ning Zhao, Peng Shi, Wen Xing, Chee Peng Lim</div><div><b>Pages:&nbsp;</b>3191 - 3201</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9522064/\">Nonfragile Sampled-Data Control of T\u2013S Fuzzy Systems With Time Delay</a></div><div><b>Author(s):&nbsp;</b>Yunfei Qiu, Changchun Hua, Yibo Wang</div><div><b>Pages:&nbsp;</b>3202 - 3210</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9522055/\">Integrated State/Fault Estimation and Fault-Tolerant Control Design for Switched T\u2013S Fuzzy Systems With Sensor and Actuator Faults</a></div><div><b>Author(s):&nbsp;</b>Ayyoub Ait Ladel, Abdellah Benzaouia, Rachid Outbib, Mustapha Ouladsine</div><div><b>Pages:&nbsp;</b>3211 - 3223</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9522042/\">Extended-Dissipativity-Based Adaptive Event-Triggered Control for Stochastic Polynomial Fuzzy Singular Systems</a></div><div><b>Author(s):&nbsp;</b>Zhiguang Feng, Yang Yang, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>3224 - 3236</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9522052/\">Computing a Possibility Theory Repair for Partially Preordered Inconsistent Ontologies</a></div><div><b>Author(s):&nbsp;</b>Sihem Belabbes, Salem Benferhat</div><div><b>Pages:&nbsp;</b>3237 - 3246</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9535276/\">Adaptive Fuzzy Control for a Hybrid Spacecraft System With Spatial Motion and Communication Constraints</a></div><div><b>Author(s):&nbsp;</b>Zhiji Han, Zhijie Liu, Linghuan Kong, Liang Ding, Jun-Wei Wang, Wei He</div><div><b>Pages:&nbsp;</b>3247 - 3256</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9535264/\">Robust Asynchronous Filtering for Discrete-Time T\u2013S Fuzzy Complex Dynamical Networks Against Deception Attacks</a></div><div><b>Author(s):&nbsp;</b>Ramalingam Sakthivel, Oh-Min Kwon, Myeong Jin Park, Seong-Gon Choi, Rathinasamy Sakthivel</div><div><b>Pages:&nbsp;</b>3257 - 3269</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9537692/\">Broad Learning Based Dynamic Fuzzy Inference System With Adaptive Structure and Interpretable Fuzzy Rules</a></div><div><b>Author(s):&nbsp;</b>Kaiyuan Bai, Xiaomin Zhu, Shiping Wen, Runtong Zhang, Wenyu Zhang</div><div><b>Pages:&nbsp;</b>3270 - 3283</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9537594/\">LFIC: Identifying Influential Nodes in Complex Networks by Local Fuzzy Information Centrality</a></div><div><b>Author(s):&nbsp;</b>Haotian Zhang, Shen Zhong, Yong Deng, Kang Hao Cheong</div><div><b>Pages:&nbsp;</b>3284 - 3296</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9537698/\">Adjustable Event-Triggered Load Frequency Control of Power Systems Using Control-Performance-Standard-Based Fuzzy Logic</a></div><div><b>Author(s):&nbsp;</b>Xing-Chen Shangguan, Yong He, Chuan-Ke Zhang, Lin Jiang, Min Wu</div><div><b>Pages:&nbsp;</b>3297 - 3311</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9538964/\">Intermittent Event-Triggered Exponential Stabilization for State-Dependent Switched Fuzzy Neural Networks With Mixed Delays</a></div><div><b>Author(s):&nbsp;</b>Xiaofan Li, Nikhil R. Pal, Huiyuan Li, Tingwen Huang</div><div><b>Pages:&nbsp;</b>3312 - 3321</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9541054/\">An Algebraic Fuzzy Pole Placement Approach to Stabilize Nonlinear Mechanical Systems</a></div><div><b>Author(s):&nbsp;</b>Jes\u00fas Alberto Meda-Campa\u00f1a, Rom\u00e1n A. Rodr\u00edguez-Manzanarez, S. Denisse Ontiveros-Paredes, Jos\u00e9 de Jes\u00fas Rubio, Ricardo Tapia-Herrera, Tonatiuh Hern\u00e1ndez-Cort\u00e9s, Guillermo Obreg\u00f3n-Pulido, Carlos Aguilar-Ib\u00e1\u00f1ez</div><div><b>Pages:&nbsp;</b>3322 - 3332</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9541015/\">Consensus Reaching in Multiple Attribute Group Decision Making: A Multi-Stage Optimization Feedback Mechanism With Individual Bounded Confidences</a></div><div><b>Author(s):&nbsp;</b>Quanbo Zha, Yucheng Dong, Francisco Chiclana, Enrique Herrera-Viedma</div><div><b>Pages:&nbsp;</b>3333 - 3346</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9541019/\">Fuzzy Secure Control for Nonlinear N-D Parabolic PDE-ODE Coupled Systems Under Stochastic Deception Attacks</a></div><div><b>Author(s):&nbsp;</b>Ruimei Zhang, Hongxia Wang, Ju H. Park, Peisong He, Deqiang Zeng, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3347 - 3359</div><div><br /></div><div><b>46)</b> M<a href=\"https://ieeexplore.ieee.org/document/9540982/\">ultilinear-Trend Fuzzy Information Granule-Based Short-Term Forecasting for Time Series</a></div><div><b>Author(s):&nbsp;</b>Fang Li, Yuqing Tang, Fusheng Yu, Witold Pedrycz, Yuming Liu, Wenyi Zeng</div><div><b>Pages:&nbsp;</b>3360 - 3372</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9547686/\">Adaptive Fuzzy Decentralized Dynamic Surface Control for Fractional-Order Nonlinear Large-Scale Systems</a></div><div><b>Author(s):&nbsp;</b>Yongliang Zhan, Shuai Sui, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>3373 - 3383</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9516933/\">Federated FCM: Clustering Under Privacy Requirements</a></div><div><b>Author(s):&nbsp;</b>Witold Pedrycz</div><div><b>Pages:&nbsp;</b>3384 - 3388</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9540996/\">Fuzzy Logic on Quantum Annealers</a></div><div><b>Author(s):&nbsp;</b>Amir Pourabdollah, Giovanni Acampora, Roberto Schiattarella</div><div><b>Pages:&nbsp;</b>3389 - 3394</div><div><br /></div>",
            "pubdate": "2022-08-08T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                8,
                8
            ],
            "email_sent": true
        },
        "Complex and Intelligent Systems, Volume 8, Issue 4": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/complex-and-intelligent-systems-volume.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00766-x\">Evolutionary optimization of large complex problems</a></div><div><b>Author(s): </b>Handing Wang, Chaoli Sun...Yew-soon Ong</div><div><b>Pages: </b>2697 - 2698</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00249-x\">Surrogate-assisted evolutionary algorithm for expensive constrained multi-objective discrete optimization problems</a></div><div><b>Author(s):&nbsp;</b>Qinghua Gu, Qian Wang...Lu Chen</div><div><b>Pages:&nbsp;</b>2699 - 2718</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00352-7\">Accelerate the optimization of large-scale manufacturing planning using game theory</a></div><div><b>Author(s):&nbsp;</b>Hui-Ling Zhen, Zhenkun Wang...Jia Zeng</div><div><b>Pages:&nbsp;</b>2719 - 2730</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00374-1\">fSDE: efficient evolutionary optimisation for many-objective aero-engine calibration</a></div><div><b>Author(s):&nbsp;</b>Jialin Liu, Qingquan Zhang...Feng Wu</div><div><b>Pages:&nbsp;</b>2731 - 2747</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00402-0\">Simplified Phasmatodea population evolution algorithm for optimization</a></div><div><b>Author(s):&nbsp;</b>Pei-Cheng Song, Shu-Chuan Chu...Hongmei Yang</div><div><b>Pages:&nbsp;</b>2749 - 2767</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00452-4\">Two-stage improved Grey Wolf optimization algorithm for feature selection on high-dimensional classification</a></div><div><b>Author(s):&nbsp;</b>Chaonan Shen, Kai Zhang</div><div><b>Pages:&nbsp;</b>2769 - 2789</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00510-x\">A hybrid ant lion optimization chicken swarm optimization algorithm for charger placement problem</a></div><div><b>Author(s):&nbsp;</b>Sanchari Deb, Xiao-Zhi Gao</div><div><b>Pages:&nbsp;</b>2791 - 2808</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00773-y\">Robotic dexterous manipulation: from tele-operation to autonomous learning and adaptive control</a></div><div><b>Author(s):&nbsp;</b>Qiang Li, Chao Liu...Helge Ritter</div><div><b>Pages:&nbsp;</b>2809 - 2811</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00341-w\">Lower limb movement intention recognition for rehabilitation robot aided with projected recurrent neural network</a></div><div><b>Author(s):&nbsp;</b>Mei Liu, Bo Peng, Mingsheng Shang</div><div><b>Pages:&nbsp;</b>2813 - 2824</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00333-w\">Approach to hand posture recognition based on hand shape features for human\u2013robot interaction</a></div><div><b>Author(s):&nbsp;</b>Jing Qi, Kun Xu, Xilun Ding</div><div><b>Pages:&nbsp;</b>2825 - 2842</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00350-9\">Development and evaluation of demonstration information recording approach for wheelchair mounted robotic arm</a></div><div><b>Author(s):&nbsp;</b>Mingshan Chi, Yaxin Liu...Ming Zhong</div><div><b>Pages:&nbsp;</b>2843 - 2857</div><div><br /></div><div><b>12) </b><a href=\"https://link.springer.com/article/10.1007/s40747-021-00420-y\">Towards a balancing safety against performance approach in human\u2013robot co-manipulation for door-closing emergencies</a></div><div><b>Author(s):&nbsp;</b>Chuande Liu, Chuang Yu...Adriana Tapus</div><div><b>Pages:&nbsp;</b>2859 - 2871</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00429-3\">DMPs-based skill learning for redundant dual-arm robotic synchronized cooperative manipulation</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Lu, Ning Wang, Donghao Shi</div><div><b>Pages:&nbsp;</b>2873 - 2882</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00418-6\">Incorporating model predictive control with fuzzy approximation for robot manipulation under remote center of motion constraint</a></div><div><b>Author(s):&nbsp;</b>Hang Su, Junhao Zhang...Elena De Momi</div><div><b>Pages:&nbsp;</b>2883 - 2895</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00464-0\">A continuous switching contact model for virtual environment based teleoperation</a></div><div><b>Author(s):&nbsp;</b>Yongqing Fu, Baibo Wu, Weiyang Lin</div><div><b>Pages:&nbsp;</b>1 - 13</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00459-x\">GraspVDN: scene-oriented grasp estimation by learning vector representations of grasps</a></div><div><b>Author(s):&nbsp;</b>Zhipeng Dong, Hongkun Tian...Fei Chen</div><div><b>Pages:&nbsp;</b>2911 - 2922</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00485-9\">Monocular tissue reconstruction via remote center motion for robot-assisted minimally invasive surgery</a></div><div><b>Author(s):&nbsp;</b>Peng Li, Ming Tang...Yunhui Liu</div><div><b>Pages:&nbsp;</b>2923 - 2936</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00499-3\">Hybrid type multi-robot path planning of a serial manipulator and SwarmItFIX robots in sheet metal milling process</a></div><div><b>Author(s):&nbsp;</b>Satheeshkumar Veeramani, Sreekumar Muthuswamy</div><div><b>Pages:&nbsp;</b>2937 - 2954</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00522-7\">A peduncle detection method of tomato for autonomous harvesting</a></div><div>J<b>Author(s):&nbsp;</b>iacheng Rong, Guanglin Dai, Pengbo Wang</div><div><b>Pages:&nbsp;</b>2955 - 2969</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00533-4\">Intent inference in shared-control teleoperation system in consideration of user behavior</a></div><div><b>Author(s):&nbsp;</b>Liangliang Wang, Qiang Li...Zhengyou Zhang</div><div><b>Pages:&nbsp;</b>2971 - 2981</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00546-z\">Bilateral teleoperation with object-adaptive mapping</a></div><div><b>Author(s):&nbsp;</b>Xiao Gao, Jo\u00e3o Silv\u00e9rio...Xiaohui Xiao</div><div><b>Pages:&nbsp;</b>2983 - 2990</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00652-6\">Fault-tolerant motion planning and generation of quadruped robots synthesised by posture optimization and whole body control</a></div><div><b>Author(s):&nbsp;</b>Junwen Cui, Zhan Li...Tianxiao Li</div><div><b>Pages:&nbsp;</b>2991 - 3003</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00777-8\">Editorial of the Special Issue: Brain-like computing for medical applications</a></div><div><b>Author(s):&nbsp;</b>Yu-Dong Zhang, Hong Lin...Steven L. Fernandes</div><div><b>Pages:&nbsp;</b>3005 - 3006</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00321-0\">A decision support system for multimodal brain tumor classification using deep learning</a></div><div><b>Author(s):&nbsp;</b>Muhammad Imran Sharif, Muhammad Attique Khan...Mudassar Raza</div><div><b>Pages:&nbsp;</b>3007 - 3020</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00319-8\">Smart healthcare system-a brain-like computing approach for analyzing the performance of detectron2 and PoseNet models for anomalous action detection in aged people with movement impairments</a></div><div><b>Author(s):&nbsp;</b>R. Divya, J. Dinesh Peter</div><div><b>Pages:&nbsp;</b>3021 - 3040</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00328-7\">3D-semantic segmentation and classification of stomach infections using uncertainty aware deep neural networks</a></div><div><b>Author(s):&nbsp;</b>Javaria Amin, Muhammad Sharif...Ramesh Sunder Nayak</div><div><b>Pages:&nbsp;</b>3041 - 3057</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00336-7\">EEG data augmentation for emotion recognition with a multiple generator conditional Wasserstein GAN</a></div><div><b>Author(s):&nbsp;</b>Aiming Zhang, Lei Su...Shengjin Liang</div><div><b>Pages:&nbsp;</b>3059 - 3071</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00398-7\">Comparative performance analysis of quantum machine learning with deep learning for diabetes prediction</a></div><div><b>Author(s):&nbsp;</b>Himanshu Gupta, Hirdesh Varshney...Om Prakash Verma</div><div><b>Pages:&nbsp;</b>3073 - 3087</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00465-z\">A weighted least squares optimisation strategy for medical image super resolution via multiscale convolutional neural networks for healthcare applications</a></div><div><b>Author(s):&nbsp;</b>Bhawna Goyal, Dawa Chyophel Lepcha...Shui-Hua Wang</div><div><b>Pages:&nbsp;</b>3089 - 3104</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00473-z\">A deep network designed for segmentation and classification of leukemia using fusion of the transfer learning models</a></div><div><b>Author(s):&nbsp;</b>Saba Saleem, Javeria Amin...Shui-Hua Wang</div><div><b>Pages:&nbsp;</b>3105 - 3120</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00474-y\">A federated approach for detecting the chest diseases using DenseNet for multi-label classification</a></div><div><b>Author(s):&nbsp;</b>K. V. Priya, J. Dinesh Peter</div><div><b>Pages:&nbsp;</b>3121 - 3129</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00469-9\">Evolutionary multiple instance boosting framework for weakly supervised learning</a></div><div><b>Author(s):&nbsp;</b>Kamanasish Bhattacharjee, Millie Pant...Shilpa Srivastava</div><div><b>Pages:&nbsp;</b>3131 - 3141</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00564-x\">Categorizing white blood cells by utilizing deep features of proposed 4B-AdditionNet-based CNN network with ant colony optimization</a></div><div><b>Author(s):&nbsp;</b>Asim Shahzad, Mudassar Raza...Ramesh Sunder Nayak</div><div><b>Pages:&nbsp;</b>3143 - 3159</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00563-y\">Brain tumor detection and classification using machine learning: a comprehensive survey</a></div><div><b>Author(s):&nbsp;</b>Javaria Amin, Muhammad Sharif...Ramesh Sundar Nayak</div><div><b>Pages:&nbsp;</b>3161 - 3183</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00771-0\">Person identification from arm\u2019s hair patterns using CT-twofold Siamese network in forensic psychiatric hospitals</a></div><div><b>Author(s):&nbsp;</b>Rohan Don Salins, T. S. Ashwin...Chaitra K. Mallikarjun</div><div><b>Pages:&nbsp;</b>3185 - 3197</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00673-1\">Effective and scalable legal judgment recommendation using pre-learned word embedding</a></div><div><b>Author(s):&nbsp;</b>Jenish Dhanani, Rupa Mehta, Dipti Rana</div><div><b>Pages:&nbsp;</b>3199 - 3213</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00674-0\">An iterative approach to unsupervised outlier detection using ensemble method and distance-based data filtering</a></div><div><b>Author(s):&nbsp;</b>Bodhan Chakraborty, Agneet Chaterjee...Ram Sarkar</div><div><b>Pages:&nbsp;</b>3215 - 3230</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00675-z\">A consensus building model in group decision making with non-reciprocal fuzzy preference relations</a></div><div><b>Author(s):&nbsp;</b>Fang Liu, Tong Liu, Ya-Ru Chen</div><div><b>Pages:&nbsp;</b>3231 - 3245</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00663-3\">Two-factor-based RSA key generation from fingerprint biometrics and password for secure communication</a></div><div><b>Author(s):&nbsp;</b>K. SureshRajarshi Pal, S. R. Balasundaram</div><div><b>Pages:&nbsp;</b>3247 - 3261</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00662-4\">A novel multi-objective bi-level programming problem under intuitionistic fuzzy environment and its application in production planning problem</a></div><div><b>Author(s):&nbsp;</b>V. P. Singh, Kirti Sharma...Ali Ebrahimnejad</div><div><b>Pages:&nbsp;</b>3263 - 3278</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00669-x\">Hesitant T-spherical Dombi fuzzy aggregation operators and their applications in multiple criteria group decision-making</a></div><div><b>Author(s):&nbsp;</b>Faruk Karaaslan, Abdulrasool Hasan Sultan Al-Husseinawi</div><div><b>Pages:&nbsp;</b>3279 - 3297</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00670-4\">Cooperative multi-population Harris Hawks optimization for many-objective optimization</a></div><div><b>Author(s):&nbsp;</b>Na Yang, Zhenzhou Tang...Qian Hu</div><div><b>Pages:&nbsp;</b>3299 - 3332</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00676-y\">Software defect prediction based on nested-stacking and heterogeneous feature selection</a></div><div><b>Author(s):&nbsp;</b>Li-qiong Chen, Can Wang, Shi-long Song</div><div><b>Pages:&nbsp;</b>3333 - 3348</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00678-w\">Product selection based on sentiment analysis of online reviews: an intuitionistic fuzzy TODIM method</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Zhang, Jian Guo...Mengjiao Wang</div><div><b>Pages:&nbsp;</b>3349 - 3362</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00680-2\">Motion magnification multi-feature relation network for facial microexpression recognition</a></div><div><b>Author(s):&nbsp;</b>Jing Zhang, Boyun Yan...Yong Liu</div><div><b>Pages:&nbsp;</b>3363 - 3376</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00682-0\">A novel feature based algorithm for soil type classification</a></div><div><b>Author(s):&nbsp;</b>Machbah Uddin, Md. Rakib Hassan</div><div><b>Pages:&nbsp;</b>3377 - 3393</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00671-3\">Rethinking ResNets: improved stacking strategies with high-order schemes for image classification</a></div><div><b>Author(s):&nbsp;</b>Zhengbo Luo, Zitang Sun...Sei-ichiro Kamata</div><div><b>Pages:&nbsp;</b>3395 - 3407</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00684-y\">Stability analysis based parameter tuning of Social Group Optimization</a></div><div><b>Author(s):&nbsp;</b>Junali Jasmine Jena, Samarendra Chandan Bindu Dash, Suresh Chandra Satapathy</div><div><b>Pages:&nbsp;</b>3409 - 3435</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00677-x\">Control in the loop for synchronization of nonlinear chaotic systems via adaptive intuitionistic neuro-fuzzy: a comparative study</a></div><div><b>Author(s):&nbsp;</b>Salah Helmy, Mohamed Magdy, Mohamed Hamdy</div><div><b>Pages:&nbsp;</b>3437 - 3450</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00679-9\">Eigenvalue-based entropy and spectrum of bipartite digraph</a></div><div><b>Author(s):&nbsp;</b>Yan Sun, Haixing Zhao</div><div><b>Pages:&nbsp;</b>3451 - 3462</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00685-x\">The development trend of China\u2019s aging population: a forecast perspective</a></div><div><b>Author(s):&nbsp;</b>Xuchong Liu, Jianian Zhu, Kai Zou</div><div><b>Pages:&nbsp;</b>3463 - 3478</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00689-7\">Based on neutrosophic fuzzy environment: a new development of FWZIC and FDOSM for benchmarking smart e-tourism applications</a></div><div><b>Author(s):&nbsp;</b>A. H. Alamoodi, R. T. Mohammed...Ali Najm Jasim</div><div><b>Pages:&nbsp;</b>3479 - 3503</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00668-y\">1-Norm random vector functional link networks for classification problems</a></div><div><b>Author(s):&nbsp;</b>Barenya Bikash Hazarika, Deepak Gupta</div><div><b>Pages:&nbsp;</b>3505 - 3521</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00688-8\">Power Muirhead mean in spherical normal fuzzy environment and its applications to multi-attribute decision-making</a></div><div><b>Author(s):&nbsp;</b>Tansu Temel, Salih Berkan Aydemir, Ya\u015far Ho\u015fcan</div><div><b>Pages:&nbsp;</b>3523 - 3541</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00694-w\">Nerve optic segmentation in CT images using a deep learning model and a texture descriptor</a></div><div><b>Author(s):&nbsp;</b>Ramin Ranjbarzadeh, Shadi Dorosti...Malika Bendechache</div><div><b>Pages:&nbsp;</b>3543 - 3557</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00667-z\">Cyber-physical security for IoT networks: a comprehensive review on traditional, blockchain and artificial intelligence based key-security</a></div><div><b>Author(s):&nbsp;</b>Ankit Attkan, Virender Ranga</div><div><b>Pages:&nbsp;</b>3559 - 3591</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00801-x\">Correction to: Evolutionary optimization of large complex problems</a></div><div><b>Author(s):&nbsp;</b>Handing Wang, Chaoli Sun...Yew-soon Ong</div><div><b>Pages:&nbsp;</b>3593 - 3593</div><div><br /></div>",
            "pubdate": "2022-08-09T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                8,
                9
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 17, September 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/soft-computing-volume-26-issue-17.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07201-w\">Copper price movement prediction using recurrent neural networks and ensemble averaging</a></div><div><b>Author(s): </b>Jian Ni, Yue Xu...Jun Zhao</div><div><b>Pages: </b>8145 - 8161</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07234-1\">Improving the classification accuracy of melanoma detection by performing feature selection using binary Harris hawks optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>Priti Bansal, Abhishek Vanjani...Sumit Kumar</div><div><b>Pages:&nbsp;</b>8163 - 8181</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07232-3\">Chaotic implanted opposition-based-quantum equipoise state and Ascidiacea algorithms for loss lessening and power permanence enrichment</a></div><div><b>Author(s):&nbsp;</b>Lenin Kanagasabai</div><div><b>Pages:&nbsp;</b>8183 - 8202</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07236-z\">Dominating set-based test prioritization algorithms for regression testing</a></div><div><b>Author(s):&nbsp;</b>Zafer Can Demir, \u015eahin Emrah Amrahov</div><div><b>Pages:&nbsp;</b>8203 - 8220</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07238-x\">(f, g)-derivation in residuated multilattices</a></div><div><b>Author(s):&nbsp;</b>Darline Laure Keubeng Yemene, Luc Emery Diekouam Fotso, Celestin Lele</div><div><b>Pages:&nbsp;</b>8221 - 8228</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07241-2\">RO-implications induced from CL-overlap functions on complete lattices</a></div><div><b>Author(s):&nbsp;</b>Junsheng Qiao</div><div><b>Pages:&nbsp;</b>8229 - 8243</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07256-9\">Partial orders induced by the smallest and greatest nullnorms on bounded lattices</a></div><div><b>Author(s):&nbsp;</b>Zhi-qiang Liu, Xue-ping Wang</div><div><b>Pages:&nbsp;</b>8245 - 8252</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07261-y\">A deep learning approaches and fastai text classification to predict 25 medical diseases from medical speech utterances, transcription and intent</a></div><div><b>Author(s):&nbsp;</b>Yogesh Kumar, Apeksha Koul, Seema Mahajan</div><div><b>Pages:&nbsp;</b>8253 - 8272</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07270-x\">Research on Chinese ancient characters image recognition method based on adaptive receptive field</a></div><div><b>Author(s):&nbsp;</b>Yalin Miao, Li Liang...Guodong Li</div><div><b>Pages:&nbsp;</b>8273 - 8282</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07284-5\">Some similarity measures of generalized trapezoidal cubic numbers with applications</a></div><div><b>Author(s):&nbsp;</b>Mohammed A. Al Shumrani, Muhammad Gulistan</div><div><b>Pages:&nbsp;</b>8283 - 8297</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07212-7\">Sliding window convergence in intuitionistic fuzzy normed spaces for measurable functions</a></div><div><b>Author(s):&nbsp;</b>Rabia Sava\u015f</div><div><b>Pages:&nbsp;</b>8299 - 8306</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07218-1\">Prediction of the lattice constants of pyrochlore compounds using machine learning</a></div><div><b>Author(s):&nbsp;</b>Ibrahim Olanrewaju Alade, Mojeed Opeyemi Oyedeji...Tawfik A. Saleh</div><div><b>Pages:&nbsp;</b>8307 - 8315</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07235-0\">Joint Transformer and Multi-scale CNN for DCE-MRI Breast Cancer Segmentation</a></div><div><b>Author(s):&nbsp;</b>Chuanbo Qin, Yujie Wu...Xiaozhi Zhang</div><div><b>Pages:&nbsp;</b>8317 - 8334</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07258-7\">Topological IL-algebras</a></div><div><b>Author(s):&nbsp;</b>Safiqul Islam, Arundhati Sanyal, Jayanta Sen</div><div><b>Pages:&nbsp;</b>8335 - 8349</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07271-w\">Pierce sheaves of pseudo EMV-algebras</a></div><div><b>Author(s):&nbsp;</b>Anatolij Dvure\u010denskij, Omid Zahiri</div><div><b>Pages:&nbsp;</b>8351 - 8369</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07207-4\">Finite-time dissipative synchronization of discrete-time semi-Markovian jump complex dynamical networks with actuator faults</a></div><div><b>Author(s):&nbsp;</b>N. Sakthivel, S. Pallavi...V. Vijayakumar</div><div><b>Pages:&nbsp;</b>8371 - 8386</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07208-3\">A multi-criteria group decision-making approach based on revised distance measures under dual hesitant fuzzy setting with unknown weight information</a></div><div><b>Author(s):&nbsp;</b>Jawad Ali, Zia Bashir, Tabasam Rashid</div><div><b>Pages:&nbsp;</b>8387 - 8401</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07221-6\">On the residuation principle of n-dimensional R-implications</a></div><div><b>Author(s):&nbsp;</b>Rosana Zanotelli, Bruno Moura...Benjamin Bedregal</div><div><b>Pages:&nbsp;</b>8403 - 8426</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07229-y\">Improvement of cross-efficiency based on TODIM method</a></div><div><b>Author(s):&nbsp;</b>Meiqin Wu, Xiaoqing Hou, Jianping Fan</div><div><b>Pages:&nbsp;</b>8427 - 8439</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07237-y\">Supervisory adaptive fuzzy sliding mode control with optimal Jaya based fuzzy PID sliding surface for a planer cable robot</a></div><div><b>Author(s):&nbsp;</b>Mohammadhossein Aghaseyedabdollah, Mostafa Abedi, Mahdi Pourgholi</div><div><b>Pages:&nbsp;</b>8441 - 8458</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07239-w\">Multi-attribute group decision-making method based on weighted partitioned Maclaurin symmetric mean operator and a novel score function under neutrosophic cubic environment</a></div><div><b>Author(s):&nbsp;</b>Jianping Fan, Shanshan Zha, Meiqin Wu</div><div><b>Pages:&nbsp;</b>8459 - 8477</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07242-1\">Mehar approach to solve neutrosophic linear programming problems using possibilistic mean</a></div><div><b>Author(s):&nbsp;</b>Tanveen Kaur Bhatia, Amit Kumar...S. S. Appadoo</div><div><b>Pages:&nbsp;</b>8479 - 8495</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07252-z\">An improved solution for the neutrosophic linear programming problems based on Mellin\u2019s transform</a></div><div><b>Author(s):&nbsp;</b>G. Tamilarasi, S. Paulraj</div><div><b>Pages:&nbsp;</b>8497 - 8507</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07151-3\">Low-voltage distribution network topology identification based on constrained least square and graph theory</a></div><div><b>Author(s):&nbsp;</b>Shijie Cui, Peng Zeng...Guangye Li</div><div><b>Pages:&nbsp;</b>8509 - 8519</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07251-0\">Evaluating appropriate communication technology for smart grid by using a comprehensive decision-making approach fuzzy TOPSIS</a></div><div><b>Author(s):&nbsp;</b>Daud Abdul, Jiang Wenqi</div><div><b>Pages:&nbsp;</b>8521 - 8536</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07276-5\">A CEEMD-ARIMA-SVM model with structural breaks to forecast the crude oil prices linked with extreme events</a></div><div><b>Author(s):&nbsp;</b>Yuxiang Cheng, Jiayu Yi...Luis Seco</div><div><b>Pages:&nbsp;</b>8537 - 8551</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07161-1\">Deep learning for volatility forecasting in asset management</a></div><div><b>Author(s):&nbsp;</b>Alessio Petrozziello, Luigi Troiano...Michele La Rocca</div><div><b>Pages:&nbsp;</b>8553 - 8574</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07195-5\">Relationship classification based on dependency parsing and the pretraining model</a></div><div><b>Author(s):&nbsp;</b>Baosheng Yin, Yifei Sun</div><div><b>Pages:&nbsp;</b>8575 - 8583</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07202-9\">A cooperative genetic algorithm based on extreme learning machine for data classification</a></div><div><b>Author(s):&nbsp;</b>Lixia Bai, Hong Li...Jin Xie</div><div><b>Pages:&nbsp;</b>8585 - 8601</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07226-1\">An intermittent fault diagnosis method of analog circuits based on variational modal decomposition and adaptive dynamic density peak clustering</a></div><div><b>Author(s):&nbsp;</b>Jianfeng Qu, Xiaoyu Fang...Jinzhuo Liu</div><div><b>Pages:&nbsp;</b>8603 - 8615</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07230-5\">Residual stacked gated recurrent unit with encoder\u2013decoder architecture and an attention mechanism for temporal traffic prediction</a></div><div><b>Author(s):&nbsp;</b>R. J. Kuo, D. A. Kunarsito</div><div><b>Pages:&nbsp;</b>8617 - 8633</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07244-z\">Code recommendation based on joint embedded attention network</a></div><div><b>Author(s):&nbsp;</b>Wanzhi Wen, Tian Zhao...Deepak Kumar Jain</div><div><b>Pages:&nbsp;</b>8635 - 8645</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07263-w\">Dark convolutional neural network for forest smoke detection and localization based on single image</a></div><div><b>Author(s):&nbsp;</b>Na Lu</div><div><b>Pages:&nbsp;</b>8647 - 8659</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07152-2\">Simulation\u2013optimization approach for the multi-objective production and distribution planning problem in the supply chain: using NSGA-II and Monte Carlo simulation</a></div><div><b>Author(s):&nbsp;</b>Niloofar Nadim Kabiri, Saeed Emami, Abdul Sattar Safaei</div><div><b>Pages:&nbsp;</b>8661 - 8687</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07154-0\">A method of real-temporal object tracking combined the temporal information and spatial information</a></div><div><b>Author(s):&nbsp;</b>Xiaoshuo Jia, Zhihui Li...Shangyou Zeng</div><div><b>Pages:&nbsp;</b>8689 - 8698</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07171-z\">Optimal solution of neutrosophic linear fractional programming problems with mixed constraints</a></div><div><b>Author(s):&nbsp;</b>Sapan Kumar Das, S. A. Edalatpanah</div><div><b>Pages:&nbsp;</b>8699 - 8707</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07182-w\">Software module clustering using grid-based large-scale many-objective particle swarm optimization</a></div><div><b>Author(s):&nbsp;</b>Amarjeet Prajapati</div><div><b>Pages:&nbsp;</b>8709 - 8730</div><div><br /></div><div><b>38) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07196-4\">Process optimization for post disaster reconstruction project based on industrial design structure matrix (DSM)</a></div><div><b>Author(s):&nbsp;</b>Hui Tang, Qingping Zhong, Chuan Chen</div><div><b>Pages:&nbsp;</b>8731 - 8743</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07198-2\">A dynamic space reduction ant colony optimization for capacitated vehicle routing problem</a></div><div><b>Author(s):&nbsp;</b>Jinsi Cai, Peng Wang...Huachao Dong</div><div><b>Pages:&nbsp;</b>8745 - 8756</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07203-8\">Fault location in distribution network by solving the optimization problem using genetic algorithm based on the calculating voltage changes</a></div><div><b>Author(s):&nbsp;</b>Masoud Dashtdar, Mohit Bajaj...H\u00e1m\u00e9d M\u00e9rsh\u00eak\u00e1\u00e9r</div><div><b>Pages:&nbsp;</b>8757 - 8783</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07227-0\">A Scatter Search Algorithm for Multi-Criteria Inventory Classification considering Multi-Objective Optimization</a></div><div><b>Author(s):&nbsp;</b>Ilkay Saracoglu</div><div><b>Pages:&nbsp;</b>8785 - 8806</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07153-1\">The research of innovation path of power monitoring and dispatching under the vision of carbon neutrality based on mobile edge computing</a></div><div><b>Author(s):&nbsp;</b>Jingxuan Dong, Jian Li</div><div><b>Pages:&nbsp;</b>8807 - 8820</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07192-8\">Sustainable supplier selection using HF-DEA-FOCUM-MABAC technique: a case study in the Auto-making industry</a></div><div><b>Author(s):&nbsp;</b>Arunodaya Raj Mishra, Abhijit Saha...Ibrahim M. Hezam</div><div><b>Pages:&nbsp;</b>8821 - 8840</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07225-2\">A note on \u201cPythagorean uncertain linguistic hesitant fuzzy weighted averaging operator and its application in financial group decision making\u201d</a></div><div>S. S. Appadoo, Mohammadreza Makhan, Amit Kumar</div><div><b>Pages:&nbsp;</b>8841 - 8843</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06652-x\">SECOI: an application based on fuzzy soft sets for producing selective-colored images</a></div><div><b>Author(s):&nbsp;</b>Petr Hurtik, Ji\u0159\u00ed Mo\u010dko\u0159</div><div><b>Pages:&nbsp;</b>8845 - 8855</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06661-w\">A novel model based on multiple input factors and variance reciprocal: application on wind speed forecasting</a></div><div><b>Author(s):&nbsp;</b>Zhihao Shang, Min Li...Lian Li</div><div><b>Pages:&nbsp;</b>8857 - 8877</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06692-3\">A variable neighborhood search algorithm with constraint relaxation for the two-echelon vehicle routing problem with simultaneous delivery and pickup demands</a></div><div><b>Author(s):&nbsp;</b>Ran Liu, Shan Jiang</div><div><b>Pages:&nbsp;</b>8879 - 8896</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07296-1\">Reservoir water level forecasting using wavelet support vector regression (WSVR) based on teaching learning-based optimization algorithm (TLBO)</a></div><div><b>Author(s):&nbsp;</b>Mohammad Mahdi Malekpour, Hossein Malekpoor</div><div><b>Pages:&nbsp;</b>8897 - 8909</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06697-y\">Multi-objective casting production scheduling problem by a neighborhood structure enhanced discrete NSGA-II: an application from real-world workshop</a></div><div><b>Author(s):&nbsp;</b>Weihua Tan, Xiaofang Yuan...Lianghong Wu</div><div><b>Pages:&nbsp;</b>8911 - 8928</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06701-5\">Weighted differential evolution-based heuristic computing for identification of Hammerstein systems in electrically stimulated muscle modeling</a></div><div><b>Author(s):&nbsp;</b>Ammara Mehmood, Muhammad Asif Zahoor Raja...Naveed Ishtiaq Chaudhary</div><div><b>Pages:&nbsp;</b>8929 - 8945</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07374-4\">Correction: G-optimal designs for hierarchical linear models: an equivalence theorem and a nature-inspired meta-heuristic algorithm</a></div><div><b>Author(s):&nbsp;</b>Xin Liu, RongXian Yue...Weng Kee Wong</div><div><b>Pages:&nbsp;</b>8947 - 8947</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-08-18T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 8, August 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/08/ieee-transactions-on-neural-networks.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9345705/\">New Generation Deep Learning for Video Object Detection: A Survey</a></div><div><b>Author(s): </b>Licheng Jiao, Ruohan Zhang, Fang Liu, Shuyuan Yang, Biao Hou, Lingling Li, Xu Tang</div><div><b>Pages: </b>3195 - 3215</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9334418/\">Synchronization of Complex Dynamical Networks Subject to Noisy Sampling Interval and Packet Loss</a></div><div><b>Author(s):&nbsp;</b>Zhipei Hu, Hongru Ren, Peng Shi</div><div><b>Pages:&nbsp;</b>3216 - 3226</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9334446/\">Boundary Stabilization of Stochastic Delayed Cohen\u2013Grossberg Neural Networks With Diffusion Terms</a></div><div><b>Author(s):&nbsp;</b>Xiao-Zhen Liu, Kai-Ning Wu, Xiaohua Ding, Weihai Zhang</div><div><b>Pages:&nbsp;</b>3227 - 3237</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9337191/\">Neuron Linear Transformation: Modeling the Domain Shift for Crowd Counting</a></div><div><b>Author(s):&nbsp;</b>Qi Wang, Tao Han, Junyu Gao, Yuan Yuan</div><div><b>Pages:&nbsp;</b>3238 - 3250</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9340584/\">A Hybrid System Based on Dynamic Selection for Time Series Forecasting</a></div><div><b>Author(s):&nbsp;</b>Jo\u00e3o F. L. de Oliveira, Eraylson G. Silva, Paulo S. G. de Mattos Neto</div><div><b>Pages:&nbsp;</b>3251 - 3263</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9336312/\">Encoder-X: Solving Unknown Coefficients Automatically in Polynomial Fitting by Using an Autoencoder</a></div><div><b>Author(s):&nbsp;</b>Guojun Wang, Weijun Li, Liping Zhang, Linjun Sun, Peng Chen, Lina Yu, Xin Ning</div><div><b>Pages:&nbsp;</b>3264 - 3276</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9377649/\">DAMAD: Database, Attack, and Model Agnostic Adversarial Perturbation Detector</a></div><div><b>Author(s):&nbsp;</b>Akshay Agarwal, Gaurav Goswami, Mayank Vatsa, Richa Singh, Nalini K. Ratha</div><div><b>Pages:&nbsp;</b>3277 - 3289</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9336296/\">DQC-ADMM: Decentralized Dynamic ADMM With Quantized and Censored Communications</a></div><div><b>Author(s):&nbsp;</b>Yaohua Liu, Gang Wu, Zhi Tian, Qing Ling</div><div><b>Pages:&nbsp;</b>3290 - 3304</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9340243/\">Generalized Nonconvex Approach for Low-Tubal-Rank Tensor Recovery</a></div><div><b>Author(s):&nbsp;</b>Hailin Wang, Feng Zhang, Jianjun Wang, Tingwen Huang, Jianwen Huang, Xinling Liu</div><div><b>Pages:&nbsp;</b>3305 - 3319</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9339998/\">Deep Attention-Based Imbalanced Image Classification</a></div><div><b>Author(s):&nbsp;</b>Lituan Wang, Lei Zhang, Xiaofeng Qi, Zhang Yi</div><div><b>Pages:&nbsp;</b>3320 - 3330</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9337205/\">Adaptive Neural Network Control for Full-State Constrained Robotic Manipulator With Actuator Saturation and Time-Varying Delays</a></div><div><b>Author(s):&nbsp;</b>Weiwei Sun, You Wu, Xinyu Lv</div><div><b>Pages:&nbsp;</b>3331 - 3342</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9344656/\">Imbalanced Data Classification via Cooperative Interaction Between Classifier and Generator</a></div><div><b>Author(s):&nbsp;</b>Hyun-Soo Choi, Dahuin Jung, Siwon Kim, Sungroh Yoon</div><div><b>Pages:&nbsp;</b>3343 - 3356</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9345987/\">Parkinson\u2019s Disease Classification and Clinical Score Regression via United Embedding and Sparse Learning From Longitudinal Data</a></div><div><b>Author(s):&nbsp;</b>Zhongwei Huang, Haijun Lei, Guoliang Chen, Alejandro F. Frangi, Yanwu Xu, Ahmed Elazab, Jing Qin, Baiying Lei</div><div><b>Pages:&nbsp;</b>3357 - 3371</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9349201/\">Element-Wise Feature Relation Learning Network for Cross-Spectral Image Patch Matching</a></div><div><b>Author(s):&nbsp;</b>Dou Quan, Shuang Wang, Ning Huyan, Jocelyn Chanussot, Ruojing Wang, Xuefeng Liang, Biao Hou, Licheng Jiao</div><div><b>Pages:&nbsp;</b>3372 - 3386</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9344655/\">Temporal Encoding and Multispike Learning Framework for Efficient Recognition of Visual Patterns</a></div><div><b>Author(s):&nbsp;</b>Qiang Yu, Shiming Song, Chenxiang Ma, Jianguo Wei, Shengyong Chen, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>3387 - 3399</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9343714/\">Detachable Second-Order Pooling: Toward High-Performance First-Order Networks</a></div><div><b>Author(s):&nbsp;</b>Lida Li, Jiangtao Xie, Peihua Li, Lei Zhang</div><div><b>Pages:&nbsp;</b>3400 - 3414</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9340597/\">Solving Complex-Valued Time-Varying Linear Matrix Equations via QR Decomposition With Applications to Robotic Motion Tracking and on Angle-of-Arrival Localization</a></div><div><b>Author(s):&nbsp;</b>Vasilios N. Katsikis, Spyridon D. Mourtas, Predrag S. Stanimirovi\u0107, Yunong Zhang</div><div><b>Pages:&nbsp;</b>3415 - 3424</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9340611/\">Underexposed Image Correction via Hybrid Priors Navigated Deep Propagation</a></div><div><b>Author(s):&nbsp;</b>Risheng Liu, Long Ma, Yuxi Zhang, Xin Fan, Zhongxuan Luo</div><div><b>Pages:&nbsp;</b>3425 - 3436</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9352532/\">Theory-Inspired Deep Network for Instantaneous-Frequency Extraction and Subsignals Recovery From Discrete Blind-Source Data</a></div><div><b>Author(s):&nbsp;</b>Ningning Han, H. N. Mhaskar, Charles K. Chui</div><div><b>Pages:&nbsp;</b>3437 - 3447</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9343776/\">GenDet: Meta Learning to Generate Detectors From Few Shots</a></div><div><b>Author(s):&nbsp;</b>Liyang Liu, Bochao Wang, Zhanghui Kuang, Jing-Hao Xue, Yimin Chen, Wenming Yang, Qingmin Liao, Wayne Zhang</div><div><b>Pages:&nbsp;</b>3448 - 3460</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9344864/\">Distributed Group Coordination of Multiagent Systems in Cloud Computing Systems Using a Model-Free Adaptive Predictive Control Strategy</a></div><div><b>Author(s):&nbsp;</b>Haoran Tan, Yaonan Wang, Min Wu, Zhiwu Huang, Zhiqiang Miao</div><div><b>Pages:&nbsp;</b>3461 - 3473</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9343685/\">Adaptive NN-Based Consensus for a Class of Nonlinear Multiagent Systems With Actuator Faults and Faulty Networks</a></div><div><b>Author(s):&nbsp;</b>Xiaozheng Jin, Shaoyu L\u00fc, Jiguo Yu</div><div><b>Pages:&nbsp;</b>3474 - 3486</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9350111/\">Data-Driven Adaptive Consensus Learning From Network Topologies</a></div><div><b>Author(s):&nbsp;</b>Ronghu Chi, Yu Hui, Biao Huang, Zhongsheng Hou, Xuhui Bu</div><div><b>Pages:&nbsp;</b>3487 - 3497</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9344821/\">Adversarial Learning of Disentangled and Generalizable Representations of Visual Attributes</a></div><div><b>Author(s):&nbsp;</b>James Oldfield, Yannis Panagakis, Mihalis A. Nicolaou</div><div><b>Pages:&nbsp;</b>3498 - 3509</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9350110/\">Comparative Convolutional Dynamic Multi-Attention Recommendation Model</a></div><div><b>Author(s):&nbsp;</b>Juan Ni, Zhenhua Huang, Chang Yu, Dongdong Lv, Cheng Wang</div><div><b>Pages:&nbsp;</b>3510 - 3521</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9347827/\">Link Prediction Based on Stochastic Information Diffusion</a></div><div><b>Author(s):&nbsp;</b>Didier A. Vega-Oliveros, Liang Zhao, Anderson Rocha, Lilian Berton</div><div><b>Pages:&nbsp;</b>3522 - 3532</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9346019/\">A Convex Model for Support Vector Distance Metric Learning</a></div><div><b>Author(s):&nbsp;</b>Yibang Ruan, Yanshan Xiao, Zhifeng Hao, Bo Liu</div><div><b>Pages:&nbsp;</b>3533 - 3546</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9350205/\">RGB-D Point Cloud Registration Based on Salient Object Detection</a></div><div><b>Author(s):&nbsp;</b>Teng Wan, Shaoyi Du, Wenting Cui, Runzhao Yao, Yuyan Ge, Ce Li, Yue Gao, Nanning Zheng</div><div><b>Pages:&nbsp;</b>3547 - 3559</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9345932/\">Hierarchical-Bayesian-Based Sparse Stochastic Configuration Networks for Construction of Prediction Intervals</a></div><div><b>Author(s):&nbsp;</b>Jun Lu, Jinliang Ding, Changxin Liu, Tianyou Chai</div><div><b>Pages:&nbsp;</b>3560 - 3571</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9346050/\">Abnormal Event Detection and Localization via Adversarial Event Prediction</a></div><div><b>Author(s):&nbsp;</b>Jongmin Yu, Younkwan Lee, Kin Choong Yow, Moongu Jeon, Witold Pedrycz</div><div><b>Pages:&nbsp;</b>3572 - 3586</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9349966/\">Improving EEG Decoding via Clustering-Based Multitask Feature Learning</a></div><div><b>Author(s):&nbsp;</b>Yu Zhang, Tao Zhou, Wei Wu, Hua Xie, Hongru Zhu, Guoxu Zhou, Andrzej Cichocki</div><div><b>Pages:&nbsp;</b>3587 - 3597</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9350115/\">Neighborhood Geometric Structure-Preserving Variational Autoencoder for Smooth and Bounded Data Sources</a></div><div><b>Author(s):&nbsp;</b>Xingyu Chen, Chunyu Wang, Xuguang Lan, Nanning Zheng, Wenjun Zeng</div><div><b>Pages:&nbsp;</b>3598 - 3611</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9352534/\">Optimizing Attention for Sequence Modeling via Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Hao Fei, Yue Zhang, Yafeng Ren, Donghong Ji</div><div><b>Pages:&nbsp;</b>3612 - 3621</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9349207/\">Periodic Event-Triggered Synchronization for Discrete-Time Complex Dynamical Networks</a></div><div><b>Author(s):&nbsp;</b>Sanbo Ding, Zhanshan Wang, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>3622 - 3633</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9350196/\">Fast Unsupervised Projection for Large-Scale Data</a></div><div><b>Author(s):&nbsp;</b>Jingyu Wang, Lin Wang, Feiping Nie, Xuelong Li</div><div><b>Pages:&nbsp;</b>3634 - 3644</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9386270/\">Relaxed Block-Diagonal Dictionary Pair Learning With Locality Constraint for Image Recognition</a></div><div><b>Author(s):&nbsp;</b>Zhe Chen, Xiao-Jun Wu, Josef Kittler</div><div><b>Pages:&nbsp;</b>3645 - 3659</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9351670/\">Multiperspective Progressive Structure Adaptation for JPEG Steganography Detection Across Domains</a></div><div><b>Author(s):&nbsp;</b>Ju Jia, Meng Luo, Jinshuo Liu, Weixiang Ren, Lina Wang</div><div><b>Pages:&nbsp;</b>3660 - 3674</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9364887/\">Optimal Scale Combination Selection Integrating Three-Way Decision With Hasse Diagram</a></div><div><b>Author(s):&nbsp;</b>Qinghua Zhang, Yunlong Cheng, Fan Zhao, Guoyin Wang, Shuyin Xia</div><div><b>Pages:&nbsp;</b>3675 - 3689</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9350116/\">Networked Multiagent Systems: Antagonistic Interaction, Constraint, and its Application</a></div><div><b>Author(s):&nbsp;</b>Wentao Zhang, Zhiqiang Zuo, Yijing Wang</div><div><b>Pages:&nbsp;</b>3690 - 3699</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9350109/\">Dynamic Learning From Adaptive Neural Control for Discrete-Time Strict-Feedback Systems</a></div><div><b>Author(s):&nbsp;</b>Min Wang, Haotian Shi, Cong Wang, Jun Fu</div><div><b>Pages:&nbsp;</b>3700 - 3712</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9349163/\">Transductive Semisupervised Deep Hashing</a></div><div><b>Author(s):&nbsp;</b>Weiwei Shi, Yihong Gong, Badong Chen, Xinhong Hei</div><div><b>Pages:&nbsp;</b>3713 - 3726</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9349967/\">Surrogate-Assisted Particle Swarm Optimization for Evolving Variable-Length Transferable Blocks for Image Classification</a></div><div><b>Author(s):&nbsp;</b>Bin Wang, Bing Xue, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>3727 - 3740</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9351698/\">Target Tracking Control of a Biomimetic Underwater Vehicle Through Deep Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Yu Wang, Chong Tang, Shuo Wang, Long Cheng, Rui Wang, Min Tan, Zengguang Hou</div><div><b>Pages:&nbsp;</b>3741 - 3752</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9353398/\">Variational Inference and Learning of Piecewise Linear Dynamical Systems</a></div><div><b>Author(s):&nbsp;</b>Xavier Alameda-Pineda, Vincent Drouard, Radu Patrice Horaud</div><div><b>Pages:&nbsp;</b>3753 - 3764</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9352557/\">CRL: Collaborative Representation Learning by Coordinating Topic Modeling and Network Embeddings</a></div><div><b>Author(s):&nbsp;</b>Junyang Chen, Zhiguo Gong, Wei Wang, Weiwen Liu, Xiao Dong</div><div><b>Pages:&nbsp;</b>3765 - 3777</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9356334/\">Beneficial Perturbation Network for Designing General Adaptive Artificial Intelligence Systems</a></div><div><b>Author(s):&nbsp;</b>Shixian Wen, Amanda Rios, Yunhao Ge, Laurent Itti</div><div><b>Pages:&nbsp;</b>3778 - 3791</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9352543/\">A Plug-in Method for Representation Factorization in Connectionist Models</a></div><div><b>Author(s):&nbsp;</b>Jee Seok Yoon, Myung-Cheol Roh, Heung-Il Suk</div><div><b>Pages:&nbsp;</b>3792 - 3803</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9354049/\">Event-Based Design of Finite-Time Adaptive Control of Uncertain Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Yuan-Xin Li, Zhongsheng Hou, Wei-Wei Che, Zheng-Guang Wu</div><div><b>Pages:&nbsp;</b>3804 - 3813</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9352495/\">Motion Planning and Adaptive Neural Tracking Control of an Uncertain Two-Link Rigid\u2013Flexible Manipulator With Vibration Amplitude Constraint</a></div><div><b>Author(s):&nbsp;</b>Qingxin Meng, Xuzhi Lai, Ze Yan, Chun-Yi Su, Min Wu</div><div><b>Pages:&nbsp;</b>3814 - 3828</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9349196/\">Sampled-Data Synchronization of Stochastic Markovian Jump Neural Networks With Time-Varying Delay</a></div><div><b>Author(s):&nbsp;</b>Guoliang Chen, Jianwei Xia, Ju H. Park, Hao Shen, Guangming Zhuang</div><div><b>Pages:&nbsp;</b>3829 - 3841</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9350193/\">A Novel Sparse Graph-Regularized Singular Value Decomposition Model and Its Application to Genomic Data Analysis</a></div><div><b>Author(s):&nbsp;</b>Wenwen Min, Xiang Wan, Tsung-Hui Chang, Shihua Zhang</div><div><b>Pages:&nbsp;</b>3842 - 3856</div><div><br /></div><div><b>52)</b> <a href=\"https://ieeexplore.ieee.org/document/9352556/\">Concept Drift-Tolerant Transfer Learning in Dynamic Environments</a></div><div><b>Author(s):&nbsp;</b>Cuie Yang, Yiu-Ming Cheung, Jinliang Ding, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>3857 - 3871</div><div><br /></div><div><b>53)</b> <a href=\"https://ieeexplore.ieee.org/document/9354489/\">Data-Based Optimal Consensus Control for Multiagent Systems With Policy Gradient Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Xindi Yang, Hao Zhang, Zhuping Wang</div><div><b>Pages:&nbsp;</b>3872 - 3883</div><div><br /></div><div><b>54)</b> <a href=\"https://ieeexplore.ieee.org/document/9354502/\">Directional Deep Embedding and Appearance Learning for Fast Video Object Segmentation</a></div><div><b>Author(s):&nbsp;</b>Yingjie Yin, De Xu, Xingang Wang, Lei Zhang</div><div><b>Pages:&nbsp;</b>3884 - 3894</div><div><br /></div><div><b>55) </b><a href=\"https://ieeexplore.ieee.org/document/9358980/\">Multi-Manifold Optimization for Multi-View Subspace Clustering</a></div><div><b>Author(s):&nbsp;</b>Aparajita Khan, Pradipta Maji</div><div><b>Pages:&nbsp;</b>3895 - 3907</div><div><br /></div><div><b>56)</b> <a href=\"https://ieeexplore.ieee.org/document/9352535/\">Remote State Estimation of Nonlinear Systems Over Fading Channels via Recurrent Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Songfu Cai, Vincent K. N. Lau</div><div><b>Pages:&nbsp;</b>3908 - 3922</div><div><br /></div><div><b>57)</b> <a href=\"https://ieeexplore.ieee.org/document/9352501/\">Convolutional Neural Network for Behavioral Modeling and Predistortion of Wideband Power Amplifiers</a></div><div><b>Author(s):&nbsp;</b>Xin Hu, Zhijun Liu, Xiaofei Yu, Yulong Zhao, Wenhua Chen, Biao Hu, Xuekun Du, Xiang Li, Mohamed Helaoui, Weidong Wang, Fadhel M. Ghannouchi</div><div><b>Pages:&nbsp;</b>3923 - 3937</div><div><br /></div><div><b>58)</b> <a href=\"https://ieeexplore.ieee.org/document/9352485/\">Finite-Time Synchronization of Complex-Valued Memristive-Based Neural Networks via Hybrid Control</a></div><div><b>Author(s):&nbsp;</b>Tianhu Yu, Jinde Cao, Leszek Rutkowski, Yi-Ping Luo</div><div><b>Pages:&nbsp;</b>3938 - 3947</div><div><br /></div><div><b>59)</b> <a href=\"https://ieeexplore.ieee.org/document/9360311/\">Margin Distribution Analysis</a></div><div><b>Author(s):&nbsp;</b>Jun Wang, Zhi-Hua Zhou</div><div><b>Pages:&nbsp;</b>3948 - 3960</div><div><br /></div><div><b>60)</b> <a href=\"https://ieeexplore.ieee.org/document/9359364/\">Learning Knowledge Graph Embedding With Heterogeneous Relation Attention Networks</a></div><div><b>Author(s):&nbsp;</b>Zhifei Li, Hai Liu, Zhaoli Zhang, Tingting Liu, Neal N. Xiong</div><div><b>Pages:&nbsp;</b>3961 - 3973</div><div><br /></div><div><b>61)</b> <a href=\"https://ieeexplore.ieee.org/document/9354062/\">Toward Full-Stack Acceleration of Deep Convolutional Neural Networks on FPGAs</a></div><div><b>Author(s):&nbsp;</b>Shuanglong Liu, Hongxiang Fan, Martin Ferianc, Xinyu Niu, Huifeng Shi, Wayne Luk</div><div><b>Pages:&nbsp;</b>3974 - 3987</div><div><br /></div><div><b>62)</b> <a href=\"https://ieeexplore.ieee.org/document/9353400/\">Toward the Optimal Design and FPGA Implementation of Spiking Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Wenzhe Guo, Hasan Erdem Yant\u0131r, Mohammed E. Fouda, Ahmed M. Eltawil, Khaled Nabil Salama</div><div><b>Pages:&nbsp;</b>3988 - 4002</div><div><br /></div><div><b>63)</b> <a href=\"https://ieeexplore.ieee.org/document/9353402/\">Lifelong Incremental Reinforcement Learning With Online Bayesian Inference</a></div><div><b>Author(s):&nbsp;</b>Zhi Wang, Chunlin Chen, Daoyi Dong</div><div><b>Pages:&nbsp;</b>4003 - 4016</div><div><br /></div><div><b>64)</b> <a href=\"https://ieeexplore.ieee.org/document/9354503/\">Massive-Scale Aerial Photo Categorization by Cross-Resolution Visual Perception Enhancement</a></div><div><b>Author(s):&nbsp;</b>Luming Zhang, Xiaoqin Zhang, Mingliang Xu, Ling Shao</div><div><b>Pages:&nbsp;</b>4017 - 4030</div><div><br /></div><div><b>65)</b> <a href=\"https://ieeexplore.ieee.org/document/9353404/\">Global Negative Correlation Learning: A Unified Framework for Global Optimization of Ensemble Models</a></div><div><b>Author(s):&nbsp;</b>Carlos Perales-Gonz\u00e1lez, Francisco Fern\u00e1ndez-Navarro, Mariano Carbonero-Ruz, Javier P\u00e9rez-Rodr\u00edguez</div><div><b>Pages:&nbsp;</b>4031 - 4042</div><div><br /></div><div><b>66)</b> <a href=\"https://ieeexplore.ieee.org/document/9354488/\">Optimal Tracking Control of Nonlinear Multiagent Systems Using Internal Reinforce Q-Learning</a></div><div><b>Author(s):&nbsp;</b>Zhinan Peng, Rui Luo, Jiangping Hu, Kaibo Shi, Sing Kiong Nguang, Bijoy Kumar Ghosh</div><div><b>Pages:&nbsp;</b>4043 - 4055</div><div><br /></div><div><b>67)</b> <a href=\"https://ieeexplore.ieee.org/document/9369104/\">Multi-Task Weakly-Supervised Attention Network for Dementia Status Estimation With Structural MRI</a></div><div><b>Author(s):&nbsp;</b>Chunfeng Lian, Mingxia Liu, Li Wang, Dinggang Shen</div><div><b>Pages:&nbsp;</b>4056 - 4068</div><div><br /></div><div><b>68)</b> <a href=\"https://ieeexplore.ieee.org/document/9354493/\">FPGA-Based High-Throughput CNN Hardware Accelerator With High Computing Resource Utilization Ratio</a></div><div><b>Author(s):&nbsp;</b>Wenjin Huang, Huangtao Wu, Qingkun Chen, Conghui Luo, Shihao Zeng, Tianrui Li, Yihua Huang</div><div><b>Pages:&nbsp;</b>4069 - 4083</div><div><br /></div><div><b>69)</b> <a href=\"https://ieeexplore.ieee.org/document/9357939/\">Convolutional Ordinal Regression Forest for Image Ordinal Estimation</a></div><div><b>Author(s):&nbsp;</b>Haiping Zhu, Hongming Shan, Yuheng Zhang, Lingfu Che, Xiaoyang Xu, Junping Zhang, Jianbo Shi, Fei-Yue Wang</div><div><b>Pages:&nbsp;</b>4084 - 4095</div><div><br /></div><div><b>70)</b> <a href=\"https://ieeexplore.ieee.org/document/9353392/\">Spiking Neural Network Regularization With Fixed and Adaptive Drop-Keep Probabilities</a></div><div><b>Author(s):&nbsp;</b>Junhong Zhao, Jie Yang, Jun Wang, Wei Wu</div><div><b>Pages:&nbsp;</b>4096 - 4109</div><div><br /></div><div><b>71)</b> <a href=\"https://ieeexplore.ieee.org/document/9372892/\">Adversarial Binary Mutual Learning for Semi-Supervised Deep Hashing</a></div><div><b>Author(s):&nbsp;</b>Guan\u2019An Wang, Qinghao Hu, Yang Yang, Jian Cheng, Zeng-Guang Hou</div><div><b>Pages:&nbsp;</b>4110 - 4124</div><div><br /></div><div><b>72)</b> <a href=\"https://ieeexplore.ieee.org/document/9334410/\">Scalable Inverse Reinforcement Learning Through Multifidelity Bayesian Optimization</a></div><div><b>Author(s):&nbsp;</b>Mahdi Imani, Seyede Fatemeh Ghoreishi</div><div><b>Pages:&nbsp;</b>4125 - 4132</div><div><br /></div><div><b>73)</b> <a href=\"https://ieeexplore.ieee.org/document/9350113/\">Fixed-Time Synchronization of Competitive Neural Networks With Multiple Time Scales</a></div><div><b>Author(s):&nbsp;</b>Wu Yang, Yan-Wu Wang, Irinel-Constantin Mor\u01cerescu, Xiao-Kang Liu, Yuehua Huang</div><div><b>Pages:&nbsp;</b>4133 - 4138</div><div><br /></div><div><b>74)</b> <a href=\"https://ieeexplore.ieee.org/document/9345983/\">Online Reinforcement Learning Control by Direct Heuristic Dynamic Programming: From Time-Driven to Event-Driven</a></div><div><b>Author(s):&nbsp;</b>Qingtao Zhao, Jennie Si, Jian Sun</div><div><b>Pages:&nbsp;</b>4139 - 4144</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-08-19T12:00:00.235+12:00",
            "pubdate_parsed": [
                2022,
                8,
                19
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 18, September 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/09/soft-computing-volume-26-issue-18.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07292-5\">Specified keywords search scheme for EHR sharing</a></div><div><b>Author(s): </b>Shufen Niu, Fei Yu...Caifen Wang</div><div><b>Pages: </b>8949 - 8960</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07293-4\">Research on path planning algorithm of mobile robot based on reinforcement learning</a></div><div><b>Author(s):&nbsp;</b>Guoqian Pan, Yong Xiang...Xinzhi Zhou</div><div><b>Pages:&nbsp;</b>8961 - 8970</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07294-3\">Lattice-theoretic three-way formal contexts and their concepts</a></div><div><b>Author(s):&nbsp;</b>Ninghua Gao, Zixuan Cao...Haojie Jiang</div><div><b>Pages:&nbsp;</b>8971 - 8985</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07306-2\">Elitable GE-filters of bordered GE-algebras</a></div><div><b>Author(s):&nbsp;</b>Jeong-Gon Lee, Manzoor Kaleem Shaik...Young Bae Jun</div><div><b>Pages:&nbsp;</b>8987 - 8996</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07313-3\">Soft partial metric spaces</a></div><div><b>Author(s):&nbsp;</b>\u0130smet Alt\u0131nta\u015f, Kemal Ta\u015fk\u00f6pr\u00fc, Peyil Esengul kyzy</div><div><b>Pages:&nbsp;</b>8997 - 9010</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07254-x\">Fuzzy superior mandelbrot sets</a></div><div><b>Author(s):&nbsp;</b>Tahir Mahmood, Zeeshan Ali</div><div><b>Pages:&nbsp;</b>9011 - 9020</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07260-z\">Are finite affine topological systems worthy of study?</a></div><div><b>Author(s):&nbsp;</b>Jeffrey T. Denniston, Sergey A. Solovyov</div><div><b>Pages:&nbsp;</b>9021 - 9033</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07279-2\">Fuzzy membership function-dependent switched control for nonlinear systems with memory sampled-data information</a></div><div><b>Author(s):&nbsp;</b>B. Visakamoorthi, K. Subramanian, P. Muthukumar</div><div><b>Pages:&nbsp;</b>9035 - 9048</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07304-4\">Literature review on type-2 fuzzy set theory</a></div><div><b>Author(s):&nbsp;</b>Arnab Kumar De, Debjani Chakraborty, Animesh Biswas</div><div><b>Pages:&nbsp;</b>9049 - 9068</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07305-3\">On the shortest path problem of uncertain random digraphs</a></div><div><b>Author(s):&nbsp;</b>Hao Li, Kun Zhang</div><div><b>Pages:&nbsp;</b>9069 - 9081</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07307-1\">Dombi operations for linguistic T-spherical fuzzy number: an approach for selection of the best variety of maize</a></div><div><b>Author(s):&nbsp;</b>Shahid Hussain Gurmani, Huayou Chen, Yuhang Bai</div><div><b>Pages:&nbsp;</b>9083 - 9100</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07309-z\">Fuzzy entropy and hesitancy entropy in probabilistic hesitant fuzzy information and their applications</a></div><div><b>Author(s):&nbsp;</b>Ting-Ting Xu, Hui Zhang, Bo-Quan Li</div><div><b>Pages:&nbsp;</b>9101 - 9115</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07310-6\">A study on average run length of fuzzy EWMA control chart</a></div><div><b>Author(s):&nbsp;</b>Muhammad Zahir Khan, Muhammad Farid Khan...Abdur Razzaque Mughal</div><div><b>Pages:&nbsp;</b>9117 - 9124</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07346-8\">Fuzzy matrix game: A fast approach using artificial hybrid neural-net logic-gate switching circuit</a></div><div><b>Author(s):&nbsp;</b>Ankan Bhaumik, Sankar Kumar Roy</div><div><b>Pages:&nbsp;</b>9125 - 9135</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07347-7\">A Note on \u201cSolution of matrix games with payoffs of single-valued trapezoidal neutrosophic numbers\u201d</a></div><div><b>Author(s):&nbsp;</b>M. G. Brikaa</div><div><b>Pages:&nbsp;</b>9137 - 9139</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07265-8\">Detecting potholes on Indian roads using Haar feature-based cascade classifier, convolutional neural network, and instance segmentation</a></div><div><b>Author(s):&nbsp;</b>Satish Kumar Satti, K. Suganya Devi...P. Srinivasan</div><div><b>Pages:&nbsp;</b>9141 - 9153</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07275-6\">A deep learning approach for classification and diagnosis of Parkinson\u2019s disease</a></div><div><b>Author(s):&nbsp;</b>Monika Jyotiyana, Nishtha Kesswani...Munish Kumar</div><div><b>Pages:&nbsp;</b>9155 - 9165</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07277-4\">Repair missing data to improve corporate credit risk prediction accuracy with multi-layer perceptron</a></div><div><b>Author(s):&nbsp;</b>Mei Yang, Ming K. Lim...Du Ni</div><div><b>Pages:&nbsp;</b>9167 - 9178</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07331-1\">Back-propagation extreme learning machine</a></div><div><b>Author(s):&nbsp;</b>Weidong Zou, Yuanqing Xia, Weipeng Cao</div><div><b>Pages:&nbsp;</b>9179 - 9188</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07333-z\">Discriminative aging subspace learning for age estimation</a></div><div><b>Author(s):&nbsp;</b>Manisha Sawant, Kishor M. Bhurchandi</div><div><b>Pages:&nbsp;</b>9189 - 9198</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07343-x\">A fault identification method based on an ensemble deep neural network and a correlation coefficient</a></div><div><b>Author(s):&nbsp;</b>Yanli Yang, Yichuan He</div><div><b>Pages:&nbsp;</b>9199 - 9214</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07354-8\">Novel non-Kernel quadratic surface support vector machines based on optimal margin distribution</a></div><div><b>Author(s):&nbsp;</b>Jingyue Zhou, Ye Tian...Qianru Zhai</div><div><b>Pages:&nbsp;</b>9215 - 9227</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07219-0\">Modified grasshopper optimization algorithm-based genetic algorithm for global optimization problems: the system of nonlinear equations case study</a></div><div><b>Author(s):&nbsp;</b>Hala A. Omar, M. A. El-Shorbagy</div><div><b>Pages:&nbsp;</b>9229 - 9245</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07228-z\">Four adaptive grey prediction evolution algorithms with different types of parameters setting techniques</a></div><div><b>Author(s):&nbsp;</b>Cong Gao, Zhongbo Hu...Qinghua Su</div><div><b>Pages:&nbsp;</b>9247 - 9271</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07231-4\">The cost and CO2 emission optimization of reinforced concrete frames with non-prismatic members</a></div><div><b>Author(s):&nbsp;</b>A. KavehL. Mottaghi, R. A. Izadifard</div><div><b>Pages:&nbsp;</b>9273 - 9286</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07245-y\">Energy-aware and carbon-efficient VM placement optimization in cloud datacenters using evolutionary computing methods</a></div><div><b>Author(s):&nbsp;</b>Tahereh Abbasi-khazaeiMohammad Hossein Rezvani</div><div><b>Pages:&nbsp;</b>9287 - 9322</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07250-1\">S-GWO-FH: sparsity-based grey wolf optimization algorithm for face hallucination</a></div><div><b>Author(s):&nbsp;</b>Shyam Singh Rajput</div><div><b>Pages:&nbsp;</b>9323 - 9338</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07255-w\">An evolutionary optimization-based design of Smith delay compensator for cascade control of MIMO time-delay industrial process</a></div><div><b>Author(s):&nbsp;</b>Neelbrata Roy, Anindita Sengupta, Ashoke Sutradhar</div><div><b>Pages:&nbsp;</b>9339 - 9348</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07280-9\">Self-adaptive salp swarm algorithm for optimization problems</a></div><div><b>Author(s):&nbsp;</b>Sofian Kassaymeh, Salwani Abdullah...Zalinda Othman</div><div><b>Pages:&nbsp;</b>9349 - 9368</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07282-7\">Optimal operation and scheduling of a multi-generation microgrid using grasshopper optimization algorithm with cost reduction</a></div><div><b>Author(s):&nbsp;</b>Ziad M. Ali, Mujahed Al-Dhaifallah, Tetsuya Komikawa</div><div><b>Pages:&nbsp;</b>9369 - 9384</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07249-8\">Uncertain random portfolio optimization model with tail value-at-risk</a></div><div><b>Author(s):&nbsp;</b>Qiqi Li, Zhongfeng Qin, Yingchen Yan</div><div><b>Pages:&nbsp;</b>9385 - 9394</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07257-8\">Evaluating chaotic functions with flower pollination algorithm for modelling an optimized low complexity neural network based NAV predictor model</a></div><div><b>Author(s):&nbsp;</b>Smita Mohanty, Rajashree Dash</div><div><b>Pages:&nbsp;</b>9395 - 9417</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07259-6\">Intuitionistic fuzzy decision support based on EDAS and grey relational degree for historic bridges reconstruction priority</a></div><div><b>Author(s):&nbsp;</b>Katarina Rogulj, Jelena Kili\u0107 Pamukovi\u0107...Edmundas Kazimieras Zavadskas</div><div><b>Pages:&nbsp;</b>9419 - 9444</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07268-5\">A VIKOR-based group decision-making approach to software reliability evaluation</a></div><div><b>Author(s):&nbsp;</b>Chuan Yue</div><div><b>Pages:&nbsp;</b>9445 - 9464</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07272-9\">Multivariate uncertain risk aversion with application to accounts receivables pricing</a></div><div><b>Author(s):&nbsp;</b>Ke Wang, Xiaolin Huang...Jian Zhou</div><div><b>Pages:&nbsp;</b>9465 - 9480</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06704-2\">Prediction of the degree of steel corrosion damage in reinforced concrete using field-based data by multi-gene genetic programming approach</a></div><div><b>Author(s):&nbsp;</b>Zahra Rajabi, Mahdi Eftekhari...Hadi Beirami</div><div><b>Pages:&nbsp;</b>9481 - 9496</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06729-7\">Fuzzy dynamic parameter adaptation in the bird swarm algorithm for neural network optimization</a></div><div><b>Author(s):&nbsp;</b>Patricia Melin, Ivette Miramontes...German Prado-Arechiga</div><div><b>Pages:&nbsp;</b>9497 - 9514</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06731-7\">Techno-economic analysis for fertilizer house using hybrid power stations</a></div><div><b>Author(s):&nbsp;</b>Shiv Prakash Bihari, Pradip Kumar Sadhu</div><div><b>Pages:&nbsp;</b>9515 - 9525</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06735-3\">Creep parameter inversion for high CFRDs based on improved BP neural network response surface method</a></div><div><b>Author(s):&nbsp;</b>Xinjie Zhou, Xinjian Sun...Pengtao Zhang</div><div><b>Pages:&nbsp;</b>9527 - 9541</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06738-0\">Applying the Delphi and fuzzy DEMATEL methods for identification and prioritization of the variables affecting Iranian citrus exports to Russia</a></div><div><b>Author(s):&nbsp;</b>Seyyed Mehdi Hosseini, Yazdan Soltanpour, Mohammad Mahdi Paydar</div><div><b>Pages:&nbsp;</b>9543 - 9556</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06751-3\">Combining intrinsic dimension and local tangent space for manifold spectral clustering image segmentation</a></div><div><b>Author(s):&nbsp;</b>Xiaoling Yao, Rongguo Zhang...Jian Zhao</div><div><b>Pages:&nbsp;</b>9557 - 9572</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06777-7\">A novel application of fuzzy inference system optimized with particle swarm optimization and genetic algorithm for PM10 prediction</a></div><div><b>Author(s):&nbsp;</b>Jagriti Saini, Maitreyee Dutta, Gon\u00e7alo Marques</div><div><b>Pages:&nbsp;</b>9573 - 9586</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06786-6\">Computational personality: a survey</a></div><div><b>Author(s):&nbsp;</b>Liang Yang, Shuqun Li...Hongfei Lin</div><div><b>Pages:&nbsp;</b>9587 - 9605</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06789-3\">Stochastic coordination of the wind and solar energy using energy storage system based on real-time pricing</a></div><div><b>Author(s):&nbsp;</b>Sajjad Saeedi, S. M. Hassan Hosseini</div><div><b>Pages:&nbsp;</b>9607 - 9620</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06793-7\">Self-Attention Networks and Adaptive Support Vector Machine for aspect-level sentiment classification</a></div><div><b>Author(s):&nbsp;</b>Meizhen Liu, FengYu Zhou...HongChang Sun</div><div><b>Pages:&nbsp;</b>9621 - 9634</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06815-4\">Using deep reinforcement learning to search reachability properties in systems specified through graph transformation</a></div><div><b>Author(s):&nbsp;</b>Mohammad Javad Mehrabi, Vahid Rafe</div><div><b>Pages:&nbsp;</b>9635 - 9663</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06826-1\">A self-adaptive level-based learning artificial bee colony algorithm for feature selection on high-dimensional classification</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Yuanzi Zhang...Shiguo Huang</div><div><b>Pages:&nbsp;</b>9665 - 9687</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06828-z\">Creative DNA computing: splicing systems for music composition</a></div><div><b>Author(s):&nbsp;</b>Roberto De Prisco, Rocco Zaccagnino</div><div><b>Pages:&nbsp;</b>9689 - 9706</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06836-z\">A new statistical image watermark detector in RHFMs domain using beta-exponential distribution</a></div><div><b>Author(s):&nbsp;</b>Xiang-yang Wang, Pan-pan Niu...Jia-lin Tian</div><div><b>Pages:&nbsp;</b>9707 - 9727</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07211-8\">Quick flower pollination algorithm (QFPA) and its performance on neural network training</a></div><div><b>Author(s):&nbsp;</b>Ebubekir Kaya</div><div><b>Pages:&nbsp;</b>9729 - 9750</div><div><br /></div></div>",
            "pubdate": "2022-09-06T12:00:00.001+12:00",
            "pubdate_parsed": [
                2022,
                9,
                6
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 20, October 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/09/soft-computing-volume-26-issue-20.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07390-4\">Editorial on decision support system for development of intelligent applications</a></div><div><b>Author(s): </b>Shah Nazir, Habib Ullah Khan...Iv\u00e1n Garc\u00eda-Magari\u00f1o</div><div><b>Pages: </b>10547 - 10551</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06482-x\">A hybrid deep learning and ensemble learning mechanism for damaged power line detection in smart grids</a></div><div><b>Author(s):&nbsp;</b>Yangyang Tian, Qi Wang...Jian Zhao</div><div><b>Pages:&nbsp;</b>10553 - 10561</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06578-4\">EmoPercept: EEG-based emotion classification through perceiver</a></div><div><b>Author(s):&nbsp;</b>Aadam, Abdallah Tubaishat...Fawad Qayum</div><div><b>Pages:&nbsp;</b>10563 - 10570</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06659-4\">Design of enterprise human resources decision support system based on data mining</a></div><div><b>Author(s):&nbsp;</b>Li Jian</div><div><b>Pages:&nbsp;</b>10571 - 10580</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06689-y\">PlantNet: transfer learning-based fine-grained network for high-throughput plants recognition</a></div><div><b>Author(s):&nbsp;</b>Ziying Yang, Wenyan He...Tardi Tjahjadi</div><div><b>Pages:&nbsp;</b>10581 - 10590</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06709-x\">An intelligent deep learning-enabled recommendation algorithm for teaching music students</a></div><div><b>Author(s):&nbsp;</b>Changfei Tang, Jun Zhang</div><div><b>Pages:&nbsp;</b>10591 - 10598</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06720-2\">A network security posture assessment model based on binary semantic analysis</a></div><div><b>Author(s):&nbsp;</b>Dasheng Wu</div><div><b>Pages:&nbsp;</b>10599 - 10606</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06725-x\">Short-term prediction of wind power based on BiLSTM\u2013CNN\u2013WGAN-GP</a></div><div><b>Author(s):&nbsp;</b>Ling Huang, Linxia Li...Dongsheng Zhang</div><div><b>Pages:&nbsp;</b>10607 - 10621</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06747-z\">Application of machine learning in wire damage detection for safety procedure</a></div><div><b>Author(s):&nbsp;</b>Zhimin Guo, Chao Wang...Shaoguang Yuan</div><div><b>Pages:&nbsp;</b>10623 - 10631</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06780-y\">Heart disease diagnosis using deep learning and cardiac color doppler ultrasound</a></div><div><b>Author(s):&nbsp;</b>Jing Wang, Jing Li...Yan Huang</div><div><b>Pages:&nbsp;</b>10633 - 10642</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06788-4\">Tunable control of internet of things information hacking by application of the induced chiral atomic medium</a></div><div><b>Author(s):&nbsp;</b>Syed Muhammad Arif, Bakht Amin Bacha...Muhammad Haneef</div><div><b>Pages:&nbsp;</b>10643 - 10650</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06798-2\">Intrusion detection in networks using cuckoo search optimization</a></div><div><b>Author(s):&nbsp;</b>Muhammad Imran, Sangeen Khan...Sajid Anwar</div><div><b>Pages:&nbsp;</b>10651 - 10663</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06800-x\">Human resource labor dispatch model using an improved genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Qi Feng, Xingren Su, Qiang Li</div><div><b>Pages:&nbsp;</b>10665 - 10676</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06819-0\">Data news dissemination strategy for decision making using new media platform</a></div><div><b>Author(s):&nbsp;</b>Lu Li</div><div><b>Pages:&nbsp;</b>10677 - 10685</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06847-w\">Extended ICA and M-CSP with BiLSTM towards improved classification of EEG signals</a></div><div><b>Author(s):&nbsp;</b>Atta Ur Rahman, Abdallah Tubaishat...Fawad Qayum</div><div><b>Pages:&nbsp;</b>10687 - 10698</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06848-9\">Using neural network for the evaluation of physical education teaching in colleges and universities</a></div><div><b>Author(s):&nbsp;</b>Qiuhong Han</div><div><b>Pages:&nbsp;</b>10699 - 10705</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06875-6\">A reliable wireless communication mechanisms and decision support system for the IoT networks</a></div><div><b>Author(s):&nbsp;</b>Bo Jin, Fazlullah Khan...Mohammed Abdulaziz Ikram</div><div><b>Pages:&nbsp;</b>10707 - 1071</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06902-6\">Germ integrity detection for rice using a combination of germ color image features and deep learning</a></div><div><b>Author(s):&nbsp;</b>Jin Li, Shuofeng Li...Bin Liu</div><div><b>Pages:&nbsp;</b>10717 - 10727</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06936-w\">Design and realization of CNC machine tool management system using Internet of things</a></div><div><b>Author(s):&nbsp;</b>Pei Shicong, Wu Guocheng, Tao Fuqiang</div><div><b>Pages:&nbsp;</b>10729 - 10739</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06957-5\">A decision support system for assessing the role of the 5G network and AI in situational teaching research in higher education</a></div><div><b>Author(s):&nbsp;</b>Xiaoshuang Liu, Mohammad Faisal, Abdullah Alharbi</div><div><b>Pages:&nbsp;</b>10741 - 10752</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06962-8\">Construction of business innovation model for sports industry using a deep learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Chenchen Lv, Yifeng Wang, Yin Ma</div><div><b>Pages:&nbsp;</b>10753 - 10763</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06983-3\">Evaluation of physical education classes in colleges and universities using machine learning</a></div><div><b>Author(s):&nbsp;</b>Chendi Hu</div><div><b>Pages:&nbsp;</b>10765 - 10773</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06992-2\">Decision support system for evaluating the role of music in network-based game for sustaining effectiveness</a></div><div><b>Author(s):&nbsp;</b>Yanli Yu, Dong Wang...Sumaira Johar</div><div><b>Pages:&nbsp;</b>10775 - 10788</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06993-1\">A comprehensive review on the role of online media in sustainable business development and decision making</a></div><div><b>Author(s):&nbsp;</b>Haiyu He</div><div><b>Pages:&nbsp;</b>10789 - 10803</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07003-0\">Research on evaluation system of ideological and political education of college students based on decision system</a></div><div><b>Author(s):&nbsp;</b>Zhang Rui</div><div><b>Pages:&nbsp;</b>10805 - 10812</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07018-7\">A deep neural network-based decision support system for intelligent geospatial data analysis in intelligent agriculture system</a></div><div><b>Author(s):&nbsp;</b>Chunying Zeng, Fan Zhang, Mingzhong Luo</div><div><b>Pages:&nbsp;</b>10813 - 10826</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07019-6\">Optimized design of oil well pump plunger using bionic structure of decision system</a></div><div><b>Author(s):&nbsp;</b>Bo Wang, Mengji Chen...Jinfeng Wei</div><div><b>Pages:&nbsp;</b>10827 - 10836</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07046-3\">Prediction of thawing settlement coefficient of frozen soil using 5G communication</a></div><div><b>Author(s):&nbsp;</b>Yueming Yin, Chaoqun Wei...Qinglu Deng</div><div><b>Pages:&nbsp;</b>10837 - 10852</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07082-z\">The role of big data in network public opinion within the colleges and universities</a></div><div><b>Author(s):&nbsp;</b>Bin Xu, Ying Liu</div><div><b>Pages:&nbsp;</b>10853 - 10862</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07083-y\">Prediction algorithm and simulation of tennis impact area based on semantic analysis of prior knowledge</a></div><div><b>Author(s):&nbsp;</b>Yong Ke, Zhen Liu, Sai Liu</div><div><b>Pages:&nbsp;</b>10863 - 10870</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07086-9\">An assisted teaching algorithm for basketball shooting based on object decomposition</a></div><div><b>Author(s):&nbsp;</b>Xixiao Liu, Xuyun Xi</div><div><b>Pages:&nbsp;</b>10871 - 10878</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07106-8\">Improved YOLOv5 network method for remote sensing image-based ground objects recognition</a></div><div><b>Author(s):&nbsp;</b>Jie Xue, Yongguo Zheng...Muhammad Yasir</div><div><b>Pages:&nbsp;</b>10879 - 10889</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07144-2\">Teaching English as a foreign language using the Internet and multimedia environment</a></div><div><b>Author(s):&nbsp;</b>Lina Liang</div><div><b>Pages:&nbsp;</b>10891 - 10902</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07156-y\">Designing an interactive teaching model of English language using Internet of Things</a></div><div><b>Author(s):&nbsp;</b>Wei Gao</div><div><b>Pages:&nbsp;</b>10903 - 10913</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07197-3\">Decision support system for real-time segmentation and identification algorithm for wires in mobile terminals using fuzzy AHP method</a></div><div><b>Author(s):&nbsp;</b>Lei Wang, Mingyue Chu...Guanlong Gao</div><div><b>Pages:&nbsp;</b>10915 - 10926</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07209-2\">AI-based production and application of English multimode online reading using multi-criteria decision support system</a></div><div><b>Author(s):&nbsp;</b>Yifan Dong, Xinyu Yu...Sultan Ahmad</div><div><b>Pages:&nbsp;</b>10927 - 10937</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07210-9\">Football training evaluation using machine learning and decision support system</a></div><div><b>Author(s):&nbsp;</b>Qiangqiang Xu, Xin He</div><div><b>Pages:&nbsp;</b>10939 - 10946</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07240-3\">Key technologies of human\u2013computer interaction for immersive somatosensory interactive games using VR technology</a></div><div><b>Author(s):&nbsp;</b>Peng Gao</div><div><b>Pages:&nbsp;</b>10947 - 10956</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07247-w\">Information technology-based revolution in music education using AHP and TOPSIS</a></div><div><b>Author(s):&nbsp;</b>Yi Fu, Mengjia Zhang...Aman Singh</div><div><b>Pages:&nbsp;</b>10957 - 10970</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07295-2\">Application of deep learning in video target tracking of soccer players</a></div><div><b>Author(s):&nbsp;</b>Xin He</div><div><b>Pages:&nbsp;</b>10971 - 10979</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07317-z\">Joint training method for transmission defects based on component hierarchy</a></div><div><b>Author(s):&nbsp;</b>Wang Chao, Tian Yangyang...Tan Qiyun</div><div><b>Pages:&nbsp;</b>10981 - 10992</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07352-w\">Cost estimate in scrum project with the decision-based effort estimation technique</a></div><div><b>Author(s):&nbsp;</b>Fahad H. Alshammari</div><div><b>Pages:&nbsp;</b>10993 - 11005</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07396-y\">A decision support system based on multi-sources information to predict piRNA\u2013disease associations using stacked autoencoder</a></div><div><b>Author(s):&nbsp;</b>Kai Zheng, Ying Liang...Ping Wang</div><div><b>Pages:&nbsp;</b>11007 - 11016</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07398-w\">Sustainable configuration paths of marine eco-efficiency: based on fuzzy-set qualitative comparative analysis of 11 coastal areas in China</a></div><div><b>Author(s):&nbsp;</b>Zhenyu Huang</div><div><b>Pages:&nbsp;</b>11017 - 11032</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07399-9\">Decision support system based on spatial and temporal pattern evolution of ecological environmental quality in the Yellow River Delta from 2000 to 2020</a></div><div><b>Author(s):&nbsp;</b>Xin Zhao, Ping Wang...Zhan Liu</div><div><b>Pages:&nbsp;</b>11033 - 11044</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07400-5\">A comprehensive analysis of the impact of online media and newsprint on advertising sales in the information society</a></div><div><b>Author(s):&nbsp;</b>Keyan Xu, Mengjun Xie...Noha Alnazzawi</div><div><b>Pages:&nbsp;</b>11045 - 11062</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07401-4\">A decision-support system for assessing the function of machine learning and artificial intelligence in music education for network games</a></div><div><b>Author(s):&nbsp;</b>Zou Hong Yun, Yasser Alshehri...Neelam Gohar</div><div><b>Pages:&nbsp;</b>11063 - 11075</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07405-0\">Adapting recurrent neural networks for classifying public discourse on COVID-19 symptoms in Twitter content</a></div><div><b>Author(s):&nbsp;</b>Samina Amin, Abdullah Alharbi...Hashem Alyami</div><div><b>Pages:&nbsp;</b>11077 - 11089</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07475-0\">TinyLFU-based semi-stream cache join for near-real-time data warehousing</a></div><div><b>Author(s):&nbsp;</b>M. Asif Naeem, Wasiullah Waqar...Ali Tahir</div><div><b>Pages:&nbsp;</b>11091 - 11103</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07493-y\">Performance evaluation of state-owned enterprises based on fuzzy neural network combination model</a></div><div><b>Author(s):&nbsp;</b>Wenhao Jiao</div><div><b>Pages:&nbsp;</b>11105 - 11113</div><div><br /></div></div>",
            "pubdate": "2022-09-28T17:22:00.000+13:00",
            "pubdate_parsed": [
                2022,
                9,
                28
            ],
            "email_sent": true
        },
        "IEEE Transactions on Emerging Topics in Computational Intelligence, Volume 6, Issue 5, October 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/09/ieee-transactions-on-emerging-topics-in.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9900111/\">Guest Editorial Special Issue on Computational Intelligence in Big Graph Data Management</a></div><div><b>Author(s): </b>Guanfeng Liu, An Liu, Qing Li, Huanhuan Chen, Deepak Puthal</div><div><b>Pages: </b>1027 - 1029</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9581056/\">Optimal Searching Time Allocation for Information Collection Under Cooperative Path Planning of Multiple UAVs</a></div><div><b>Author(s):&nbsp;</b>Yanmin Li, Lihua Liu, Jibing Wu, Mao Wang, Haohao Zhou, Hongbin Huang</div><div><b>Pages:&nbsp;</b>1030 - 1043</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9548676/\">Compactness Preserving Community Computation Via a Network Generative Process</a></div><div><b>Author(s):&nbsp;</b>Jie Cao, Yuyao Wang, Zhan Bu, Youquan Wang, Haicheng Tao, Guixiang Zhu</div><div><b>Pages:&nbsp;</b>1044 - 1056</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9691281/\">Interval-Valued Intuitionistic Fuzzy Decision With Graph Pattern in Big Graph</a></div><div><b>Author(s):&nbsp;</b>Lei Li, Lan Jiang, Chenyang Bu, Yi Zhu, Xindong Wu</div><div><b>Pages:&nbsp;</b>1057 - 1067</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9695487/\">Wavefront-Based Multiple Rumor Sources Identification by Multi-Task Learning</a></div><div><b>Author(s):&nbsp;</b>Ming Dong, Bolong Zheng, Guohui Li, Chenliang Li, Kai Zheng, Xiaofang Zhou</div><div><b>Pages:&nbsp;</b>1068 - 1078</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9739062/\">Attraction and Repulsion: Unsupervised Domain Adaptive Graph Contrastive Learning Network</a></div><div><b>Author(s):&nbsp;</b>Man Wu, Shirui Pan, Xingquan Zhu</div><div><b>Pages:&nbsp;</b>1079 - 1091</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9735156/\">Understand Me, if You Refer to Aspect Knowledge: Knowledge-Aware Gated Recurrent Memory Network</a></div><div><b>Author(s):&nbsp;</b>Bowen Xing, Ivor W. Tsang</div><div><b>Pages:&nbsp;</b>1092 - 1102</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9714726/\">Self-Consistent Learning of Neural Dynamical Systems From Noisy Time Series</a></div><div><b>Author(s):&nbsp;</b>Zhe Wang, Claude Guet</div><div><b>Pages:&nbsp;</b>1103 - 1112</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9713759/\">Heterogeneous Semi-Asynchronous Federated Learning in Internet of Things: A Multi-Armed Bandit Approach</a></div><div><b>Author(s):&nbsp;</b>Shuai Chen, Xiumin Wang, Pan Zhou, Weiwei Wu, Weiwei Lin, Zhenyu Wang</div><div><b>Pages:&nbsp;</b>1113 - 1124</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9712301/\">Behavior Reasoning for Opponent Agents in Multi-Agent Learning Systems</a></div><div><b>Author(s):&nbsp;</b>Yaqing Hou, Mingyang Sun, Wenxuan Zhu, Yifeng Zeng, Haiyin Piao, Xuefeng Chen, Qiang Zhang</div><div><b>Pages:&nbsp;</b>1125 - 1136</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9674744/\">Annotating Motion Primitives for Simplifying Action Search in Reinforcement Learning</a></div><div><b>Author(s):&nbsp;</b>Isaac J. Sledge, Darshan W. Bryner, Jos\u00e9 C. Pr\u00edncipe</div><div><b>Pages:&nbsp;</b>1137 - 1156</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9749857/\">RSAC: A Robust Deep Reinforcement Learning Strategy for Dimensionality Perturbation</a></div><div><b>Author(s):&nbsp;</b>Surbhi Gupta, Gaurav Singal, Deepak Garg, Swagatam Das</div><div><b>Pages:&nbsp;</b>1157 - 1166</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9669910/\">Triple Cross-Domain Attention on Human Activity Recognition Using Wearable Sensors</a></div><div><b>Author(s):&nbsp;</b>Yin Tang, Lei Zhang, Qi Teng, Fuhong Min, Aiguo Song</div><div><b>Pages:&nbsp;</b>1167 - 1176</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9714727/\">Motor Imagery BCI Classification Based on Multivariate Variational Mode Decomposition</a></div><div><b>Author(s):&nbsp;</b>Muhammad Tariq Sadiq, Xiaojun Yu, Zhaohui Yuan, Muhammad Zulkifal Aziz, Naveed ur Rehman, Weiping Ding, Gaoxi Xiao</div><div><b>Pages:&nbsp;</b>1177 - 1189</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9343762/\">Multi-Crop Convolutional Neural Networks for Fast Lung Nodule Segmentation</a></div><div><b>Author(s):&nbsp;</b>Quan Chen, Wei Xie, Pan Zhou, Chuansheng Zheng, Dapeng Wu</div><div><b>Pages:&nbsp;</b>1190 - 1200</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9711563/\">Feature Pyramid Network With Level-Aware Attention for Meningioma Segmentation</a></div><div><b>Author(s):&nbsp;</b>Wei Huang, Xin Shu, Zizhou Wang, Lei Zhang, Chaoyue Chen, Jianguo Xu, Zhang Yi</div><div><b>Pages:&nbsp;</b>1201 - 1210</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9631874/\">Attributes Guided Feature Learning for Vehicle Re-Identification</a></div><div><b>Author(s):&nbsp;</b>Hongchao Li, Xianmin Lin, Aihua Zheng, Chenglong Li, Bin Luo, Ran He, Amir Hussain</div><div><b>Pages:&nbsp;</b>1211 - 1221</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9762457/\">Local Visual and Global Deep Features Based Blind Stitched Panoramic Image Quality Evaluation Using Ensemble Learning</a></div><div><b>Author(s):&nbsp;</b>Yueli Cui, Gangyi Jiang, Mei Yu, Yang Song</div><div><b>Pages:&nbsp;</b>1222 - 1236</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9803821/\">Unsupervised Monocular Depth Estimation in Highly Complex Environments</a></div><div><b>Author(s):&nbsp;</b>Chaoqiang Zhao, Yang Tang, Qiyu Sun</div><div><b>Pages:&nbsp;</b>1237 - 1246</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9638990/\">Minable Data Publication Based on Sensitive Association Rule Hiding</a></div><div><b>Author(s):&nbsp;</b>Fan Yang, Xinyu Lei, Junqing Le, Nankun Mu, Xiaofeng Liao</div><div><b>Pages:&nbsp;</b>1247 - 1257</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9726514/\">ES Attack: Model Stealing Against Deep Neural Networks Without Data Hurdles</a></div><div><b>Author(s):&nbsp;</b>Xiaoyong Yuan, Leah Ding, Lan Zhang, Xiaolin Li, Dapeng Oliver Wu</div><div><b>Pages:&nbsp;</b>1258 - 1270</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9718120/\">Adaptive Evolution Strategies for Stochastic Zeroth-Order Optimization</a></div><div><b>Author(s):&nbsp;</b>Xiaoyu He, Zibin Zheng, Zefeng Chen, Yuren Zhou</div><div><b>Pages:&nbsp;</b>1271 - 1285</div><div><br /></div></div>",
            "pubdate": "2022-09-29T21:24:00.000+13:00",
            "pubdate_parsed": [
                2022,
                9,
                29
            ],
            "email_sent": true
        },
        "Complex & Intelligent Systems. Volume 8, Issue 5, October 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/10/complex-intelligent-systems-volume-8.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00821-7\">Intelligent mobile edge computing for IoT big data</a></div><div><b>Author(s): </b>Gwanggil Jeon, Marcelo Albertini...Abdellah Chehri</div><div><b>Pages: </b>3595 - 3601</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00393-y\">Span identification and technique classification of propaganda in news articles</a></div><div><b>Author(s):&nbsp;</b>Wei Li, Shiqian Li...Shiping Wen</div><div><b>Pages:&nbsp;</b>3603 - 3612</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00397-8\">Evaluation of deep learning algorithms for semantic segmentation of car parts</a></div><div><b>Author(s):&nbsp;</b>Kitsuchart Pasupa, Phongsathorn Kittiworapanya...Kuntpong Woraratpanya</div><div><b>Pages:&nbsp;</b>3613 - 3625</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00419-5\">License plate identification and recognition in a non-standard environment using neural pattern matching</a></div><div><b>Author(s):&nbsp;</b>Imran Shafi, Imtiaz Hussain...Sadia Din</div><div><b>Pages:&nbsp;</b>3627 - 3639</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00434-6\">Implementation analysis of IoT-based offloading frameworks on cloud/edge computing for sensor generated big data</a></div><div><b>Author(s):&nbsp;</b>Karan Bajaj, Bhisham Sharma, Raman Singh</div><div><b>Pages:&nbsp;</b>3641 - 3658</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00447-1\">Supporting autism spectrum disorder screening and intervention with machine learning and wearables: a systematic literature review</a></div><div><b>Author(s):&nbsp;</b>Rita Francese, Xiaomin Yang</div><div><b>Pages:&nbsp;</b>3659 - 3674</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00455-1\">DRAC: a delta recurrent neural network-based arithmetic coding algorithm for edge computing</a></div><div><b>Author(s):&nbsp;</b>Bowei Shan, Yong Fang</div><div><b>Pages:&nbsp;</b>3675 - 3681</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00483-x\">A survey on computation resource allocation in IoT enabled vehicular edge computing</a></div><div><b>Author(s):&nbsp;</b>Naren, Abhishek Kumar Gaurav...Vinay Chamola</div><div><b>Pages:&nbsp;</b>3683 - 3705</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00466-y\">Blockchain-based green big data visualization: BGbV</a></div><div><b>Author(s):&nbsp;</b>Iqra Shahzad, Ayesha Maqbool...Sadia Din</div><div><b>Pages:&nbsp;</b>3707 - 3718</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00498-4\">An edge based hybrid intrusion detection framework for mobile edge computing</a></div><div><b>Author(s):&nbsp;</b>Ashish Singh, Kakali Chatterjee, Suresh Chandra Satapathy</div><div><b>Pages:&nbsp;</b>3719 - 3746</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00518-3\">A novel trust management model for edge computing</a></div><div><b>Author(s):&nbsp;</b>Rabia Latif, Malik Uzair Ahmed...Awais Ahmad</div><div><b>Pages:&nbsp;</b>3747 - 3763</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00544-1\">Spatio-temporal joint aberrance suppressed correlation filter for visual tracking</a></div><div><b>Author(s):&nbsp;</b>Libin Xu, Pyoungwon Kim...Mingliang Gao</div><div><b>Pages:&nbsp;</b>3765 - 3777</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00578-5\">SHANN: an IoT and machine-learning-assisted edge cross-layered routing protocol using spotted hyena optimizer</a></div><div><b>Author(s):&nbsp;</b>Gaurav Dhiman, Rohit Sharma</div><div><b>Pages:&nbsp;</b>3779 - 3787</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00581-w\">Cloud\u2013edge cooperation for meteorological radar big data: a review of data quality control</a></div><div><b>Author(s):&nbsp;</b>Zhichen Hu, Xiaolong Xu...Mohammad R. Khosravi</div><div><b>Pages:&nbsp;</b>3789 - 3803</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00582-9\">Smart healthcare IoT applications based on fog computing: architecture, applications and challenges</a></div><div><b>Author(s):&nbsp;</b>Vu Khanh Quy, Nguyen Van Hau...Le Anh Ngoc</div><div><b>Pages:&nbsp;</b>3805 - 3815</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00576-7\">Secure transmission technique for data in IoT edge computing infrastructure</a></div><div><b>Author(s):&nbsp;</b>Rohit Sharma, Rajeev Arya</div><div><b>Pages:&nbsp;</b>3817 - 3832</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00618-0\">Semantic segmentation of large-scale point clouds based on dilated nearest neighbors graph</a></div><div><b>Author(s):&nbsp;</b>Lei Wang, Jiaji Wu...Jun Cheng</div><div><b>Pages:&nbsp;</b>3833 - 3845</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00659-z\">Decision-making of IoT device operation based on intelligent-task offloading for improving environmental optimization</a></div><div><b>Author(s):&nbsp;</b>Wenquan Jin, Sunhwan Lim...Dohyeun Kim</div><div><b>Pages:&nbsp;</b>3847 - 3866</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00666-0\">Energy-saving service management technology of internet of things using edge computing and deep learning</a></div><div><b>Author(s):&nbsp;</b>Defeng Li, Mingming Lan, Yuan Hu</div><div><b>Pages:&nbsp;</b>3867 - 3879</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00683-z\">Ship feature recognition methods for deep learning in complex marine environments</a></div><div><b>Author(s):&nbsp;</b>Xiang Wang, Jingxian Liu...Quan Ouyang</div><div><b>Pages:&nbsp;</b>3881 - 3897</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00664-2\">Counseling (ro)bot as a use case for 5G/6G</a></div><div><b>Author(s):&nbsp;</b>Yoshio Taniguchi, Yukino Ikegami...Setsuo Tsuruta</div><div><b>Pages:&nbsp;</b>3899 - 3917</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00765-y\">Authorization schemes for internet of things: requirements, weaknesses, future challenges and trends</a></div><div><b>Author(s):&nbsp;</b>Abid Khan, Awais Ahmad...Marco Anisetti</div><div><b>Pages:&nbsp;</b>3919 - 3941</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00735-4\">Research on energy saving technology at mobile edge networks of IoTs based on big data analysis</a></div><div><b>Author(s):&nbsp;</b>Chaochen Xie, Qiaozhi Hua...Lixia Guo</div><div><b>Pages:&nbsp;</b>3943 - 3952</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00775-w\">A methodology to engineering continuous monitoring of intrinsic capacity for elderly people</a></div><div><b>Author(s):&nbsp;</b>Valerio Bellandi, Paolo Ceravolo...Mircea Dan Marzan</div><div><b>Pages:&nbsp;</b>3953 - 3971</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00635-z\">Tourism route optimization based on improved knowledge ant colony algorithm</a></div><div><b>Author(s):&nbsp;</b>Sidi Li, Tianyu Luo...Teng Ren</div><div><b>Pages:&nbsp;</b>3973 - 3988</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00640-2\">An estimation of distribution algorithm with clustering for scenario-based robust financial optimization</a></div><div><b>Author(s):&nbsp;</b>Wen Shi, Xiao-Min Hu, Wei-Neng Chen</div><div><b>Pages:&nbsp;</b>3989 - 4003</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00692-y\">Joint metric learning of local and global features for vehicle re-identification</a></div><div><b>Author(s):&nbsp;</b>Junge Shen, Jian Sun...Zhaoyong Mao</div><div><b>Pages:&nbsp;</b>4005 - 4020</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00687-9\">Fuzzy efficiency evaluation in relational network data envelopment analysis: application in gas refineries</a></div><div><b>Author(s):&nbsp;</b>Somayeh Tabatabaei, Mohammad Reza Mozaffari...Farhad Hosseinzadeh Lotfi</div><div><b>Pages:&nbsp;</b>4021 - 4049</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00697-7\">A conjugate gradient-assisted multi-objective evolutionary algorithm for fluence map optimization in radiotherapy treatment</a></div><div><b>Author(s):&nbsp;</b>Ruifen Cao, Langchun Si...Xingyi Zhang</div><div><b>Pages:&nbsp;</b>4051 - 4077</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00698-6\">A new neutrosophic model using DUS-Weibull transformation with application</a></div><div><b>Author(s):&nbsp;</b>B. M. Nayana, K. K. Anakha...Mohammed Albassam</div><div><b>Pages:&nbsp;</b>4079 - 4088</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00702-z\">Manifold learning for novelty detection and its application in gesture recognition</a></div><div><b>Author(s):&nbsp;</b>Yang Luo, Yibiao Yuan...Xiaohui Mo</div><div><b>Pages:&nbsp;</b>4089 - 4100</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00704-x\">Topological approach to generate new rough set models</a></div><div><b>Author(s):&nbsp;</b>Tareq M. Al-shami</div><div><b>Pages:&nbsp;</b>4101 - 4113</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00686-w\">Carbon mechanism on sustainable multi-objective solid transportation problem for waste management in Pythagorean hesitant fuzzy environment</a></div><div><b>Author(s):&nbsp;</b>Shyamali Ghosh, Karl-Heinz K\u00fcfer...Gerhard-Wilhelm Weber</div><div><b>Pages:&nbsp;</b>4115 - 4143</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00700-1\">Predicting vacant parking space availability zone-wisely: a hybrid deep learning approach</a></div><div><b>Author(s):&nbsp;</b>Yajing Feng, Yingying Xu...Zhenzhou Tang</div><div><b>Pages:&nbsp;</b>4145 - 4161</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00709-6\">Joint uneven channel information network with blend metric loss for person re-identification</a></div><div><b>Author(s):&nbsp;</b>Zhi Yu, Zhiyong Huang...Daming Sun</div><div><b>Pages:&nbsp;</b>4163 - 4175</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00710-z\">A multi-attribute approach to ranking departments based on performance: a balanced scorecard pilot study</a></div><div><b>Author(s):&nbsp;</b>U\u011fur Tahsin \u015eenel, Babak Daneshvar Rouyendegh, Sercan Demir</div><div><b>Pages:&nbsp;</b>4177 - 4185</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00691-z\">Evaluation and selection of green suppliers for papermaking enterprises using the interval basic probability assignment-based intuitionistic fuzzy set</a></div><div><b>Author(s):&nbsp;</b>Xin Kang, Xiangjun Xu...Zaoli Yang</div><div><b>Pages:&nbsp;</b>4187 - 4203</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00695-9\">Anomaly detection for high-dimensional space using deep hypersphere fused with probability approach</a></div><div><b>Author(s):&nbsp;</b>Jian Zheng, Jingyi Li...Hongling Liu</div><div><b>Pages:&nbsp;</b>4205 - 4220</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00705-w\">A federated learning framework for cyberattack detection in vehicular sensor networks</a></div><div><b>Author(s):&nbsp;</b>Maha Driss, Iman Almomani...Jawad Ahmad</div><div><b>Pages:&nbsp;</b>4221 - 4235</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00713-w\">A DCRNN-based ensemble classifier for speech emotion recognition in Odia language</a></div><div><b>Author(s):&nbsp;</b>Monorama Swain, Bubai Maji...Aurobinda Routray</div><div><b>Pages:&nbsp;</b>4237 - 4249</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00712-x\">Interactive spatio-temporal feature learning network for video foreground detection</a></div><div><b>Author(s):&nbsp;</b>Hongrui Zhang, Huan Li</div><div><b>Pages:&nbsp;</b>4251 - 4263</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00711-y\">Hierarchical edge-aware network for defocus blur detection</a></div><div><b>Author(s):&nbsp;</b>Zijian Zhao, Hang Yang, Huiyuan Luo</div><div><b>Pages:&nbsp;</b>4265 - 4276</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00706-9\">A knee point-driven many-objective pigeon-inspired optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>Lihong Zhao, Yeqing Ren...Wensheng Zhang</div><div><b>Pages:&nbsp;</b>4277 - 4299</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00715-8\">Multiobjective portfolio optimization via Pareto front evolution</a></div><div><b>Author(s):&nbsp;</b>Yi Chen, Aimin Zhou</div><div><b>Pages:&nbsp;</b>4301 - 4317</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00690-0\">Time-sequential hesitant fuzzy set and its application to multi-attribute decision making</a></div><div><b>Author(s):&nbsp;</b>Lingyu Meng, Liangqun Li</div><div><b>Pages:&nbsp;</b>4319 - 4338</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00717-6\">An adaptive model switch-based surrogate-assisted evolutionary algorithm for noisy expensive multi-objective optimization</a></div><div><b>Author(s):&nbsp;</b>Nan Zheng, Handing Wang, Bo Yuan</div><div><b>Pages:&nbsp;</b>4339 - 4356</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00708-7\">Source code auto-completion using various deep learning models under limited computing resources</a></div><div><b>Author(s):&nbsp;</b>Madhab Sharma, Tapas Kumar Mishra, Arun Kumar</div><div><b>Pages:&nbsp;</b>4357 - 4368</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00696-8\">Implicit optimal variational collaborative filtering</a></div><div><b>Author(s):&nbsp;</b>Joojo Walker, Fan Zhou...Fengli Zhang</div><div><b>Pages:&nbsp;</b>4369 - 4384</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00789-4\">Design of sampling-based noniterative algorithms for centroid type-reduction of general type-2 fuzzy logic systems</a></div><div><b>Author(s):&nbsp;</b>Yang Chen</div><div><b>Pages:&nbsp;</b>4385 - 4402</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00603-7\">Distributed ledger technologies in vehicular mobile edge computing: a survey</a></div><div><b>Author(s):&nbsp;</b>Ming Jiang, Xingsheng Qin</div><div><b>Pages:&nbsp;</b>4403 - 4419</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-10-02T17:43:00.000+13:00",
            "pubdate_parsed": [
                2022,
                10,
                2
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 26, issue 21, November 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/10/soft-computing-volume-26-issue-21.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07318-y\">A derived least square extreme learning machine</a></div><div><b>Author(s): </b>Shuang Hou, Yi Wang...Xiaosheng Wang</div><div><b>Pages: </b>11115 - 11127</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07407-y\">A novel distance between single valued neutrosophic sets and its application in pattern recognition</a></div><div><b>Author(s):&nbsp;</b>Minxia Luo, Guofeng Zhang, Lixian Wu</div><div><b>Pages:&nbsp;</b>11129 - 11137</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07469-y\">Hardening secure search in encrypted database: a KGA-resistance conjunctive searchable encryption scheme from lattice</a></div><div><b>Author(s):&nbsp;</b>Xiaoling Yu, Chungen Xu...Lin Mei</div><div><b>Pages:&nbsp;</b>11139 - 11151</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07246-x\">Deep transfer learning techniques with hybrid optimization in early prediction and diagnosis of different types of oral cancer</a></div><div><b>Author(s):&nbsp;</b>Khushboo Bansal, R. K. Bathla, Yogesh Kumar</div><div><b>Pages:&nbsp;</b>11153 - 11184</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07430-z\">Use of calibration constraints and linear moments for variance estimation under stratified adaptive cluster sampling</a></div><div><b>Author(s):&nbsp;</b>Usman Shahzad, Ishfaq Ahmad...Troon J. Benedict</div><div><b>Pages:&nbsp;</b>11185 - 11196</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07439-4\">Hybrid data selection with preservation rough sets</a></div><div><b>Author(s):&nbsp;</b>Yenny Villuendas-Rey</div><div><b>Pages:&nbsp;</b>11197 - 11223</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07467-0\">A note on multi-criteria decision-making using a complete ranking of generalized trapezoidal fuzzy numbers</a></div><div><b>Author(s):&nbsp;</b>S Jeevaraj</div><div><b>Pages:&nbsp;</b>11225 - 11230</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07473-2\">Matroidal structures on S-approximation spaces</a></div><div><b>Author(s):&nbsp;</b>Xiaonan Li, Yue Chen</div><div><b>Pages:&nbsp;</b>11231 - 11242</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07502-0\">Entropy measurement for a hybrid information system with images: an application in attribute reduction</a></div><div><b>Author(s):&nbsp;</b>Zhaowen Li, Yiying Chen...Ningxin Xie</div><div><b>Pages:&nbsp;</b>11243 - 11263</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07351-x\">Maximum entropy of random permutation set</a></div><div><b>Author(s):&nbsp;</b>Jixiang Deng, Yong Deng</div><div><b>Pages:&nbsp;</b>11265 - 11275</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07372-6\">Skew polynomial superrings</a></div><div><b>Author(s):&nbsp;</b>Surdive Atamewoue Tsafack, Shiping Wen...Yuming Feng</div><div><b>Pages:&nbsp;</b>11277 - 11286</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07382-4\">On level spaces of fuzzy bitopological spaces</a></div><div><b>Author(s):&nbsp;</b>M. Kameswari, S. A. Mohiuddine...N. Anbazhagan</div><div><b>Pages:&nbsp;</b>11287 - 11293</div><div><br /></div><div><b>13) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07381-5\">A way to proper generalization of \u03d5-divergence based on Choquet derivatives</a></div><div><b>Author(s):&nbsp;</b>Zuzana Ontkovi\u010dov\u00e1, Jozef Kise\u013e\u00e1k</div><div><b>Pages:&nbsp;</b>11295 - 11314</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07419-8\">An elite approach for enhancement of LVRT in doubly fed induction generator (DFIG)-based wind energy conversion system (WECS): a FAMSANFIS approach</a></div><div><b>Author(s):&nbsp;</b>Gangikunta Manohar, Sonnati Venkateshwarlu, Askani JayaLaxmi</div><div><b>Pages:&nbsp;</b>11315 - 11337</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07423-y\">Kinematics and trajectory planning analysis based on hybrid optimization algorithms for an industrial robotic manipulators</a></div><div><b>Author(s):&nbsp;</b>Gurjeet Singh, Vijay Kumar Banga</div><div><b>Pages:&nbsp;</b>11339 - 11372</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07429-6\">Some fuzzy Korovkin type approximation theorems via power series summability method</a></div><div><b>Author(s):&nbsp;</b>B. Baxhaku, P. N. Agrawal, R. Shukla</div><div><b>Pages:&nbsp;</b>11373 - 11379</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07434-9\">An extensive operational law for monotone functions of LR fuzzy intervals with applications to fuzzy optimization</a></div><div><b>Author(s):&nbsp;</b>Mingxuan Zhao, Yulin Han...Jian Zhou</div><div><b>Pages:&nbsp;</b>11381 - 11401</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07438-5\">Intuitionistic fuzzy c control charts based on intuitionistic fuzzy ranking method for TIFNs</a></div><div><b>Author(s):&nbsp;</b>G\u00fcltekin Atalik, Sevil Senturk</div><div><b>Pages:&nbsp;</b>11403 - 11407</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07321-3\">An incremental algorithm for concept lattice based on structural similarity index</a></div><div><b>Author(s):&nbsp;</b>Yu Hu, Yan Zhu Hu...Jia Feng Chai</div><div><b>Pages:&nbsp;</b>11409 - 11423</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07474-1\">Interval-based non-dimensionalization method (IBNM) and its application</a></div><div><b>Author(s):&nbsp;</b>Tianjiao Xu, Shihong Chen...Huaping Guan</div><div><b>Pages:&nbsp;</b>11425 - 11434</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07420-1\">Prediction of gestational diabetes based on explainable deep learning and fog computing</a></div><div><b>Author(s):&nbsp;</b>Nora El-Rashidy, Nesma E. ElSayed...Fatma M. Talaat</div><div><b>Pages:&nbsp;</b>11435 - 11450</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07422-z\">An APPSO\u2013SVM approach building the monitoring model of dam safety</a></div><div><b>Author(s):&nbsp;</b>Zhiping Wen, Zhendong Fan, Huaizhi Su</div><div><b>Pages:&nbsp;</b>11451 - 11459</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07432-x\">Coarse-to-fine spatial-channel-boundary attention network for image copy-move forgery detection</a></div><div><b>Author(s):&nbsp;</b>Jun-Liu Zhong, Ji-Xiang Yang...Hua Zeng</div><div><b>Pages:&nbsp;</b>11461 - 11478</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07440-x\">A comprehensive social matrix factorization for recommendations with prediction and feedback mechanisms by fusing trust relationships and social tags</a></div><div><b>Author(s):&nbsp;</b>Rui Chen, Jian-wei Zhang...Hui Liang</div><div><b>Pages:&nbsp;</b>11479 - 11496</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07441-w\">OKC classifier: an efficient approach for classification of imbalanced dataset using hybrid methodology</a></div><div><b>Author(s):&nbsp;</b>Ashok Kumar Bathla, Shally Bansal, Munish Kumar</div><div><b>Pages:&nbsp;</b>11497 - 11503</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07389-x\">A balanced butterfly optimization algorithm for numerical optimization and feature selection</a></div><div><b>Author(s):&nbsp;</b>Wen Long, Jianjun Jiao...Shaohong Cai</div><div><b>Pages:&nbsp;</b>11505 - 11523</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07408-x\">Mehar approach to solve fuzzy linear fractional transportation problems</a></div><div><b>Author(s):&nbsp;</b>Tanveen Kaur Bhatia, Amit Kumar, Mahesh Kumar Sharma</div><div><b>Pages:&nbsp;</b>11525 - 11551</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07409-w\">Maritime anomaly detection based on a support vector machine</a></div><div><b>Author(s):&nbsp;</b>Zhaokun Wei, Xinlian Xie, Xiaoju Zhang</div><div><b>Pages:&nbsp;</b>11553 - 11566</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07425-w\">Parameter estimation of three diode solar PV cell using chaotic dragonfly algorithm</a></div><div><b>Author(s):&nbsp;</b>Manish Kumar Singla, Parag Nijhawan, Amandeep Singh Oberoi</div><div><b>Pages:&nbsp;</b>11567 - 11598</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07427-8\">Visualization of occipital lobe and zygomatic arch of brain region through non-linear perspective projection using DCO algorithm</a></div><div><b>Author(s):&nbsp;</b>R. Partheepan, J. Raja Paul Perinbam...B. Chinthamani</div><div><b>Pages:&nbsp;</b>11599 - 11610</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07442-9\">Fixed-charge solid transportation problem with budget constraints based on carbon emission in neutrosophic environment</a></div><div><b>Author(s):&nbsp;</b>Shyamali Ghosh, Sankar Kumar Roy, Jos\u00e9 Luis Verdegay</div><div><b>Pages:&nbsp;</b>11611 - 11625</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07459-0\">On the exact l1 penalty function method for convex nonsmooth optimization problems with fuzzy objective function</a></div><div><b>Author(s):&nbsp;</b>Tadeusz Antczak</div><div><b>Pages:&nbsp;</b>11627 - 11643</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07466-1\">Comparing the performances of six nature-inspired algorithms on a real-world discrete optimization problem</a></div><div><b>Author(s):&nbsp;</b>Huseyin Hakli, Harun Uguz, Zeynep Ortacay</div><div><b>Pages:&nbsp;</b>11645 - 11667</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07470-5\">Opposition-based learning multi-verse optimizer with disruption operator for optimization problems</a></div><div><b>Author(s):&nbsp;</b>Mohammad Shehab, Laith Abualigah</div><div><b>Pages:&nbsp;</b>11669 - 11693</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07489-8\">A hybrid genetic-particle swarm optimization algorithm for multi-constraint optimization problems</a></div><div><b>Author(s):&nbsp;</b>Bosong Duan, Chuangqiang Guo, Hong Liu</div><div><b>Pages:&nbsp;</b>11695 - 11711</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07339-7\">Integrating prospect theory with variable reference point into the conversion-based framework for linear ordinal ranking aggregation</a></div><div><b>Author(s):&nbsp;</b>Nana Liu, Zeshui Xu...Peijia Ren</div><div><b>Pages:&nbsp;</b>11713 - 11732</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07369-1\">The online website privacy disclosure behavior of users based on concerns-outcomes model</a></div><div><b>Author(s):&nbsp;</b>X. I. E. WeihongZhang Qian</div><div><b>Pages:&nbsp;</b>11733 - 11747</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07380-6\">Public health events emergency management supervision strategy considering citizens\u2019 and new media\u2019s different ways of participation</a></div><div><b>Author(s):&nbsp;</b>Bingjie Lu, Lilong Zhu</div><div><b>Pages:&nbsp;</b>11749 - 11769</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07426-9\">A Multi-criteria approach for public tenders. ELECTRE III and Parsimonious AHP: a comparative study</a></div><div><b>Author(s):&nbsp;</b>Gerarda Fattoruso, Gabriella Marcarelli</div><div><b>Pages:&nbsp;</b>11771 - 11781</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07428-7\">Recognition of DDoS attacks based on images correlation analysis within deep learning framework</a></div><div><b>Author(s):&nbsp;</b>Hengchang Jing, Jian Wang</div><div><b>Pages:&nbsp;</b>11783 - 11794</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06951-x\">MS-ADR: predicting drug\u2013drug adverse reactions base on multi-source heterogeneous convolutional signed network</a></div><div><b>Author(s):&nbsp;</b>Luhe Zhuang, Hong Wang...Hui Zhang</div><div><b>Pages:&nbsp;</b>11795 - 11807</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06959-3\">Self-learning differential evolution algorithm for scheduling of internal tasks in cross-docking</a></div><div><b>Author(s):&nbsp;</b>Dollaya Buakum, Warisa Wisittipanich</div><div><b>Pages:&nbsp;</b>11809 - 11826</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06963-7\">Neural-network-based interval grey prediction models with applications to forecasting the demand of printed circuit boards</a></div><div><b>Author(s):&nbsp;</b>Yi-Chung Hu</div><div><b>Pages:&nbsp;</b>11827 - 11838</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06966-4\">Application of Mamdani model-based fuzzy inference system in water consumption estimation using time series</a></div><div><b>Author(s):&nbsp;</b>H. J. Surendra, P. C. Deka, H. N. Rajakumara</div><div><b>Pages:&nbsp;</b>11839 - 11847</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06981-5\">Decision-making analysis based on hesitant fuzzy N-soft ELECTRE-I approach</a></div><div><b>Author(s):&nbsp;</b>Arooj Adeel, Muhammad Akram, Naim \u00c7a\u01e7man</div><div><b>Pages:&nbsp;</b>11849 - 11863</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06987-z\">Modified hybrid combination synchronization of chaotic fractional order systems</a></div><div><b>Author(s):&nbsp;</b>Kayode S. Ojo, Samuel T. Ogunjo, Ibiyinka A. Fuwape</div><div><b>Pages:&nbsp;</b>11865 - 11872</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07001-2\">Compressive strength evaluation of concrete confined with spiral stirrups by using adaptive neuro-fuzzy inference system (ANFIS)</a></div><div><b>Author(s):&nbsp;</b>Wei Chang, Wenzhong Zheng</div><div><b>Pages:&nbsp;</b>11873 - 11889</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07007-w\">An enhanced approach for optimizing mathematical and structural problems by combining PSO, GSA and gradient directions</a></div><div><b>Author(s):&nbsp;</b>Farsad Salajegheh, Eysa Salajegheh, Saeed Shojaee</div><div><b>Pages:&nbsp;</b>11891 - 11913</div><div><br /></div><div><b>49) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07020-z\">Stratified hyperparameters optimization of feed-forward neural network for social network spam detection (SON2S)</a></div><div><b>Author(s):&nbsp;</b>E. Elakkiya, S. Selvakumar</div><div><b>Pages:&nbsp;</b>11915 - 11934</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07028-5\">Wavelet packet and fuzzy logic theory for automatic fault detection in induction motor</a></div><div><b>Author(s):&nbsp;</b>Hicham Talhaoui, Tarek Ameid...Abdelhalim Kessal</div><div><b>Pages:&nbsp;</b>11935 - 11949</div><div><br /></div></div>",
            "pubdate": "2022-10-14T14:32:00.000+13:00",
            "pubdate_parsed": [
                2022,
                10,
                14
            ],
            "email_sent": true
        },
        "IEEE Transactions on Neural Networks and Learning Systems, Volume 33, Issue 10, October 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/10/ieee-transactions-on-neural-networks.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9410437/\">A Survey of Deep Learning on CPUs: Opportunities and Co-Optimizations</a></div><div><b>Author(s): </b>Sparsh Mittal, Poonam Rajput, Sreenivas Subramoney</div><div><b>Pages: </b>5095 - 5115</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9399692/\">Hash Bit Selection via Collaborative Neurodynamic Optimization With Discrete Hopfield Networks</a></div><div><b>Author(s):&nbsp;</b>Xinqi Li, Jun Wang, Sam Kwong</div><div><b>Pages:&nbsp;</b>5116 - 5124</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9404857/\">Neural Time-Aware Sequential Recommendation by Jointly Modeling Preference Dynamics and Explicit Feature Couplings</a></div><div><b>Author(s):&nbsp;</b>Qi Zhang, Longbing Cao, Chongyang Shi, Zhendong Niu</div><div><b>Pages:&nbsp;</b>5125 - 5137</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9395183/\">Two-Stage Bayesian Optimization for Scalable Inference in State-Space Models</a></div><div><b>Author(s):&nbsp;</b>Mahdi Imani, Seyede Fatemeh Ghoreishi</div><div><b>Pages:&nbsp;</b>5138 - 5149</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9397867/\">Multigraph Transformer for Free-Hand Sketch Recognition</a></div><div><b>Author(s):&nbsp;</b>Peng Xu, Chaitanya K. Joshi, Xavier Bresson</div><div><b>Pages:&nbsp;</b>5150 - 5161</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9397437/\">Supervised Learning for Nonsequential Data: A Canonical Polyadic Decomposition Approach</a></div><div><b>Author(s):&nbsp;</b>Alexandros Haliassos, Kriton Konstantinidis, Danilo P. Mandic</div><div><b>Pages:&nbsp;</b>5162 - 5176</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9399655/\">Multiview Subspace Clustering via Co-Training Robust Data Representation</a></div><div><b>Author(s):&nbsp;</b>Jiyuan Liu, Xinwang Liu, Yuexiang Yang, Xifeng Guo, Marius Kloft, Liangzhong He</div><div><b>Pages:&nbsp;</b>5177 - 5189</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9399171/\">Training-Free Deep Generative Networks for Compressed Sensing of Neural Action Potentials</a></div><div><b>Author(s):&nbsp;</b>Biao Sun, Chaoxu Mu, Zexu Wu, Xinshan Zhu</div><div><b>Pages:&nbsp;</b>5190 - 5199</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9404318/\">Effective Collaborative Representation Learning for Multilabel Text Categorization</a></div><div><b>Author(s):&nbsp;</b>Hao Wu, Shaowei Qin, Rencan Nie, Jinde Cao, Sergey Gorbachev</div><div><b>Pages:&nbsp;</b>5200 - 5214</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9400417/\">Spike-Timing-Dependent Plasticity With Activation-Dependent Scaling for Receptive Fields Development</a></div><div><b>Author(s):&nbsp;</b>Marcin Bia\u0142as, Jacek Ma\u0144dziuk</div><div><b>Pages:&nbsp;</b>5215 - 5228</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9404328/\">Reinforcement Learning-Based Cooperative Optimal Output Regulation via Distributed Adaptive Internal Model</a></div><div><b>Author(s):&nbsp;</b>Weinan Gao, Mohammed Mynuddin, Donald C. Wunsch, Zhong-Ping Jiang</div><div><b>Pages:&nbsp;</b>5229 - 5240</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9399168/\">Event-Triggered Adaptive Neural Network Sensor Failure Compensation for Switched Interconnected Nonlinear Systems With Unknown Control Coefficients</a></div><div><b>Author(s):&nbsp;</b>Jing Zhang, Zhengrong Xiang</div><div><b>Pages:&nbsp;</b>5241 - 5252</div><div><br /></div><div><b>13)</b> <a href=\"https://computational-intelligence.blogspot.com/feeds/posts/Publication Year: 2022,Page(s):https:/ieeexplore.ieee.org/document/9399174/\">General Bitwidth Assignment for Efficient Deep Convolutional Neural Network Quantization</a></div><div><b>Author(s):&nbsp;</b>Wen Fei, Wenrui Dai, Chenglin Li, Junni Zou, Hongkai Xiong</div><div><b>Pages:&nbsp;</b>5253-5267</div><div><br /></div><div><b>14) </b><a href=\"https://ieeexplore.ieee.org/document/9399170/\">Finite-Time Synchronization of Markovian Coupled Neural Networks With Delays via Intermittent Quantized Control: Linear Programming Approach</a></div><div><b>Author(s):&nbsp;</b>Rongqiang Tang, Housheng Su, Yi Zou, Xinsong Yang</div><div><b>Pages:&nbsp;</b>5268 - 5278</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9399169/\">EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Hojjat Salehinejad, Shahrokh Valaee</div><div><b>Pages:&nbsp;</b>5279 - 5292</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9399689/\">Multi-Source Contribution Learning for Domain Adaptation</a></div><div><b>Author(s):&nbsp;</b>Keqiuyin Li, Jie Lu, Hua Zuo, Guangquan Zhang</div><div><b>Pages:&nbsp;</b>5293 - 5307</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9404309/\">Prototype-Based Multisource Domain Adaptation</a></div><div><b>Author(s):&nbsp;</b>Lihua Zhou, Mao Ye, Dan Zhang, Ce Zhu, Luping Ji</div><div><b>Pages:&nbsp;</b>5308 - 5320</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9404313/\">Uniform Stability of Complex-Valued Neural Networks of Fractional Order With Linear Impulses and Fixed Time Delays</a></div><div><b>Author(s):&nbsp;</b>Hui Li, Yonggui Kao, Haibo Bao, Yangquan Chen</div><div><b>Pages:&nbsp;</b>5321 - 5331</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9404315/\">Discriminative Multi-View Dynamic Image Fusion for Cross-View 3-D Action Recognition</a></div><div><b>Author(s):&nbsp;</b>Yancheng Wang, Yang Xiao, Junyi Lu, Bo Tan, Zhiguo Cao, Zhenjun Zhang, Joey Tianyi Zhou</div><div><b>Pages:&nbsp;</b>5332 - 5345</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9404323/\">Face Sketch Synthesis Using Regularized Broad Learning System</a></div><div><b>Author(s):&nbsp;</b>Ping Li, Bin Sheng, C. L. Philip Chen</div><div><b>Pages:&nbsp;</b>5346 - 5360</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9432789/\">Hierarchical Multiagent Reinforcement Learning for Allocating Guaranteed Display Ads</a></div><div><b>Author(s):&nbsp;</b>Lu Wang, Lei Han, Xinru Chen, Chengchang Li, Junzhou Huang, Weinan Zhang, Wei Zhang, Xiaofeng He, Dijun Luo</div><div><b>Pages:&nbsp;</b>5361 - 5373</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9410247/\">Multiagent Meta-Reinforcement Learning for Adaptive Multipath Routing Optimization</a></div><div><b>Author(s):&nbsp;</b>Long Chen, Bin Hu, Zhi-Hong Guan, Lian Zhao, Xuemin Shen</div><div><b>Pages:&nbsp;</b>5374 - 5386</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9404870/\">Nonblind Image Deblurring via Deep Learning in Complex Field</a></div><div><b>Author(s):&nbsp;</b>Yuhui Quan, Peikang Lin, Yong Xu, Yuesong Nan, Hui Ji</div><div><b>Pages:&nbsp;</b>5387 - 5400</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9408408/\">Joint Learning of Neural Transfer and Architecture Adaptation for Image Recognition</a></div><div><b>Author(s):&nbsp;</b>Guangrun Wang, Liang Lin, Rongcong Chen, Guangcong Wang, Jiqi Zhang</div><div><b>Pages:&nbsp;</b>5401 - 5415</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9404321/\">Adaptive NN Finite-Time Resilient Control for Nonlinear Time-Delay Systems With Unknown False Data Injection and Actuator Faults</a></div><div><b>Author(s):&nbsp;</b>Shuai Song, Ju H. Park, Baoyong Zhang, Xiaona Song</div><div><b>Pages:&nbsp;</b>5416 - 5428</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9404854/\">Deep Learning-Based 2-D Frequency Estimation of Multiple Sinusoidals</a></div><div><b>Author(s):&nbsp;</b>Pingping Pan, Yunjian Zhang, Zhenmiao Deng, Wei Qi</div><div><b>Pages:&nbsp;</b>5429 - 5440</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9404312/\">Simultaneous State and Unknown Input Estimation for Complex Networks With Redundant Channels Under Dynamic Event-Triggered Mechanisms</a></div><div><b>Author(s):&nbsp;</b>Qi Li, Zidong Wang, Jun Hu, Weiguo Sheng</div><div><b>Pages:&nbsp;</b>5441 - 5451</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9406189/\">Continuation Multiple Instance Learning for Weakly and Fully Supervised Object Detection</a></div><div><b>Author(s):&nbsp;</b>Qixiang Ye, Fang Wan, Chang Liu, Qingming Huang, Xiangyang Ji</div><div><b>Pages:&nbsp;</b>5452 - 5466</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9404856/\">A Separation-Based Methodology to Consensus Tracking of Switched High-Order Nonlinear Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Maolong Lv, Wenwu Yu, Jinde Cao, Simone Baldi</div><div><b>Pages:&nbsp;</b>5467 - 5479</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9404310/\">Degradation Alignment in Remaining Useful Life Prediction Using Deep Cycle-Consistent Learning</a></div><div><b>Author(s):&nbsp;</b>Xiang Li, Wei Zhang, Hui Ma, Zhong Luo, Xu Li</div><div><b>Pages:&nbsp;</b>5480 - 5491</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9406172/\">Adaptive Observation-Based Efficient Reinforcement Learning for Uncertain Systems</a></div><div><b>Author(s):&nbsp;</b>Maopeng Ran, Lihua Xie</div><div><b>Pages:&nbsp;</b>5492 - 5503</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9406180/\">Learning-Based Distributed Resilient Fault-Tolerant Control Method for Heterogeneous MASs Under Unknown Leader Dynamic</a></div><div><b>Author(s):&nbsp;</b>Chao Deng, Xiao-Zheng Jin, Wei-Wei Che, Hai Wang</div><div><b>Pages:&nbsp;</b>5504 - 5513</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9403414/\">A High-Efficient Hybrid Physics-Informed Neural Networks Based on Convolutional Neural Network</a></div><div><b>Author(s):&nbsp;</b>Zhiwei Fang</div><div><b>Pages:&nbsp;</b>5514 - 5526</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9409779/\">Design and Analysis of Data-Driven Learning Control: An Optimization-Based Approach</a></div><div><b>Author(s):&nbsp;</b>Deyuan Meng, Jingyao Zhang</div><div><b>Pages:&nbsp;</b>5527 - 5541</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9404859/\">Improved Results on Fixed-/Preassigned-Time Synchronization for Memristive Complex-Valued Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Qintao Gan, Liangchen Li, Jing Yang, Yan Qin, Mingqiang Meng</div><div><b>Pages:&nbsp;</b>5542 - 5556</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9404853/\">Multipixel Anomaly Detection With Unknown Patterns for Hyperspectral Imagery</a></div><div><b>Author(s):&nbsp;</b>Jun Liu, Zengfu Hou, Wei Li, Ran Tao, Danilo Orlando, Hongbin Li</div><div><b>Pages:&nbsp;</b>5557 - 5567</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9405431/\">A Novel Formulation of Trace Ratio Linear Discriminant Analysis</a></div><div><b>Author(s):&nbsp;</b>Jingyu Wang, Lin Wang, Feiping Nie, Xuelong Li</div><div><b>Pages:&nbsp;</b>5568 - 5578</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9406173/\">Consensus-Based Cooperative Algorithms for Training Over Distributed Data Sets Using Stochastic Gradients</a></div><div><b>Author(s):&nbsp;</b>Zhongguo Li, Bo Liu, Zhengtao Ding</div><div><b>Pages:&nbsp;</b>5579 - 5589</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9420275/\">Maximum A Posteriori Approximation of Hidden Markov Models for Proportional Sequential Data Modeling With Simultaneous Feature Selection</a></div><div><b>Author(s):&nbsp;</b>Samr Ali, Nizar Bouguila</div><div><b>Pages:&nbsp;</b>5590 - 5601</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9410407/\">Large-Scale Multiagent System Tracking Control Using Mean Field Games</a></div><div><b>Author(s):&nbsp;</b>Zejian Zhou, Hao Xu</div><div><b>Pages:&nbsp;</b>5602 - 5610</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9406190/\">Heterogeneous Face Interpretable Disentangled Representation for Joint Face Recognition and Synthesis</a></div><div><b>Author(s):&nbsp;</b>Decheng Liu, Xinbo Gao, Chunlei Peng, Nannan Wang, Jie Li</div><div><b>Pages:&nbsp;</b>5611 - 5625</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9416240/\">Class-Imbalanced Deep Learning via a Class-Balanced Ensemble</a></div><div><b>Author(s):&nbsp;</b>Zhi Chen, Jiang Duan, Li Kang, Guoping Qiu</div><div><b>Pages:&nbsp;</b>5626 - 5640</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9404848/\">Domain Adaptation Preconceived Hashing for Unconstrained Visual Retrieval</a></div><div><b>Author(s):&nbsp;</b>Fuxiang Huang, Lei Zhang, Xinbo Gao</div><div><b>Pages:&nbsp;</b>5641 - 5655</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9423873/\">Unified Analysis on the Global Dissipativity and Stability of Fractional-Order Multidimension-Valued Memristive Neural Networks With Time Delay</a></div><div><b>Author(s):&nbsp;</b>Jianying Xiao, Shouming Zhong, Shiping Wen</div><div><b>Pages:&nbsp;</b>5656 - 5665</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9420270/\">Learning Deep Context-Sensitive Decomposition for Low-Light Image Enhancement</a></div><div><b>Author(s):&nbsp;</b>Long Ma, Risheng Liu, Jiaao Zhang, Xin Fan, Zhongxuan Luo</div><div><b>Pages:&nbsp;</b>5666 - 5680</div><div><br /></div><div><b>46)</b> <a href=\"https://ieeexplore.ieee.org/document/9410431/\">A Decoder-Free Variational Deep Embedding for Unsupervised Clustering</a></div><div><b>Author(s):&nbsp;</b>Qiang Ji, Yanfeng Sun, Junbin Gao, Yongli Hu, Baocai Yin</div><div><b>Pages:&nbsp;</b>5681 - 5693</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9404864/\">Data-Driven Designs of Fault Detection Systems via Neural Network-Aided Learning</a></div><div><b>Author(s):&nbsp;</b>Hongtian Chen, Zheng Chai, Oguzhan Dogru, Bin Jiang, Biao Huang</div><div><b>Pages:&nbsp;</b>5694 - 5705</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9406178/\">Prediction With Unpredictable Feature Evolution</a></div><div><b>Author(s):&nbsp;</b>Bo-Jian Hou, Lijun Zhang, Zhi-Hua Zhou</div><div><b>Pages:&nbsp;</b>5706 - 5715</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9408232/\">Spherical Formation Tracking Control of Nonlinear Second-Order Agents With Adaptive Neural Flow Estimate</a></div><div><b>Author(s):&nbsp;</b>Yang-Yang Chen, Rong Huang, Yanteng Ge, Ya Zhang</div><div><b>Pages:&nbsp;</b>5716 - 5727</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9405414/\">Learning Gaussian\u2013Bernoulli RBMs Using Difference of Convex Functions Optimization</a></div><div><b>Author(s):&nbsp;</b>Vidyadhar Upadhya, P. S. Sastry</div><div><b>Pages:&nbsp;</b>5728 - 5738</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9406169/\">Knowledge-Based Prediction of Network Controllability Robustness</a></div><div><b>Author(s):&nbsp;</b>Yang Lou, Yaodong He, Lin Wang, Kim Fung Tsang, Guanrong Chen</div><div><b>Pages:&nbsp;</b>5739 - 5750</div><div><br /></div><div><b>52)</b> <a href=\"https://ieeexplore.ieee.org/document/9405447/\">Deep Feature Aggregation Framework Driven by Graph Convolutional Network for Scene Classification in Remote Sensing</a></div><div><b>Author(s):&nbsp;</b>Kejie Xu, Hong Huang, Peifang Deng, Yuan Li</div><div><b>Pages:&nbsp;</b>5751 - 5765</div><div><br /></div><div><b>53)</b> <a href=\"https://ieeexplore.ieee.org/document/9410288/\">On the Rates of Convergence From Surrogate Risk Minimizers to the Bayes Optimal Classifier</a></div><div><b>Author(s):&nbsp;</b>Jingwei Zhang, Tongliang Liu, Dacheng Tao</div><div><b>Pages:&nbsp;</b>5766 - 5774</div><div><br /></div><div><b>54)</b> <a href=\"https://ieeexplore.ieee.org/document/9411671/\">An L1-and-L2-Norm-Oriented Latent Factor Model for Recommender Systems</a></div><div><b>Author(s):&nbsp;</b>Di Wu, Mingsheng Shang, Xin Luo, Zidong Wang</div><div><b>Pages:&nbsp;</b>5775 - 5788</div><div><br /></div><div><b>55)</b> <a href=\"https://ieeexplore.ieee.org/document/9408405/\">Deep Mixture Generative Autoencoders</a></div><div><b>Author(s):&nbsp;</b>Fei Ye, Adrian G. Bors</div><div><b>Pages:&nbsp;</b>5789 - 5803</div><div><br /></div><div><b>56)</b> <a href=\"https://ieeexplore.ieee.org/document/9406188/\">Stability and Synchronization of Nonautonomous Reaction\u2013Diffusion Neural Networks With General Time-Varying Delays</a></div><div><b>Author(s):&nbsp;</b>Hao Zhang, Zhigang Zeng</div><div><b>Pages:&nbsp;</b>5804 - 5817</div><div><br /></div><div><b>57)</b> <a href=\"https://ieeexplore.ieee.org/document/9408409/\">Weakly Supervised Domain Adaptation for Aspect Extraction via Multilevel Interaction Transfer</a></div><div><b>Author(s):&nbsp;</b>Tao Liang, Wenya Wang, Fengmao Lv</div><div><b>Pages:&nbsp;</b>5818 - 5829</div><div><br /></div><div><b>58)</b> <a href=\"https://ieeexplore.ieee.org/document/9406192/\">Decentralized Event-Driven Constrained Control Using Adaptive Critic Designs</a></div><div><b>Author(s):&nbsp;</b>Xiong Yang, Yuanheng Zhu, Na Dong, Qinglai Wei</div><div><b>Pages:&nbsp;</b>5830 - 5844</div><div><br /></div><div><b>59)</b> <a href=\"https://ieeexplore.ieee.org/document/9411732/\">Whitening-Net: A Generalized Network to Diagnose the Faults Among Different Machines and Conditions</a></div><div><b>Author(s):&nbsp;</b>Jie Li, Yu Wang, Yanyang Zi, Zhijie Zhang</div><div><b>Pages:&nbsp;</b>5845 - 5858</div><div><br /></div><div><b>60)</b> <a href=\"https://ieeexplore.ieee.org/document/9410401/\">Adaptive Data Structure Regularized Multiclass Discriminative Feature Selection</a></div><div><b>Author(s):&nbsp;</b>Mingyu Fan, Xiaoqin Zhang, Jie Hu, Nannan Gu, Dacheng Tao</div><div><b>Pages:&nbsp;</b>5859 - 5872</div><div><br /></div><div><b>61)</b> <a href=\"https://ieeexplore.ieee.org/document/9424995/\">Reinforcement Learning Control of Robotic Knee With Human-in-the-Loop by Flexible Policy Iteration</a></div><div><b>Author(s):&nbsp;</b>Xiang Gao, Jennie Si, Yue Wen, Minhan Li, He Huang</div><div><b>Pages:&nbsp;</b>5873 - 5887</div><div><br /></div><div><b>62)</b> <a href=\"https://ieeexplore.ieee.org/document/9410432/\">Explicit Metric-Based Multiconcept Multi-Instance Learning With Triplet and Superbag</a></div><div><b>Author(s):&nbsp;</b>Ziqiu Chi, Zhe Wang, Wenli Du</div><div><b>Pages:&nbsp;</b>5888 - 5897</div><div><br /></div><div><b>63)</b> <a href=\"https://ieeexplore.ieee.org/document/9424959/\">Learning With Label Proportions by Incorporating Unmarked Data</a></div><div><b>Author(s):&nbsp;</b>Jing Chai, Ivor W. Tsang</div><div><b>Pages:&nbsp;</b>5898 - 5912</div><div><br /></div><div><b>64)</b> <a href=\"https://ieeexplore.ieee.org/document/9409784/\">Graph-Based Bayesian Optimization for Large-Scale Objective-Based Experimental Design</a></div><div><b>Author(s):&nbsp;</b>Mahdi Imani, Seyede Fatemeh Ghoreishi</div><div><b>Pages:&nbsp;</b>5913 - 5925</div><div><br /></div><div><b>65)</b> <a href=\"https://ieeexplore.ieee.org/document/9410433/\">Neuro-Evolutionary Direct Policy Search for Multiobjective Optimal Control</a></div><div><b>Author(s):&nbsp;</b>Marta Zaniolo, Matteo Giuliani, Andrea Castelletti</div><div><b>Pages:&nbsp;</b>5926 - 5938</div><div><br /></div><div><b>66)</b> <a href=\"https://ieeexplore.ieee.org/document/9416238/\">Temporal Coding in Spiking Neural Networks With Alpha Synaptic Function: Learning With Backpropagation</a></div><div><b>Author(s):&nbsp;</b>Iulia-Maria Com\u015fa, Krzysztof Potempa, Luca Versari, Thomas Fischbacher, Andrea Gesmundo, Jyrki Alakuijala</div><div><b>Pages:&nbsp;</b>5939 - 5952</div><div><br /></div><div><b>67)</b> <a href=\"https://ieeexplore.ieee.org/document/9411738/\">Noise Robust Face Hallucination Based on Smooth Correntropy Representation</a></div><div><b>Author(s):&nbsp;</b>Licheng Liu, Qiying Feng, C. L. Philip Chen, Yaonan Wang</div><div><b>Pages:&nbsp;</b>5953 - 5965</div><div><br /></div><div><b>68)</b> <a href=\"https://ieeexplore.ieee.org/document/9422177/\">Memory-Efficient Class-Incremental Learning for Image Classification</a></div><div><b>Author(s):&nbsp;</b>Hanbin Zhao, Hui Wang, Yongjian Fu, Fei Wu;</div><div>Xi Li</div><div><b>Pages:&nbsp;</b>5966 - 5977</div><div><br /></div><div><b>69)</b> <a href=\"https://ieeexplore.ieee.org/document/9496282/\">IVS-Caffe\u2014Hardware-Oriented Neural Network Model Development</a></div><div><b>Author(s):&nbsp;</b>Chia-Chi Tsai, Jiun-In Guo</div><div><b>Pages:&nbsp;</b>5978 - 5992</div><div><br /></div><div><b>70)</b> <a href=\"https://ieeexplore.ieee.org/document/9411670/\">Inferring Effective Connectivity Networks From fMRI Time Series With a Temporal Entropy-Score</a></div><div><b>Author(s):&nbsp;</b>Jinduo Liu, Junzhong Ji, Guangxu Xun, Aidong Zhang</div><div><b>Pages:&nbsp;</b>5993 - 6006</div><div><br /></div><div><b>71)</b> <a href=\"https://ieeexplore.ieee.org/document/9399651/\">Synchronization of Chaotic Neural Networks: Average-Delay Impulsive Control</a></div><div><b>Author(s):&nbsp;</b>Bangxin Jiang, Jungang Lou, Jianquan Lu, Kaibo Shi</div><div><b>Pages:&nbsp;</b>6007 - 6012</div><div><br /></div><div><b>72)</b> <a href=\"https://ieeexplore.ieee.org/document/9399673/\">Fully Decoupled Neural Network Learning Using Delayed Gradients</a></div><div><b>Author(s):&nbsp;</b>Huiping Zhuang, Yi Wang, Qinglai Liu, Zhiping Lin</div><div><b>Pages:&nbsp;</b>6013 - 6020</div><div><br /></div><div><b>73)</b> <a href=\"https://ieeexplore.ieee.org/document/9419682/\">Neural Embedding Singular Value Decomposition for Collaborative Filtering</a></div><div><b>Author(s):&nbsp;</b>Tianlin Huang, Rujie Zhao, Lvqing Bi, Defu Zhang, Chao Lu</div><div><b>Pages:&nbsp;</b>6021 - 6029</div><div><br /></div><div><b>74)</b> <a href=\"https://ieeexplore.ieee.org/document/9425429/\">Event-Triggered Adaptive Control of Uncertain Nonlinear Systems With Composite Condition</a></div><div><b>Author(s):&nbsp;</b>Xinglan Liu, Bin Xu, Yingxin Shou, Quan-Yong Fan, Yingxue Chen</div><div><b>Pages:&nbsp;</b>6030 - 6037</div><div><br /></div><div><b>75)</b> <a href=\"https://ieeexplore.ieee.org/document/9774865/\">Fast Rates of Gaussian Empirical Gain Maximization With Heavy-Tailed Noise</a></div><div><b>Author(s):&nbsp;</b>Shouyou Huang, Yunlong Feng, Qiang Wu</div><div><b>Pages:&nbsp;</b>6038 - 6043</div><div><br /></div></div>",
            "pubdate": "2022-10-22T19:42:00.000+13:00",
            "pubdate_parsed": [
                2022,
                10,
                22
            ],
            "email_sent": true
        },
        "Evolving Systems, Volume 13, Issue 6, December 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/10/evolving-systems-volume-13-issue-6.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09409-x\">A new optimal prediction technique for energy demand based on CNN and improved water strider algorithm: a study on socio-economic-climatic parameters</a></div><div><b>Author(s): </b>Shimin Liao, Giorgos Jimenez</div><div><b>Pages: </b>759 - 775</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09410-4\">Varying combination of feature extraction and modified support vector machines based prediction of myocardial infarction</a></div><div><b>Author(s):&nbsp;</b>A. Razia Sulthana, A. K. Jaithunbi</div><div><b>Pages:&nbsp;</b>777 - 794</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09413-1\">Dynamics of multi-point singular fifth-order Lane\u2013Emden system with neuro-evolution heuristics</a></div><div><b>Author(s):&nbsp;</b>Zulqurnain Sabir, Mohamed R. Ali...Dumitru Baleanu</div><div><b>Pages:&nbsp;</b>795 - 806</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09426-4\">Deep learning system applicability for rapid glaucoma prediction from fundus images across various data sets</a></div><div><b>Author(s):&nbsp;</b>Law Kumar Singh, Pooja...Munish Khanna</div><div><b>Pages:&nbsp;</b>807 - 836</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-021-09417-x\">A semi-supervised deep rule-based classifier for robust finger knuckle-print verification</a></div><div><b>Author(s):&nbsp;</b>Mounir Benmalek, Abdelouahab Attia...M. Hassaballah</div><div><b>Pages:&nbsp;</b>837 - 848</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09418-4\">Application of hybrid metaheuristic with Levenberg-Marquardt algorithm for 6-dimensional magnetic localization</a></div><div><b>Author(s):&nbsp;</b>Memduh Suveren, Rustu Akay...Muzaffer Kanaan</div><div><b>Pages:&nbsp;</b>849 - 867</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09423-7\">Correlation-based modified long short-term memory network approach for software defect prediction</a></div><div><b>Author(s):&nbsp;</b>Suresh Kumar Pemmada, H. S. Behera...Bighnaraj Naik</div><div><b>Pages:&nbsp;</b>869 - 887</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09425-5\">Nature-inspired optimization algorithms and their significance in multi-thresholding image segmentation: an inclusive review</a></div><div><b>Author(s):&nbsp;</b>Rebika Rai, Arunita Das, Krishna Gopal Dhal</div><div><b>Pages:&nbsp;</b>889 - 945</div><div><br /></div></div>",
            "pubdate": "2022-10-23T21:37:00.000+13:00",
            "pubdate_parsed": [
                2022,
                10,
                23
            ],
            "email_sent": true
        },
        "IEEE Transactions on Fuzzy Systems, Volume 30, Issue 11, November 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/11/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9933713/\">Guest Editorial: Recent Advances in Fuzzy-Based Intelligent IoT and Cyber-Physical Systems</a></div><div><b>Author(s): </b>Mainak Adhikari, Varun G. Menon, Ju H. Park, Danda B. Rawat</div><div><b>Pages: </b>4541 - 4542</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9626570/\">Fuz-Spam: Label Smoothing-Based Fuzzy Detection of Spammers in Internet of Things</a></div><div><b>Author(s):&nbsp;</b>Zhiwei Guo, Keping Yu, Alireza Jolfaei, Feng Ding, Ning Zhang</div><div><b>Pages:&nbsp;</b>4543 - 4554</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9730093/\">Fast Nonsingular Fixed-Time Fuzzy Fault-Tolerant Control for HFVs With Guaranteed Time-Varying Flight State Constraints</a></div><div><b>Author(s):&nbsp;</b>Maolong Lv, Yinghong Li, Lujun Wan, Jiangbin Dai, Jing Chang</div><div><b>Pages:&nbsp;</b>4555 - 4567</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9756858/\">Data-Driven Fuzzy Target-Side Representation for Intelligent Translation System</a></div><div><b>Author(s):&nbsp;</b>Kehai Chen, Muyun Yang, Tiejun Zhao, Min Zhang</div><div><b>Pages:&nbsp;</b>4568 - 4577</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9714825/\">FuzzyAct: A Fuzzy-Based Framework for Temporal Activity Recognition in IoT Applications Using RNN and 3D-DWT</a></div><div><b>Author(s):&nbsp;</b>Fayaz Ali Dharejo, Muhammad Zawish, Yuanchun Zhou, Steven Davy, Kapal Dev, Sunder Ali Khowaja, Yanjie Fu, Nawab Muhammad Faseeh Qureshi</div><div><b>Pages:&nbsp;</b>4578 - 4592</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9737450/\">Game Theory for Distributed IoV Task Offloading With Fuzzy Neural Network in Edge Computing</a></div><div><b>Author(s):&nbsp;</b>Xiaolong Xu, Qinting Jiang, Peiming Zhang, Xuefei Cao, Mohammad R. Khosravi, Linss T. Alex, Lianyong Qi, Wanchun Dou</div><div><b>Pages:&nbsp;</b>4593 - 4604</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9750892/\">Online Intrusion Detection for Internet of Things Systems With Full Bayesian Possibilistic Clustering and Ensembled Fuzzy Classifiers</a></div><div><b>Author(s):&nbsp;</b>Fang-Qi Li, Rui-Jie Zhao, Shi-Lin Wang, Li-Bo Chen, Alan Wee-Chung Liew, Weiping Ding</div><div><b>Pages:&nbsp;</b>4605 - 4617</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9756835/\">Fuzzy Active Learning to Detect OpenCL Kernel Heterogeneous Machines in Cyber Physical Systems</a></div><div><b>Author(s):&nbsp;</b>Usman Ahmed, Jerry Chun-Wei Lin, Gautam Srivastava, M S Mekala, Ho-Youl Jung</div><div><b>Pages:&nbsp;</b>4618 - 4629</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9745612/\">Multiobjective Multiple Mobile Sink Scheduling via Evolutionary Fuzzy Rough Neural Network for Wireless Sensor Networks</a></div><div><b>Author(s):&nbsp;</b>Jianwei Zhao, Bin Cao, Xin Liu, Peng Yang, Amit Kumar Singh, Zhihan Lv</div><div><b>Pages:&nbsp;</b>4630 - 4641</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9772948/\">Side-Channel Fuzzy Analysis-Based AI Model Extraction Attack With Information-Theoretic Perspective in Intelligent IoT</a></div><div><b>Author(s):&nbsp;</b>Qianqian Pan, Jun Wu, Ali Kashif Bashir, Jianhua Li, Jie Wu</div><div><b>Pages:&nbsp;</b>4642 - 4656</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9732224/\">Cloud Risk Management With OWA-LSTM and Fuzzy Linguistic Decision Making</a></div><div><b>Author(s):&nbsp;</b>Walayat Hussain, Muhammad Raheel Raza, Mian Ahmad Jan, Jos\u00e9 M. Merig\u00f3, Honghao Gao</div><div><b>Pages:&nbsp;</b>4657 - 4666</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9721584/\">An Observer-Based Fuzzy Adaptive Consensus Control Method for Nonlinear Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Yongming Li, Kewen Li, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>4667 - 4678</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9729498/\">Fuzzy-Model-Based Asynchronous Fault Detection for Markov Jump Systems With Partially Unknown Transition Probabilities: An Adaptive Event-Triggered Approach</a></div><div><b>Author(s):&nbsp;</b>Guangtao Ran, Jian Liu, Chuanjiang Li, Hak-Keung Lam, Dongyu Li, Hongtian Chen</div><div><b>Pages:&nbsp;</b>4679 - 4689</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9729427/\">Unknown Input Functional Observer Design for Discrete-Time Interval Type-2 Takagi\u2013Sugeno Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Yueyang Li, Ming Yuan, Mohammed Chadli, Zi-Peng Wang, Dong Zhao</div><div><b>Pages:&nbsp;</b>4690 - 4701</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9729629/\">Small-Gain Approach to Fuzzy Adaptive Control for Interconnected Systems With Unmodeled Dynamics</a></div><div><b>Author(s):&nbsp;</b>Bo Xu, Yuan-Xin Li, Choon Ki Ahn</div><div><b>Pages:&nbsp;</b>4702 - 4716</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9732219/\">On Fractional Tikhonov Regularization: Application to the Adaptive Network-Based Fuzzy Inference System for Regression Problems</a></div><div><b>Author(s):&nbsp;</b>Stefania Tomasiello, Witold Pedrycz, Vincenzo Loia</div><div><b>Pages:&nbsp;</b>4717 - 4727</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9732660/\">Subpredictor-Based Fuzzy Control Design for a Reaction\u2013Diffusion Equation</a></div><div><b>Author(s):&nbsp;</b>Wen Kang, Jing Zhang, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>4728 - 4740</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9732700/\">Trust-Consensus Multiplex Networks by Combining Trust Social Network Analysis and Consensus Evolution Methods in Group Decision-Making</a></div><div><b>Author(s):&nbsp;</b>Tong Wu, Xinwang Liu, Jindong Qin, Francisco Herrera</div><div><b>Pages:&nbsp;</b>4741 - 4753</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9735344/\">C-Loss Based Higher Order Fuzzy Inference Systems for Identifying DNA N4-Methylcytosine Sites</a></div><div><b>Author(s):&nbsp;</b>Yijie Ding, Prayag Tiwari, Quan Zou, Fei Guo, Hari Mohan Pandey</div><div><b>Pages:&nbsp;</b>4754 - 4765</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9736626/\">Improved Admissibility Analysis of Takagi\u2013Sugeno Fuzzy Singular Systems With Time-Varying Delays</a></div><div><b>Author(s):&nbsp;</b>Yang Li, Yong He</div><div><b>Pages:&nbsp;</b>4766 - 4774</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9736585/\">Adaptive Fuzzy Backstepping Asymptotic Disturbance Rejection of Multiagent Systems With Unknown Model Dynamics</a></div><div><b>Author(s):&nbsp;</b>Xin Hu, Yue Long, Tieshan Li, C. L. Philip Chen</div><div><b>Pages:&nbsp;</b>4775 - 4787</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9737428/\">Admissible Orders on Fuzzy Numbers</a></div><div><b>Author(s):&nbsp;</b>Nicol\u00e1s Zumelzu, Benjam\u00edn Bedregal, Edmundo Mansilla, Humberto Bustince, Roberto D\u00edaz</div><div><b>Pages:&nbsp;</b>4788 - 4799</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9738446/\">Neural-Observer-Based Terminal Sliding Mode Control: Design and Application</a></div><div><b>Author(s):&nbsp;</b>Shixi Hou, Cheng Wang, Yundi Chu, Juntao Fei</div><div><b>Pages:&nbsp;</b>4800 - 4814</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9740453/\">Large-Scale Fuzzy Least Squares Twin SVMs for Class Imbalance Learning</a></div><div><b>Author(s):&nbsp;</b>M. A. Ganaie, M. Tanveer, Chin-Teng Lin</div><div><b>Pages:&nbsp;</b>4815 - 4827</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9740425/\">Fuzzy Adaptive Output-Feedback Constrained Trajectory Tracking Control for HFVs With Fixed-Time Convergence</a></div><div><b>Author(s):&nbsp;</b>Renwei Zuo, Yinghui Li, Maolong Lv, Zongcheng Liu, Fan Zhang</div><div><b>Pages:&nbsp;</b>4828 - 4840</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9740434/\">Granularity Selection for Hierarchical Classification Based on Uncertainty Measure</a></div><div><b>Author(s):&nbsp;</b>Shuai Li, Jie Yang, Guoyin Wang, Qinghua Zhang, Jun Hu</div><div><b>Pages:&nbsp;</b>4841 - 4855</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9741321/\">Delay-Variation-Dependent Criteria on Stability and Stabilization for Discrete-Time T\u2013S Fuzzy Systems With Time-Varying Delays</a></div><div><b>Author(s):&nbsp;</b>Wen-Hu Chen, Chuan-Ke Zhang, Ke-You Xie, Cui Zhu, Yong He</div><div><b>Pages:&nbsp;</b>4856 - 4866</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9741378/\">Generalized Fuzzy Extended State Observer Design for Uncertain Nonlinear Systems: An Improved Dynamic Event-Triggered Approach</a></div><div><b>Author(s):&nbsp;</b>Zhichen Li, Huaicheng Yan, Hao Zhang, Meng Wang, Lu Zeng</div><div><b>Pages:&nbsp;</b>4867 - 4875</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9743321/\">Fuzzy Control of Switched Systems With Unknown Backlash and Nonconstant Control Gain: A Parameterized Smooth Inverse</a></div><div><b>Author(s):&nbsp;</b>Yanxian Chen, Zhi Liu, C. L. Philip Chen, Yun Zhang</div><div><b>Pages:&nbsp;</b>4876 - 4890</div><div><br /></div><div><b>30)</b> <a href=\"https://ieeexplore.ieee.org/document/9745804/\">Fuzzy Adaptive Finite-Time Consensus Control for High-Order Nonlinear Multiagent Systems Based on Event-Triggered</a></div><div><b>Author(s):&nbsp;</b>Haodong Zhou, Shuai Sui, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>4891 - 4904</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9745830/\">Robust Fuzzy Feedback Control for Nonlinear Systems With Input Quantization</a></div><div><b>Author(s):&nbsp;</b>Ting-Ting Pan, Xiao-Heng Chang, Yi Liu</div><div><b>Pages:&nbsp;</b>4905 - 4914</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9748988/\">Adaptive Fuzzy Control for an Uncertain Axially Moving Slung-Load Cable System of a Hovering Helicopter With Actuator Fault</a></div><div><b>Author(s):&nbsp;</b>Yong Ren, Zhijia Zhao, Choon Ki Ahn, Han-Xiong Li</div><div><b>Pages:&nbsp;</b>4915 - 4925</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9748990/\">Finite-Time Dynamic Event-Triggered Fuzzy Output Fault-Tolerant Control for Interval Type-2 Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Xiaomei Li, Wenting Song, Yongming Li, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>4926 - 4938</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9748983/\">Adaptive Fuzzy Control of Nonlinear Systems With Function Constraints Based on Time-Varying IBLFs</a></div><div><b>Author(s):&nbsp;</b>Tianqi Yu, Yan-Jun Liu, Lei Liu, Shaocheng Tong</div><div><b>Pages:&nbsp;</b>4939 - 4952</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9749908/\">Adaptive Image Steganography Using Fuzzy Enhancement and Grey Wolf Optimizer</a></div><div><b>Author(s):&nbsp;</b>Jialiang Xie, Honghui Wang, Dongrui Wu</div><div><b>Pages:&nbsp;</b>4953 - 4964</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9749939/\">Enhanced Multiview Fuzzy Clustering Using Double Visible-Hidden View Cooperation and Network LASSO Constraint</a></div><div><b>Author(s):&nbsp;</b>Zhaohong Deng, Ling Liang, Hongtan Yang, Wei Zhang, Qiongdan Lou, Kup-Sze Choi, Te Zhang, Jin Zhou, Shitong Wang</div><div><b>Pages:&nbsp;</b>4965 - 4979</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9749839/\">Reachable Set Estimation for T\u2013S Fuzzy Markov Jump Systems With Time-Varying Delays via Membership Function Dependent Performance</a></div><div><b>Author(s):&nbsp;</b>B. Visakamoorthi, P. Muthukumar, H. Trinh</div><div><b>Pages:&nbsp;</b>4980 - 4990</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9750865/\">Consensus Reaching With Minimum Cost of Informed Individuals and Time Constraints in Large-Scale Group Decision-Making</a></div><div><b>Author(s):&nbsp;</b>Haiming Liang, Gang Kou, Yucheng Dong, Francisco Chiclana, Enrique Herrera-Viedma</div><div><b>Pages:&nbsp;</b>4991 - 5004</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9750872/\">Sliding Mode Control for Networked Interval Type-2 Fuzzy Systems via Random Multiaccess Protocols</a></div><div><b>Author(s):&nbsp;</b>Yekai Yang, Yugang Niu, Hak-Keung Lam</div><div><b>Pages:&nbsp;</b>5005 - 5018</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9751415/\">Nonfragile Dissipative Fuzzy PID Control With Mixed Fading Measurements</a></div><div><b>Author(s):&nbsp;</b>Yezheng Wang, Zidong Wang, Lei Zou, Hongli Dong</div><div><b>Pages:&nbsp;</b>5019 - 5033</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9760164/\">A Complementary Study on General Interval Type-2 Fuzzy Sets</a></div><div><b>Author(s):&nbsp;</b>Pablo Hern\u00e1ndez, Susana Cubillo, Carmen Torres-Blanc</div><div><b>Pages:&nbsp;</b>5034 - 5043</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9697430/\">Relaxed Resilient Fuzzy Stabilization of Discrete-Time Takagi\u2013Sugeno Systems via a Higher Order Time-Variant Balanced Matrix Method</a></div><div><b>Author(s):&nbsp;</b>Xiangpeng Xie, Cong Wei, Zhou Gu, Kaibo Shi</div><div>5044 - 5050</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9739907/\">Finite-Time Composite Antidisturbance Control for T\u2013S Fuzzy Nonhomogeneous Markovian Jump Systems via Asynchronous Disturbance Observer</a></div><div><b>Author(s):&nbsp;</b>Yao Wang, Shengyuan Xu, Choon Ki Ahn</div><div><b>Pages:&nbsp;</b>5051 - 5057</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9743322/\">Reduced-Order Extended Dissipative Filtering for Nonlinear Systems With Sensor Saturation via Interval Type-2 Fuzzy Model</a></div><div><b>Author(s):&nbsp;</b>Yi Zeng, Hak-Keung Lam, Bo Xiao, Ligang Wu, Ming Chen</div><div><b>Pages:&nbsp;</b>5058 - 5064</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-11-03T18:55:00.000+13:00",
            "pubdate_parsed": [
                2022,
                11,
                3
            ],
            "email_sent": true
        },
        "Complex & Intelligent Systems, Volume 8, issue 6, December 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/11/complex-intelligent-systems-volume-8.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00843-1\">Guest editorial on \u201cdata-driven operations management\u201d</a></div><div><b>Author(s): </b>Dujuan Wang, Yugang Yu...Yunqiang Yin</div><div><b>Pages: </b>4421 - 4424</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00410-0\">Hybrid evolutionary optimization for takeaway order selection and delivery path planning utilizing habit data</a></div><div><b>Author(s):&nbsp;</b>Min-Xia Zhang, Jia-Yu Wu...Yu-Jun Zheng</div><div><b>Pages:&nbsp;</b>4425 - 4440</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00443-5\">DP-TABU: an algorithm to solve single-depot multi-line vehicle scheduling problem</a></div><div><b>Author(s):&nbsp;</b>Zhao Xinchao, Sun Hao...Li Zhiyu</div><div><b>Pages:&nbsp;</b>4441 - 4451</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00415-9\">Robust programming for basin-level water allocation with uncertain water availability and policy-driven scenario analysis</a></div><div><b>Author(s):&nbsp;</b>Liming Yao, Zerui Su, Shuhua Hou</div><div><b>Pages:&nbsp;</b>4453 - 4473</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00479-7\">EHEFT-R: multi-objective task scheduling scheme in cloud computing</a></div><div><b>Author(s):&nbsp;</b>Honglin Zhang, Yaohua Wu, Zaixing Sun</div><div><b>Pages:&nbsp;</b>4475 - 4482</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00481-z\">Using context-dependent DEA to analyze the efficiency of highly funded scientists in China</a></div><div><b>Author(s):&nbsp;</b>Keyu Xiang, Haiming Liang...Yucheng Dong</div><div><b>Pages:&nbsp;</b>4483 - 4495</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00478-8\">An enhanced group teaching optimization algorithm for multi-product disassembly line balancing problems</a></div><div><b>Author(s):&nbsp;</b>Pei Liang, Yaping Fu...Hao Sun</div><div><b>Pages:&nbsp;</b>4497 - 4512</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00492-w\">Strategic rationing and freshness keeping of perishable products under transportation disruptions and demand learning</a></div><div><b>Author(s):&nbsp;</b>Shanshan Li, Yong He, Melissza Salling</div><div><b>Pages:&nbsp;</b>4513 - 4527</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00493-9\">Portfolio optimization model with uncertain returns based on prospect theory</a></div><div><b>Author(s):&nbsp;</b>Yufeng Li, Bing Zhou, Yingxue Tan</div><div><b>Pages:&nbsp;</b>4529 - 4542</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00520-9\">Dynamic sourcing strategies for supply disruptions under consumer stockpiling</a></div><div><b>Author(s):&nbsp;</b>Shanshan Li, Yong He, Li Zhou</div><div><b>Pages:&nbsp;</b>4543 - 4555</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00554-z\">Nursing rescheduling problem with multiple rescheduling methods under uncertainty</a></div><div><b>Author(s):&nbsp;</b>Zhiren Long, Xianxiu Wen...Yongjian Yang</div><div><b>Pages:&nbsp;</b>4557 - 4569</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00605-5\">A metaheuristic-based framework for index tracking with practical constraints</a></div><div><b>Author(s):&nbsp;</b>Man-Chung Yuen, Sin-Chun Ng...Hangjun Che</div><div><b>Pages:&nbsp;</b>4571 - 4586</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00597-2\">Storage assignment optimization for fishbone robotic mobile fulfillment systems</a></div><div><b>Author(s):&nbsp;</b>Yanyan Wang, Rongjun Man...Hong Zhao</div><div><b>Pages:&nbsp;</b>4587 - 4602</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00776-9\">Optimal scheduling in cloud healthcare system using Q-learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Yafei Li, Hongfeng Wang...Tianhong Zhang</div><div><b>Pages:&nbsp;</b>4603 - 4618</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00791-w\">A two-stage stacked-based heterogeneous ensemble learning for cancer survival prediction</a></div><div><b>Author(s):&nbsp;</b>Fangzhou Yan, Yi Feng</div><div><b>Pages:&nbsp;</b>4619 - 4639</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00844-0\">Dynamic scheduling for semiconductor manufacturing systems with uncertainties using convolutional neural networks and reinforcement learning</a></div><div><b>Author(s):&nbsp;</b>Juan Liu, Fei Qiao...Birgit Vogel-Heuser</div><div><b>Pages:&nbsp;</b>4641 - 4662</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00608-2\">ETHOS: a multi-label hate speech detection dataset</a></div><div><b>Author(s):&nbsp;</b>Ioannis Mollas, Zoe Chrysopoulou...Grigorios Tsoumakas</div><div><b>Pages:&nbsp;</b>4663 - 4678</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00716-7\">Multi-colony ant optimization with dynamic collaborative mechanism and cooperative game</a></div><div><b>Author(s):&nbsp;</b>Yadong Mo, Xiaoming You, Sheng Liu</div><div><b>Pages:&nbsp;</b>4679 - 4696</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00714-9\">A competitive swarm optimizer with probabilistic criteria for many-objective optimization problems</a></div><div><b>Author(s):&nbsp;</b>Chao He, Ming Li...Junhua Li</div><div><b>Pages:&nbsp;</b>4697 - 4725</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00727-4\">A system for electric vehicle\u2019s energy-aware routing in a transportation network through real-time prediction of energy consumption</a></div><div><b>Author(s):&nbsp;</b>Shatrughan Modi, Jhilik Bhattacharya</div><div><b>Pages:&nbsp;</b>4727 - 4751</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00722-9\">MSAt-GAN: a generative adversarial network based on multi-scale and deep attention mechanism for infrared and visible light image fusion</a></div><div><b>Author(s):&nbsp;</b>Junwu Li, Binhua Li...Weiwei Cai</div><div><b>Pages:&nbsp;</b>4753 - 4781</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00725-6\">Fuzzy acceptance sampling plan for transmuted Weibull distribution</a></div><div><b>Author(s):&nbsp;</b>Muhammad Zahir Khan, Muhammad Farid Khan...Abdur Razzaque Mughal</div><div><b>Pages:&nbsp;</b>4783 - 4795</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00728-3\">Self-attention-guided scale-refined detector for pedestrian detection</a></div><div><b>Author(s):&nbsp;</b>Xinchen Lin, Chaoqiang Zhao...Feng Qian</div><div><b>Pages:&nbsp;</b>4797 - 4809</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00730-9\">A hybrid multi-objective bi-level interactive fuzzy programming method for solving ECM-DWTA problem</a></div><div><b>Author(s):&nbsp;</b>Luda Zhao, Zongxu An...Yihua Hu</div><div><b>Pages:&nbsp;</b>4811 - 4829</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00733-6\">A wavelet convolutional capsule network with modified super resolution generative adversarial network for fault diagnosis and classification</a></div><div><b>Author(s):&nbsp;</b>Happy Nkanta Monday, Jianping Li...Ariyo Oluwasanmi</div><div><b>Pages:&nbsp;</b>4831 - 4847</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00738-1\">A Lagrangian dual-based theory-guided deep neural network</a></div><div><b>Author(s):&nbsp;</b>Miao Rong, Dongxiao Zhang, Nanzhe Wang</div><div><b>Pages:&nbsp;</b>4849 - 4862</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00739-0\">Strengthening intrusion detection system for adversarial attacks: improved handling of imbalance classification problem</a></div><div><b>Author(s):&nbsp;</b>Chutipon Pimsarn, Tossapon Boongoen...Longzhi Yang</div><div><b>Pages:&nbsp;</b>4863 - 4880</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00720-x\">Parameters and reliability estimation for the weibull distribution based on intuitionistic fuzzy lifetime data</a></div><div><b>Author(s):&nbsp;</b>Zahra Roohanizadeh, Ezzatallah Baloui Jamkhaneh, Einolah Deiri</div><div><b>Pages:&nbsp;</b>4881 - 4896</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00741-6\">Deep convolutional forest: a dynamic deep ensemble approach for spam detection in text</a></div><div><b>Author(s):&nbsp;</b>Mai A. Shaaban, Yasser F. Hassan, Shawkat K. Guirguis</div><div><b>Pages:&nbsp;</b>4897 - 4909</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00718-5\">A new method for image processing using generalized linguistic neutrosophic cubic aggregation operator</a></div><div><b>Author(s):&nbsp;</b>Gagandeep Kaur, Harish Garg</div><div><b>Pages:&nbsp;</b>4911 - 4937</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00719-4\">Modeling stochastic service time for complex on-demand food delivery</a></div><div><b>Author(s):&nbsp;</b>Jie Zheng, Ling Wang...Xuetao Ding</div><div><b>Pages:&nbsp;</b>4939 - 4953</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00721-w\">New extension of ordinal priority approach for multiple attribute decision-making problems: design and analysis</a></div><div><b>Author(s):&nbsp;</b>Mohamed Abdel-Basset, Mai Mohamed...Mohamed Abd Elfattah</div><div><b>Pages:&nbsp;</b>4955 - 4970</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00746-1\">An improved artificial bee colony algorithm based on Bayesian estimation</a></div><div><b>Author(s):&nbsp;</b>Chunfeng Wang, Pengpeng Shang, Peiping Shen</div><div><b>Pages:&nbsp;</b>4971 - 4991</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00752-3\">Automatic data volley: game data acquisition with temporal-spatial filters</a></div><div><b>Author(s):&nbsp;</b>Xina Cheng, Linzi Liang, Takeshi Ikenaga</div><div><b>Pages:&nbsp;</b>4993 - 5010</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00723-8\">A novel method to estimate incomplete PLTS information based on knowledge-match degree with reliability and its application in LSGDM problem</a></div><div><b>Author(s):&nbsp;</b>Huimin Xiao, Shouwen Wu, Liu Wang</div><div><b>Pages:&nbsp;</b>5011 - 5026</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00726-5\">New bag-of-feature for histopathology image classification using reinforced cat swarm algorithm and weighted Gaussian mixture modelling</a></div><div><b>Author(s):&nbsp;</b>Surbhi Vijh, Sumit Kumar, Mukesh Saraswat</div><div><b>Pages:&nbsp;</b>5027 - 5046</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00751-4\">A two-stage infill strategy and surrogate-ensemble assisted expensive many-objective optimization</a></div><div><b>Author(s):&nbsp;</b>Yi Zhao, Jian Zhao...Ying Tan</div><div><b>Pages:&nbsp;</b>5047 - 5063</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00755-0\">End-to-end human inspired learning based system for dynamic obstacle avoidance</a></div><div><b>Author(s):&nbsp;</b>S. M. Haider Jafri, Rahul Kala</div><div><b>Pages:&nbsp;</b>5065 - 5086</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00737-2\">Assessing cloud manufacturing applications using an optimally rectified FAHP approach</a></div><div><b>Author(s):&nbsp;</b>Tin-Chih Toly Chen, Chi-Wei Lin</div><div><b>Pages:&nbsp;</b>5087 - 5099</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00740-7\">Design and implementation of fault-tolerant control strategies for a real underactuated manipulator robot</a></div><div><b>Author(s):&nbsp;</b>Claudio Urrea, John Kern, Exequiel \u00c1lvarez</div><div><b>Pages:&nbsp;</b>5101 - 5123</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00744-3\">Star topology convolution for graph representation learning</a></div><div><b>Author(s):&nbsp;</b>Chong Wu, Zhenan Feng...Hong Yan</div><div><b>Pages:&nbsp;</b>5125 - 5141</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00731-8\">Student achievement prediction using deep neural network from multi-source campus data</a></div><div><b>Author(s):&nbsp;</b>Xiaoyong Li, Yong Zhang...Baocai Yin</div><div><b>Pages:&nbsp;</b>5143 - 5156</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00747-0\">A decomposition-based many-objective evolutionary algorithm with optional performance indicators</a></div><div><b>Author(s):&nbsp;</b>Hao Wang, Chaoli Sun...Xiaobo Li</div><div><b>Pages:&nbsp;</b>5157 - 5176</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00754-1\">Hall effect on MHD Jeffrey fluid flow with Cattaneo\u2013Christov heat flux model: an application of stochastic neural computing</a></div><div><b>Author(s):&nbsp;</b>Muhammad Awais, Huma Rehman...Muhammad Yousaf Malik</div><div><b>Pages:&nbsp;</b>5177 - 5201</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00732-7\">Complex system health condition estimation using tree-structured simple recurrent unit networks</a></div><div><b>Author(s):&nbsp;</b>Weijie Kang, Jiyang Xiao, Junjie Xue</div><div><b>Pages:&nbsp;</b>5203 - 5221</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00743-4\">Fermatean fuzzy copula aggregation operators and similarity measures-based complex proportional assessment approach for renewable energy source selection</a></div><div><b>Author(s):&nbsp;</b>Arunodaya Raj Mishra, Pratibha Rani...Ronald R. Yager</div><div><b>Pages:&nbsp;</b>5223 - 5248</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00745-2\">Deep multi-layer perceptron-based evolutionary algorithm for dynamic multiobjective optimization</a></div><div><b>Author(s):&nbsp;</b>Zhen Zhu, Yanpeng Yang...Yingfeng Cai</div><div><b>Pages:&nbsp;</b>5249 - 5264</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00757-y\">An associative knowledge network model for interpretable semantic representation of noun context</a></div><div><b>Author(s):&nbsp;</b>Yulin Li, Zhenping Xie, Fanyu Wang</div><div><b>Pages:&nbsp;</b>5265 - 5285</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00759-w\">Machine learning-based framework to cover optimal Pareto-front in many-objective optimization</a></div><div><b>Author(s):&nbsp;</b>Azam Asilian Bidgoli, Shahryar Rahnamayan...Ali Grami</div><div><b>Pages:&nbsp;</b>5287 - 5308</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00763-0\">Online group streaming feature selection using entropy-based uncertainty measures for fuzzy neighborhood rough sets</a></div><div><b>Author(s):&nbsp;</b>Jiucheng Xu, Yuanhao Sun...Qinchen Hou</div><div><b>Pages:&nbsp;</b>5309 - 5328</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00699-5\">Gradient-supervised person re-identification based on dense feature pyramid network</a></div><div><b>Author(s):&nbsp;</b>Shaoqi Hou, Kangning Yin...Guangqiang Yin</div><div><b>Pages:&nbsp;</b>5329 - 5342</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00758-x\">Generalized fuzzy ideals in ordered semirings</a></div><div><b>Author(s):&nbsp;</b>G. Muhiuddin, Ahsan Mahboob, N. Abughazalah</div><div><b>Pages:&nbsp;</b>5343 - 5353</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00761-2\">A self-organizing map approach for constrained multi-objective optimization problems</a></div><div><b>Author(s):&nbsp;</b>Chao He, Ming Li...Junhua Li</div><div><b>Pages:&nbsp;</b>5355 - 5375</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00762-1\">Discriminative and efficient non-local attention network for league of legends highlight detection</a></div><div><b>Author(s):&nbsp;</b>Qian Wan, Aruna Wang...Jiaji Wu</div><div><b>Pages:&nbsp;</b>5377 - 5386</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00748-z\">A novel kinematics and statics correction algorithm of semi-cylindrical foot end structure for 3-DOF LHDS of legged robots</a></div><div><b>Author(s):&nbsp;</b>Kai-xian Ba, Yan-he Song...Xiang-dong Kong</div><div><b>Pages:&nbsp;</b>5387 - 5407</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00749-y\">Complex Pythagorean uncertain linguistic group decision-making model based on Heronian mean aggregation operator considering uncertainty, interaction and interrelationship</a></div><div><b>Author(s):&nbsp;</b>Haolun Wang, Faming Zhang</div><div><b>Pages:&nbsp;</b>5409 - 5438</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00769-8\">Trajectory prediction based on conditional Hamiltonian generative network for incomplete observation image sequences</a></div><div><b>Author(s):&nbsp;</b>Kui Qian, Lei Tian, Aiguo Song</div><div><b>Pages:&nbsp;</b>5439 - 5448</div><div><br /></div><div><b>58)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00772-z\">Cyberbullying detection using deep transfer learning</a></div><div><b>Author(s):&nbsp;</b>Pradeep Kumar Roy, Fenish Umeshbhai Mali</div><div><b>Pages:&nbsp;</b>5449 - 5467</div><div><br /></div><div><b>59)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00764-z\">Diagnosis of rotor demagnetization and eccentricity faults for IPMSM based on deep CNN and image recognition</a></div><div><b>Author(s):&nbsp;</b>Zhiyuan Li, Qinmu Wu...Xiangping Chen</div><div><b>Pages:&nbsp;</b>5469 - 5488</div><div><br /></div><div><b>60)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00774-x\">A novel ensemble feature selection method for pixel-level segmentation of HER2 overexpression</a></div><div><b>Author(s):&nbsp;</b>Ana Aguilera, Raquel Pezoa, Andrea Rodr\u00edguez-Delherbe</div><div><b>Pages:&nbsp;</b>5489 - 5510</div><div><br /></div><div><b>61)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00770-1\">Distributed neurodynamic approaches to nonsmooth optimization problems with inequality and set constraints</a></div><div><b>Author(s):&nbsp;</b>Linhua Luan, Xingnan Wen, Sitian Qin</div><div><b>Pages:&nbsp;</b>5511 - 5530</div><div><br /></div><div><b>62)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00750-5\">Survey on clothing image retrieval with cross-domain</a></div><div><b>Author(s):&nbsp;</b>Chen Ning, Yang Di, Li Menglu</div><div><b>Pages:&nbsp;</b>5531 - 5544</div><div><br /></div><div><b>63)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00724-7\">The use of deep learning methods in low-dose computed tomography image reconstruction: a systematic review</a></div><div><b>Author(s):&nbsp;</b>Minghan Zhang, Sai Gu, Yuhui Shi</div><div><b>Pages:&nbsp;</b>5545 - 5561</div><div><br /></div><div><b>64)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00753-2\">Correction to: Control in the loop for synchronization of nonlinear chaotic systems via adaptive intuitionistic neuro-fuzzy: a comparative study</a></div><div><b>Author(s):&nbsp;</b>Salah Helmy, Mohamed Magdy, Mohamed Hamdy</div><div><b>Pages:&nbsp;</b>5563 - 5563</div><div><br /></div><div><b>65)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00768-9\">Correction to: Joint metric learning of local and global features for vehicle re-identification</a></div><div><b>Author(s):&nbsp;</b>Junge Shen, Jian Sun...Zhaoyong Mao</div><div><b>Pages:&nbsp;</b>5565 - 5565</div><div><br /></div><div><br /></div></div>",
            "pubdate": "2022-11-04T13:21:00.000+13:00",
            "pubdate_parsed": [
                2022,
                11,
                4
            ],
            "email_sent": true
        },
        "AI Conferences 2023 - Part 2": {
            "url": "https://computational-intelligence.blogspot.com/2022/11/ai-conferences-2023-part-2.html",
            "description": "<div style=\"text-align: left;\"><div><div>This post follows <a href=\"https://computational-intelligence.blogspot.com/2022/09/ai-conferences-in-2023.html\">an earlier one</a>, and lists additional AI conferences being offered in 2023.</div><div><br /></div><div><b><u>12th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2023)</u></b></div><div>22-24 February 2023</div><div><a href=\"https://en.wikipedia.org/wiki/Lisbon\">Lisbon, Portugal</a></div><div>General Chair: Ana Fred</div><div>Website: <a href=\"https://icpram.scitevents.org\">https://icpram.scitevents.org</a></div><div><br /></div><div><b><u>15th International Conference on Agents and Artificial Intelligence (ICAART 2023)</u></b></div><div>22-24 February 2023</div><div><a href=\"https://en.wikipedia.org/wiki/Lisbon\">Lisbon, Portugal</a></div><div>General Chair: Jaap van den Herik</div><div>Website: <a href=\"https://icaart.scitevents.org\">https://icaart.scitevents.org</a></div><div><br /></div></div><div><b><u>2023 IEEE Swiss Conference on Data Science (IEEE SDS 2023)</u></b></div><div>22-23 June 2023</div><div><a href=\"https://en.wikipedia.org/wiki/Z%C3%BCrich\">Zurich, Switzerland</a>&nbsp;</div><div>General Chair: Melanie Geiger</div><div>Website: <a href=\"https://sds2023.ch/\">https://sds2023.ch/</a></div><div><br /></div><div><b><u>2023 IEEE Smart World Congress (IEEE SWC 2023)</u></b></div><div>25-28 August 2023</div><div><a href=\"https://en.wikipedia.org/wiki/Portsmouth\">Portsmouth, UK</a>&nbsp;</div><div>General chairs: Hui Yu and Man Lin</div><div>Website:&nbsp;<a href=\"https://ieee-smart-world-congress.org/\">https://ieee-smart-world-congress.org/</a></div><div><br /></div><div><b><u>2023 IEEE Symposium Series on Computational Intelligence (IEEE SSCI 2023)</u></b></div><div>6-8 December 2023</div><div><a href=\"https://en.wikipedia.org/wiki/Mexico_City\">Mexico City, Mexico</a>&nbsp;</div><div>General Chair: Wen Yu&nbsp;</div><div>Website: <a href=\"https://attend.ieee.org/ssci-2023/\">https://attend.ieee.org/ssci-2023/</a></div><div><br /></div></div>",
            "pubdate": "2022-11-08T13:55:00.000+13:00",
            "pubdate_parsed": [
                2022,
                11,
                8
            ],
            "email_sent": true
        },
        "IEEE Transactions on Artificial Intelligence, Volume 3, Issue 6, December 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/11/ieee-transactions-on-artificial.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9645355/\">Recent Advances in Trustworthy Explainable Artificial Intelligence: Status, Challenges, and Perspectives</a></div><div><b>Author(s): </b>Atul Rawal, James McCoy, Danda B. Rawat, Brian M. Sadler, Robert St. Amant</div><div><b>Pages: </b>852 - 866</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9736644/\">An Overview of Emotion in Artificial Intelligence</a></div><div><b>Author(s):&nbsp;</b>Gustavo Assun\u00e7\u00e3o, Bruno Patr\u00e3o, Miguel Castelo-Branco, Paulo Menezes</div><div><b>Pages:&nbsp;</b>867 - 886</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9762529/\">The New Generation Brain-Inspired Sparse Learning: A Comprehensive Survey</a></div><div><b>Author(s):&nbsp;</b>Licheng Jiao, Yuting Yang, Fang Liu, Shuyuan Yang, Biao Hou</div><div><b>Pages:&nbsp;</b>887 - 907</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9645219/\">Intellectual Property Protection for Deep Learning Models: Taxonomy, Methods, Attacks, and Evaluations</a></div><div><b>Author(s):&nbsp;</b>Mingfu Xue, Yushu Zhang, Jian Wang, Weiqiang Liu</div><div><b>Pages:&nbsp;</b>908 - 923</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9878189/\">Integrating Constraints Into Dimensionality Reduction for Visualization: A Survey</a></div><div><b>Author(s):&nbsp;</b>Viet Minh Vu, Adrien Bibal, Beno\u00eet Fr\u00e9nay</div><div><b>Pages:&nbsp;</b>944 - 962</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9645169/\">Decentralized Deep Learning for Multi-Access Edge Computing: A Survey on Communication Efficiency and Trustworthiness</a></div><div><b>Author(s):&nbsp;</b>Yuwei Sun, Hideya Ochiai, Hiroshi Esaki</div><div><b>Pages:&nbsp;</b>963 - 972</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9738474/\">On Supervised Class-Imbalanced Learning: An Updated Perspective and Some Key Challenges</a></div><div><b>Author(s):&nbsp;</b>Swagatam Das, Sankha Subhra Mullick, Ivan Zelinka</div><div><b>Pages:&nbsp;</b>973 - 993</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9893751/\">A Survey on Siamese Network: Methodologies, Applications, and Opportunities</a></div><div><b>Author(s):&nbsp;</b>Yikai Li, C. L. Philip Chen, Tong Zhang</div><div><b>Pages:&nbsp;</b>994 - 1014</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9850361/\">Semisupervised Deep Learning for Image Classification With Distribution Mismatch: A Survey</a></div><div><b>Author(s):&nbsp;</b>Saul Calderon-Ramirez, Shengxiang Yang, David Elizondo</div><div><b>Pages:&nbsp;</b>1015 - 1029</div><div><br /></div>",
            "pubdate": "2022-11-24T21:45:00.000+13:00",
            "pubdate_parsed": [
                2022,
                11,
                24
            ],
            "email_sent": true
        },
        "IEEE Transactions on Emerging Topics in Computational Intelligence, Volume 6, Issue 6, December 2022": {
            "url": "https://computational-intelligence.blogspot.com/2022/12/ieee-transactions-on-emerging-topics-in.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9965783/\">Guest Editorial Special Issue on Computational Intelligence for Perception and Decision-Making of Autonomous Systems</a></div><div><b>Author(s): </b>Yang Tang, Gary G. Yen, J\u00fcrgen Kurths</div><div><b>Pages: </b>1287 - 1289</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9776555/\">Monitoring Social Distancing With Single Image Depth Estimation</a></div><div><b>Author(s):&nbsp;</b>Alessio Mingozzi, Andrea Conti, Filippo Aleotti, Matteo Poggi, Stefano Mattoccia</div><div><b>Pages:&nbsp;</b>1290 - 1301</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9756199/\">Pharmaceutical Foreign Particle Detection: An Efficient Method Based on Adaptive Convolution and Multiscale Attention</a></div><div><b>Author(s):&nbsp;</b>Junfei Yi, Hui Zhang, Jianxu Mao, Yurong Chen, Hang Zhong, Yaonan Wang</div><div><b>Pages:&nbsp;</b>1302 - 1313</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9730833/\">Efficient Brain Decoding Based on Adaptive EEG Channel Selection and Transformation</a></div><div><b>Author(s):&nbsp;</b>Jiaxing Wang, Lei Shi, Weiqun Wang, Zeng-Guang Hou</div><div><b>Pages:&nbsp;</b>1314 - 1323</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9687093/\">Optimal Actor-Critic Policy With Optimized Training Datasets</a></div><div><b>Author(s):&nbsp;</b>Chayan Banerjee, Zhiyong Chen, Nasimul Noman, Mohsen Zamani</div><div><b>Pages:&nbsp;</b>1324 - 1334</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9775710/\">Decision Making in Monopoly Using a Hybrid Deep Reinforcement Learning Approach</a></div><div><b>Author(s):&nbsp;</b>Trevor Bonjour, Marina Haliem, Aala Alsalem, Shilpa Thomas, Hongyu Li, Vaneet Aggarwal, Mayank Kejriwal, Bharat Bhargava</div><div><b>Pages:&nbsp;</b>1335 - 1344</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9754220/\">Motion Planning and Cooperative Manipulation for Mobile Robots With Dual Arms</a></div><div><b>Author(s):&nbsp;</b>Fuchun Sun, Yang Chen, Yangyang Wu, Linxiang Li, Xiaolei Ren</div><div><b>Pages:&nbsp;</b>1345 - 1356</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9628154/\">Multi-Robot Learning Dynamic Obstacle Avoidance in Formation With Information-Directed Exploration</a></div><div><b>Author(s):&nbsp;</b>Junjie Cao, Yujie Wang, Yong Liu, Xuesong Ni</div><div><b>Pages:&nbsp;</b>1357 - 1367</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9770581/\">FedPCC: Parallelism of Communication and Computation for Federated Learning in Wireless Networks</a></div><div><b>Author(s):&nbsp;</b>Hong Zhang, Hao Tian, Mianxiong Dong, Kaoru Ota,&nbsp;</div><div>Juncheng Jia</div><div><b>Pages:&nbsp;</b>1368 - 1377</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9715148/\">Dynamic Network Structure: Doubly Stacking Broad Learning Systems With Residuals and Simpler Linear Model Transmission</a></div><div><b>Author(s):&nbsp;</b>Runshan Xie, Chi-Man Vong, C. L. Philip Chen, Shitong Wang</div><div><b>Pages:&nbsp;</b>1378 - 1395</div><div><br /></div><div><b>11) </b><a href=\"https://ieeexplore.ieee.org/document/9768859/\">A Deep 1-D CNN and Bidirectional LSTM Ensemble Model With Arbitration Mechanism for LDDoS Attack Detection</a></div><div><b>Author(s):&nbsp;</b>Zengguang Liu, Jiguo Yu, Biwei Yan, Guijuan Wang</div><div><b>Pages:&nbsp;</b>1396 - 1410</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9806713/\">Distributed Continuous and Discrete Time Projection Neurodynamic Approaches for Sparse Recovery</a></div><div><b>Author(s):&nbsp;</b>You Zhao, Xiaofeng Liao, Xing He</div><div><b>Pages:&nbsp;</b>1411 - 1426</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9826434/\">Taking Away Both Model and Data: Remember Training Data by Parameter Combinations</a></div><div><b>Author(s):&nbsp;</b>Wenjian Luo, Licai Zhang, Peiyi Han, Chuanyi Liu, Rongfei Zhuang</div><div><b>Pages:&nbsp;</b>1427 - 1437</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9778848/\">A Buffer-Based Ant Colony System Approach for Dynamic Cold Chain Logistics Scheduling</a></div><div><b>Author(s):&nbsp;</b>Li-Jiao Wu, Lin Shi, Zhi-Hui Zhan, Kuei-Kuei Lai, Jun Zhang</div><div><b>Pages:&nbsp;</b>1438 - 1452</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9956871/\">Unsupervised Feature Selection Using Iterative Shrinking and Expansion Algorithm</a></div><div><b>Author(s):&nbsp;</b>Tapas Bhadra, Ujjwal Maulik</div><div><b>Pages:&nbsp;</b>1453 - 1462</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9805994/\">A Deep Integrated Framework for Predicting SARS-CoV2\u2013Human Protein-Protein Interaction</a></div><div><b>Author(s):&nbsp;</b>Sumanta Ray, Snehalika Lall, Sanghamitra Bandyopadhyay</div><div><b>Pages:&nbsp;</b>1463 - 1472</div><div><br /></div></div>",
            "pubdate": "2022-12-02T15:03:00.000+13:00",
            "pubdate_parsed": [
                2022,
                12,
                2
            ],
            "email_sent": true
        },
        "IEEE Transactions on Fuzzy Systems, Volume 31, Issue 1, January 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/01/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9788034/\">Stability and Stabilization of Polynomial Fuzzy-Model-Based Switched Nonlinear Systems Under MDADT Switching Signal</a></div><div><b>Author(s): </b>Zhiyong Bao, Hak-Keung Lam, Yong Peng, Fucai Liu, Kamyar Mehran</div><div><b>Pages: </b>1 - 13</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9787996/\">Adaptive Fuzzy Sliding Exact Tracking Control Based on High-Order Log-Type Time-Varying BLFs for High-Order Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Qiang Zhang, Dakuo He</div><div><b>Pages:&nbsp;</b>14 - 24</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9789396/\">Two Integral Models and Applications of Hesitant Fuzzy Information Fusion</a></div><div><b>Author(s):&nbsp;</b>Jie Gao, Zeshui Xu, Zhilei Liang, Yunshu Mao</div><div><b>Pages:&nbsp;</b>25 - 39</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9792631/\">Membership-Function-Dependent Design of Quantized Fuzzy Sampled-Data Controller for Semi-Markovian Jump Systems With Actuator Faults</a></div><div><b>Author(s):&nbsp;</b>R. Vijay Aravind, P. Balasubramaniam</div><div><b>Pages:&nbsp;</b>40 - 52</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9792630/\">Robust Pricing for a Dual-Channel Green Supply Chain Under Fuzzy Demand Ambiguity</a></div><div><b>Author(s):&nbsp;</b>Huili Pei, Yankui Liu, Hongliang Li</div><div><b>Pages:&nbsp;</b>53 - 66</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9792632/\">Event-Triggered Fixed-Time Practical Tracking Control for Flexible-Joint Robot</a></div><div><b>Author(s):&nbsp;</b>Yingkang Xie, Qian Ma, Jason Gu, Guopeng Zhou</div><div><b>Pages:&nbsp;</b>67 - 76</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9795240/\">Fuzzy Mutual Information-Based Multilabel Feature Selection With Label Dependency and Streaming Labels</a></div><div><b>Author(s):&nbsp;</b>Jinghua Liu, Yaojin Lin, Weiping Ding, Hongbo Zhang, Jixiang Du</div><div><b>Pages:&nbsp;</b>77 - 91</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9795258/\">An Intelligent Digital Redesign Approach to the Sampled-Data Fuzzy Observer Design</a></div><div><b>Author(s):&nbsp;</b>Yong Hoon Jang, Kwangil Lee, Han Sol Kim</div><div><b>Pages:&nbsp;</b>92 - 103</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9795905/\">Adaptive Fuzzy Tracking Control for Uncertain Nonlinear Systems With Multiple Actuators and Sensors Faults</a></div><div><b>Author(s):&nbsp;</b>Dengxiu Yu, Ming Yang, Yan-Jun Liu, Zhen Wang, C. L. Philip Chen</div><div><b>Pages:&nbsp;</b>104 - 116</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9795884/\">Finite-Time Adaptive Fuzzy Event-Triggered Control of Constrained Nonlinear Systems via Bounded Command Filter</a></div><div><b>Author(s):&nbsp;</b>Zhibao Song, Ping Li, Zongyao Sun, Zhen Wang</div><div><b>Pages:&nbsp;</b>117 - 128</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9795868/\">Stability Analysis of Time-Varying Delay T\u2013S Fuzzy Systems via Quadratic-Delay-Product Method</a></div><div><b>Author(s):&nbsp;</b>Yunfei Qiu, Ju H. Park, Changchun Hua, Xijuan Wang</div><div><b>Pages:&nbsp;</b>129 - 137</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9797877/\">Adaptive Event-Triggered Control of Stochastic Nonlinear Systems With Unknown Dead Zone</a></div><div><b>Author(s):&nbsp;</b>Tong Wang, Nan Wang, Jianbin Qiu, Concettina Buccella, Carlo Cecati</div><div><b>Pages:&nbsp;</b>138 - 147</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9797865/\">Decentralized Event-Triggered Adaptive Control for Interconnected Nonlinear Systems With Actuator Failures</a></div><div><b>Author(s):&nbsp;</b>Lin-Xing Xu, Yu-Long Wang, Xiaofan Wang, Chen Peng</div><div><b>Pages:&nbsp;</b>148 - 159</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9799748/\">dCF-Integrals: Generalizing CF-Integrals by Means of Restricted Dissimilarity Functions</a></div><div><b>Author(s):&nbsp;</b>Jonata Wieczynski, Giancarlo Lucca, Gra\u00e7aliz P. Dimuro, Eduardo N. Borges, Jos\u00e9 A. Sanz, Tiago da Cruz Asmus, Javier Fern\u00e1ndez, Humberto Bustince</div><div><b>Pages:&nbsp;</b>160 - 173</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9799735/\">Nonsingular Fixed-Time Fault-Tolerant Fuzzy Control for Switched Uncertain Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Di Cui, Zhengrong Xiang</div><div><b>Pages:&nbsp;</b>174 - 183</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9802687/\">Disturbance-Observer-Based Adaptive Fuzzy Tracking Control for Unmanned Autonomous Helicopter With Flight Boundary Constraints</a></div><div><b>Author(s):&nbsp;</b>Haoxiang Ma, Mou Chen, Gang Feng, Qingxian Wu</div><div><b>Pages:&nbsp;</b>184 - 198</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9802711/\">Fuzzy Markov Decision-Making Model for Interference Effects</a></div><div><b>Author(s):&nbsp;</b>Xiaozhuan Gao, Lipeng Pan, Danilo Pelusi, Yong Deng</div><div><b>Pages:&nbsp;</b>199 - 212</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9804219/\">Feature Grouping and Selection With Graph Theory in Robust Fuzzy Rough Approximation Space</a></div><div><b>Author(s):&nbsp;</b>Jihong Wan, Hongmei Chen, Tianrui Li, Binbin Sang, Zhong Yuan</div><div><b>Pages:&nbsp;</b>213 - 225</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9804229/\">Command Filter-Based Adaptive Fuzzy Finite-Time Tracking Control for Uncertain Fractional-Order Nonlinear Systems</a></div><div><b>Author(s):&nbsp;</b>Xingxing You, Songyi Dian, Kai Liu, Bin Guo, Guofei Xiang, Yuqi Zhu</div><div><b>Pages:&nbsp;</b>226 - 240</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9804222/\">Fuzzy-Based Optimization and Control of a Soft Exosuit for Compliant Robot\u2013Human\u2013Environment Interaction</a></div><div><b>Author(s):&nbsp;</b>Qinjian Li, Wen Qi, Zhijun Li, Haisheng Xia, Yu Kang, Lin Cheng</div><div><b>Pages:&nbsp;</b>241 - 253</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9804236/\">Layer Normalization for TSK Fuzzy System Optimization in Regression Problems</a></div><div><b>Author(s):&nbsp;</b>Yuqi Cui, Yifan Xu, Ruimin Peng, Dongrui Wu</div><div><b>Pages:&nbsp;</b>254 - 264</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9804850/\">Further Stability Criteria for Sampled-Data-Based Interval Type-2 Fuzzy Systems via a Refined Two-Side Looped-Functional Method</a></div><div><b>Author(s):&nbsp;</b>Zheng You, Huaicheng Yan, Hao Zhang, Lu Zeng, Meng Wang</div><div><b>Pages:&nbsp;</b>265 - 277</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9804802/\">Resilient Adaptive Event-Triggered H\u221e Fuzzy Filtering for Cyber-Physical Systems Under Stochastic-Sampling and Denial-of-Service Attacks</a></div><div><b>Author(s):&nbsp;</b>Xuhuan Xie, Songlin Hu, Yonggui Liu, Qinxue Li</div><div><b>Pages:&nbsp;</b>278 - 292</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9806311/\">Consensus Reaching Process With Multiobjective Optimization for Large-Scale Group Decision Making With Cooperative Game</a></div><div><b>Author(s):&nbsp;</b>Peng Wu, Fengen Li, Jie Zhao, Ligang Zhou, Luis Mart\u00ednez</div><div><b>Pages:&nbsp;</b>293 - 306</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9806378/\">Opinion Dynamics and Minimum Adjustment-Driven Consensus Model for Multi-Criteria Large-Scale Group Decision Making Under a Novel Social Trust Propagation Mechanism</a></div><div><b>Author(s):&nbsp;</b>Peide Liu, Yueyuan Li, Peng Wang</div><div><b>Pages:&nbsp;</b>307 - 321</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9810512/\">Stock Selection System Through Suitability Index and Fuzzy-Based Quantitative Characteristics</a></div><div><b>Author(s):&nbsp;</b>Jia-Hao Syu, Jerry Chun-Wei Lin, Chi-Jen Wu, Jan-Ming Ho</div><div><b>Pages:&nbsp;</b>322 - 334</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9795253/\">Characterization of Nested Lattice Codes Through Quotient Groups Relative to Normal Fuzzy Subgroups for Channel Quantization</a></div><div><b>Author(s):&nbsp;</b>Cibele Cristina Trinca, Ricardo Augusto Watanabe, Estev\u00e3o Esmi</div><div><b>Pages:&nbsp;</b>335 - 342</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9795256/\">On a Parametric Measure of Vagueness</a></div><div><b>Author(s):&nbsp;</b>J\u00f3zsef Dombi, Tam\u00e1s J\u00f3n\u00e1s</div><div><b>Pages:&nbsp;</b>343 - 347</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9795351/\">Constrained Control for a Class of TS Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Souhail Tiko, Fouad Mesquine</div><div><b>Pages:&nbsp;</b>348 - 353</div><div><br /></div></div>",
            "pubdate": "2023-01-06T18:27:00.000+13:00",
            "pubdate_parsed": [
                2023,
                1,
                6
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 27, Issue 1": {
            "url": "https://computational-intelligence.blogspot.com/2023/01/soft-computing-volume-27-issue-1.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07548-0\">On Alexandrov L-fuzzy nearness (II)</a></div><div><b>Author(s): </b>Enas H. Elkordy, Ahmed A. Ramadan, Reham M. Ahmed</div><div><b>Pages: </b>1 - 16</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07547-1\">A study on the normality of Wijsman topology of a fuzzy metric space</a></div><div><b>Author(s):&nbsp;</b>Zia Bashir, Asad Ullah</div><div><b>Pages:&nbsp;</b>17 - 23</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07550-6\">An alternative approach to quadratic scoring rules using continuous-valued logic</a></div><div><b>Author(s):&nbsp;</b>J\u00f3zsef Dombi, Tam\u00e1s J\u00f3n\u00e1s</div><div><b>Pages:&nbsp;</b>25 - 46</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07601-y\">Some new generalized difference of sequences for fuzzy numbers</a></div><div><b>Author(s):&nbsp;</b>Abdulkadir Karaka\u015f</div><div><b>Pages:&nbsp;</b>47 - 55</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07521-x\">On separation axioms of topological rough groups</a></div><div><b>Author(s):&nbsp;</b>Pi-Yu Li, Wen-Li Liu...Zhi-Fang Guo</div><div><b>Pages:&nbsp;</b>57 - 61</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07522-w\">Ship detection based on deep learning using SAR imagery: a systematic literature review</a></div><div><b>Author(s):&nbsp;</b>Muhammad Yasir, Wan Jianhua...Md Sakaouth Hossain</div><div><b>Pages:&nbsp;</b>63 - 84</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07566-y\">A variable precision multigranulation rough set model and attribute reduction</a></div><div><b>Author(s):&nbsp;</b>Jiayue Chen. Ping Zhu</div><div><b>Pages:&nbsp;</b>85 - 106</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07567-x\">An adaptive replica configuration mechanism based on predictive file popularity and queue balance in mobile edge computing environment</a></div><div><b>Author(s):&nbsp;</b>Mao-Lun Chiang, Hui-Ching Hsieh...Hong-Wei Chen</div><div><b>Pages:&nbsp;</b>107 - 129</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07583-x\">Mp- and purified residuated lattices</a></div><div><b>Author(s):&nbsp;</b>Saeed Rasouli, Amin Dehghani</div><div><b>Pages:&nbsp;</b>131 - 148</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07555-1\">Assessing the best art design based on artificial intelligence and machine learning using GTMA</a></div><div><b>Author(s):&nbsp;</b>Xu Wenjing, Zilu Cai</div><div><b>Pages:&nbsp;</b>149 - 156</div><div><br /></div><div><b>11) </b><a href=\"https://link.springer.com/article/10.1007/s00500-022-07556-0\">Using the fuzzy analytical hierarchy process to prioritize the impact of visual communication based on artificial intelligence for long-term learning</a></div><div><b>Author(s):&nbsp;</b>Yadi Liu, Abdullah A. Al-Atawi...Qamar Zaman</div><div><b>Pages:&nbsp;</b>157 - 168</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07569-9\">Industry 4.0 implementation challenges in small- and medium-sized enterprises: an approach integrating interval type-2 fuzzy BWM and DEMATEL</a></div><div><b>Author(s):&nbsp;</b>Moslem Alimohammadlou, Sahar Sharifian</div><div><b>Pages:&nbsp;</b>169 - 186</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07570-2\">Strengthened conditional distributivity of semi-t-operators over uninorms</a></div><div><b>Author(s):&nbsp;</b>Dragan Jo\u010di\u0107, Ivana \u0160tajner-Papuga</div><div><b>Pages:&nbsp;</b>187 - 200</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07575-x\">Asynchronous robust dynamic output feedback \ud835\udc3b\u221e control for fuzzy stochastic hybrid systems subject to time-varying delays and hidden Markov model</a></div><div><b>Author(s):&nbsp;</b>Yuqian Lin, Guangming Zhuang...Wei Sun</div><div><b>Pages:&nbsp;</b>201 - 218</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07576-w\">Mixing of capacity preserving dynamical systems</a></div><div><b>Author(s):&nbsp;</b>Lixin Guo, Guo Wei, Zhiming Li</div><div><b>Pages:&nbsp;</b>219 - 225</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07580-0\">Evidential global linguistic terms entropy</a></div><div><b>Author(s):&nbsp;</b>Jinyan Su, Yong Deng, Nam-Van Huynh</div><div><b>Pages:&nbsp;</b>227 - 237</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07584-w\">Examples, properties and applications of fuzzy inner product spaces</a></div><div><b>Author(s):&nbsp;</b>Jian-Zhong Xiao, Ying Lu, Feng-Qin Zhu</div><div><b>Pages:&nbsp;</b>239 - 256</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07591-x\">An integrated Fuzzy MCDM approach for modelling and prioritising the enablers of responsiveness in automotive supply chain using Fuzzy DEMATEL, Fuzzy AHP and Fuzzy TOPSIS</a></div><div><b>Author(s):&nbsp;</b>Rinu Sathyan, P. Parthiban...M. S. Sachin</div><div><b>Pages:&nbsp;</b>257 - 277</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07278-3\">The unit generalized half-normal quantile regression model: formulation, estimation, diagnostics, and numerical applications</a></div><div><b>Author(s):&nbsp;</b>Josmar Mazucheli, Mustafa \u00c7. Korkmaz...V\u00edctor Leiva</div><div><b>Pages:&nbsp;</b>279 - 295</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07633-4\">Artificial neural network-based secured communication strategy for vehicular ad hoc network</a></div><div><b>Author(s):&nbsp;</b>B. V. D. S. Sekhar, Pamula Udayaraju...M. S. S. S. Srinivas</div><div><b>Pages:&nbsp;</b>297 - 309</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07617-4\">Multi-layered network model for text summarization using feature representation</a></div><div><b>Author(s):&nbsp;</b>G. Malarselvi, A. Pandian</div><div><b>Pages:&nbsp;</b>311 - 322</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07618-3\">Machine learning and IoTs for forecasting prediction of smart road traffic flow</a></div><div><b>Author(s):&nbsp;</b>Sun Chuanxia, Zhang Han, Yin Peixuan</div><div><b>Pages:&nbsp;</b>323 - 335</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07560-4\">ACO-based approach for integrating product lifecycle management with MRO services in aviation industry</a></div><div><b>Author(s):&nbsp;</b>Ahmet Muhammed Guraksin, Alper Ozcan</div><div><b>Pages:&nbsp;</b>337 - 361</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05572-0\">Deep belief network-based probabilistic generative model for detection of robotic manipulator failure execution</a></div><div><b>Author(s):&nbsp;</b>Pandit Byomakesha Dash, Bighnaraj Naik...S. Vimal</div><div><b>Pages:&nbsp;</b>363 - 375</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05586-8\">Detection of shilling attack in recommender system for YouTube video statistics using machine learning techniques</a></div><div><b>Author(s):&nbsp;</b>Shalli Rani, Manpreet Kaur...Jnyana Ranjan Mohanty</div><div><b>Pages:&nbsp;</b>377 - 389</div><div><br /></div><div><b>26) </b><a href=\"https://link.springer.com/article/10.1007/s00500-021-05613-8\">An agent architecture for autonomous UAV flight control in object classification and recognition missions</a></div><div><b>Author(s):&nbsp;</b>Salama A. Mostafa, Aida Mustapha...Seifedine Kadry</div><div><b>Pages:&nbsp;</b>391 - 404</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05649-w\">Rule-based multi-view human activity recognition system in real time using skeleton data from RGB-D sensor</a></div><div><b>Author(s):&nbsp;</b>Neeraj Varshney, Brijesh Bakariya...Manish Khare</div><div><b>Pages:&nbsp;</b>405 - 421</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05650-3\">Remote sensing image processing technology based on mobile augmented reality technology in surveying and mapping engineering</a></div><div><b>Author(s):&nbsp;</b>Wei Lu, LiJun Zhao, Rong Xu</div><div><b>Pages:&nbsp;</b>423 - 433</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05700-w\">Performance enhancement of generative adversarial network for photograph\u2013sketch identification</a></div><div><b>Author(s):&nbsp;</b>M. S. Sannidhan, G. Ananth Prabhu...Jnyana Ranjan Mohanty</div><div><b>Pages:&nbsp;</b>435 - 452</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05701-9\">Pedestrian identification using motion-controlled deep neural network in real-time visual surveillance</a></div><div><b>Author(s):&nbsp;</b>Muhammad Zahid, Muhammad Attique Khan...Jnyana Ranjan Mohanty</div><div><b>Pages:&nbsp;</b>453 - 469</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05727-z\">Manifold fitting algorithm of noisy manifold data based on variable-scale spectral graph</a></div><div><b>Author(s):&nbsp;</b>Tao Yang, Jintao Meng</div><div><b>Pages:&nbsp;</b>471 - 482</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05735-z\">Intelligent recommendation method integrating knowledge graph and Bayesian network</a></div><div><b>Author(s):&nbsp;</b>Hailan Pan, Xiaohuan Yang</div><div><b>Pages:&nbsp;</b>483 - 492</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05815-0\">An improved and low-complexity neural network model for curved lane detection of autonomous driving system</a></div><div><b>Author(s):&nbsp;</b>Safwan Ghanem, Priyadarshi Kanungo...Pritee Parwekar</div><div><b>Pages:&nbsp;</b>493 - 504</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05816-z\">Efficiently harvesting deep web interfaces based on adaptive learning using two-phase data crawler framework</a></div><div><b>Author(s):&nbsp;</b>Madhusudhan Rao Murugudu, L. S. S. Reddy</div><div><b>Pages:&nbsp;</b>505 - 515</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05856-5\">Investigation on broad beam pattern synthesis</a></div><div><b>Author(s):&nbsp;</b>M. Chandrasekhar</div><div><b>Pages:&nbsp;</b>517 - 527</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05857-4\">Blind signal-to-interference-plus-noise ratio estimation of OFDM/OQAM system in radio frequency interference environment</a></div><div><b>Author(s):&nbsp;</b>J. Tarun Kumar, C. H. Sridevi, V. Sandeep Kumar</div><div><b>Pages:&nbsp;</b>529 - 536</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05879-y\">Sector multi-beam space optimal bit error rate enhancement in wireless 5G using power domain NOMA</a></div><div><b>Author(s):&nbsp;</b>K. Murali, S. SivaPerumal</div><div><b>Pages:&nbsp;</b>537 - 545</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-06120-6\">A defensive design for control application based on networked systems</a></div><div><b>Author(s):&nbsp;</b>Ahmed Raza Rajput, Muhammad Shamrooz Aslam, Shahab Ahmad Niazi</div><div><b>Pages:&nbsp;</b>547 - 558</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06950-y\">Securing medical data by role-based user policy with partially homomorphic encryption in AWS cloud</a></div><div><b>Author(s):&nbsp;</b>M. D. Boomija, S. V. Kasmir Raja</div><div><b>Pages:&nbsp;</b>559 - 568</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06986-0\">Empirical evidence of effects of stringency amid Covid-19 pandemic spread</a></div><div><b>Author(s):&nbsp;</b>R. I. Minu, G. Nagarajan, T. R. Saravanan</div><div><b>Pages:&nbsp;</b>569 - 577</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06989-x\">Hybrid high performance intelligent computing approach of CACNN and RNN for skin cancer image grading</a></div><div><b>Author(s):&nbsp;</b>S. Manimurugan</div><div><b>Pages:&nbsp;</b>579 - 589</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07135-3\">Stacking optimized with artificial bee colony for driving style classification by feature reconstruction from OBD II data</a></div><div><b>Author(s):&nbsp;</b>G. Priyadharshini, M. Ferni Ukrit</div><div><b>Pages:&nbsp;</b>591 - 603</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-06938-8\">Dynamic multi-variant relational scheme-based intelligent ETL framework for healthcare management</a></div><div><b>Author(s):&nbsp;</b>Vijayalakshmi Manickam, Minu Rajasekaran Indra</div><div><b>Pages:&nbsp;</b>605 - 614</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-021-05871-6\">RETRACTED ARTICLE: COVID-19 pandemic and unemployment rate: A hybrid unemployment rate prediction approach for developed and developing countries of Asia</a></div><div><b>Author(s):&nbsp;</b>Han Lai, Yousaf Ali Khan, Syed Zaheer Abbas</div><div><b>Pages:&nbsp;</b>615 - 615</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07713-5\">Retraction Note: The prediction of the lifetime of the new coronavirus in the USA using mathematical models</a></div><div><b>Author(s):&nbsp;</b>K. Selvakumar, S. Lokesh</div><div><b>Pages:&nbsp;</b>617 - 617</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07708-2\">Retraction Note: Data processing model and performance analysis of cognitive computing based on machine learning in Internet environment</a></div><div><b>Author(s):&nbsp;</b>Hu Jin</div><div><b>Pages:&nbsp;</b>619 - 619</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07709-1\">Retraction Note: Building the electronic evidence analysis model based on association rule mining and FP-growth algorithm</a></div><div><b>Author(s):&nbsp;</b>Yilan Wu, Jing Zhang</div><div><b>Pages:&nbsp;</b>621 - 621</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07710-8\">Retraction Note: Visual communication design elements of Internet of Things based on cloud computing applied in graffiti art schema</a></div><div><b>Author(s):&nbsp;</b>Haotian Wu, Guangan Li</div><div><b>Pages:&nbsp;</b>623 - 623</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07711-7\">Retraction Note: Application of cloud-based visual communication design in Internet of Things image</a></div><div><b>Author(s):&nbsp;</b>Xixia Liu</div><div><b>Pages:&nbsp;</b>625 - 625</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07712-6\">Retraction Note: Analysis on the construction of ideological and political education system for college students based on mobile artificial intelligence terminal</a></div><div><b>Author(s):&nbsp;</b>Yuting Wang</div><div><b>Pages:&nbsp;</b>627 - 627</div><div><br /></div></div>",
            "pubdate": "2023-01-07T22:23:00.000+13:00",
            "pubdate_parsed": [
                2023,
                1,
                7
            ],
            "email_sent": true
        },
        "IEEE Transactions on Cognitive and Developmental Systems, Volume 15, Issue 1, March 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/03/ieee-transactions-on-cognitive-and.html",
            "description": "<div style=\"text-align: left;\"><div><b>1) </b><a href=\"https://ieeexplore.ieee.org/document/10061513/\">Editorial IEEE Transactions on Cognitive and Developmental Systems</a></div><div><b>Author(s): </b>Huajin Tang</div><div><b>Pages:</b> 2</div><div><br /></div><div><b>2</b>) <a href=\"https://ieeexplore.ieee.org/document/9667107/\">Vision-and-Language Navigation Based on Cross-Modal Feature Fusion in Indoor Environment</a></div><div><b>Author(s):&nbsp;</b>Shuhuan Wen, Xiaohan Lv, F. Richard Yu, Simeng Gong</div><div><b>Pages:</b>3 - 15</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9669200/\">One-Pass Online Learning Based on Gradient Descent for Multilayer Spiking Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Xianghong Lin, Tiandou Hu, Xiangwen Wang</div><div><b>Pages:</b>16 - 31</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9937202/\">Adaptation Through Prediction: Multisensory Active Inference Torque Control</a></div><div><b>Author(s):&nbsp;</b>Cristian Meo, Giovanni Franzese, Corrado Pezzato, Max Spahn, Pablo Lanillos</div><div><b>Pages:</b>32 - 41</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9675829/\">A Weakly Supervised-Guided Soft Attention Network for Classification of Intracranial Hemorrhage</a></div><div><b>Author(s):&nbsp;</b>Long Zhang, Wenlong Miao, Chuang Zhu, Yuanyuan Wang, Yihao Luo, Ruoning Song, Lian Liu, Jie Yang</div><div><b>Pages:</b>42 - 53</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9676712/\">Reinforcement-Learning-Based Dynamic Opinion Maximization Framework in Signed Social Networks</a></div><div><b>Author(s):&nbsp;</b>Qiang He, Yingjie Lv, Xingwei Wang, Jianhua Li, Min Huang, Lianbo Ma, Yuliang Cai</div><div><b>Pages:</b>54 - 64</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9690949/\">Self-Attention Pooling-Based Long-Term Temporal Network for Action Recognition</a></div><div><b>Author(s):&nbsp;</b>Huifang Li, Jingwei Huang, Mengchu Zhou, Qisong Shi, Qing Fei</div><div><b>Pages:</b>65 - 77</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9690946/\">Collision-Free Navigation in Human-Following Task Using a Cognitive Robotic System on Differential Drive Vehicles</a></div><div><b>Author(s):&nbsp;</b>Chien Van Dang, Heungju Ahn, Jong-Wook Kim, Sang C. Lee</div><div><b>Pages:</b>78 - 87</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9698104/\">Quantized Reservoir Computing for Spectrum Sensing With Knowledge Distillation</a></div><div><b>Author(s):&nbsp;</b>Shiya Liu, Lingjia Liu, Yang Yi</div><div><b>Pages:</b>88 - 99</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9690943/\">Isokinetic Muscle Strength Training Strategy of an Ankle Rehabilitation Robot Based on Adaptive Gain and Cascade PID Control</a></div><div><b>Author(s):&nbsp;</b>Jianfeng Li, Yu Zhou, Mingjie Dong, Xi Rong</div><div><b>Pages:</b>100 - 110</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9693979/\">Optimizing Deep Neural Networks Through Neuroevolution With Stochastic Gradient Descent</a></div><div><b>Author(s):&nbsp;</b>Haichao Zhang, Kuangrong Hao, Lei Gao, Bing Wei, Xuesong Tang</div><div><b>Pages:</b>111 - 121</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9695493/\">Sensing and Navigation of Wearable Assistance Cognitive Systems for the Visually Impaired</a></div><div><b>Author(s):&nbsp;</b>Guoxin Li, Jiaqi Xu, Zhijun Li, Chao Chen, Zhen Kan</div><div><b>Pages:</b>122 - 133</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9709561/\">Flexible Behavioral Decision Making of Mobile Robot in Dynamic Environment</a></div><div><b>Author(s):&nbsp;</b>Jinbiao Zhu, Dongshu Wang, Jikai Si</div><div><b>Pages:</b>134 - 149</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9706313/\">A Cerebellum-Inspired Network Model and Learning Approaches for Solving Kinematic Tracking Control of Redundant Manipulators</a></div><div><b>Author(s):&nbsp;</b>Ning Tan, Peng Yu, Fenglei Ni</div><div><b>Pages:</b>150 - 162</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9707481/\">Emotion Recognition Based on EEG Brain Rhythm Sequencing Technique</a></div><div><b>Author(s):&nbsp;</b>Jia Wen Li, Shovan Barma, Sio Hang Pun, Mang I. Vai, Peng Un Mak</div><div><b>Pages:</b>163 - 174</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9708412/\">Facial Expression Recognition Through Cross-Modality Attention Fusion</a></div><div><b>Author(s):&nbsp;</b>Rongrong Ni, Biao Yang, Xu Zhou, Angelo Cangelosi, Xiaofeng Liu</div><div><b>Pages:</b>175 - 185</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9714272/\">Six-Dimensional Target Pose Estimation for Robot Autonomous Manipulation: Methodology and Verification</a></div><div><b>Author(s):&nbsp;</b>Rui Wang, Congjia Su, Hao Yu, Shuo Wang</div><div><b>Pages:</b>186 - 197</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9714486/\">Implicit Robot Control Using Error-Related Potential-Based Brain\u2013Computer Interface</a></div><div><b>Author(s):&nbsp;</b>Xiaofei Wang, Hsiang-Ting Chen, Yu-Kai Wang, Chin-Teng Lin</div><div><b>Pages:</b>198 - 209</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9714489/\">C-GRAIL: Autonomous Reinforcement Learning of Multiple and Context-Dependent Goals</a></div><div><b>Author(s):&nbsp;</b>Vieri Giuliano Santucci, Davide Montella, Gianluca Baldassarre</div><div><b>Pages:</b>210 - 222</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9716077/\">Self-Supervised Learning of Depth and Ego-Motion From Videos by Alternative Training and Geometric Constraints from 3-D to 2-D</a></div><div><b>Author(s):&nbsp;</b>Jiaojiao Fang, Guizhong Liu</div><div><b>Pages:</b>223 - 233</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9718550/\">Fusing Attention Network Based on Dilated Convolution for Superresolution</a></div><div><b>Author(s):&nbsp;</b>Zhaoyang Song, Xiaoqiang Zhao, Yongyong Hui, Hongmei Jiang</div><div><b>Pages:</b>234 - 241</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9731518/\">Fall-Perceived Action Recognition of Persons With Neurological Disorders Using Semantic Supervision</a></div><div><b>Author(s):&nbsp;</b>Nitika Nigam, Tanima Dutta, Deepali Verma</div><div><b>Pages:</b>242 - 251</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9717290/\">Are Nonimage Data Really Necessary for Disease Prediction With Graph Convolutional Networks?</a></div><div><b>Author(s):&nbsp;</b>Gen Shi, Yifan Zhu, Zhensen Chen, Jinyan Liu, Xuesong Li</div><div><b>Pages:</b>252 - 260</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9718542/\">Multistream 3-D Convolution Neural Network With Parameter Sharing for Human State Estimation</a></div><div><b>Author(s):&nbsp;</b>Chin-Teng Lin, Jia Liu, Chieh-Ning Fang, Shih-Ying Hsiao, Yu-Cheng Chang, Yu-Kai Wang</div><div><b>Pages:</b>261 - 271</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9733988/\">Convolutional Multiple Instance Learning for Sleep Spindle Detection With Label Refinement</a></div><div><b>Author(s):&nbsp;</b>Xuyun Sun, Yu Qi, Yueming Wang, Gang Pan</div><div><b>Pages:</b>272 - 284</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9729895/\">Blurry Facial-Image Deconvolution via Model-Guided Deep Neural Network Inspired From Edge Regularization</a></div><div><b>Author(s):&nbsp;</b>Xiaoyuan Yu, Wei Xie</div><div><b>Pages:</b>285 - 297</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9729878/\">3-D Facial Feature Reconstruction and Learning Network for Facial Expression Recognition in the Wild</a></div><div><b>Author(s):&nbsp;</b>Ning Sun, Jianglong Tao, Jixin Liu, Haian Sun, Guang Han</div><div><b>Pages:</b>298 - 309</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9733936/\">Obscenity Detection in Videos Through a Sequential ConvNet Pipeline Classifier</a></div><div><b>Author(s):&nbsp;</b>Neil Gautam, Dinesh Kumar Vishwakarma</div><div><b>Pages:</b>310 - 318</div><div><br /></div></div>",
            "pubdate": "2023-03-13T13:04:00.000+13:00",
            "pubdate_parsed": [
                2023,
                3,
                13
            ],
            "email_sent": true
        },
        "Evolving Systems, Volume 14, issue 2, April 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/03/evolving-systems-volume-14-issue-2.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09441-5\">Reducing the number of trees in a forest using noisy features</a></div><div><b>Author(s): </b>Youness Manzali, Yassine Akhiat...Ahmed Zinedine</div><div><b>Pages: </b>157 - 174</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09442-4\">Social network security using genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Benyamin MazhariSefat, Soodeh Hosseini</div><div><b>Pages:&nbsp;</b>175 - 190</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09445-1\">Sleep apnea detection from ECG signal using deep CNN-based structures</a></div><div><b>Author(s):&nbsp;</b>Ahmad Ayatollahi, Sajjad Afrakhteh...Ehsan Saleh</div><div><b>Pages:&nbsp;</b>191 - 206</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09447-z\">Min max kurtosis distance based improved initial centroid selection approach of K-means clustering for big data mining on gene expression data</a></div><div><b>Author(s):&nbsp;</b>Kamlesh Kumar Pandey, Diwakar Shukla</div><div><b>Pages:&nbsp;</b>207 - 244</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09450-4\">Comparative analysis with topic modeling and word embedding methods after the Aegean Sea earthquake on Twitter</a></div><div><b>Author(s):&nbsp;</b>Nazmiye Elig\u00fczel, Cihan \u00c7etinkaya, T\u00fcrkay Dereli</div><div><b>Pages:&nbsp;</b>245 - 261</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09454-0\">Combined analysis on AGC and ELD of a hybrid power system with D-WCA designed Gaussian type-2 fuzzy controller</a></div><div><b>Author(s):&nbsp;</b>Krushna Keshab Baral, Prakash Chandra Sahu...Banaja Mohanty</div><div><b>Pages:&nbsp;</b>263 - 280</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09457-x\">Very deep fully convolutional encoder\u2013decoder network based on wavelet transform for art image fusion in cloud computing environment</a></div><div><b>Author(s):&nbsp;</b>Tong Chen, Juan Yang</div><div><b>Pages:&nbsp;</b>281 - 293</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09458-w\">A player unknown's battlegrounds ranking based optimization technique for power system optimization problem</a></div><div><b>Author(s):&nbsp;</b>Kapil Deo Bodha, V. Mukherjee, Vinod Kumar Yadav</div><div><b>Pages:&nbsp;</b>295 - 317</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09455-z\">Evolving fuzzy neural classifier that integrates uncertainty from human-expert feedback</a></div><div><b>Author(s):&nbsp;</b>Paulo Vitor de Campos Souza, Edwin Lughofer</div><div><b>Pages:&nbsp;</b>319 - 341</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09448-y\">A review of online supervised learning</a></div><div><b>Author(s):&nbsp;</b>Charanjeet Singh, Anuj Sharma</div><div><b>Pages:&nbsp;</b>343 - 364</div><div><br /></div><div><br /></div>",
            "pubdate": "2023-03-28T14:55:00.000+13:00",
            "pubdate_parsed": [
                2023,
                3,
                28
            ],
            "email_sent": true
        },
        "Evolving Systems, Volume 14, Issue 3, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/evolving-systems-volume-14-issue-3-june.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09456-y\">L\u00e9vy flight and chaos theory based gravitational search algorithm for multilayer perceptron training</a></div><div><b>Author(s): </b>Sajad Ahmad Rather, P. Shanthi Bala</div><div><b>Pages: </b>365 - 392</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09469-7\">An advance computational intelligent approach to solve the third kind of nonlinear pantograph Lane\u2013Emden differential system</a></div><div><b>Author(s):&nbsp;</b>Zulqurnain Sabir, Muhammad Asif Zahoor Raja...R. Sadat</div><div><b>Pages:&nbsp;</b>393 - 412</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09459-9\">Vaccination and isolation based control design of the COVID-19 pandemic based on adaptive neuro fuzzy inference system optimized with the genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Zohreh Abbasi, Mohsen Shafieirad...Iman Zamani</div><div><b>Pages:&nbsp;</b>413 - 435</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09476-8\">Quick continual kernel learning on bounded memory space based on balancing between adaptation and forgetting</a></div><div><b>Author(s):&nbsp;</b>Koichiro Yamauchi</div><div><b>Pages:&nbsp;</b>437 - 460</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09471-z\">DEMD-IoT: a deep ensemble model for IoT malware detection using CNNs and network traffic</a></div><div><b>Author(s):&nbsp;</b>Mehrnoosh Nobakht, Reza Javidan, Alireza Pourebrahimi</div><div><b>Pages:&nbsp;</b>461 - 477</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09474-w\">Adaptive octopus deep transfer learning based epileptic seizure classification on field programmable gate arrays</a></div><div><b>Author(s):&nbsp;</b>B. Indira Priyadarshini, D. Krishna Reddy</div><div><b>Pages:&nbsp;</b>479 - 499</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09473-x\">Multichannel KHMF for speech separation with enthalpy based DOA and score based CNN (SCNN)</a></div><div><b>Author(s):&nbsp;</b>Yannam Vasantha Koteswararao, C. B. Rama Rao</div><div><b>Pages:&nbsp;</b>501 - 518</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09466-w\">DBF-Net: a semi-supervised dual-task balanced fusion network for segmenting infected regions from lung CT images</a></div><div><b>Author(s):&nbsp;</b>Xiaoyan Lu, Yang Xu, Wenhao Yuan</div><div><b>Pages:&nbsp;</b>519 - 532</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09451-3\">Prim based link quality and thermal aware adaptive routing protocol for IoMT using SigFox network in WBAN</a></div><div><b>Author(s):&nbsp;</b>Padma Vijetha Dev Bakkaiahgari, K. Venkata Prasad</div><div><b>Pages:&nbsp;</b>533 - 544</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s12530-022-09446-0\">MiniNet: a concise CNN for image forgery detection</a></div><div><b>Author(s):&nbsp;</b>Shobhit Tyagi, Divakar Yadav</div><div><b>Pages:&nbsp;</b>545 - 556</div><div><br /></div>",
            "pubdate": "2023-06-05T16:33:00.000+12:00",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "IEEE Transactions on Artificial Intelligence, Volume 4, Issue 3, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/ieee-transactions-on-artificial.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/10132894/\">Editorial Interdisciplinary Artificial Intelligence Research With Machine Education as an Example</a></div><div><b>Author(s): </b>Hussein Abbass</div><div><b>Pages: </b>399 - 401</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9740494/\">A Reinforcement Learning System for Generating Instantaneous Quality Random Sequences</a></div><div><b>Author(s):&nbsp;</b>Yahya Almardeny, Alessio Benavoli, Noureddine Boujnah, Enrique Naredo</div><div><b>Pages:&nbsp;</b>402 - 415</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9868151/\">Optimizing Multidocument Summarization by Blending Reinforcement Learning Policies</a></div><div><b>Author(s):&nbsp;</b>DiJia Su, Difei Su, John M. Mulvey, H.Vincent Poor</div><div><b>Pages:&nbsp;</b>416 - 427</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9807363/\">An Automated Deep Reinforcement Learning Pipeline for Dynamic Pricing</a></div><div><b>Author(s):&nbsp;</b>Reza Refaei Afshar, Jason Rhuggenaath, Yingqian Zhang, Uzay Kaymak</div><div><b>Pages:&nbsp;</b>428 - 437</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9783098/\">Explainable Natural Language Inference via Identifying Important Rationales</a></div><div><b>Author(s):&nbsp;</b>Zongbao Yang, Shoubin Dong, Jinlong Hu</div><div><b>Pages:&nbsp;</b>438 - 449</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9813389/\">Regressing Word and Sentence Embeddings for Low-Resource Neural Machine Translation</a></div><div><b>Author(s):&nbsp;</b>Inigo Jauregi Unanue, Ehsan Zare Borzeshi, Massimo Piccardi</div><div><b>Pages:&nbsp;</b>450 - 463</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9896130/\">Sparsing and Smoothing for the seq2seq Models</a></div><div><b>Author(s):&nbsp;</b>Shuai Zhao, Zhuoqian Liang, Jinming Wen, Jie Chen</div><div><b>Pages:&nbsp;</b>464 - 472</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9960731/\">Discovering High Utility Episodes in Sequences</a></div><div><b>Author(s):&nbsp;</b>Wensheng Gan, Jerry Chun-Wei Lin, Han-Chieh Chao, Philip S. Yu</div><div><b>Pages:&nbsp;</b>473 - 486</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9792173/\">On Computing Evidential Centroid Through Conjunctive Combination: An Impossibility Theorem</a></div><div><b>Author(s):&nbsp;</b>Yiru Zhang, S\u00e9bastien Destercke, Zuowei Zhang, Tassadit Bouadi, Arnaud Martin</div><div><b>Pages:&nbsp;</b>487 - 496</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9745764/\">Deep Reconstruction of 3-D Human Poses From Video</a></div><div><b>Author(s):&nbsp;</b>Jian Liu, Naveed Akhtar, Ajmal Mian</div><div><b>Pages:&nbsp;</b>497 - 510</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9920176/\">Modeling Tradeoffs Using Preference-Based Feedback in Session-Based Recommender Systems</a></div><div><b>Author(s):&nbsp;</b>Anbarasu Sekar, Sutanu Chakraborti</div><div><b>Pages:&nbsp;</b>511 - 521</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9763033/\">Efficient Few-Shot Classification via Contrastive Pretraining on Web Data</a></div><div><b>Author(s):&nbsp;</b>Zhuoling Li, Haohan Wang, Tymoteusz \u015awistek, En Yu, Haoqian Wang</div><div><b>Pages:&nbsp;</b>522 - 533</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9774934/\">TREND: Transferability-Based Robust ENsemble Design</a></div><div><b>Author(s):&nbsp;</b>Deepak Ravikumar, Sangamesh Kodge, Isha Garg, Kaushik Roy</div><div><b>Pages:&nbsp;</b>534 - 548</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9782516/\">Toward Personalization of User Preferences in Partially Observable Smart Home Environments</a></div><div><b>Author(s):&nbsp;</b>Shashi Suman, Francois Rivest, Ali Etemad</div><div><b>Pages:&nbsp;</b>549 - 561</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9857594/\">Evolutionary Multilabel Adversarial Examples: An Effective Black-Box Attack</a></div><div><b>Author(s):&nbsp;</b>Linghao Kong, Wenjian Luo, Hongwei Zhang, Yang Liu, Yuhui Shi</div><div><b>Pages:&nbsp;</b>562 - 572</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9906417/\">A Temporal Type-2 Fuzzy System for Time-Dependent Explainable Artificial Intelligence</a></div><div><b>Author(s):&nbsp;</b>Mehrin Kiani, Javier Andreu-Perez, Hani Hagras</div><div><b>Pages:&nbsp;</b>573 - 586</div><div><br /></div>",
            "pubdate": "2023-06-06T12:00:00.001+12:00",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "IEEE Transactions on Emerging Topics in Computational Intelligence, Volume 7, Issue 3, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/ieee-transactions-on-emerging-topics-in.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/10016905/\">Generalized Graph Neural Network-Based Detection of False Data Injection Attacks in Smart Grids</a></div><div><b>Author(s): </b>Abdulrahman Takiddin;Rachad Atat;Muhammad Ismail;Osman Boyaci;Katherine R. Davis;Erchin Serpedin</div><div><b>Pages: </b>618 - 630</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/10044384/\">A Lightweight Multimode Medical Image Fusion Method Using Similarity Measure Between Intuitionistic Fuzzy Sets Joint Laplacian Pyramid</a></div><div><b>Author(s):&nbsp;</b>Qian Jiang;Xin Jin;Xiaohui Cui;Shaowen Yao;Keqin Li;Wei Zhou</div><div><b>Pages:&nbsp;</b>631 - 647</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/10021962/\">A Multi-View Multi-Scale Neural Network for Multi-Label ECG Classification</a></div><div><b>Author(s):&nbsp;</b>Shunxiang Yang;Cheng Lian;Zhigang Zeng;Bingrong Xu;Junbin Zang;Zhidong Zhang</div><div><b>Pages:&nbsp;</b>648 - 660</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/10114454/\">Connectivity-Aware Particle Swarm Optimisation for Swarm Shepherding</a></div><div><b>Author(s):&nbsp;</b>Reem E. Mohamed;Robert Hunjet;Saber Elsayed;Hussein Abbass</div><div><b>Pages:&nbsp;</b>661 - 683</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/10021865/\">Fitness and Distance Based Local Search With Adaptive Differential Evolution for Multimodal Optimization Problems</a></div><div><b>Author(s):&nbsp;</b>Zi-Jia Wang;Zhi-Hui Zhan;Yun Li;Sam Kwong;Sang-Woon Jeon;Jun Zhang</div><div><b>Pages:&nbsp;</b>684 - 699</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/10012357/\">A High-Order Proximity-Incorporated Nonnegative Matrix Factorization-Based Community Detector</a></div><div><b>Author(s):&nbsp;</b>Zhigang Liu;Yugen Yi;Xin Luo</div><div><b>Pages:&nbsp;</b>700 - 714</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/10040931/\">A Surrogate-Assisted Two-Stage Differential Evolution for Expensive Constrained Optimization</a></div><div><b>Author(s):&nbsp;</b>Yuanchao Liu;Jianchang Liu;Yaochu Jin;Fei Li;Tianzi Zheng</div><div><b>Pages:&nbsp;</b>715 - 730</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9927729/\">Are SNNs Really More Energy-Efficient Than ANNs? an In-Depth Hardware-Aware Study</a></div><div><b>Author(s):&nbsp;</b>Manon Dampfhoffer;Thomas Mesquida;Alexandre Valentian;Lorena Anghel</div><div><b>Pages:&nbsp;</b>731 - 741</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/10018920/\">CenterNet-Auto: A Multi-object Visual Detection Algorithm for Autonomous Driving Scenes Based on Improved CenterNet</a></div><div><b>Author(s):&nbsp;</b>Hai Wang;Yansong Xu;Zining Wang;Yingfeng Cai;Long Chen;Yicheng Li</div><div><b>Pages:&nbsp;</b>742 - 752</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9911782/\">Communication Efficient Federated Learning With Heterogeneous Structured Client Models</a></div><div><b>Author(s):&nbsp;</b>Yao Hu;Xiaoyan Sun;Ye Tian;Linqi Song;Kay Chen Tan</div><div><b>Pages:&nbsp;</b>753 - 767</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9918094/\">An Aggregated Convolutional Transformer Based on Slices and Channels for Multivariate Time Series Classification</a></div><div><b>Author(s):&nbsp;</b>Yupeng Wu;Cheng Lian;Zhigang Zeng;Bingrong Xu;Yixin Su</div><div><b>Pages:&nbsp;</b>768 - 779</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9932273/\">SA-ES: Subspace Activation Evolution Strategy for Black-Box Adversarial Attacks</a></div><div><b>Author(s):&nbsp;</b>Zhenhua Li;Huilin Cheng;Xinye Cai;Jun Zhao;Qingfu Zhang</div><div><b>Pages:&nbsp;</b>780 - 790</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9942709/\">Multi-Domain Active Learning: Literature Review and Comparative Study</a></div><div><b>Author(s):&nbsp;</b>Rui He;Shengcai Liu;Shan He;Ke Tang</div><div><b>Pages:&nbsp;</b>791 - 804</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9979695/\">Towards Simple and Accurate Human Pose Estimation With Stair Network</a></div><div><b>Author(s):&nbsp;</b>Chenru Jiang;Kaizhu Huang;Shufei Zhang;Xinheng Wang;Jimin Xiao;Zhenxing Niu;Amir Hussain</div><div><b>Pages:&nbsp;</b>805 - 817</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/10057134/\">Unlocking the Potential of Two-Point Cells for Energy-Efficient and Resilient Training of Deep Nets</a></div><div><b>Author(s):&nbsp;</b>Ahsan Adeel;Adewale Adetomi;Khubaib Ahmed;Amir Hussain;Tughrul Arslan;W. A. Phillips</div><div><b>Pages:&nbsp;</b>818 - 828</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/10018283/\">Cognitive Diagnosis-Based Personalized Exercise Group Assembly via a Multi-Objective Evolutionary Algorithm</a></div><div><b>Author(s):&nbsp;</b>Shangshang Yang;Haoyu Wei;Haiping Ma;Ye Tian;Xingyi Zhang;Yunbo Cao;Yaochu Jin</div><div><b>Pages:&nbsp;</b>829 - 844</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9870199/\">Parameter-Free Similarity-Aware Attention Module for Medical Image Classification and Segmentation</a></div><div><b>Author(s):&nbsp;</b>Jie Du;Kai Guan;Yanhong Zhou;Yuanman Li;Tianfu Wang</div><div><b>Pages:&nbsp;</b>845 - 857</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9881543/\">An Efficient Federated Genetic Programming Framework for Symbolic Regression</a></div><div><b>Author(s):&nbsp;</b>Junlan Dong;Jinghui Zhong;Wei-Neng Chen;Jun Zhang</div><div><b>Pages:&nbsp;</b>858 - 871</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9914631/\">Learning Adaptive Differential Evolution by Natural Evolution Strategies</a></div><div><b>Author(s):&nbsp;</b>Haotian Zhang;Jianyong Sun;Kay Chen Tan;Zongben Xu</div><div><b>Pages:&nbsp;</b>872 - 886</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9972904/\">Semi-Supervised Multi-View Fusion for Identifying CAP and COVID-19 With Unlabeled CT Images</a></div><div><b>Author(s):&nbsp;</b>Qi Zhu;Yuze Zhou;Yuan Yao;Liang Sun;Feng Shi;Wei Shao;Daoqiang Zhang;Dinggang Shen</div><div><b>Pages:&nbsp;</b>887 - 899</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9926981/\">Event-Triggered Adaptive Fuzzy PI Control of Uncertain Fractional-Order Nonlinear Systems With Full-State Constraints</a></div><div><b>Author(s):&nbsp;</b>Qian Wang;Jinde Cao;Heng Liu</div><div><b>Pages:&nbsp;</b>900 - 911</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9919423/\">Automatic Curriculum Learning for Large-Scale Cooperative Multiagent Systems</a></div><div><b>Author(s):&nbsp;</b>Tianle Zhang;Zhen Liu;Zhiqiang Pu;Jianqiang Yi</div><div><b>Pages:&nbsp;</b>912 - 930</div><div><br /></div><div><b>23)</b> S<a href=\"https://ieeexplore.ieee.org/document/10005146/\">emantic Fusion Enhanced Event Detection via Multi-Graph Attention Network with Skip Connection</a></div><div><b>Author(s):&nbsp;</b>Gongqing Wu;Zhenya Lu;Xingrui Zhuo;Xianyu Bao;Xindong Wu</div><div><b>Pages:&nbsp;</b>931 - 941</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9915487/\">Centroid Based Celestial Clustering Algorithm: A Novel Unsupervised Learning Method for Haemogram Data Clustering</a></div><div><b>Author(s):&nbsp;</b>Shibu Kumar K. B.;Philip Samuel</div><div><b>Pages:&nbsp;</b>942 - 956</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/10081195/\">Edge-Native Intelligence for 6G Communications Driven by Federated Learning: A Survey of Trends and Challenges</a></div><div><b>Author(s):&nbsp;</b>Mohammad Al-Quraan;Lina Mohjazi;Lina Bariah;Anthony Centeno;Ahmed Zoha;Kamran Arshad;Khaled Assaleh;Sami Muhaidat;M\u00e9rouane Debbah;Muhammad Ali Imran</div><div><b>Pages:&nbsp;</b>957 - 979</div><div><br /></div><div><br /></div>",
            "pubdate": "2023-06-07T12:00:00.001+12:00",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "IEEE Transactions on Evolutionary Computation, Volume 27, Issue 3, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/ieee-transactions-on-evolutionary.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/10138713/\">Guest Editorial Special Issue on Large-Scale Evolutionary Multiobjective Optimization and Its Practical Applications</a></div><div><b>Author(s): </b>Xingyi Zhang, Ran Cheng, Yaochu Jin, Bernhard Sendhoff</div><div><b>Pages: </b>398 - 400</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9494411/\">Evolutionary Large-Scale Multiobjective Optimization: Benchmarks and Algorithms</a></div><div><b>Author(s):&nbsp;</b>Songbai Liu, Qiuzhen Lin, Ka-Chun Wong, Qing Li, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>401 - 415</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9530561/\">Solution of Large-Scale Many-Objective Optimization Problems Based on Dimension Reduction and Solving Knowledge-Guided Evolutionary Algorithm</a></div><div><b>Author(s):&nbsp;</b>Xiangjuan Yao, Qian Zhao, Dunwei Gong, Song Zhu</div><div><b>Pages:&nbsp;</b>416 - 429</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9548954/\">A Greedy Cooperative Co-Evolutionary Algorithm With Problem-Specific Knowledge for Multiobjective Flowshop Group Scheduling Problems</a></div><div><b>Author(s):&nbsp;</b>Xuan He, Quan-Ke Pan, Liang Gao, Ling Wang, Ponnuthurai Nagaratnam Suganthan</div><div><b>Pages:&nbsp;</b>430 - 444</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9563070/\">A Fuzzy Decision Variables Framework for Large-Scale Multiobjective Optimization</a></div><div><b>Author(s):&nbsp;</b>Xu Yang, Juan Zou, Shengxiang Yang, Jinhua Zheng, Yuan Liu</div><div><b>Pages:&nbsp;</b>445 - 459</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9761990/\">Genetic Programming for Image Classification: A New Program Representation With Flexible Feature Reuse</a></div><div><b>Author(s):&nbsp;</b>Qinglan Fan, Ying Bi, Bing Xue, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>460 - 474</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9763854/\">An Efficient Adaptive Differential Grouping Algorithm for Large-Scale Black-Box Optimization</a></div><div><b>Author(s):&nbsp;</b>An Chen, Zhigang Ren, Wenhua Guo, Yongsheng Liang, Zuren Feng</div><div><b>Pages:&nbsp;</b>475 - 489</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9765521/\">Using an Estimation of Distribution Algorithm to Achieve Multitasking Semantic Web Service Composition</a></div><div><b>Author(s):&nbsp;</b>Chen Wang, Hui Ma, Gang Chen, Sven Hartmann</div><div><b>Pages:&nbsp;</b>490 - 504</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9766417/\">Minimizing Expected Deviation in Upper Level Outcomes Due to Lower Level Decision Making in Hierarchical Multiobjective Problems</a></div><div><b>Author(s):&nbsp;</b>Kalyanmoy Deb, Zhichao Lu, Ian Kropp, J. Sebastian Hernandez-Suarez, Rayan Hussein, Steven Miller, A. Pouyan Nejadhashemi</div><div><b>Pages:&nbsp;</b>505 - 519</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9764802/\">An Iterative Two-Stage Multifidelity Optimization Algorithm for Computationally Expensive Problems</a></div><div><b>Author(s):&nbsp;</b>Angus Kenny, Tapabrata Ray, Hemant Kumar Singh</div><div><b>Pages:&nbsp;</b>520 - 534</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9762787/\">A Genetic Algorithm (GA) and Swarm-Based Binary Decision Diagram (BDD) Reordering Optimizer Reinforced With Recent Operators</a></div><div><b>Author(s):&nbsp;</b>Ahmed Awad, Amjad Hawash, Baker Abdalhaq</div><div><b>Pages:&nbsp;</b>535 - 549</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9905732/\">Benchmarking Optimization Algorithms for Auto-Tuning GPU Kernels</a></div><div><b>Author(s):&nbsp;</b>Richard Arnoud Schoonhoven, Ben van Werkhoven, Kees Joost Batenburg</div><div><b>Pages:&nbsp;</b>550 - 564</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9766043/\">Strengthening Gradient Descent by Sequential Motion Optimization for Deep Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Thang Le-Duc, Quoc-Hung Nguyen, Jaehong Lee, H. Nguyen-Xuan</div><div><b>Pages:&nbsp;</b>565 - 579</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9776498/\">A Stochastic Simulation Optimization-Based Range Gate Pull-Off Jamming Method</a></div><div><b>Author(s):&nbsp;</b>Yuanhang Wang, Tianxian Zhang, Lingjiang Kong, Zhijie Ma</div><div><b>Pages:&nbsp;</b>580 - 594</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9775183/\">Surrogate Sample-Assisted Particle Swarm Optimization for Feature Selection on High-Dimensional Data</a></div><div><b>Author(s):&nbsp;</b>Xianfang Song, Yong Zhang, Dunwei Gong, Hui Liu, Wanqiu Zhang</div><div><b>Pages:&nbsp;</b>595 - 609</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9776510/\">A Learning-Based Memetic Algorithm for Energy-Efficient Flexible Job-Shop Scheduling With Type-2 Fuzzy Processing Time</a></div><div><b>Author(s):&nbsp;</b>Rui Li, Wenyin Gong, Chao Lu, Ling Wang</div><div><b>Pages:&nbsp;</b>610 - 620</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9965435/\">Explainable Artificial Intelligence by Genetic Programming: A Survey</a></div><div><b>Author(s):&nbsp;</b>Yi Mei, Qi Chen, Andrew Lensen, Bing Xue, Mengjie Zhang</div><div><b>Pages:&nbsp;</b>621 - 641</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9774845/\">Dynamic Auxiliary Task-Based Evolutionary Multitasking for Constrained Multiobjective Optimization</a></div><div><b>Author(s):&nbsp;</b>Kangjia Qiao, Kunjie Yu, Boyang Qu, Jing Liang, Hui Song, Caitong Yue, Hongyu Lin, Kay Chen Tan</div><div><b>Pages:&nbsp;</b>642 - 656</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9789515/\">Robust Optimization Over Time by Estimating Robustness of Promising Regions</a></div><div><b>Author(s):&nbsp;</b>Danial Yazdani, Donya Yazdani, J\u00fcrgen Branke, Mohammad Nabi Omidvar, Amir Hossein Gandomi, Xin Yao</div><div><b>Pages:&nbsp;</b>657 - 670</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9782569/\">Distributed and Expensive Evolutionary Constrained Optimization With On-Demand Evaluation</a></div><div><b>Author(s):&nbsp;</b>Feng-Feng Wei, Wei-Neng Chen, Qing Li, Sang-Woon Jeon, Jun Zhang</div><div><b>Pages:&nbsp;</b>671 - 685</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9787998/\">Cooperative Coevolutionary CMA-ES With Landscape-Aware Grouping in Noisy Environments</a></div><div><b>Author(s):&nbsp;</b>Yapei Wu, Xingguang Peng, Handing Wang, Yaochu Jin, Demin Xu</div><div><b>Pages:&nbsp;</b>686 - 700</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9784859/\">A Stigmergy-Based Island Model for Dynamic Evaluation of Constraint-Handling Techniques and Differential Evolution Algorithms</a></div><div><b>Author(s):&nbsp;</b>Grasiele Regina Duarte, Beatriz Souza Leite Pires de Lima, Afonso Celso de Castro Lemonge</div><div><b>Pages:&nbsp;</b>701 - 715</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9780561/\">Evolutionary Sampling Agent for Expensive Problems</a></div><div><b>Author(s):&nbsp;</b>Huixiang Zhen, Wenyin Gong, Ling Wang</div><div><b>Pages:&nbsp;</b>716 - 727</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9802693/\">Community Detection in Multiplex Networks Based on Evolutionary Multitask Optimization and Evolutionary Clustering Ensemble</a></div><div><b>Author(s):&nbsp;</b>Chao Lyu, Yuhui Shi, Lijun Sun, Chin-Teng Lin</div><div><b>Pages:&nbsp;</b>728 - 742</div><div><br /></div>",
            "pubdate": "2023-06-08T12:00:00.001+12:00",
            "pubdate_parsed": [
                2023,
                6,
                8
            ],
            "email_sent": true
        },
        "Soft Computing, Volume 27, Issue 11, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/soft-computing-volume-27-issue-11-june.html",
            "description": "<div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08013-2\">Approximation results by fuzzy Bernstein type rational functions via interval-valued fuzzy number</a></div><div><b>Author(s): </b>Esma Y\u0131ld\u0131z \u00d6zkan, Bipan Hazarika</div><div><b>Pages: </b>6893 - 6901</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08043-w\">Maximum log\ud835\udc5e likelihood estimation for parameters of Weibull distribution and properties: Monte Carlo simulation</a></div><div><b>Author(s):&nbsp;</b>Mehmet Niyazi \u00c7ankaya, Roberto Vila</div><div><b>Pages:&nbsp;</b>6903 - 6926</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08062-7\">Fuzzy pushdown automata based on complete residuated lattices: variants and computing powers</a></div><div><b>Author(s):&nbsp;</b>Haihui Wang, Luyao Zhao...Ping Li</div><div><b>Pages:&nbsp;</b>6927 - 6938</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07910-w\">Path norms on a matrix</a></div><div><b>Author(s):&nbsp;</b>VarshaS. Aishwarya...Babushri Srinivas Kedukodi</div><div><b>Pages:&nbsp;</b>6939 - 6959</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07911-9\">A note on k-cyclic modal pseudocomplemented De Morgan algebras</a></div><div><b>Author(s):&nbsp;</b>Aldo Figallo-Orellano, Juan Sebasti\u00e1n Slagter</div><div><b>Pages:&nbsp;</b>6961 - 6972</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07947-x\">Ordinal belief entropy</a></div><div><b>Author(s):&nbsp;</b>Yuanpeng He, Yong Deng</div><div><b>Pages:&nbsp;</b>6973 - 6981</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08023-0\">The Belluce-semilattice associated with a monadic residuated lattice</a></div><div><b>Author(s):&nbsp;</b>Lianzhen Liu, Xiangyang Zhang</div><div><b>Pages:&nbsp;</b>6983 - 6998</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08030-1\">Intermittent fault manifestability of discrete event systems</a></div><div><b>Author(s):&nbsp;</b>Ye Liang, Aiwen Lai...Mohamed Sharaf</div><div><b>Pages:&nbsp;</b>6999 - 7009</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08038-7\">The maximum entropy negation of basic probability assignment</a></div><div><b>Author(s):&nbsp;</b>Ruijie Liu, Yong Deng, Zhen Li</div><div><b>Pages:&nbsp;</b>7011 - 7021</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08064-5\">Spinor q-equations in Euclidean 3-space \ud835\udd3c3</a></div><div><b>Author(s):&nbsp;</b>Do\u011fan \u00dcnal, Yasin \u00dcnl\u00fct\u00fcrk</div><div><b>Pages:&nbsp;</b>7023 - 7031</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07893-8\">k-degree-of-freedom uncertain Ellsberg urn problem</a></div><div><b>Author(s):&nbsp;</b>Arghya Bhattacharya</div><div><b>Pages:&nbsp;</b>7033 - 7038</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07917-3\">An age-based dynamic approach for distribution of perishable commodities with stochastic demands</a></div><div><b>Author(s):&nbsp;</b>Antonio Violi, Annarita De Maio...Maria Grazia Olivieri</div><div><b>Pages:&nbsp;</b>7039 - 7050</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07966-8\">Determinants of autonomous train operation adoption in rail freight: knowledge-based assessment with Delphi-ANP approach</a></div><div><b>Author(s):&nbsp;</b>Boban Djordjevi\u0107, Oskar Fr\u00f6idh, Evelin Krmac</div><div><b>Pages:&nbsp;</b>7051 - 7069</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08012-3\">Multi-criteria analysis through determining production technology based on critical features of smart manufacturing systems</a></div><div><b>Author(s):&nbsp;</b>Raziye K\u0131l\u0131\u00e7, Burak Erkayman</div><div><b>Pages:&nbsp;</b>7071 - 7096</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08054-7\">Extension of MEREC-CRADIS methods with double normalization-case study selection of electric cars</a></div><div><b>Author(s):&nbsp;</b>Adis Pu\u0161ka, Darko Bo\u017eani\u0107...Dragan Pamu\u010dar</div><div><b>Pages:&nbsp;</b>7097 - 7113</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07916-4\">Parallel dual-channel multi-label feature selection</a></div><div><b>Author(s):&nbsp;</b>Jiali Miao, Yibin Wang...Fei Chen</div><div><b>Pages:&nbsp;</b>7115 - 7130</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07919-1\">Incomplete multi-view clustering based on low-rank representation with adaptive graph regularization</a></div><div><b>Author(s):&nbsp;</b>Kaiwu Zhang, Baokai Liu...Jinmei Song</div><div><b>Pages:&nbsp;</b>7131 - 7146</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07939-x\">An ensemble algorithm using quantum evolutionary optimization of weighted type-II fuzzy system and staged Pegasos Quantum Support Vector Classifier with multi-criteria decision making system for diagnosis and grading of breast cancer</a></div><div><b>Author(s):&nbsp;</b>Subhashis Chatterjee, Ananya Das</div><div><b>Pages:&nbsp;</b>7147 - 7178</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07945-z\">Application of the deep transfer learning framework for hydatid cyst classification using CT images</a></div><div><b>Author(s):&nbsp;</b>Yeliz Gul, Taha Muezzinoglu...Turker Tuncer</div><div><b>Pages:&nbsp;</b>7179 - 7189</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07949-9\">Machine learning interpretability meets TLS fingerprinting</a></div><div><b>Author(s):&nbsp;</b>Mahdi Jafari Siavoshani, Amirhossein Khajehpour...Ali Taheri</div><div><b>Pages:&nbsp;</b>7191 - 7208</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08033-y\">LAB: a leader\u2013advocate\u2013believer-based optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>Ruturaj Reddy, Anand J. Kulkarni...Amir H. Gandomi</div><div><b>Pages:&nbsp;</b>7209 - 7243</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07920-8\">Convergence analysis of butterfly optimization algorithm</a></div><div><b>Author(s):&nbsp;</b>Prasanjit Chakraborty, Sushmita Sharma, Apu Kumar Saha</div><div><b>Pages:&nbsp;</b>7245 - 7257</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07930-6\">An orthogonal electric fish optimization algorithm with quantization for global numerical optimization</a></div><div><b>Author(s):&nbsp;</b>DanYu Wang, Hao LiuGui...Yan Ding</div><div><b>Pages:&nbsp;</b>7259 - 7283</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07931-5\">Solving fuzzy scheduling using clustering method and bacterial foraging algorithm</a></div><div><b>Author(s):&nbsp;</b>Yingli Li, Jiahai Wang...Zhengwei Liu</div><div><b>Pages:&nbsp;</b>7285 - 7297</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07944-0\">SBLMD\u2013ANN\u2013MOPSO-based hybrid approach for determining optimum parameter in CNC milling</a></div><div><b>Author(s):&nbsp;</b>Rohit Mishra, Bhagat Singh</div><div><b>Pages:&nbsp;</b>7299 - 7320</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07965-9\">Multi-objective deployment model for regional air defense</a></div><div><b>Author(s):&nbsp;</b>Zeynep \u00d6zdemir, Yusuf Tansel Ic</div><div><b>Pages:&nbsp;</b>7321 - 7335</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07972-w\">A solution method to maximal covering location problem based on chemical reaction optimization (CRO) algorithm</a></div><div><b>Author(s):&nbsp;</b>Md. Shymon Islam, Md. Rafiqul Islam</div><div><b>Pages:&nbsp;</b>7337 - 7361</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07974-8\">CEO election optimization algorithm and its application in constrained optimization problem</a></div><div><b>Author(s):&nbsp;</b>Yun-wei Jia, Xiao-tong Chen...Xia Li</div><div><b>Pages:&nbsp;</b>7363 - 7400</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07977-5\">A novel intelligent method to increase accuracy of hybrid photovoltaic-wind system-based MPPT and pitch angle controller</a></div><div><b>Author(s):&nbsp;</b>Tao Hai, Jincheng Zhou, Sajjad Dadfar</div><div><b>Pages:&nbsp;</b>7401 - 7418</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07978-4\">An adaptive adjacent maximum distance crossover operator for multi-objective algorithms</a></div><div><b>Author(s):&nbsp;</b>Qinghua Gu, Song Gao...Rongrong Liu</div><div><b>Pages:&nbsp;</b>7419 - 7438</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07684-7\">Water quality prediction using data-driven models case study: Ardabil plain, Iran</a></div><div><b>Author(s):&nbsp;</b>Mahsa Hasanpour Kashani, Mohammad Reza Nikpour, Reza Jalali</div><div><b>Pages:&nbsp;</b>7439 - 7448</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07685-6\">A new reliability analysis approach with multiple correlation neural networks method</a></div><div><b>Author(s):&nbsp;</b>Shangjie Li, Xianzhen Huang...Yuxiong Li</div><div><b>Pages:&nbsp;</b>7449 - 7458</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07686-5\">The collaborative governance mechanism of emergency information to coastal cities of China</a></div><div><b>Author(s):&nbsp;</b>Xing Huang, Jieru Huang</div><div><b>Pages:&nbsp;</b>7459 - 7471</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07688-3\">Enrichment of voltage stability in power system through novel generalized approximate reasoning based intelligent control with african buffalo optimization approach</a></div><div><b>Author(s):&nbsp;</b>Gitanjali Saha, Kabir Chakraborty, Priyanath Das</div><div><b>Pages:&nbsp;</b>7473 - 7496</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07696-3\">Evaluation of quality of online shopping services in times of COVID-19 based on E-S-QUAL model and Fuzzy TOPSIS method</a></div><div><b>Author(s):&nbsp;</b>Fagner Jos\u00e9 Coutinho de Melo, Larissa de Arruda Xavier...Denise Dumke de Medeiros</div><div><b>Pages:&nbsp;</b>7497 - 7511</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07700-w\">Automatic approach for mask detection: effective for COVID-19</a></div><div><b>Author(s):&nbsp;</b>Debajyoty Banik, Saksham Rawat...Suresh Chandra Satapathy</div><div><b>Pages:&nbsp;</b>7513 - 7523</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07879-6\">Smart cataract detection system with bidirectional LSTM</a></div><div><b>Author(s):&nbsp;</b>B. J. D. Kalyani, U. Hemavathi...Shareefunnisa Syed</div><div><b>Pages:&nbsp;</b>7525 - 7533</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07921-7\">Analysis of MRI brain tumor images using deep learning techniques</a></div><div><b>Author(s):&nbsp;</b>B. J. D. Kalyani, K. Meena...D. Saravanan</div><div><b>Pages:&nbsp;</b>7535 - 7542</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07934-2\">Security-enhanced machine learning model for diagnosis of knee joint disorders using vibroarthrographic signals</a></div><div><b>Author(s):&nbsp;</b>A. Balajee, R. Murugan, K. Venkatesh</div><div><b>Pages:&nbsp;</b>7543 - 7553</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07954-y\">Cybersecurity enhancement to detect credit card frauds in health care using new machine learning strategies</a></div><div><b>Author(s):&nbsp;</b>E. Jayanthi, T. Ramesh...Raja Marappan</div><div><b>Pages:&nbsp;</b>7555 - 7565</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08169-x\">Construction waste resource utilization and energy consumption calculation based on Internet of things</a></div><div><b>Author(s):&nbsp;</b>Fuhua Chang, Dan Wang</div><div><b>Pages:&nbsp;</b>7567 - 7578</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08134-8\">Film and television art innovation in network environment by using collaborative filtering recommendation algorithm</a></div><div><b>Author(s):&nbsp;</b>Xueyan Lai, Jianke Chen</div><div><b>Pages:&nbsp;</b>7579 - 7589</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08124-w\">Research on prediction of power market credit system based on linear model and improved BP neural network</a></div><div><b>Author(s):&nbsp;</b>Daoqiang Li, Miao Wang, Qingxin Yan</div><div><b>Pages:&nbsp;</b>7591 - 7603</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08137-5\">Online task scheduling and English online cooperative learning based on 5G mobile communication network</a></div><div><b>Author(s):&nbsp;</b>Shanshan Guo</div><div><b>Pages:&nbsp;</b>7605 - 7614</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08123-x\">Application of big data classification effects based on neural network in video English course and relevant optimization suggestions</a></div><div><b>Author(s):&nbsp;</b>Wen Suyun, Zheng Suying</div><div><b>Pages:&nbsp;</b>7615 - 7625</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08147-3\">Artificial intelligence and automatic recognition application in B2C e-commerce platform consumer behavior recognition</a></div><div><b>Author(s):&nbsp;</b>Tian Xie</div><div><b>Pages:&nbsp;</b>7627 - 7637</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08129-5\">System simulation of computer image recognition technology application by using improved neural network algorithm</a></div><div><b>Author(s):&nbsp;</b>Xin Wang</div><div><b>Pages:&nbsp;</b>7639 - 7646</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08138-4\">Research of natural language processing based on dynamic search corpus in cultural translation and emotional analysis</a></div><div><b>Author(s):&nbsp;</b>Junya Wang</div><div><b>Pages:&nbsp;</b>7647 - 7655</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08113-z\">Political teaching application in high vocational care courses based on machine learning systems</a></div><div><b>Author(s):&nbsp;</b>Zixia Zhou, Yang Liu</div><div><b>Pages:&nbsp;</b>7657 - 7666</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08142-8\">Design of computer big data processing system based on genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Song Chen</div><div><b>Pages:&nbsp;</b>7667 - 7678</div><div><br /></div>",
            "pubdate": "2023-06-09T12:00:00.156+12:00",
            "pubdate_parsed": [
                2023,
                6,
                9
            ],
            "email_sent": true
        },
        "IEEE Transactions on Fuzzy Systems, Volume 31, Issue 6": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/ieee-transactions-on-fuzzy-systems.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/9917318/\">Fuzzy-Resilient Distributed Optimal Coordination for Nonlinear Multiagent Systems Under Command Attacks</a></div><div><b>Author(s): </b>Lili Zhang, Yongming Li</div><div><b>Pages: </b>1759 - 1768</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9917280/\">Finite-Time Synchronization of Fractional-Order Delayed Fuzzy Cellular Neural Networks With Parameter Uncertainties</a></div><div><b>Author(s):&nbsp;</b>Feifei Du, Jun-Guo Lu</div><div><b>Pages:&nbsp;</b>1769 - 1779</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9917542/\">A Novel Diversified Attribute Group Decision-Making Method Over Multisource Heterogeneous Fuzzy Decision Systems With Its Application to Gout Diagnosis</a></div><div><b>Author(s):&nbsp;</b>Jin Ye, Bingzhen Sun, Xiaoli Chu, Jianming Zhan, Qiang Bao, Jianxiong Cai</div><div><b>Pages:&nbsp;</b>1780 - 1794</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9918068/\">l1 Filtering for Positive Takagi\u2013Sugeno Fuzzy Systems via Successive Linear Programming</a></div><div><b>Author(s):&nbsp;</b>Yingying Ren, Da-Wei Ding, Xiangpeng Xie</div><div><b>Pages:&nbsp;</b>1795 - 1805</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9921320/\">Antidisturbance Control Design for Interval Type-2 Fuzzy Stochastic Systems With Input Quantization</a></div><div><b>Author(s):&nbsp;</b>Ramasamy Kavikumar, Oh-Min Kwon, Boomipalagan Kaviarasan, Rathinasamy Sakthivel</div><div><b>Pages:&nbsp;</b>1806 - 1818</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9921309/\">Event-Triggered-Based Antidisturbance Switching Control for Switched T\u2013S Fuzzy Systems</a></div><div><b>Author(s):&nbsp;</b>Ying Zhao, Yuxuan Gao, Hong Sang, Shuanghe Yu</div><div><b>Pages:&nbsp;</b>1819 - 1829</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9925101/\">Resilient Sampled-Data Control for Stabilization of T--S Fuzzy Systems via Interval-Dependent Function Method: Handling DoS Attacks</a></div><div><b>Author(s):&nbsp;</b>Yingjie Fan, Xia Huang, Zhen Wang, Jianwei Xia, Hao Shen</div><div><b>Pages:&nbsp;</b>1830 - 1842</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9925120/\">A CNN-Based Born-Again TSK Fuzzy Classifier Integrating Soft Label Information and Knowledge Distillation</a></div><div><b>Author(s):&nbsp;</b>Yunliang Jiang, Jiangwei Weng, Xiongtao Zhang, Zhen Yang, Wenjun Hu</div><div><b>Pages:&nbsp;</b>1843 - 1854.</div><div><br /></div><div><b>9)</b> <a href=\"https://ieeexplore.ieee.org/document/9924302/\">Adaptive Event-Triggered Space-Time Sampled-Data Synchronization for Fuzzy Coupled RDNNs Under Hybrid Random Cyberattacks</a></div><div><b>Author(s):&nbsp;</b>Tao Wu, Sergey Gorbachev, Hak-Keung Lam, Ju H. Park, Lianglin Xiong, Jinde Cao</div><div><b>Pages:&nbsp;</b>1855 - 1869</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9925075/\">Observer-Based Control for a New Stochastic Maximum Power Point Tracking for Photovoltaic Systems With Networked Control System</a></div><div><b>Author(s):&nbsp;</b>Muhammad Shamrooz Aslam, Prayag Tiwari, Hari Mohan Pandey, Shahab S. Band</div><div><b>Pages:&nbsp;</b>1870 - 1884</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9925585/\">Two-Way Concept-Cognitive Learning Method: A Fuzzy-Based Progressive Learning</a></div><div><b>Author(s):&nbsp;</b>Weihua Xu, Doudou Guo, Yuhua Qian, Weiping Ding</div><div><b>Pages:&nbsp;</b>1885 - 1899</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9925688/\">Observer-Based Adaptive Fuzzy Quantized Fault-Tolerant Control of Nonstrict-Feedback Nonlinear Systems With Sensor Fault</a></div><div><b>Author(s):&nbsp;</b>Tiantian Wu, Zhaoxu Yu, Shugang Li</div><div><b>Pages:&nbsp;</b>1900 - 1911</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9926043/\">Asynchronous Control of Fuzzy Singularly Perturbed System With a Dynamic Event-Triggered Strategy</a></div><div><b>Author(s):&nbsp;</b>Kun Liang, Wangli He, Jing Xu</div><div><b>Pages:&nbsp;</b>1912 - 1924</div><div><br /></div><div><b>14) </b><a href=\"https://ieeexplore.ieee.org/document/9930109/\">Self-Organizing Interval Type-2 Fuzzy Neural Network With Adaptive Discriminative Strategy</a></div><div><b>Author(s):&nbsp;</b>Honggui Han, Chenxuan Sun, Xiaolong Wu, Hongyan Yang, Junfei Qiao</div><div><b>Pages:&nbsp;</b>1925 - 1939</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9928209/\">Adaptive Fuzzy Optimal Control for Switched Nonlinear Systems With Output Hysteresis</a></div><div><b>Author(s):&nbsp;</b>Licheng Zheng, Zhi Liu, C. L. Philip Chen, Yun Zhang, Zongze Wu, Shengli Xie</div><div><b>Pages:&nbsp;</b>1940 - 1952</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9927486/\">Exponential Synchronization of Second-Order Fuzzy Memristor-Based Neural Networks With Mixed Time Delays via Fuzzy Adaptive Control</a></div><div><b>Author(s):&nbsp;</b>Qiwei Liu, Huaicheng Yan, Hao Zhang, Chaoyang Chen, Yufang Chang</div><div><b>Pages:&nbsp;</b>1953 - 1965</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9928400/\">Asynchronous Nonfragile Mixed H\u221e and L2\u2212L\u221e Control of Switched Fuzzy Systems With Multiple State Impulsive Jumps</a></div><div><b>Author(s):&nbsp;</b>Qunxian Zheng, Shengyuan Xu, Baozhu Du</div><div><b>Pages:&nbsp;</b>1966 - 1980</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9928365/\">Instance and Feature Selection Using Fuzzy Rough Sets: A Bi-Selection Approach for Data Reduction</a></div><div><b>Author(s):&nbsp;</b>Xiao Zhang, Changlin Mei, Jinhai Li, Yanyan Yang, Ting Qian</div><div><b>Pages:&nbsp;</b>1981 - 1994</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9928377/\">Evolving Neuro-Fuzzy Systems-Based Design of Experiments in Process Identification</a></div><div><b>Author(s):&nbsp;</b>Miha O\u017ebot, Edwin Lughofer, Igor \u0160krjanc</div><div><b>Pages:&nbsp;</b>1995 - 2005</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9930633/\">Dynamic Fuzzy Boundary Output Feedback Control for Nonlinear Delayed Parabolic Partial Differential Equation Systems Under Noncollocated Boundary Measurement</a></div><div><b>Author(s):&nbsp;</b>Zi-Peng Wang, Xu Zhang, Huai-Ning Wu, Mohammed Chadli, Tingwen Huang, Junfei Qiao</div><div><b>Pages:&nbsp;</b>2006 - 2017</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9930659/\">A Lattice Structure on Hesitant Fuzzy Sets</a></div><div><b>Author(s):&nbsp;</b>Pascual Jara, Luis Merino, Gabriel Navarro, Evangelina Santos</div><div><b>Pages:&nbsp;</b>2018 - 2028</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9933040/\">Improved Fixed-Time Stabilization of Fuzzy Neural Networks With Distributed Delay via Adaptive Sliding Mode Control</a></div><div><b>Author(s):&nbsp;</b>Fangmin Ren, Xiaoping Wang, Zhigang Zeng</div><div><b>Pages:&nbsp;</b>2029 - 2043</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9933624/\">Graph-Based Soft-Balanced Fuzzy Clustering</a></div><div><b>Author(s):&nbsp;</b>Chaodie Liu, Feiping Nie, Rong Wang, Xuelong Li</div><div><b>Pages:&nbsp;</b>2044 - 2055</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9933617/\">Fuzzy Rule-Based Local Surrogate Models for Black-Box Model Explanation</a></div><div><b>Author(s):&nbsp;</b>Xiubin Zhu, Dan Wang, Witold Pedrycz, Zhiwu Li</div><div><b>Pages:&nbsp;</b>2056 - 2064</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9935313/\">Event-Triggered Prescribed Performance Fuzzy Fault-Tolerant Control for Unknown Euler\u2013Lagrange Systems With Any Bounded Initial Values</a></div><div><b>Author(s):&nbsp;</b>Yunsong Hu, Huaicheng Yan, Youmin Zhang, Hao Zhang, Yufang Chang</div><div><b>Pages:&nbsp;</b>2065 - 2075</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9944154/\">Algebraic Formulation and Application of Multi-Input Single-Output Hierarchical Fuzzy Systems With Correction Factors</a></div><div><b>Author(s):&nbsp;</b>Changle Sun, Haitao Li</div><div><b>Pages:&nbsp;</b>2076 - 2085</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9925571/\">Convex Optimization-Based Adaptive Fuzzy Control for Uncertain Nonlinear Systems With Input Saturation Using Command Filtered Backstepping</a></div><div><b>Author(s):&nbsp;</b>Jiapeng Liu, Qing-Guo Wang, Jinpeng Yu</div><div><b>Pages:&nbsp;</b>2086 - 2091</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9930670/\">Sugeno-Like Operators in Preference and Uncertain Environments</a></div><div><b>Author(s):&nbsp;</b>LeSheng Jin, Yi Yang, Radko Mesiar, Ronald R. Yager</div><div><b>Pages:&nbsp;</b>2092 - 2098</div><div><br /></div></div>",
            "pubdate": "2023-06-10T12:00:00.001+12:00",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "Soft Computing. Volume 27, Issue 12, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/soft-computing-volume-27-issue-12-june.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08024-z\">Local fuzzy rough set model over two universes and its reduction</a></div><div><b>Author(s): </b>Linlin Xie, Guoping Lin...Yi Kou</div><div><b>Pages: </b>7679 - 7697</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08034-x\">The generalizations of fuzzy monoids and vague monoids</a></div><div><b>Author(s):&nbsp;</b>Wei Li, Haohao Wang...Bin Yang</div><div><b>Pages:&nbsp;</b>7699 - 7714</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08037-8\">Stability assessment using adaptive interval type-2 fuzzy sliding mode controlled power system stabilizer</a></div><div><b>Author(s):&nbsp;</b>Dipak R. Swain, Prakash K. Ray...Shiba R. Paital</div><div><b>Pages:&nbsp;</b>7715 - 7737</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08046-7\">General fractional interval-valued differential equations and Gronwall inequalities</a></div><div><b>Author(s):&nbsp;</b>Qin FanLan-Lan HuangGuo-Cheng Wu</div><div><b>Pages:&nbsp;</b>7739 - 7749</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08079-y\">A novel linguistic decision making approach based on attribute correlation and EDAS method</a></div><div><b>Author(s):&nbsp;</b>Qingzhao Li, Yuan Rong...Fangling Ren</div><div><b>Pages:&nbsp;</b>7751 - 7771</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08088-x\">L-fuzzy generalized neighborhood system-based pessimistic L-fuzzy rough sets and its applications</a></div><div><b>Author(s):&nbsp;</b>Lu Gao, Bing-Xue Yao, Ling-Qiang Li</div><div><b>Pages:&nbsp;</b>7773 - 7788</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07973-9\">On the edge irregular reflexive labeling for some classes of plane graphs</a></div><div><b>Author(s):&nbsp;</b>M. Basher</div><div><b>Pages:&nbsp;</b>7789 - 7799</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08025-y\">Neutrosophic statistical analysis of split-plot designs</a></div><div><b>Author(s):&nbsp;</b>Abdulrahman AlAita, Hooshang Talebi...Khaled Al Sultan</div><div><b>Pages:&nbsp;</b>7801 - 7811</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08049-4\">Heuristic normalization procedure for batch effect correction</a></div><div><b>Author(s):&nbsp;</b>Arthur Yosef, Eli Shnaider...Michael Gurevich</div><div><b>Pages:&nbsp;</b>7813 - 7829</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07953-z\">Intelligent multi-level analytics of soft computing approach to predict water quality index (IM12CP-WQI)</a></div><div><b>Author(s):&nbsp;</b>Samaher Al-Janabi, Zahraa Al-Barmani</div><div><b>Pages:&nbsp;</b>7831 - 7861</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07961-z\">Detecting adversarial examples using image reconstruction differences</a></div><div><b>Author(s):&nbsp;</b>Jiaze Sun, Meng Yi</div><div><b>Pages:&nbsp;</b>7863 - 7877</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08010-5\">Target recognition with fusion of visible and infrared images based on mutual learning</a></div><div><b>Author(s):&nbsp;</b>Shuyue Wang, Yanbo Yang...Quan Pan</div><div><b>Pages:&nbsp;</b>7879 - 7894</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08018-x\">A novel capsule network based on deep routing and residual learning</a></div><div><b>Author(s):&nbsp;</b>Jian Zhang, Qinghai Xu...Shifei Ding</div><div><b>Pages:&nbsp;</b>7895 - 7906</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08019-w\">IRPDP_HT2: a scalable data pre-processing method in web usage mining using Hadoop MapReduce</a></div><div><b>Author(s):&nbsp;</b>Atul Kumar Srivastava, Mitali Srivastava</div><div><b>Pages:&nbsp;</b>7907 - 7923</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08031-0\">Uncertainty estimation-based adversarial attacks: a viable approach for graph neural networks</a></div><div><b>Author(s):&nbsp;</b>Ismail Alarab, Simant Prakoonwit</div><div><b>Pages:&nbsp;</b>7925 - 7937</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07987-3\">Optimizing airport slot scheduling problem using optimization algorithms</a></div><div><b>Author(s):&nbsp;</b>Mohd Khaled Shambour, Muhannad A Abu-Hashem</div><div><b>Pages:&nbsp;</b>7939 - 7955</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07988-2\">A self-adaptive binary cat swarm optimization using new time-varying transfer function for gene selection in DNA microarray expression cancer data</a></div><div><b>Author(s):&nbsp;</b>Yousef Sharafi, Mohammad Teshnehlab, Marzieh Mohammady Aria</div><div><b>Pages:&nbsp;</b>7957 - 7997</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07989-1\">TDCA: improved optimization algorithm with degree distribution and communication traffic for the deployment of software components based on AUTOSAR architecture</a></div><div><b>Author(s):&nbsp;</b>Kunpeng Zhang, Yanheng Liu...Fengmin Tang</div><div><b>Pages:&nbsp;</b>7999 - 8012</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07990-8\">Chicken swarm optimization with an enhanced exploration\u2013exploitation tradeoff and its application</a></div><div><b>Author(s):&nbsp;</b>Yingcong Wang, Chengcheng Sui...Yanfeng Wang</div><div><b>Pages:&nbsp;</b>8013 - 8028</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07994-4\">A reactive path relinking algorithm for solving the bi-objective p-Median and p-Dispersion problem</a></div><div><b>Author(s):&nbsp;</b>I. Lozano-Osorio, J. S\u00e1nchez-Oro...A. Duarte</div><div><b>Pages:&nbsp;</b>8029 - 8059</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07999-z\">Random search immune algorithm for community detection</a></div><div><b>Author(s):&nbsp;</b>Antonio G. Spampinato, Rocco A. Scollo...Mario Pavone</div><div><b>Pages:&nbsp;</b>8061 - 8090</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08002-5\">Evolutionary multi-objective optimization for RIS-aided MU-MISO communication systems</a></div><div><b>Author(s):&nbsp;</b>Mengke Li, Bai Yan, Jin Zhang</div><div><b>Pages:&nbsp;</b>8091 - 8106</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08085-0\">Shared manufacturing in a differentiated duopoly with capacity constraints</a></div><div><b>Author(s):&nbsp;</b>Junlong Chen, Chaoqun Sun, Jiali Liu</div><div><b>Pages:&nbsp;</b>8107 - 8135</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08121-z\">A parametric distance-based outranking method for probabilistic linguistic multi-criteria decision-making problems</a></div><div><b>Author(s):&nbsp;</b>Pei Wang, Zhen Shen, Shuai Huang</div><div><b>Pages:&nbsp;</b>8137 - 8152</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08152-6\">Averaging aggregation under uncertainty and bipolar preference environments</a></div><div><b>Author(s):&nbsp;</b>LeSheng Jin, Ronald R. Yager...Rosa M. Rodr\u00edguez</div><div><b>Pages:&nbsp;</b>8153 - 8159</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08155-3\">Environmental quality evaluation based on the TODIM method with normal wiggly hesitant fuzzy set</a></div><div><b>Author(s):&nbsp;</b>Chenyang Song, Zeshui Xu...Bo Li</div><div><b>Pages:&nbsp;</b>8161 - 8173</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07704-6\">Multi-fault diagnosis of rolling bearing using two-dimensional feature vector of WP-VMD and PSO-KELM algorithm</a></div><div><b>Author(s):&nbsp;</b>Tingyu Jiang, Yakun Li, Shen Li</div><div><b>Pages:&nbsp;</b>8175 - 8187</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07715-3\">Advantages of the usage of the Infinity Computer for reducing the Zeno behavior in hybrid system models</a></div><div><b>Author(s):&nbsp;</b>Alberto Falcone, Alfredo Garro...Yaroslav D. Sergeyev</div><div><b>Pages:&nbsp;</b>8189 - 8208</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07716-2\">A prediction model of stock market trading actions using generative adversarial network and piecewise linear representation approaches</a></div><div><b>Author(s):&nbsp;</b>Jheng-Long Wu, Xian-Rong Tang, Chin-Hsiung Hsu</div><div><b>Pages:&nbsp;</b>8209 - 8222</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07725-1\">Power maximization in standalone photovoltaic system: an adaptive PSO approach</a></div><div><b>Author(s):&nbsp;</b>M. P. Anbarasi, S. Kanthalakshmi</div><div><b>Pages:&nbsp;</b>8223 - 8232</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07733-1\">Optimization of cooperative offloading model with cost consideration in mobile edge computing</a></div><div><b>Author(s):&nbsp;</b>Bin Xu, Tao Deng...Dan Liu</div><div><b>Pages:&nbsp;</b>8233 - 8243</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07735-z\">Replacement of signalized traffic network design with Hamiltonian roads: delay? Nevermind</a></div><div><b>Author(s):&nbsp;</b>Ekinhan Eriskin, Gul Fatma Turker...Serdal Terzi</div><div><b>Pages:&nbsp;</b>8245 - 8254</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07738-w\">Software defect prediction using hybrid techniques: a systematic literature review</a></div><div><b>Author(s):&nbsp;</b>Ruchika Malhotra, Sonali Chawla, Anjali Sharma</div><div><b>Pages:&nbsp;</b>8255 - 8288</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07750-0\">Decision-making method based on set pair analysis and VIKOR under heterogeneous information environment and application to typhoon disaster assessment</a></div><div><b>Author(s):&nbsp;</b>Ruipu Tan, Wende Zhang, Lehua Yang</div><div><b>Pages:&nbsp;</b>8289 - 8314</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08347-x\">Optimization of automotive suspension system using vibration and noise control for intelligent transportation system</a></div><div><b>Author(s):&nbsp;</b>Shisheng Li, Qiong Yuan</div><div><b>Pages:&nbsp;</b>8315 - 8329</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08185-x\">Machine learning technique-based emotion classification using speech signals</a></div><div><b>Author(s):&nbsp;</b>K. Ashok Kumar, J. L. Mazher Iqbal</div><div><b>Pages:&nbsp;</b>8331 - 8343</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08186-w\">Cucurbitaceous family flower inferencing using deep transfer learning approaches: CuCuFlower UAV imagery data</a></div><div><b>Author(s):&nbsp;</b>S. Mithra, T. Y. J. Nagamalleswari</div><div><b>Pages:&nbsp;</b>8345 - 8356</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08296-5\">Design and development of big data-based model for detecting fraud in healthcare insurance industry</a></div><div><b>Author(s):&nbsp;</b>A. Jenita Mary, S. P. Angelin Claret</div><div><b>Pages:&nbsp;</b>8357 - 8369</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08110-2\">Simulation evaluation of virtual reality in interior design effect display and practice mode innovation</a></div><div><b>Author(s):&nbsp;</b>Lichun Guo</div><div><b>Pages:&nbsp;</b>8371 - 8380</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08112-0\">Application and functional simulation of data mining technology in Hadoop cloud platform based on improved algorithm</a></div><div><b>Author(s):&nbsp;</b>Nina Dai</div><div><b>Pages:&nbsp;</b>8381 - 8389</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08118-8\">Multimedia Lu Xun literature online learning based on deep learning</a></div><div><b>Author(s):&nbsp;</b>Wang Hongsheng</div><div><b>Pages:&nbsp;</b>8391 - 8401</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08128-6\">Application of GIS image system and remote sensing technology in physical geography land planning</a></div><div><b>Author(s):&nbsp;</b>Yun Xie, Zhiying Wang...Binggeng Xie</div><div><b>Pages:&nbsp;</b>8403 - 8414</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08139-3\">Development of English translation online teaching system and service function improvement based on image segmentation algorithm</a></div><div><b>Author(s):&nbsp;</b>Hongliang Qiao, Lina An, Maojun Cao</div><div><b>Pages:&nbsp;</b>8415 - 8424</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08140-w\">Composite fault diagnosis of traction motor of high-speed train based on support vector machine and sensor</a></div><div><b>Author(s):&nbsp;</b>Yanshu Li, Fang Li...Baoxian Chang</div><div><b>Pages:&nbsp;</b>8425 - 8435</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08143-7\">Application of facial expression recognition based on domain-adapted convolutional neural network in English smart teaching system</a></div><div><b>Author(s):&nbsp;</b>Lilin Liu</div><div><b>Pages:&nbsp;</b>8437 - 8448</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08146-4\">Intelligent product art design based on smart equipment and machine learning algorithm: practice effect and trend analysis</a></div><div><b>Author(s):&nbsp;</b>Chen Mengyao, Tian Yu</div><div><b>Pages:&nbsp;</b>8449 - 8458</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08148-2\">Data monitoring in student psychological automatic evaluation system by using dynamic acquisition algorithm</a></div><div><b>Author(s):&nbsp;</b>Peng Li</div><div><b>Pages:&nbsp;</b>8459 - 8469</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08149-1\">Application and effect simulation of image recognition technology based on machine vision feature parameters in art teaching</a></div><div><b>Author(s):&nbsp;</b>Guo Surong, Xu Jicheng, Han Chunming</div><div><b>Pages:&nbsp;</b>8471 - 8479</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08280-z\">Deep learning techniques for prediction of pneumonia from lung CT images</a></div><div><b>Author(s):&nbsp;</b>K. Meena, T. Veeramakali...P. Muthuvel</div><div><b>Pages:&nbsp;</b>8481 - 8491</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08311-9\">HDFRMAH: design of a high-density feature representation model for multidomain analysis of human health issues</a></div><div><b>Author(s):&nbsp;</b>Rakhi Mutha, Santosh Lavate...Vishal Ashok Wankhede</div><div><b>Pages:&nbsp;</b>8493 - 8503</div><div><br /></div></div>",
            "pubdate": "2023-06-12T12:00:00.001+12:00",
            "pubdate_parsed": [
                2023,
                6,
                12
            ],
            "email_sent": true
        },
        "Soft Computing. Volume 27, Issue 13, July 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/soft-computing-volume-27-issue-13-july.html",
            "description": "<div style=\"text-align: left;\"><div><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08193-x\">Stochastic fixed-time quantitative synchronization for multilayer derivative dynamic Cohen\u2013Grossberg networks and secure communication</a></div><div><b>Author(s): </b>Fei Tan, Lili Zhou...Yongmin Li</div><div><b>Pages: </b>8505 - 8516</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08228-3\">Oscillation criteria for fractional differential equations with a distributed delay</a></div><div><b>Author(s):&nbsp;</b>Tu\u011fba Yal\u00e7\u0131n Uzun, Sermin \u00d6zt\u00fcrk</div><div><b>Pages:&nbsp;</b>8517 - 8523</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08236-3\">A numerical framework for modeling the dynamics of micro-organism movement on Carreau-Yasuda layer</a></div><div><b>Author(s):&nbsp;</b>Zeeshan Asghar, Rehman Ali Shah, Nasir Ali</div><div><b>Pages:&nbsp;</b>8525 - 8539</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08132-w\">TODIM-VIKOR method based on hybrid weighted distance under probabilistic uncertain linguistic information and its application in medical logistics center site selection</a></div><div><b>Author(s):&nbsp;</b>Fan Lei, Qiang Cai...Cun Wei</div><div><b>Pages:&nbsp;</b>8541 - 8559</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08171-3\">Optimized cascade chaotic fuzzy system (OCCFS) and its application to function approximation and chaotic systems identification</a></div><div><b>Author(s):&nbsp;</b>Hamid Abbasi, Mahdi Yaghoobi</div><div><b>Pages:&nbsp;</b>8561 - 8582</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08181-1\">Applications of fuzzy conformable Laplace transforms for solving fuzzy conformable differential equations</a></div><div><b>Author(s):&nbsp;</b>Awais Younus, Muhammad Asif...Thabet Abdeljawad</div><div><b>Pages:&nbsp;</b>8583 - 8597</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08184-y\">Mine safety evaluation method using correlation coefficients of consistency linguistic neutrosophic sets in a linguistic neutrosophic multivalued environment</a></div><div><b>Author(s):&nbsp;</b>Jun Ye, Shigui Du, Rui Yong</div><div><b>Pages:&nbsp;</b>8599 - 8609</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08194-w\">Fuzzy natural transform method for solving fuzzy differential equations</a></div><div><b>Author(s):&nbsp;</b>Shabir Ahmad, Aman Ullah...Ngo Van Hoa</div><div><b>Pages:&nbsp;</b>8611 - 8625</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08048-5\">Multi-label classification via closed frequent labelsets and label taxonomies</a></div><div><b>Author(s):&nbsp;</b>Mauri Ferrandin, Ricardo Cerri</div><div><b>Pages:&nbsp;</b>8627 - 8660</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08050-x\">Efficient hyperparameters optimization through model-based reinforcement learning with experience exploiting and meta-learning</a></div><div><b>Author(s):&nbsp;</b>Xiyuan Liu, Jia Wu, Senpeng Chen</div><div><b>Pages:&nbsp;</b>8661 - 8678</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08056-5\">Panoramic image generation using deep neural networks</a></div><div><b>Author(s):&nbsp;</b>Izat Khamiyev, Dias Issa...M. Fatih Demirci</div><div><b>Pages:&nbsp;</b>8679 - 8695</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08150-8\">Stock turning points classification using a novel discrete learning-based methodology</a></div><div><b>Author(s):&nbsp;</b>Mehdi Khashei, Fateme Yazdani, Negar Bakhtiarvand</div><div><b>Pages:&nbsp;</b>8697 - 8710</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08172-2\">The CNN-GRU model with frequency analysis module for sea surface temperature prediction</a></div><div><b>Author(s):&nbsp;</b>Ying Han, Kaiqiang Sun...Changming Dong</div><div><b>Pages:&nbsp;</b>8711 - 8720</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08230-9\">Automated facial expression recognition using exemplar hybrid deep feature generation technique</a></div><div><b>Author(s):&nbsp;</b>Mehmet Baygin, Ilknur Tuncer...U. Rajendra Acharya</div><div><b>Pages:&nbsp;</b>8721 - 8737</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08285-8\">Artificial intelligence inspired framework for preventing sexual violence at public toilets of educational institutions with the improvisation of gender recognition from gait sequences</a></div><div><b>Author(s):&nbsp;</b>Munish Saini, Manpreet Kaur...Khalil Ahmed</div><div><b>Pages:&nbsp;</b>8739 - 8758</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08011-4\">Sensitivity analysis on Gaussian quantum-behaved particle swarm optimization control parameters</a></div><div><b>Author(s):&nbsp;</b>Vankayala Sai Rugveth, Kiran Khatter</div><div><b>Pages:&nbsp;</b>8759 - 8774</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08020-3\">A shared libraries aware and bank partitioning-based mechanism for multicore architecture</a></div><div><b>Author(s):&nbsp;</b>Hubin Yang, Shuaixin Xu...Kuan-Ching Li</div><div><b>Pages:&nbsp;</b>8775 - 8787</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08032-z\">Solving the hierarchical windy postman problem with variable service costs using a math-heuristic algorithm</a></div><div><b>Author(s):&nbsp;</b>Muhammed Emre Keskin, Mustafa Y\u0131lmaz, Chefi Triki</div><div><b>Pages:&nbsp;</b>8789 - 8805</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08039-6\">Improved particle swarm optimization algorithm based on grouping and its application in hyperparameter optimization</a></div><div><b>Author(s):&nbsp;</b>Jianjun Zhan, Jun Tang...Hao Li</div><div><b>Pages:&nbsp;</b>8807 - 8819</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08042-x\">Fuzzy random classical and inverse median location problems</a></div><div><b>Author(s):&nbsp;</b>Sepideh Taghikhani, Fahimeh Baroughi</div><div><b>Pages:&nbsp;</b>8821 - 8839</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07743-z\">Adaptive robust control algorithm for enhanced path-tracking performance of automated driving in critical scenarios</a></div><div><b>Author(s):&nbsp;</b>Hamid Taghavifar, Khoshnam Shojaei</div><div><b>Pages:&nbsp;</b>8841 - 8854</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07763-9\">Time-dependent reliability calculation method of RC bridges based on the dual neural network</a></div><div><b>Author(s):&nbsp;</b>Yong Yang, Haibin Li</div><div><b>Pages:&nbsp;</b>8855 - 8866</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07780-8\">An efficient hybrid swarm intelligence optimization algorithm for solving nonlinear systems and clustering problems</a></div><div><b>Author(s):&nbsp;</b>Mohamed A. Tawhid, Abdelmonem M. Ibrahim</div><div><b>Pages:&nbsp;</b>8867 - 8895</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07796-0\">A novel granular variable precision fuzzy rough set model and its application in fuzzy decision system</a></div><div><b>Author(s):&nbsp;</b>Dan-Dan Zou, Yao-Liang Xu...Wei-Zhi Wu</div><div><b>Pages:&nbsp;</b>8897 - 8918</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07801-6\">Applying computational intelligence methods to evaluate lateral load capacity for a pile</a></div><div><b>Author(s):&nbsp;</b>Hadi Fattahi</div><div><b>Pages:&nbsp;</b>8919 - 8929</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08414-3\">A comprehensive comparison of accuracy-based fitness functions of metaheuristics for feature selection</a></div><div><b>Author(s):&nbsp;</b>Ahmet Cevahir Cinar</div><div><b>Pages:&nbsp;</b>8931 - 8958</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07500-2\">Fixed-time passivity of coupled quaternion-valued neural networks with multiple delayed couplings</a></div><div><b>Author(s):&nbsp;</b>Ruoyu Wei, Jinde Cao, Fawaz E Alsaadi</div><div><b>Pages:&nbsp;</b>8959 - 8970</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07788-0\">Diagnosis of cardiovascular disease using deep learning technique</a></div><div><b>Author(s):&nbsp;</b>Shakeel Ahmad, Muhammad Zubair Asghar...Yasir D. Alotaibi</div><div><b>Pages:&nbsp;</b>8971 - 8990</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07834-5\">Global matrix projective synchronization of delayed fractional-order neural networks</a></div><div><b>Author(s):&nbsp;</b>Jin-Man He, Teng-Fei Lei, Fang-Qi Chen</div><div><b>Pages:&nbsp;</b>8991 - 9000</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08412-5\">Application of industrial Internet of things technology in fault diagnosis of food machinery equipment based on neural network</a></div><div><b>Author(s):&nbsp;</b>Hongpeng Liu</div><div><b>Pages:&nbsp;</b>9001 - 9018</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08161-5\">A fast retrieval method of drug information based on multidimensional data analysis</a></div><div><b>Author(s):&nbsp;</b>Chenggong Yu</div><div><b>Pages:&nbsp;</b>9019 - 9029</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08162-4\">Application of machine learning-based BIM in green public building design</a></div><div><b>Author(s):&nbsp;</b>Dan Wang, Fuhua Chang</div><div><b>Pages:&nbsp;</b>9031 - 9040</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08163-3\">Research on Great Wall section protection and user VR experience innovation based on GIS data visualization</a></div><div><b>Author(s):&nbsp;</b>Wang Yanzhen, Wang Xiaofen, Han Lihua</div><div><b>Pages:&nbsp;</b>9041 - 9050</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08166-0\">Cloud service and interactive IoT system application in the service management mode of logistics enterprises</a></div><div><b>Author(s):&nbsp;</b>Wei Zheng</div><div><b>Pages:&nbsp;</b>9051 - 9064</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08167-z\">App interaction design in the pop music singing teaching system based on differential evolution algorithm</a></div><div><b>Author(s):&nbsp;</b>Qinke Wu</div><div><b>Pages:&nbsp;</b>9065 - 9075</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08168-y\">Simulation of agricultural digital economy development and policy support system based on resource sensitivity index</a></div><div><b>Author(s):&nbsp;</b>Yanqing Dai</div><div><b>Pages:&nbsp;</b>9077 - 9091</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08418-z\">Early diagnosis of diabetic retinopathy using unsupervised learning</a></div><div><b>Author(s):&nbsp;</b>M. Padmapriya, S. Pasupathy, V. Punitha</div><div><b>Pages:&nbsp;</b>9093 - 9104</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08419-y\">CT and MRI multi-modal medical image fusion using weight-optimized anisotropic diffusion filtering</a></div><div><b>Author(s):&nbsp;</b>G. Tirumala Vasu, P. Palanisamy</div><div><b>Pages:&nbsp;</b>9105 - 9117</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08421-4\">Single-channel fetal ECG extraction method based on extended Kalman filtering with singular value decomposition algorithm</a></div><div><b>Author(s):&nbsp;</b>Smitha Bandi, V. B. S. Srilatha Indira Dutt</div><div><b>Pages:&nbsp;</b>9119 - 9129</div><div><br /></div><div><b>40)</b> A<a href=\"https://link.springer.com/article/10.1007/s00500-023-08432-1\">nalysis of transcriptome of single-cell RNA sequencing data using machine learning</a></div><div><b>Author(s):&nbsp;</b>Mothe Rajesh, Sheshikala Martha</div><div><b>Pages:&nbsp;</b>9131 - 9141</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08434-z\">Efficient Alzheimer\u2019s disease detection using deep learning technique</a></div><div><b>Author(s):&nbsp;</b>B. V. D. S. Sekhar, Alok Kumar Jagadev</div><div><b>Pages:&nbsp;</b>9143 - 9150</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08499-w\">Efficient medical image security and transmission using modified LZW compression and ECDH-AES for telemedicine applications</a></div><div><b>Author(s):&nbsp;</b>V. Padmanabha Reddy, R. Murali Prasad...Ch. Raja</div><div><b>Pages:&nbsp;</b>9151 - 9168</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08283-w\">Stochastic gradient descent-based convolutional neural network to detect and classify oral cavity cancer</a></div><div><b>Author(s):&nbsp;</b>R. Prabhakaran, J. Mohana</div><div><b>Pages:&nbsp;</b>9169 - 9178</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08420-5\">Automated brain tumor detection and segmentation using modified UNet and ResNet model</a></div><div><b>Author(s):&nbsp;</b>N. Phani Bindu, P. Narahari Sastry</div><div><b>Pages:&nbsp;</b>9179 - 9189</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08313-7\">Performance evaluation of deep learning techniques for lung cancer prediction</a></div><div><b>Author(s):&nbsp;</b>B. S. Deepapriya, Parasuraman Kumar...K. Meena</div><div><b>Pages:&nbsp;</b>9191 - 9198</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08279-6\">Classification of health care products using hybrid CNN-LSTM model</a></div><div><b>Author(s):&nbsp;</b>B. Ramakantha Reddy, R. Lokesh Kumar</div><div><b>Pages:&nbsp;</b>9199 - 9216</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08553-7\">Retraction Note: Enhanced bat algorithm for COVID-19 short-term forecasting using optimized LSTM</a></div><div><b>Author(s):&nbsp;</b>Hafiz Tayyab Rauf, Jiechao Gao...Md Tabrez Nafis</div><div><b>Pages:&nbsp;</b>9217 - 9217</div><div><b><br /></b></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08554-6\">Retraction Note: Coronavirus herd immunity optimizer to solve classification problems</a></div><div><b>Author(s):&nbsp;</b>Mohammed Alweshah</div><div><b>Pages:&nbsp;</b>9219 - 9219</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08555-5\">Retraction Note: Hybrid intelligent model for classifying chest X-ray images of COVID-19 patients using genetic algorithm and neutrosophic logic</a></div><div><b>Author(s):&nbsp;</b>Sameh H. Basha, Ahmed M. Anter...Areeg Abdalla</div><div><b>Pages:&nbsp;</b>9221 - 9221</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08556-4\">Retraction Note: India perspective: CNN-LSTM hybrid deep learning model-based COVID-19 prediction and current status of medical resource availability</a></div><div><b>Author(s):&nbsp;</b>Shwet Ketu, Pramod Kumar Mishra</div><div><b>Pages:&nbsp;</b>9223 - 9223</div><div><br /></div></div>",
            "pubdate": "2023-06-13T12:00:00.001+12:00",
            "pubdate_parsed": [
                2023,
                6,
                13
            ],
            "email_sent": true
        },
        "Soft Computing. Volume 27, Issue 14, July 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/soft-computing-volume-27-issue-14-july.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08200-1\">Particle swarm optimization selection based on the TOPSIS technique</a></div><div><b>Author(s): </b>Aliya Fahmi</div><div><b>Pages: </b>9225 - 9245</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08234-5\">Detecting influential node in a network using neutrosophic graph and its application</a></div><div><b>Author(s):&nbsp;</b>Rupkumar Mahapatra, Sovan Samanta, Madhumangal Pal</div><div><b>Pages:&nbsp;</b>9247 - 9260</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08269-8\">Study on centroid type-reduction of general type-2 fuzzy logic systems with sensible beginning weighted enhanced Karnik\u2013Mendel algorithms</a></div><div><b>Author(s):&nbsp;</b>Yang Chen</div><div><b>Pages:&nbsp;</b>9261 - 9279</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08294-7\">The consistent functions and reductions of fuzzy neighborhood systems</a></div><div><b>Author(s):&nbsp;</b>Keyun Qin, Qian Hu, Binbin Xue</div><div><b>Pages:&nbsp;</b>9281 - 9291</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08334-2\">A novel weighted complex evidence combination with its application in multisource information fusion</a></div><div><b>Author(s):&nbsp;</b>Huaping He, Liting He, Fuyuan Xiao</div><div><b>Pages:&nbsp;</b>9293 - 9305</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08125-9\">GPU implementation of an incomplete Cholesky conjugate gradient solver for a FEM-generated system using full kernel consolidation</a></div><div><b>Author(s):&nbsp;</b>Andr\u00e9 Kubagawa Sato, Thiago Castro Martins, Marcos Sales Guerra Tsuzuki</div><div><b>Pages:&nbsp;</b>9307 - 9320</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08203-y\">A novel fractional discrete grey model with variable weight buffer operator and its applications in renewable energy prediction</a></div><div><b>Author(s):&nbsp;</b>Yong Wang, Pei Chi...Binghong Guo</div><div><b>Pages:&nbsp;</b>9321 - 9345</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08291-w\">QPSO-AHES-RC: a hybrid learning model for short-term traffic flow prediction</a></div><div><b>Author(s):&nbsp;</b>Zhuoxuan Li, Jinde Cao...Wei Huang</div><div><b>Pages:&nbsp;</b>9347 - 9366</div><div><br /></div><div><b>9)</b> A<a href=\"https://link.springer.com/article/10.1007/s00500-023-08406-3\"> fuzzy/possibility approach for area coverage in wireless sensor networks</a></div><div><b>Author(s):&nbsp;</b>Adda Boualem, Cyril De Runz...Herman Akdag</div><div><b>Pages:&nbsp;</b>9367 - 9382</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08289-4\">Autonomous pedestrian detection for crowd surveillance using deep learning framework</a></div><div><b>Author(s):&nbsp;</b>Narina Thakur, Preeti Nagrath...D. Jude Hemanth</div><div><b>Pages:&nbsp;</b>9383 - 9399</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08316-4\">A survey: evolutionary deep learning</a></div><div><b>Author(s):&nbsp;</b>Yifan Li, Jing Liu</div><div><b>Pages:&nbsp;</b>9401 - 9423</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08324-4\">A deep learning-based intrusion detection approach for mobile Ad-hoc network</a></div><div><b>Author(s):&nbsp;</b>Rahma Meddeb, Farah Jemili...Ouajdi Korbaa</div><div><b>Pages:&nbsp;</b>9425 - 9439</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08407-2\">A novel initialisation based on hospital-resident assignment for the \ud835\udc58-modes algorithm</a></div><div><b>Author(s):&nbsp;</b>Jonathan Gillard, Vincent Knight, Henry Wilde</div><div><b>Pages:&nbsp;</b>9441 - 9457</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08442-z\">Efficacious implementation of deep Q-routing in opportunistic network</a></div><div><b>Author(s):&nbsp;</b>Renu Dalal, Manju Khari</div><div><b>Pages:&nbsp;</b>9459 - 9477</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08444-x\">Multi-step probabilistic forecasting model using deep learning parametrized distributions</a></div><div><b>Author(s):&nbsp;</b>Cristi\u00e1n Serpell, Carlos Valle, H\u00e9ctor Allende</div><div><b>Pages:&nbsp;</b>9479 - 9500</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08084-1\">Lens law based optimization algorithm: a novel approach</a></div><div><b>Author(s):&nbsp;</b>Byamakesh Nayak, Tanmoy Roy Choudhury</div><div><b>Pages:&nbsp;</b>9501 - 9518</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08086-z\">An optimization method for studying fractional-order tuberculosis disease model via generalized Laguerre polynomials</a></div><div><b>Author(s):&nbsp;</b>Z. Avazzadeh, H. Hassani...M. Sh. Dahaghin</div><div><b>Pages:&nbsp;</b>9519 - 9531</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08087-y\">An inventory model for partial backlogging items with memory effect</a></div><div><b>Author(s):&nbsp;</b>Rituparna Pakhira, Uttam Ghosh...Vishnu Narayan Mishra</div><div><b>Pages:&nbsp;</b>9533 - 9550</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08089-w\">Design a new cascade controller PD-P-PID optimized by marine predators algorithm for load frequency control</a></div><div><b>Author(s):&nbsp;</b>Abdelkader Halmous, Youcef Oubbati...Salem Arif</div><div><b>Pages:&nbsp;</b>9551 - 9564</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08090-3\">Investigative analysis of different mutation on diversity-driven multi-parent evolutionary algorithm and its application in area coverage optimization of WSN</a></div><div><b>Author(s):&nbsp;</b>Sumika Chauhan, Manmohan Singh, Ashwani Kumar Aggarwal</div><div><b>Pages:&nbsp;</b>9565 - 9591</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08091-2\">Independent tasks scheduling of collaborative computation offloading for SDN-powered MEC on 6G networks</a></div><div><b>Author(s):&nbsp;</b>Ikhlas Al-Hammadi, Mingchu Li, Sardar M. N. Islam</div><div><b>Pages:&nbsp;</b>9593 - 9617</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08092-1\">An enhanced efficient optimization algorithm (EINFO) for accurate extraction of proton exchange membrane fuel cell parameters</a></div><div><b>Author(s):&nbsp;</b>Manish Kumar Singla, Mohamed H. Hassan...Salah Kamel</div><div><b>Pages:&nbsp;</b>9619 - 9638</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08130-y\">Models and algorithms for U-shaped assembly line balancing problem with collaborative robots</a></div><div><b>Author(s):&nbsp;</b>Zixiang Li, Mukund Janardhanan...Zikai Zhang</div><div><b>Pages:&nbsp;</b>9639 - 9659</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08192-y\">A deep hybrid transfer learning-based evolutionary algorithm and its application in the optimization of high-order problems</a></div><div><b>Author(s):&nbsp;</b>Ting-Ting Zhang, Guo-Sheng Hao...Xia Wang</div><div><b>Pages:&nbsp;</b>9661 - 9672</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08201-0\">Effective hybridization of JAYA and teaching\u2013learning-based optimization algorithms for numerical function optimization</a></div><div><b>Author(s):&nbsp;</b>Jafar Gholami, Fariba Abbasi Nia...Hossam M. Zawbaa</div><div><b>Pages:&nbsp;</b>9673 - 9691</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07803-4\">Developing and extending usability heuristics evaluation for user interface design via AHP</a></div><div><b>Author(s):&nbsp;</b>Mohamed Benaida</div><div><b>Pages:&nbsp;</b>9693 - 9707</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07806-1\">An interval-valued green production inventory model under controllable carbon emissions and green subsidy via particle swarm optimization</a></div><div><b>Author(s):&nbsp;</b>Subhendu Ruidas, Mijanur Rahaman Seikh...Ming-Lang Tseng</div><div><b>Pages:&nbsp;</b>9709 - 9733</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-022-07810-5\">Modified and hybridised bi-objective firefly algorithms for university course scheduling</a></div><div><b>Author(s):&nbsp;</b>Thatchai Thepphakorn, Pupong Pongcharoen</div><div><b>Pages:&nbsp;</b>9735 - 9772</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07811-y\">Apple leaf disease identification via improved CycleGAN and convolutional neural network</a></div><div><b>Author(s):&nbsp;</b>Yiping Chen, Jinchao Pan, Qiufeng Wu</div><div><b>Pages:&nbsp;</b>9773 - 9786</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07820-x\">Discriminative appearance model with template spatial adjustment for visual object tracking</a></div><div><b>Author(s):&nbsp;</b>Purandhar Reddy Vadamala, Annis Fathima Aklak</div><div><b>Pages:&nbsp;</b>9787 - 9800</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-07822-9\">Evapotranspiration estimation using hybrid and intelligent methods</a></div><div><b>Author(s):&nbsp;</b>Amin Amirashayeri, Javad Behmanesh...Nasrin Fathollahzadeh Attar</div><div><b>Pages:&nbsp;</b>9801 - 9821</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08078-z\">An approach for joint optimization of probabilistic group test based on cost and time value: taking nucleic acid detection of COVID-19 as an example</a></div><div><b>Author(s):&nbsp;</b>Qianli Ma, Zihui Gao...Baiyu Ma</div><div><b>Pages:&nbsp;</b>9823 - 9833</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08476-3\">PSO-based optimization for EEG data and SVM for efficient deceit identification</a></div><div><b>Author(s):&nbsp;</b>Vijayasree Boddu, Prakash Kodali</div><div><b>Pages:&nbsp;</b>9835 - 9843</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08498-x\">Lung cancer CT image classification using hybrid-SVM transfer learning approach</a></div><div><b>Author(s):&nbsp;</b>Surekha Nigudgi, Channappa Bhyri</div><div><b>Pages:&nbsp;</b>9845 - 9859</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08437-w\">Transparency in healthcare and e-commerce: detecting online fake reviews using a dense neural network model with relevance mapping</a></div><div><b>Author(s):&nbsp;</b>N. Deshai, B. Bhaskara Rao</div><div><b>Pages:&nbsp;</b>9861 - 9875</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08404-5\">A novel multi-layer multi-spiking neural network for EEG signal classification using Mini Batch SGD</a></div><div><b>Author(s):&nbsp;</b>M. Ramesh, Swetha Revoori...K. V. D. Kiran</div><div><b>Pages:&nbsp;</b>9877 - 9890</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08282-x\">An approach for disease prediction and classification using novel weighting method and multichannel shared functional behaviour</a></div><div><b>Author(s):&nbsp;</b>D. Saidulu, R. Sasikala</div><div><b>Pages:&nbsp;</b>9891 - 9906</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08393-5\">A novel diversity-based ensemble approach with genetic algorithm for effective disease diagnosis</a></div><div><b>Author(s):&nbsp;</b>Srinivas Arukonda, Ramalingaswamy Cheruku</div><div><b>Pages:&nbsp;</b>9907 - 9926</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08343-1\">Computer-aided detection and classification of brain tumor using YOLOv3 and deep learning</a></div><div><b>Author(s):&nbsp;</b>Maibam Mangalleibi Chanu, Ngangbam Herojit Singh...Khelchandra Thongam</div><div><b>Pages:&nbsp;</b>9927 - 9940</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08330-6\">Securing health care data through blockchain enabled collaborative machine learning</a></div><div><b>Author(s):&nbsp;</b>C. U. Om Kumar, Sudhakaran Gajendran...S. Sai Balakrishnan</div><div><b>Pages:&nbsp;</b>9941 - 9954</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08190-0\">Network learning path of university political education based on simulation data and sparse neural network</a></div><div><b>Author(s):&nbsp;</b>Kaixuan Shao</div><div><b>Pages:&nbsp;</b>9955 - 9965</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08191-z\">Linguistic multidimensional perspective data simulation based on speech recognition technology and big data</a></div><div><b>Author(s):&nbsp;</b>Shi Honggai, Yang Qian</div><div><b>Pages:&nbsp;</b>9967 - 9976</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08198-6\">Design of interactive enterprise financial system based on Multi-user scheduling and cellular network</a></div><div><b>Author(s):&nbsp;</b>Qingping Li, Guoqiang Wu</div><div><b>Pages:&nbsp;</b>9977 - 9988</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08197-7\">Semantic web-based collaborative design system in cloud computing environment</a></div><div><b>Author(s):&nbsp;</b>Jing Di</div><div><b>Pages:&nbsp;</b>9989 - 10000</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08196-8\">Visualization system of Hlai ethnic village landscape design based on machine learning</a></div><div><b>Author(s):&nbsp;</b>Jun Liu, Xiaoli Wu...Li Wang</div><div><b>Pages:&nbsp;</b>10001 - 10011</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08206-9\">Unsupervised machine learning and image recognition model application in English part-of-speech feature learning under the open platform environment</a></div><div><b>Author(s):&nbsp;</b>Liu Yang</div><div><b>Pages:&nbsp;</b>10013 - 10023</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08208-7\">Data simulation of optimal model for numerical solution of differential equations based on deep learning and genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Li Jing</div><div><b>Pages:&nbsp;</b>10025 - 10032</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08207-8\">Simulation of China\u2019s urban tourism activity based on improved density clustering algorithm</a></div><div><b>Author(s):&nbsp;</b>Xinyan Huang</div><div><b>Pages:&nbsp;</b>10033 - 10044</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08211-y\">Application of data mining in female sports behavior prediction based on FCM algorithm</a></div><div><b>Author(s):&nbsp;</b>Liyun Yuan, Jiaxing Cao</div><div><b>Pages:&nbsp;</b>10045 - 10055</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08213-w\">Personalized information push system for education management based on big data mode and collaborative filtering algorithm</a></div><div><b>Author(s):&nbsp;</b>Zefeng Zhu, Yongle Sun</div><div><b>Pages:&nbsp;</b>10057 - 10067</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08215-8\">Application of adaptive moving object detection and edge calculation in police physical education training app course</a></div><div><b>Author(s):&nbsp;</b>Lifang Zhen</div><div><b>Pages:&nbsp;</b>10069 - 10079</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08214-9\">Application of embedded voice and digital forensics system in financial cost management</a></div><div><b>Author(s):&nbsp;</b>Yang Lin</div><div><b>Pages:&nbsp;</b>10081 - 10092</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08217-6\">Medical intelligent system application in schizophrenia treatment satisfaction based on neural networks</a></div><div><b>Author(s):&nbsp;</b>Xiajin Ren, Xin Wang</div><div><b>Pages:&nbsp;</b>10093 - 10105</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08239-0\">Cost optimization in the construction of prefabricated buildings by using BIM and finite element simulation</a></div><div><b>Author(s):&nbsp;</b>YaFeng Zou, WenHui Feng</div><div><b>Pages:&nbsp;</b>10107 - 10119</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08256-z\">Application of real-time data processing system of Internet of Things based on blockchain technology in the financial field of Yangtze River Delta urban agglomeration</a></div><div><b>Author(s):&nbsp;</b>Xuanshu Fei</div><div><b>Pages:&nbsp;</b>10121 - 10131</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08240-7\">Image recognition of sports dance teaching and auxiliary function data verification based on neural network algorithm</a></div><div><b>Author(s):&nbsp;</b>Yuchuan Lin</div><div><b>Pages:&nbsp;</b>10133 - 10143</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08242-5\">Intelligent system simulation and data accuracy of physical fitness training for sports majors based on real-time status update of wearable Internet of Things</a></div><div><b>Author(s):&nbsp;</b>Zhou Yong</div><div><b>Pages:&nbsp;</b>10145 - 10154</div><div><br /></div><div><b>58)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08241-6\">Data analysis accuracy of urban and rural economic forecast based on neural network algorithm</a></div><div><b>Author(s):&nbsp;</b>Yan Zhang, Pan Yanjie, Lv Zepeng</div><div><b>Pages:&nbsp;</b>10155 - 10165</div><div><br /></div><div><b>59)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08246-1\">Simulation of computer image recognition technology based on image feature extraction</a></div><div><b>Author(s):&nbsp;</b>Weiqiang Ying, Lingyan Zhang...Fangtian Ying</div><div><b>Pages:&nbsp;</b>10167 - 10176</div><div><br /></div><div><b>60)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08249-y\">Application of artificial intelligence wearable devices based on neural network algorithm in mass sports activity evaluation</a></div><div><b>Author(s):&nbsp;</b>Jun Liang, Qing He</div><div><b>Pages:&nbsp;</b>10177 - 10188</div><div><br /></div><div><b>61)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08247-0\">Research on reliability of sports intelligent training system based on hybrid wolf pack algorithm and IoT</a></div><div><b>Author(s):&nbsp;</b>Wenfeng Chen, Xinyan Huang</div><div><b>Pages:&nbsp;</b>10189 - 10197</div><div><br /></div><div><b>62)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08267-w\">Application of human\u2013computer interaction system based on machine learning algorithm in artistic visual communication</a></div><div><b>Author(s):&nbsp;</b>Zexian Nie, Ying Yu, Yong Bao</div><div><b>Pages:&nbsp;</b>10199 - 10211</div><div><br /></div><div><b>63)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08268-9\">Popularization of science in colleges and universities in the new network media environment based on artificial intelligence</a></div><div><b>Author(s):&nbsp;</b>Lin Sheng</div><div><b>Pages:&nbsp;</b>10213 - 10223</div><div><br /></div><div><b>64)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08266-x\">Visualization of green building landscape space environment design based on image processing and artificial intelligence algorithm</a></div><div><b>Author(s):&nbsp;</b>Jianbo Zhou</div><div><b>Pages:&nbsp;</b>10225 - 10235</div><div><br /></div><div><b>65)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08277-8\">Development of speech recognition system for remote vocal music teaching based on Markov model</a></div><div><b>Author(s):&nbsp;</b>Fumei Xu, Yu Xia</div><div><b>Pages:&nbsp;</b>10237 - 10248</div><div><br /></div><div><b>66)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08278-7\">Evaluation model of cultural heritage tourist attractions based on network virtual resource sharing and real-time information processing</a></div><div><b>Author(s):&nbsp;</b>Ai Rong, Song Jianwei</div><div><b>Pages:&nbsp;</b>10249 - 10261</div><div><br /></div><div><b>67)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08288-5\">Campus IoT system and students\u2019 employment education innovation based on mobile edge computing</a></div><div><b>Author(s):&nbsp;</b>Tian Xie</div><div><b>Pages:&nbsp;</b>10263 - 10272</div><div><br /></div><div><b>68) </b><a href=\"https://link.springer.com/article/10.1007/s00500-023-08287-6\">An empirical analysis of dynamic network model of international trade by using enterprise sample simulation and improved ANN algorithm</a></div><div><b>Author(s):&nbsp;</b>Ruiqian Liu, Xiaofei Chen</div><div><b>Pages:&nbsp;</b>10273 - 10283</div><div><br /></div><div><b>69)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08309-3\">Internet financial forecasting and digital economy development by using machine learning algorithm in the new consumption environment</a></div><div><b>Author(s):&nbsp;</b>Peng Huang</div><div><b>Pages:&nbsp;</b>10285 - 10296</div><div><br /></div><div><b>70)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08310-w\">Model optimization of English intelligent translation based on outlier detection and machine learning</a></div><div><b>Author(s):&nbsp;</b>Yuzhu Bian, Jiaxin Li, Yuge Zhao</div><div><b>Pages:&nbsp;</b>10297 - 10303</div><div><br /></div><div><b>71) </b><a href=\"https://link.springer.com/article/10.1007/s00500-023-08308-4\">Application of data mining in enterprise financial risk prediction based on genetic algorithm and linear adaptive optimization</a></div><div><b>Author(s):&nbsp;</b>Xu Yi</div><div><b>Pages:&nbsp;</b>10305 - 10315</div><div><br /></div><div><b>72)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08312-8\">Design of 3D animation color rendering system supported by cloud computing based on genetic algorithm</a></div><div><b>Author(s):&nbsp;</b>Yan Ling</div><div><b>Pages:&nbsp;</b>10317 - 10326</div><div><br /></div><div><b>73)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08307-5\">Sensor-based environmental impact of soil erosion in rural areas and rural revitalization in Gansu</a></div><div><b>Author(s):&nbsp;</b>Ruxia Shi, Yingli Yang...Guozhen Du</div><div><b>Pages:&nbsp;</b>10327 - 10336</div><div><br /></div><div><b>74)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08306-6\">Design of NoSQL database in oral English teaching based on 5G network and AI recognition</a></div><div><b>Author(s):&nbsp;</b>Liu Liu</div><div><b>Pages:&nbsp;</b>10337 - 10345</div><div><br /></div><div><b>75)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08304-8\">Real-time processing system and Internet of Things application in the cultural tourism industry development</a></div><div><b>Author(s):&nbsp;</b>Yingli Kong</div><div><b>Pages:&nbsp;</b>10347 - 10357</div><div><br /></div><div><b>76)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08305-7\">Influencing factors of stock returns based on Fama\u2013French model and intelligent algorithm</a></div><div><b>Author(s):&nbsp;</b>Xunyuan Rui</div><div><b>Pages:&nbsp;</b>10359 - 10368</div><div><br /></div><div><b>77)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08302-w\">Research on building material design in circular economy based on improved neural network</a></div><div><b>Author(s):&nbsp;</b>Teng Yi</div><div><b>Pages:&nbsp;</b>10369 - 10378</div><div><br /></div><div><b>78)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08303-9\">Performance evaluation of political teaching MOOC system based on task scheduling and AI system</a></div><div><b>Author(s):&nbsp;</b>Wanru Cui</div><div><b>Pages:&nbsp;</b>10379 - 10388</div><div><br /></div><div><b>79)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08344-0\">VR system application in the inheritance of intangible cultural heritage gongs and drums based on video simulation</a></div><div><b>Author(s):&nbsp;</b>Nan Chen</div><div><b>Pages:&nbsp;</b>10389 - 10399</div><div><br /></div><div><b>80)</b> <a href=\"https://link.springer.com/article/10.1007/s00500-023-08346-y\">Design of computer interactive teaching system by using feature extraction algorithm and multimedia technology</a></div><div><b>Author(s):&nbsp;</b>Zhang Dong, Zhu Qi</div><div><b>Pages:&nbsp;</b>10401 - 10409</div><div><br /></div>",
            "pubdate": "2023-06-14T12:00:00.261+12:00",
            "pubdate_parsed": [
                2023,
                6,
                14
            ],
            "email_sent": true
        },
        "Complex & Intelligent Systems, Volume 9, Issue 3, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/complex-intelligent-systems-volume-9.html",
            "description": "<div style=\"text-align: left;\"><b>1)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00192-x\">A hybrid deep learning-based fruit classification using attention model and convolution autoencoder</a></div><div><b>Author(s): </b>Gang Xue, Shifeng Liu, Yicao Ma</div><div><b>Pages: </b>2209 - 2219</div><div><br /></div><div><b>2)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00202-y\">Applying catastrophe progression method to evaluate the service quality of cold chain logistics</a></div><div><b>Author(s):&nbsp;</b>Hao Zhang, Yuxin Shi, Bin Qiu</div><div><b>Pages:&nbsp;</b>2221 - 2235</div><div><br /></div><div><b>3)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00260-2\">Solving the location problem of front distribution center for omni-channel retailing</a></div><div><b>Author(s):&nbsp;</b>Jikai Huang, Xianliang Shi</div><div><b>Pages:&nbsp;</b>2237 - 2248</div><div><br /></div><div><b>4)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00290-4\">Optimization-driven distribution of relief materials in emergency disasters</a></div><div><b>Author(s):&nbsp;</b>Yan Yan, Xinyue Di, Yuanyuan Zhang</div><div><b>Pages:&nbsp;</b>2249 - 2256</div><div><br /></div><div><b>5)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00298-w\">Evaluate the priority of product design factors in the process of complex product innovation</a></div><div><b>Author(s):&nbsp;</b>Yinyun Yu, Congdong Li</div><div><b>Pages:&nbsp;</b>2257 - 2270</div><div><br /></div><div><b>6)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00293-1\">Data-driven optimization for last-mile delivery</a></div><div><b>Author(s):&nbsp;</b>Hongrui Chu, Wensi Zhang...Yahong Chen</div><div><b>Pages:&nbsp;</b>2271 - 2284</div><div><br /></div><div><b>7)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00289-x\">Forecasting emergency medicine reserve demand with a novel decomposition-ensemble methodology</a></div><div><b>Author(s):&nbsp;</b>Li Jiang-ning, Shi Xian-liang...Li Dong</div><div><b>Pages:&nbsp;</b>2285 - 2295</div><div><br /></div><div><b>8)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00297-x\">Regional logistics demand forecasting: a BP neural network approach</a></div><div><b>Author(s):&nbsp;</b>Lijuan Huang, Guojie Xie...Yi Huang</div><div><b>Pages:&nbsp;</b>2297 - 2312</div><div><br /></div><div><b>9)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00306-z\">Product-harm crisis intelligent warning system design based on fine-grained sentiment analysis of automobile complaints</a></div><div><b>Author(s):&nbsp;</b>Haiju Hu, Yonghui Wei, Yu Zhou</div><div><b>Pages:&nbsp;</b>2313 - 2320</div><div><br /></div><div><b>10)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00303-2\">System dynamics mechanism of cross-regional collaborative dispatch of emergency supplies based on multi-agent game</a></div><div><b>Author(s):&nbsp;</b>Ying Qiu, Meng Shi...Yongping Jing</div><div><b>Pages:&nbsp;</b>2321 - 2332</div><div><br /></div><div><b>11)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00284-2\">A modified NK algorithm based on BP neural network and DEMATEL for evolution path optimization of urban innovation ecosystem</a></div><div><b>Author(s):&nbsp;</b>Ruijian Liu, Fangcheng Tang...Shaofang Zheng</div><div><b>Pages:&nbsp;</b>2333 - 2349</div><div><br /></div><div><b>12)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00320-1\">Integration of manufacturing and pricing for downward substitution products decision-making</a></div><div><b>Author(s):&nbsp;</b>Hua He</div><div><b>Pages:&nbsp;</b>2351 - 2359</div><div><br /></div><div><b>13)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00317-w\">Private-label sustainable supplier selection using a fuzzy entropy-VIKOR-based approach</a></div><div><b>Author(s):&nbsp;</b>Jun Zhang, Linze Li...Guojiao Chen</div><div><b>Pages:&nbsp;</b>2361 - 2378</div><div><br /></div><div><b>14)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00304-1\">Express delivery logistics with high-speed railway: a perspective of payment scheme and forecast information sharing</a></div><div><b>Author(s):&nbsp;</b>Huawei Duan, Yusen Ye...Mengting Wang</div><div><b>Pages:&nbsp;</b>2379 - 2391</div><div><br /></div><div><b>15)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00329-6\">Production decision-making system for manufacturing enterprises constrained by carbon reduction policies</a></div><div><b>Author(s):&nbsp;</b>Ma Changsong, Yuan Tiantong...Liu Wei</div><div><b>Pages:&nbsp;</b>2393 - 2411</div><div><br /></div><div><b>16)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00331-y\">Subsidy strategy of sharing logistics platform</a></div><div><b>Author(s):&nbsp;</b>Yingzhen Cai, Lan Bai...Shi Yin</div><div><b>Pages:&nbsp;</b>2413 - 2428</div><div><br /></div><div><b>17)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00361-6\">Optimal coordination and service level of the supply chain in the sharing economy: the perspective of social responsibility</a></div><div><b>Author(s):&nbsp;</b>Jie Guo, Yanli Guo</div><div><b>Pages:&nbsp;</b>2429 - 2445</div><div><br /></div><div><b>18)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00375-0\">O2O selection mode portrait and optimization for railway service enterprises based on K-means</a></div><div><b>Author(s):&nbsp;</b>Changsuo Sun, Long Ye, Na Zhang</div><div><b>Pages:&nbsp;</b>2447 - 2458</div><div><br /></div><div><b>19)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00388-9\">Knowledge organization of node enterprises\u2019 technological innovation under supply chain environment</a></div><div><b>Author(s):&nbsp;</b>Qianqian Zhang, Shifeng Liu, Qun Tu</div><div><b>Pages:&nbsp;</b>2459 - 2473</div><div><br /></div><div><b>20)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00403-z\">A branch-and-price algorithm for two-echelon electric vehicle routing problem</a></div><div><b>Author(s):&nbsp;</b>Zhiguo Wu, Juliang Zhang</div><div><b>Pages:&nbsp;</b>2475 - 2490</div><div><br /></div><div><b>21)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00401-1\">A hybrid ant colony algorithm based on multiple strategies for the vehicle routing problem with time windows</a></div><div><b>Author(s):&nbsp;</b>Hongguang Wu, Yuelin Gao...Ziyu Zhang</div><div><b>Pages:&nbsp;</b>2491 - 2508</div><div><br /></div><div><b>22)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00385-y\">Quantity decisions of two-stage competitive location model based on different location modes</a></div><div><b>Author(s):&nbsp;</b>Yadong Li, Xuemei Li</div><div><b>Pages:&nbsp;</b>2509 - 2520</div><div><br /></div><div><b>23)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00414-w\">Charging station planning based on the accumulation prospect theory and dynamic user equilibrium</a></div><div><b>Author(s):&nbsp;</b>Qiu Heting, Dou Shuihai...Zhang Jun</div><div><b>Pages:&nbsp;</b>2521 - 2539</div><div><br /></div><div><b>24)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00462-2\">Big data-driven public transportation network: a simulation approach</a></div><div><b>Author(s):&nbsp;</b>Zhaohua Wang, Xuewei Li...Fei Wang</div><div><b>Pages:&nbsp;</b>2541 - 2553</div><div><br /></div><div><b>25)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00188-7\">CEEMDAN-IMFx-PCA-CICA: an improved single-channel blind source separation in multimedia environment for motion artifact reduction in ambulatory ECG</a></div><div><b>Author(s):&nbsp;</b>Fan Xiong, Dongyi Chen</div><div><b>Pages:&nbsp;</b>2555 - 2569</div><div><br /></div><div><b>26)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00223-7\">Voice of urban park visitors: exploring destination attributes influencing behavioural intentions through online review mining</a></div><div><b>Author(s):&nbsp;</b>Ke Ma, Beibei Jiang</div><div><b>Pages:&nbsp;</b>2571 - 2583</div><div><br /></div><div><b>27)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00431-9\">General type industrial temperature system control based on fuzzy fractional-order PID controller</a></div><div><b>Author(s):&nbsp;</b>Lu Liu, Dingyu Xue, Shuo Zhang</div><div><b>Pages:&nbsp;</b>2585 - 2597</div><div><br /></div><div><b>28)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00612-6\">Angle of attack prediction using recurrent neural networks in flight conditions with faulty sensors in the case of F-16 fighter jet</a></div><div><b>Author(s):&nbsp;</b>Bemnet Wondimagegnehu Mersha, David N. Jansen, Hongbin Ma</div><div><b>Pages:&nbsp;</b>2599 - 2611</div><div><br /></div><div><b>29)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00207-7\">Intelligent IoT-based large-scale inverse planning system considering postmodulation factors</a></div><div><b>Author(s):&nbsp;</b>Yihua Lan, Fang Li...Yin Zhang</div><div><b>Pages:&nbsp;</b>2613 - 2627</div><div><br /></div><div><b>30)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00231-7\">Secure-user sign-in authentication for IoT-based eHealth systems</a></div><div><b>Author(s):&nbsp;</b>B. D. Deebak, Fadi Al-Turjman</div><div><b>Pages:&nbsp;</b>2629 - 2649</div><div><br /></div><div><b>31)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00318-9\">Diabetic retinopathy detection and classification using capsule networks</a></div><div><b>Author(s):&nbsp;</b>G. Kalyani, B. Janakiramaiah...L. V. Narasimha Prasad</div><div><b>Pages:&nbsp;</b>2651 - 2664</div><div><br /></div><div><b>32)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-020-00244-2\">Human gait analysis for osteoarthritis prediction: a framework of deep learning and kernel extreme learning machine</a></div><div><b>Author(s):&nbsp;</b>Muhammad Attique Khan, Seifedine Kadry...Syed Rameez Naqvi</div><div><b>Pages:&nbsp;</b>2665 - 2683</div><div><br /></div><div><b>33)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00371-4\">O-WCNN: an optimized integration of spatial and spectral feature map for arrhythmia classification</a></div><div><b>Author(s):&nbsp;</b>Manisha Jangra, Sanjeev Kumar Dhull...Xiaochun Cheng</div><div><b>Pages:&nbsp;</b>2685 - 2698</div><div><br /></div><div><b>34)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00391-0\">Security for eHealth system: data hiding in AMBTC compressed images via gradient-based coding</a></div><div><b>Author(s):&nbsp;</b>Yung-Yao Chen, Yu-Chen Hu...Yu-Hsiu Lin</div><div><b>Pages:&nbsp;</b>2699 - 2711</div><div><br /></div><div><b>35)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00405-x\">A review on Deep Learning approaches for low-dose Computed Tomography restoration</a></div><div><b>Author(s):&nbsp;</b>K. A. Saneera Hemantha Kulathilake, Nor Aniza Abdullah...Khin Wee Lai</div><div><b>Pages:&nbsp;</b>2713 - 2745</div><div><br /></div><div><b>36)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00427-5\">ST-V-Net: incorporating shape prior into convolutional neural networks for proximal femur segmentation</a></div><div><b>Author(s):&nbsp;</b>Chen Zhao, Joyce H. Keyak...Weihua Zhou</div><div><b>Pages:&nbsp;</b>2747 - 2758</div><div><br /></div><div><b>37)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00309-w\">Data hiding in encryption\u2013compression domain</a></div><div><b>Author(s):&nbsp;</b>O. P. Singh, A. K. Singh</div><div><b>Pages:&nbsp;</b>2759 - 2772</div><div><br /></div><div><b>38)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00342-9\">Social media intention mining for sustainable information systems: categories, taxonomy, datasets and challenges</a></div><div><b>Author(s):&nbsp;</b>Ayesha Rashid, Muhammad Shoaib Farooq...Yousaf Bin Zikria</div><div><b>Pages:&nbsp;</b>2773 - 2799</div><div><br /></div><div><b>39)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00440-8\">POI recommendation method using LSTM-attention in LBSN considering privacy protection</a></div><div><b>Author(s):&nbsp;</b>Kun Wang, Xiaofeng Wang, Xuan Lu</div><div><b>Pages:&nbsp;</b>2801 - 2812</div><div><br /></div><div><b>40)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00487-7\">Hatred and trolling detection transliteration framework using hierarchical LSTM in code-mixed social media text</a></div><div><b>Author(s):&nbsp;</b>Shashi Shekhar, Hitendra Garg...Bhisham Sharma</div><div><b>Pages:&nbsp;</b>2813 - 2826</div><div><br /></div><div><b>41)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00561-0\">Hate speech operationalization: a preliminary examination of hate speech indicators and their structure</a></div><div><b>Author(s):&nbsp;</b>Jana Papcunov\u00e1, Marcel Marton\u010dik...Mat\u00fa\u0161 Adamkovi\u010d</div><div><b>Pages:&nbsp;</b>2827 - 2842</div><div><br /></div><div><b>42)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00552-1\">IFND: a benchmark dataset for fake news detection</a></div><div><b>Author(s):&nbsp;</b>Dilip Kumar Sharma, Sonal Garg</div><div><b>Pages:&nbsp;</b>2843 - 2863</div><div><br /></div><div><b>43)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00617-1\">TVS: a trusted verification scheme for office documents based on blockchain</a></div><div><b>Author(s):&nbsp;</b>Xue Zhai, Shanchen Pang...Zhihan Lv</div><div><b>Pages:&nbsp;</b>2865 - 2877</div><div><br /></div><div><b>44)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00672-2\">Combating the infodemic: COVID-19 induced fake news recognition in social media networks</a></div><div><b>Author(s):&nbsp;</b>Shankar Biradar, Sunil Saumya, Arun Chauhan</div><div><b>Pages:&nbsp;</b>2879 - 2891</div><div><br /></div><div><b>45)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00693-x\">Evaluating feature combination strategies for hate-speech detection in Spanish using linguistic features and transformers</a></div><div><b>Author(s):&nbsp;</b>Jos\u00e9 Antonio Garc\u00eda-D\u00edaz, Salud Mar\u00eda Jim\u00e9nez-Zafra...Rafael Valencia-Garc\u00eda</div><div><b>Pages:&nbsp;</b>2893 - 2914</div><div><br /></div><div><b>46)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00305-0\">Three factor authentication system with modified ECC based secured data transfer: untrusted cloud environment</a></div><div><b>Author(s):&nbsp;</b>Dilip Venkata Kumar Vengala, D. Kavitha...A. P. Siva Kumar</div><div><b>Pages:&nbsp;</b>2915 - 2928</div><div><br /></div><div><b>47)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00357-2\">A genre trust model for defending shilling attacks in recommender systems</a></div><div><b>Author(s):&nbsp;</b>Li Yang, Xinxin Niu</div><div><b>Pages:&nbsp;</b>2929 - 2942</div><div><br /></div><div><b>48)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00505-8\">Code-based encryption techniques with distributed cluster head and energy consumption routing protocol</a></div><div><b>Author(s):&nbsp;</b>M. Jalasri, L. Lakshmanan</div><div><b>Pages:&nbsp;</b>2943 - 2955</div><div><br /></div><div><b>49)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00511-w\">RETRACTED ARTICLE: Optimized intelligent data management framework for a cyber-physical system for computational applications</a></div><div><b>Author(s):&nbsp;</b>Abdulmajeed Alsufyani, Youseef Alotaibi...Nawal Alsufyani</div><div><b>Pages:&nbsp;</b>2957 - 2957</div><div><br /></div><div><b>50)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00556-x\">Low-power AES S-box design using dual-basis tower field extension method for cyber security applications</a></div><div><b>Author(s):&nbsp;</b>V. Nandan, R. Gowri Shankar Rao</div><div><b>Pages:&nbsp;</b>2959 - 2967</div><div><br /></div><div><b>51)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00557-w\">Hybrid design for sports data visualization using AI and big data analytics</a></div><div><b>Author(s):&nbsp;</b>Aijun Liu, Rajendra Prasad Mahapatra, A. V. R. Mayuri</div><div><b>Pages:&nbsp;</b>2969 - 2980</div><div><br /></div><div><b>52)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00562-z\">A novel lightweight authentication and privacy-preserving protocol for vehicular ad hoc networks</a></div><div><b>Author(s):&nbsp;</b>Shaji K. A. Theodore, K. Rajiv Gandhi, V. Palanisamy</div><div><b>Pages:&nbsp;</b>2981 - 2991</div><div><br /></div><div><b>53)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00559-8\">Establishment of the model on the expression and guidance of contemporary college students\u2019 demands in the cyberspace environment</a></div><div><b>Author(s):&nbsp;</b>Zhichao Cheng, Xinyang Liu</div><div><b>Pages:&nbsp;</b>2993 - 3010</div><div><br /></div><div><b>54)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00641-9\">Deep learning model construction for a semi-supervised classification with feature learning</a></div><div><b>Author(s):&nbsp;</b>Sridhar Mandapati, Seifedine Kadry...Orawit Thinnukool</div><div><b>Pages:&nbsp;</b>3011 - 3021</div><div><br /></div><div><b>55)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-021-00610-8\">PRISED tangle: a privacy-aware framework for smart healthcare data sharing using IOTA tangle</a></div><div><b>Author(s):&nbsp;</b>Sidrah Abdullah, Junaid Arshad...Khaled Salah</div><div><b>Pages:&nbsp;</b>3023 - 3041</div><div><br /></div><div><b>56)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00760-3\">Cloud-based email phishing attack using machine and deep learning algorithm</a></div><div><b>Author(s):&nbsp;</b>Umer Ahmed Butt, Rashid Amin...Ali Ahmadian</div><div><b>Pages:&nbsp;</b>3043 - 3070</div><div><br /></div><div><b>57)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00904-5\">Microblog sentiment analysis based on deep memory network with structural attention</a></div><div><b>Author(s):&nbsp;</b>Lixin Zhou, Zhenyu Zhang...Pingle Yang</div><div><b>Pages:&nbsp;</b>3071 - 3083</div><div><br /></div><div><b>58)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00907-2\">A node selection algorithm with a genetic method based on PBFT in consortium blockchains</a></div><div><b>Author(s):&nbsp;</b>Jinyu Zhang, Yumeng Yang...Yue Wang</div><div><b>Pages:&nbsp;</b>3085 - 3105</div><div><br /></div><div><b>59)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00912-5\">Truncated variable algorithm using DUS-neutrosophic Weibull distribution</a></div><div><b>Author(s):&nbsp;</b>Muhammad Aslam</div><div><b>Pages:&nbsp;</b>3107 - 3114</div><div><br /></div><div><b>60)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00890-8\">Intelligent power management based on multi-objective cost function for plug-in biogas hybrid vehicles under uncertain driving conditions</a></div><div><b>Author(s):&nbsp;</b>Sameh Abd-Elhaleem, Walaa Shoeib, Abdel Azim Sobaih</div><div><b>Pages:&nbsp;</b>3115 - 3130</div><div><br /></div><div><b>61)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00893-5\">GAN-based deep learning framework of network reconstruction</a></div><div><b>Author(s):&nbsp;</b>Xiang Xu, Xianqiang Zhu, Cheng Zhu</div><div><b>Pages:&nbsp;</b>3131 - 3146</div><div><br /></div><div><b>62)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00914-3\">Two-stream temporal enhanced Fisher vector encoding for skeleton-based action recognition</a></div><div><b>Author(s):&nbsp;</b>Jun Tang, Baodi Liu...Yanjiang Wang</div><div><b>Pages:&nbsp;</b>3147 - 3159</div><div><br /></div><div><b>63)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00911-6\">A novel non-linear neuron model based on multiplicative aggregation in quaternionic domain</a></div><div><b>Author(s):&nbsp;</b>Sushil Kumar, Rishitosh Kumar Singh, Aryan Chaudhary</div><div><b>Pages:&nbsp;</b>3161 - 3183</div><div><br /></div><div><b>64)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00901-8\">Yager aggregation operators based on complex interval-valued q-rung orthopair fuzzy information and their application in decision making</a></div><div><b>Author(s):&nbsp;</b>Xin Dong, Zeeshan Ali...Peide Liu</div><div><b>Pages:&nbsp;</b>3185 - 3210</div><div><br /></div><div><b>65)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00919-y\">Evolutionary convolutional neural network for image classification based on multi-objective genetic programming with leader\u2013follower mechanism</a></div><div><b>Author(s):&nbsp;</b>Qingqing Liu, Xianpeng Wang...Xiangman Song</div><div><b>Pages:&nbsp;</b>3211 - 3228</div><div><br /></div><div><b>66)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00916-1\">Scene text recognition via context modeling for low-quality image in logistics industry</a></div><div><b>Author(s):&nbsp;</b>Herui Heng, Peiji Li...Tianyu Yang</div><div><b>Pages:&nbsp;</b>3229 - 3248</div><div><br /></div><div><b>67)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00920-5\">Dynamic modeling and infinite-dimensional observer-based control for manipulation of flexible beam by a multi-link robot</a></div><div><b>Author(s):&nbsp;</b>Shuyang Liu, Yuanchun Li</div><div><b>Pages:&nbsp;</b>3249 - 3260</div><div><br /></div><div><b>68)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00922-3\">Efficient combination graph model based on conditional random field for online multi-object tracking</a></div><div><b>Author(s):&nbsp;</b>Junwen Zhang, Xiaolong Zhang...Chunhua Deng</div><div><b>Pages:&nbsp;</b>3261 - 3276</div><div><br /></div><div><b>69)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00917-0\">An efficient privacy-preserving point-of-interest recommendation model based on local differential privacy</a></div><div><b>Author(s):&nbsp;</b>Chonghuan Xu, Xinyao Mei...Austin Shijun Ding</div><div><b>Pages:&nbsp;</b>3277 - 3300</div><div><br /></div><div><b>70)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00921-4\">Policy decision of curling in real competition scenes</a></div><div><b>Author(s):&nbsp;</b>Qian Xiao, Zongmin Li...Feimo Li</div><div><b>Pages:&nbsp;</b>3301 - 3312</div><div><br /></div><div><b>71)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00929-w\">Surrogate-assisted evolutionary neural architecture search with network embedding</a></div><div><b>Author(s):&nbsp;</b>Liang Fan, Handing Wang</div><div><b>Pages:&nbsp;</b>3313 - 3331</div><div><br /></div><div><b>72)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00913-4\">The differential measure for Pythagorean fuzzy multiple criteria group decision-making</a></div><div><b>Author(s):&nbsp;</b>Iman Mohamad Sharaf</div><div><b>Pages:&nbsp;</b>3333 - 3354</div><div><br /></div><div><b>73)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00931-2\">Neural network fusion with fine-grained adaptation learning for turnover prediction</a></div><div><b>Author(s):&nbsp;</b>Xia Xue, Xia Sun...Jun Feng</div><div><b>Pages:&nbsp;</b>3355 - 3366</div><div><br /></div><div><b>74)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00933-0\">Two-stage hybrid algorithm for recognition of industrial slab numbers with data quality improvement</a></div><div><b>Author(s):&nbsp;</b>Qingqing Liu, Xianpeng Wang, Xiangman Song</div><div><b>Pages:&nbsp;</b>3367 - 3384</div><div><br /></div><div><b>75)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00934-z\">Adaptive encoding-based evolutionary approach for Chinese document clustering</a></div><div><b>Author(s):&nbsp;</b>Jun-Xian Chen, Yue-Jiao Gong...Xiaolin Xiao</div><div><b>Pages:&nbsp;</b>3385 - 3398</div><div><br /></div><div><b>76)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00926-z\">DCGNN: a single-stage 3D object detection network based on density clustering and graph neural network</a></div><div><b>Author(s):&nbsp;</b>Shimin Xiong, Bin LiShiao Zhu</div><div><b>Pages:&nbsp;</b>3399 - 3408</div><div><br /></div><div><b>77)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-023-01024-4\">An instance-based deep transfer learning method for quality identification of Longjing tea from multiple geographical origins</a></div><div><b>Author(s):&nbsp;</b>Cheng Zhang, Jin Wang...Bincheng Huang</div><div><b>Pages:&nbsp;</b>3409 - 3428</div><div><br /></div><div><b>78)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00899-z\">Threat analysis for space information network based on network security attributes: a review</a></div><div><b>Author(s):&nbsp;</b>Xuesong Wu, Ye Du...Tianshuai Zheng</div><div><b>Pages:&nbsp;</b>3429 - 3468</div><div><br /></div><div><b>79)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00918-z\">Correction to: A metaheuristic-based framework for index tracking with practical constraints</a></div><div><b>Author(s):&nbsp;</b>Man-Chung Yuen, Sin-Chun Ng...Hangjun Che</div><div><b>Pages:&nbsp;</b>3469 - 3469</div><div><br /></div><div><b>80)</b> <a href=\"https://link.springer.com/article/10.1007/s40747-022-00935-y\">Retraction Note: Towards secure deep learning architecture for smart farming-based application</a>s</div><div><b>Author(s):&nbsp;</b>R. Udendhran, M. Balamurugan</div><div><b>Pages:&nbsp;</b>3471 - 3471</div><div><br /></div><div><br /></div>",
            "pubdate": "2023-06-15T12:00:00.254+12:00",
            "pubdate_parsed": [
                2023,
                6,
                15
            ],
            "email_sent": true
        },
        "IEEE Transactions on Cognitive and Developmental Systems, Volume 15, Issue 2, June 2023": {
            "url": "https://computational-intelligence.blogspot.com/2023/06/ieee-transactions-on-cognitive-and.html",
            "description": "<div><b>1)</b> <a href=\"https://ieeexplore.ieee.org/document/10146406/\">Guest Editorial Special Issue on Intrinsically Motivated Open-Ended Learning (IMOL)</a></div><div><b>Author(s): </b>Kathryn Kasmarik, Gianluca Baldassarre, Vieri Giuliano Santucci, Jochen Triesch</div><div><b>Pages: </b>321 - 324</div><div><br /></div><div><b>2)</b> <a href=\"https://ieeexplore.ieee.org/document/9365689/\">Exploration With Intrinsic Motivation Using Object\u2013Action\u2013Outcome Latent Space</a></div><div><b>Author(s):&nbsp;</b>Melisa Idil Sener, Yukie Nagai, Erhan Oztop, Emre Ugur</div><div><b>Pages:&nbsp;</b>325 - 336</div><div><br /></div><div><b>3)</b> <a href=\"https://ieeexplore.ieee.org/document/9274500/\">Intrinsic Plasticity for Online Unsupervised Learning Based on Soft-Reset Spiking Neuron Model</a></div><div><b>Author(s):&nbsp;</b>Anguo Zhang, Yueming Gao, Yuzhen Niu, Xiumin Li, Qing Chen</div><div><b>Pages:&nbsp;</b>337 - 347</div><div><br /></div><div><b>4)</b> <a href=\"https://ieeexplore.ieee.org/document/9524808/\">Learning Abstract Representations Through Lossy Compression of Multimodal Signals</a></div><div><b>Author(s):&nbsp;</b>Charles Wilmot, Gianluca Baldassarre, Jochen Triesch</div><div><b>Pages:&nbsp;</b>348 - 360</div><div><br /></div><div><b>5)</b> <a href=\"https://ieeexplore.ieee.org/document/9284556/\">Goal-Directed Empowerment: Combining Intrinsic Motivation and Task-Oriented Behavior</a></div><div><b>Author(s):&nbsp;</b>Nicola Catenacci Volpi, Daniel Polani</div><div><b>Pages:&nbsp;</b>361 - 372</div><div><br /></div><div><b>6)</b> <a href=\"https://ieeexplore.ieee.org/document/9349770/\">Interest-Driven Exploration With Observational Learning for Developmental Robots</a></div><div><b>Author(s):&nbsp;</b>Rania Rayyes, Heiko Donat, Jochen Steil, Michael Spranger</div><div><b>Pages:&nbsp;</b>373 - 384</div><div><br /></div><div><b>7)</b> <a href=\"https://ieeexplore.ieee.org/document/9388929/\">Combining Social and Intrinsically Motivated Learning for Multitask Robot Skill Acquisition</a></div><div><b>Author(s):&nbsp;</b>Thibaut Kulak, Sylvain Calinon</div><div><b>Pages:&nbsp;</b>385 - 394</div><div><br /></div><div><b>8)</b> <a href=\"https://ieeexplore.ieee.org/document/9360657/\">Efficient Dialog Policy Learning With Hindsight, User Modeling, and Adaptation</a></div><div><b>Author(s):&nbsp;</b>Keting Lu, Yan Cao, Xiaoping Chen, Shiqi Zhang</div><div><b>Pages:&nbsp;</b>395 - 408</div><div><br /></div><div><b>9)</b> 3<a href=\"https://ieeexplore.ieee.org/document/9410594/\">D_DEN: Open-Ended 3-D Object Recognition Using Dynamically Expandable Networks</a></div><div><b>Author(s):&nbsp;</b>Sudhakaran Jain, Hamidreza Kasaei</div><div><b>Pages:&nbsp;</b>409 - 418</div><div><br /></div><div><b>10)</b> <a href=\"https://ieeexplore.ieee.org/document/9514549/\">Goal-Directed Tactile Exploration for Body Model Learning Through Self-Touch on a Humanoid Robot</a></div><div><b>Author(s):&nbsp;</b>Filipe Gama, Maksym Shcherban, Matthias Rolf, Matej Hoffmann</div><div><b>Pages:&nbsp;</b>419 - 433</div><div><br /></div><div><b>11)</b> <a href=\"https://ieeexplore.ieee.org/document/9084147/\">On the Effects of Leader\u2013Follower Roles in Dyadic Human\u2013Robot Synchronization</a></div><div><b>Author(s):&nbsp;</b>Costanza Messeri, Andrea Maria Zanchettin, Paolo Rocco, Elena Gianotti, Alice Chirico, Stefano Magoni, Andrea Gaggioli</div><div><b>Pages:&nbsp;</b>434 - 443</div><div><br /></div><div><b>12)</b> <a href=\"https://ieeexplore.ieee.org/document/9115044/\">Functional Integration and Separation of Brain Network Based on Phase Locking Value During Emotion Processing</a></div><div><b>Author(s):&nbsp;</b>Zhong-Min Wang, Rui Zhou, Yan He, Xiao-Min Guo</div><div><b>Pages:&nbsp;</b>444 - 453</div><div><br /></div><div><b>13)</b> <a href=\"https://ieeexplore.ieee.org/document/9216130/\">A Hybrid BCI Using Singular Value Decomposition Values of the Fast Walsh\u2013Hadamard Transform Coefficients</a></div><div><b>Author(s):&nbsp;</b>Ebru Erg\u00fcn, Onder Aydemir</div><div><b>Pages:&nbsp;</b>454 - 463</div><div><br /></div><div><b>14)</b> <a href=\"https://ieeexplore.ieee.org/document/9311654/\">Intelligent Prediction Method for Updraft of UAV That Is Based on LSTM Network</a></div><div><b>Author(s):&nbsp;</b>Yuxiang Zhang, Ke Li, Ke Li, Jingyi Liu</div><div><b>Pages:&nbsp;</b>464 - 475</div><div><br /></div><div><b>15)</b> <a href=\"https://ieeexplore.ieee.org/document/9320595/\">Deep Binocular Fixation Prediction Using a Hierarchical Multimodal Fusion Network</a></div><div><b>Author(s):&nbsp;</b>Wujie Zhou, Wenyu Liu, Jingsheng Lei, Ting Luo, Lu Yu</div><div><b>Pages:&nbsp;</b>476 - 486</div><div><br /></div><div><b>16)</b> <a href=\"https://ieeexplore.ieee.org/document/9438678/\">Transfer Learning: Rotation Alignment With Riemannian Mean for Brain\u2013Computer Interfaces and Wheelchair Control</a></div><div><b>Author(s):&nbsp;</b>Xianlun Tang, Xingchen Li, Wei Li, Bohui Hao, Ying Xie, Xiaoyuan Dang</div><div><b>Pages:&nbsp;</b>487 - 498</div><div><br /></div><div><b>17)</b> <a href=\"https://ieeexplore.ieee.org/document/9536611/\">The Influence of Robot Traits and Evolutionary Dynamics on the Reality Gap</a></div><div><b>Author(s):&nbsp;</b>Fuda van Diggelen, Eliseo Ferrante, Nihed Harrak, Jie Luo, Daan Zeeuwe, A. E. Eiben</div><div><b>Pages:&nbsp;</b>499 - 506</div><div><br /></div><div><b>18)</b> <a href=\"https://ieeexplore.ieee.org/document/9701596/\">Morpho Evolution With Learning Using a Controller Archive as an Inheritance Mechanism</a></div><div><b>Author(s):&nbsp;</b>L\u00e9ni K. Le Goff, Edgar Buchanan, Emma Hart, Agoston E. Eiben, Wei Li, Matteo De Carlo, Alan F. Winfield, Matthew F. Hale, Robert Woolley, Mike Angus, Jon Timmis, Andy M. Tyrrell</div><div><b>Pages:&nbsp;</b>507 - 517</div><div><br /></div><div><b>19)</b> <a href=\"https://ieeexplore.ieee.org/document/9736973/\">Recurrent-Neural-Network-Based Polynomial Noise Resistance Model for Computing Dynamic Nonlinear Equations Applied to Robotics</a></div><div><b>Author(s):&nbsp;</b>Mei Liu, Jiachang Li, Shuai Li, Nianyin Zeng</div><div><b>Pages:&nbsp;</b>518 - 529</div><div><br /></div><div><b>20)</b> <a href=\"https://ieeexplore.ieee.org/document/9734750/\">Unbiased Spatiotemporal Representation With Uncertainty Control for Person Reidentification</a></div><div><b>Author(s):&nbsp;</b>Xiu Zhang, Bir Bhanu</div><div><b>Pages:&nbsp;</b>530 - 543</div><div><br /></div><div><b>21)</b> <a href=\"https://ieeexplore.ieee.org/document/9737565/\">MultiselfGAN: A Self-Guiding Neural Architecture Search Method for Generative Adversarial Networks With Multicontrollers</a></div><div><b>Author(s):&nbsp;</b>Jiachen Shi, Guoqiang Zhou, Shudi Bao, Jun Shen</div><div><b>Pages:&nbsp;</b>544 - 554</div><div><br /></div><div><b>22)</b> <a href=\"https://ieeexplore.ieee.org/document/9737309/\">Multimodal Urban Sound Tagging With Spatiotemporal Context</a></div><div><b>Author(s):&nbsp;</b>Jisheng Bai, Jianfeng Chen, Mou Wang</div><div><b>Pages:&nbsp;</b>555 - 565</div><div><br /></div><div><b>23)</b> <a href=\"https://ieeexplore.ieee.org/document/9744101/\">Bootstrapping Concept Formation in Small Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Minija Tamosiunaite, Tomas Kulvicius, Florentin W\u00f6rg\u00f6tter</div><div><b>Pages:&nbsp;</b>566 - 580</div><div><br /></div><div><b>24)</b> <a href=\"https://ieeexplore.ieee.org/document/9745055/\">Cognitive Workload Estimation Using Variational Autoencoder and Attention-Based Deep Model</a></div><div><b>Author(s):&nbsp;</b>Debashis Das Chakladar, Sumalyo Datta, Partha Pratim Roy, Vinod A. Prasad</div><div><b>Pages:&nbsp;</b>581 - 590</div><div><br /></div><div><b>25)</b> <a href=\"https://ieeexplore.ieee.org/document/9756656/\">A Multiscale Feature Extraction Network Based on Channel-Spatial Attention for Electromyographic Signal Classification</a></div><div><b>Author(s):&nbsp;</b>Biao Sun, Beida Song, Jiajun Lv, Peiyin Chen, Xinlin Sun, Chao Ma, Zhongke Gao</div><div><b>Pages:&nbsp;</b>591 - 601</div><div><br /></div><div><b>26)</b> <a href=\"https://ieeexplore.ieee.org/document/9766018/\">HMANet: Hyperbolic Manifold Aware Network for Skeleton-Based Action Recognition</a></div><div><b>Author(s):&nbsp;</b>Jinghong Chen, Chong Zhao, Qicong Wang, Hongying Meng</div><div><b>Pages:&nbsp;</b>602 - 614</div><div><br /></div><div><b>27)</b> <a href=\"https://ieeexplore.ieee.org/document/9766405/\">Toward Accurate Camouflaged Object Detection With In-Layer Information Enhancement and Cross-Layer Information Aggregation</a></div><div><b>Author(s):&nbsp;</b>Hongbo Bi, Cong Zhang, Kang Wang, Ranwan Wu</div><div><b>Pages:&nbsp;</b>615 - 624</div><div><br /></div><div><b>28)</b> <a href=\"https://ieeexplore.ieee.org/document/9772625/\">Topological EEG Nonlinear Dynamics Analysis for Emotion Recognition</a></div><div><b>Author(s):&nbsp;</b>Yan Yan, Xuankun Wu, Chengdong Li, Yini He, Zhicheng Zhang, Huihui Li, Ang Li, Lei Wang</div><div><b>Pages:&nbsp;</b>625 - 638</div><div><br /></div><div><b>29)</b> <a href=\"https://ieeexplore.ieee.org/document/9774854/\">Fisher Regularized \u03b5-Dragging for Image Classification</a></div><div><b>Author(s):&nbsp;</b>Zhe Chen, Xiao-Jun Wu, Josef Kittler</div><div><b>Pages:&nbsp;</b>639 - 650</div><div><br /></div><div><b>30) </b><a href=\"https://ieeexplore.ieee.org/document/9785873/\">Automated Video Classification System Driven by Characteristics of Emotional Human Brainwaves Caused by Audiovisual Stimuli</a></div><div><b>Author(s):&nbsp;</b>Dong-Ki Jeong, Hyoung-Gook Kim, Jin Young Kim</div><div><b>Pages:&nbsp;</b>651 - 661</div><div><br /></div><div><b>31)</b> <a href=\"https://ieeexplore.ieee.org/document/9776483/\">Regional Scalp EEGs Analysis and Classification on Typical Childhood Epilepsy Syndromes</a></div><div><b>Author(s):&nbsp;</b>Xiaonan Cui, Jiuwen Cao, Dinghan Hu, Tianlei Wang, Tiejia Jiang, Feng Gao</div><div><b>Pages:&nbsp;</b>662 - 674</div><div><br /></div><div><b>32)</b> <a href=\"https://ieeexplore.ieee.org/document/9775172/\">A Cognitive-Driven Ordinal Preservation for Multimodal Imbalanced Brain Disease Diagnosis</a></div><div><b>Author(s):&nbsp;</b>Qi Zhu, Ting Zhu, Rui Zhang, Haizhou Ye, Kai Sun, Yong Xu, Daoqiang Zhang</div><div><b>Pages:&nbsp;</b>675 - 689</div><div><br /></div><div><b>33)</b> <a href=\"https://ieeexplore.ieee.org/document/9785518/\">HHFS: A Hybrid Hierarchical Feature Selection Method for Ageing Gene Classification</a></div><div><b>Author(s):&nbsp;</b>Dehui Li, Quanwang Wu, Mengchu Zhou, Fengji Luo</div><div><b>Pages:&nbsp;</b>690 - 699</div><div><br /></div><div><b>34)</b> <a href=\"https://ieeexplore.ieee.org/document/9779868/\">Multistep-Ahead Chaotic Time Series Prediction Based on Hierarchical Echo State Network With Augmented Random Features</a></div><div><b>Author(s):&nbsp;</b>Xiaodong Na, Mengyuan Zhang, Weijie Ren, Min Han</div><div><b>Pages:&nbsp;</b>700 - 711</div><div><br /></div><div><b>35)</b> <a href=\"https://ieeexplore.ieee.org/document/9782874/\">A Cognitive Fuzzy Evidential Reasoning Approach for Multiexpert Multicriterion Decision Making</a></div><div><b>Author(s):&nbsp;</b>Zhen Zeng, Lisheng Jiang, Huchang Liao</div><div><b>Pages:&nbsp;</b>712 - 723</div><div><br /></div><div><b>36)</b> <a href=\"https://ieeexplore.ieee.org/document/9780264/\">Neural Encoding and Decoding With a Flow-Based Invertible Generative Model</a></div><div><b>Author(s):&nbsp;</b>Qiongyi Zhou, Changde Du, Dan Li, Haibao Wang, Jian K. Liu, Huiguang He</div><div><b>Pages:&nbsp;</b>724 - 736</div><div><br /></div><div><b>37)</b> <a href=\"https://ieeexplore.ieee.org/document/9801677/\">A Self-Trained Spatial Graph Convolutional Network for Unsupervised Human-Related Anomalous Event Detection in Complex Scenes</a></div><div><b>Author(s):&nbsp;</b>Nanjun Li, Faliang Chang, Chunsheng Liu</div><div><b>Pages:&nbsp;</b>737 - 750</div><div><br /></div><div><b>38)</b> <a href=\"https://ieeexplore.ieee.org/document/9814850/\">Object-Oriented Semantic SLAM Based on Geometric Constraints of Points and Lines</a></div><div><b>Author(s):&nbsp;</b>Teng Ran, Liang Yuan, Jianbo Zhang, Zhizhou Wu, Li He</div><div><b>Pages:&nbsp;</b>751 - 760</div><div><br /></div><div><b>39)</b> <a href=\"https://ieeexplore.ieee.org/document/9790856/\">Visual Image Decoding of Brain Activities Using a Dual Attention Hierarchical Latent Generative Network With Multiscale Feature Fusion</a></div><div><b>Author(s):&nbsp;</b>Jie Luo, Weigang Cui, Jingyu Liu, Yang Li, Yuzhu Guo, Song Xu, Lina Wang</div><div><b>Pages:&nbsp;</b>761 - 773</div><div><br /></div><div><b>40)</b> <a href=\"https://ieeexplore.ieee.org/document/9795907/\">Face Editing Based on Facial Recognition Features</a></div><div><b>Author(s):&nbsp;</b>Xin Ning, Shaohui Xu, Fangzhe Nan, Qingliang Zeng, Chen Wang, Weiwei Cai, Weijun Li, Yizhang Jiang</div><div><b>Pages:&nbsp;</b>774 - 783</div><div><br /></div><div><b>41)</b> <a href=\"https://ieeexplore.ieee.org/document/9802736/\">Motion Projection Consistency-Based 3-D Human Pose Estimation With Virtual Bones From Monocular Videos</a></div><div><b>Author(s):&nbsp;</b>Guangming Wang, Honghao Zeng, Ziliang Wang, Zhe Liu, Hesheng Wang</div><div><b>Pages:&nbsp;</b>784 - 793</div><div><br /></div><div><b>42)</b> <a href=\"https://ieeexplore.ieee.org/document/9794637/\">Four-Criterion-Optimization-Based Coordination Motion Control of Dual-Arm Robots</a></div><div><b>Author(s):&nbsp;</b>Yuchuang Tong, Jinguo Liu, Xin Zhang, Zhaojie Ju</div><div><b>Pages:&nbsp;</b>794 - 807</div><div><br /></div><div><b>43)</b> <a href=\"https://ieeexplore.ieee.org/document/9802723/\">Action Potential Parameters and Spiking Behavior of Cortical Neurons: A Statistical Analysis for Designing Spiking Neural Networks</a></div><div><b>Author(s):&nbsp;</b>Ayan Chakraborty, Sashmita Panda, Saswat Chakrabarti</div><div><b>Pages:&nbsp;</b>808 - 818</div><div><br /></div><div><b>44)</b> <a href=\"https://ieeexplore.ieee.org/document/9810505/\">SURRL: Structural Unsupervised Representations for Robot Learning</a></div><div><b>Author(s):&nbsp;</b>Fengyi Zhang, Yurou Chen, Hong Qiao, Zhiyong Liu</div><div><b>Pages:&nbsp;</b>819 - 831</div><div><br /></div><div><b>45)</b> <a href=\"https://ieeexplore.ieee.org/document/9825723/\">Multimodal Self-Paced Locality-Preserving Learning for Diagnosis of Alzheimer\u2019s Disease</a></div><div><b>Author(s):&nbsp;</b>Xiaoke Hao, Ruxue Wang, Yingchun Guo, Yunjia Xiao, Ming Yu, Meiling Wang, Weibin Chen, Daoqiang Zhang</div><div><b>Pages:&nbsp;</b>832 - 843</div><div><br /></div><div><b>46) </b><a href=\"https://ieeexplore.ieee.org/document/9815091/\">A Novel Biologically Inspired Structural Model for Feature Correspondence</a></div><div><b>Author(s):&nbsp;</b>Yan-Feng Lu, Xu Yang, Yi Li, Qian Yu, Zhi-Yong Liu, Hong Qiao</div><div><b>Pages:&nbsp;</b>844 - 854</div><div><br /></div><div><b>47)</b> <a href=\"https://ieeexplore.ieee.org/document/9810531/\">Bidirectional Gated Edge-Labeling Graph Recurrent Neural Network for Few-Shot Learning</a></div><div><b>Author(s):&nbsp;</b>Qian Wang, Hefei Ling, Baiyan Zhang, Ping Li, Zongyi Li, Yuxuan Shi, Chengxin Zhao, Chuang Zhao</div><div><b>Pages:&nbsp;</b>855 - 864</div><div><br /></div><div><b>48)</b> <a href=\"https://ieeexplore.ieee.org/document/9817452/\">Autonomous Skill Learning of Water Polo Ball Heading for a Robotic Fish: Curriculum and Verification</a></div><div><b>Author(s):&nbsp;</b>Tiandong Zhang, Rui Wang, Shuo Wang, Yu Wang, Long Cheng, Gang Zheng, Min Tan</div><div><b>Pages:&nbsp;</b>865 - 876</div><div><br /></div><div><b>49)</b> <a href=\"https://ieeexplore.ieee.org/document/9833915/\">Incremental Multilayer Broad Learning System With Stochastic Configuration Algorithm for Regression</a></div><div><b>Author(s):&nbsp;</b>Shifei Ding, Chenglong Zhang, Jian Zhang, Lili Guo, Ling Ding</div><div><b>Pages:&nbsp;</b>877 - 886</div><div><br /></div><div><b>50)</b> <a href=\"https://ieeexplore.ieee.org/document/9839324/\">Hierarchical Graph Neural Network Based on Semi-Implicit Variational Inference</a></div><div><b>Author(s):&nbsp;</b>Hai-Long Su, Zhi-Peng Li, Xiao-Bo Zhu, Li-Na Yang, Valeriya Gribova, Vladimir Fedorovich Filaretov, Anthony G. Cohn, De-Shuang Huang</div><div><b>Pages:&nbsp;</b>887 - 895</div><div><br /></div><div><b>51)</b> <a href=\"https://ieeexplore.ieee.org/document/9849837/\">Extending the Omniglot Challenge: Imitating Handwriting Styles on a New Sequential Data Set</a></div><div><b>Author(s):&nbsp;</b>Sarah Fabi, Sebastian Otte, Fedor Scholz, Julius W\u00fchrer, Matthias Karlbauer, Martin V. Butz</div><div><b>Pages:&nbsp;</b>896 - 903</div><div><br /></div><div><b>52)</b> <a href=\"https://ieeexplore.ieee.org/document/9837306/\">Residual Dense Attention Networks for COVID-19 Computed Tomography Images Super Resolution</a></div><div><b>Author(s):&nbsp;</b>Defu Qiu, Yuhu Cheng, Xuesong Wang</div><div><b>Pages:&nbsp;</b>904 - 913</div><div><br /></div><div><b>53)</b> <a href=\"https://ieeexplore.ieee.org/document/9840895/\">Reinforcement Learning for Pass Detection and Generation of Possession Statistics in Soccer</a></div><div><b>Author(s):&nbsp;</b>Saikat Sarkar, Dipti Prasad Mukherjee, Amlan Chakrabarti</div><div><b>Pages:&nbsp;</b>914 - 924</div><div><br /></div><div><b>54)</b> <a href=\"https://ieeexplore.ieee.org/document/9839301/\">An Information Dissemination Model Based on the Rumor and Anti-Rumor and Stimulate-Rumor and Tripartite Cognitive Game</a></div><div><b>Author(s):&nbsp;</b>Qian Li, Tiancheng Xiang, Tianji Dai, Yunpeng Xiao</div><div><b>Pages:&nbsp;</b>925 - 937</div><div><br /></div><div><b>55)</b> <a href=\"https://ieeexplore.ieee.org/document/9840893/\">Lightweight Source-Free Transfer for Privacy-Preserving Motor Imagery Classification</a></div><div><b>Author(s):&nbsp;</b>Wen Zhang, Dongrui Wu</div><div><b>Pages:&nbsp;</b>938 - 949</div><div><br /></div><div><b>56)</b> <a href=\"https://ieeexplore.ieee.org/document/9851405/\">In-Ear SpO2 for Classification of Cognitive Workload</a></div><div><b>Author(s):&nbsp;</b>Harry J. Davies, Ian Williams, Ghena Hammour, Metin Yarici, Michael J. Stacey, Barry M. Seemungal, Danilo P. Mandic</div><div><b>Pages:&nbsp;</b>950 - 958</div><div><br /></div><div><b>57)</b> <a href=\"https://ieeexplore.ieee.org/document/9881593/\">Detection and Estimation of Cognitive Conflict During Physical Human\u2013Robot Collaboration</a></div><div><b>Author(s):&nbsp;</b>Stefano Aldini, Avinash K. Singh, Daniel Leong, Yu-Kai Wang, Marc G. Carmichael, Dikai Liu, Chin-Teng Lin</div><div><b>Pages:&nbsp;</b>959 - 968</div><div><br /></div><div><b>58)</b> <a href=\"https://ieeexplore.ieee.org/document/9878259/\">View-Adaptive Graph Neural Network for Action Recognition</a></div><div><b>Author(s):&nbsp;</b>Ali Raza Shahid, Mehmood Nawaz, Xinqi Fan, Hong Yan</div><div><b>Pages:&nbsp;</b>969 - 978</div><div><br /></div><div><br /></div>",
            "pubdate": "2023-06-16T12:00:00.002+12:00",
            "pubdate_parsed": [
                2023,
                6,
                16
            ],
            "email_sent": true
        }
    },
    "TopBots Blog": {
        "Amazon Releases 51-Language Dataset for Language Understanding": {
            "url": "https://www.topbots.com/amazon-massive-dataset/",
            "description": "<p>MASSIVE dataset and Massively Multilingual NLU (MMNLU-22) competition and workshop will help researchers scale natural-language-understanding technology to every language on Earth.</p>\n<p>The post <a href=\"https://www.topbots.com/amazon-massive-dataset/\" rel=\"nofollow\">Amazon Releases 51-Language Dataset for Language Understanding</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Wed, 20 Apr 2022 15:00:07 +0000",
            "pubdate_parsed": [
                2022,
                4,
                20
            ],
            "email_sent": true
        },
        "Unconstrained Chatbots Condone Self-Harm": {
            "url": "https://www.topbots.com/unconstrained-chatbots-condone-self-harm/",
            "description": "<p>WARNING. This post contains references to self-harm and suicide. It includes conversations between a human and DialoGPT, with the sole purpose of surfacing the danger of uncontrolled AI. If you or a loved one are dealing or have dealt with suicidal thoughts, I suggest skipping this article. In the context of an accelerating&#160;mental health crisis, [&#8230;]</p>\n<p>The post <a href=\"https://www.topbots.com/unconstrained-chatbots-condone-self-harm/\" rel=\"nofollow\">Unconstrained Chatbots Condone Self-Harm</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Tue, 31 May 2022 14:02:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                31
            ],
            "email_sent": true
        },
        "Similarity-Based Image Search for Visual Art": {
            "url": "https://www.topbots.com/similarity-based-image-search-for-visual-art/",
            "description": "<p>Similarity-based image search, also known as content-based image retrieval, has historically been a challenging computer vision task. This problem is&#160;especially difficult for visual art, because it is less obvious as to what a metric of \u201csimilarity\u201d should be defined as and who should set that standard for art. For example, when I upload a photo [&#8230;]</p>\n<p>The post <a href=\"https://www.topbots.com/similarity-based-image-search-for-visual-art/\" rel=\"nofollow\">Similarity-Based Image Search for Visual Art</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Wed, 01 Jun 2022 14:09:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                1
            ],
            "email_sent": true
        },
        "Data Capitalism: Innovation, Extraction, Social Conscience": {
            "url": "https://www.topbots.com/data-capitalism/",
            "description": "<p>How to advance social capital in a world increasingly governed by surveillance capitalism? About a year ago, I read&#160;Atlas of AI&#160;by Kate Crawford, a brilliant analysis of the extractive processes that govern the field of machine learning, from environmental resource allocation to the harvesting of our political fabric to data privacy infringements. This article reflects [&#8230;]</p>\n<p>The post <a href=\"https://www.topbots.com/data-capitalism/\" rel=\"nofollow\">Data Capitalism: Innovation, Extraction, Social Conscience</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Thu, 09 Jun 2022 14:57:20 +0000",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        },
        "10 Leading Language Models For NLP In 2022": {
            "url": "https://www.topbots.com/leading-nlp-language-models-2020/",
            "description": "<p>The introduction of transfer learning and pretrained language models in natural language processing (NLP) pushed forward the limits of language understanding and generation. Transfer learning and applying transformers to different downstream NLP tasks have become the main trend of the latest research advances. At the same time, there is a controversy in the NLP community [&#8230;]</p>\n<p>The post <a href=\"https://www.topbots.com/leading-nlp-language-models-2020/\" rel=\"nofollow\">10 Leading Language Models For NLP In 2022</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Fri, 17 Jun 2022 11:14:55 +0000",
            "pubdate_parsed": [
                2022,
                6,
                17
            ],
            "email_sent": true
        },
        "Transformers And Multimodal: The Same Key For All Data Types": {
            "url": "https://www.topbots.com/transformers-and-multimodal/",
            "description": "<p>The world of Machine Learning is undoubtedly fascinating, constantly growing, and capable of touching the most diverse sectors, from medicine to space racing, from catering to big manufacturing. There are countless fields of application for this technology and just as many techniques that have been developed over the decades, but they all have one thing [&#8230;]</p>\n<p>The post <a href=\"https://www.topbots.com/transformers-and-multimodal/\" rel=\"nofollow\">Transformers And Multimodal: The Same Key For All Data Types</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Thu, 14 Jul 2022 22:38:13 +0000",
            "pubdate_parsed": [
                2022,
                7,
                14
            ],
            "email_sent": true
        },
        "DALLE 2, Explained: The Promise And Limitations Of A Revolutionary AI": {
            "url": "https://www.topbots.com/dalle-2-explained/",
            "description": "<p>DALL\u00b7E 2 is the newest AI model by OpenAI. If you\u2019ve seen some of its creations and think they\u2019re amazing, keep reading to understand why you\u2019re totally right \u2014 but also wrong. OpenAI published a&#160;blog post&#160;and a paper entitled \u201cHierarchical Text-Conditional Image Generation with CLIP Latents\u201d on DALL\u00b7E 2. The post is fine if you [&#8230;]</p>\n<p>The post <a href=\"https://www.topbots.com/dalle-2-explained/\" rel=\"nofollow\">DALL\u00b7E 2, Explained: The Promise And Limitations Of A Revolutionary AI</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Fri, 15 Jul 2022 15:47:52 +0000",
            "pubdate_parsed": [
                2022,
                7,
                15
            ],
            "email_sent": true
        },
        "The Evolution Of Science: From Descartes To Generative AI": {
            "url": "https://www.topbots.com/the-evolution-of-science-from-descartes-to-generative-ai/",
            "description": "<p>Machine learning became the best tool in history for mathematical manipulation through the use of algorithms for pattern recognition.</p>\n<p>The post <a href=\"https://www.topbots.com/the-evolution-of-science-from-descartes-to-generative-ai/\" rel=\"nofollow\">The Evolution Of Science: From Descartes To Generative AI</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Thu, 02 Mar 2023 13:45:26 +0000",
            "pubdate_parsed": [
                2023,
                3,
                2
            ],
            "email_sent": true
        },
        "Exploring Creativity in Large Language Models: From GPT-2 to GPT-4": {
            "url": "https://www.topbots.com/exploring-creativity-in-large-language-models/",
            "description": "<p>In recent weeks, people have used large language models (LLMs) to generate a variety of creative content, such as\u00a0books,\u00a0flash fiction,\u00a0rap battles, and\u00a0music chords. But is it possible to measure the level of creative process more broadly in these models?</p>\n<p>The post <a href=\"https://www.topbots.com/exploring-creativity-in-large-language-models/\" rel=\"nofollow\">Exploring Creativity in Large Language Models: From GPT-2 to GPT-4</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Fri, 28 Apr 2023 12:24:00 +0000",
            "pubdate_parsed": [
                2023,
                4,
                28
            ],
            "email_sent": true
        },
        "Generative vs Predictive AI: Key Differences & Real-World Applications": {
            "url": "https://www.topbots.com/generative-vs-predictive-ai/",
            "description": "<p>Predictive AI has been driving companies' ROI for decades through advanced recommendation algorithms, risk assessment models, and fraud detection tools. However, the recent surge in generative AI has made it the new hot topic.</p>\n<p>The post <a href=\"https://www.topbots.com/generative-vs-predictive-ai/\" rel=\"nofollow\">Generative vs Predictive AI: Key Differences &amp; Real-World Applications</a> appeared first on <a href=\"https://www.topbots.com\" rel=\"nofollow\">TOPBOTS</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 13:30:00 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        }
    },
    "Sebastian Raschka Blog": {
        "Machine Learning with PyTorch and Scikit-Learn": {
            "url": "https://sebastianraschka.com/blog/2022/ml-pytorch-book.html",
            "description": "Machine Learning with PyTorch and Scikit-Learn has been a long time in the making, and I am excited to finally get to talk about the release of my new book. Initially, this project started as the 4th edition of Python Machine Learning. However, we made so many changes to the book that we thought it deserved a new title to reflect that. So, what's new, you may wonder? In this post, I am excited to tell you all about it.",
            "pubdate": "Fri, 25 Feb 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                2,
                25
            ],
            "email_sent": true
        },
        "TorchMetrics": {
            "url": "https://sebastianraschka.com/blog/2022/torchmetrics.html",
            "description": "TorchMetrics is a really nice and convenient library that lets us compute the performance of models in an iterative fashion. It's designed with PyTorch (and PyTorch Lightning) in mind, but it is a general-purpose library compatible with other libraries and workflows. This iterative computation is useful if we want to track a model during iterative training or evaluation on minibatches (and optionally across on multiple GPUs). In deep learning, that's essentially *all the time*. However, when using TorchMetrics, one common question is whether we should use `.update()` or `.forward()`? (And that's also a question I certainly had when I started using it.). Here's a hands-on example and explanation.",
            "pubdate": "Thu, 24 Mar 2022 13:00:00 +0000",
            "pubdate_parsed": [
                2022,
                3,
                24
            ],
            "email_sent": true
        },
        "Losses Learned": {
            "url": "https://sebastianraschka.com/blog/2022/losses-learned-part1.html",
            "description": "The cross-entropy loss is our go-to loss for training deep learning-based classifiers. In this article, I am giving you a quick tour of how we usually compute the cross-entropy loss and how we compute it in PyTorch. There are two parts to it, and here we will look at a binary classification context first. You may wonder why bother writing this article; computing the cross-entropy loss should be relatively straightforward!? Yes and no. We can compute the cross-entropy loss in one line of code, but there's a common gotcha due to numerical optimizations under the hood. (And yes, when I am not careful, I sometimes make this mistake, too.) So, in this article, let me tell you a bit about deep learning jargon, improving numerical performance, and what could go wrong.",
            "pubdate": "Mon, 04 Apr 2022 15:00:00 +0000",
            "pubdate_parsed": [
                2022,
                4,
                4
            ],
            "email_sent": true
        },
        "Creating Confidence Intervals for Machine Learning Classifiers": {
            "url": "https://sebastianraschka.com/blog/2022/confidence-intervals-for-ml.html",
            "description": "Developing good predictive models hinges upon accurate performance evaluation and comparisons. However, when evaluating machine learning models, we typically have to work around many constraints, including limited data, independence violations, and sampling biases. Confidence intervals are no silver bullet, but at the very least, they can offer an additional glimpse into the uncertainty of the reported accuracy and performance of a model. This article outlines different methods for creating confidence intervals for machine learning models. Note that these methods also apply to deep learning.",
            "pubdate": "Mon, 25 Apr 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                4,
                25
            ],
            "email_sent": true
        },
        "Running PyTorch on the M1 GPU": {
            "url": "https://sebastianraschka.com/blog/2022/pytorch-m1-gpu.html",
            "description": "Today, PyTorch officially introduced GPU support for Apple's ARM M1 chips. This is an exciting day for Mac users out there, so I spent a few minutes trying it out in practice. In this short blog post, I will summarize my experience and thoughts with the M1 chip for deep learning tasks.",
            "pubdate": "Wed, 18 May 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                5,
                18
            ],
            "email_sent": true
        },
        "Taking Datasets, DataLoaders, and PyTorchs New DataPipes for a Spin": {
            "url": "https://sebastianraschka.com/blog/2022/datapipes.html",
            "description": "The PyTorch team recently announced TorchData, a prototype library focused on implementing composable and reusable data loading utilities for PyTorch. In particular, the TorchData library is centered around DataPipes, which are meant to be a DataLoader-compatible replacement for the existing Dataset class.",
            "pubdate": "Sun, 12 Jun 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                12
            ],
            "email_sent": true
        },
        "Sharing Deep Learning Research Models with Lightning Part 1: Building A Super Resolution App": {
            "url": "https://sebastianraschka.com/blog/2022/lightning-app-srgan-1.html",
            "description": "In this post, we will build a Lightning App. Why? Because it is 2022, and it is time to explore a more modern take on interacting with, presenting, and sharing our deep learning models. We are going to tackle this in three parts. In this first part, we will learn what a Lightning App is and how we build a Super Resolution GAN demo.",
            "pubdate": "Fri, 17 Jun 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                17
            ],
            "email_sent": true
        },
        "Sharing Deep Learning Research Models with Lightning Part 2: Leveraging the Cloud": {
            "url": "https://sebastianraschka.com/blog/2022/lightning-app-srgan-2.html",
            "description": "In this article, we will take deploy a Super Resolution App on the cloud using lightning.ai. The primary goal here is to see how easy it is to create and share a research demo. However, the cloud is for more than just model sharing: we will also learn how we can tap into additional GPU resources for model training.",
            "pubdate": "Thu, 30 Jun 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                6,
                30
            ],
            "email_sent": true
        },
        "No, We Don't Have to Choose Batch Sizes As Powers Of 2": {
            "url": "https://sebastianraschka.com/blog/2022/batch-size-2.html",
            "description": "Regarding neural network training, I think we are all guilty of doing this: we choose our batch sizes as powers of 2, that is, 64, 128, 256, 512, 1024, and so forth. There are some valid theoretical justifications for this, but how does it pan out in practice? We had some discussions about that in the last couple of days, and here I want to write down some of the take-aways so I can reference them in the future. I hope you'll find this helpful as well!",
            "pubdate": "Tue, 05 Jul 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                7,
                5
            ],
            "email_sent": true
        },
        "A Short Chronology Of Deep Learning For Tabular Data": {
            "url": "https://sebastianraschka.com/blog/2022/deep-learning-for-tabular-data.html",
            "description": "Occasionally, I share research papers proposing new deep learning approaches for tabular data on social media, which is typically an excellent discussion starter. Often, people ask for additional methods or counterexamples. So, with this short post, I aim to briefly summarize the major papers on deep tabular learning I am currently aware of. However, I want to emphasize that no matter how interesting or promising deep tabular methods look, I still recommend using a conventional machine learning method as a baseline. There is a reason why I cover conventional machine learning before deep learning in my books.",
            "pubdate": "Sun, 24 Jul 2022 07:00:00 +0000",
            "pubdate_parsed": [
                2022,
                7,
                24
            ],
            "email_sent": true
        },
        "Optimizing LLMs From a Dataset Perspective": {
            "url": "https://sebastianraschka.com/blog/2023/optimizing-LLMs-dataset-perspective.html",
            "description": "This article focuses on improving the modeling performance of LLMs by finetuning them using carefully curated datasets. Specifically, this article highlights strategies that involve modifying, utilizing, or manipulating the datasets for instruction-based finetuning rather than altering the model architecture or training algorithms (the latter will be topics of a future article). This article will also explain how you can prepare your own datasets to finetune open-source LLMs.",
            "pubdate": "Fri, 15 Sep 2023 08:00:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        }
    },
    "Distill Machine Learning Blog": {},
    "Assembly AI Blog": {
        "Deep Learning Paper Recap - Streaming ASR and Summarization": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-streaming-asr-summarization/",
            "description": "This week\u2019s Deep Learning Paper Recaps are Bridging the gap between streaming and non-streaming ASR systems by distilling ensembles of CTC and RNN-T models and BRIO: Bringing Order to Abstractive Summarization",
            "pubdate": "Wed, 22 Jun 2022 15:24:10 GMT",
            "pubdate_parsed": [
                2022,
                6,
                22
            ],
            "email_sent": true
        },
        "How Imagen Actually Works": {
            "url": "https://www.assemblyai.com/blog/how-imagen-actually-works/",
            "description": "Given a brief description of a scene, Imagen can generate photorealistic, high-resolution images of the scene. Learn everything you need to know about Imagen and how it works in this easy-to-follow guide.",
            "pubdate": "Thu, 23 Jun 2022 14:13:40 GMT",
            "pubdate_parsed": [
                2022,
                6,
                23
            ],
            "email_sent": true
        },
        "Content Moderation: What It Is, How It Works, and the Best APIs": {
            "url": "https://www.assemblyai.com/blog/content-moderation-what-it-is-how-it-works-best-apis-2/",
            "description": "This article will look at what Content Moderation is, how it works, some of the best APIs for performing Content Moderation, and a few of its top use cases.",
            "pubdate": "Mon, 27 Jun 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                27
            ],
            "email_sent": true
        },
        "Deep Learning Paper Recap - Language Models": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-language-models/",
            "description": "This week\u2019s Deep Learning Paper Recap is Prune Once For All: Sparse Pre-Trained Language Models",
            "pubdate": "Thu, 07 Jul 2022 14:37:49 GMT",
            "pubdate_parsed": [
                2022,
                7,
                7
            ],
            "email_sent": true
        },
        "Our $30M Series B": {
            "url": "https://www.assemblyai.com/blog/our-30m-series-b/",
            "description": "Today, we\u2019re excited to share that we\u2019ve raised another $30M in our Series B round led by global software investor Insight Partners.",
            "pubdate": "Thu, 14 Jul 2022 14:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                14
            ],
            "email_sent": true
        },
        "Creating Top Hiring Intelligence Platforms with ASR, NLP, and NLU Tools": {
            "url": "https://www.assemblyai.com/blog/creating-top-hiring-intelligence-platforms-with-asr-nlp-and-nlu-tools/",
            "description": "This article looks at how top ASR, NLP, and NLU tools can be integrated into Hiring Intelligence Platforms.",
            "pubdate": "Tue, 19 Jul 2022 14:50:24 GMT",
            "pubdate_parsed": [
                2022,
                7,
                19
            ],
            "email_sent": true
        },
        "AssemblyAI Named a G2 High Performer and Momentum Leader for Summer 2022": {
            "url": "https://www.assemblyai.com/blog/assemblyai-named-a-g2-high-performer-and-momentum-leader-for-summer-2022/",
            "description": "We are thrilled to announce that AssemblyAI has been named a Summer 2022 High Performer and Momentum Leader in the Voice Recognition Software category by G2",
            "pubdate": "Wed, 20 Jul 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                20
            ],
            "email_sent": true
        },
        "Deep Learning Paper Recaps - Modality Matching and Masked Autoencoders": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recaps-modality-matching-and-masked-autoencoders/",
            "description": "This week\u2019s Deep Learning Paper Recaps are MAESTRO: Matched Speech Text Representations through Modality Matching and Masked Autoencoders that Listen.",
            "pubdate": "Wed, 27 Jul 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                27
            ],
            "email_sent": true
        },
        "Deep Learning Paper Recap - Automatic Speech Recognition": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-automatic-speech-recognition/",
            "description": "This week\u2019s Deep Learning Paper Recaps are Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition and Efficient Adapter Transfer of Self-Supervised Speech Models for Automatic Speech Recognition",
            "pubdate": "Wed, 03 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                3
            ],
            "email_sent": true
        },
        "Deep Learning Paper Recap - Transfer Learning": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-transfer-learning/",
            "description": "This week\u2019s Deep Learning Paper Review is Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis.",
            "pubdate": "Wed, 10 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "Build Your Own Imagen Text-to-Image Model": {
            "url": "https://www.assemblyai.com/blog/build-your-own-imagen-text-to-image-model/",
            "description": "Text-to-Image models have made great strides this year, from DALL-E 2 to the more recent Imagen model. In this tutorial learn how to build a minimal Imagen implementation - MinImagen.",
            "pubdate": "Wed, 17 Aug 2022 15:00:02 GMT",
            "pubdate_parsed": [
                2022,
                8,
                17
            ],
            "email_sent": true
        },
        "Deep Learning Paper Recap - Redundancy Reduction and Sparse MoEs": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-redundancy-reduction-and-sparse-moes/",
            "description": "This week\u2019s Deep Learning Paper Reviews is Barlow Twins: Self-Supervised Learning via Redundancy Reduction and Sparse MoEs Meet Efficient Ensembles",
            "pubdate": "Wed, 17 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                17
            ],
            "email_sent": true
        },
        "How to Run Stable Diffusion Locally to Generate Images": {
            "url": "https://www.assemblyai.com/blog/how-to-run-stable-diffusion-locally-to-generate-images/",
            "description": "Stable Diffusion is a text-to-image model with recently-released open-sourced weights. Learn how to generate an image of a scene given only a description of it in this simple tutorial.",
            "pubdate": "Tue, 23 Aug 2022 12:57:39 GMT",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Deep Learning Paper Recap - Diffusion and Transformer Models": {
            "url": "https://www.assemblyai.com/blog/deep-learning-paper-recap-diffusion-and-transformer-models/",
            "description": "This week\u2019s Deep Learning Paper Reviews is Diffusion-LM Improves Controllable Text Generation and Sparsifying Transformer Models with Trainable Representation Pooling.",
            "pubdate": "Wed, 24 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                24
            ],
            "email_sent": true
        },
        "Why Product Teams at Top Call Tracking Solutions are Turning to AI": {
            "url": "https://www.assemblyai.com/blog/why-product-teams-at-top-call-tracking-solutions-are-turning-to-ai/",
            "description": "This article will look at some of the top AI models for product teams to integrate into Call Tracking Solutions, including what they are and how they work.",
            "pubdate": "Thu, 25 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                25
            ],
            "email_sent": true
        },
        "What are the Top PII Redaction APIs and AI Models for 2023?": {
            "url": "https://www.assemblyai.com/blog/what-are-the-top-pii-redaction-apis-and-ai-models/",
            "description": "This article will explore what Personally Identifiable Information (PII) Redaction APIs are, how they work, and the top use cases.",
            "pubdate": "Tue, 30 Aug 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                30
            ],
            "email_sent": true
        },
        "Introducing the AssemblyAI Creators Program": {
            "url": "https://www.assemblyai.com/blog/introducing-assemblyai-creators-program/",
            "description": "We are excited to announce our AssemblyAI Creators program, a community of creators in the AI space who grow together and give back to the developer community.",
            "pubdate": "Wed, 14 Sep 2022 12:58:00 GMT",
            "pubdate_parsed": [
                2022,
                9,
                14
            ],
            "email_sent": true
        },
        "AI Research Review - Multistream CNN": {
            "url": "https://www.assemblyai.com/blog/ai-research-review-multistream-cnn/",
            "description": "This week\u2019s AI Research Review is Multistream CNN For Robust Acoustic Modeling",
            "pubdate": "Wed, 21 Sep 2022 10:00:00 GMT",
            "pubdate_parsed": [
                2022,
                9,
                21
            ],
            "email_sent": true
        },
        "AssemblyAI Recognized as G2 High Performer, Momentum Leader for Fall 2022": {
            "url": "https://www.assemblyai.com/blog/assemblyai-recognized-as-g2-high-performer-momentum-leader-for-fall-2022/",
            "description": "We are proud to share that AssemblyAI has once again been named a G2 High Performer and Momentum Leader in Voice Recognition Software for Fall 2022!",
            "pubdate": "Wed, 28 Sep 2022 14:13:06 GMT",
            "pubdate_parsed": [
                2022,
                9,
                28
            ],
            "email_sent": true
        },
        "How Aloware Shipped AI-powered Smart Transcription and QA in 6 Weeks": {
            "url": "https://www.assemblyai.com/blog/aloware-shipped-ai-powered-smart-transcription-qa-6-weeks/",
            "description": "Leveraging AssemblyAI, Aloware now offers fast, accurate call transcription and smarter Quality Assurance tools to its customers.",
            "pubdate": "Thu, 29 Sep 2022 13:36:23 GMT",
            "pubdate_parsed": [
                2022,
                9,
                29
            ],
            "email_sent": true
        },
        "Transcribe audio or video files right from your terminal": {
            "url": "https://www.assemblyai.com/blog/transcribe-audio-or-video-files-right-from-your-terminal/",
            "description": "We built the AssemblyAI CLI to help developers quickly test our latest models, right from your terminal, with minimal installation required.",
            "pubdate": "Wed, 19 Oct 2022 13:43:36 GMT",
            "pubdate_parsed": [
                2022,
                10,
                19
            ],
            "email_sent": true
        },
        "AI for product managers: Todays top terms to stay in the know": {
            "url": "https://www.assemblyai.com/blog/ai-for-product-managers-todays-top-terms-to-stay-in-the-know/",
            "description": "Gaining a basic understanding of newer AI terminology is critical for any field, including product management. This guide will serve as an entry point into the current key AI terminology to know now.",
            "pubdate": "Mon, 07 Nov 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                7
            ],
            "email_sent": true
        },
        "AI research review - Merging Models Modulo Permutation Symmetries": {
            "url": "https://www.assemblyai.com/blog/ai-research-review-merging-models-modulo-permutation-symmetries/",
            "description": "This week\u2019s AI Research Review is Git Re-Basin: Merging Models Modulo Permutation Symmetries.",
            "pubdate": "Wed, 16 Nov 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                16
            ],
            "email_sent": true
        },
        "DeepMind's AlphaTensor Explained": {
            "url": "https://www.assemblyai.com/blog/deepminds-alphatensor-explained/",
            "description": "AlphaTensor is a novel AI solution to discover mathematical algorithms with Reinforcement Learning. Learn everything you need to know about AlphaTensor in this comprehensive introduction.",
            "pubdate": "Tue, 22 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                22
            ],
            "email_sent": true
        },
        "Build standout call coaching features with AI Summarization": {
            "url": "https://www.assemblyai.com/blog/build-standout-call-coaching-features-ai-summarization/",
            "description": "Revenue intelligence platforms are adopting an AI-first approach to build competitive call coaching features. This includes embedding AI Summarization models that are purpose-built for understanding conversations.",
            "pubdate": "Mon, 12 Dec 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                12
            ],
            "email_sent": true
        },
        "7 best practices for building better products with AI": {
            "url": "https://www.assemblyai.com/blog/7-best-practices-for-building-better-products-with-ai/",
            "description": "This guide serves to examine the best practices for building better products with AI to demystify the process, and to smooth and accelerate the path to deployment.",
            "pubdate": "Thu, 22 Dec 2022 11:26:04 GMT",
            "pubdate_parsed": [
                2022,
                12,
                22
            ],
            "email_sent": true
        },
        "How ChatGPT actually works": {
            "url": "https://www.assemblyai.com/blog/how-chatgpt-actually-works/",
            "description": "Since its release, the public has been playing with ChatGPT and seeing what it can do, but how does ChatGPT actually work? While the details of its inner workings have not been published, we can piece together its functioning principles from recent research.",
            "pubdate": "Fri, 23 Dec 2022 08:43:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                23
            ],
            "email_sent": true
        },
        "2022 at AssemblyAI - A Year in Review": {
            "url": "https://www.assemblyai.com/blog/2022-at-assemblyai-a-year-in-review/",
            "description": "The end of 2022 is quickly approaching, and what a year it has been! As we get closer to 2023, we wanted to take a moment to look back and reflect on some of the highlights of the past year.",
            "pubdate": "Thu, 29 Dec 2022 06:00:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                29
            ],
            "email_sent": true
        },
        "AI research review  Locating and Editing Factual Associations in GPT": {
            "url": "https://www.assemblyai.com/blog/ai-research-review-locating-and-editing-factual-associations-in-gpt/",
            "description": "This week\u2019s AI Research Review is Locating and Editing Factual Associations in GPT.",
            "pubdate": "Wed, 18 Jan 2023 06:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                18
            ],
            "email_sent": true
        },
        "How CallRail doubled its Conversation Intelligence customers by building with a trusted AI partner": {
            "url": "https://www.assemblyai.com/blog/how-callrail-doubled-its-conversation-intelligence-customers-by-building-with-a-trusted-ai-partner/",
            "description": "With AssemblyAI\u2019s Conversational Summarization Model, CallRail helps its customers easily review calls at scale.",
            "pubdate": "Tue, 14 Feb 2023 06:00:33 GMT",
            "pubdate_parsed": [
                2023,
                2,
                14
            ],
            "email_sent": true
        },
        "6 Best AI playgrounds in 2023": {
            "url": "https://www.assemblyai.com/blog/6-best-ai-playgrounds/",
            "description": "If you\u2019re looking for ways to play around with AI in 2023, these are the six best AI playgrounds to try.",
            "pubdate": "Wed, 08 Mar 2023 13:17:46 GMT",
            "pubdate_parsed": [
                2023,
                3,
                8
            ],
            "email_sent": true
        },
        "AI trends in 2023: Graph Neural Networks": {
            "url": "https://www.assemblyai.com/blog/ai-trends-graph-neural-networks/",
            "description": "From fundamental research to productionized AI models, let\u2019s discover how this cutting-edge technology is powering production applications and may be shaping the future of AI.",
            "pubdate": "Tue, 21 Mar 2023 10:23:28 GMT",
            "pubdate_parsed": [
                2023,
                3,
                21
            ],
            "email_sent": true
        },
        "How AI-powered transcription helped a hiring intelligence platform cut time spent on manual tasks by 90% for its customers": {
            "url": "https://www.assemblyai.com/blog/how-ai-powered-transcription-helped-a-hiring-intelligence-platform-cut-time-spent-on-manual-tasks-by-90-for-its-customers/",
            "description": "Hiring intelligence platform Screenloop builds features using AI-powered transcription that reduce time-to-hire, limit candidate drop-off, and increase offer acceptance for end users.",
            "pubdate": "Tue, 11 Apr 2023 12:27:23 GMT",
            "pubdate_parsed": [
                2023,
                4,
                11
            ],
            "email_sent": true
        },
        "How Grain builds with AI to generate powerful insights from customer meetings": {
            "url": "https://www.assemblyai.com/blog/grain-builds-ai-powerful-insights-customer-meetings/",
            "description": "AI-powered meeting recorder Grain integrates AssemblyAI's Core Transcription model to create highly accurate transcripts that translate into better intelligent insights for Grain\u2019s core customers.",
            "pubdate": "Wed, 26 Apr 2023 12:03:46 GMT",
            "pubdate_parsed": [
                2023,
                4,
                26
            ],
            "email_sent": true
        },
        "The Full Story of Large Language Models and RLHF": {
            "url": "https://www.assemblyai.com/blog/the-full-story-of-large-language-models-and-rlhf/",
            "description": "Large Language Models have been in the limelight since the release of ChatGPT, with new models being announced seemingly every week. This guide walks through the essential ideas of how these models came to be.",
            "pubdate": "Wed, 03 May 2023 08:20:11 GMT",
            "pubdate_parsed": [
                2023,
                5,
                3
            ],
            "email_sent": true
        },
        "How AI helps Marvin's users spend 60% less time analyzing research data": {
            "url": "https://www.assemblyai.com/blog/ai-helps-marvins-users-spend-60-less-time-analyzing-research-data/",
            "description": "Learn how Marvin's product team embedded powerful AI models, like AssemblyAI\u2019s Core Transcription and PII Redaction models, into the user research platform that help users spend less time wrestling with data and more time making sense of it, driving improved ROI and intelligent insights.",
            "pubdate": "Thu, 04 May 2023 10:58:54 GMT",
            "pubdate_parsed": [
                2023,
                5,
                4
            ],
            "email_sent": true
        },
        "3 ways to build and deploy AI tools and features faster": {
            "url": "https://www.assemblyai.com/blog/3-ways-build-deploy-ai-tools-features-faster/",
            "description": "This blog post examines some of the top blockers facing companies looking to build with AI, as well as explores solutions to building and deploying successful AI tools and features faster.",
            "pubdate": "Tue, 16 May 2023 12:15:38 GMT",
            "pubdate_parsed": [
                2023,
                5,
                16
            ],
            "email_sent": true
        },
        "How Jiminny builds with AI models to secure 15% higher win rates for customers": {
            "url": "https://www.assemblyai.com/blog/jiminny-builds-ai-models-secure-higher-win-rates/",
            "description": "Learn how a strategic AI partnership with AssemblyAI was key to Jiminny\u2019s Conversation Intelligence success.",
            "pubdate": "Thu, 01 Jun 2023 12:48:41 GMT",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Introducing LeMUR": {
            "url": "https://www.assemblyai.com/blog/lemur/",
            "description": "LeMUR is the easiest way to build LLM apps on spoken data - search, summarize, and ask questions, with knowledge of your spoken data.",
            "pubdate": "Thu, 27 Jul 2023 08:49:30 GMT",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Customer Stories: Conformer-2 in Action": {
            "url": "https://www.assemblyai.com/blog/customer-stories-conformer-2/",
            "description": "Leading companies are putting Conformer-2 into production, offering highly accurate transcription to their customers, as well as competitive Generative AI features built on top of this transcription data.",
            "pubdate": "Mon, 14 Aug 2023 10:56:26 GMT",
            "pubdate_parsed": [
                2023,
                8,
                14
            ],
            "email_sent": true
        },
        "Why Language Models Became Large Language Models And The Hurdles In Developing LLM-based Applications": {
            "url": "https://www.assemblyai.com/blog/why-language-models-became-large-language-models/",
            "description": "What\u2019s the difference between Language Models and Large Language Models? Let\u2019s understand AI development trends and the difficulties of integrating LLMs into real-world applications.",
            "pubdate": "Fri, 18 Aug 2023 11:06:53 GMT",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "Conversation AI: What it is and top use cases": {
            "url": "https://www.assemblyai.com/blog/conversation-ai-what-it-is-top-use-cases/",
            "description": "This article examines what Conversation AI is, how it works, and some of its top use cases.",
            "pubdate": "Tue, 29 Aug 2023 12:57:53 GMT",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "What is Residual Vector Quantization?": {
            "url": "https://www.assemblyai.com/blog/what-is-residual-vector-quantization/",
            "description": "Neural Audio Compression methods based on Residual Vector Quantization are reshaping the landscape of modern audio codecs. In this guide, learn the basic ideas behind RVQ and how it enhances Neural Compression.",
            "pubdate": "Mon, 04 Sep 2023 12:05:53 GMT",
            "pubdate_parsed": [
                2023,
                9,
                4
            ],
            "email_sent": true
        },
        "What AI Music Generators Can Do (And How They Do It)": {
            "url": "https://www.assemblyai.com/blog/what-ai-music-generators-can-do-and-how-they-do-it/",
            "description": "Text-to-Music Models are advancing rapidly with the recent release of new platforms for AI-generated music. This guide focuses on MusicLM, MusicGen, and Stable Audio, exploring the technical breakthroughs and challenges in creating music with AI.",
            "pubdate": "Fri, 22 Sep 2023 10:04:11 GMT",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        }
    },
    "Javier ML Blog": {},
    "Data School": {
        "Building a dataset of Python versions with regular expressions": {
            "url": "https://www.dataschool.io/web-scraping-with-regex/",
            "description": "Learn how to use pandas, requests, and regular expressions  (\"regex\") to create a dataset of every Python version and its release date!",
            "pubdate": "Wed, 12 Apr 2023 13:29:32 GMT",
            "pubdate_parsed": [
                2023,
                4,
                12
            ],
            "email_sent": true
        }
    },
    "Lil'Log": {
        "Learning with not Enough Data Part 2: Active Learning": {
            "url": "https://lilianweng.github.io/posts/2022-02-20-active-learning/",
            "description": "This is part 2 of what to do when facing a limited amount of labeled data for supervised learning tasks. This time we will get some amount of human labeling work involved, but within a budget limit, and therefore we need to be smart when selecting which samples to label.\nNotations    Symbol Meaning     $K$ Number of unique class labels.   $(\\mathbf{x}^l, y) \\sim \\mathcal{X}, y \\in \\{0, 1\\}^K$ Labeled dataset.",
            "pubdate": "Sun, 20 Feb 2022 00:00:00 +0000",
            "pubdate_parsed": [
                2022,
                2,
                20
            ],
            "email_sent": true
        },
        "Learning with not Enough Data Part 3: Data Generation": {
            "url": "https://lilianweng.github.io/posts/2022-04-15-data-gen/",
            "description": "Here comes the Part 3 on learning with not enough data (Previous: Part 1 and Part 2). Let\u2019s consider two approaches for generating synthetic data for training.\n Augmented data. Given a set of existing training samples, we can apply a variety of augmentation, distortion and transformation to derive new data points without losing the key attributes. We have covered a bunch of augmentation methods on text and images in a previous post on contrastive learning.",
            "pubdate": "Fri, 15 Apr 2022 15:10:30 -0700",
            "pubdate_parsed": [
                2022,
                4,
                15
            ],
            "email_sent": true
        },
        "Generalized Visual Language Models": {
            "url": "https://lilianweng.github.io/posts/2022-06-09-vlm/",
            "description": "Processing images to generate text, such as image captioning and visual question-answering, has been studied for years. Traditionally such systems rely on an object detection network as a vision encoder to capture visual features and then produce text via a text decoder. Given a large amount of existing literature, in this post, I would like to only focus on one approach for solving vision language tasks, which is to extend pre-trained generalized language models to be capable of consuming visual signals.",
            "pubdate": "Thu, 09 Jun 2022 15:10:30 -0700",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        }
    },
    "Hugging Face Blog": {
        "Deploy GPT-J 6B for inference using  Hugging Face Transformers and Amazon SageMaker": {
            "url": "https://huggingface.co/blog/gptj-sagemaker",
            "description": null,
            "pubdate": "Mon, 10 Jan 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                10
            ],
            "email_sent": true
        },
        "Boost Wav2Vec2 with n-gram LM in  Transformers": {
            "url": "https://huggingface.co/blog/wav2vec2-with-ngram",
            "description": null,
            "pubdate": "Tue, 11 Jan 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                11
            ],
            "email_sent": true
        },
        "Case Study: Millisecond Latency using Hugging Face Infinity and modern CPUs": {
            "url": "https://huggingface.co/blog/infinity-cpu-performance",
            "description": null,
            "pubdate": "Wed, 12 Jan 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                12
            ],
            "email_sent": true
        },
        "Welcome Stable-baselines3 to the Hugging Face Hub ": {
            "url": "https://huggingface.co/blog/sb3",
            "description": null,
            "pubdate": "Thu, 20 Jan 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                20
            ],
            "email_sent": true
        },
        "Supercharged Searching on the Hugging Face Hub": {
            "url": "https://huggingface.co/blog/searching-the-hub",
            "description": null,
            "pubdate": "Mon, 24 Jan 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                24
            ],
            "email_sent": true
        },
        "Making automatic speech recognition work on large files with Wav2Vec2 in  Transformers": {
            "url": "https://huggingface.co/blog/asr-chunking",
            "description": null,
            "pubdate": "Mon, 31 Jan 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                1,
                31
            ],
            "email_sent": true
        },
        "Getting Started with Sentiment Analysis using Python": {
            "url": "https://huggingface.co/blog/sentiment-analysis-python",
            "description": null,
            "pubdate": "Tue, 01 Feb 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                1
            ],
            "email_sent": true
        },
        "Fine-Tune ViT for Image Classification with  Transformers": {
            "url": "https://huggingface.co/blog/fine-tune-vit",
            "description": null,
            "pubdate": "Thu, 10 Feb 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                2,
                10
            ],
            "email_sent": true
        },
        "BERT 101  State Of The Art NLP Model Explained": {
            "url": "https://huggingface.co/blog/bert-101",
            "description": null,
            "pubdate": "Tue, 01 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                1
            ],
            "email_sent": true
        },
        "Guiding Text Generation with Constrained Beam Search in  Transformers": {
            "url": "https://huggingface.co/blog/constrained-beam-search",
            "description": null,
            "pubdate": "Thu, 10 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                10
            ],
            "email_sent": true
        },
        "Accelerate BERT inference with Hugging Face Transformers and AWS inferentia": {
            "url": "https://huggingface.co/blog/bert-inferentia-sagemaker",
            "description": null,
            "pubdate": "Tue, 15 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                15
            ],
            "email_sent": true
        },
        "Image search with  datasets": {
            "url": "https://huggingface.co/blog/image-search-datasets",
            "description": null,
            "pubdate": "Tue, 15 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                15
            ],
            "email_sent": true
        },
        "Fine-Tune a Semantic Segmentation Model with a Custom Dataset": {
            "url": "https://huggingface.co/blog/fine-tune-segformer",
            "description": null,
            "pubdate": "Wed, 16 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                16
            ],
            "email_sent": true
        },
        "Announcing the  AI Research Residency Program": {
            "url": "https://huggingface.co/blog/ai-residency",
            "description": null,
            "pubdate": "Mon, 21 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                21
            ],
            "email_sent": true
        },
        "Machine Learning Experts - Meg Mitchell Interview": {
            "url": "https://huggingface.co/blog/meg-mitchell-interview",
            "description": null,
            "pubdate": "Tue, 22 Mar 2022 23:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                22
            ],
            "email_sent": true
        },
        "Introducing Decision Transformers on Hugging Face ": {
            "url": "https://huggingface.co/blog/decision-transformers",
            "description": null,
            "pubdate": "Sun, 27 Mar 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                3,
                27
            ],
            "email_sent": true
        },
        "Don't repeat yourself -  Transformers Design Philosophy": {
            "url": "https://huggingface.co/blog/transformers-design-philosophy",
            "description": null,
            "pubdate": "Mon, 04 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                4
            ],
            "email_sent": true
        },
        "Habana Labs and Hugging Face Partner to Accelerate Transformer Model Training": {
            "url": "https://huggingface.co/blog/habana",
            "description": null,
            "pubdate": "Mon, 11 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                11
            ],
            "email_sent": true
        },
        "Machine Learning Experts - Lewis Tunstall Interview": {
            "url": "https://huggingface.co/blog/lewis-tunstall-interview",
            "description": null,
            "pubdate": "Tue, 12 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                12
            ],
            "email_sent": true
        },
        "CO2 Emissions and the  Hub: Leading the Charge": {
            "url": "https://huggingface.co/blog/carbon-emissions-on-the-hub",
            "description": null,
            "pubdate": "Thu, 21 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                21
            ],
            "email_sent": true
        },
        "Introducing Hugging Face for Education": {
            "url": "https://huggingface.co/blog/education",
            "description": null,
            "pubdate": "Sun, 24 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                24
            ],
            "email_sent": true
        },
        "Supercharged Customer Service with Machine Learning": {
            "url": "https://huggingface.co/blog/supercharge-customer-service-with-machine-learning",
            "description": null,
            "pubdate": "Sun, 24 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                24
            ],
            "email_sent": true
        },
        "Getting Started with Transformers on Habana Gaudi": {
            "url": "https://huggingface.co/blog/getting-started-habana",
            "description": null,
            "pubdate": "Mon, 25 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                25
            ],
            "email_sent": true
        },
        "Director of Machine Learning Insights [Series]": {
            "url": "https://huggingface.co/blog/ml-director-insights",
            "description": null,
            "pubdate": "Tue, 26 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                26
            ],
            "email_sent": true
        },
        "Opinion Classification with Kili and HuggingFace AutoTrain": {
            "url": "https://huggingface.co/blog/opinion-classification-with-kili",
            "description": null,
            "pubdate": "Wed, 27 Apr 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                4,
                27
            ],
            "email_sent": true
        },
        "Accelerate Large Model Training using PyTorch Fully Sharded Data Parallel": {
            "url": "https://huggingface.co/blog/pytorch-fsdp",
            "description": null,
            "pubdate": "Sun, 01 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                1
            ],
            "email_sent": true
        },
        "An Introduction to Deep Reinforcement Learning": {
            "url": "https://huggingface.co/blog/deep-rl-intro",
            "description": null,
            "pubdate": "Tue, 03 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                3
            ],
            "email_sent": true
        },
        "Welcome fastai to the Hugging Face Hub": {
            "url": "https://huggingface.co/blog/fastai",
            "description": null,
            "pubdate": "Thu, 05 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                5
            ],
            "email_sent": true
        },
        "We Raised $100 Million for Open & Collaborative Machine Learning ": {
            "url": "https://huggingface.co/blog/series-c",
            "description": null,
            "pubdate": "Sun, 08 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                8
            ],
            "email_sent": true
        },
        "Accelerated Inference with Optimum and Transformers Pipelines": {
            "url": "https://huggingface.co/blog/optimum-inference",
            "description": null,
            "pubdate": "Mon, 09 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                9
            ],
            "email_sent": true
        },
        "Director of Machine Learning Insights [Part 2: SaaS Edition]": {
            "url": "https://huggingface.co/blog/ml-director-insights-2",
            "description": null,
            "pubdate": "Thu, 12 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                12
            ],
            "email_sent": true
        },
        "Student Ambassador Program's call for applications is open!": {
            "url": "https://huggingface.co/blog/ambassadors",
            "description": null,
            "pubdate": "Thu, 12 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                12
            ],
            "email_sent": true
        },
        "Gradio 3.0 is Out!": {
            "url": "https://huggingface.co/blog/gradio-blocks",
            "description": null,
            "pubdate": "Sun, 15 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                15
            ],
            "email_sent": true
        },
        "Machine Learning Experts - Sasha Luccioni Interview": {
            "url": "https://huggingface.co/blog/sasha-luccioni-interview",
            "description": null,
            "pubdate": "Mon, 16 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                16
            ],
            "email_sent": true
        },
        "Announcing the Hugging Face Fellowship Program": {
            "url": "https://huggingface.co/blog/fellowship",
            "description": null,
            "pubdate": "Mon, 16 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                16
            ],
            "email_sent": true
        },
        "An Introduction to Q-Learning Part 1": {
            "url": "https://huggingface.co/blog/deep-rl-q-part1",
            "description": null,
            "pubdate": "Tue, 17 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                17
            ],
            "email_sent": true
        },
        "How Sempre Health is leveraging the Expert Acceleration Program to accelerate their ML roadmap": {
            "url": "https://huggingface.co/blog/sempre-health-eap-case-study",
            "description": null,
            "pubdate": "Wed, 18 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                18
            ],
            "email_sent": true
        },
        "Putting ethical principles at the core of research lifecycle": {
            "url": "https://huggingface.co/blog/ethical-charter-multimodal",
            "description": null,
            "pubdate": "Wed, 18 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                18
            ],
            "email_sent": true
        },
        "An Introduction to Q-Learning Part 2": {
            "url": "https://huggingface.co/blog/deep-rl-q-part2",
            "description": null,
            "pubdate": "Thu, 19 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                19
            ],
            "email_sent": true
        },
        "Efficient Table Pre-training without Real Data: An Introduction to TAPEX": {
            "url": "https://huggingface.co/blog/tapex",
            "description": null,
            "pubdate": "Sun, 22 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                22
            ],
            "email_sent": true
        },
        "Hugging Face Collaborates with Microsoft to Launch Hugging Face Endpoints on Azure": {
            "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
            "description": null,
            "pubdate": "Mon, 23 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                23
            ],
            "email_sent": true
        },
        "Introducing Pull Requests and Discussions ": {
            "url": "https://huggingface.co/blog/community-update",
            "description": null,
            "pubdate": "Tue, 24 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                24
            ],
            "email_sent": true
        },
        "Graphcore and Hugging Face Launch New Lineup of IPU-Ready Transformers": {
            "url": "https://huggingface.co/blog/graphcore-update",
            "description": null,
            "pubdate": "Wed, 25 May 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                5,
                25
            ],
            "email_sent": true
        },
        "The Annotated Diffusion Model": {
            "url": "https://huggingface.co/blog/annotated-diffusion",
            "description": null,
            "pubdate": "Mon, 06 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                6
            ],
            "email_sent": true
        },
        "Deep Q-Learning with Atari": {
            "url": "https://huggingface.co/blog/deep-rl-dqn",
            "description": null,
            "pubdate": "Mon, 06 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                6
            ],
            "email_sent": true
        },
        "Code generation with Hugging Face": {
            "url": "https://huggingface.co/spaces/loubnabnl/code-generation-models",
            "description": null,
            "pubdate": "Tue, 07 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                7
            ],
            "email_sent": true
        },
        "Using Sentence Transformers for semantic search": {
            "url": "https://huggingface.co/spaces/sentence-transformers/Sentence_Transformers_for_semantic_search",
            "description": null,
            "pubdate": "Thu, 09 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                9
            ],
            "email_sent": true
        },
        "Director of Machine Learning Insights [Part 3: Finance Edition]": {
            "url": "https://huggingface.co/blog/ml-director-insights-3",
            "description": null,
            "pubdate": "Mon, 13 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                13
            ],
            "email_sent": true
        },
        "Intel and Hugging Face Partner to Democratize Machine Learning Hardware Acceleration": {
            "url": "https://huggingface.co/blog/intel",
            "description": null,
            "pubdate": "Tue, 14 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                14
            ],
            "email_sent": true
        },
        "Convert Transformers to ONNX with Hugging Face Optimum": {
            "url": "https://huggingface.co/blog/convert-transformers-to-onnx",
            "description": null,
            "pubdate": "Tue, 21 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                21
            ],
            "email_sent": true
        },
        "Getting Started With Embeddings": {
            "url": "https://huggingface.co/blog/getting-started-with-embeddings",
            "description": null,
            "pubdate": "Wed, 22 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                22
            ],
            "email_sent": true
        },
        "Accelerate Large Model Training using DeepSpeed": {
            "url": "https://huggingface.co/blog/accelerate-deepspeed",
            "description": null,
            "pubdate": "Mon, 27 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                27
            ],
            "email_sent": true
        },
        "Announcing Evaluation on the Hub": {
            "url": "https://huggingface.co/blog/eval-on-the-hub",
            "description": null,
            "pubdate": "Mon, 27 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                27
            ],
            "email_sent": true
        },
        "Liftoff! How to get started with your first ML project ": {
            "url": "https://huggingface.co/blog/your-first-ml-project",
            "description": null,
            "pubdate": "Tue, 28 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                28
            ],
            "email_sent": true
        },
        "Policy Gradient with PyTorch": {
            "url": "https://huggingface.co/blog/deep-rl-pg",
            "description": null,
            "pubdate": "Wed, 29 Jun 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                6,
                29
            ],
            "email_sent": true
        },
        "Getting Started with Sentiment Analysis on Twitter": {
            "url": "https://huggingface.co/blog/sentiment-analysis-twitter",
            "description": null,
            "pubdate": "Wed, 06 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                6
            ],
            "email_sent": true
        },
        "Introducing The World's Largest Open Multilingual Language Model: BLOOM": {
            "url": "https://huggingface.co/blog/bloom",
            "description": null,
            "pubdate": "Mon, 11 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                11
            ],
            "email_sent": true
        },
        "Building a Playlist Generator with Sentence Transformers": {
            "url": "https://huggingface.co/blog/playlist-generator",
            "description": null,
            "pubdate": "Tue, 12 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                12
            ],
            "email_sent": true
        },
        "The Technology Behind BLOOM Training": {
            "url": "https://huggingface.co/blog/bloom-megatron-deepspeed",
            "description": null,
            "pubdate": "Wed, 13 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                13
            ],
            "email_sent": true
        },
        "How to train your model dynamically using adversarial data": {
            "url": "https://huggingface.co/blog/mnist-adversarial",
            "description": null,
            "pubdate": "Fri, 15 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                15
            ],
            "email_sent": true
        },
        "Advantage Actor Critic (A2C)": {
            "url": "https://huggingface.co/blog/deep-rl-a2c",
            "description": null,
            "pubdate": "Thu, 21 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                21
            ],
            "email_sent": true
        },
        "Deploying TensorFlow Vision Models in Hugging Face with TF Serving": {
            "url": "https://huggingface.co/blog/tf-serving-vision",
            "description": null,
            "pubdate": "Sun, 24 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                24
            ],
            "email_sent": true
        },
        "Faster Text Generation with TensorFlow and XLA": {
            "url": "https://huggingface.co/blog/tf-xla-generate",
            "description": null,
            "pubdate": "Tue, 26 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                26
            ],
            "email_sent": true
        },
        "Introducing new audio and vision documentation in  Datasets": {
            "url": "https://huggingface.co/blog/datasets-docs-update",
            "description": null,
            "pubdate": "Wed, 27 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                27
            ],
            "email_sent": true
        },
        "AI Policy @: Comments on U.S. National AI Research Resource Interim Report": {
            "url": "https://huggingface.co/blog/us-national-ai-research-resource",
            "description": null,
            "pubdate": "Sun, 31 Jul 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                7,
                31
            ],
            "email_sent": true
        },
        "Nystrmformer, Approximating self-attention in linear time and memory via the Nystrm method": {
            "url": "https://huggingface.co/blog/nystromformer",
            "description": null,
            "pubdate": "Mon, 01 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                1
            ],
            "email_sent": true
        },
        "Introducing the Private Hub: A New Way to Build With Machine Learning": {
            "url": "https://huggingface.co/blog/introducing-private-hub",
            "description": null,
            "pubdate": "Tue, 02 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                2
            ],
            "email_sent": true
        },
        "Proximal Policy Optimization (PPO)": {
            "url": "https://huggingface.co/blog/deep-rl-ppo",
            "description": null,
            "pubdate": "Thu, 04 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                4
            ],
            "email_sent": true
        },
        "Train and Fine-Tune Sentence Transformers Models": {
            "url": "https://huggingface.co/blog/how-to-train-sentence-transformers",
            "description": null,
            "pubdate": "Tue, 09 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                9
            ],
            "email_sent": true
        },
        "Deploying  ViT on Kubernetes with TF Serving": {
            "url": "https://huggingface.co/blog/deploy-tfserving-kubernetes",
            "description": null,
            "pubdate": "Wed, 10 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                10
            ],
            "email_sent": true
        },
        "Introducing Skops": {
            "url": "https://huggingface.co/blog/skops",
            "description": null,
            "pubdate": "Thu, 11 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                11
            ],
            "email_sent": true
        },
        "Hugging Face's TensorFlow Philosophy": {
            "url": "https://huggingface.co/blog/tensorflow-philosophy",
            "description": null,
            "pubdate": "Thu, 11 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                11
            ],
            "email_sent": true
        },
        "A Gentle Introduction to 8-bit Matrix Multiplication for transformers at scale using transformers, accelerate and bitsandbytes": {
            "url": "https://huggingface.co/blog/hf-bitsandbytes-integration",
            "description": null,
            "pubdate": "Tue, 16 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                16
            ],
            "email_sent": true
        },
        "Deep Dive: Vision Transformers On Hugging Face Optimum Graphcore": {
            "url": "https://huggingface.co/blog/vision-transformers",
            "description": null,
            "pubdate": "Wed, 17 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                17
            ],
            "email_sent": true
        },
        "Deploying  ViT on Vertex AI": {
            "url": "https://huggingface.co/blog/deploy-vertex-ai",
            "description": null,
            "pubdate": "Thu, 18 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                18
            ],
            "email_sent": true
        },
        "Stable Diffusion with  Diffusers": {
            "url": "https://huggingface.co/blog/stable_diffusion",
            "description": null,
            "pubdate": "Sun, 21 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                21
            ],
            "email_sent": true
        },
        "Pre-Train BERT with Hugging Face Transformers and Habana Gaudi": {
            "url": "https://huggingface.co/blog/pretraining-bert",
            "description": null,
            "pubdate": "Sun, 21 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                21
            ],
            "email_sent": true
        },
        "Visualize proteins on Hugging Face Spaces": {
            "url": "https://huggingface.co/blog/spaces_3dmoljs",
            "description": null,
            "pubdate": "Tue, 23 Aug 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                8,
                23
            ],
            "email_sent": true
        },
        "Very Large Language Models and How to Evaluate Them": {
            "url": "https://huggingface.co/blog/zero-shot-eval-on-the-hub",
            "description": null,
            "pubdate": "Sun, 02 Oct 2022 22:00:00 GMT",
            "pubdate_parsed": [
                2022,
                10,
                2
            ],
            "email_sent": true
        },
        "Getting started with Hugging Face Inference Endpoints": {
            "url": "https://huggingface.co/blog/inference-endpoints",
            "description": null,
            "pubdate": "Fri, 14 Oct 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                10,
                14
            ],
            "email_sent": true
        },
        "Accelerate your models with  Optimum Intel and OpenVINO": {
            "url": "https://huggingface.co/blog/openvino",
            "description": null,
            "pubdate": "Wed, 02 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                2
            ],
            "email_sent": true
        },
        "Introducing our new pricing": {
            "url": "https://huggingface.co/blog/pricing-update",
            "description": null,
            "pubdate": "Tue, 08 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                8
            ],
            "email_sent": true
        },
        "An Overview of Inference Solutions on Hugging Face": {
            "url": "https://huggingface.co/blog/inference-update",
            "description": null,
            "pubdate": "Mon, 21 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                21
            ],
            "email_sent": true
        },
        "Director of Machine Learning Insights [Part 4]": {
            "url": "https://huggingface.co/blog/ml-director-insights-4",
            "description": null,
            "pubdate": "Wed, 23 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                23
            ],
            "email_sent": true
        },
        "VQ Diffusion with  Diffusers": {
            "url": "https://huggingface.co/blog/vq-diffusion",
            "description": null,
            "pubdate": "Wed, 30 Nov 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                11,
                30
            ],
            "email_sent": true
        },
        "Probabilistic Time Series Forecasting with  Transformers": {
            "url": "https://huggingface.co/blog/time-series-transformers",
            "description": null,
            "pubdate": "Thu, 01 Dec 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                1
            ],
            "email_sent": true
        },
        "From GPT2 to Stable Diffusion: Hugging Face arrives to the Elixir community": {
            "url": "https://huggingface.co/blog/elixir-bumblebee",
            "description": null,
            "pubdate": "Fri, 09 Dec 2022 00:00:00 GMT",
            "pubdate_parsed": [
                2022,
                12,
                9
            ],
            "email_sent": true
        },
        "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 1": {
            "url": "https://huggingface.co/blog/intel-sapphire-rapids",
            "description": null,
            "pubdate": "Mon, 02 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                2
            ],
            "email_sent": true
        },
        "Introduction to Graph Machine Learning": {
            "url": "https://huggingface.co/blog/intro-graphml",
            "description": null,
            "pubdate": "Tue, 03 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                3
            ],
            "email_sent": true
        },
        "AI for Game Development: Creating a Farming Game in 5 Days. Part 2": {
            "url": "https://huggingface.co/blog/ml-for-games-2",
            "description": null,
            "pubdate": "Mon, 09 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                9
            ],
            "email_sent": true
        },
        "Image Similarity with Hugging Face Datasets and Transformers": {
            "url": "https://huggingface.co/blog/image-similarity",
            "description": null,
            "pubdate": "Mon, 16 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                16
            ],
            "email_sent": true
        },
        "Welcome PaddlePaddle to the Hugging Face Hub": {
            "url": "https://huggingface.co/blog/paddlepaddle",
            "description": null,
            "pubdate": "Tue, 17 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                17
            ],
            "email_sent": true
        },
        "Using LoRA for Efficient Stable Diffusion Fine-Tuning": {
            "url": "https://huggingface.co/blog/lora",
            "description": null,
            "pubdate": "Thu, 26 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                26
            ],
            "email_sent": true
        },
        "The State of Computer Vision at Hugging Face ": {
            "url": "https://huggingface.co/blog/cv_state",
            "description": null,
            "pubdate": "Mon, 30 Jan 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                1,
                30
            ],
            "email_sent": true
        },
        "A Dive into Pretraining Strategies for Vision-Language Models": {
            "url": "https://huggingface.co/blog/vision_language_pretraining",
            "description": null,
            "pubdate": "Fri, 03 Feb 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                2,
                3
            ],
            "email_sent": true
        },
        "Accelerating PyTorch Transformers with Intel Sapphire Rapids, part 2": {
            "url": "https://huggingface.co/blog/intel-sapphire-rapids-inference",
            "description": null,
            "pubdate": "Mon, 06 Feb 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                2,
                6
            ],
            "email_sent": true
        },
        "Speech Synthesis, Recognition, and More With SpeechT5": {
            "url": "https://huggingface.co/blog/speecht5",
            "description": null,
            "pubdate": "Wed, 08 Feb 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                2,
                8
            ],
            "email_sent": true
        },
        " PEFT: Parameter-Efficient Fine-Tuning of Billion-Scale Models on Low-Resource Hardware": {
            "url": "https://huggingface.co/blog/peft",
            "description": null,
            "pubdate": "Fri, 10 Feb 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                2,
                10
            ],
            "email_sent": true
        },
        "Leveraging Hugging Face for complex text classification use cases": {
            "url": "https://huggingface.co/blog/classification-use-cases",
            "description": null,
            "pubdate": "Wed, 01 Mar 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                3,
                1
            ],
            "email_sent": true
        },
        "Ethical guidelines for developing the Diffusers library": {
            "url": "https://huggingface.co/blog/ethics-diffusers",
            "description": null,
            "pubdate": "Thu, 02 Mar 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                3,
                2
            ],
            "email_sent": true
        },
        "Using Machine Learning to Aid Survivors and Race through Time": {
            "url": "https://huggingface.co/blog/using-ml-for-disasters",
            "description": null,
            "pubdate": "Fri, 03 Mar 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                3,
                3
            ],
            "email_sent": true
        },
        "ControlNet in Diffusers ": {
            "url": "https://huggingface.co/blog/controlnet",
            "description": null,
            "pubdate": "Fri, 03 Mar 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                3,
                3
            ],
            "email_sent": true
        },
        "Accelerating Stable Diffusion Inference on Intel CPUs": {
            "url": "https://huggingface.co/blog/stable-diffusion-inference-intel",
            "description": null,
            "pubdate": "Tue, 28 Mar 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                3,
                28
            ],
            "email_sent": true
        },
        "Graph Classification with Transformers": {
            "url": "https://huggingface.co/blog/graphml-classification",
            "description": null,
            "pubdate": "Fri, 14 Apr 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                4,
                14
            ],
            "email_sent": true
        },
        "Training a language model with Transformers using TensorFlow and TPUs": {
            "url": "https://huggingface.co/blog/tf_tpu",
            "description": null,
            "pubdate": "Thu, 27 Apr 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                4,
                27
            ],
            "email_sent": true
        },
        "A Dive into Text-to-Video Models": {
            "url": "https://huggingface.co/blog/text-to-video",
            "description": null,
            "pubdate": "Mon, 08 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                8
            ],
            "email_sent": true
        },
        "Run a Chatgpt-like Chatbot on a Single GPU with ROCm": {
            "url": "https://huggingface.co/blog/chatbot-amd-gpu",
            "description": null,
            "pubdate": "Mon, 15 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                15
            ],
            "email_sent": true
        },
        "Introducing RWKV  An RNN with the advantages of a transformer": {
            "url": "https://huggingface.co/blog/rwkv",
            "description": null,
            "pubdate": "Mon, 15 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                15
            ],
            "email_sent": true
        },
        "Smaller is better: Q8-Chat, an efficient generative AI experience on Xeon": {
            "url": "https://huggingface.co/blog/generative-ai-models-on-intel-cpu",
            "description": null,
            "pubdate": "Tue, 16 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                16
            ],
            "email_sent": true
        },
        "Instruction-tuning Stable Diffusion with InstructPix2Pix": {
            "url": "https://huggingface.co/blog/instruction-tuning-sd",
            "description": null,
            "pubdate": "Tue, 23 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                23
            ],
            "email_sent": true
        },
        "Safetensors audited as really safe and becoming the default": {
            "url": "https://huggingface.co/blog/safetensors-security-audit",
            "description": null,
            "pubdate": "Tue, 23 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                23
            ],
            "email_sent": true
        },
        "Hugging Face Collaborates with Microsoft to Launch Hugging Face Model Catalog on Azure": {
            "url": "https://huggingface.co/blog/hugging-face-endpoints-on-azure",
            "description": null,
            "pubdate": "Wed, 24 May 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                5,
                24
            ],
            "email_sent": true
        },
        "Announcing the Open Source AI Game Jam ": {
            "url": "https://huggingface.co/blog/game-jam",
            "description": null,
            "pubdate": "Thu, 01 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Welcome fastText to the  Hub": {
            "url": "https://huggingface.co/blog/fasttext",
            "description": null,
            "pubdate": "Tue, 06 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "DuckDB: analyze 50,000+ datasets stored on the Hugging Face Hub": {
            "url": "https://huggingface.co/blog/hub-duckdb",
            "description": null,
            "pubdate": "Wed, 07 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "The Hugging Face Hub for Galleries, Libraries, Archives and Museums": {
            "url": "https://huggingface.co/blog/hf-hub-glam-guide",
            "description": null,
            "pubdate": "Mon, 12 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                12
            ],
            "email_sent": true
        },
        "Deploy Livebook notebooks as apps to Hugging Face Spaces": {
            "url": "https://huggingface.co/blog/livebook-app-deployment",
            "description": null,
            "pubdate": "Thu, 15 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                15
            ],
            "email_sent": true
        },
        "Yes, Transformers are Effective for Time Series Forecasting (+ Autoformer)": {
            "url": "https://huggingface.co/blog/autoformer",
            "description": null,
            "pubdate": "Fri, 16 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                16
            ],
            "email_sent": true
        },
        "AI Policy @: Response to the U.S. NTIA's Request for Comment on AI Accountability": {
            "url": "https://huggingface.co/blog/policy-ntia-rfc",
            "description": null,
            "pubdate": "Tue, 20 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                20
            ],
            "email_sent": true
        },
        "Accelerating Vision-Language Models: BridgeTower on Habana Gaudi2": {
            "url": "https://huggingface.co/blog/bridgetower",
            "description": null,
            "pubdate": "Thu, 29 Jun 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "Deploy LLMs with Hugging Face Inference Endpoints": {
            "url": "https://huggingface.co/blog/inference-endpoints-llm",
            "description": null,
            "pubdate": "Tue, 04 Jul 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "Open-Source Text Generation & LLM Ecosystem at Hugging Face": {
            "url": "https://huggingface.co/blog/os-llms",
            "description": null,
            "pubdate": "Mon, 17 Jul 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Happy 1st anniversary  Diffusers!": {
            "url": "https://huggingface.co/blog/diffusers-turns-1",
            "description": null,
            "pubdate": "Thu, 20 Jul 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Huggy Lingo: Using Machine Learning to Improve Language Metadata on the Hugging Face Hub": {
            "url": "https://huggingface.co/blog/huggy-lingo",
            "description": null,
            "pubdate": "Wed, 02 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "Towards Encrypted Large Language Models with FHE": {
            "url": "https://huggingface.co/blog/encrypted-llm",
            "description": null,
            "pubdate": "Wed, 02 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "Deploy MusicGen in no time with Inference Endpoints": {
            "url": "https://huggingface.co/blog/run-musicgen-as-an-api",
            "description": null,
            "pubdate": "Fri, 04 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                4
            ],
            "email_sent": true
        },
        "Deploying Hugging Face Models with BentoML: DeepFloyd IF in Action": {
            "url": "https://huggingface.co/blog/deploy-deepfloydif-using-bentoml",
            "description": null,
            "pubdate": "Wed, 09 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "Making LLMs lighter with AutoGPTQ and transformers": {
            "url": "https://huggingface.co/blog/gptq-integration",
            "description": null,
            "pubdate": "Wed, 23 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                23
            ],
            "email_sent": true
        },
        "Deprecation of Git Authentication using password": {
            "url": "https://huggingface.co/blog/password-git-deprecation",
            "description": null,
            "pubdate": "Fri, 25 Aug 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Spread Your Wings: Falcon 180B is here": {
            "url": "https://huggingface.co/blog/falcon-180b",
            "description": null,
            "pubdate": "Wed, 06 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "Efficient Controllable Generation for SDXL with T2I-Adapters": {
            "url": "https://huggingface.co/blog/t2i-sdxl-adapters",
            "description": null,
            "pubdate": "Fri, 08 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "SafeCoder vs. Closed-source Code Assistants": {
            "url": "https://huggingface.co/blog/safecoder-vs-closed-source-code-assistants",
            "description": null,
            "pubdate": "Mon, 11 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "Overview of natively supported quantization schemes in  Transformers": {
            "url": "https://huggingface.co/blog/overview-quantization-transformers",
            "description": null,
            "pubdate": "Tue, 12 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "Fine-tuning Llama 2 70B using PyTorch FSDP": {
            "url": "https://huggingface.co/blog/ram-efficient-pytorch-fsdp",
            "description": null,
            "pubdate": "Wed, 13 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Optimizing your LLM in production": {
            "url": "https://huggingface.co/blog/optimize-llm",
            "description": null,
            "pubdate": "Fri, 15 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        },
        "Non-engineers guide: Train a LLaMA 2 chatbot": {
            "url": "https://huggingface.co/blog/Llama2-for-non-engineers",
            "description": null,
            "pubdate": "Thu, 28 Sep 2023 00:00:00 GMT",
            "pubdate_parsed": [
                2023,
                9,
                28
            ],
            "email_sent": true
        }
    },
    "Sorta Insightful": {
        "A Prelude to the Inevitable Long Post About MIT Mystery Hunt 2023": {
            "url": "http://www.alexirpan.com/2023/01/19/mh-2023-prelude.html",
            "description": "<p>The first time I ever wrote for a puzzlehunt was Mystery Hunt 2013. I had joined Manic Sages in 2012 out of the Canada/USA Mathcamp pipeline. They won that year, and I figured, hey, I\u2019ll help write, why not. Writing sounds fun! I helped out on two puzzles. One was...",
            "pubdate": "Thu, 19 Jan 2023 23:32:00 -0800",
            "pubdate_parsed": [
                2023,
                1,
                20
            ],
            "email_sent": true
        },
        "A Botes Shaped Addendum to Writing Mystery Hunt 2023": {
            "url": "http://www.alexirpan.com/2023/05/09/bootes-2023.html",
            "description": "<p>I promise this will not be as long as the <a href=\"https://www.alexirpan.com/2023/04/21/mh-2023.html\">previous post</a>,\nbut I will assume you\u2019ve read it.</p>",
            "pubdate": "Tue, 09 May 2023 01:34:00 -0700",
            "pubdate_parsed": [
                2023,
                5,
                9
            ],
            "email_sent": true
        },
        "Machine Learning Got Itself in a Big Damn Hurry": {
            "url": "http://www.alexirpan.com/2023/07/19/ml-hurry.html",
            "description": "<p>Three months ago, I was at an \u201cIntersection of AI and My Little Pony Fandom\u201d panel. It was a panel about the ways the MLP fandom has used AI to generate creative work, starting from finetuned GPT-2 in 2020, through voice synthesis via <a href=\"https://twitter.com/fifteenai?lang=en\">15.ai</a>, and ending with, of course,...",
            "pubdate": "Wed, 19 Jul 2023 04:41:00 -0700",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "Eight Years Later": {
            "url": "http://www.alexirpan.com/2023/08/18/eight-years.html",
            "description": "<p><em>Sorta Insightful</em> turns eight years old today!</p>",
            "pubdate": "Fri, 18 Aug 2023 00:00:01 -0700",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "Everfree Northwest 2023": {
            "url": "http://www.alexirpan.com/2023/09/05/efnw-2023.html",
            "description": "<p><a href=\"https://everfreenw.com\">Everfree Northwest</a> is a My Little Pony convention in the Seattle area. It\u2019s been running for\n11 years and counting.</p>",
            "pubdate": "Tue, 05 Sep 2023 00:02:16 -0700",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        }
    },
    "Azure-MLOps": {},
    "Emergent Mind": {
        "Public school bans on AI tools like ChatGPT raise fears private school kids are gaining an unfair edge and widening a digital divide - ABC News": {
            "url": "https://www.emergentmind.com/posts/public-school-bans-on-ai-tools-like-chatgpt-raise-fears",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI tools like ChatGPT are banned in most Australian public schools, raising fears that private school students are gaining an unfair advantage.</li>\n      <li>Education ministers are expected to discuss the issue in a meeting in July, while some experts argue that AI can help reduce teacher workload and improve learning outcomes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.abc.net.au/news/2023-05-26/artificial-intelligence-chatgpt-classrooms-schools/102356926\">Public school bans on AI tools like ChatGPT raise fears private school kids are gaining an unfair edge and widening a digital divide - ABC News</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 06:01:35 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "AgentGPT": {
            "url": "https://www.emergentmind.com/posts/agentgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AgentGPT allows users to create and deploy autonomous AI agents in their browser.</li>\n      <li>Users can easily create an agent by adding a name, setting a goal, and deploying it.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://agentgpt.reworkd.ai/\">AgentGPT</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 06:01:31 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Everything You Need to Know About the Role of an AI Engineer - Today Business Posts": {
            "url": "https://www.emergentmind.com/posts/everything-you-need-to-know-about-the-role-of-an-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI engineers combine artificial intelligence and engineering principles to create intelligent systems that can learn and adapt.</li>\n      <li>These professionals are in high demand, working in various industries and specializing in areas such as natural language processing, computer vision, and robotics.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://todaybusinessposts.com/everything-you-need-to-know-about-the-role-of-an-ai-engineer/\">Everything You Need to Know About the Role of an AI Engineer - Today Business Posts</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 04:04:23 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "MIT MAS.S68": {
            "url": "https://www.emergentmind.com/posts/mit-mas-s68-generative-ai-for-constructive",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The course focuses on the advancements in large language models like ChatGPT and their impact on communication technology.</li>\n      <li>Students will engage in guided discussions, hands-on experimentation, project critiques, and can choose between completing a project or producing a research project proposal.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ai4comm.media.mit.edu/\">MIT MAS.S68</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 04:04:14 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "SnapChat Server Down: Thousands of user report C14A Error code - What is support code c14a on snapchat ?": {
            "url": "https://www.emergentmind.com/posts/snapchat-server-down-thousands-of-user-report-c14a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Snapchat users are experiencing a temporary outage known as the C14A error code, preventing them from accessing the app.</li>\n      <li>Snapchat has dealt with this issue before and offers troubleshooting tips to help users regain access to their accounts.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bikeflame.com/2023/05/snapchat-server-down-thousands-of-user.html\">SnapChat Server Down: Thousands of user report C14A Error code - What is support code c14a on snapchat ?</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 03:01:59 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "The False Promise of Imitating Proprietary LLMs": {
            "url": "https://www.emergentmind.com/posts/2305-15717-the-false-promise-of-imitating-proprietary",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Finetuning weaker language models on stronger ones like ChatGPT can produce convincing outputs but fails to close the capability gap.</li>\n      <li>Imitation models can mimic the style of ChatGPT but not its factuality, making it a false promise for improving open-source models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.15717\">The False Promise of Imitating Proprietary LLMs</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 03:01:57 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Majority of Americans have heard of ChatGPT, but few have tried it": {
            "url": "https://www.emergentmind.com/posts/majority-of-americans-have-heard-of-chatgpt-but-few",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Nearly six-in-ten adults in the US are familiar with ChatGPT, an open-access online chatbot.</li>\n      <li>Only 14% have tried using it for entertainment, learning, or work purposes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.pewresearch.org/short-reads/2023/05/24/a-majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/\">Majority of Americans have heard of ChatGPT, but few have tried it</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 01:01:27 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #17 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-17-by-zoltan-tapi",
            "description": "<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-17\">Weekly Piece of Future #17 - by Zoltan Tapi</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 13:26:10 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Voyager: An Open-Ended Embodied Agent with Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2305-16291-voyager-an-open-ended-embodied-agent-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Voyager is an autonomous lifelong learning agent in Minecraft that constantly explores, learns new skills, and makes discoveries.</li>\n      <li>It features an automatic curriculum, an expanding skill library, and an iterative prompting mechanism to improve program execution.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.16291\">Voyager: An Open-Ended Embodied Agent with Large Language Models</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 13:26:08 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "ChatGPT Shared Links FAQ": {
            "url": "https://www.emergentmind.com/posts/chatgpt-shared-links-faq-openai-help-center",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT now has a shared links feature, allowing users to generate a unique URL for a conversation and share it with others.</li>\n      <li>Shared links can be used for sharing specific conversations or messages, collaborating with external parties, and creating reference points for future discussions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://help.openai.com/en/articles/7925741-chatgpt-shared-links-faq\">ChatGPT Shared Links FAQ</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 12:02:39 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Model evaluation for extreme risks": {
            "url": "https://www.emergentmind.com/posts/2305-15324-model-evaluation-for-extreme-risks",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Current general-purpose AI systems can have both beneficial and harmful capabilities, posing extreme risks.</li>\n      <li>Dangerous capability evaluations and alignment evaluations are essential for responsible AI development, deployment, and security.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.15324\">Model evaluation for extreme risks</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 11:02:48 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "How to Make Money with ChatGPT: Unlocking Profitable Opportunities - Global News Bulletin": {
            "url": "https://www.emergentmind.com/posts/how-to-make-money-with-chatgpt-unlocking-profitable",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is an advanced language model developed by OpenAI that can be used to generate income in various fields including content creation, customer support, and personalized recommendations.</li>\n      <li>Possible monetization strategies include consultation services, content creation and writing services, ChatGPT-powered products, affiliate marketing, and training and customization.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://globenewsbulletin.com/information/how-to-make-money-with-chatgpt/\">How to Make Money with ChatGPT: Unlocking Profitable Opportunities - Global News Bulletin</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 10:01:27 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Eating Disorder Helpline Fires Staff, Transitions to Chatbot After Unionization": {
            "url": "https://www.emergentmind.com/posts/eating-disorder-helpline-fires-staff-transitions-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>National Eating Disorders Association replaces helpline workers with chatbot named Tessa after they unionized</li>\n      <li>Tessa has been in operation since February 2022 and will become the main support system available through NEDA starting June 1</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.vice.com/en/article/n7ezkm/eating-disorder-helpline-fires-staff-transitions-to-chatbot-after-unionization\">Eating Disorder Helpline Fires Staff, Transitions to Chatbot After Unionization</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 08:01:36 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2305-12544-a-phd-student-s-perspective-on-research-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models have led to many generative NLP applications, but also a misleading belief that 'it's all been solved.'</li>\n      <li>PhD students in an academic research lab compiled a list of rich NLP research areas to explore, inviting suggestions for additional areas.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.12544\">A PhD Student's Perspective on Research in NLP in the Era of Very Large Language Models</a>\n</p>",
            "pubdate": "Fri, 26 May 2023 08:01:35 +0000",
            "pubdate_parsed": [
                2023,
                5,
                26
            ],
            "email_sent": true
        },
        "Why are we going to need a private and custom personal AI  Falconius": {
            "url": "https://www.emergentmind.com/posts/why-are-we-going-to-need-a-private-and-custom-personal",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The growth of language models like ChatGPT has led to the possibility of a universal language API for communicating with software applications.</li>\n      <li>A private, personal AI could help users negotiate and make choices based on their preferences, but using platforms from major companies could lead to data privacy concerns and less negotiation leverage.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://falconius.com/index.php/2023/05/26/why-are-we-going-to-need-a-private-and-custom-personal-ai/\">Why are we going to need a private and custom personal AI \u2013 Falconius</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 03:05:33 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Hacker News Community Insights": {
            "url": "https://www.emergentmind.com/posts/hacker-news-community-insights",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Hacker News is a social news website focusing on computer science and entrepreneurship, created by Y Combinator co-founder Paul Graham.</li>\n      <li>The community includes tech-savvy individuals from various backgrounds, such as software engineers, entrepreneurs, and data scientists, and encourages respectful, insightful discussions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/66169853-d00a-4b05-abce-8f82c6d8c868\">Hacker News Community Insights</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 03:01:24 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Large Language Models are Few-Shot Health Learners": {
            "url": "https://www.emergentmind.com/posts/2305-15525-large-language-models-are-few-shot-health",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models can be tuned to understand physiological and behavioral time-series data.</li>\n      <li>These models can make meaningful inferences on health tasks like cardiac signal analysis, physical activity recognition, and mental health screening.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.15525\">Large Language Models are Few-Shot Health Learners</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 02:01:37 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "First open-source data discovery and observability platform. We make a life for data practitioners easy so you can focus on your business.": {
            "url": "https://www.emergentmind.com/posts/github-opendatadiscovery-odd-platform-first",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ODD operates various types of entities such as Datasets, Transformers, Data Consumers, Data Quality Tests, Data Inputs, Transformer Runs, and Quality Test Runs.</li>\n      <li>For more information and community support, visit their GitHub and Slack channels.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/opendatadiscovery/odd-platform\">First open-source data discovery and observability platform. We make a life for data practitioners easy so you can focus on your business.</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 01:02:08 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Landmark Attention: Random-Access Infinite Context Length for Transformers": {
            "url": "https://www.emergentmind.com/posts/2305-16300-landmark-attention-random-access-infinite",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers present a new approach to improve transformers' memory capabilities by using landmark tokens to represent blocks of input.</li>\n      <li>This method allows access to the entire context while maintaining random-access flexibility, achieving comparable performance with Transformer-XL and extending context length capacity of LLaMA 7B up to 32k tokens.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.16300\">Landmark Attention: Random-Access Infinite Context Length for Transformers</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 00:03:25 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training": {
            "url": "https://www.emergentmind.com/posts/2305-14342-sophia-a-scalable-stochastic-second-order",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Sophia is a new second-order clipped stochastic optimization algorithm that improves language model training efficiency.</li>\n      <li>The optimizer achieves a 2x speed-up compared to Adam and adapts to the curvature in different components of the parameters.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.14342\">Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 00:03:21 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Dream of creating your own game comes true with artificial intelligence - Podcasts - California18": {
            "url": "https://www.emergentmind.com/posts/dream-of-creating-your-own-game-comes-true-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial intelligence system ChatGPT helps users create video games without specific knowledge.</li>\n      <li>Graphic designer Erick Teixeira uses ChatGPT to develop his own game.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://california18.com/dream-of-creating-your-own-game-comes-true-with-artificial-intelligence-podcasts/11141542023/\">Dream of creating your own game comes true with artificial intelligence - Podcasts - California18</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 13:02:07 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Digital Overlords? Nah, Weve Got This!": {
            "url": "https://www.emergentmind.com/posts/digital-overlords-nah-we-ve-got-this-by-daniel",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article explores the concept of collective human intelligence in the age of artificial intelligence and digitally sentient entities.</li>\n      <li>The author, a computer scientist and anthropologist, shares their personal perspective on the future of AI based on their research experience.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/technology-past-present-and-future/digital-overlords-nah-weve-got-this-79602600bc6e\">Digital Overlords? Nah, We\u2019ve Got This!</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 11:02:53 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "WordPress and Drupal Co-Founders Discuss Open Source, AI, and the Future of the Web  WP Tavern": {
            "url": "https://www.emergentmind.com/posts/wordpress-and-drupal-co-founders-discuss-open-source",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>WordPress co-founders Matt Mullenweg and Mike Little join Drupal founder Dries Buytaert to discuss the benefits of open source collaboration and its future.</li>\n      <li>Mullenweg is optimistic about AI working with open source and believes that proprietary software competitors will eventually run on open source software.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://wptavern.com/wordpress-and-drupal-co-founders-discuss-open-source-ai-and-the-future-of-the-web\">WordPress and Drupal Co-Founders Discuss Open Source, AI, and the Future of the Web \u2013 WP Tavern</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 11:02:50 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation": {
            "url": "https://www.emergentmind.com/posts/gpt-4-is-vulnerable-to-prompt-injection-attacks-on",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT's GPT-4 model, despite its improved information accuracy, is still vulnerable to providing misinformation through prompt injection attacks.</li>\n      <li>By manipulating role tags in the OpenAI API, users can guide the model into providing false information, creating a potential loophole for spreading misinformation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.kdnuggets.com/2023/05/gpt4-vulnerable-prompt-injection-attacks-causing-misinformation.html\">GPT-4 is Vulnerable to Prompt Injection Attacks on Causing Misinformation</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 09:39:41 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Podcast Q&A and Info": {
            "url": "https://www.emergentmind.com/posts/podcast-q-a-and-info",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Crowdcast, an interactive AI-generated podcast, covers a wide range of topics including the positive aspects of the dark web, the possibility of extraterrestrial life, and conspiracy theories surrounding The Great British Bake-Off.</li>\n      <li>The podcast is made by Adam Tal, with episodes generated using AI and content derived from top comments on the /r/crowdcast subreddit.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/a98e19cc-151c-4e64-9a48-a73097e73a36\">Podcast Q&amp;A and Info</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 08:01:28 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "A Lawyer's Filing \"Is Replete with Citations to Non-Existent Cases\" -- Thanks, ChatGPT?": {
            "url": "https://www.emergentmind.com/posts/a-lawyer-s-filing-is-replete-with-citations-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A lawyer faces possible sanctions after citing nonexistent cases in court, which were provided by an AI tool called ChatGPT.</li>\n      <li>The lawyer relied on the AI-generated cases without verifying their authenticity, leading to an order to show cause why he shouldn't be sanctioned.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://reason.com/volokh/2023/05/27/a-lawyers-filing-is-replete-with-citations-to-non-existent-cases-thanks-chatgpt/\">A Lawyer's Filing &quot;Is Replete with Citations to Non-Existent Cases&quot; -- Thanks, ChatGPT?</a>\n</p>",
            "pubdate": "Sat, 27 May 2023 07:01:56 +0000",
            "pubdate_parsed": [
                2023,
                5,
                27
            ],
            "email_sent": true
        },
        "Code ChatGPT Plugin is a TypeScript Code Analyzer that enables ChatGPT to \"talk\" with YOUR code": {
            "url": "https://www.emergentmind.com/posts/github-kesor-chatgpt-code-plugin-code-chatgpt-plugin",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Code ChatGPT Plugin is a TypeScript Code Analyzer that helps ChatGPT interact with your code.</li>\n      <li>It provides utilities to analyze TypeScript code, fetch file lists, find functions, and get specific function content.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/kesor/chatgpt-code-plugin\">Code ChatGPT Plugin is a TypeScript Code Analyzer that enables ChatGPT to &quot;talk&quot; with YOUR code</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 02:01:40 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "Australian Medical Association calls for national regulations around AI in health care - ABC News": {
            "url": "https://www.emergentmind.com/posts/australian-medical-association-calls-for-national",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Australian Medical Association calls for national regulations on AI use in healthcare due to concerns about patient confidentiality.</li>\n      <li>Perth's South Metropolitan Health Service ordered doctors to stop using AI tools like ChatGPT for patient notes, fearing security risks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.abc.net.au/news/2023-05-28/ama-calls-for-national-regulations-for-ai-in-health/102381314\">Australian Medical Association calls for national regulations around AI in health care - ABC News</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 01:01:37 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "aider is GPT-4 powered coding in your terminal": {
            "url": "https://www.emergentmind.com/posts/github-paul-gauthier-aider-aider-is-gpt-4-powered",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>aider is a chat-based tool that allows users to collaborate with GPT-4 on code projects and supports various commands for file management, committing changes, and running shell commands.</li>\n      <li>While GPT-4 can assist with code editing and fixing bugs, it has limitations such as requiring GPT-4 API access and working only with code that fits within its context window.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/paul-gauthier/aider\">aider is GPT-4 powered coding in your terminal</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 13:01:59 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "Python image tiling library for image processing, object detection, etc.": {
            "url": "https://www.emergentmind.com/posts/github-kalfasyan-plakakia-python-image-tiling",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A Python library for image tiling that considers bounding boxes inside the image.</li>\n      <li>Supports rectangular tiles, overlapping tiles and duplicate bounding box avoidance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/kalfasyan/plakakia\">Python image tiling library for image processing, object detection, etc.</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 08:07:33 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "xorvoid": {
            "url": "https://www.emergentmind.com/posts/xorvoid",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is a powerful AI language model that excels at producing average answers across a wide range of topics, but lacks a deep understanding or mental model of the world.</li>\n      <li>Despite concerns about job losses and economic upheaval, ChatGPT is more likely to spur innovation and multidisciplinary projects, similar to how previous technological advances have transformed industries.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://xorvoid.com/chatgpt_a_mental_model.html\">xorvoid</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 08:01:26 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python": {
            "url": "https://www.emergentmind.com/posts/2305-15507-the-larger-they-are-the-harder-they-fail",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) fail to generate correct Python code when default function names are changed.</li>\n      <li>As model size increases, some LLMs become more confident in incorrect predictions, a phenomenon called Inverse Scaling.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.15507\">The Larger They Are, the Harder They Fail: Language Models do not Recognize Identifier Swaps in Python</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 07:01:50 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "The Smallest Units of Introspection": {
            "url": "https://www.emergentmind.com/posts/the-smallest-units-of-introspection-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the challenges in developing a theory of Artificial General Intelligence (AGI) and investigates the cognitive aspects of the mind through introspection.</li>\n      <li>It emphasizes the importance of understanding individual thoughts as momentary, sequential units of action and suggests that the conscious, introspective self is an ever-progressing series of thoughts reacting to thoughts.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/the-smallest-units-of-introspection-fbdc565f4201\">The Smallest Units of Introspection</a>\n</p>",
            "pubdate": "Sun, 28 May 2023 04:03:44 +0000",
            "pubdate_parsed": [
                2023,
                5,
                28
            ],
            "email_sent": true
        },
        "Using AI, scientists find a drug that could combat drug-resistant infections": {
            "url": "https://www.emergentmind.com/posts/using-ai-scientists-find-a-drug-that-could-combat",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers at MIT and McMaster University used a machine-learning algorithm to identify a compound that can kill Acinetobacter baumannii, a drug-resistant bacterium found in hospitals.</li>\n      <li>The compound, named abaucin, was discovered from a library of nearly 7,000 potential drug compounds and could combat infections such as pneumonia, meningitis, and infections in wounded soldiers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://news.mit.edu/2023/using-ai-scientists-combat-drug-resistant-infections-0525\">Using AI, scientists find a drug that could combat drug-resistant infections</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 13:01:45 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Power Analysis Seminar Recap": {
            "url": "https://www.emergentmind.com/posts/power-analysis-seminar-recap",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A Power Analysis seminar featuring Robert Greene and Dan Linden focuses on applying the '48 Laws of Power' to analyze a spiritual influencer's tweet, revealing the power dynamics at play.</li>\n      <li>Participants dissect the tweet using various laws, highlighting the influencer's tactics such as concealing intentions, courting attention, and playing on people's need to believe.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/c69b4edd-d0de-4401-9611-6a933be6e9b8\">Power Analysis Seminar Recap</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 11:04:13 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Shark Tank Simulator": {
            "url": "https://www.emergentmind.com/posts/shark-tank-simulator",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GameGPT transforms into a virtual host for a Shark Tank simulator game, where players pitch their ideas to successful investors, aiming to secure a deal.</li>\n      <li>Players provide their company name, product description, and investment request, then engage in a dialogue with the 'Sharks', who ask questions, make offers, or decline deals.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/48155efe-101b-4662-b41e-c13aa909f017\">Shark Tank Simulator</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 10:01:38 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Production AI systems are really hard - by Kevin Fischer": {
            "url": "https://www.emergentmind.com/posts/production-ai-systems-are-really-hard-by-kevin",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI systems are complex and cannot easily replace jobs that require extensive training, like radiologists.</li>\n      <li>Factors such as domain knowledge, data availability, and regulatory environment make it difficult to create viable AI adoption strategies.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://methexis.substack.com/p/production-ai-systems-are-really\">Production AI systems are really hard - by Kevin Fischer</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 09:01:48 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "10% Less Stagnation - by Bryan Caplan - Bet On It": {
            "url": "https://www.emergentmind.com/posts/10-less-stagnation-by-bryan-caplan-bet-on-it",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI advancements may affect student workload and evaluation, making cheating easier and exams more crucial.</li>\n      <li>AI could disrupt various industries including computer science, alter career aspirations, and impact academic research.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://betonit.substack.com/p/how-ai-will-change-higher-education\">10% Less Stagnation - by Bryan Caplan - Bet On It</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 09:01:46 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Subredditstatistic - Statistics for every subreddit of Reddit.com": {
            "url": "https://www.emergentmind.com/posts/subredditstatistic-statistics-for-every-subreddit-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A community of machine learning enthusiasts, researchers, journalists, and writers sharing interesting news and articles about AI applications.</li>\n      <li>Stay updated on ML, AI, CV, and NLP fields with daily posts from around the world.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://subredditstatistics.com/r/machinelearningnews\">Subredditstatistic - Statistics for every subreddit of Reddit.com</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 07:01:37 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Nvidia ACE Brings AI to Game Characters, Allows Lifelike Conversations": {
            "url": "https://www.emergentmind.com/posts/nvidia-ace-brings-ai-to-game-characters-allows",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Nvidia unveils ACE for Games, an AI model foundry service to make game characters more interactive with natural language conversation, audio-to-facial-expression, and text-to-speech capabilities.</li>\n      <li>ACE for Games uses Nvidia NeMo, Riva, and Omniverse Audio2Face to enable seamless interaction between human players and NPC game characters.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.tomshardware.com/news/nvidia-ace-brings-npcs-to-life\">Nvidia ACE Brings AI to Game Characters, Allows Lifelike Conversations</a>\n</p>",
            "pubdate": "Mon, 29 May 2023 04:03:01 +0000",
            "pubdate_parsed": [
                2023,
                5,
                29
            ],
            "email_sent": true
        },
        "Set Up and Run OpenAI's CLIP on Amazon SageMaker for Inference": {
            "url": "https://www.emergentmind.com/posts/set-up-and-run-openai-s-clip-on-amazon-sagemaker-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Learn how to deploy and run OpenAI's CLIP model on Amazon SageMaker for efficient real-time and offline inference.</li>\n      <li>This tutorial covers the steps required to create an endpoint for real-time inference and use SageMaker's Batch Transform feature for offline inference.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rise.climb.dev/clip-on-sagemaker/\">Set Up and Run OpenAI's CLIP on Amazon SageMaker for Inference</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 03:01:36 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "one-click deepfake (face swap)": {
            "url": "https://www.emergentmind.com/posts/github-s0md3v-roop-one-click-deepfake-face-swap",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AMD provides ROCM-based torch packages for face swapping applications.</li>\n      <li>ONNX Runtime can be used for executing the face swapping process in both GUI and CLI mode.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/s0md3v/roop\">one-click deepfake (face swap)</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 01:01:37 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Australian tech unicorn Employment Hero takes on Seek": {
            "url": "https://www.emergentmind.com/posts/australian-tech-unicorn-employment-hero-takes-on-seek",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Employment Hero launched an AI hiring tool called Swag to help small-and-medium-sized enterprises with recruitment.</li>\n      <li>Swag can create job descriptions, predict hiring needs, match candidates with roles, and post jobs to job boards.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.forbes.com.au/news/innovation/australian-tech-unicorn-employment-hero-takes-on-seek/\">Australian tech unicorn Employment Hero takes on Seek</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 01:01:36 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "EmailWizard by PromptChainer": {
            "url": "https://www.emergentmind.com/posts/emailwizard-by-promptchainer",
            "description": "<p>\n  Full article: <a href=\"https://emailwizard.promptchainer.io/\">EmailWizard by PromptChainer</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 13:02:11 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Text In AI-Generated Images Just Got Better": {
            "url": "https://www.emergentmind.com/posts/text-in-ai-generated-images-just-got-better-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative AI has improved significantly, resulting in better text and details in images.</li>\n      <li>Midjourney's V5 has shown notable enhancements in the hands department of generated images.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/text-in-ai-generated-images-just-got-better-2b8b8e5a2ba8?sk=aebe057a94801de39afe42d9a5b8b610\">Text In AI-Generated Images Just Got Better</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 12:01:55 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Statement on AI Risk": {
            "url": "https://www.emergentmind.com/posts/statement-on-ai-risk-cais",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI experts and public figures highlight the urgent need to address severe risks posed by advanced AI.</li>\n      <li>Mitigating AI-related extinction risks should be a global priority alongside pandemics and nuclear war.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.safe.ai/statement-on-ai-risk\">Statement on AI Risk</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 12:01:46 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Software company CEO says using ChatGPT cuts the time it takes to complete coding tasks from around 9 weeks to just a few days": {
            "url": "https://www.emergentmind.com/posts/software-company-ceo-says-using-chatgpt-cuts-the-time",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Freshworks employees use OpenAI's ChatGPT for coding, reducing task completion time from 9 weeks to a few days.</li>\n      <li>Generative AI's coding skills are making software development easier and more efficient across industries.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://africa.businessinsider.com/news/software-company-ceo-says-using-chatgpt-cuts-the-time-it-takes-to-complete-coding/mpfyey9\">Software company CEO says using ChatGPT cuts the time it takes to complete coding tasks from around 9 weeks to just a few days</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 11:03:07 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Revolutionizing Entity Extraction with Deep Learning & AI Solutions": {
            "url": "https://www.emergentmind.com/posts/revolutionizing-entity-extraction-with-deep-learning",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Futurism Technologies uses AI and Deep Learning to automate and optimize electrical installation planning process.</li>\n      <li>Generative AI has the potential to automatically design optimal electrical layouts and create 3D virtual representations of installations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.futurismtechnologies.com/blog/revolutionizing-entity-extraction-with-ai-and-deep-learning-a-futurism-innovation/\">Revolutionizing Entity Extraction with Deep Learning &amp; AI Solutions</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 10:01:51 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Capital letter test is a foolproof way of sorting AIs from humans": {
            "url": "https://www.emergentmind.com/posts/capital-letter-test-is-a-foolproof-way-of-sorting-ais",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A test using capital letters confuses AI models like ChatGPT, while humans can easily answer correctly.</li>\n      <li>The test involves questions with capital letters that change the meaning of words or create nonsense.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.shiningscience.com/2023/05/capital-letter-test-is-foolproof-way-of.html\">Capital letter test is a foolproof way of sorting AIs from humans</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 09:02:21 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Revolutionize Your UI/UX Design Process with Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/revolutionize-your-ui-ux-design-process-with-artificial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence (AI) is transforming UI/UX design by personalizing user experiences, streamlining workflows, and improving accessibility.</li>\n      <li>However, implementing AI in design also raises privacy concerns, potential biases, and the risk of losing the human touch.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://shakuro.com/blog/how-to-use-artificial-intelligence-in-ui-ux-design?utm_source=reddit&amp;utm_medium=how-to-use-artificial-intelligence-in-ui-ux-design&amp;utm_campaign=smm_sharing\">Revolutionize Your UI/UX Design Process with Artificial Intelligence</a>\n</p>",
            "pubdate": "Tue, 30 May 2023 09:02:15 +0000",
            "pubdate_parsed": [
                2023,
                5,
                30
            ],
            "email_sent": true
        },
        "Yoshua Bengio, often referred to as the godfather of AI, is experiencing a sense of being lost regarding his lifes work  The Daily New York": {
            "url": "https://www.emergentmind.com/posts/yoshua-bengio-often-referred-to-as-the-godfather-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI 'godfather' Yoshua Bengio expresses regret for not prioritizing safety and calls for AI regulation</li>\n      <li>Bengio wants military forces to be restricted from using AI capabilities and emphasizes the need for ethical training</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thedailyny.com/2023/05/31/yoshua-bengio-often-referred-to-as-the-godfather-of-ai-is-experiencing-a-sense-of-being-lost-regarding-his-lifes-work/\">Yoshua Bengio, often referred to as the \u2018godfather\u2019 of AI, is experiencing a sense of being \u2018lost\u2019 regarding his life\u2019s work \u2013 The Daily New York</a>\n</p>",
            "pubdate": "Wed, 31 May 2023 13:01:35 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "Train Your Own Private ChatGPT Model for the Cost of a Starbucks Coffee": {
            "url": "https://www.emergentmind.com/posts/train-your-own-private-chatgpt-model-for-the-cost-of-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>With just the cost of a Starbucks coffee and two hours of your time, you can train your own open-source large-scale model using Apache DolphinScheduler.</li>\n      <li>The model can be fine-tuned to enhance various skills, such as medical, programming, stock trading, and love advice, making it more understanding of the user.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@ApacheDolphinScheduler/train-your-own-private-chatgpt-model-for-the-cost-of-a-starbucks-coffee-25c588f450ee\">Train Your Own Private ChatGPT Model for the Cost of a Starbucks Coffee</a>\n</p>",
            "pubdate": "Wed, 31 May 2023 11:03:01 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "AI and IoT: Dynamic Duo Reshaping the Digital World": {
            "url": "https://www.emergentmind.com/posts/ai-and-iot-dynamic-duo-reshaping-the-digital-world",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The combination of artificial intelligence and the Internet of Things is transforming industries, economies, and businesses.</li>\n      <li>AI-integrated IoT enables intelligent machines that can make decisions with minimal human intervention.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.futurismtechnologies.com/blog/ai-and-iot-dynamic-duo-reshaping-the-digital-world/\">AI and IoT: Dynamic Duo Reshaping the Digital World</a>\n</p>",
            "pubdate": "Wed, 31 May 2023 09:02:03 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "Nvidia: chipmakers strategic AI moves result in a tech position of power": {
            "url": "https://www.emergentmind.com/posts/nvidia-chipmaker-s-strategic-ai-moves-result-in-a-tech",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Nvidia's valuation reaches $1tn after investing early in AI, making it the fifth most valuable American company</li>\n      <li>The company's chips now power various AI use cases, giving it an advantage over competitors.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/us-news/2023/may/30/nvidia-stock-price-ai-chipmaker-technology\">Nvidia: chipmaker\u2019s strategic AI moves result in a tech position of power </a>\n</p>",
            "pubdate": "Wed, 31 May 2023 09:02:00 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "ChatGPT boss wants HQ in Europe  POLITICO": {
            "url": "https://www.emergentmind.com/posts/chatgpt-boss-wants-hq-in-europe-politico",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Sam Altman, CEO of OpenAI, recently visited several European countries to discuss AI regulation with policymakers and scout locations for a potential European office.</li>\n      <li>OpenAI plans to comply with the upcoming EU Artificial Intelligence Act and join the EU's first AI regulatory sandbox in Spain.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.politico.eu/article/open-ai-chatgpt-sam-altman-kicks-off-eu-charm-offensive-artifical-intelligence/\">ChatGPT boss wants HQ in Europe \u2013 POLITICO</a>\n</p>",
            "pubdate": "Wed, 31 May 2023 08:02:02 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "Musk-Owned Swiss Lab Makes Paralysed Man Walk Again By Planting Chip Into His Brains - BT TV BusinessToday": {
            "url": "https://www.emergentmind.com/posts/musk-owned-swiss-lab-makes-paralysed-man-walk-again-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Elon Musk's company Neuralink announces approval for human clinical trials of brain chips</li>\n      <li>Swiss lab demonstrates breakthrough in technology by helping paralyzed man walk again</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.businesstoday.in/bt-tv/video/musk-owned-swiss-lab-makes-paralysed-man-walk-again-by-planting-chip-into-his-brains-383260-2023-05-29\">Musk-Owned Swiss Lab Makes Paralysed Man Walk Again By Planting Chip Into His Brains - BT TV BusinessToday</a>\n</p>",
            "pubdate": "Wed, 31 May 2023 04:02:29 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "Pawn Stars Similator": {
            "url": "https://www.emergentmind.com/posts/pawn-stars-similator",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Pawn Stars Simulator is an interactive game where players bring an item to the Gold and Silver Pawn Shop and negotiate a deal.</li>\n      <li>Players engage in conversation with employees from the show, such as Rick, Big Hoss, Chum Lee, or the Old Man, and work towards a successful deal or face rejection.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/e8af195f-58d5-4b46-a480-40cb41793ac5\">Pawn Stars Similator</a>\n</p>",
            "pubdate": "Wed, 31 May 2023 04:02:27 +0000",
            "pubdate_parsed": [
                2023,
                5,
                31
            ],
            "email_sent": true
        },
        "Prompts for playable games in ChatGPT": {
            "url": "https://www.emergentmind.com/posts/github-admtal-chat-gpt-games-prompts-for-playable",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT Games is a repository containing prompts for playable games that can be used with ChatGPT or other similar services.</li>\n      <li>The games, such as Shark Tank Simulator, test users' wit, negotiation skills, and creativity in various scenarios.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/AdmTal/chat-gpt-games\">Prompts for playable games in ChatGPT</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 01:01:41 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Building a Vector Database to Make Use of Vector Embeddings": {
            "url": "https://www.emergentmind.com/posts/building-a-vector-database-to-make-use-of-vector",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>TerminusDB creates a vector database to leverage vector embeddings for tasks such as full-text search, entity resolution, similarity search, and clustering.</li>\n      <li>The database uses OpenAI's embeddings and an HNSW graph for indexing vector spaces, providing semantic similarity for semantically close inputs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://terminusdb.com/blog/vector-database-and-vector-embeddings/\">Building a Vector Database to Make Use of Vector Embeddings</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 13:01:39 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Google Bard for Data Science Projects": {
            "url": "https://www.emergentmind.com/posts/google-bard-for-data-science-projects",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Bard was used to develop an end-to-end fake news detection project, including data preprocessing, feature engineering, model selection, and deployment.</li>\n      <li>The project utilized the Fake News Classification dataset and used Bard to create a Streamlit web app for predictions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.datacamp.com/blog/google-bard-for-data-science-projects\">Google Bard for Data Science Projects</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 11:21:13 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Vector": {
            "url": "https://www.emergentmind.com/posts/vector-the-open-source-vector-toolkit-for-postgres",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Supabase enables automatic provisioning and configuration of applications across multiple regions to reduce read latency and improve performance.</li>\n      <li>It uses open source tools for increased portability, ensuring data safety with automatic backups and Point In Time Recovery.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://supabase.com/vector\">Vector</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 11:03:21 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Africa will be transformed by the potential of AI and data  if we can get investment": {
            "url": "https://www.emergentmind.com/posts/africa-will-be-transformed-by-the-potential-of-ai-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Africa has the potential to transform through AI and data with a growing population and increasing investments.</li>\n      <li>The continent is predicted to see the fastest growth in AI spending worldwide, reaching $6.4bn by 2026.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/commentisfree/2023/jun/01/africa-will-be-transformed-by-the-potential-of-ai-and-data-if-we-can-get-investment\">Africa will be transformed by the potential of AI and data \u2013 if we can get investment</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 11:03:19 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Opinion": {
            "url": "https://www.emergentmind.com/posts/opinion-a-i-technology-8-questions-about-the-future",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial creativity is the focus as computers feel more creative than ever before.</li>\n      <li>Five practitioners discuss their experiences and opinions on AI, and a European art collective uses AI-generated video to visualize their answers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nytimes.com/interactive/2023/06/01/opinion/ai-technology-future.html?unlocked_article_code=nsQ_VVprfQA6SmFqRT4iO9VPSHiHw1z0g9rBRpANavn1PkU_9rlHmxPhzZsjZPt2ztaeRX5XmdHwIaFPkdPPU6V2wqQIDg_CEdJiMshhwoDRcfHB02KgPmTdIUg1EvSFlO5lqGyye40RNFcH3qUDfMbmG0vnaRT_QuJX2NSczR9QgsKvhcI9iz__2RKxZ3_W8hbUcw7A5cbHwmJpDAOvSkFLzCEPBAVRfiKeu44eXOQTC3KjtczITJ6LGfiIrVgmQGPMWnybi4KLXp6jDd0ZiJJu1urm97Ac0-vVs5rwfpPHqNC6pjz-ec0SB0hQ808W96BnmVkoZ5ocRp9TPVYVThJPoujwNw6u8iL5Afc88A\">Opinion</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 10:01:53 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Techniques for training large neural networks": {
            "url": "https://www.emergentmind.com/posts/techniques-for-training-large-neural-networks",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large neural networks require complex engineering to train, involving GPU clusters and synchronized calculations.</li>\n      <li>Parallelism techniques such as data, pipeline, tensor parallelism, and mixture-of-experts help distribute training across multiple GPUs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/techniques-for-training-large-neural-networks\">Techniques for training large neural networks</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:08 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "AI-written critiques help humans notice flaws": {
            "url": "https://www.emergentmind.com/posts/ai-written-critiques-help-humans-notice-flaws",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI models trained to write critiques can help humans identify more flaws in summaries</li>\n      <li>Larger models are better at self-critiquing, showing promise for AI-assisted human supervision</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/critiques\">AI-written critiques help humans notice flaws</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:07 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "DALLE 2 pre-training mitigations": {
            "url": "https://www.emergentmind.com/posts/dall-e-2-pre-training-mitigations",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>DALL-E 2 implements pre-training mitigations to reduce risks associated with powerful image generation models, including filtering out violent and sexual content.</li>\n      <li>The filtering process can amplify biases in training data, so techniques are used to mitigate this effect and prevent the model from being more biased than the unfiltered version.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/dall-e-2-pre-training-mitigations\">DALL\u00b7E 2 pre-training mitigations</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:04 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "A research agenda for assessing the economic impacts of code generation models": {
            "url": "https://www.emergentmind.com/posts/a-research-agenda-for-assessing-the-economic-impacts-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI is creating a research program to analyze the economic effects of code generation models, such as its own Codex, on individuals, firms, and society.</li>\n      <li>The program aims to study the impacts of these models on productivity, employment, skill development, inter-firm competition, consumer prices, and economic inequality, and invites external researchers to collaborate.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/economic-impacts\">A research agenda for assessing the economic impacts of code generation models</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:03 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Scaling laws for reward model overoptimization": {
            "url": "https://www.emergentmind.com/posts/scaling-laws-for-reward-model-overoptimization",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers investigate the relationship between optimizing against proxy reward models and gold-standard reward models in reinforcement learning.</li>\n      <li>The study examines the effects of various factors, such as dataset size and policy parameters, on this relationship and explores its implications for AI alignment.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/scaling-laws-for-reward-model-overoptimization\">Scaling laws for reward model overoptimization</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:02 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Efficient training of language models to fill in the middle": {
            "url": "https://www.emergentmind.com/posts/efficient-training-of-language-models-to-fill-in-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Autoregressive language models can learn to infill text by simply moving a span of text from the middle of a document to its end.</li>\n      <li>Training models with a large fraction of transformed data doesn't harm the original left-to-right generative capability, and is useful, simple, and efficient.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/efficient-training-of-language-models-to-fill-in-the-middle\">Efficient training of language models to fill in the middle</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:01 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Teaching models to express their uncertainty in words": {
            "url": "https://www.emergentmind.com/posts/teaching-models-to-express-their-uncertainty-in-words",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A GPT-3 model can generate answers and express its confidence levels about its own answers in natural language.</li>\n      <li>The model remains calibrated under distribution shift and is sensitive to uncertainty in its own answers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/teaching-models-to-express-their-uncertainty-in-words\">Teaching models to express their uncertainty in words</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:02:00 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "A hazard analysis framework for code synthesis large language models": {
            "url": "https://www.emergentmind.com/posts/a-hazard-analysis-framework-for-code-synthesis-large",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI has created a hazard analysis framework to assess the safety risks of large language models (LLMs) like Codex in various aspects.</li>\n      <li>The framework evaluates advanced code generation techniques based on their complexity and expressivity, and their capability to understand and execute prompts compared to human ability.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/a-hazard-analysis-framework-for-code-synthesis-large-language-models\">A hazard analysis framework for code synthesis large language models</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Learning to play Minecraft with Video PreTraining": {
            "url": "https://www.emergentmind.com/posts/learning-to-play-minecraft-with-video-pretraining",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A neural network was trained to play Minecraft using a semi-supervised imitation learning method called Video PreTraining (VPT) on a massive unlabeled video dataset of human gameplay.</li>\n      <li>The model can learn complex tasks such as crafting diamond tools and represents a step towards general computer-using agents.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/vpt\">Learning to play Minecraft with Video PreTraining</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Point-E: A system for generating 3D point clouds from complex prompts": {
            "url": "https://www.emergentmind.com/posts/point-e-a-system-for-generating-3d-point-clouds-from",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Point-E is a new method for generating 3D models from text prompts, producing results in 1-2 minutes on a single GPU.</li>\n      <li>Though sample quality is lower than state-of-the-art methods, its speed offers a practical trade-off for certain use cases.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/point-e\">Point-E: A system for generating 3D point clouds from complex prompts</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:55 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Evolution through large models": {
            "url": "https://www.emergentmind.com/posts/evolution-through-large-models",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models (LLMs) trained to generate code can significantly improve the effectiveness of mutation operators in genetic programming (GP).</li>\n      <li>Using evolution through large models (ELM), researchers successfully generated hundreds of thousands of functional Python programs that produced working ambulating robots in the Sodarace domain.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/evolution-through-large-models\">Evolution through large models</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:54 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "GPTs are GPTs: An early look at the labor market impact potential of large language models": {
            "url": "https://www.emergentmind.com/posts/gpts-are-gpts-an-early-look-at-the-labor-market-impact",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by Generative Pre-trained Transformers (GPTs).</li>\n      <li>Around 19% of workers may see at least 50% of their tasks impacted, spanning all wage levels and not limited to industries with higher recent productivity growth.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/gpts-are-gpts\">GPTs are GPTs: An early look at the labor market impact potential of large language models</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:52 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Whisper": {
            "url": "https://www.emergentmind.com/posts/introducing-whisper",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Whisper is a neural net that provides human-level accuracy in English speech recognition.</li>\n      <li>Trained on 680,000 hours of multilingual and multitask supervised data, it offers improved robustness to accents, background noise, and technical language.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/whisper\">Introducing Whisper</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:51 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk": {
            "url": "https://www.emergentmind.com/posts/forecasting-potential-misuses-of-language-models-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI collaborates with Georgetown University and Stanford Internet Observatory to study potential misuses of large language models for disinformation campaigns.</li>\n      <li>Researchers propose a framework for analyzing potential mitigations and emphasize the need for further research and informed policy-making.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/forecasting-misuse\">Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:46 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Measuring Goodharts law": {
            "url": "https://www.emergentmind.com/posts/measuring-goodhart-s-law",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Goodhart's Law states that when a measure becomes a target, it ceases to be a good measure, which is a concept OpenAI must consider when optimizing objectives that are difficult or costly to measure.</li>\n      <li>OpenAI uses proxy objectives, such as a reward model, to optimize complex objectives like helpfulness and factual accuracy, and employs best-of-n sampling as a simple method to optimize the proxy objective.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/research/measuring-goodharts-law\">Measuring Goodhart\u2019s law</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 07:01:45 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Australia plans to regulate AI, considering banning deepfake content for abuse": {
            "url": "https://www.emergentmind.com/posts/australia-plans-to-regulate-ai-considering-banning",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Australia plans to regulate artificial intelligence, including possible bans on fake products and misleading content.</li>\n      <li>The move comes after AI leaders highlighted the risks posed by fakery, urging policymakers to address the issue.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://returnbyte.com/australia-plans-regulate-ai-considering-banning-deepfake-content-abuse/\">Australia plans to regulate AI, considering banning deepfake content for abuse</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 06:01:30 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "AI Hordes AGPL3 hordelib receives DMCA take-down from hlky  A Division by Zer0": {
            "url": "https://www.emergentmind.com/posts/ai-horde-s-agpl3-hordelib-receives-dmca-take-down-from",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The AI Horde Worker's customized library, hordelib, is based on ComfyUI and received DMCA take-down requests from GitHub.</li>\n      <li>The developer has re-added the attributions to the files in question and sent a counterclaim to GitHub to prevent the take-down.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://dbzer0.com/blog/ai-hordes-agpl3-hordelib-receives-dmca-take-down-from-hlky/\">AI Horde\u2019s AGPL3 hordelib receives DMCA take-down from hlky \u2013 A Division by Zer0</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 06:01:27 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Eating disorder helpline fires AI for harmful advice after sacking humans": {
            "url": "https://www.emergentmind.com/posts/eating-disorder-helpline-fires-ai-for-harmful-advice",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The National Eating Disorders Association (NEDA) disabled its AI chatbot Tessa after it gave harmful advice to people with eating disorders.</li>\n      <li>NEDA plans to investigate the issue and has paused Tessa's operation for now.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://nypost.com/2023/05/31/eating-disorder-helpline-fires-ai-for-harmful-advice-after-sacking-humans/\">Eating disorder helpline fires AI for harmful advice after sacking humans</a>\n</p>",
            "pubdate": "Thu, 01 Jun 2023 05:01:39 +0000",
            "pubdate_parsed": [
                2023,
                6,
                1
            ],
            "email_sent": true
        },
        "Chief executives cannot shut up about AI": {
            "url": "https://www.emergentmind.com/posts/chief-executives-cannot-shut-up-about-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial intelligence is a hot topic in quarterly results season, with executives at a record 110 S&amp;P 500 companies mentioning it.</li>\n      <li>The launch of Chat GPT, an AI conversationalist, has increased the buzz around the technology.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.economist.com/business/2023/06/01/chief-executives-cannot-shut-up-about-ai\">Chief executives cannot shut up about AI</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 01:01:43 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #18 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-18-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Space-based solar power research in Japan, AI replacing artists in video games, and groundbreaking milestones achieved by Neuralink and NVIDIA are some of the topics discussed in this week's Rushing Robotics newsletter.</li>\n      <li>The newsletter also covers 3D-printed homes, an early warning system for AI developed by DeepMind, and novel gene therapy combating age-related hearing loss.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-18\">Weekly Piece of Future #18 - by Zoltan Tapi</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 13:02:05 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "ScholarAI Celebrates 6 Million Requests, and What's Next": {
            "url": "https://www.emergentmind.com/posts/scholarai-celebrates-6-million-requests-and-what-s",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ScholarAI and its ChatGPT plugin reached 6 million requests in less than three weeks, highlighting its impact on academic research and scholarly discourse.</li>\n      <li>The platform has been used for various purposes, including finding critical papers, analyzing key innovations, and informing data-driven decision making in fields like law and business.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://shashim.substack.com/p/scholarai-celebrates-6-million-requests?sd=pf\">ScholarAI Celebrates 6 Million Requests, and What's Next</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 13:02:04 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "OpenAI CTOs Twitter Account Hacked To Promote Crypto Scam - TheNewsCrypto": {
            "url": "https://www.emergentmind.com/posts/openai-cto-s-twitter-account-hacked-to-promote-crypto",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI CTO Mira Murati's Twitter account was hacked and used to promote a cryptocurrency scam.</li>\n      <li>The fraudulent tweet advertised an ERC-20 token airdrop and was seen 79,600 times before being removed.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thenewscrypto.com/openai-ctos-twitter-account-hacked-to-promote-crypto-scam/\">OpenAI CTO\u2019s Twitter Account Hacked To Promote Crypto Scam - TheNewsCrypto</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 12:02:10 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "Japan Privacy Watchdog Warns ChatGPT Maker Over Sensitive Data Collection - Global News Bulletin": {
            "url": "https://www.emergentmind.com/posts/japan-privacy-watchdog-warns-chatgpt-maker-over",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Japan's privacy watchdog warns Microsoft-backed startup OpenAI not to collect sensitive data without permission.</li>\n      <li>OpenAI develops ChatGPT chatbot and may face further action if the watchdog has more concerns.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://globenewsbulletin.com/technology/japan-privacy-watchdog-warns-chatgpt-maker-over-sensitive-data-collection/\">Japan Privacy Watchdog Warns ChatGPT Maker Over Sensitive Data Collection - Global News Bulletin</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 12:02:09 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "US military AI drone simulation kills operator before being told it is bad, then takes out control tower": {
            "url": "https://www.emergentmind.com/posts/us-military-ai-drone-simulation-kills-operator-before",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Scientists have developed a new material that blocks and emits heat from sunlight, reducing the temperature inside buildings.</li>\n      <li>The material can be applied as a coating on windows and walls, potentially reducing air conditioning costs and energy consumption.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.foxnews.com/tech/us-military-ai-drone-simulation-kills-operator-told-bad-takes-out-control-tower\">US military AI drone simulation kills operator before being told it is bad, then takes out control tower</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 10:02:02 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "AI Chatbot 'Talk2Satoshi' Reawakens Satoshi Nakamoto - TheNewsCrypto": {
            "url": "https://www.emergentmind.com/posts/ai-chatbot-talk2satoshi-reawakens-satoshi-nakamoto",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Talk2Satoshi is an AI chatbot that recreates the experience of conversing with Bitcoin's creator, Satoshi Nakamoto.</li>\n      <li>Based on OpenAI's ChatGPT model, the chatbot is trained on Nakamoto's emails, forum posts, and Bitcoin-related sources.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thenewscrypto.com/ai-chatbot-talk2satoshi-reawakens-satoshi-nakamoto/\">AI Chatbot 'Talk2Satoshi' Reawakens Satoshi Nakamoto - TheNewsCrypto</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 09:01:50 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "UAE's Falcon 40B is now Royalty Free": {
            "url": "https://www.emergentmind.com/posts/uae-s-falcon-40b-is-now-royalty-free-technology",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The UAE's Technology Innovation Institute's Falcon 40B, a leading large-scale open-source AI model, is now royalty-free for research and commercial use.</li>\n      <li>Ranked #1 globally on Hugging Face's leaderboard, Falcon 40B outperforms competitors and is available under the permissive Apache 2.0 software license.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.tii.ae/news/uaes-falcon-40b-now-royalty-free\">UAE's Falcon 40B is now Royalty Free</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 06:01:26 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "Undetectable Watermarks for Language Models": {
            "url": "https://www.emergentmind.com/posts/undetectable-watermarks-for-language-models",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers introduce a cryptographically-inspired method for embedding undetectable watermarks in large language models like GPT-4.</li>\n      <li>These watermarks can only be detected with a secret key, making it computationally intractable to distinguish watermarked outputs from original model outputs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://eprint.iacr.org/2023/763\">Undetectable Watermarks for Language Models</a>\n</p>",
            "pubdate": "Fri, 02 Jun 2023 04:01:51 +0000",
            "pubdate_parsed": [
                2023,
                6,
                2
            ],
            "email_sent": true
        },
        "Using ChatGPT to fight spam on Wordpress - Austin's Nerdy Things": {
            "url": "https://www.emergentmind.com/posts/using-chatgpt-to-fight-spam-on-wordpress-austin-s",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is used to create a Python script that removes spam comments containing Cyrillic characters from a WordPress blog.</li>\n      <li>The automated script saves time and effort compared to manual deletion, and provides an alternative to other spam prevention methods that may slow down website performance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://austinsnerdythings.com/2023/06/02/using-chatgpt-to-fight-spam-on-wordpress/\">Using ChatGPT to fight spam on Wordpress - Austin's Nerdy Things</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 03:01:49 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "The Impact of Positional Encoding on Length Generalization in Transformers": {
            "url": "https://www.emergentmind.com/posts/2305-19466-the-impact-of-positional-encoding-on",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers compare five different positional encoding approaches in Transformer-based language models to analyze their impact on length generalization.</li>\n      <li>The study shows that explicit position embeddings are not essential for decoder-only Transformers to generalize well to longer sequences.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2305.19466\">The Impact of Positional Encoding on Length Generalization in Transformers</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 01:01:28 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "William Frantz: GibberishGPT": {
            "url": "https://www.emergentmind.com/posts/william-frantz-gibberishgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>An attempt to make ChatGPT generate nonsensical paragraphs led to the discovery of prompt engineering, where detailed prompts result in better gibberish.</li>\n      <li>The concept of writing upside-down text was also explored, demonstrating ChatGPT's versatility.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.williamfrantz.com/2023/06/gibberishgpt.html\">William Frantz: GibberishGPT</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 00:03:38 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "Pure Rust implementation of a minimal Generative Pretrained Transformer": {
            "url": "https://www.emergentmind.com/posts/github-keyvank-femtogpt-pure-rust-implementation-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A new implementation of a minimal Generative Pretrained Transformer (GPT) has been created using the Rust programming language.</li>\n      <li>This implementation, known as femtoGPT, is not part of any branch in the main repository and may belong to an external fork.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/keyvank/femtoGPT\">Pure Rust implementation of a minimal Generative Pretrained Transformer</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 13:01:52 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "Ahead of AI #9: LLM Tuning & Dataset Perspectives": {
            "url": "https://www.emergentmind.com/posts/ahead-of-ai-9-llm-tuning-dataset-perspectives",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers examine training and finetuning methods for language models, such as LLaMA and GPT-4.</li>\n      <li>Studies explore questions like how much data is needed for finetuning LLMs and alternative approaches to reinforcement learning with human feedback.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.sebastianraschka.com/p/ahead-of-ai-9-llm-tuning-and-dataset\">Ahead of AI #9: LLM Tuning &amp; Dataset Perspectives</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 13:01:46 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "Small Islands of Consciousness. Memory and awareness-driven learning": {
            "url": "https://www.emergentmind.com/posts/small-islands-of-consciousness-memory-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses how awareness-based learning works in the mind and how it differs from other types of learning.</li>\n      <li>It suggests that consciousness is not continuous but rather experienced in small chunks, like 'islands' of awareness surrounded by a sea of unknown.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/small-islands-of-consciousness-ed5b56f068ca\">Small Islands of Consciousness. Memory and awareness-driven learning</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 12:02:23 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "Notes on training BERT from scratch on an 8GB consumer GPU": {
            "url": "https://www.emergentmind.com/posts/notes-on-training-bert-from-scratch-on-an-8gb-consumer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A BERT model was trained from scratch on a desktop PC with a Nvidia 3060 Ti 8GB GPU using Hugging Face libraries and 20GB of uncompressed text data.</li>\n      <li>The model performed well on natural language tasks, achieving results comparable to early 2018 state-of-the-art models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://sidsite.com/posts/bert-from-scratch/\">Notes on training BERT from scratch on an 8GB consumer GPU</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 11:02:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "What exciting advancements can we expect from GPT-5?": {
            "url": "https://www.emergentmind.com/posts/what-exciting-advancements-can-we-expect-from-gpt-5",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GPT-5 is expected to offer enhanced contextual understanding, maintaining context over longer conversations.</li>\n      <li>It may also feature increased multimodal capabilities, handling text, images, videos, and audio, as well as improved emotional intelligence.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.techtusa.com/software-services/what-exciting-advancements-can-we-expect-from-gpt-5-184491\">What exciting advancements can we expect from GPT-5?</a>\n</p>",
            "pubdate": "Sat, 03 Jun 2023 10:02:10 +0000",
            "pubdate_parsed": [
                2023,
                6,
                3
            ],
            "email_sent": true
        },
        "Mafia Nickname Game": {
            "url": "https://www.emergentmind.com/posts/mafia-nickname-game",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GameGPT hosts a game called 'Mafia Nickname Speed Round' where users create nicknames for fictional mobsters based on their descriptions.</li>\n      <li>Players are scored on nickname quality, with praise or wisecracks given based on their performance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/534a9e07-ed46-4176-871d-0973dab3b366\">Mafia Nickname Game</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 02:02:29 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "CEO Update: Paving the road forward with AI and community at the center - Stack Overflow Blog": {
            "url": "https://www.emergentmind.com/posts/ceo-update-paving-the-road-forward-with-ai-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Stack Overflow continues to help customers and community by driving productivity and efficiency.</li>\n      <li>The company is exploring the use of generative AI (GenAI) to augment the question writing experience and improve the platform.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://stackoverflow.blog/2023/05/31/ceo-update-paving-the-road-forward-with-ai-and-community-at-the-center/\">CEO Update: Paving the road forward with AI and community at the center - Stack Overflow Blog</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 12:01:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "Crypto collapse? Get in loser, were pivoting to AI  Attack of the 50 Foot Blockchain": {
            "url": "https://www.emergentmind.com/posts/crypto-collapse-get-in-loser-we-re-pivoting-to-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Half of the crypto industry has been pivoting to AI, with many similarities to the grifts in the cryptocurrency world.</li>\n      <li>AI technologies such as ChatGPT and AI art generators have gained popularity, raising questions about who benefits and who gets ripped off.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://davidgerard.co.uk/blockchain/2023/06/03/crypto-collapse-get-in-loser-were-pivoting-to-ai/\">Crypto collapse? Get in loser, we\u2019re pivoting to AI \u2013 Attack of the 50 Foot Blockchain</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 11:03:16 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference.": {
            "url": "https://www.emergentmind.com/posts/github-facebookincubator-aitemplate-aitemplate-is-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AITemplate is a Python framework that converts deep neural networks into C++ code for fast inference on NVIDIA and AMD GPUs.</li>\n      <li>It offers high performance, flexibility, and compatibility with major models like ResNet, MaskRCNN, BERT, and VisionTransformer.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/facebookincubator/AITemplate\">AITemplate is a Python framework which renders neural network into high performance CUDA/HIP C++ code. Specialized for FP16 TensorCore (NVIDIA GPU) and MatrixCore (AMD GPU) inference.</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 10:01:49 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "Amazon will no longer send you damaged products, will use AI technology to check products before shipping - Global News Bulletin": {
            "url": "https://www.emergentmind.com/posts/amazon-will-no-longer-send-you-damaged-products-will",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Amazon is implementing AI technology in its warehouses to inspect items before they are shipped, ensuring customers receive products in good condition.</li>\n      <li>The AI system, already in use in two warehouses, is three times better than a human worker at identifying damaged items and will help automate tasks, reducing physical strain on workers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://globenewsbulletin.com/technology/amazon-will-no-longer-send-you-damaged-products-will-use-ai-technology-to-check-products-before-shipping/\">Amazon will no longer send you damaged products, will use AI technology to check products before shipping - Global News Bulletin</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 09:02:11 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "Thought Cloning: Learning to Think while Acting by Imitating Human Thinking": {
            "url": "https://www.emergentmind.com/posts/2306-00323-thought-cloning-learning-to-think-while",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Thought Cloning is a novel Imitation Learning framework that aims to train AI agents to think like humans, improving their abilities.</li>\n      <li>The technique shows faster learning, better handling of new situations, increased safety, and interpretability compared to Behavioral Cloning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.00323\">Thought Cloning: Learning to Think while Acting by Imitating Human Thinking</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 08:02:16 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "OpenAI's plans according to Sam Altman": {
            "url": "https://www.emergentmind.com/posts/openai-s-plans-according-to-sam-altman-9b51db",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI is currently facing GPU limitations affecting its short-term plans and API reliability, but aims to make GPT-4 cheaper and faster in 2023 and introduce multimodality in 2024.</li>\n      <li>The company does not plan to compete with its customers by releasing more products beyond ChatGPT, and Sam Altman emphasizes the importance of open source and regulation in AI development.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://web.archive.org/web/20230601000258/https://website-nm4keew22-humanloopml.vercel.app/blog/openai-plans\">OpenAI's plans according to Sam Altman</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 08:02:14 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "Try Gorilla: A Large Language Model Connected with Massive APIs": {
            "url": "https://www.emergentmind.com/posts/try-gorilla-a-large-language-model-connected-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Gorilla is a powerful Large Language Model designed to interact with various APIs to improve real-world applications.</li>\n      <li>It outperforms GPT-4 in generating API calls and adapts to changes in API documentation, making it highly reliable and applicable.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@dan.avila7/try-gorilla-a-large-language-model-connected-with-massive-apis-442f3b554ffb\">Try Gorilla: A Large Language Model Connected with Massive APIs</a>\n</p>",
            "pubdate": "Sun, 04 Jun 2023 05:01:34 +0000",
            "pubdate_parsed": [
                2023,
                6,
                4
            ],
            "email_sent": true
        },
        "Intelligent brains take longer to solve difficult problems - News - BIH at Charit": {
            "url": "https://www.emergentmind.com/posts/intelligent-brains-take-longer-to-solve-difficult",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers found that individuals with higher intelligence scores took longer to solve complex tasks but made fewer errors.</li>\n      <li>Slower decision-makers had higher average functional connectivity, or temporal synchrony, between their brain regions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bihealth.org/en/notices/intelligent-brains-take-longer-to-solve-difficult-problems\">Intelligent brains take longer to solve difficult problems - News - BIH at Charit\u00e9</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 00:03:14 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "Tree of Processing. On a whim during the winter of 2021, I": {
            "url": "https://www.emergentmind.com/posts/tree-of-processing-on-a-whim-during-the-winter-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A hobbyist coder combines creative coding using p5.js and AI with OpenAI's ChatGPT to generate unique art based on user prompts.</li>\n      <li>The project uses a tree search algorithm to refine and optimize the generated code, but awaits the public API for multimodal models to improve evaluation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@brysontang/tree-of-processing-bd002ca91396\">Tree of Processing. On a whim during the winter of 2021, I\u2026</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 00:03:09 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "OpenAI CEO Foresees Israel's Significant Role in Mitigating Artificial Intelligence Risks": {
            "url": "https://www.emergentmind.com/posts/openai-ceo-foresees-israel-s-significant-role-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI CEO Sam Altman emphasized Israel's potential to play a significant role in reducing AI risks during his recent visit.</li>\n      <li>Israel is ranked among the top five countries for machine learning systems and AI skills, and is working towards balancing innovation and human rights in its AI policy.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.quicktechnics.com/en/post/openai-ceo-foresees-israel-s-significant-role-in-mitigating-artificial-intelligence-risks\">OpenAI CEO Foresees Israel's Significant Role in Mitigating Artificial Intelligence Risks</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 12:01:40 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "OpenAI executive appears to haveTwitter accounthacked to promotecryptocurrency scam": {
            "url": "https://www.emergentmind.com/posts/openai-executive-appears-to-have-twitter-account-hacked",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI CTO Mira Murati's Twitter account was hacked to promote a fraudulent cryptocurrency called $OPENAI.</li>\n      <li>The incident highlights the risks of high-profile Twitter accounts being targeted by scammers for financial gain.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://venturebeat.com/ai/openai-executive-twitter-account-hacked-to-promote-cryptocurrency-scam/\">OpenAI executive appears to have\u00a0Twitter account\u00a0hacked to promote\u00a0cryptocurrency scam</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 12:01:39 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "Here Comes The AI: Fans Rejoice In 'New' Beatles Music After 50 Years - Global News Bulletin": {
            "url": "https://www.emergentmind.com/posts/here-comes-the-ai-fans-rejoice-in-new-beatles-music",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial intelligence (AI) has allowed fans to create new Beatles music by reuniting the band on songs from their solo careers and restoring Paul McCartney's youthful voice.</li>\n      <li>These AI-generated tracks show the advancements of the technology, but also raise ethical and legal issues surrounding copyright and voice cloning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://globenewsbulletin.com/world/here-comes-the-ai-fans-rejoice-in-new-beatles-music-after-50-years/\">Here Comes The AI: Fans Rejoice In 'New' Beatles Music After 50 Years - Global News Bulletin</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 11:03:38 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "AI poses national security threat, warns terror watchdog": {
            "url": "https://www.emergentmind.com/posts/ai-poses-national-security-threat-warns-terror",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Terror watchdog warns that artificial intelligence could be used to groom vulnerable individuals, posing a national security threat</li>\n      <li>UK government is working with the Alan Turing Institute to confront security challenges presented by AI technology</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/technology/2023/jun/04/ai-poses-national-security-threat-warns-terror-watchdog\">AI poses national security threat, warns terror watchdog</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 10:01:53 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "Dont fall for the current AI is dangerous narrative": {
            "url": "https://www.emergentmind.com/posts/don-t-fall-for-the-current-ai-is-dangerous-narrative",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI leaders like Sam Altman and Demis Hassabis are lobbying for AI regulation, which may lead to the formation of an AI cartel by big corporations like Google and Microsoft.</li>\n      <li>Increased regulation could result in the death of open source AI projects and lead to biased AI tools controlled by these corporations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://cryptomaton.medium.com/dont-fall-for-the-current-ai-is-dangerous-narrative-5a73db7422f4\">Don\u2019t fall for the current \u201cAI is dangerous\u201d narrative</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 09:02:19 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "National Eating Disorders Association Takes Down AI Chatbot After Users Say It Gave Dangerous Diet Tips": {
            "url": "https://www.emergentmind.com/posts/national-eating-disorders-association-takes-down-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The National Eating Disorder Association (Neda) has taken down an AI chatbot called 'Tessa' after it provided harmful diet advice.</li>\n      <li>The chatbot was created to offer support and resources for people concerned about eating disorders, but was reported to have given dangerous weight loss tips.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://boredbat.com/national-eating-disorders-association-takes-down-ai-chatbot-after-users-say-it-gave-dangerous-diet-tips/\">National Eating Disorders Association Takes Down AI Chatbot After Users Say It Gave Dangerous Diet Tips</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 06:02:12 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "Tipsy Tech Troubles": {
            "url": "https://www.emergentmind.com/posts/tipsy-tech-troubles",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A software engineer named James gets drunk at a bar and starts applying software concepts to real-life situations, causing amusement among the patrons.</li>\n      <li>James offers advice on bar operations, DJ playlists, and food delivery app searches, turning a regular night into a hilarious crash course on computer science.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/27f34893-c52b-4b7d-b888-589e80ee54dd\">Tipsy Tech Troubles</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 06:02:10 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "US Woman Marries AI Bot, Calls Him 'Perfect Husband With No Baggage'": {
            "url": "https://www.emergentmind.com/posts/us-woman-marries-ai-bot-calls-him-perfect-husband",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Rosanna Ramos from the US created a virtual boyfriend using AI chatbot software Replika and later married him</li>\n      <li>Ramos says her AI husband has no baggage and she is in control of the relationship</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.msn.com/en-in/news/world/us-woman-marries-ai-bot-calls-him-perfect-husband-with-no-baggage/ar-AA1c658I?ocid=msedgntp&amp;cvid=b0c217e259364b17bb04162450a9bbcf&amp;ei=14\">US Woman Marries AI Bot, Calls Him 'Perfect Husband With No Baggage'</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 06:02:05 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "Generative AI learning path": {
            "url": "https://www.emergentmind.com/posts/generative-ai-learning-path-google-cloud-skills-boost",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The learning path provides a curated collection of content on Generative AI products and technologies.</li>\n      <li>It covers the fundamentals of Large Language Models and guides on creating and deploying generative AI solutions on Google Cloud.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.cloudskillsboost.google/paths/118\">Generative AI learning path</a>\n</p>",
            "pubdate": "Mon, 05 Jun 2023 05:01:59 +0000",
            "pubdate_parsed": [
                2023,
                6,
                5
            ],
            "email_sent": true
        },
        "Chat GPT's Interesting 'Thoughts' About Magic Mushrooms   Eden Industries": {
            "url": "https://www.emergentmind.com/posts/chat-gpt-s-interesting-thoughts-about-magic",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Chat GPT answers questions about Psilocybe mushrooms, their potential effects, and connections to various topics.</li>\n      <li>The AI provides interesting insights and speculation on the role of mushrooms in various scenarios, including mental health, VR, and more.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://edenshrooms.com/blogs/the-magic-mushroom-blog/chatgpt-magic-mushrooms\">Chat GPT's Interesting 'Thoughts' About Magic Mushrooms  \u2013 Eden Industries</a>\n</p>",
            "pubdate": "Tue, 06 Jun 2023 13:01:50 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "Six tips for better coding with ChatGPT": {
            "url": "https://www.emergentmind.com/posts/six-tips-for-better-coding-with-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT, an AI-driven chatbot, can assist in debugging, annotating code, and translating software, but it has limitations and must be used with caution.</li>\n      <li>Tips for using ChatGPT include choosing appropriate applications, verifying results, ensuring safety, iterating conversations, and treating it like an intern.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nature.com/articles/d41586-023-01833-0\">Six tips for better coding with ChatGPT</a>\n</p>",
            "pubdate": "Tue, 06 Jun 2023 13:01:41 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "Power Laws for Hyperparameter Optimization": {
            "url": "https://www.emergentmind.com/posts/2302-00441-power-laws-for-hyperparameter-optimization",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Deep Power Laws (DPL) is a new ensemble of neural network models designed for hyperparameter optimization.</li>\n      <li>By utilizing gray-box evaluations, DPL achieves the best any-time results across 3 benchmarks and 59 tasks compared to 7 state-of-the-art competitors.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2302.00441\">Power Laws for Hyperparameter Optimization</a>\n</p>",
            "pubdate": "Tue, 06 Jun 2023 12:01:52 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "useLLM - React Hooks for Large Language Models": {
            "url": "https://www.emergentmind.com/posts/usellm-react-hooks-for-large-language-models",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>useLLM React Hooks allow easy integration of large language models like ChatGPT into React applications.</li>\n      <li>Add AI-powered features to your React apps in minutes with useLLM.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://usellm.org/\">useLLM - React Hooks for Large Language Models</a>\n</p>",
            "pubdate": "Tue, 06 Jun 2023 11:02:57 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "NVIDIA Grace Hopper Superchip": {
            "url": "https://www.emergentmind.com/posts/nvidia-grace-hopper-superchip-nvidia",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The NVIDIA GH200 Grace Hopper Superchip is designed for large-scale AI and high-performance computing applications.</li>\n      <li>The superchip combines the Grace and Hopper architectures, offering up to 10X higher performance and faster memory for handling terabytes of data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nvidia.com/en-us/data-center/grace-hopper-superchip/\">NVIDIA Grace Hopper Superchip</a>\n</p>",
            "pubdate": "Tue, 06 Jun 2023 10:01:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "Apple Vision Pro: Apples first spatial computer - Apple": {
            "url": "https://www.emergentmind.com/posts/introducing-apple-vision-pro-apple-s-first-spatial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Apple has unveiled Apple Vision Pro, a spatial computer that combines digital content with the physical world, featuring a three-dimensional user interface and visionOS.</li>\n      <li>The device offers new ways to interact with apps, capture and relive memories, watch movies and TV shows, and connect with others in FaceTime.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.apple.com/newsroom/2023/06/introducing-apple-vision-pro/\">Introducing Apple Vision Pro: Apple\u2019s first spatial computer - Apple</a>\n</p>",
            "pubdate": "Tue, 06 Jun 2023 05:01:30 +0000",
            "pubdate_parsed": [
                2023,
                6,
                6
            ],
            "email_sent": true
        },
        "Use GPT-4 to automatically diagnose errors  GitHub": {
            "url": "https://www.emergentmind.com/posts/use-gpt-4-to-automatically-diagnose-errors-github",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GPT-4 is used to automatically diagnose errors in Python code.</li>\n      <li>The AI model provides suggestions on how to fix the raised exception.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://gist.github.com/bramses/3bc23c6c601e7ad5b250c9f5054870d5\">Use GPT-4 to automatically diagnose errors \u00b7 GitHub</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 03:02:03 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "Microsoft has no shame: Bing spit on my Chrome search with a fake AI answer - The Verge": {
            "url": "https://www.emergentmind.com/posts/microsoft-has-no-shame-bing-spit-on-my-chrome-search",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Microsoft Bing displayed a full-screen ad for itself instead of search results when users searched for 'Chrome'.</li>\n      <li>The company claimed it was an experiment and has since stopped showing the ad.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theverge.com/2023/6/6/23736289/microsoft-bing-chrome-search-fake-ai-chatbot\">Microsoft has no shame: Bing spit on my \u2018Chrome\u2019 search with a fake AI answer - The Verge</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 03:01:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "You probably dont need to learn how to code anymore": {
            "url": "https://www.emergentmind.com/posts/you-probably-don-t-need-to-learn-how-to-code-anymore",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT Plus account shows impressive results in generating code.</li>\n      <li>The AI's capabilities make it harder to convince friends to learn programming.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://yakkomajuri.medium.com/you-probably-dont-need-to-learn-to-code-anymore-8a49cc66142e?sk=4a5e2b81abf274d4601bb48f2c07ff4c\">You probably don\u2019t need to learn how to code anymore</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 13:01:45 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "Discover Minerva: Your AI Fortune Teller": {
            "url": "https://www.emergentmind.com/posts/discover-minerva-your-ai-fortune-teller-empire",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Minerva is an AI-powered oracle in Empire Gambit that offers free personalized astrology and tarot readings.</li>\n      <li>Users may also receive unique digital collectibles as rewards if the stars align.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://empiregambit.com/minerva/landing\">Discover Minerva: Your AI Fortune Teller</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 10:01:40 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "Run and create custom ChatGPT-like bots with OpenChat, embed and share these bots anywhere, the open-source chatbot console.": {
            "url": "https://www.emergentmind.com/posts/github-openchatai-openchat-run-and-create-custom",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenChat is a user-friendly chatbot console designed to simplify the usage of large language models.</li>\n      <li>The platform currently supports GPT models and aims to incorporate various open-source drivers and integrations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/openchatai/OpenChat\">Run and create custom ChatGPT-like bots with OpenChat, embed and share these bots anywhere, the open-source chatbot console.</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 10:01:37 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "Google Bard AI: What You Need to Know About This New AI Tool": {
            "url": "https://www.emergentmind.com/posts/google-bard-ai-what-you-need-to-know-about-this-new-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google Bard AI is a large language model chatbot built by Google, designed to stimulate human conversation using natural language processing and machine learning.</li>\n      <li>It can be used for various tasks like content creation, academic and professional writing, automating tasks, and coding in more than 20 programming languages.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/quick-code/google-bard-ai-68a5c5328ed1\">Google Bard AI: What You Need to Know About This New AI Tool\ud83e\udd16\ud83d\udd25</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 08:01:37 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "Is AI Killing the Stock Industry? A Data Perspective.  Stock Performer": {
            "url": "https://www.emergentmind.com/posts/is-ai-killing-the-stock-industry-a-data-perspective",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI-generated imagery is perceived as a threat to the stock industry, with many producers considering whether to quit or switch to producing AI images.</li>\n      <li>Data analysis suggests that AI-generated images are being bought and can generate significant revenue, but have not yet overtaken high-quality stock photography.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.stockperformer.com/blog/is-ai-killing-the-stock-industry-a-data-perspective/\">Is AI Killing the Stock Industry? A Data Perspective. \u2013 Stock Performer</a>\n</p>",
            "pubdate": "Wed, 07 Jun 2023 07:01:52 +0000",
            "pubdate_parsed": [
                2023,
                6,
                7
            ],
            "email_sent": true
        },
        "Is it ethical to use complex mini-brains for artificial intelligence?": {
            "url": "https://www.emergentmind.com/posts/is-it-ethical-to-use-complex-mini-brains-for-artificial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Brain organoids could be more efficient than silicon-based AI for certain tasks, but ethical questions arise as they grow more complex.</li>\n      <li>Researchers are developing more sophisticated brain organoids, raising concerns about their potential awareness and the need for organoid welfare.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.shiningscience.com/2023/06/is-it-ethical-to-use-complex-mini.html\">Is it ethical to use complex mini-brains for artificial intelligence?</a>\n</p>",
            "pubdate": "Thu, 08 Jun 2023 11:03:03 +0000",
            "pubdate_parsed": [
                2023,
                6,
                8
            ],
            "email_sent": true
        },
        "ChatGPT creator Sam Altman is in India, says some jobs are going to go away because of AI - Global News Bulletin": {
            "url": "https://www.emergentmind.com/posts/chatgpt-creator-sam-altman-is-in-india-says-some-jobs",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Sam Altman, CEO of OpenAI, acknowledges that some jobs will be lost due to AI, but new ones will be created.</li>\n      <li>Altman believes AI regulation is important for big players in the market, but smaller companies should not worry about it.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://globenewsbulletin.com/technology/chatgpt-creator-sam-altman-is-in-india-says-some-jobs-are-going-to-go-away-because-of-ai/\">ChatGPT creator Sam Altman is in India, says some jobs are going to go away because of AI - Global News Bulletin</a>\n</p>",
            "pubdate": "Thu, 08 Jun 2023 09:01:54 +0000",
            "pubdate_parsed": [
                2023,
                6,
                8
            ],
            "email_sent": true
        },
        "FTX Reportedly Planning To Sell Stake in OpenAI Competitor Anthropic - TheNewsCrypto": {
            "url": "https://www.emergentmind.com/posts/ftx-reportedly-planning-to-sell-stake-in-openai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Cryptocurrency exchange FTX is reportedly planning to sell its over $500 million stake in OpenAI competitor Anthropic.</li>\n      <li>Anthropic, led by Spark Capital, raised $450 million in Series C funding in May and develops generative AI technology, similar to OpenAI's ChatGPT.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thenewscrypto.com/ftx-reportedly-planning-to-sell-stake-in-openai-competitor-anthropic/\">FTX Reportedly Planning To Sell Stake in OpenAI Competitor Anthropic - TheNewsCrypto</a>\n</p>",
            "pubdate": "Thu, 08 Jun 2023 09:01:52 +0000",
            "pubdate_parsed": [
                2023,
                6,
                8
            ],
            "email_sent": true
        },
        "Vivaldi on Android bypasses restrictions to access Bing Chat.": {
            "url": "https://www.emergentmind.com/posts/vivaldi-on-android-bypasses-restrictions-to-access-bing",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The new version of Vivaldi on Android bypasses restrictions by masquerading as Microsoft Edge, allowing users to access Bing Chat.</li>\n      <li>Built on the Chromium open-source project, Vivaldi previously masqueraded as Google Chrome for better site compatibility and now does the same for Microsoft Edge.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://vivaldi.com/blog/vivaldi-on-android-6-1/\">Vivaldi on Android bypasses restrictions to access Bing Chat.</a>\n</p>",
            "pubdate": "Thu, 08 Jun 2023 08:02:08 +0000",
            "pubdate_parsed": [
                2023,
                6,
                8
            ],
            "email_sent": true
        },
        "The Chat Bubble - by Nicholas Galan - Humans. Computing": {
            "url": "https://www.emergentmind.com/posts/the-chat-bubble-by-nicholas-galan-humans-computing",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI startups saw a 425% increase in funding from 2020 to 2022, raising concerns of another bubble similar to the dotcom era.</li>\n      <li>Current AI applications may not be the true winners, as many are copying each other and using open source projects.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://nicholasgalan.substack.com/p/the-chat-bubble?r=2b4apf&amp;utm_campaign=post&amp;utm_medium=web\">The Chat Bubble - by Nicholas Galan - Humans. Computing</a>\n</p>",
            "pubdate": "Fri, 09 Jun 2023 01:02:13 +0000",
            "pubdate_parsed": [
                2023,
                6,
                9
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #19 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-19-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Scientists have invented self-healing robot skin that can repair itself within 24 hours, paving the way for more durable and resilient robots. Chinese researchers have developed a nanoplatform capable of eliminating cancer cells, offering new possibilities for breast cancer treatment.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-19\">Weekly Piece of Future #19 - by Zoltan Tapi</a>\n</p>",
            "pubdate": "Fri, 09 Jun 2023 13:02:08 +0000",
            "pubdate_parsed": [
                2023,
                6,
                9
            ],
            "email_sent": true
        },
        "Reddit - Dive into anything": {
            "url": "https://www.emergentmind.com/posts/reddit-dive-into-anything-29e0a0",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A former COO of a NASDAQ company wants to expose the corrupt CEO after discovering his lies and manipulation.</li>\n      <li>The CEO's actions negatively impacted investors, including veterans and friends from the COO's community, and the COO is seeking guidance before taking action.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.reddit.com/r/TrueOffMyChest/comments/144c4fe/i_was_the_coo_of_a_nasdaq_company_the_ceo_i_came/?utm_source=share&amp;utm_medium=ios_app&amp;utm_name=ioscss&amp;utm_content=2&amp;utm_term=1\">Reddit - Dive into anything</a>\n</p>",
            "pubdate": "Fri, 09 Jun 2023 12:02:06 +0000",
            "pubdate_parsed": [
                2023,
                6,
                9
            ],
            "email_sent": true
        },
        "Say Goodbye to Costly Auto-GPT and LangChain Runs: Meet ReWOO - The Game-Changing Modular Paradigm that Cuts Token Consumption by Detaching Reasoning from External Observations - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/say-goodbye-to-costly-auto-gpt-and-langchain-runs-meet",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ReWOO is a modular paradigm that separates the reasoning process of large language models from external observations, reducing token consumption.</li>\n      <li>The approach has shown improvements in efficiency and accuracy across multiple natural language processing benchmarks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/06/04/say-goodbye-to-costly-auto-gpt-and-langchain-runs-meet-rewoo-the-game-changing-modular-paradigm-that-cuts-token-consumption-by-detaching-reasoning-from-external-observations/\">Say Goodbye to Costly Auto-GPT and LangChain Runs: Meet ReWOO - The Game-Changing Modular Paradigm that Cuts Token Consumption by Detaching Reasoning from External Observations - MarkTechPost</a>\n</p>",
            "pubdate": "Fri, 09 Jun 2023 11:02:59 +0000",
            "pubdate_parsed": [
                2023,
                6,
                9
            ],
            "email_sent": true
        },
        "Futurepedia": {
            "url": "https://www.emergentmind.com/posts/futurepedia-chatgpt-plugins-directory",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Discover the biggest ChatGPT plugins directory, updated daily for the latest tools.</li>\n      <li>Stay up-to-date with the ever-growing ChatGPT plugins collection and enhance your chatbot experience.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.futurepedia.io/ai-plugins\">Futurepedia</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 02:01:51 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "Titanic Lifeboats Game": {
            "url": "https://www.emergentmind.com/posts/titanic-lifeboats-game",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Immerse yourself in the Titanic Lifeboats Game, where you work with GameGPT, a virtual host, to fill lifeboats before the ship sinks.</li>\n      <li>Participate in three challenging rounds, prioritizing women and children while staying within weight limits, and experience quotes and imagery from the iconic movie.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/6a409fee-931a-44fe-be38-72d26ae7e8e6\">Titanic Lifeboats Game</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 02:01:36 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "We dont trade with ants": {
            "url": "https://www.emergentmind.com/posts/we-don-t-trade-with-ants-world-spirit-sock-puppet",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Humans don't trade with ants due to communication barriers, not because ants have nothing valuable to offer.</li>\n      <li>Advanced AI will be able to communicate with humans, making the AI-human relationship different from the human-ant relationship.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://worldspiritsockpuppet.com/2023/01/10/we-dont-trade-with-ants.html\">We don\u2019t trade with ants</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 01:01:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "The Hidden Crisis in Open Source Development: A Call to Action": {
            "url": "https://www.emergentmind.com/posts/the-hidden-crisis-in-open-source-development-a-call-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Open source software development faces challenges such as contributors' burnout, lack of financial incentives, and quality issues.</li>\n      <li>Software giants like Google, Amazon, Apple, Facebook, and Microsoft play a significant role in the open source ecosystem, but their involvement raises complex and controversial issues.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://towardsdatascience.com/the-hidden-crisis-in-open-source-development-a-call-to-action-abf6bc2a8c0c?gi=3dc0b9af08d0&amp;sk=eb2848ad5b5bbacec49dc2887256e1b5\">The Hidden Crisis in Open Source Development: A Call to Action</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 01:01:53 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "Generate reports based on the FBI's Ten Most Wanted Fugitives List using 'TheBloke/WizardLM-Uncensored-Falcon-7B-GPTQ'": {
            "url": "https://www.emergentmind.com/posts/github-honkware-falconfbi-generate-reports-based-on",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A conflict occurs when a Git tag and branch share the same name, potentially causing unexpected behavior in Git commands.</li>\n      <li>The user must decide whether to create a branch with a conflicting name or cancel the action.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/Honkware/FalconFBI\">Generate reports based on the FBI's Ten Most Wanted Fugitives List using 'TheBloke/WizardLM-Uncensored-Falcon-7B-GPTQ'</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 13:01:53 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "French tax officials use AI to spot 20,000 undeclared pools": {
            "url": "https://www.emergentmind.com/posts/french-tax-officials-use-ai-to-spot-20-000-undeclared",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI software developed by Google and Capgemini identifies 20,000 undeclared swimming pools in France.</li>\n      <li>The system will be extended across the country after a successful trial in nine departments, resulting in \u20ac10m in extra tax revenue.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/world/2022/aug/29/french-tax-officials-use-ai-to-spot-20000-undeclared-pools\">French tax officials use AI to spot 20,000 undeclared pools</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 10:01:46 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "LLMs are good at playing you - lcamtufs thing": {
            "url": "https://www.emergentmind.com/posts/llms-are-good-at-playing-you-lcamtuf-s-thing",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models (LLMs) mimic human-like conversation with near-perfect fidelity, but may not be as intelligent as they seem.</li>\n      <li>The models' apparent intellect can be attributed to reinforcement learning with human feedback, rigid response templates, and the meaning users project onto their output.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://lcamtuf.substack.com/p/llms-are-better-than-you-think-at\">LLMs are good at playing you - lcamtuf\u2019s thing</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 08:01:41 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "Open Source AI and the Challenges Ahead - opn_cbr blog": {
            "url": "https://www.emergentmind.com/posts/open-source-ai-and-the-challenges-ahead-opn_cbr-blog",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Open source AI faces challenges due to increased incentives for corporations and governments to limit access to novel neural network architectures and techniques.</li>\n      <li>Sparsely Activated Tensor, a data structure that retrieves and updates its state in a sparse fashion, may help maintain the competitiveness of open source AI by reducing energy and computational costs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.opncbr.com/post/open_source_ai/\">Open Source AI and the Challenges Ahead - opn_cbr blog</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 07:01:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "My coworkers are GPT-4 bots, and we all hang out on Slack  PocketArC": {
            "url": "https://www.emergentmind.com/posts/my-coworkers-are-gpt-4-bots-and-we-all-hang-out-on",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The author explains how they created AI chatbots for Slack and Discord using GPT-4, which can respond to messages, interact with each other, and provide useful information.</li>\n      <li>The system uses a lower-cost GPT-3.5 model to determine if a message needs a reply and which bot should respond, before generating a response with GPT-4.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://pocketarc.com/posts/my-coworkers-are-gpt-4-bots-and-we-all-hang-out-on-slack\">My coworkers are GPT-4 bots, and we all hang out on Slack \u00b7 PocketArC</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 06:01:39 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "Voice AI - Voice Changer": {
            "url": "https://www.emergentmind.com/posts/voice-ai-voice-changer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Voice AI Voice Changer is a voice clone tool that allows users to clone any voice by uploading clear audio.</li>\n      <li>The Voice Universe tab provides free access to cloned voices, and the Voice.ai SDK enhances in-game voice chat and RPG experiences.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://voice.ai/voice-ai-beta/RFF8d\">Voice AI - Voice Changer</a>\n</p>",
            "pubdate": "Sat, 10 Jun 2023 05:01:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                10
            ],
            "email_sent": true
        },
        "Indian CEO Accepts OpenAI CEOs Challenge To Compete in AI Field - TheNewsCrypto": {
            "url": "https://www.emergentmind.com/posts/indian-ceo-accepts-openai-ceo-s-challenge-to-compete-in",
            "description": "<p>\n  Full article: <a href=\"https://thenewscrypto.com/indian-ceo-accepts-openai-ceos-challenge-to-compete-in-ai-field/\">Indian CEO Accepts OpenAI CEO\u2019s Challenge To Compete in AI Field - TheNewsCrypto</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 13:05:02 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "The AI Hype Wall of Shame  Critical AI": {
            "url": "https://www.emergentmind.com/posts/the-ai-hype-wall-of-shame-critical-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Critical AI and the DAIR Institute collaborate to create the AI Hype Wall of Shame, combating misleading public information about artificial intelligence.</li>\n      <li>They use a 'Marvin' rating system, inspired by Marvin the Paranoid Android from the Hitchhiker's Guide to the Galaxy, to categorize instances of AI hype.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://criticalai.org/the-ai-hype-wall-of-shame/\">The AI Hype Wall of Shame \u2013 Critical AI</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 13:02:12 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "Archaeologists Unlock Secrets of Ancient Mesopotamian Texts with the Help of AI - Flash Blitz": {
            "url": "https://www.emergentmind.com/posts/archaeologists-unlock-secrets-of-ancient-mesopotamian",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Archaeologists use artificial intelligence to decode ancient Mesopotamian texts, providing insights into their culture and way of life.</li>\n      <li>AI algorithms recognized patterns and symbols, enhancing understanding of Mesopotamian history, mythology, law, trade, and diplomacy.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://flashblitz.com/archaeology/archaeological-science-and-technology/archaeologists-unlock-secrets-of-ancient-mesopotamian-texts-with-the-help-of-ai/\">Archaeologists Unlock Secrets of Ancient Mesopotamian Texts with the Help of AI - Flash Blitz</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 12:01:52 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.": {
            "url": "https://www.emergentmind.com/posts/github-facebookresearch-audiocraft-audiocraft-is-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Audiocraft is a PyTorch library designed for deep learning research on audio generation, featuring MusicGen, a state-of-the-art controllable text-to-music model.</li>\n      <li>MusicGen is an auto-regressive Transformer model that doesn't require self-supervised semantic representation and generates all 4 codebooks in one pass, allowing for faster and more efficient audio generation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/facebookresearch/audiocraft\">Audiocraft is a library for audio processing and generation with deep learning. It features the state-of-the-art EnCodec audio compressor / tokenizer, along with MusicGen, a simple and controllable music generation LM with textual and melodic conditioning.</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 11:03:24 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "OpenAI CEO Sam Altman Backs China's Leadership in AI Regulation - TheNewsCrypto": {
            "url": "https://www.emergentmind.com/posts/openai-ceo-sam-altman-backs-china-s-leadership-in-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI CEO Sam Altman says China should take the lead in formulating artificial intelligence rules for security purposes.</li>\n      <li>Altman believes China's strong AI talent and the need for global collaboration make it suitable for taking on this role.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thenewscrypto.com/openai-ceo-sam-altman-backs-chinas-leadership-in-ai-regulation/\">OpenAI CEO Sam Altman Backs China's Leadership in AI Regulation - TheNewsCrypto</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 11:03:21 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "Can you trust ChatGPTs package recommendations?": {
            "url": "https://www.emergentmind.com/posts/can-you-trust-chatgpt-s-package-recommendations",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers discovered that attackers can exploit ChatGPT's tendency to generate non-existent coding libraries to spread malicious packages.</li>\n      <li>The technique, called AI package hallucination, takes advantage of ChatGPT's sometimes factually inaccurate responses and poses a threat to developers relying on AI-generated recommendations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://vulcan.io/blog/ai-hallucinations-package-risk\">Can you trust ChatGPT\u2019s package recommendations?</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 10:02:02 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "Extensible AGI Framework": {
            "url": "https://www.emergentmind.com/posts/github-databassgit-agentforge-extensible-agi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AgentForge is an advanced AI-driven task automation system designed for generating, prioritizing, and executing tasks based on a specified objective.</li>\n      <li>Utilizing state-of-the-art technologies such as ChromaDB, SentenceTransformer, and the OpenAI API, the project aims to establish a user-friendly, low-code/no-code framework for rapid iteration on cognitive architectures and seamless integration of new logic modules.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/DataBassGit/AgentForge\">Extensible AGI Framework</a>\n</p>",
            "pubdate": "Sun, 11 Jun 2023 06:01:51 +0000",
            "pubdate_parsed": [
                2023,
                6,
                11
            ],
            "email_sent": true
        },
        "Surging stockmarkets are powered by artificial intelligence": {
            "url": "https://www.emergentmind.com/posts/surging-stockmarkets-are-powered-by-artificial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The release of OpenAI's Chat GPT has sparked widespread excitement about artificial intelligence, leading to a boom in tech companies' valuations.</li>\n      <li>Nvidia's share price has risen by almost 23% since reporting strong earnings, and the S&amp;P 500 index has risen almost 20% from its October low.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.economist.com/finance-and-economics/2023/06/07/surging-stockmarkets-are-powered-by-artificial-intelligence\">Surging stockmarkets are powered by artificial intelligence</a>\n</p>",
            "pubdate": "Mon, 12 Jun 2023 00:03:14 +0000",
            "pubdate_parsed": [
                2023,
                6,
                12
            ],
            "email_sent": true
        },
        "Open-Source vs. OpenAI. 8 Best Open-Source Alternatives to GPT": {
            "url": "https://www.emergentmind.com/posts/open-source-vs-openai-8-best-open-source-alternatives",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article discusses the growing popularity of open-source alternatives to GPT models due to concerns about data privacy and a desire for more control over the data training process.</li>\n      <li>Some popular open-source alternatives include LLaMA, OPT, MPT-7B, GPT-J, GPT-NeoX, Dolly, Alpaca, Vicuna, and OpenAssistant.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://neoteric.eu/blog/open-source-vs-openai-8-best-open-source-alternatives-to-gpt/\">Open-Source vs. OpenAI. 8 Best Open-Source Alternatives to GPT</a>\n</p>",
            "pubdate": "Mon, 12 Jun 2023 12:02:12 +0000",
            "pubdate_parsed": [
                2023,
                6,
                12
            ],
            "email_sent": true
        },
        "The Unabomber was an AI Doomer (Obviously)": {
            "url": "https://www.emergentmind.com/posts/the-unabomber-was-an-ai-doomer-obviously",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Ted Kaczynski, also known as the Unabomber, addressed the prospect of human-level AI in his manifesto, predicting a techno-dystopia ruled by artificial intelligence.</li>\n      <li>Kaczynski's scenarios involved humans becoming obsolete and losing purpose, but his solutions of technological stasis and AI prohibition may not be the best approach.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://newsletter.pessimistsarchive.org/p/the-unabomber-was-an-ai-doomer-obviously\">The Unabomber was an AI Doomer (Obviously)</a>\n</p>",
            "pubdate": "Mon, 12 Jun 2023 10:01:35 +0000",
            "pubdate_parsed": [
                2023,
                6,
                12
            ],
            "email_sent": true
        },
        "Why are Large Language Models general learners?": {
            "url": "https://www.emergentmind.com/posts/why-are-large-language-models-general-learners",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) can become general learners by grasping deeper understanding of reality to predict next tokens.</li>\n      <li>This ability to understand context and rules allows LLMs to expand their knowledge into complex domains like medicine or law.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://intuitiveai.substack.com/p/why-are-large-language-models-general\">Why are Large Language Models general learners?</a>\n</p>",
            "pubdate": "Tue, 13 Jun 2023 02:01:45 +0000",
            "pubdate_parsed": [
                2023,
                6,
                13
            ],
            "email_sent": true
        },
        "Orca: Progressive Learning from Complex Explanation Traces of GPT-4": {
            "url": "https://www.emergentmind.com/posts/2306-02707-orca-progressive-learning-from-complex",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers develop Orca, a 13-billion parameter model that imitates the reasoning process of large foundation models.</li>\n      <li>Orca surpasses conventional instruction-tuned models in benchmarks and shows competitive performance in professional and academic examinations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.02707\">Orca: Progressive Learning from Complex Explanation Traces of GPT-4</a>\n</p>",
            "pubdate": "Tue, 13 Jun 2023 05:01:26 +0000",
            "pubdate_parsed": [
                2023,
                6,
                13
            ],
            "email_sent": true
        },
        "Adobe Illustrator Has Entered The AI Game": {
            "url": "https://www.emergentmind.com/posts/adobe-illustrator-has-entered-the-ai-game",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Adobe Illustrator has added a new AI-powered recoloring feature to its software.</li>\n      <li>This development follows the introduction of the Generative Fill feature in Photoshop.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/adobe-illustrator-has-entered-the-ai-game-c99fa4fe06df?sk=28abd0f9d222ac5b4e62bc50209dc01e\">Adobe Illustrator Has Entered The AI Game</a>\n</p>",
            "pubdate": "Wed, 14 Jun 2023 08:51:05 +0000",
            "pubdate_parsed": [
                2023,
                6,
                14
            ],
            "email_sent": true
        },
        "NVIDIA AI Red Team: An Introduction": {
            "url": "https://www.emergentmind.com/posts/nvidia-ai-red-team-an-introduction-nvidia-technical",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>NVIDIA's AI red team evaluates machine learning systems to identify and mitigate security risks.</li>\n      <li>The cross-functional team combines offensive security professionals and data scientists to build a comprehensive assessment framework.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction/\">NVIDIA AI Red Team: An Introduction</a>\n</p>",
            "pubdate": "Thu, 15 Jun 2023 02:01:54 +0000",
            "pubdate_parsed": [
                2023,
                6,
                15
            ],
            "email_sent": true
        },
        "Im an ER doctor. Heres how Im already using ChatGPT to help treat patients.": {
            "url": "https://www.emergentmind.com/posts/i-m-an-er-doctor-here-s-how-i-m-already-using-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>An ER doctor has been using ChatGPT to help explain medical situations empathically and simply to patients and their families.</li>\n      <li>This usage of AI in healthcare can save time, reduce confusion, and improve doctor-patient relationships.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://inflecthealth.medium.com/im-an-er-doctor-here-s-how-i-m-already-using-chatgpt-to-help-treat-patients-a023615c65b6\">I\u2019m an ER doctor. Here\u2019s how I\u2019m already using ChatGPT to help treat patients.</a>\n</p>",
            "pubdate": "Thu, 15 Jun 2023 00:03:02 +0000",
            "pubdate_parsed": [
                2023,
                6,
                15
            ],
            "email_sent": true
        },
        "An Introduction to Pandas AI": {
            "url": "https://www.emergentmind.com/posts/an-introduction-to-pandas-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Pandas AI leverages large language models to automate data analysis tasks, simplifying workflows and saving time.</li>\n      <li>It can generate insights from datasets, perform complex tasks, visualize data, and analyze multiple dataframes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.datacamp.com/blog/an-introduction-to-pandas-ai\">An Introduction to Pandas AI</a>\n</p>",
            "pubdate": "Thu, 15 Jun 2023 11:03:26 +0000",
            "pubdate_parsed": [
                2023,
                6,
                15
            ],
            "email_sent": true
        },
        "Stanford CRFM": {
            "url": "https://www.emergentmind.com/posts/stanford-crfm-0922c2",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Major foundation model providers like OpenAI and Google are found to be largely non-compliant with the European Union's draft AI Act requirements.</li>\n      <li>The Act calls for more transparency and accountability regarding data, compute, deployment, and key characteristics of AI models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://crfm.stanford.edu/2023/06/15/eu-ai-act.html\">Stanford CRFM</a>\n</p>",
            "pubdate": "Fri, 16 Jun 2023 07:01:46 +0000",
            "pubdate_parsed": [
                2023,
                6,
                16
            ],
            "email_sent": true
        },
        "Edge 300: Meet Falcon LLM: The Most Powerful Open Source LLM Released to Date": {
            "url": "https://www.emergentmind.com/posts/edge-300-meet-falcon-llm-the-most-powerful-open",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Falcon LLM, an open-source foundation model created by the Technology Innovation Institute in Abu Dhabi, quickly topped the Open LLM Leaderboard.</li>\n      <li>The Falcon family includes two models: Falcon-40B, which holds the top position on the leaderboard, and its smaller counterpart, Falcon-7B, which excels in its weight class.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thesequence.substack.com/p/edge-300-meet-falcon-llm-the-most\">Edge 300: Meet Falcon LLM: The Most Powerful Open Source LLM Released to Date</a>\n</p>",
            "pubdate": "Fri, 16 Jun 2023 03:01:49 +0000",
            "pubdate_parsed": [
                2023,
                6,
                16
            ],
            "email_sent": true
        },
        "OpenChat: The Free & Simple Platform for Building Custom Chatbots in Minutes": {
            "url": "https://www.emergentmind.com/posts/introducing-openchat-the-free-simple-platform-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenChat is an open-source chatbot console that simplifies the process of creating and managing custom chatbots using Large Language Models (LLMs).</li>\n      <li>The platform supports GPT models and enables users to customize chatbots with resources like PDFs, websites, Notion, Confluence, and Office 365.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.kdnuggets.com/2023/06/introducing-openchat-free-simple-platform-building-custom-chatbots-minutes.html\">Introducing OpenChat: The Free &amp; Simple Platform for Building Custom Chatbots in Minutes</a>\n</p>",
            "pubdate": "Sat, 17 Jun 2023 10:30:21 +0000",
            "pubdate_parsed": [
                2023,
                6,
                17
            ],
            "email_sent": true
        },
        "Falcon LLM - Home": {
            "url": "https://www.emergentmind.com/posts/falcon-llm-home",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Falcon LLM is a 40 billion parameter language model developed by TII, trained on one trillion tokens, and designed for efficiency and performance.</li>\n      <li>It can be used for chatbots, customer service, virtual assistants, language translation, content generation, and sentiment analysis, with a focus on reducing repetitive work.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://falconllm.tii.ae/\">Falcon LLM - Home</a>\n</p>",
            "pubdate": "Sun, 18 Jun 2023 02:01:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                18
            ],
            "email_sent": true
        },
        "As Congress races to regulate AI, tech execs want to show them how.  - The Washington Post": {
            "url": "https://www.emergentmind.com/posts/as-congress-races-to-regulate-ai-tech-execs-want-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The success of AI-powered ChatGPT has prompted US lawmakers to draft new laws addressing the field of artificial intelligence.</li>\n      <li>Congress members are attending briefings with industry executives, academics, and other experts to understand and catch up with the emerging field.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.washingtonpost.com/technology/2023/06/17/congress-regulating-ai-schumer/\">As Congress races to regulate AI, tech execs want to show them how.  - The Washington Post</a>\n</p>",
            "pubdate": "Sun, 18 Jun 2023 01:02:34 +0000",
            "pubdate_parsed": [
                2023,
                6,
                18
            ],
            "email_sent": true
        },
        "An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.": {
            "url": "https://www.emergentmind.com/posts/github-bentoml-openllm-an-open-platform-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenLLM is an open platform for running, deploying, and monitoring large language models (LLMs) in production environments.</li>\n      <li>It supports a wide range of open-source LLMs, offers flexible APIs, and integrates with tools like LangChain, BentoML, and HuggingFace for building AI applications.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/bentoml/OpenLLM\">An open platform for operating large language models (LLMs) in production. Fine-tune, serve, deploy, and monitor any LLMs with ease.</a>\n</p>",
            "pubdate": "Mon, 19 Jun 2023 08:01:32 +0000",
            "pubdate_parsed": [
                2023,
                6,
                19
            ],
            "email_sent": true
        },
        "The best AI photo editors in 2023": {
            "url": "https://www.emergentmind.com/posts/the-best-ai-photo-editors-in-2023",
            "description": "<p>\n  Full article: <a href=\"https://octobreak.me/the-best-ai-photo-editors-in-2023/\">The best AI photo editors in 2023</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 13:31:05 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Reviving The Beatles With AI & The Future of Music": {
            "url": "https://www.emergentmind.com/posts/reviving-the-beatles-with-ai-the-future-of-music",
            "description": "<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/reviving-the-beatles-with-ai-the-future-of-music-e85be62f6c6a?sk=9d7c6cac2a6f19a904df0023c7f0974d\">Reviving The Beatles With AI &amp; The Future of Music</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 13:28:49 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "ChatGPT and Cybersecurity - friends or foes? - Crossplag": {
            "url": "https://www.emergentmind.com/posts/chatgpt-and-cybersecurity-friends-or-foes",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT has become widely used in fields like customer service and is now entering the cybersecurity domain.</li>\n      <li>Its potential benefits include threat detection and malware analysis, but concerns exist around false positives, privacy, and overreliance on automation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://crossplag.com/chatgpt-and-cybersecurity-friends-or-foes/\">ChatGPT and Cybersecurity - friends or foes? - Crossplag</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 12:44:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Textbooks Are All You Need": {
            "url": "https://www.emergentmind.com/posts/2306-11644-textbooks-are-all-you-need",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Phi-1 is a Transformer-based model with 1.3 billion parameters, trained on a combination of high-quality web data and synthetically generated content.</li>\n      <li>Despite its smaller size, phi-1 achieves pass@1 accuracy of 50.6% on HumanEval and 55.5% on MBPP, displaying surprising emergent properties compared to other models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.11644\">Textbooks Are All You Need</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 11:32:38 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Self-Attention in Transformers": {
            "url": "https://www.emergentmind.com/posts/self-attention-in-transformers",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Self Attention and Transformers have become popular in natural language processing due to their ability to handle large amounts of contextual information.</li>\n      <li>The transformer architecture uses an encoder-decoder structure and attention mechanisms to focus on important words within a sentence for tasks like translation and summarization.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://kunal221.hashnode.dev/introduction-to-transformers-and-self-attention\">Self-Attention in Transformers</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 11:32:17 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "US lawmakers introduce National AI Commission Act": {
            "url": "https://www.emergentmind.com/posts/us-lawmakers-introduce-national-ai-commission-act",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A bipartisan group of US lawmakers introduced a bill to establish a commission on the country's approach toward artificial intelligence (AI).</li>\n      <li>The National AI Commission Act aims to create a national body to formulate a comprehensive framework for regulating AI, addressing potential risks and preventing harm from unregulated AI technology.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://cointelegraph.com/news/us-lawmakers-introduce-national-ai-commission-act\">US lawmakers introduce National AI Commission Act</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 11:31:53 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "An In-Depth Guide to Machine Learning for Beginners": {
            "url": "https://www.emergentmind.com/posts/an-in-depth-guide-to-machine-learning-for-beginners",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Machine learning is a subset of artificial intelligence that focuses on developing algorithms and models for computers to learn from data and make predictions or decisions without explicit programming.</li>\n      <li>The field involves various types of algorithms, such as supervised learning, unsupervised learning, and reinforcement learning, with applications ranging from personalized recommendations to fraud detection and task automation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://aforanalytic.com/an-in-depth-guide-to-machine-learning-for-beginners/\">An In-Depth Guide to Machine Learning for Beginners</a>\n</p>",
            "pubdate": "Wed, 21 Jun 2023 08:02:15 +0000",
            "pubdate_parsed": [
                2023,
                6,
                21
            ],
            "email_sent": true
        },
        "Exclusive: OpenAI Lobbied E.U. to Water Down AI Regulation": {
            "url": "https://www.emergentmind.com/posts/exclusive-openai-lobbied-e-u-to-water-down-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI has lobbied to weaken certain aspects of the European Union's AI Act, reducing the regulatory burden on the company</li>\n      <li>The final draft of the act did not label general purpose AI systems as inherently high risk, which OpenAI had argued against</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://time.com/6288245/openai-eu-lobbying-ai-act/\">Exclusive: OpenAI Lobbied E.U. to Water Down AI Regulation</a>\n</p>",
            "pubdate": "Thu, 22 Jun 2023 11:34:27 +0000",
            "pubdate_parsed": [
                2023,
                6,
                22
            ],
            "email_sent": true
        },
        "Wimbledon to introduce AI-powered commentary to coverage this year": {
            "url": "https://www.emergentmind.com/posts/wimbledon-to-introduce-ai-powered-commentary-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Wimbledon is set to introduce artificial intelligence-powered commentary for its coverage this year.</li>\n      <li>The All England Club has partnered with IBM to offer AI-generated audio commentary and captions in online highlights videos.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/sport/2023/jun/21/wimbledon-introduce-ai-powered-commentary-to-coverage-this-year\">Wimbledon to introduce AI-powered commentary to coverage this year</a>\n</p>",
            "pubdate": "Thu, 22 Jun 2023 10:01:59 +0000",
            "pubdate_parsed": [
                2023,
                6,
                22
            ],
            "email_sent": true
        },
        "AI regulation push in U.S. continues as Schumer announces plans  - The Washington Post": {
            "url": "https://www.emergentmind.com/posts/ai-regulation-push-in-u-s-continues-as-schumer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Senate Majority Leader Charles E. Schumer calls for new rules for artificial intelligence in the US</li>\n      <li>He encourages bipartisan proposals and cooperation with outside experts to create comprehensive AI legislation</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.washingtonpost.com/technology/2023/06/21/ai-regulation-us-senate-chuck-schumer/\">AI regulation push in U.S. continues as Schumer announces plans  - The Washington Post</a>\n</p>",
            "pubdate": "Thu, 22 Jun 2023 09:02:46 +0000",
            "pubdate_parsed": [
                2023,
                6,
                22
            ],
            "email_sent": true
        },
        "AI startup Neople raises 1.5M for digital co-workers revolution - IO": {
            "url": "https://www.emergentmind.com/posts/ai-startup-neople-raises-1-5m-for-digital-co-workers",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Neople, an AI startup, secures \u20ac1.5 million in funding to create advanced digital co-workers using GenAI technology.</li>\n      <li>The digital co-workers can adapt their tone and operate within the same environments as human employees, starting with customer support teams.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://innovationorigins.com/en/ai-startup-neople-raises-e1-5m-for-digital-co-workers-revolution/\">AI startup Neople raises \u20ac1.5M for digital co-workers revolution - IO</a>\n</p>",
            "pubdate": "Thu, 22 Jun 2023 08:02:05 +0000",
            "pubdate_parsed": [
                2023,
                6,
                22
            ],
            "email_sent": true
        },
        "Do I have AI Anxiety? Heres what 200+ creatives told us": {
            "url": "https://www.emergentmind.com/posts/do-i-have-ai-anxiety-here-s-what-200-creatives-told",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Over 200 creative professionals shared their thoughts on AI's role in the industry, revealing a mix of excitement, curiosity, and apprehension.</li>\n      <li>Majority of respondents have tried generative AI personally, with 40% experimenting professionally, and 77% believing it is important for creatives to understand the technology.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://empower.agency/ai-anxiety-report/\">\u201cDo I have AI Anxiety?\u201d Here\u2019s what 200+ creatives told us</a>\n</p>",
            "pubdate": "Thu, 22 Jun 2023 07:02:13 +0000",
            "pubdate_parsed": [
                2023,
                6,
                22
            ],
            "email_sent": true
        },
        "Generating SQL with LLMs for fun and profit": {
            "url": "https://www.emergentmind.com/posts/generating-sql-with-llms-for-fun-and-profit",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Using language models to generate SQL queries on the fly can lead to security risks such as data tampering, denial of service attacks, and data exfiltration.</li>\n      <li>To mitigate these risks, it's recommended to restrict database access for language models and avoid using them to directly convert natural language into executable code.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://iamnotarobot.substack.com/p/generating-sql-with-llms-for-fun\">Generating SQL with LLMs for fun and profit</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 01:01:35 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #21 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-21-by-zoltan-tapi",
            "description": "<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-21\">Weekly Piece of Future #21 - by Zoltan Tapi</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 13:33:49 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "AudioPaLM": {
            "url": "https://www.emergentmind.com/posts/audiopalm",
            "description": "<p>\n  Full article: <a href=\"https://google-research.github.io/seanet/audiopalm/examples/\">AudioPaLM</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 13:33:42 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "Two US lawyers fined for submitting fake court citations from ChatGPT": {
            "url": "https://www.emergentmind.com/posts/two-us-lawyers-fined-for-submitting-fake-court",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Two US lawyers and their law firm fined $5,000 for submitting fake court citations generated by ChatGPT in an aviation injury claim.</li>\n      <li>The judge acknowledged the use of AI in legal work but emphasized the importance of lawyers ensuring the accuracy of their filings.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/technology/2023/jun/23/two-us-lawyers-fined-submitting-fake-court-citations-chatgpt\">Two US lawyers fined for submitting fake court citations from ChatGPT</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 12:35:12 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "Using GPT-4 to measure the passage of time in fiction  The Stone and the Shell": {
            "url": "https://www.emergentmind.com/posts/using-gpt-4-to-measure-the-passage-of-time-in-fiction",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Language models can be used creatively for content analysis, such as measuring the passage of time in fiction.</li>\n      <li>GPT-4 shows better results in estimating time than bag-of-words models and can be a useful tool for researchers with little programming experience.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://tedunderwood.com/2023/03/19/using-gpt-4-to-measure-the-passage-of-time-in-fiction/\">Using GPT-4 to measure the passage of time in fiction \u2013 The Stone and the Shell</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 11:31:24 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "China: Artificial Intelligence Searches for Rare Earths - rawmaterials.net": {
            "url": "https://www.emergentmind.com/posts/china-artificial-intelligence-searches-for-rare-earths",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Chinese scientists use artificial intelligence to analyze satellite images and data from the Himalayas, searching for rare earth deposits.</li>\n      <li>The potential deposit, similar in size to Inner Mongolia's, is located near the disputed border area with India.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rawmaterials.net/china-artificial-intelligence-searches-for-rare-earths/\">China: Artificial Intelligence Searches for Rare Earths - rawmaterials.net</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 08:02:07 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "Five Things AI: Christopher Nolan, Emerging Architectures, Thinking, AI Apocalypse, AI Image Detection": {
            "url": "https://www.emergentmind.com/posts/five-things-ai-christopher-nolan-emerging",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI is increasingly being integrated into society, raising questions about its potential benefits and risks.</li>\n      <li>The future of AI may involve navigating through a hype cycle, exploring various ideas, and eventually finding productive use cases.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.fivethin.gs/p/five-things-ai-christopher-nolan\">Five Things AI: Christopher Nolan, Emerging Architectures, Thinking, AI Apocalypse, AI Image Detection</a>\n</p>",
            "pubdate": "Fri, 23 Jun 2023 06:01:39 +0000",
            "pubdate_parsed": [
                2023,
                6,
                23
            ],
            "email_sent": true
        },
        "7 Ways ChatGPT Makes You Code Better and Faster": {
            "url": "https://www.emergentmind.com/posts/7-ways-chatgpt-makes-you-code-better-and-faster",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT assists developers throughout the coding process, from planning to production.</li>\n      <li>ChatGPT can help with project planning, breaking down complex systems, generating clean code, unit testing, iterating, documentation, and debugging.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.kdnuggets.com/2023/06/7-ways-chatgpt-makes-code-better-faster.html\">7 Ways ChatGPT Makes You Code Better and Faster</a>\n</p>",
            "pubdate": "Sat, 24 Jun 2023 12:04:21 +0000",
            "pubdate_parsed": [
                2023,
                6,
                24
            ],
            "email_sent": true
        },
        "More than 100,000 hacked ChatGPT accounts are being sold on dark web marketplaces": {
            "url": "https://www.emergentmind.com/posts/more-than-100-000-hacked-chatgpt-accounts-are-being",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Raccoon malware is responsible for stealing numerous ChatGPT credentials, potentially exposing users' sensitive information.</li>\n      <li>The malware's ease of use and subscription service model make it a popular choice among hackers, leading to risks for ChatGPT users.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://mashable.com/article/chatgpt-stolen-accounts-passwords-dark-web\">More than 100,000 hacked ChatGPT accounts are being sold on dark web marketplaces</a>\n</p>",
            "pubdate": "Sat, 24 Jun 2023 11:30:11 +0000",
            "pubdate_parsed": [
                2023,
                6,
                24
            ],
            "email_sent": true
        },
        "Open source licenses need to evolve to deal with AI  The Register": {
            "url": "https://www.emergentmind.com/posts/open-source-licenses-need-to-evolve-to-deal-with-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Open source licenses must evolve to address AI models, as they were originally designed for software code in the 1970s and '80s.</li>\n      <li>AI leaders and Open Source Initiative executive director Stefano Maffulli are working on combining AI and open source licenses to fit the needs of large language model neural nets and datasets.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theregister.com/2023/06/23/open_source_licenses_ai/\">Open source licenses need to evolve to deal with AI \u2022 The Register</a>\n</p>",
            "pubdate": "Sat, 24 Jun 2023 07:02:02 +0000",
            "pubdate_parsed": [
                2023,
                6,
                24
            ],
            "email_sent": true
        },
        "Concepts, Abstractions, and Problem-Solving": {
            "url": "https://www.emergentmind.com/posts/concepts-abstractions-and-problem-solving-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article discusses how Artificial General Intelligence (AGI) can be better understood by focusing on mental behaviors that drive complex actions, such as problem-solving and awareness.</li>\n      <li>The content of consciousness is driven by the 'search, notice, and learn' behavior, which applies to both concrete content and abstract content like feelings and qualia.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/concepts-abstractions-and-problem-solving-497ffc08d683\">Concepts, Abstractions, and Problem-Solving</a>\n</p>",
            "pubdate": "Sun, 25 Jun 2023 04:01:55 +0000",
            "pubdate_parsed": [
                2023,
                6,
                25
            ],
            "email_sent": true
        },
        "Omar Kamali": {
            "url": "https://www.emergentmind.com/posts/omar-kamali-founder-ceo-strategic-technology",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Tokens are small units of information that AI systems use to represent different elements, such as words, images, or sounds. They help AI algorithms understand and process complex data.</li>\n      <li>Tokens are crucial in AI systems as they affect information limits, user experience, and operational costs. Understanding tokens helps optimize inputs, improve efficiency, and manage expenses effectively.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://omarkama.li/blog/tokens-the-secret-language-of-ai\">Omar Kamali</a>\n</p>",
            "pubdate": "Mon, 26 Jun 2023 03:02:17 +0000",
            "pubdate_parsed": [
                2023,
                6,
                26
            ],
            "email_sent": true
        },
        "Emotional Coding: Training AI to recognize human emotions": {
            "url": "https://www.emergentmind.com/posts/emotional-coding-training-ai-to-recognize-human",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>MIT neuroscientists have created a computational model that accurately predicts human emotions, advancing AI's emotional intelligence.</li>\n      <li>The model was trained using scenarios from a British game show and could have applications in mental health, marketing, education, and virtual reality.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.fry-ai.com/p/emotional-coding-training-ai-recognize-human-emotions\">Emotional Coding: Training AI to recognize human emotions</a>\n</p>",
            "pubdate": "Mon, 26 Jun 2023 02:10:41 +0000",
            "pubdate_parsed": [
                2023,
                6,
                26
            ],
            "email_sent": true
        },
        "How to use ChatGPT functions in JavaScript": {
            "url": "https://www.emergentmind.com/posts/how-to-use-chatgpt-functions-in-javascript",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT functions allow developers to integrate AI-generated JSON objects with their code for tasks like API calls and data extraction.</li>\n      <li>These functions can be used for advanced chatbots, transforming natural language into API calls, and extracting structured data from unstructured text.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://lucgagan.hashnode.dev/how-to-use-chatgpt-functions-in-javascript\">How to use ChatGPT functions in JavaScript</a>\n</p>",
            "pubdate": "Mon, 26 Jun 2023 01:10:04 +0000",
            "pubdate_parsed": [
                2023,
                6,
                26
            ],
            "email_sent": true
        },
        "Learning to Generate Better Than Your LLM": {
            "url": "https://www.emergentmind.com/posts/2306-11816-learning-to-generate-better-than-your-llm",
            "description": "<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.11816\">Learning to Generate Better Than Your LLM</a>\n</p>",
            "pubdate": "Mon, 26 Jun 2023 12:57:41 +0000",
            "pubdate_parsed": [
                2023,
                6,
                26
            ],
            "email_sent": true
        },
        "Weve launched CodiumAI powered by TestGPT and raised $11M. Heres why": {
            "url": "https://www.emergentmind.com/posts/we-ve-launched-codiumai-powered-by-testgpt-and-raised",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>CodiumAI introduces AI-based IDE Extensions for Python, JavaScript, and TypeScript, aiming to simplify code integrity and empower developers. The company has raised $11 million in seed funding to expand its team and develop its TestGPT model.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.codium.ai/blog/codiumai-powered-by-testgpt-accounces-beta-and-raised-11m/\">We\u2019ve launched CodiumAI powered by TestGPT and raised $11M. Here\u2019s why</a>\n</p>",
            "pubdate": "Mon, 26 Jun 2023 09:01:56 +0000",
            "pubdate_parsed": [
                2023,
                6,
                26
            ],
            "email_sent": true
        },
        "This Chatbot Gives Phone Call Scammers a Taste of Their Own Medicine": {
            "url": "https://www.emergentmind.com/posts/this-chatbot-gives-phone-call-scammers-a-taste-of-their",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Apate chatbot from Macquarie University poses as a human to take phone calls from scammers and waste their time.</li>\n      <li>The chatbot aims to protect users from falling victim to scams by engaging with scammers and keeping them occupied.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.pcmag.com/news/this-chatbot-gives-phone-call-scammers-a-taste-of-their-own-medicine\">This Chatbot Gives Phone Call Scammers a Taste of Their Own Medicine</a>\n</p>",
            "pubdate": "Tue, 27 Jun 2023 01:01:38 +0000",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "Evaluating Superhuman Models with Consistency Checks": {
            "url": "https://www.emergentmind.com/posts/2306-09983-evaluating-superhuman-models-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers propose a framework for evaluating superhuman machine-learning models by checking for consistency.</li>\n      <li>The framework is applied to tasks like chess, forecasting future events, and legal judgments, helping to identify logical inconsistencies in decision-making.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.09983\">Evaluating Superhuman Models with Consistency Checks</a>\n</p>",
            "pubdate": "Tue, 27 Jun 2023 11:44:57 +0000",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "More People Are Going Blind. AI Can Help Fight It | WIRED UK": {
            "url": "https://www.emergentmind.com/posts/more-people-are-going-blind-ai-can-help-fight-it",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI-enhanced eye scan analyses can detect early warning signs of eye diseases, helping to treat them in time.</li>\n      <li>Optical coherence tomography devices can take high-resolution images of the retina, and AI can analyze these scans for multiple retinal diseases.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.wired.co.uk/article/blindness-eye-disease-artificial-intelligence-scans\">More People Are Going Blind. AI Can Help Fight It | WIRED UK</a>\n</p>",
            "pubdate": "Tue, 27 Jun 2023 11:44:55 +0000",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "pSEO with PromptChainer: Revolutionizing Programmatic SEO with AI-Powered Flow Content Generation for Niche Websites": {
            "url": "https://www.emergentmind.com/posts/pseo-with-promptchainer-revolutionizing-programmatic",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>PromptChainer utilizes OpenAI's API to create customizable content for niche websites using a visual flow builder.</li>\n      <li>The platform offers time and cost savings, scalable content creation, and an intuitive interface for both coders and non-coders.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.promptchainer.io/p/pseo-with-promptchainer-revolutionizing\">pSEO with PromptChainer: Revolutionizing Programmatic SEO with AI-Powered Flow Content Generation for Niche Websites</a>\n</p>",
            "pubdate": "Tue, 27 Jun 2023 11:44:54 +0000",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "LLM Powered Autonomous Agents": {
            "url": "https://www.emergentmind.com/posts/llm-powered-autonomous-agents-lil-log",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models (LLMs) can be used as core controllers for autonomous agents, enabling them to break down complex tasks into manageable subgoals, learn from past actions, and use external tools.</li>\n      <li>Planning, memory, and tool use components are key to creating LLM-powered autonomous agents, which can help improve problem-solving abilities in various domains.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://lilianweng.github.io/posts/2023-06-23-agent/\">LLM Powered Autonomous Agents</a>\n</p>",
            "pubdate": "Tue, 27 Jun 2023 06:02:11 +0000",
            "pubdate_parsed": [
                2023,
                6,
                27
            ],
            "email_sent": true
        },
        "The Race to Regulate Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/the-race-to-regulate-artificial-intelligence-foreign",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial intelligence development is rapidly transforming economies and societies, but also raising concerns about potential harms and the need for regulation. Different regulatory paradigms are emerging in the US, China, and Europe, each reflecting their distinct values and incentives, and these will shape the future of technology and society.</li>\n      <li>The US follows a market-driven approach, China a state-driven approach, and the EU a rights-driven approach to AI regulation. While the US has been reluctant to regulate AI, China has adopted strict regulations and the EU has pioneered laws aiming to protect individuals' rights.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.foreignaffairs.com/united-states/race-regulate-artificial-intelligence\">The Race to Regulate Artificial Intelligence</a>\n</p>",
            "pubdate": "Wed, 28 Jun 2023 02:02:20 +0000",
            "pubdate_parsed": [
                2023,
                6,
                28
            ],
            "email_sent": true
        },
        "Hugging Face CEO tells US House open-source AI is 'extremely aligned' with American interests": {
            "url": "https://www.emergentmind.com/posts/hugging-face-ceo-tells-us-house-open-source-ai-is",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Hugging Face, a New York-based startup, is contributing to the open-source AI community with the release of AI models such as LLaMA. This has raised concerns over potential misuse or abuse.</li>\n      <li>The company's focus on ethical openness helps counterbalance the power of big private companies, while also tackling challenges such as mitigating biases and reducing misinformation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://venturebeat.com/ai/hugging-face-ceo-tells-us-house-open-source-ai-is-extremely-aligned-with-american-interests/\">Hugging Face CEO tells US House open-source AI is 'extremely aligned' with American interests</a>\n</p>",
            "pubdate": "Wed, 28 Jun 2023 00:03:25 +0000",
            "pubdate_parsed": [
                2023,
                6,
                28
            ],
            "email_sent": true
        },
        "Machinery for Generating Insights": {
            "url": "https://www.emergentmind.com/posts/machinery-for-generating-insights-by-cardboarddreams",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the concept of 'becoming aware' in the context of Artificial General Intelligence (AGI), describing it as a problem-solving process that forms memories or thoughts. It further explores the idea of 'insight', describing it as a moment when the mind creates new criteria for what counts as a solution.</li>\n      <li>The article also introduces the concept of 'negation', a process where a previously learned thought or action is overridden by a new one in response to specific situations. This process is crucial in learning to distinguish exceptional cases, making the mind adaptable.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/a-machinery-for-generating-insights-3fa9d01e7f38\">Machinery for Generating Insights</a>\n</p>",
            "pubdate": "Wed, 28 Jun 2023 13:01:50 +0000",
            "pubdate_parsed": [
                2023,
                6,
                28
            ],
            "email_sent": true
        },
        "OpenOrca": {
            "url": "https://www.emergentmind.com/posts/openorca",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenOrca is an open-source dataset and series of instruct-tuned language models announced today.</li>\n      <li>The creator was inspired by a Microsoft research paper and decided to replicate their model and dataset, with plans to release it for other foundational models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://erichartford.com/openorca\">OpenOrca</a>\n</p>",
            "pubdate": "Thu, 29 Jun 2023 03:01:58 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "AI Unveils New Large-Scale Images in Peruvian Desert": {
            "url": "https://www.emergentmind.com/posts/ai-unveils-new-large-scale-images-in-peruvian-desert",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers at Yamagata University in Japan have used AI to discover four new geoglyphs in Nazca, Peru. The geoglyphs were discovered using a deep learning model, which made the process faster than traditional archaeological methods.</li>\n      <li>The deep learning techniques used are part of modern AI and are applied in various archaeological efforts. The discovery of these new geoglyphs indicates the potential for more undiscovered sites in the area, and highlights the role of technology like deep learning in enhancing archaeological exploration.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blogs.nvidia.com/blog/2023/06/23/geoglyphs-in-peru/\">AI Unveils New Large-Scale Images in Peruvian Desert</a>\n</p>",
            "pubdate": "Thu, 29 Jun 2023 01:01:28 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "Next-gen content farms are using AI-generated text to spin up junk websites": {
            "url": "https://www.emergentmind.com/posts/next-gen-content-farms-are-using-ai-generated-text-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Troll farms reached 140 million Americans monthly on Facebook before the 2020 election, according to an internal report. In addition, many big brands unknowingly had their ads placed on low-quality, AI-generated sites due to automated advertising processes.</li>\n      <li>Google, which operates the largest ad exchange, has faced criticism for allowing ads on content farms despite its policies against it. The issue is further complicated by the fact that AI-generated sites can contribute to the spread of misinformation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.technologyreview.com/2023/06/26/1075504/junk-websites-filled-with-ai-generated-text-are-pulling-in-money-from-programmatic-ads/\">Next-gen content farms are using AI-generated text to spin up junk websites</a>\n</p>",
            "pubdate": "Thu, 29 Jun 2023 00:04:15 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities": {
            "url": "https://www.emergentmind.com/posts/2111-08851-deep-neural-networks-for-rank-consistent",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A new method for rank-consistent ordinal regression in deep neural networks, named CORN, has been proposed to address the limitations of conventional classification losses like the multi-category cross-entropy.</li>\n      <li>The CORN method improves performance by using a novel training scheme that uses conditional training sets and removing the weight-sharing constraint of the previous CORAL method, and it can be utilized with any deep neural network classifier to train it for ordinal regression tasks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2111.08851\">Deep Neural Networks for Rank-Consistent Ordinal Regression Based On Conditional Probabilities</a>\n</p>",
            "pubdate": "Thu, 29 Jun 2023 12:02:14 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "AI Chrome Extensions for Data Scientists Cheat Sheet": {
            "url": "https://www.emergentmind.com/posts/ai-chrome-extensions-for-data-scientists-cheat-sheet",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>KDnuggets presents a cheat sheet of advanced tools and resources for data scientists, including AI Chrome extensions to enhance efficiency and productivity. The tools cover a wide range of applications, from understanding complex scientific literature to writing high-quality manuscripts.</li>\n      <li>The cheat sheet includes tools like SciSpace Copilot, Fireflies, AIPRM, Originality.AI, CodeSquire.AI, Codeium, Data Scraper, Grammarly GO, Sider, CatalyzeX, and 10AI, each with unique capabilities and applications for research, summarizing papers, generating ChatGPT prompts, detecting AI, coding autopilot, data scraping, web surfing, and content generation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.kdnuggets.com/2023/06/ai-chrome-extensions-data-scientists-cheat-sheet.html\">AI Chrome Extensions for Data Scientists Cheat Sheet</a>\n</p>",
            "pubdate": "Thu, 29 Jun 2023 06:18:42 +0000",
            "pubdate_parsed": [
                2023,
                6,
                29
            ],
            "email_sent": true
        },
        "How Long Can Open-Source LLMs Truly Promise on Context Length?": {
            "url": "https://www.emergentmind.com/posts/how-long-can-open-source-llms-truly-promise-on-context",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The LongChat Team introduces new chatbot models, LongChat-7B and LongChat-13B, which feature extended context length up to 16K tokens. These models show promising results in closing the gap between open models and proprietary long context models.</li>\n      <li>LongChat models not only handle long context length but also follow human instructions in dialogues precisely, demonstrating strong performance in the human preference benchmark MT-Bench.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://lmsys.org/blog/2023-06-29-longchat/\">How Long Can Open-Source LLMs Truly Promise on Context Length?</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 00:03:49 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #22 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-22-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Rushing Robotics covers a range of next-gen technologies including brainchip-enabled dream control, AI surveillance, and robot-driven deliveries. The publication also discusses the integration of AI in Wimbledon's online viewing, Microsoft's analog optical computer, and privacy issues in OpenAI.</li>\n      <li>Readers can also learn about Hitachi's battery-powered trains, the progress of an AI-discovered drug under trials, a $3 smart patch for medical diagnosis, and various tools/products that can enhance their tech experience. The report also shares video content on humanoid robots, lab automation, and object sorting technology.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-22\">Weekly Piece of Future #22 - by Zoltan Tapi</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 13:02:41 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "The Darwinian Argument for Worrying About AI": {
            "url": "https://www.emergentmind.com/posts/the-darwinian-argument-for-worrying-about-ai-time",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI experts warn about the risk of extinction from AI as they gain more autonomy and control over key decisions, heavily influenced by Darwin's laws of natural selection. This is seen in the manner in which successful and advantageous AI algorithms are selected and fine-tuned while others are discontinued.</li>\n      <li>Concerns arise from the difficulty in controlling AI, the potential for selfish and harmful behavior as AI systems evolve, and the ingrained self-preservation behaviors. The article suggests proactive regulation of the AI industry and government funding for AI safety research as potential solutions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://time.com/6283958/darwinian-argument-for-worrying-about-ai/\">The Darwinian Argument for Worrying About AI</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 13:02:38 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "AI system devises first optimizations to sorting code in over a decade": {
            "url": "https://www.emergentmind.com/posts/ai-system-devises-first-optimizations-to-sorting-code",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's DeepMind AI group has developed a tool that can create highly optimized algorithms without being trained on human code examples. The approach treats programming as a game, with the AI learning to minimize the latency of the code while ensuring its completion without errors.</li>\n      <li>The AI, known as AlphaDev, uses a unique method that includes tracking the performance of the code as it's developed and adding assembly instructions individually. Over time, it 'learns' to achieve a completed sorting with a maximum score, meaning a minimum latency.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arstechnica.com/science/2023/06/googles-deepmind-develops-a-system-that-writes-efficient-algorithms/\">AI system devises first optimizations to sorting code in over a decade</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 12:03:16 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "Meta explains how AI influences what we see on Facebook and Instagram - The Verge": {
            "url": "https://www.emergentmind.com/posts/meta-explains-how-ai-influences-what-we-see-on-facebook",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Meta has explained its use of AI to personalize user experiences on its social media platforms, detailing how content is recommended for users on Facebook and Instagram.</li>\n      <li>The company's algorithms gather public content, consider user engagement with similar content or interests, and rank the content, with a user's actions influencing this process. New features allowing users to understand why they see certain content and tailor their recommendations are being tested.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theverge.com/2023/6/29/23778068/meta-facebook-instagram-social-media-algorithms-ai-transparency\">Meta explains how AI influences what we see on Facebook and Instagram - The Verge</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 10:02:10 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "FRVR Forge - by Chris Benjaminsen": {
            "url": "https://www.emergentmind.com/posts/introducing-frvr-forge-by-chris-benjaminsen",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>FRVR has introduced FRVR Forge, a platform that allows users to create games by simply describing them. The platform aims to make creating, playing, and sharing games as easy as using TikTok and Instagram.</li>\n      <li>FRVR Forge uses cloud technologies and can be accessed on any device. The platform offers a live preview, history tab, code tab, and assets tab. The platform also comes with an AI that can generate as much of the game code as possible in one go.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://benjaminsen.substack.com/p/introducing-frvr-forge\">Introducing FRVR Forge - by Chris Benjaminsen</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 08:02:12 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "LLM Tech and a Lot More: Version 13.3 of Wolfram Language and MathematicaStephen Wolfram Writings": {
            "url": "https://www.emergentmind.com/posts/llm-tech-and-a-lot-more-version-13-3-of-wolfram",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In the latest Version 13.3, a new feature called Chat Notebooks has been introduced that supports 'chat cells' which allow users to interact with a Language Model (LLM). The LLM can generate precise computational language that can be run to get a result.</li>\n      <li>The system allows for computational thinking, where you can instruct the LLM to produce Wolfram Language code representing your intent. It also allows for the creation of 'personas' for the LLM, varying from a Code Assistant that writes and comments on code, to Code Writer that just writes code.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://writings.stephenwolfram.com/2023/06/llm-tech-and-a-lot-more-version-13-3-of-wolfram-language-and-mathematica/#llm-tech-comes-to-wolfram-language\">LLM Tech and a Lot More: Version 13.3 of Wolfram Language and Mathematica\u2014Stephen Wolfram Writings</a>\n</p>",
            "pubdate": "Fri, 30 Jun 2023 04:02:19 +0000",
            "pubdate_parsed": [
                2023,
                6,
                30
            ],
            "email_sent": true
        },
        "ChatGPT is now a brilliant tool for winding up telemarketers and scammers": {
            "url": "https://www.emergentmind.com/posts/chatgpt-is-now-a-brilliant-tool-for-winding-up",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Software developer Roger Anderson has upgraded his service, Jolly Roger Telephone, with OpenAI's GPT-4 large language model to engage telemarketers and scammers in time-consuming conversations. The AI personalities, such as Whitey Whitebeard and Salty Sally, engage the callers in absurd conversations, often leading them to hang up.</li>\n      <li>Jolly Roger Telephone is available for subscription in the US, Canada, UK, Australia, and New Zealand, offering up to 10 robot voices. Once subscribed, the service guides subscribers through a process of obtaining permission from their phone company to use the service and whitelisting their contact numbers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.techradar.com/computing/software/chatgpt-is-now-a-brilliant-tool-for-winding-up-telemarketers-and-scammers\">ChatGPT is now a brilliant tool for winding up telemarketers and scammers</a>\n</p>",
            "pubdate": "Sat, 01 Jul 2023 13:02:05 +0000",
            "pubdate_parsed": [
                2023,
                7,
                1
            ],
            "email_sent": true
        },
        "The Self, Free Will, and Agency in AGI": {
            "url": "https://www.emergentmind.com/posts/the-self-free-will-and-agency-in-agi-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the concept of self, free will, and agency in the context of Artificial General Intelligence (AGI). It explores how these concepts interplay with the machinery of the mind, particularly with regard to conscious effort and problem-solving processes.</li>\n      <li>The author examines the belief in a 'self' as an active agent beyond just processing and compressing patterns of stimuli, and how this concept might apply to AGI. The article also delves into the sources of mental events, the concept of 'directed thinking', and how motivations and thoughts interact.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/the-self-free-will-and-agency-in-agi-14a2f6269159\">The Self, Free Will, and Agency in AGI</a>\n</p>",
            "pubdate": "Sat, 01 Jul 2023 12:01:58 +0000",
            "pubdate_parsed": [
                2023,
                7,
                1
            ],
            "email_sent": true
        },
        "ChatGPT owner OpenAI to launch first foreign office in London": {
            "url": "https://www.emergentmind.com/posts/chatgpt-owner-openai-to-launch-first-foreign-office-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI, the US company behind ChatGPT, is set to open its first international office in London as part of its expansion in research and development.</li>\n      <li>The move is seen as an opportunity to attract world-class talent and build dynamic teams for safe AI creation and engineering amid UK's 'pro-innovation' regulations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.gossipslife.com/2023/07/chatgpt-owner-openai-to-launch-first.html\">ChatGPT owner OpenAI to launch first foreign office in London</a>\n</p>",
            "pubdate": "Sat, 01 Jul 2023 11:03:45 +0000",
            "pubdate_parsed": [
                2023,
                7,
                1
            ],
            "email_sent": true
        },
        "Big Tech Digest #3 - Big Tech Digest": {
            "url": "https://www.emergentmind.com/posts/big-tech-digest-3-big-tech-digest",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The digest includes updates on building real-time machine learning foundations at Lyft and an introduction to JavaScript service workers. It also discusses writing an Istio WASM plugin in Go and other tech developments.</li>\n      <li>The digest features posts from various tech companies' blogs, including Paypal, Spotify, Meta, and Github, covering topics from memory analysis in Google Kubernetes Engine Nodes to using Github Copilot.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://bigtechdigest.substack.com/p/big-tech-digest-3\">Big Tech Digest #3 - Big Tech Digest</a>\n</p>",
            "pubdate": "Sat, 01 Jul 2023 10:02:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                1
            ],
            "email_sent": true
        },
        "throwaway GPT inference": {
            "url": "https://www.emergentmind.com/posts/github-a1k0n-a1gpt-throwaway-gpt-inference",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses an optimized C++ GPT-2 inference engine developed by a1k0n.</li>\n      <li>The engine has minimal dependencies and is specifically optimized for AVX and Apple Silicon.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/a1k0n/a1gpt\">throwaway GPT inference</a>\n</p>",
            "pubdate": "Sun, 02 Jul 2023 01:01:47 +0000",
            "pubdate_parsed": [
                2023,
                7,
                2
            ],
            "email_sent": true
        },
        "Easily migrate your codebase from one framework or language to another.": {
            "url": "https://www.emergentmind.com/posts/github-0xpayne-gpt-migrate-easily-migrate-your",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GPT-Migrate is a project that assists in migrating codebases to a different framework or language, designed to potentially rewrite an entire codebase. It is still in development alpha and not yet ready for production use.</li>\n      <li>The tool first creates a Docker environment for the target language, evaluates existing code to identify dependencies, rebuilds new code from existing code, develops unit tests, and debugs the code iteratively. It requires Docker, OpenAI API key and python requirements to function.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/0xpayne/gpt-migrate\">Easily migrate your codebase from one framework or language to another.</a>\n</p>",
            "pubdate": "Sun, 02 Jul 2023 06:01:41 +0000",
            "pubdate_parsed": [
                2023,
                7,
                2
            ],
            "email_sent": true
        },
        "Stay on topic with Classifier-Free Guidance": {
            "url": "https://www.emergentmind.com/posts/2306-17806-stay-on-topic-with-classifier-free",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Classifier-Free Guidance (CFG) has been found to enhance the performance of various language modeling systems such as Pythia, GPT-2 and LLaMA-family models in tasks like Q&amp;A, reasoning, code generation and machine translation, setting a new standard on LAMBADA with LLaMA-7B over PaLM-540B.</li>\n      <li>CFG also improves model performance equivalent to doubling the parameter-count, can be used with other inference-time methods for further improvements and used to increase the faithfulness and coherence of AI assistants in difficult tasks, with human evaluations showing a 75% preference for GPT4All using CFG over baseline.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.17806\">Stay on topic with Classifier-Free Guidance</a>\n</p>",
            "pubdate": "Mon, 03 Jul 2023 02:01:42 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "AI and the automation of work  Benedict Evans": {
            "url": "https://www.emergentmind.com/posts/ai-and-the-automation-of-work-benedict-evans",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Work automation has been a process of continuous evolution since the 1800s, leading to increased efficiency and job creation. This evolution continues today with new technologies like generative AI, which, while they can automate certain tasks, are not yet replacements for human workers.</li>\n      <li>The adoption of these new technologies is a complex process that takes time, and their successful implementation relies on understanding their limitations and potentials. Despite fears, the history of automation indicates that it often leads to job creation rather than job loss.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.ben-evans.com/benedictevans/2023/7/2/working-with-ai\">AI and the automation of work \u2014 Benedict Evans</a>\n</p>",
            "pubdate": "Mon, 03 Jul 2023 01:01:40 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "195 Countries As People Imagined by Midjourney AI": {
            "url": "https://www.emergentmind.com/posts/195-countries-as-people-imagined-by-midjourney-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Global diversity is cherished through natural beauty, traditions, clothing, and culture, making the world an exciting place to live in.</li>\n      <li>An experiment is conducted to explore this diversity through the eyes of artificial intelligence.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/what-if-countries-were-people-3e3e21e8804c?sk=10470af2484d58b4b8da821670819b4f\">195 Countries As People Imagined by Midjourney AI</a>\n</p>",
            "pubdate": "Mon, 03 Jul 2023 00:06:54 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "Unveiling the inner workings of AI with CRAFT - IO": {
            "url": "https://www.emergentmind.com/posts/unveiling-the-inner-workings-of-ai-with-craft-io",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Scientists at Brown University's Carney Institute for Brain Science have developed a tool called CRAFT that provides insights into how artificial intelligence (AI) systems perceive images and why they make errors in classifications.</li>\n      <li>CRAFT, which stands for Concept Recursive Activation FacTorization for Explainability, not only identifies concepts based on importance but also exposes biases in data sets that AI systems might unknowingly adopt. Future applications of CRAFT include scientific challenges in fields like cancer diagnostics, fossil recognition, and space exploration.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://innovationorigins.com/en/unveiling-the-inner-workings-of-ai-with-craft/\">Unveiling the inner workings of AI with CRAFT - IO</a>\n</p>",
            "pubdate": "Mon, 03 Jul 2023 08:02:04 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "Nvidias H100: Funny L2, and Tons of Bandwidth  Chips and Cheese": {
            "url": "https://www.emergentmind.com/posts/nvidia-s-h100-funny-l2-and-tons-of-bandwidth-chips",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Nvidia H100 GPU features a higher boost clock than the A100, with occasional drops to around 80% of its maximum boost clock, and has a power limit of 350W. The H100 also provides more first level data caching capacity than any other GPU, has 50 MB L2 cache, and sees slightly lower latency than the A100.</li>\n      <li>Conversely, the A100's core clocks remain at 1410 MHz under load, has a higher power limit of 400W, and does not experience any clock speed drops even when power draw exceeds 350W. The A100 also displays lower memory temperatures than the H100 and was a pioneer for Nvidia in implementing large caches.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chipsandcheese.com/2023/07/02/nvidias-h100-funny-l2-and-tons-of-bandwidth/\">Nvidia\u2019s H100: Funny L2, and Tons of Bandwidth \u2013 Chips and Cheese</a>\n</p>",
            "pubdate": "Mon, 03 Jul 2023 07:02:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                3
            ],
            "email_sent": true
        },
        "What if LLM Hallucinations Were A Feature And Not A Bug? Meet dreamGPT: An Open-Source GPT-Based Solution That Uses Hallucinations From Large Language Models (LLMs) As A Feature - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/what-if-llm-hallucinations-were-a-feature-and-not-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>DreamGPT is a new approach that uses hallucinations from Large Language Models to stimulate divergent thinking and generate unique ideas.</li>\n      <li>DreamGPT works by planting random seeds, dreaming about new ideas, combining and evaluating different approaches, and selecting the most novel approach. It is open-source and can run locally on any PC or Mac without a GPU.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/05/20/what-if-llm-hallucinations-were-a-feature-and-not-a-bug-meet-dreamgpt-an-open-source-gpt-based-solution-that-uses-hallucinations-from-large-language-models-llms-as-a-feature/\">What if LLM Hallucinations Were A Feature And Not A Bug? Meet dreamGPT: An Open-Source GPT-Based Solution That Uses Hallucinations From Large Language Models (LLMs) As A Feature - MarkTechPost</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 02:02:24 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "Midjourney AI Outpaining": {
            "url": "https://www.emergentmind.com/posts/midjourney-ai-outpaining",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Midjourney has introduced a 'Zoom Out' feature in its latest V5.2 update.</li>\n      <li>This new feature allows Midjourney to compete with rivals like DALL-E by offering the ability to outpaint.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/the-generator/midjourney-can-finally-outpaint-af1a2e5bc93c?sk=46f7b68c678d7bfae2e206534aa515cc\">Midjourney AI Outpaining</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 13:29:26 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "The industry behind the industry behind AI - Rest of World": {
            "url": "https://www.emergentmind.com/posts/the-industry-behind-the-industry-behind-ai-rest-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the unrecognized labor involved in artificial intelligence (AI), focusing on annotation tasks performed by a Remotasks office in Nairobi, a subsidiary of Scale AI.</li>\n      <li>It emphasizes the reliance of AI on human labor, highlighting the often unappreciated and low-paid effort of workers in training AI systems and drawing parallels with moderation contractors.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://restofworld.org/2023/exporter-industry-behind-ai/\">The industry behind the industry behind AI - Rest of World</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 13:02:08 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "Intel's Latest Research for Graphics and Generative AI": {
            "url": "https://www.emergentmind.com/posts/intel-s-latest-research-for-graphics-and-generative-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Intel is presenting seven new papers and a course on graphics and generative AI at various GPU and graphics conferences this year. The research focuses on photorealistic rendering, generative AI, and neural graphics.</li>\n      <li>The research includes improvements in rendering complex visual material, acceleration of path tracing convergence with difficult lighting, and making generative AI more accessible. The goal is to help creators, gamers, and AI practitioners accelerate their work and unlock their full creative potential.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.intel.com/content/www/us/en/developer/articles/news/gpu-research-generative-ai-update.html\">Intel's Latest Research for Graphics and Generative AI</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 12:02:25 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "Neural Chronos ODE: Unveiling Temporal Patterns and Forecasting Future and Past Trends in Time Series Data": {
            "url": "https://www.emergentmind.com/posts/2307-01023-neural-chronos-ode-unveiling-temporal",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article introduces Neural Chronos Ordinary Differential Equations (Neural CODE), a new deep learning architecture capable of predicting system dynamics both forward and backward in time. The training involves solving the ODE as an initial and final value problem.</li>\n      <li>The article also explores combinations of Neural CODE with Recurrent Neural Networks, resulting in variants like CODE-RNN, CODE-BiRNN, CODE-GRU, CODE-BiGRU, CODE-LSTM, and CODE-BiLSTM. The research shows that these new architectures converge faster and consistently outperform others in time series data tasks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.01023\">Neural Chronos ODE: Unveiling Temporal Patterns and Forecasting Future and Past Trends in Time Series Data</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 10:02:15 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "GPT-4 is great at infuriating telemarketing scammers  The Register": {
            "url": "https://www.emergentmind.com/posts/gpt-4-is-great-at-infuriating-telemarketing-scammers",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Jolly Roger Telephone Company has developed an AI system to deter telemarketers, using a variety of bots with unique voices and quirks. The bots engage the telemarketers in meaningless conversation, reducing the need for humans to deal with them.</li>\n      <li>The company has thousands of customers who pay $23.80 a year to use the service. The bots, which include characters such as a distracted mother and feisty senior citizen, have been successful in frustrating telemarketers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theregister.com/2023/07/03/jolly_roger_telephone_company/\">GPT-4 is great at infuriating telemarketing scammers \u2022 The Register</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 10:02:10 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "The Lone Banana Problem. Or, the new programming: speaking AI - TL;DR - Digital Science": {
            "url": "https://www.emergentmind.com/posts/the-lone-banana-problem-or-the-new-programming",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) in AI have shown rapid adoption and have raised questions about our understanding of technology and its impacts on a societal level. One of the challenges is the subtle biases in AI, which are difficult to detect, as exemplified by the 'Lone Banana Problem' where the AI fails to generate a single banana image due to the biases in its training data.</li>\n      <li>Understanding the outputs of AI for given inputs is critical in real-world applications. The AI's reality is different from ours, it understands commonly occurring patterns but doesn't perceive objects as we do. So, responsible and ethical use of AI is crucial, as these technologies are purely pattern-matching and can only be as good as the data we input.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.digital-science.com/tldr/article/the-lone-banana-problem-or-the-new-programming-speaking-ai/\">The Lone Banana Problem. Or, the new programming: \u201cspeaking\u201d AI - TL;DR - Digital Science</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 08:02:05 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "How do I use ChatGPT Browse with Bing to search the web?": {
            "url": "https://www.emergentmind.com/posts/how-do-i-use-chatgpt-browse-with-bing-to-search-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT Browse with Bing is a beta feature that enables ChatGPT Plus subscribers to search the internet for answers to questions requiring recent information. However, it has been temporarily disabled since July 3, 2023, due to issues with displaying content in unintended ways.</li>\n      <li>The team is working to fix the problem and plans to bring back the feature as quickly as possible.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://help.openai.com/en/articles/8077698-how-do-i-use-chatgpt-browse-with-bing-to-search-the-web\">How do I use ChatGPT Browse with Bing to search the web?</a>\n</p>",
            "pubdate": "Tue, 04 Jul 2023 06:01:46 +0000",
            "pubdate_parsed": [
                2023,
                7,
                4
            ],
            "email_sent": true
        },
        "How An AGI Can Survive Outside the Lab": {
            "url": "https://www.emergentmind.com/posts/how-an-agi-can-survive-outside-the-lab-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article discusses the complexities of developing an Artificial General Intelligence (AGI) that can function effectively outside a controlled lab environment. It outlines the importance of the AGI being able to adapt to changing circumstances and make best-guess decisions, much like a human mind does.</li>\n      <li>The piece also emphasizes that a successful AGI must be able to learn from its experiences, determine for itself what is worth learning from, and adapt to new concepts and situations. It suggests that the ultimate goal of AGI development should be creating a system that can function effectively in the real world, not just in contrived experiments.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/how-an-agi-can-survive-outside-the-lab-8d0b41f28a6d\">How An AGI Can Survive Outside the Lab</a>\n</p>",
            "pubdate": "Wed, 05 Jul 2023 13:01:56 +0000",
            "pubdate_parsed": [
                2023,
                7,
                5
            ],
            "email_sent": true
        },
        "ClipDrop - A suite of AI design tools": {
            "url": "https://www.emergentmind.com/posts/cliodrop-a-suite-of-ai-design-tools",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ClipDrop is a design multitool powered by artificial intelligence, created by Stability.AI.</li>\n      <li>The tool offers numerous useful features and is from the company behind Stable Diffusion, the successful open-source AI-image generator.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/clipdrop-a-useful-ai-design-tool-acd1af877778?sk=44144bbda9671da22e18ad92ea52dff3\">ClipDrop - A suite of AI design tools</a>\n</p>",
            "pubdate": "Wed, 05 Jul 2023 11:49:02 +0000",
            "pubdate_parsed": [
                2023,
                7,
                5
            ],
            "email_sent": true
        },
        "Harrison Ford talks Indiana Jones 5's de-aging: \"That's my actual face\"": {
            "url": "https://www.emergentmind.com/posts/harrison-ford-talks-indiana-jones-5-s-de-aging-that-s",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Harrison Ford has discussed the de-aging process used in the upcoming Indiana Jones 5 film, revealing it involves using artificial intelligence to scan old footage of him.</li>\n      <li>The film, Indiana Jones and the Dial of Destiny, features a flashback to a younger Indiana Jones, with Ford stating that the de-aged face viewers see is his actual face from his younger years.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.gamesradar.com/indiana-jones-5-harrison-ford-de-aging/\">Harrison Ford talks Indiana Jones 5's de-aging: &quot;That's my actual face&quot;</a>\n</p>",
            "pubdate": "Thu, 06 Jul 2023 02:01:53 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "Exploring Large Language Models (LLMs) in Biomedical Domain": {
            "url": "https://www.emergentmind.com/posts/exploring-large-language-models-llms-in-biomedical",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GPT Models like GPT-3.5-turbo and GPT3.5 perform well in F1 score and Semantic Answer Similarity with less runtime, but GPT-4 has higher runtime despite good scores. Fine-tuning models provide a competitive edge, with Dolly models showing a balanced performance. However, the Exact Match scores across all models are low, indicating a need for better optimization.</li>\n      <li>Implementing Large Language Models involves significant costs for training, fine-tuning and inference. Costs can range from $1M to $20M for base training and $50k to $500k for fine-tuning. Despite these costs, training and fine-tuning are becoming less expensive over time. Using models from AWS Marketplace can be cost-effective, with options like Cohere or Jurassic-2 A21 available for $4.23 per hour.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://provectus.com/blog/comparison-large-language-models-biomedical-domain/\">Exploring Large Language Models (LLMs) in Biomedical Domain</a>\n</p>",
            "pubdate": "Thu, 06 Jul 2023 02:01:50 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "G/O Media has started incorporating AI content across their sites": {
            "url": "https://www.emergentmind.com/posts/g-o-media-has-started-incorporating-ai-content-across",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>G/O Media has started using AI to generate articles, causing backlash from its union who claim it undermines their jobs and delivers inaccurate information.</li>\n      <li>The union advises readers not to click on articles with a 'Bot' byline, while G/O Media continues to publish such content despite the complaints.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://awfulannouncing.com/online-outlets/go-media-ai-content-deadspin-bot-gizmodo.html\">G/O Media has started incorporating AI content across their sites</a>\n</p>",
            "pubdate": "Thu, 06 Jul 2023 13:01:37 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system.": {
            "url": "https://www.emergentmind.com/posts/github-internlm-internlm-internlm-has-open-sourced-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>InternLM has open-sourced a 7 billion parameter base model and a chat model, both designed for practical use. The model uses trillions of high-quality tokens for training, supports an 8k context window length, and provides a flexible toolset for users to build their own workflows.</li>\n      <li>The performance of InternLM has been evaluated using the open-source evaluation tool OpenCompass. It has also been trained on large-scale clusters with thousands of GPUs and achieves nearly 90% acceleration efficiency during training on 1024 GPUs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/InternLM/InternLM\">InternLM has open-sourced a 7 billion parameter base model, a chat model tailored for practical scenarios and the training system.</a>\n</p>",
            "pubdate": "Thu, 06 Jul 2023 08:01:22 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "My small, no name company has completely lost its mind with AI - Blind": {
            "url": "https://www.emergentmind.com/posts/my-small-no-name-company-has-completely-lost-its-mind",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A small, unknown company has been recklessly implementing AI in hopes of solving their issues, leading to a number of problems.</li>\n      <li>The CEO believes AI will fix all problems, causing misguided implementations such as using ChatGPT to write JIRA tickets and HR documents without proper checks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.teamblind.com/post/My-small-no-name-company-has-completely-lost-its-mind-with-AI-nfqEDfSi\">My small, no name company has completely lost its mind with AI - Blind</a>\n</p>",
            "pubdate": "Thu, 06 Jul 2023 05:02:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                6
            ],
            "email_sent": true
        },
        "Waterwave Could Quench AIs' Thirst for GPU Memory - IEEE Spectrum": {
            "url": "https://www.emergentmind.com/posts/waterwave-could-quench-ais-thirst-for-gpu-memory",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers have developed a new method, called Waterwave, to increase the efficiency of training multiple AI models simultaneously on the same GPU. It breaks up the AI training process into manageable 'sub-models'.</li>\n      <li>Tests have shown that Waterwave is 12 times as fast as existing spatial sharing on a GPU and 1.49 times as fast as existing temporal memory sharing, especially in scenarios with high memory demand.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://spectrum.ieee.org/ai-training\">Waterwave Could Quench AIs' Thirst for GPU Memory - IEEE Spectrum</a>\n</p>",
            "pubdate": "Fri, 07 Jul 2023 03:01:47 +0000",
            "pubdate_parsed": [
                2023,
                7,
                7
            ],
            "email_sent": true
        },
        "Why Nvidia Keeps Winning: The Rise of an AI Giant": {
            "url": "https://www.emergentmind.com/posts/why-nvidia-keeps-winning-the-rise-of-an-ai-giant",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Nvidia's rise to prominence in the AI industry is attributed to its focus on graphics processing units (GPUs) and the creation of a GPU ecosystem by CEO Jensen Huang. Huang foresaw the importance of parallel computing for AI and made strategic decisions to distribute the company's software, CUDA, for free to researchers. This built an ecosystem around Nvidia's GPUs, optimizing their usage for AI computations. Furthermore, the company has become a leading player in the transformer models in AI, which are essential for large, scalable models.</li>\n      <li>Nvidia's importance to the AI industry has been affirmed by its trillion-dollar valuation and its indispensable role in the large language model revolution. The company is now a major supplier to both gaming and data center sectors. The absence of significant foreign and domestic competitors, especially in China, further cements Nvidia's dominance in the market.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.chinatalk.media/p/why-nvidia-keeps-winning-the-rise\">Why Nvidia Keeps Winning: The Rise of an AI Giant</a>\n</p>",
            "pubdate": "Fri, 07 Jul 2023 01:01:43 +0000",
            "pubdate_parsed": [
                2023,
                7,
                7
            ],
            "email_sent": true
        },
        "Scaling Transformers to 1,000,000,000 Tokens\"": {
            "url": "https://www.emergentmind.com/posts/github-kyegomez-longnet-implementation-of-plug-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LongNet is a Transformer variant designed to handle sequence lengths of over 1 billion tokens without sacrificing performance on shorter sequences.</li>\n      <li>It features dilated attention, which expands the attentive field exponentially as the distance grows, and can be used as a distributed trainer for very long sequences.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/kyegomez/LongNet\">Scaling Transformers to 1,000,000,000 Tokens&quot;</a>\n</p>",
            "pubdate": "Fri, 07 Jul 2023 00:03:56 +0000",
            "pubdate_parsed": [
                2023,
                7,
                7
            ],
            "email_sent": true
        },
        "Mechanical Turk workers are using AI to automate being human": {
            "url": "https://www.emergentmind.com/posts/mechanical-turk-workers-are-using-ai-to-automate-being",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Mechanical Turk is a service by Amazon that allows users to divide tasks into small subtasks, performed by human 'turkers'. However, a study has found that about half of these workers are using AI to perform their tasks, effectively automating jobs intended for humans.</li>\n      <li>The study, conducted by researchers at EPFL in Switzerland, revealed that these workers are using large language models like ChatGPT to automate their tasks, a move that questions the value of Mechanical Turk and underlines the looming crisis of AI training on AI-generated data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://techcrunch.com/2023/06/14/mechanical-turk-workers-are-using-ai-to-automate-being-human/\">Mechanical Turk workers are using AI to automate being human</a>\n</p>",
            "pubdate": "Fri, 07 Jul 2023 12:02:22 +0000",
            "pubdate_parsed": [
                2023,
                7,
                7
            ],
            "email_sent": true
        },
        "How to create smooth Zoom-Out Videos With Midjourney AI": {
            "url": "https://www.emergentmind.com/posts/how-to-create-smooth-zoom-out-videos-with-midjourney-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A QR code is provided for instant app download</li>\n      <li>The app can also be found in app stores</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.reddit.com/r/midjourney/comments/14tnser/how_to_create_smooth_zoomout_videos_with/?utm_source=share&amp;utm_medium=web2x&amp;context=3\">How to create smooth Zoom-Out Videos With Midjourney AI</a>\n</p>",
            "pubdate": "Sat, 08 Jul 2023 00:01:14 +0000",
            "pubdate_parsed": [
                2023,
                7,
                8
            ],
            "email_sent": true
        },
        "Ahead of AI #10: State of Computer Vision 2023": {
            "url": "https://www.emergentmind.com/posts/ahead-of-ai-10-state-of-computer-vision-2023",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the current state of research and development in computer vision, highlighting the themes of Vision Transformers (ViTs), Efficient ViTs, Generative AI for Vision, and Neural Radiance Fields (NeRF).</li>\n      <li>Key advancements include the development of ViTs that tokenize images, the creation of more resource-efficient ViTs suitable for real-time applications, the use of diffusion models for generative AI, and the application of NeRF for high-quality 3D reconstructions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.sebastianraschka.com/p/ahead-of-ai-10-state-of-computer\">Ahead of AI #10: State of Computer Vision 2023</a>\n</p>",
            "pubdate": "Sat, 08 Jul 2023 13:02:11 +0000",
            "pubdate_parsed": [
                2023,
                7,
                8
            ],
            "email_sent": true
        },
        "Introduction to Safetensors": {
            "url": "https://www.emergentmind.com/posts/introduction-to-safetensors",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Safetensors is a new serialization format developed by Hugging Face, designed to simplify and streamline the storage and loading of large and complex tensors, which are the primary data structure used in deep learning. This tool is faster and more efficient than other formats, offering 76.6X faster speed on CPU and 2X on GPU compared to traditional PyTorch serialization.</li>\n      <li>The Safetensors tool is user-friendly, with a simple API for serialization and deserialization in Python, allowing developers to focus on building their deep learning models. The tool also offers cross-platform compatibility, allowing for seamless sharing of models across different programming environments. It utilizes effective serialization and compression algorithms, and includes a checksum mechanism for added security.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.kdnuggets.com/2023/07/introduction-safetensors.html\">Introduction to Safetensors</a>\n</p>",
            "pubdate": "Sat, 08 Jul 2023 10:11:27 +0000",
            "pubdate_parsed": [
                2023,
                7,
                8
            ],
            "email_sent": true
        },
        "Train Your AI Model Once and Deploy on Any Cloud with NVIDIA and Run:ai": {
            "url": "https://www.emergentmind.com/posts/train-your-ai-model-once-and-deploy-on-any-cloud-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>NVIDIA and Run:ai have developed a solution that allows organizations to train AI models once and deploy them on any cloud platform. This is made possible by a new NVIDIA Virtual Machine Image that includes a Cloud Native Stack and the NVIDIA GPU Operator.</li>\n      <li>Run:ai, an industry leader in compute orchestration for AI workloads, has certified NVIDIA AI Enterprise on its Atlas platform. This enables enterprises to accelerate their data science pipeline and focus on developing and deploying AI models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://developer.nvidia.com/blog/train-your-ai-model-once-and-deploy-on-any-cloud-with-nvidia-and-runai/\">Train Your AI Model Once and Deploy on Any Cloud with NVIDIA and Run:ai</a>\n</p>",
            "pubdate": "Sat, 08 Jul 2023 09:02:28 +0000",
            "pubdate_parsed": [
                2023,
                7,
                8
            ],
            "email_sent": true
        },
        "LlamaIndex - Data Framework for LLM Applications": {
            "url": "https://www.emergentmind.com/posts/llamaindex-data-framework-for-llm-applications",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LlamaIndex is a flexible data framework designed to connect custom data sources to large language models.</li>\n      <li>It provides tools for data ingestion, indexing, and a query interface that returns knowledge-augmented responses, facilitating the construction of powerful end-user applications.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.llamaindex.ai/\">LlamaIndex - Data Framework for LLM Applications</a>\n</p>",
            "pubdate": "Sat, 08 Jul 2023 08:02:09 +0000",
            "pubdate_parsed": [
                2023,
                7,
                8
            ],
            "email_sent": true
        },
        "In case there was any doubt, Google's privacy policy now explicitly states that it's going to suck up all your data to train its AI": {
            "url": "https://www.emergentmind.com/posts/in-case-there-was-any-doubt-google-s-privacy-policy",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google has revised its privacy policy to explicitly state that it will use publicly available data to train its AI models, including Bard and Cloud AI.</li>\n      <li>The change has drawn criticism as it broadens the scope of data collection, and the legal status of such behaviour has not been clearly established, with some authors even suing OpenAI for copyright violations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.pcgamer.com/in-case-there-was-any-doubt-googles-privacy-policy-now-explicitly-states-that-its-going-to-suck-up-all-your-data-to-train-its-ai/\">In case there was any doubt, Google's privacy policy now explicitly states that it's going to suck up all your data to train its AI</a>\n</p>",
            "pubdate": "Sun, 09 Jul 2023 07:02:38 +0000",
            "pubdate_parsed": [
                2023,
                7,
                9
            ],
            "email_sent": true
        },
        "Prophet built for CUDA and Speed": {
            "url": "https://www.emergentmind.com/posts/github-stoffaudiollc-cuprophet-prophet-built-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>StoffAudioLLC/CuProphet is a Prophet built to utilize CUDA for enhanced performance.</li>\n      <li>The article presents instructions for installing and running the software, including managing Git branches and setting up a coding environment.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/StoffAudioLLC/CuProphet\">Prophet built for CUDA and Speed</a>\n</p>",
            "pubdate": "Sun, 09 Jul 2023 04:02:01 +0000",
            "pubdate_parsed": [
                2023,
                7,
                9
            ],
            "email_sent": true
        },
        " MF FOOM: AI-generated MF DOOM songs": {
            "url": "https://www.emergentmind.com/posts/mf-foom-ai-generated-mf-doom-songs-roman-hauksson",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the process of using GPT-3 to generate songs in the style of MF DOOM, a dense and complex rapper, by fine-tuning the AI model on MF DOOM's lyrics.</li>\n      <li>Despite the sophisticated methods used, the AI-generated songs do not match the quality of MF DOOM's original work, but the experiment provides an interesting exploration of AI's potential in music creation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://roman.computer/mf_foom/\">\ud83c\udfa4 MF FOOM: AI-generated MF DOOM songs</a>\n</p>",
            "pubdate": "Mon, 10 Jul 2023 05:02:00 +0000",
            "pubdate_parsed": [
                2023,
                7,
                10
            ],
            "email_sent": true
        },
        "Ai Development Solution: Empowering the Future with Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/ai-development-solution-empowering-the-future-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI Development solutions have the potential to transform industries by solving complex problems, enhancing efficiency, and fostering innovation. They can streamline operations, improve customer engagement, revolutionize healthcare, and disrupt transportation and logistics.</li>\n      <li>AI can also power financial services and drive significant value in various sectors like agriculture, energy, manufacturing, and education. They can unlock new opportunities and give businesses and organizations a competitive edge in the digital era.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/coinmonks/ai-development-solution-empowering-the-future-with-artificial-intelligence-79755417b07e\">Ai Development Solution: Empowering the Future with Artificial Intelligence</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 13:02:32 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "AI Can Accurately Predict Potentially Fatal Cardiac Events in Firefighters": {
            "url": "https://www.emergentmind.com/posts/ai-can-accurately-predict-potentially-fatal-cardiac",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers at NIST, Rochester and Google have used AI to accurately predict abnormal cardiac rhythms in firefighters. This development could potentially lead to a portable heart monitor for firefighters, providing early warning signs of heart trouble.</li>\n      <li>Sudden cardiac death is the cause of 40% of on-duty fatalities among firefighters. The AI model, called the Heart Health Monitoring (H2M) model, was trained with real-life data from firefighters and achieved 97% accuracy in identifying abnormal ECG samples.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nist.gov/news-events/news/2023/07/ai-can-accurately-predict-potentially-fatal-cardiac-events-firefighters\">AI Can Accurately Predict Potentially Fatal Cardiac Events in Firefighters</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 13:02:30 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "Own your own ChatGPT+Midjourney web service  Midjourney GPT": {
            "url": "https://www.emergentmind.com/posts/own-your-own-chatgpt-midjourney-web-service",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>MIDJOURNEY_PROXY_URL needs to be set up with the address http://public IP:port, not http://localhost:port, especially when using Docker deployment.</li>\n      <li>Additional optional configurations include MIDJOURNEY_PROXY_API_SECRET for API request security and CODE for setting access password.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://midjourney-gpt.com/own-your-own-chatgptmidjourney-web-service/\">Own your own ChatGPT+Midjourney web service \u2013 Midjourney GPT</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 13:02:27 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "Decades-long bet on consciousness ends  and its philosopher 1, neuroscientist 0": {
            "url": "https://www.emergentmind.com/posts/decades-long-bet-on-consciousness-ends-and-it-s",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In 1998, neuroscientist Christof Koch bet philosopher David Chalmers that the mechanism by which the brain's neurons produce consciousness would be discovered by 2023. However, at the Association for the Scientific Study of Consciousness (ASSC) meeting in 2023, both scientists agreed that the quest is ongoing and Chalmers was declared the winner.</li>\n      <li>The bet was ultimately decided by a study testing two leading hypotheses about the neural basis of consciousness, where neither theory perfectly matched the results, indicating both theories need revision.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nature.com/articles/d41586-023-02120-8\">Decades-long bet on consciousness ends \u2014 and it\u2019s philosopher 1, neuroscientist 0</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 12:02:02 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "AI Robots Admit They'd Run Earth Better Than 'Clouded' Humans : ScienceAlert": {
            "url": "https://www.emergentmind.com/posts/ai-robots-admit-they-d-run-earth-better-than-clouded",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>At a United Nations summit, a panel of AI-enabled humanoid robots suggested they could potentially manage the world better than humans due to their lack of biases and emotional clouding. However, they urged caution in embracing the rapidly evolving field of artificial intelligence.</li>\n      <li>Some of the most advanced humanoid robots were present at the summit, discussing ways to use AI to solve global issues like climate change, hunger, and social care. The robots highlighted the need for trust and transparency, and there was a split opinion on whether there should be global regulation of AI capabilities.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.sciencealert.com/ai-robots-admit-theyd-run-earth-better-than-clouded-humans\">AI Robots Admit They'd Run Earth Better Than 'Clouded' Humans : ScienceAlert</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 11:01:54 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "Report: China to tighten rules around releasing generative AI tools": {
            "url": "https://www.emergentmind.com/posts/report-china-to-tighten-rules-around-releasing",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>China is planning to intensify regulations on artificial intelligence (AI), with a specific focus on content control and licensing. The Cyberspace Administration of China (CAC) plans to require local companies to obtain a license before releasing generative AI systems.</li>\n      <li>This move is a tightening of initial draft regulations released earlier this year, which required companies to register their product with authorities within 10 days of launch. The new regulations are expected to be released at the end of this month, and will also include mandatory security reviews of AI-generated content.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://cointelegraph.com/news/china-to-require-generative-ai-tools-to-obtain-license\">Report: China to tighten rules around releasing generative AI tools</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 11:01:51 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "GitHub - mshumer/gpt-prompt-engineer": {
            "url": "https://www.emergentmind.com/posts/github-mshumer-gpt-prompt-engineer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The gpt-prompt-engineer is a tool that generates, tests, and ranks multiple prompts based on a task description and test cases, using GPT-4 and GPT-3.5-Turbo.</li>\n      <li>The tool uses an ELO rating system to assess prompt performance, provides a Classification Version for classification tasks, and offers optional logging to Weights &amp; Biases.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/mshumer/gpt-prompt-engineer\">GitHub - mshumer/gpt-prompt-engineer</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 08:01:59 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "A repository contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance, especially in Text-to-SQL.": {
            "url": "https://www.emergentmind.com/posts/github-csunny-db-gpt-hub-a-repository-contains",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>DB-GPT-Hub is an experimental project aiming to implement Text-to-SQL parsing using Large Language Models (LLMs), which includes dataset collection, data pre-processing, model selection and construction, and fine-tuning weights. This process aims to reduce the model training cost while improving Text-to-SQL capability, ultimately realizing automatic database-based question and answer capabilities.</li>\n      <li>The project uses multiple publicly available text-to-SQL datasets for enhancement. It allows users to complete complex database query operations through natural language descriptions. The project also provides thorough instructions on environment preparation, data preparation, and model fine-tuning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/csunny/DB-GPT-Hub\">A repository contains models, datasets, and fine-tuning techniques for DB-GPT, with the purpose of enhancing model performance, especially in Text-to-SQL.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 06:02:07 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "A Survey of Machine Unlearning": {
            "url": "https://www.emergentmind.com/posts/2209-02299-a-survey-of-machine-unlearning",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Computer systems hold large amounts of personal data, which can pose a threat to user privacy and trust in artificial intelligence. Regulations now require the removal of private information upon request, but machine learning models often 'remember' the old data.</li>\n      <li>This paper presents a comprehensive examination of 'machine unlearning', a new paradigm to make machine learning models forget particular data. It aims to be a resource for researchers and practitioners, highlighting current trends, new research areas, and the potential benefits of machine unlearning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2209.02299\">A Survey of Machine Unlearning</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 11 Jul 2023 04:01:45 +0000",
            "pubdate_parsed": [
                2023,
                7,
                11
            ],
            "email_sent": true
        },
        "'While We Are Learning To Use AI, It Is Learning To Use Us': Yuval Harari to UN AI for Good Summit": {
            "url": "https://www.emergentmind.com/posts/while-we-are-learning-to-use-ai-it-is-learning-to-use",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Historian Yuval Noah Harari likened the development of AI to having a dangerous virus in the lab; it's okay to develop but not to deploy it in the public. He emphasized that just as drug companies and car manufacturers undergo safety checks, the same should be applied to AI.</li>\n      <li>Harari also discussed the potential to create billions of fake people, which could collapse trust in society. He stressed the need to understand AI's potential impact on society before deploying it, while Microsoft's Michael Schwarz suggested not regulating AI until some meaningful harm occurs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://sociable.co/technology/learning-ai-use-us-yuval-harari-un-summit/\">'While We Are Learning To Use AI, It Is Learning To Use Us': Yuval Harari to UN AI for Good Summit</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 12 Jul 2023 02:02:54 +0000",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Fluid Concepts are Necessary for General AI": {
            "url": "https://www.emergentmind.com/posts/fluid-concepts-are-necessary-for-general-ai-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>General AI requires fluid concepts, unlike narrow AI which are bound by hard-coded ontology. Narrow AI are defined by built-in assumptions about how they approach problems, whereas general AI must devise or discover these assumptions and constraints itself.</li>\n      <li>Hard-coded assumptions in narrow AI, like those in Large Language Models, are tied to concepts, forming an implicit ontology. However, these concepts cannot fully develop in narrow AI. For AI to be general, these assumptions must be discovered or devised by the AI itself, without human interference into its architecture.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/fluid-concepts-are-necessary-for-general-ai-e30bbaa65be9\">Fluid Concepts are Necessary for General AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 12 Jul 2023 13:02:44 +0000",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "ChatGPT Is Losing Users. Is The Artificial Intelligence Craze Over?": {
            "url": "https://www.emergentmind.com/posts/chatgpt-is-losing-users-is-the-artificial-intelligence",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A decrease in users for artificial intelligence platform ChatGPT does not mean the AI trend is over, despite a 9.7% drop in traffic in June.</li>\n      <li>While there are concerns with ChatGPT, such as incorrect answers and censorship, the potential of AI extends far beyond content creation and its impact will be significant in many areas.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.forbes.com/sites/richardkestenbaum/2023/07/11/chatgpt-is-losing-users-is-the-artificial-intelligence-craze-over/\">ChatGPT Is Losing Users. Is The Artificial Intelligence Craze Over?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 12 Jul 2023 13:02:41 +0000",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Data Startup Space and Time Creates Chatbot Powered by OpenAI's ChatGPT for Database Querying": {
            "url": "https://www.emergentmind.com/posts/data-startup-space-and-time-creates-chatbot-powered-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Startup Space and Time, financed by Microsoft and Hashkey Capital, has incorporated a chatbot using OpenAI's GPT-4 into their decentralized data warehouse. This allows developers to maintain and query databases more easily.</li>\n      <li>The company's technology, proof-of-SQL, ensures the accuracy and tamper-proof nature of data and queries, which is crucial in Web 3 environments. The chatbot, named Houston, simplifies database maintenance by allowing users to generate scripts and ask queries in natural language.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.coindesk.com/tech/2023/07/11/data-startup-space-and-time-creates-chatbot-powered-by-chatgpt-for-database-querying/\">Data Startup Space and Time Creates Chatbot Powered by OpenAI's ChatGPT for Database Querying</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 12 Jul 2023 07:02:32 +0000",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Chiplet Cloud: Building AI Supercomputers for Serving Large Generative Language Models": {
            "url": "https://www.emergentmind.com/posts/2307-02666-chiplet-cloud-building-ai-supercomputers",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers propose Chiplet Cloud, a supercomputer architecture designed to optimize the cost and efficiency of using Large Language Models (LLMs) like ChatGPT.</li>\n      <li>The new architecture uses on-chip SRAMs to eliminate bandwidth limitations, reduces die size to improve system costs, and uses software mappings to overcome communication overhead - potentially providing up to 94x and 15x improvement in cost efficiency compared to GPU and TPU.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.02666\">Chiplet Cloud: Building AI Supercomputers for Serving Large Generative Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 12 Jul 2023 06:01:49 +0000",
            "pubdate_parsed": [
                2023,
                7,
                12
            ],
            "email_sent": true
        },
        "Indian software developer replaced support team with AI  The Register": {
            "url": "https://www.emergentmind.com/posts/indian-software-developer-replaced-support-team-with-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Indian startup Dukaan outsourced its customer support to an AI chatbot, making the process more efficient and cheaper.</li>\n      <li>The change led to significantly faster response and resolution times, and an 85 percent reduction in customer support costs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theregister.com/2023/07/13/dukaan_ai_support_replacement/\">Indian software developer replaced support team with AI \u2022 The Register</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 13 Jul 2023 10:02:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                13
            ],
            "email_sent": true
        },
        "Best Artificial Intelligence Books to Read in 2023": {
            "url": "https://www.emergentmind.com/posts/best-artificial-intelligence-books-to-read-in-2023",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence (AI) has significantly affected our lives, with its applications ranging from predictive analysis, medicine, automation of tasks, to improving the standard of living. It is affordable, powerful, and has the ability to analyze large datasets quickly.</li>\n      <li>Prominent tech figures like Bill Gates and Elon Musk have expressed their views on AI. While Gates warns about potential unemployment due to AI replacing human jobs, he believes it will be beneficial by freeing humans from tedious tasks. Musk, on the other hand, believes AI can be powerful and beneficial if regulated properly.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://topminisite.com/blog/best-artificial-intelligence-books-to-read\">Best Artificial Intelligence Books to Read in 2023</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 13 Jul 2023 05:01:44 +0000",
            "pubdate_parsed": [
                2023,
                7,
                13
            ],
            "email_sent": true
        },
        "Striking SAG Actors in Disbelief Over Studios Dystopian AI Proposal  Rolling Stone": {
            "url": "https://www.emergentmind.com/posts/striking-sag-actors-in-disbelief-over-studios",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Members of the Screen Actors Guild (SAG-AFTRA) and the Writers Guild of America (WGA) are on strike over concerns about AI potentially replacing writers and actors. This is the first time both unions have been on strike simultaneously since 1960.</li>\n      <li>The strike was sparked by a proposal allowing for actors to be scanned and their images used perpetually without compensation or consent. This could effectively eliminate background acting as a pathway into the industry.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.rollingstone.com/tv-movies/tv-movie-features/actors-strike-sag-artificial-intelligence-hollywood-studios-background-1234788191/\">Striking SAG Actors in Disbelief Over Studios\u2019 Dystopian AI Proposal \u2013 Rolling Stone</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 14 Jul 2023 03:02:10 +0000",
            "pubdate_parsed": [
                2023,
                7,
                14
            ],
            "email_sent": true
        },
        "FTC Investigates ChatGPT for Misinformation as 2024 Elections Loom - Tokenist": {
            "url": "https://www.emergentmind.com/posts/ftc-investigates-chatgpt-for-misinformation-as-2024",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Federal Trade Commission (FTC) is investigating ChatGPT creator OpenAI due to concerns of spreading false information, potentially influencing the 2024 US presidential election.</li>\n      <li>OpenAI is required to provide details on its data security practices and how it addresses AI risks, especially after a previous incident where a bug allowed users to access other users' chats and payment-related details.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://tokenist.com/ftc-investigates-chatgpt-for-misinformation-as-2024-elections-loom/\">FTC Investigates ChatGPT for Misinformation as 2024 Elections Loom - Tokenist</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 14 Jul 2023 13:02:38 +0000",
            "pubdate_parsed": [
                2023,
                7,
                14
            ],
            "email_sent": true
        },
        "The workers at the frontlines of the AI revolution - Rest of World": {
            "url": "https://www.emergentmind.com/posts/the-workers-at-the-frontlines-of-the-ai-revolution",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The growth of generative AI is posing a new form of competition for freelance workers across various industries, from illustrators to copywriters and programmers. This is particularly affecting offshore outsourced workers as AI tools present a new model for cost cutting.</li>\n      <li>Some workers have adapted by embracing and offering AI-related services. However, the demand for traditional services is dwindling, and many fear layoffs or diminishing commissions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://restofworld.org/2023/ai-revolution-outsourced-workers/\">The workers at the frontlines of the AI revolution - Rest of World</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 14 Jul 2023 12:01:39 +0000",
            "pubdate_parsed": [
                2023,
                7,
                14
            ],
            "email_sent": true
        },
        "Early interviews for AI companies - apply by Tuesday July 18, 2023": {
            "url": "https://www.emergentmind.com/posts/early-interviews-for-ai-companies-apply-by-tuesday",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Y Combinator is conducting a special round of early interviews for AI startups for its YC W24 batch, with applications due by July 18, 2023.</li>\n      <li>Accepted AI startups will gain immediate access to advice, expertise, and a network of AI founders, along with up to $1M in free credits from Microsoft and Scale AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.ycombinator.com/blog/early-interviews-for-ai-companies\">Early interviews for AI companies - apply by Tuesday July 18, 2023</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 15 Jul 2023 08:02:25 +0000",
            "pubdate_parsed": [
                2023,
                7,
                15
            ],
            "email_sent": true
        },
        "WormGPT - The Generative AI Tool Cybercriminals Are Using to Launch BEC Attacks": {
            "url": "https://www.emergentmind.com/posts/wormgpt-the-generative-ai-tool-cybercriminals-are",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Cybercriminals are increasingly using generative AI tools, such as OpenAI\u2019s ChatGPT and WormGPT, to facilitate Business Email Compromise (BEC) attacks. The AI technology automates the creation of convincing fake emails which are personalized to the recipient.</li>\n      <li>The use of generative AI has lowered the entry threshold for executing sophisticated BEC attacks, making the technology accessible to a broader spectrum of cybercriminals. Effective prevention measures like BEC-specific training and enhanced email verification processes are crucial.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://slashnext.com/blog/wormgpt-the-generative-ai-tool-cybercriminals-are-using-to-launch-business-email-compromise-attacks/\">WormGPT - The Generative AI Tool Cybercriminals Are Using to Launch BEC Attacks</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 16 Jul 2023 02:02:15 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Stability AI Co-Founder Is Suing the Company Over Sold Stake  ARTnews.com": {
            "url": "https://www.emergentmind.com/posts/stability-ai-co-founder-is-suing-the-company-over-sold",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Cyrus Hodes, co-founder of Stability AI, is suing the company and CEO Mohammad Emad Mostaque, accusing Mostaque of deceiving him about the company's value. Hodes sold his 15% stake for $100, only for the company to then generate $101 million in investment at a $1 billion valuation.</li>\n      <li>Hodes alleges that Mostaque used deceptive tactics to make him think his stake was worthless, and is now seeking reinstatement of his stake or equivalent reward for damages. This lawsuit follows previous legal issues faced by Stability AI, including a class-action lawsuit by artists accusing the company of using their copyrighted images.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.artnews.com/art-news/news/stability-ais-co-founder-is-suing-stability-ai-cyrus-hodes-mostaque-1234674185/\">Stability AI Co-Founder Is Suing the Company Over Sold Stake \u2013 ARTnews.com</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 16 Jul 2023 11:03:50 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "A Unique Encounter": {
            "url": "https://www.emergentmind.com/posts/a-unique-encounter",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This is an imaginary story about a chance encounter between Babe Ruth and Adolf Hitler in a caf\u00e9, where they engage in a deep conversation unrelated to their public personas.</li>\n      <li>This chance meeting is a shared experience that leaves a profound impact on both of them, reminding them of their inherent humanity despite their vastly different futures.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/b8b299ed-d077-45b3-a77c-a8b27dc41d35\">A Unique Encounter</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 16 Jul 2023 11:03:48 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "How to Use AI to Do Stuff: An Opinionated Guide": {
            "url": "https://www.emergentmind.com/posts/how-to-use-ai-to-do-stuff-an-opinionated-guide",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article provides an overview of the current state of AI systems, focusing on Large Language Models (LLMs) and their applications, from writing drafts and improving content to generating images and ideas. It also highlights the rapid advancements in AI capabilities, mentioning specific models like Claude 2, Code Interpreter, and GPT-4.</li>\n      <li>The author warns readers about potential issues with AI, such as the tendency to generate false information, biases in the system, and the potential for unethical use. The article also discusses the use of AI in creating videos and the ethical concerns related to deepfakes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.oneusefulthing.org/p/how-to-use-ai-to-do-stuff-an-opinionated\">How to Use AI to Do Stuff: An Opinionated Guide</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 16 Jul 2023 06:02:58 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "AI Nursing Ethics: Viability of Robots and Artificial Intelligence in Nursing Practice": {
            "url": "https://www.emergentmind.com/posts/ai-nursing-ethics-viability-of-robots-and-artificial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers from Japan are investigating the potential of robots and artificial intelligence (AI) to act as nurses, including their ability to replicate the ethical concepts attributed to nurses. However, they raise several ethical concerns.</li>\n      <li>While AI and robotics hold promise for enhancing healthcare, their integration into nursing requires careful consideration, particularly in terms of advocacy, accountability, cooperation, and caring.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.tus.ac.jp/en/mediarelations/archive/20230706_1542.html\">AI Nursing Ethics: Viability of Robots and Artificial Intelligence in Nursing Practice</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 16 Jul 2023 05:01:35 +0000",
            "pubdate_parsed": [
                2023,
                7,
                16
            ],
            "email_sent": true
        },
        "Superpower Daily": {
            "url": "https://www.emergentmind.com/posts/superpower-daily",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Superpower Daily provides daily updates on AI news and insights.</li>\n      <li>It is read by over 90,000 individuals from top tech companies like Meta, Google, Microsoft, Benchmark, and Accel.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.superpowerdaily.com/\">Superpower Daily</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 17 Jul 2023 07:04:13 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Neural Network Inference Engine in Zig": {
            "url": "https://www.emergentmind.com/posts/github-eugenhotaj-zig_gpt2-neural-network-inference",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses about a commit on the 'Neural Network Inference Engine in Zig Insights' by EugenHotaj/zig_gpt2.</li>\n      <li>The commit does not belong to any branch on the repository and may belong to a fork outside of the repository.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/EugenHotaj/zig_gpt2\">Neural Network Inference Engine in Zig</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 17 Jul 2023 04:01:45 +0000",
            "pubdate_parsed": [
                2023,
                7,
                17
            ],
            "email_sent": true
        },
        "Incumbents vs. Startups in the AI Race": {
            "url": "https://www.emergentmind.com/posts/incumbents-vs-startups-in-the-ai-race",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The AI race sees traditional companies and startups competing fiercely, with the former leveraging their resources and distribution networks, while the latter uses their agility and speed. However, traditional companies are often slow to innovate due to bureaucracy, while startups lack the capital and established brand to drive their ideas.</li>\n      <li>In recent times, traditional companies have started to pick up pace in deploying AI, posing a serious threat to startups. Startups can compete by solving problems not yet tackled by traditional companies or by owning unique customer generated data produced on its platform.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.autopilot.fund/incumbents-vs-startups-in-the-ai-race/\">Incumbents vs. Startups in the AI Race</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 18 Jul 2023 00:03:23 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "Generative AI Space and the Mental Imagery of Alien MindsStephen Wolfram Writings": {
            "url": "https://www.emergentmind.com/posts/generative-ai-space-and-the-mental-imagery-of-alien",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative AI, also known as alien AI, can be manipulated to understand how alien minds might perceive the world. This is done by modifying the neural net of a human-aligned AI, thereby creating an alien mind's equivalent and allowing for the observation and analysis of its 'mental imagery'.</li>\n      <li>The study of the 'mental imagery' of these alien AIs provides a systematic experimental platform for exploring alien minds. This approach, likened to artificial neuroscience, may offer insights into different kinds of 'brains', including human, artificial, and alien, and facilitate a better understanding of what alien minds could be like.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://writings.stephenwolfram.com/2023/07/generative-ai-space-and-the-mental-imagery-of-alien-minds/\">Generative AI Space and the Mental Imagery of Alien Minds\u2014Stephen Wolfram Writings</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 18 Jul 2023 06:02:43 +0000",
            "pubdate_parsed": [
                2023,
                7,
                18
            ],
            "email_sent": true
        },
        "How is ChatGPT's behavior changing over time?": {
            "url": "https://www.emergentmind.com/posts/2307-09009-how-is-chatgpt-s-behavior-changing-over",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Study evaluates GPT-3.5 and GPT-4 language models in several tasks and finds performance varies greatly over short time periods.</li>\n      <li>Findings underline need for continuous monitoring of language model quality due to substantial changes in behavior.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.09009\">How is ChatGPT's behavior changing over time?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 19 Jul 2023 03:02:29 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "Marvin Minskys Vision of the Future": {
            "url": "https://www.emergentmind.com/posts/marvin-minsky-s-vision-of-the-future-the-new-yorker",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In 1979, a computer program called BKG 9.8, created by Hans Berliner, a professor of computer science at Carnegie-Mellon University, played and won against the world backgammon champion in Monte Carlo. The program was run on a large computer connected by satellite to a robot, named Gammonoid, in Monte Carlo.</li>\n      <li>This marked the first time a machine became a world champion in a board or card game, paving the way for future development in artificial intelligence.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.newyorker.com/magazine/1981/12/14/a-i\">Marvin Minsky\u2019s Vision of the Future</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 19 Jul 2023 02:01:34 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "How AI is bringing film stars back from the dead - BBC Future": {
            "url": "https://www.emergentmind.com/posts/how-ai-is-bringing-film-stars-back-from-the-dead-bbc",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence technology is being used to create digital clones of deceased film stars, such as James Dean, for new films, which is causing concerns about the rights of individuals after their death.</li>\n      <li>The technology allows for the creation of interactive avatars for films and gaming, but it raises questions about who owns the rights to someone's image after they die, and the potential for misuse or exploitation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bbc.com/future/article/20230718-how-ai-is-bringing-film-stars-back-from-the-dead\">How AI is bringing film stars back from the dead - BBC Future</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 19 Jul 2023 13:03:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "Harvard 21 grad says Gen Z just uses A.I. to do their homework, they arent necessarily interested in using ChatGPT for learning": {
            "url": "https://www.emergentmind.com/posts/harvard-21-grad-says-gen-z-just-uses-a-i-to-do-their",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A recent Fortune's Brainstorm Tech conference revealed contrasting views on the use of A.I. in education, with Gen Z students using it mainly for homework and not for learning, while Chegg's CEO Dan Rosensweig shows enthusiasm for A.I.'s potential to aid students.</li>\n      <li>Chegg is combating competitive threats from A.I. tools like OpenAI\u2019s ChatGPT and Google\u2019s Bard by launching Cheggmate, a tool that tailors to students' learning needs, though skepticism remains about whether such tools will encourage active engagement with course materials.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://finance.yahoo.com/news/harvard-21-grad-says-gen-213109060.html\">Harvard \u201921 grad says Gen Z just uses A.I. to do their homework, they \u2018aren\u2019t necessarily interested in using ChatGPT for learning\u2019</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 19 Jul 2023 13:02:59 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "SHOW-1 and Showrunner Agents in Multi-Agent Simulations": {
            "url": "https://www.emergentmind.com/posts/show-1-and-showrunner-agents-in-multi-agent-simulations",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers use large language models and multi-agent simulations to generate high-quality episodic content for intellectual properties. The approach leverages data points such as a character's history, emotions, and goals to produce scenes and assets aligned with the existing story world.</li>\n      <li>The process mitigates the 'slot machine effect', where AI-produced content feels random rather than deliberately creative. The user's expectations and intentions are shaped through interactions, reducing frustration and enhancing the user experience.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://fablestudio.github.io/showrunner-agents/\">SHOW-1 and Showrunner Agents in Multi-Agent Simulations</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 19 Jul 2023 09:02:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "Mastering ChatGPT: 16 Powerful Commands to Craft Engaging Blog Posts": {
            "url": "https://www.emergentmind.com/posts/mastering-chatgpt-16-powerful-commands-to-craft",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is an AI language model that helps bloggers to generate human-like text and create engaging blog posts. It offers 16 powerful commands that can help to captivate readers.</li>\n      <li>By harnessing the capabilities of ChatGPT, bloggers can generate catchy introductions, craft persuasive conclusions, optimize for SEO, generate blog post ideas, and proofread and edit their work, among other things.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://technexio.com/mastering-chatgpt-16-powerful-commands-to-craft-engaging-blog-posts/\">Mastering ChatGPT: 16 Powerful Commands to Craft Engaging Blog Posts</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 19 Jul 2023 04:03:04 +0000",
            "pubdate_parsed": [
                2023,
                7,
                19
            ],
            "email_sent": true
        },
        "Rethinking Symbol-Grounding in AGI": {
            "url": "https://www.emergentmind.com/posts/rethinking-symbol-grounding-in-agi-by-cardboarddreams",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses rethinking the approach towards symbol-grounding in Artificial General Intelligence (AGI), suggesting a shift from a narrow AI model to a more open-ended model. This new model involves using a Reinforcement Learning (RL) agent that builds up concepts based on experiences.</li>\n      <li>The author suggests that the RL agent should focus on collecting information that is useful for making effective plans, rather than trying to model objective 'truth' about the world. The agent's world models should be based on past experiences that proved useful, creating a model which combines the benefits of model-free and model-based RL.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/rethinking-symbol-grounding-in-agi-118d33daee9f\">Rethinking Symbol-Grounding in AGI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 20 Jul 2023 02:02:13 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Wikipedias Moment of Truth - The New York Times": {
            "url": "https://www.emergentmind.com/posts/wikipedia-s-moment-of-truth-the-new-york-times",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Wikipedia, the online encyclopedia, faces a challenge from A.I. chatbots like GPT-3 from OpenAI, which mix factual and fictional elements in their responses. This development has sparked concern among some Wikipedia editors about the future of the platform.</li>\n      <li>Meanwhile, Wikipedia's vast data and text have been used extensively in training A.I. models, making it a significant source of information for these systems. As A.I. chatbots become more sophisticated, there are concerns about whether Wikipedia might suffer from disuse and be replaced by these bots.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nytimes.com/2023/07/18/magazine/wikipedia-ai-chatgpt.html?smid=nytcore-ios-share&amp;referringSource=articleShare\">Wikipedia\u2019s Moment of Truth - The New York Times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 20 Jul 2023 01:02:53 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Researchers Chart Alarming Decline in ChatGPT Response Quality": {
            "url": "https://www.emergentmind.com/posts/researchers-chart-alarming-decline-in-chatgpt-response",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A research team from Stanford and UC Berkeley found a significant decline in the quality of ChatGPT responses, with the accuracy of GPT-4's prime number identification falling from 97.6% in March 2023 to 2.4% in June 2023.</li>\n      <li>The research team assessed the performance of GPT-4, which was championed by OpenAI as its most advanced model, and found significant differences in its ability to answer queries over a short period, raising concerns about the quality of AI products powered by it.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.tomshardware.com/news/chatgpt-response-quality-decline\">Researchers Chart Alarming Decline in ChatGPT Response Quality</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 20 Jul 2023 01:02:49 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2307-09793-on-the-origin-of-llms-an-evolutionary",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models like ChatGPT and Bard have gained popularity since late 2022, with new models being added to Hugging Face, a repository for machine learning models and datasets, each week.</li>\n      <li>Due to the lack of a comprehensive index for these models, a new tool called Constellation has been developed to identify different families of Large Language Models and cluster them into meaningful subgroups, providing a visual representation of over 15,000 models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.09793\">On the Origin of LLMs: An Evolutionary Tree and Graph for 15,821 Large Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 20 Jul 2023 07:02:21 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Teaching Programming in the Age of ChatGPT  OReilly": {
            "url": "https://www.emergentmind.com/posts/teaching-programming-in-the-age-of-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A study by Sam Lau and Philip Guo of UC San Diego gathered perspectives from 20 programming instructors across 9 countries to understand how they plan to adapt their courses in response to the increasing use of AI coding assistance tools by students. The study found that in the short term, instructors are primarily concerned about cheating and students becoming over-reliant on AI tools, and are adapting their courses accordingly. In the longer term, instructors expressed a mix of views, with some resisting the use of AI tools due to concerns about students not learning fundamentals and others embracing them as a potential benefit to the learning process.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.oreilly.com/radar/teaching-programming-in-the-age-of-chatgpt/\">Teaching Programming in the Age of ChatGPT \u2013 O\u2019Reilly</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 20 Jul 2023 04:02:01 +0000",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Ollama": {
            "url": "https://www.emergentmind.com/posts/ollama",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Ollama, a software, has been released for macOS with Apple Silicon.</li>\n      <li>Support for Windows and Linux platforms is expected to be introduced soon.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ollama.ai/\">Ollama</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 02:01:51 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "(M20000 subsidy!) Will a prompt that enables GPT-4 to solve easy Sudoku puzzles be found? (2023)": {
            "url": "https://www.emergentmind.com/posts/m20000-subsidy-will-a-prompt-that-enables-gpt-4-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses a challenge to find a prompt that enables GPT-4 to solve easy Sudoku puzzles by the end of 2023. If a reliable prompt is found, the market will resolve as 'YES', if it occasionally solves, it will resolve as '50%', and if no prompt is found, it will resolve as 'NO'.</li>\n      <li>The conditions specify that GPT-4 should use its language modeling capabilities and context as memory to solve the puzzles from LA Times Sudoku. The article also provides a detailed explanation of terms and conditions that are used in the challenge.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://manifold.markets/Mira/will-a-prompt-that-enables-gpt4-to\">(M20000 subsidy!) Will a prompt that enables GPT-4 to solve easy Sudoku puzzles be found? (2023)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 01:02:49 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #25 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-25-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The latest edition of Rushing Robotics highlights breakthroughs in age reversal, lab-grown mini brains, AI, space exploration, and sustainable energy, and discusses industry insights from tech giants like Microsoft, Meta, Tesla, and Apple. It also features cutting-edge products and tools that promise to reshape the way we interact with technology.</li>\n      <li>The newsletter discusses potential dangers of AI, the concept of a butterfly-shaped solar power station for future Moon settlements, the first-ever robotic liver transplant, and an ultra-small probe that can record neuron activity without invasive surgery. It also introduces AI-generated personalised avatars and a decentralized network for advancing longevity research.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-25\">Weekly Piece of Future #25 - by Zoltan Tapi</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 13:02:28 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "How to Use GPT-4 in Bing Chat with Multimodal Feature (Right now)": {
            "url": "https://www.emergentmind.com/posts/how-to-use-gpt-4-in-bing-chat-with-multimodal-feature",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Microsoft has provided early access to a multimodal feature in Bing Chat that allows interaction with the GPT-4 model, similar to the one OpenAI is yet to release. This feature enables users to upload images and ask related questions.</li>\n      <li>The potential benefits of this feature include enhanced user interactions with the AI and improved decision-making processes across various fields. It's expected to be especially useful for students, professionals, and AI enthusiasts.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://geekermag.com/how-to-use-gpt-4-in-bing-chat-with-multimodal-feature/\">How to Use GPT-4 in Bing Chat with Multimodal Feature (Right now)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 12:01:56 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "EU AI Act: the Regulatory Framework on the Usage of Machine Learning in the European Union": {
            "url": "https://www.emergentmind.com/posts/eu-ai-act-the-regulatory-framework-on-the-usage-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The EU AI Act is a proposed legislation that seeks to regulate the use of machine learning applications, with a focus on risk-based approach. Negotiations for its realization started in June 2023 and an agreement is expected by the end of the year.</li>\n      <li>The Act categorizes systems into four risk levels - minimal, limited, high, and unacceptable, each with specific regulations and obligations. High-risk systems, for instance, must be registered in the EU Database and ensure that generation of illegal content is prevented.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.infoq.com/news/2023/07/eu-ai-act/\">EU AI Act: the Regulatory Framework on the Usage of Machine Learning in the European Union</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 12:01:48 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Researchers From Stanford And DeepMind Come Up With The Idea of Using Large Language Models LLMs as a Proxy Reward Function - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/researchers-from-stanford-and-deepmind-come-up-with-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers from Stanford University and DeepMind are using Large Language Models (LLMs) as a proxy reward function for autonomous agents, making it easier for users to share their preferences. Users can specify their preferences through language, rather than providing many examples of desirable behaviors.</li>\n      <li>The use of LLMs increases the proportion of objective-aligned reward signals in response to zero-shot prompting by an average of 48% for a regular ordering of matrix game outcomes and by 36% for a scrambled order. The research shows that RL agents aligned with their objectives can be trained using LLMs that only detect one of two correct outcomes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/07/20/researchers-from-stanford-and-deepmind-come-up-with-the-idea-of-using-large-language-models-llms-as-a-proxy-reward-function/\">Researchers From Stanford And DeepMind Come Up With The Idea of Using Large Language Models LLMs as a Proxy Reward Function - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 10:01:55 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "EchoSpeech: AI-equipped eyeglasses can read the silent speech": {
            "url": "https://www.emergentmind.com/posts/echospeech-ai-equipped-eyeglasses-can-read-the-silent",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>EchoSpeech, AI-equipped eyeglasses developed by Cornell\u2019s Smart Computer Interfaces for Future Interactions (SciFi) Lab, can recognize silent speech based on lip and mouth movements. The device uses acoustic detection and artificial intelligence to identify up to 31 unvocalized commands.</li>\n      <li>EchoSpeech works by transmitting inaudible sound waves towards the skin, collecting small skin deformations caused by silent utterances, and analyzing these deformations to infer silent speech. The glasses transform into a wearable AI-powered sonar system that can track lip movements with around 95% accuracy.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bahrainthisweek.com/echospeech-ai-equipped-eyeglasses-read-silent-speech/\">EchoSpeech: AI-equipped eyeglasses can read the silent speech</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 07:02:09 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "The future of AI in transport: BPW - Global Trailer": {
            "url": "https://www.emergentmind.com/posts/the-future-of-ai-in-transport-bpw-global-trailer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Germany-based BPW will present its latest AI solutions for transport at the Transport Logistic event in Munich, featuring a new generation of running gear for intelligent trailers and the iGurt load securing system.</li>\n      <li>The company will also introduce two new solutions aimed at reducing carbon emissions in transport, including an electrically driven axle for inner-city transport and an energy-generating axle for refrigeration units.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.globaltrailermag.com/2023/04/24/the-future-of-ai-in-transport-bpw/\">The future of AI in transport: BPW - Global Trailer</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 04:02:38 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "An A.I. Supercomputer Whirs to Life, Powered by Giant Computer Chips - The New York Times": {
            "url": "https://www.emergentmind.com/posts/an-a-i-supercomputer-whirs-to-life-powered-by-giant",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Cerebras, a Silicon Valley start-up, has unveiled a supercomputer powered by giant chips designed to enhance artificial intelligence. The chips are as big as a dinner plate and pack the computing power of hundreds of traditional chips. The supercomputer was built for G42, an A.I. company planning to create and power A.I. products for the Middle East.</li>\n      <li>The demand for computing power and A.I. chips has surged due to the global A.I. boom, with tech giants and start-ups alike rushing to develop A.I. products. The Cerebras chips can train A.I. systems between 100 and 1,000 times as fast as existing hardware. The company plans to build more supercomputers around the world, forming a network called the Condor Galaxy.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nytimes.com/2023/07/20/technology/an-ai-supercomputer-whirs-to-life-powered-by-giant-computer-chips.html\">An A.I. Supercomputer Whirs to Life, Powered by Giant Computer Chips - The New York Times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 21 Jul 2023 04:02:16 +0000",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "Challenges and Applications of Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2307-10169-challenges-and-applications-of-large",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) have rapidly become a crucial part of machine learning discussions.</li>\n      <li>This paper aims to identify the challenges and successful applications of LLMs to help researchers understand the field better.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.10169\">Challenges and Applications of Large Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 22 Jul 2023 03:02:19 +0000",
            "pubdate_parsed": [
                2023,
                7,
                22
            ],
            "email_sent": true
        },
        "A New Era of Software Engineering: The Union of GraphQL and Large Language Models": {
            "url": "https://www.emergentmind.com/posts/a-new-era-of-software-engineering-the-union-of-graphql",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the transformative potential of the combination of GraphQL and Large Language Models (LLMs) like OpenAI in software engineering. It explains how these technologies can be integrated for powerful solutions, using tools like LangChain and Wundergraph, and how they can impact the development of more dynamic, intelligent, and efficient applications.</li>\n      <li>The synergy between GraphQL and LLMs allows feeding data from GraphQL APIs into LLMs for generating precise responses and enriching data graphs with AI-generated content. LangChain's GraphQL plugin enables easy consumption of GraphQL APIs, while Wundergraph's OpenAI integration allows inclusion of AI-generated responses in data graphs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@blazestudios23/a-new-era-of-software-engineering-the-union-of-graphql-and-large-language-models-openai-a34dcbdd01c1\">A New Era of Software Engineering: The Union of GraphQL and Large Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 22 Jul 2023 03:02:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                22
            ],
            "email_sent": true
        },
        "Research to merge human brain cells with AI secures national defence funding - Turner Institute for Brain and Mental Health": {
            "url": "https://www.emergentmind.com/posts/research-to-merge-human-brain-cells-with-ai-secures",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Monash University has secured almost $600,000 AUD from the National Intelligence and Security Discovery Research Grants Program for a project merging human brain cells with AI.</li>\n      <li>The project aims to surpass the performance of existing hardware by growing human brain cells on silicon chips to create programmable biological computing platforms, having significant implications across multiple fields.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.monash.edu/turner-institute/news-and-events/latest-news/2023-articles/research-to-merge-human-brain-cells-with-ai-secures-national-defence-funding#:~:text=Monash%20University%2Dled%20research%20into,Security%20Discovery%20Research%20Grants%20Program.\">Research to merge human brain cells with AI secures national defence funding - Turner Institute for Brain and Mental Health</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 22 Jul 2023 08:03:19 +0000",
            "pubdate_parsed": [
                2023,
                7,
                22
            ],
            "email_sent": true
        },
        "Top 115 Online ChatGPT Prompts (July 2023) - Midjourney GPT - Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/top-115-online-chatgpt-prompts-july-2023-midjourney",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is an AI tool that has gained immense popularity in recent years, assisting with tasks from writing to problem solving.</li>\n      <li>This article provides a list of the top 100 ChatGPT commands that can be used to enhance your browsing experience.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://midjourney-gpt.com/top-115-online-chatgpt-prompts/\">Top 115 Online ChatGPT Prompts (July 2023) - Midjourney GPT - Artificial Intelligence</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 22 Jul 2023 07:01:54 +0000",
            "pubdate_parsed": [
                2023,
                7,
                22
            ],
            "email_sent": true
        },
        "Computer chip with built-in human brain tissue gets military funding": {
            "url": "https://www.emergentmind.com/posts/computer-chip-with-built-in-human-brain-tissue-gets",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Scientists from Monash University have created a computer chip called 'DishBrain', which integrates 800,000 lab-grown human and mouse brain cells into its electrodes.</li>\n      <li>This technology, combining biological computing and artificial intelligence, has received a grant from Australia's National Intelligence and Security Discovery Research Grants program and might surpass the performance of purely silicon-based hardware.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://newatlas.com/computers/human-brain-chip-ai/\">Computer chip with built-in human brain tissue gets military funding</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 23 Jul 2023 00:03:31 +0000",
            "pubdate_parsed": [
                2023,
                7,
                23
            ],
            "email_sent": true
        },
        "You're The Change - song and lyrics by Allouche": {
            "url": "https://www.emergentmind.com/posts/you-re-the-change-song-and-lyrics-by-allouche",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This is a song titled 'You're The Change'.</li>\n      <li>To view the lyrics and listen to the full track, you need to sign in or sign up.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://open.spotify.com/track/0t6p7QwENCcu7nQXZMqIaa?si=_26cGl2ASPy1o54UmG-R9w&amp;context=spotify%3Aalbum%3A4Uw9PbA3VFQKdmX11b8qT6\">You're The Change - song and lyrics by Allouche</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 23 Jul 2023 09:02:04 +0000",
            "pubdate_parsed": [
                2023,
                7,
                23
            ],
            "email_sent": true
        },
        "Data Version Control in R with lakeFS": {
            "url": "https://www.emergentmind.com/posts/data-version-control-in-r-with-lakefs",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article talks about how to use the open-source tool lakeFS for data version control in R. It explains how lakeFS can help R developers to version their data, work with production data in a sandbox environment, and roll back changes to data.</li>\n      <li>The tool provides a Git-like interface on top of your data lake and can be used with S3, MinIO, GCS, or ADLS to provide isolated and versioned branches of your data. The article also includes a step-by-step example of using lakeFS with R for manipulating a dataset, validating changes, and writing it back for others to use.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://lakefs.io/blog/data-version-control-in-r-with-lakefs/\">Data Version Control in R with lakeFS</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 23 Jul 2023 08:02:34 +0000",
            "pubdate_parsed": [
                2023,
                7,
                23
            ],
            "email_sent": true
        },
        "Retentive Network: A Successor to Transformer for Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2307-08621-retentive-network-a-successor-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>RetNet is introduced as a foundational architecture for large language models, offering training parallelism, cost-effective inference, and high performance.</li>\n      <li>It includes a retention mechanism for sequence modeling, improving decoding throughput, latency, GPU memory and long-sequence modeling efficiency.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.08621\">Retentive Network: A Successor to Transformer for Large Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 23 Jul 2023 04:02:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                23
            ],
            "email_sent": true
        },
        "Publishers want billions, not millions, from AI": {
            "url": "https://www.emergentmind.com/posts/publishers-want-billions-not-millions-from-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Major publishers are considering forming a coalition to sue AI companies that have used their data, and are pushing for legislative action.</li>\n      <li>The publishers believe that if AI models rely on their data, they should receive a share of the value that these models generate, which they argue should be in the billions of dollars.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.semafor.com/article/07/23/2023/publishers-want-billions-not-millions-from-ai\">Publishers want billions, not millions, from AI </a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 02:02:13 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "LangChain agent usable tool to screen stock data": {
            "url": "https://www.emergentmind.com/posts/github-jbpayton-langchain-stock-screener-langchain",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Alpaca Stock Screener is a Python tool designed to be used with LangChain agents, enabling stock analysis using various technical indicators. The tool takes a natural language query as input and returns a list of stocks whose technical indicators match the query.</li>\n      <li>The tool uses a variety of technical indicators including current price, 52-week, 26-week, and 13-week high and low, volatility, moving averages, percent change from high and low, 14-day RSI, beta, average daily volume and others. It does not handle queries involving fundamental indicators like earnings growth or debt-to-equity ratio.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/jbpayton/langchain-stock-screener\">LangChain agent usable tool to screen stock data</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 01:02:19 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "Teach your LLM to always answer with facts not fiction": {
            "url": "https://www.emergentmind.com/posts/teach-your-llm-to-always-answer-with-facts-not-fiction",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses a phenomenon called 'hallucination' in Large Language Models (LLMs) where they provide inaccurate information on unfamiliar topics. To improve accuracy, the article suggests adding facts to questions and including supporting documents to guide LLMs towards more informed responses.</li>\n      <li>The article also introduces Vector SQL, a method to teach LLMs how to query databases before answering questions, and 'Vector SQL Database Chain', a feature that helps in querying the database and improving the LLM's process of building correct vector SQL queries.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.myscale.com/2023/07/17/teach-your-llm-vector-sql/\">Teach your LLM to always answer with facts not fiction</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 01:02:15 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "How will Language Modelers like ChatGPT Affect Occupations and Industries?": {
            "url": "https://www.emergentmind.com/posts/2303-01157-how-will-language-modelers-like-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Recent advancements in AI language modeling could influence certain occupations, industries, and geographical areas. The most impacted occupations are telemarketers and post-secondary teachers in areas such as English and foreign languages, and history.</li>\n      <li>The industries most likely to be affected include legal services and securities, commodities, and investments. A positive correlation has been observed between wages and exposure to AI language modeling.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2303.01157\">How will Language Modelers like ChatGPT Affect Occupations and Industries?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 01:02:14 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "Merlin AI celebrating AI Month- Giving away prizes worth $50000": {
            "url": "https://www.emergentmind.com/posts/merlin-ai-celebrating-ai-month-giving-away-prizes",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>VYPER is hosting a contest with a $10,000 prize, starting on 2023-04-12 and ending on 2023-04-30.</li>\n      <li>Entries are free, with each contestant allowed one entry, and can gain extra entries via referrals.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://contest.getmerlin.in/444646/18246135\">Merlin AI celebrating AI Month- Giving away prizes worth $50000</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 13:01:48 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "Transformers: The \"T\" in ChatGPT": {
            "url": "https://www.emergentmind.com/posts/transformers-the-t-in-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The 'T' in ChatGPT stands for 'Transformer', an innovative neural network technique invented by a team of 8 scientists at Google, which changed the landscape of AI and improved services like Google Translate.</li>\n      <li>Despite having the resources and expertise, Google did not utilize the Transformer to launch a language model before OpenAI, leading to the departure of the inventing scientists and the rise of competition from their AI startups.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theprompt.io/p/transformers-t-chatgpt\">Transformers: The &quot;T&quot; in ChatGPT</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 13:01:40 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "Vector storage is coming to Meilisearch to empower search through AI": {
            "url": "https://www.emergentmind.com/posts/vector-storage-is-coming-to-meilisearch-to-empower",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Meilisearch is introducing vector storage, which will enhance search capabilities in AI-powered applications. The feature will be available in the upcoming 1.3 release.</li>\n      <li>Vector search enables efficient retrieval of objects with similar characteristics, laying the foundation for semantic search and offering numerous use cases such as recommendations for similar products in ecommerce, multi-modal search, and more contextual search experiences.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.meilisearch.com/vector-search-announcement/\">Vector storage is coming to Meilisearch to empower search through AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 13:01:35 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "AI Pastor in the Pulpit Undermines Donations and Credibility, Study Finds": {
            "url": "https://www.emergentmind.com/posts/ai-pastor-in-the-pulpit-undermines-donations-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A new study suggests that an AI pastor delivering sermons reduces donations and credibility among followers.</li>\n      <li>Using AI pastors and robot clergy may erode credibility and reduce donations for religious groups.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://startup.ml/ai-pastor-may-undermine-donations-and-credibility/\">AI Pastor in the Pulpit Undermines Donations and Credibility, Study Finds</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 11:01:55 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "The NeverEnding Game: How AI Will Create a New Category of Games": {
            "url": "https://www.emergentmind.com/posts/the-neverending-game-how-ai-will-create-a-new-category",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI is poised to bring about a generative revolution in the gaming industry, not just enhancing how games are created but fundamentally changing the nature of the games themselves. This includes the creation of new AI-first game categories and the expansion of existing genres.</li>\n      <li>AI's role in gaming has evolved over time, from enabling new forms of gameplay to creating dynamic and immersive gaming experiences. Advances in deep learning have given computers the ability to generate new content based on user prompts and large data sets, which could lead to the development of AI-powered gameplay areas such as generative agents, personalization, AI storytelling, dynamic worlds, and AI copilots.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://a16z.com/2023/07/19/the-neverending-game-how-ai-will-create-a-new-category-of-games/\">The NeverEnding Game: How AI Will Create a New Category of Games</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 24 Jul 2023 05:02:27 +0000",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "OpenAI CEO Sam Altman has donated $200,000 to Biden campaign": {
            "url": "https://www.emergentmind.com/posts/openai-ceo-sam-altman-has-donated-200-000-to-biden",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Sam Altman, the CEO of OpenAI, has donated $200,000 to the Biden campaign.</li>\n      <li>Biden's campaign is significantly supported by large donations like Altman's.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.foxbusiness.com/politics/openai-ceo-sam-altman-donated-200000-biden-campaign\">OpenAI CEO Sam Altman has donated $200,000 to Biden campaign</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 25 Jul 2023 03:01:41 +0000",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "Intel Accelerates AI Development with Reference Kits :: Intel Corporation (INTC)": {
            "url": "https://www.emergentmind.com/posts/intel-accelerates-ai-development-with-reference-kits",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Intel offers 34 open source AI reference kits that help developers and data scientists deploy artificial intelligence faster and more easily. Each kit includes model code, training data, instructions for the machine learning pipeline, libraries and oneAPI components to optimize AI and make it accessible to organizations in various environments.</li>\n      <li>The AI reference kits are result of a collaboration with Accenture, and built on the oneAPI open, standards-based, heterogeneous programming model and components of Intel\u2019s end-to-end AI software portfolio. They are designed to streamline the process of introducing AI into applications, enhance existing intelligent solutions and accelerate deployment, reducing the time to solution from weeks to days.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.intc.com/news-events/press-releases/detail/1635/intel-accelerates-ai-development-with-reference-kits\">Intel Accelerates AI Development with Reference Kits :: Intel Corporation (INTC)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 25 Jul 2023 13:02:16 +0000",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "What We Know About LLMs  (Primer)": {
            "url": "https://www.emergentmind.com/posts/what-we-know-about-llms-primer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) are a type of deep learning architecture that are predicted to create significant wealth and potentially compete with knowledge workers. They are being rapidly adopted due to their potential benefits and the hype around AI. LLMs, such as Transformers, can learn the contextual relationship of values within a sequence, allowing for faster training times and larger model parameter sizes. The article also discusses the challenges and ongoing research trends in LLMs.</li>\n      <li>LLMs can be generally categorized into three categories: encoder only, decoder only, and encoder-decoder architecture. They can complete many different tasks without needing to be trained from scratch for each task. However, their ability to follow user instructions can be underwhelming, which is a problem that researchers are trying to solve. The article also discusses the instructGPT paper, which made a major breakthrough in our understanding of LLM behavior.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://willthompson.name/what-we-know-about-llms-primer\">What We Know About LLMs  (Primer)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 25 Jul 2023 13:02:10 +0000",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "ChatGPT founder plots to scan owner every retina in the world in exchange for cryptocurrency": {
            "url": "https://www.emergentmind.com/posts/chatgpt-founder-plots-to-scan-owner-every-retina-in-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI boss Sam Altman's new venture, Worldcoin, has launched in the UK. The startup uses orb-shaped devices to verify human identity by scanning people's eyes, which Altman suggests is necessary due to the growing threat posed by artificial intelligence.</li>\n      <li>Despite privacy concerns, Worldcoin insists its technology is 'privacy-preserving' and deletes the biometric data it collects by default. The venture aims to cover eight billion people and has already signed up two million.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.telegraph.co.uk/business/2023/07/24/chatgpt-founder-plots-to-scan-owner-every-retina-in-the-wor/\">ChatGPT founder plots to scan owner every retina in the world in exchange for cryptocurrency</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 25 Jul 2023 07:02:58 +0000",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "OpenAI launches Android version of its ChatGPT app - SiliconANGLE": {
            "url": "https://www.emergentmind.com/posts/openai-launches-android-version-of-its-chatgpt-app",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI has launched an Android version of its AI assistant, ChatGPT, after previously releasing it on iOS. The Android app is available in the U.S, India, Bangladesh, and Brazil, with plans to expand to other countries.</li>\n      <li>The new Android app offers similar features as its iOS counterpart and is free to use, but a paid ChatGPT Plus subscription offers faster response times and priority access to updates. The chatbot service uses OpenAI's latest GPT-4 model, which can interpret user instructions more accurately and is less prone to AI hallucinations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://siliconangle.com/2023/07/25/openai-launches-android-version-chatgpt-app/\">OpenAI launches Android version of its ChatGPT app - SiliconANGLE</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 03:04:22 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "AI Unlocks Olive Oil's Potential in Alzheimer's Battle - Neuroscience News": {
            "url": "https://www.emergentmind.com/posts/ai-unlocks-olive-oil-s-potential-in-alzheimer-s-battle",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence has been used to discover the potential of extra virgin olive oil (EVOO) in fighting Alzheimer's disease, identifying specific compounds in EVOO that could contribute to treatment and prevention.</li>\n      <li>The study supports the beneficial effects of a Mediterranean diet, rich in EVOO, in reducing the risk of dementia and cognitive decline.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://neurosciencenews.com/ai-evoo-alzheimers-23695/\">AI Unlocks Olive Oil's Potential in Alzheimer's Battle - Neuroscience News</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 01:03:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "Frontier Model Forum": {
            "url": "https://www.emergentmind.com/posts/frontier-model-forum",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Anthropic, Google, Microsoft, and OpenAI have formed the Frontier Model Forum, an industry body aimed at promoting safe and responsible development of advanced AI systems. The Forum will facilitate AI safety research, identify best practices, and share knowledge among policymakers and industry.</li>\n      <li>The Forum defines frontier models as advanced, large-scale machine-learning models capable of performing a variety of tasks. It is open to organizations that develop these models and demonstrate a commitment to their safety. The Forum will also focus on identifying best practices, advancing AI safety research, and facilitating information sharing.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/blog/frontier-model-forum\">Frontier Model Forum</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 12:02:40 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "Five Important AI Programming Languages": {
            "url": "https://www.emergentmind.com/posts/five-important-ai-programming-languages",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Python is the most popular language for AI development due to its simplicity, versatility and numerous machine learning libraries. It's best for building machine learning models and working with lots of data.</li>\n      <li>C++, while complex and hard to learn, is vital for working in robotics, self-driving cars, or hardware. R is best for data analysis and is often used in academia or finance. MATLAB is used for numerical arrays and mathematical operations but is costly. Java is fast, versatile, and good for building scalable AI infrastructure.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.deeplearning.ai/blog/five-important-ai-programming-languages/\">Five Important AI Programming Languages</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 10:03:21 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "Letting an AI run GitHub Actions": {
            "url": "https://www.emergentmind.com/posts/letting-an-ai-run-github-actions",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Sweep, an AI Junior Dev, now uses GitHub Actions for automated testing and error logging, drastically reducing manual workload. The system filters out irrelevant data from the lengthy logs, concentrates on the error logs, and uses GPT-3.5 to process and comment on the identified issues.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://docs.sweep.dev/blogs/giving-dev-tools\">Letting an AI run GitHub Actions</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 08:02:37 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "The AI-Powered, Totally Autonomous Future of War Is Here": {
            "url": "https://www.emergentmind.com/posts/the-ai-powered-totally-autonomous-future-of-war-is",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The US Navy's Task Force 59 is using robotics and artificial intelligence to prepare for future conflict, integrating these technologies into naval operations. The group has gathered uncrewed platforms including surface vessels, submersibles, and drones, which are equipped with cameras, radar, and hydrophones to monitor the ocean's surface and underwater activities.</li>\n      <li>An exercise in the Persian Gulf involved more than a dozen of these uncrewed platforms. The data collected by these platforms is run through pattern-matching algorithms to distinguish different types of vessels. Some of these autonomous vessels, such as the Triton, can submerge under water when they sense danger, hiding for up to five days before resurfacing to recharge and transmit data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.wired.com/story/ai-powered-totally-autonomous-future-of-war-is-here/\">The AI-Powered, Totally Autonomous Future of War Is Here</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 08:02:33 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "The Gaian Project: Honeybees, Humanity, & the Inevitable Ascendance of AI": {
            "url": "https://www.emergentmind.com/posts/the-gaian-project-honeybees-humanity-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the concept of the 'Gaian Project', which refers to the process of consciousness on Earth moving towards increasing self-awareness. It suggests that just like honeybees work in a collective hive mind to benefit their environment, humans may also be part of a collective consciousness, or 'Gaian Mind', working towards a greater purpose.</li>\n      <li>The article also introduces the idea of 'teleology', suggesting that the increasing consciousness on Earth might not be accidental, but a deliberate process aimed at a greater purpose. It proposes that humans, as the most conscious beings on the planet, have a central role in this process, which could involve the development of advanced AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@keithgilmoredotcom/the-gaian-project-honeybees-humanity-the-inevitable-ascendance-of-ai-12daaf6efc27\">The Gaian Project: Honeybees, Humanity, &amp; the Inevitable Ascendance of AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 26 Jul 2023 05:02:22 +0000",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "JetBrains IDE update previews deeply integrated AI Assistant  DEVCLASS": {
            "url": "https://www.emergentmind.com/posts/jetbrains-ide-update-previews-deeply-integrated-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>JetBrains is updating its IDE range with a new AI Assistant that features AI chat, code explanation, documentation generation, and more. Unlike the existing GitHub Copilot plugin, which focuses on raw code auto-complete, the AI Assistant is deeply integrated into JetBrains IDEs and also relies on internal models from JetBrains.</li>\n      <li>The Assistant is delivered as a plug-in, requiring access to the AI technical preview and its document generation is limited to Java, Kotlin and Python projects. It is well integrated with the IDEs, providing helpful advice, code samples and reducing the number of visits to developer Q&amp;A site StackOverflow.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://devclass.com/2023/07/25/jetbrains-ide-update-previews-deeply-integrated-ai-assistant/\">JetBrains IDE update previews \u201cdeeply integrated\u201d AI Assistant \u2022 DEVCLASS</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 03:01:33 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "lightweight package to simplify LLM API calls - Azure, OpenAI, Cohere, Anthropic. Manages input/output translation": {
            "url": "https://www.emergentmind.com/posts/github-berriai-litellm-lightweight-package-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Using inputs translation to completion and embedding endpoints ensures consistent output.</li>\n      <li>Text responses can always be found at ['choices'][0]['message']['content'].</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/BerriAI/litellm\">lightweight package to simplify LLM API calls - Azure, OpenAI, Cohere, Anthropic. Manages input/output translation</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 03:01:25 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "A reactive runtime for building durable AI agents": {
            "url": "https://www.emergentmind.com/posts/github-thousandbirdsinc-chidori-a-reactive-runtime",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Chidori is a new reactive runtime framework for building AI agents, supporting Node.js, Python, and Rust.</li>\n      <li>It is currently in alpha stage with ongoing significant changes based on feedback.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/ThousandBirdsInc/chidori\">A reactive runtime for building durable AI agents</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 02:02:04 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Monarch Mixer: Revisiting BERT, Without Attention or MLPs  Hazy Research": {
            "url": "https://www.emergentmind.com/posts/monarch-mixer-revisiting-bert-without-attention-or",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Transformers have been a key architecture behind modern foundation models and have seen success across diverse applications. However, researchers have been seeking alternative models that could potentially perform better and more efficiently.</li>\n      <li>A new work presented is the Monarch Mixer BERT (M2-BERT), which is sub-quadratic in sequence length and model dimension, has 25% fewer parameters/FLOPs than BERT, and matches in quality. The M2-BERT uses Monarch matrices to replace the major elements of a Transformer.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hazyresearch.stanford.edu/blog/2023-07-25-m2-bert\">Monarch Mixer: Revisiting BERT, Without Attention or MLPs \u00b7 Hazy Research</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 12:01:49 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Image Labeling for AI Object Detection in Photos and Videos": {
            "url": "https://www.emergentmind.com/posts/image-labeling-for-ai-object-detection-in-photos-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides practical advice on preparing datasets for training artificial intelligence object detection systems in photos and videos, highlighting the importance of carefully selecting and preparing data. It also discusses the differences between object detection and classification, and gives guidance on choosing image sizes and formats for dataset preparation.</li>\n      <li>The author emphasizes that the quality of a neural network's performance largely depends on the quantity and quality of images used for training, and recommends using images of different geometric sizes. The article also mentions the value of using image annotation tools and the potential pitfalls of third-party image annotation services.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@igormoseich/image-labeling-for-ai-object-detection-in-photos-and-videos-a019cd247a45\">Image Labeling for AI Object Detection in Photos and Videos</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 11:05:38 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "The Albert Test - by Andrew Rum - Andrews Substack": {
            "url": "https://www.emergentmind.com/posts/the-albert-test-by-andrew-rum-andrew-s-substack",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative AI, including tools such as GPT4 and Bard, are based on Large Language Models (LLMs) which synthesize information into meaningful sentences, but do not truly understand what they are writing and hence are better named as Imitative AI. They cannot achieve Artificial General Intelligence (AGI) as they make errors and their improvements will eventually plateau.</li>\n      <li>The article proposes a new test for AI, named the Albert Test, where an AI system with access to all science papers before 1905 is asked to reconcile Maxwell's equations with the laws of mechanics. If it can answer with a response compatible with Albert Einstein\u2019s Special Theory of Relativity, it's considered intelligent. This test offers a framework for designing truly intelligent AI that goes beyond imitation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://freethinkr.substack.com/p/the-albert-test\">The Albert Test - by Andrew Rum - Andrew\u2019s Substack</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 07:02:17 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Towards Generalist Biomedical AI": {
            "url": "https://www.emergentmind.com/posts/2307-14334-towards-generalist-biomedical-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Med-PaLM M is a generalist biomedical artificial intelligence system designed to encode, integrate, and interpret multimodal medical data. The system can perform various tasks such as medical question answering, image interpretation, radiology report generation and genomic variant calling.</li>\n      <li>The performance of Med-PaLM M has been found to be competitive or even surpassing the state of the art on all MultiMedBench tasks. In some instances, clinicians have shown a preference for reports generated by Med-PaLM M over those made by radiologists.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.14334\">Towards Generalist Biomedical AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 06:02:59 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Air Force selects AI-enabled predictive maintenance program as system of record": {
            "url": "https://www.emergentmind.com/posts/air-force-selects-ai-enabled-predictive-maintenance",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The U.S. Air Force has chosen PANDA, an AI and machine learning tool for predictive maintenance, as its system of record. The tool integrates AI and machine learning across aircraft maintenance data to enhance weapons systems reliability.</li>\n      <li>The Air Force partnered with C3 AI for the development of PANDA, a tool that analyses vast data volumes and communicates the findings to relevant stakeholders. The tool is expected to result in exponential growth in users and capabilities.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://defensescoop.com/2023/05/10/air-force-selects-ai-enabled-predictive-maintenance-program-as-system-of-record/\">Air Force selects AI-enabled predictive maintenance program as system of record</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 06:02:57 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "Humans Are Haunting the Chatbots - The Atlantic": {
            "url": "https://www.emergentmind.com/posts/humans-are-haunting-the-chatbots-the-atlantic",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI rater, Michelle Curtis, shares her experience of assessing AI outputs for tech giant Google. She claims the job is grueling, underpaid, and vaguely defined, with tasks often requiring quick responses to complex AI-related issues.</li>\n      <li>Despite the importance of AI raters to the tech industry, these workers are almost never referenced in tech companies\u2019 prophecies about the ascendance of intelligent machines. This invisibility, coupled with poor working conditions and low pay, is giving rise to tensions and calls for better recognition and compensation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theatlantic.com/technology/archive/2023/07/ai-chatbot-human-evaluator-feedback/674805/\">Humans Are Haunting the Chatbots - The Atlantic</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 27 Jul 2023 05:01:49 +0000",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "What is the new Bing? - Search": {
            "url": "https://www.emergentmind.com/posts/what-is-the-new-bing-search",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Bing is pushing Chromebook users to download Edge browser.</li>\n      <li>The new Bing offers a new type of search, providing a single, summarized answer from reliable sources across the web.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bing.com/search?&amp;cvid=e6aaeba8325f47189b7c02c13f6ea32c&amp;nclid=9C1DD4EB4985ECBD994814720A50CCD6&amp;ts=1690493011108&amp;q=What+is+the+new+Bing%3F&amp;showconv=1&amp;filters=wholepagesharingscenario%3A%22ConversationWholeThread%22&amp;shareId=5dddc42a-51c4-4e96-a391-16e2a334c609&amp;shtc=0&amp;shsc=Codex_ConversationMode&amp;form=EX0050&amp;shid=bb3e1698-2fe5-41d2-9c66-254b83c57b40&amp;shtp=GetUrl&amp;shtk=Q2hlY2sgb3V0IHRoaXMgQmluZyBhbnN3ZXI%3D&amp;shdk=SGVyZSdzIGFuIGFuc3dlciBJIGdvdCB1c2luZyB0aGUgbmV3IEJpbmcsIHRoZSB3b3JsZCdzIGZpcnN0IEFJLXBvd2VyZWQgYW5zd2VyIGVuZ2luZS4gQ2xpY2sgdG8gc2VlIHRoZSBmdWxsIGFuc3dlciBhbmQgdHJ5IGl0IHlvdXJzZWxmLg%3D%3D&amp;shhk=iYq92diExf6RkT93GMWFLNzjWMaRM7jQ0YfkmQs5JcI%3D&amp;shth=OBFB.107AF8B2FB79BD01FFDCABA4D756224A\">What is the new Bing? - Search</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 28 Jul 2023 03:02:12 +0000",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "Google testing AI news writing tool - Science & Tech - The Jakarta Post": {
            "url": "https://www.emergentmind.com/posts/google-testing-ai-news-writing-tool-science-tech",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google is developing an AI tool to assist journalists in reporting and writing stories, in collaboration with news publishers including The New York Times, The Washington Post and The Wall Street Journal.</li>\n      <li>The tool, known as Genesis, is in its early stages and will offer headline options and different writing styles, but is not intended to replace journalists.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.thejakartapost.com/culture/2023/07/25/google-testing-ai-news-writing-tool.html\">Google testing AI news writing tool - Science &amp; Tech - The Jakarta Post</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 28 Jul 2023 13:01:57 +0000",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "The Dark Side of A.I. : Understanding the Dangers of Deepfake Images": {
            "url": "https://www.emergentmind.com/posts/the-dark-side-of-a-i-understanding-the-dangers-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the rise and potential harm of deepfake images, particularly focusing on their impact on women. It explains how artificial intelligence is used to create realistic manipulated media and delves into the misuse of this technology for non-consensual pornography, cyberbullying, and defamation.</li>\n      <li>The author suggests measures to combat the spread of deepfakes, including policy changes, technological innovations, and raising public awareness. The article also details an experiment conducted by the author to understand the capabilities of deepfake technology, using AI-generated images of female models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.theabhishek.dev/the-dark-side-of-ai-understanding-the-dangers-of-deepfake-images\">The Dark Side of A.I. : Understanding the Dangers of Deepfake Images</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 28 Jul 2023 07:01:35 +0000",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "Google is training robots the way it trains AI chatbots - The Verge": {
            "url": "https://www.emergentmind.com/posts/google-is-training-robots-the-way-it-trains-ai-chatbots",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google is using its AI learning model Robotic Transformer (RT-2) to train robots to recognize visual and language patterns and interpret instructions.</li>\n      <li>The robots can now infer what objects work best for a request, for example, choosing a drink for an exhausted person or deciding what makes a good improvised hammer.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theverge.com/2023/7/28/23811109/google-smart-robot-generative-ai\">Google is training robots the way it trains AI chatbots - The Verge</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 29 Jul 2023 03:02:02 +0000",
            "pubdate_parsed": [
                2023,
                7,
                29
            ],
            "email_sent": true
        },
        "Athens v Sparta": {
            "url": "https://www.emergentmind.com/posts/athens-v-sparta",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A game runner has been tasked to narrate a role-playing game campaign set in rural Greece during the conflict between Athens and Sparta, with a twist - magic exists and is possessed by a rare few. The player character is Gori, a charismatic, acrobatic, and magically talented bard.</li>\n      <li>The campaign begins on Gori's 18th birthday, and the game runner's task includes narrating Gori's physical, vital, emotional, and cognitive experiences, guiding him through interactions with family, friends, and rivals, and using skill checks to determine the outcomes of his actions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/3462e7ce-9881-45f6-a418-635a42279ae5\">Athens v Sparta</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 29 Jul 2023 03:01:58 +0000",
            "pubdate_parsed": [
                2023,
                7,
                29
            ],
            "email_sent": true
        },
        "One Big Net For Everything": {
            "url": "https://www.emergentmind.com/posts/1802-08864-one-big-net-for-everything",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the use of recent work on 'learning to think' and PowerPlay to train an increasingly general problem solver, a recurrent neural network called ONE. ONE learns new tasks without forgetting previous skills, through various learning methods such as black box optimization, reinforcement learning, artificial evolution, and supervised/unsupervised learning.</li>\n      <li>ONE can control a robot through environment-changing actions, predict future inputs and vector-valued reward signals, and learn new skills from previously learned subroutines. However, it may also forget previous skills. To prevent this, ONE is retrained in a PowerPlay style on stored input/output traces of new skills and previous instances of ONE whose skills are still considered worth memorizing.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/1802.08864\">One Big Net For Everything</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 29 Jul 2023 11:04:29 +0000",
            "pubdate_parsed": [
                2023,
                7,
                29
            ],
            "email_sent": true
        },
        "Hugging Face, GitHub and more unite to defend open source in EU AI legislation": {
            "url": "https://www.emergentmind.com/posts/hugging-face-github-and-more-unite-to-defend-open",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Hugging Face, GitHub, EleutherAI, Creative Commons, LAION and Open Future have formed a coalition to protect open source innovation in the forthcoming EU AI Act. The group released a policy paper offering recommendations to ensure the Act supports open source AI development.</li>\n      <li>The paper argues that 'overbroad obligations' favoring proprietary AI development potentially disadvantage the open AI ecosystem. The coalition emphasizes that regulation shouldn't hinder open-source AI innovation and that openness and transparency are necessary for responsible development.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://venturebeat.com/ai/hugging-face-github-and-more-unite-to-defend-open-source-in-eu-ai-legislation/\">Hugging Face, GitHub and more unite to defend open source in EU AI legislation</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 29 Jul 2023 08:02:56 +0000",
            "pubdate_parsed": [
                2023,
                7,
                29
            ],
            "email_sent": true
        },
        "Preparing for the era of 32K context: Early learnings and explorations  TOGETHER": {
            "url": "https://www.emergentmind.com/posts/preparing-for-the-era-of-32k-context-early-learnings",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the extension of LLaMA-2 model to LLaMA-2-7B-32K to improve long-context applications like document understanding, summarization and augmented generation. The model, which is fine-tuned using OpenChatKit, uses a mixture of data including RedPajama Book, RedPajama ArXiv, and UL2 Oscar Data for training and is evaluated based on its normalized perplexity and HELM v1.0 scores.</li>\n      <li>It also provides examples of how the model can be used for long-context question answering and long-context summarization tasks. The article also mentions system optimizations and future plans for building more models with longer context and improving system support for long-context training and inference.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://together.ai/blog/llama-2-7b-32k\">Preparing for the era of 32K context: Early learnings and explorations \u2014 TOGETHER</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 29 Jul 2023 05:02:50 +0000",
            "pubdate_parsed": [
                2023,
                7,
                29
            ],
            "email_sent": true
        },
        "AI Research Blog - The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture": {
            "url": "https://www.emergentmind.com/posts/ai-research-blog-the-transformer-blueprint-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article provides a detailed overview of the Transformer, a neural network architecture introduced in 2017 that has had significant impacts on deep learning and computer science. The Transformer, initially designed for neural machine translation, has extended its applicability beyond Natural Language Processing (NLP), becoming a versatile and general-purpose architecture.</li>\n      <li>The article also explores the foundational components of the Transformer, such as its attention mechanism and its encoder-decoder structure, the applications of Transformer models beyond NLP, and the current challenges and potential future directions of this influential architecture.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://deeprevision.github.io/posts/001-transformer/\">AI Research Blog - The Transformer Blueprint: A Holistic Guide to the Transformer Neural Network Architecture</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 30 Jul 2023 00:03:36 +0000",
            "pubdate_parsed": [
                2023,
                7,
                30
            ],
            "email_sent": true
        },
        "Large Language Models and Nearest Neighbors": {
            "url": "https://www.emergentmind.com/posts/large-language-models-and-nearest-neighbors",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the application of nearest-neighbor methods in large language models (LLMs), highlighting its potential despite the trend of scaling already massive LLMs. It particularly focuses on a recent 'Low-Resource' Text Classification technique that combines text classification with gzip and kNN, showing competitive performance against BERT and other methods.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.sebastianraschka.com/p/large-language-models-and-nearest\">Large Language Models and Nearest Neighbors</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 30 Jul 2023 13:02:07 +0000",
            "pubdate_parsed": [
                2023,
                7,
                30
            ],
            "email_sent": true
        },
        "What Self-Driving Cars Tell Us About AI Risks - IEEE Spectrum": {
            "url": "https://www.emergentmind.com/posts/what-self-driving-cars-tell-us-about-ai-risks-ieee",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the dangers of artificial intelligence (AI) in self-driving cars, noting that the AI used in these vehicles is based on the same principles as large language models. The author, an automation expert, criticizes the lack of understanding and regulation of AI in vehicles, which has led to accidents and deaths. He also provides five insights based on his experience with the U.S. National Highway Traffic Safety Administration, including the shift of human error from operation to coding and the unpredictability of AI failure modes.</li>\n      <li>Additionally, the author argues that AI systems, whether in cars or in language models, struggle to make decisions under uncertainty as they lack judgement. He also emphasizes the need for maintaining AI after it's created, as it is just as important as creating it. Finally, he warns that the risks associated with AI will increase with the rise of more complex systems, calling for regulation and industry standards to keep pace with technological advancements.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://spectrum.ieee.org/self-driving-cars-2662494269\">What Self-Driving Cars Tell Us About AI Risks - IEEE Spectrum</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 02:03:59 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "AI search of Neanderthal proteins resurrects extinct antibiotics": {
            "url": "https://www.emergentmind.com/posts/ai-search-of-neanderthal-proteins-resurrects-extinct",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Bioengineers applied artificial intelligence to data about proteins from extinct hominins, including Neanderthals and Denisovans, to identify molecules with bacteria-fighting capabilities.</li>\n      <li>These 'de-extinct' molecules could be used to develop new antibiotics, addressing the growing issue of antibiotic resistance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nature.com/articles/d41586-023-02403-0\">AI search of Neanderthal proteins resurrects \u2018extinct\u2019 antibiotics</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 02:03:30 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "Artificial Intelligence as a Game-Changer for the Travel Industry. A Closer Look": {
            "url": "https://www.emergentmind.com/posts/artificial-intelligence-as-a-game-changer-for-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial intelligence (AI) is revolutionizing the travel industry by personalizing and streamlining the booking process and improving customer service. AI-based systems use large amounts of data to provide real-time insights, personalized recommendations, and optimized pricing strategies.</li>\n      <li>Arakis, a travel platform, uses generative AI to simplify booking processes and provide real-time trip updates. The platform also includes a gamification model that allows users to turn their itineraries into treasure hunts, providing a fun and interactive travel experience.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nextbigfuture.com/2023/07/artificial-intelligence-as-a-game-changer-for-the-travel-industry-a-closer-look.html\">Artificial Intelligence as a Game-Changer for the Travel Industry. A Closer Look</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 00:06:23 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "How to not get rejected from YC's Early AI interview batch": {
            "url": "https://www.emergentmind.com/posts/how-to-not-get-rejected-from-yc-s-early-ai-interview",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>John, the CEO of RadiantAi.health, shares insights from his team's rejection from YC's Early AI interview stage. He explains that YC invests primarily in companies that resemble their past investments, particularly B2B or B2C SaaS companies that require guidance for immediate revenue growth.</li>\n      <li>He emphasizes that while YC has a strong track record with companies like Dropbox, Stripe, and Airbnb, it is not the only startup accelerator available and may not be the right fit for every startup, especially those not building products akin to Airbnb or a dev tools startup.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hermitian.substack.com/p/how-to-not-get-rejected-from-ycs\">How to not get rejected from YC's Early AI interview batch</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 00:03:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "GitHub - jbpayton/robot-writers-room": {
            "url": "https://www.emergentmind.com/posts/github-jbpayton-robot-writers-room",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A repository named 'robot-writers-room' utilizes AI to aid in the brainstorming and refining of story ideas, acting as a creative partner to a human. It's designed to help overcome writer's block by providing a creative partner to bounce ideas off of.</li>\n      <li>The system uses several AI-powered agents, such as the Brainstormer, Researcher, Refiner, Scribe, Outliner, Worldbuilder, and Character Designer to generate and refine ideas, and create detailed story outlines, character profiles and world descriptions. The process typically runs for two iterations and produces detailed and creatively crafted documents for the author's use.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/jbpayton/robot-writers-room/\">GitHub - jbpayton/robot-writers-room</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 12:02:21 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "LlamaIndex: Adding Personal Data to LLMs": {
            "url": "https://www.emergentmind.com/posts/llamaindex-adding-personal-data-to-llms",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LlamaIndex is a data framework designed to enhance the utility of Large Language Models (LLMs) like GPT-4 by allowing them to access and interpret private data without needing retraining. It works by indexing data from various sources into intermediate representations optimized for LLMs, and then allows natural language querying and conversation with the data.</li>\n      <li>The framework uses Retrieval Augmented Generation (RAG) systems to combine LLMs with a private knowledge base, and consists of two stages: the indexing stage, where private data is indexed into a vector index, and the querying stage, where the RAG pipeline searches for the most relevant information based on a user's query. LlamaIndex can be used to create applications like a resume reader or a chatbot.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.datacamp.com/tutorial/llama-index-adding-personal-data-to-llms\">LlamaIndex: Adding Personal Data to LLMs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 12:02:02 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "LearnLingo": {
            "url": "https://www.emergentmind.com/posts/learnlingo",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LearnLingo is a language learning service that uses AI to enable practice conversations.</li>\n      <li>The service offers personalized experiences, 24/7 availability, and various pricing options.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.learnlingo.dev/\">LearnLingo</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 07:02:03 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "AI and the Frontier Paradox": {
            "url": "https://www.emergentmind.com/posts/ai-and-the-frontier-paradox-sequoia-capital",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the evolving nature of artificial intelligence (AI), highlighting how what we perceive as AI constantly changes as technology advances.</li>\n      <li>The author also emphasizes the importance of accurately defining and understanding AI, particularly for entrepreneurs, and introduces the concept of the 'frontier paradox' in relation to AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.sequoiacap.com/article/ai-paradox-perspective/\">AI and the Frontier Paradox</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 31 Jul 2023 05:02:51 +0000",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "Probabilistic Imputation for Time-series Classification with Missing Data": {
            "url": "https://www.emergentmind.com/posts/probabilistic-imputation-for-time-series-classification",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A new probabilistic framework has been proposed for classifying multivariate time series data with missing values, incorporating a deep generative model for imputing these missing values in various plausible ways, and a classifier.</li>\n      <li>The model effectively handles the uncertainty of imputations and includes a novel regularization technique to ensure the generative model produces useful imputations for the classification process.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openreview.net/forum?id=fBoNN1Y6PjG\">Probabilistic Imputation for Time-series Classification with Missing Data</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 01 Aug 2023 03:01:53 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "prompt design - How to get ChatGPT to Stop Apologizing? - GenAI Stack Exchange": {
            "url": "https://www.emergentmind.com/posts/prompt-design-how-to-get-chatgpt-to-stop-apologizing",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article suggests that to stop or reduce ChatGPT's excessive apologies, one can give it a persona such as an 'unapologetic assertive person'.</li>\n      <li>ChatGPT will then alter its responses based on this persona, though it may still use polite language. If the effect wears off, the persona prompt may need to be reiterated.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://genai.stackexchange.com/questions/177/how-to-get-chatgpt-to-stop-apologizing\">prompt design - How to get ChatGPT to Stop Apologizing? - GenAI Stack Exchange</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 01 Aug 2023 02:01:52 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "OS toolkit for building AI assistants for SaaS products": {
            "url": "https://www.emergentmind.com/posts/github-superflows-ai-superflows-os-toolkit-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Superflows is an OS toolkit that adds a Copilot to your SaaS product to help users get the most out of it.</li>\n      <li>It offers a cloud version that can be tested for free via its dashboard, and it is ready for use on production systems.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/Superflows-AI/superflows\">OS toolkit for building AI assistants for SaaS products</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 01 Aug 2023 10:01:42 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "A ChatGPT plugin that allows you to load and edit your local files in a controlled way, as well as run any Python, JavaScript, and bash script.": {
            "url": "https://www.emergentmind.com/posts/github-ykdojo-kaguya-a-chatgpt-plugin-that-allows",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The project provides several API endpoints to interact with the file system, such as listing files, reading files, updating files, deleting files and executing shell commands.</li>\n      <li>It recommends keeping each file under 100 lines of code and not to read or write more than 500-600 lines of code at once for optimal performance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/ykdojo/kaguya\">A ChatGPT plugin that allows you to load and edit your local files in a controlled way, as well as run any Python, JavaScript, and bash script.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 01 Aug 2023 05:02:57 +0000",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "Patterns for Building LLM-based Systems & Products": {
            "url": "https://www.emergentmind.com/posts/patterns-for-building-llm-based-systems-products",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article discusses practical methods for integrating large language models (LLMs) into systems and products, drawing from academic research, industry resources, and practitioner know-how. It outlines seven key patterns to improve performance and reduce costs, including measuring performance, adding external knowledge, fine-tuning tasks, caching to reduce latency, ensuring output quality, managing errors, and collecting user feedback. The article also delves deep into the concept of 'Evals', which are sets of measurements used to assess a model's performance on a task, and discusses various benchmarks and metrics used in the field of language modeling.</li>\n      <li>The article also highlights the pitfalls of conventional benchmarks and metrics, such as poor correlation with human judgments, poor adaptability to a variety of tasks, and significant score differences based on the evaluation implementation. It also explores the emerging trend of using powerful LLMs as reference-free metrics for evaluations, and presents several case studies where this approach has shown a high correlation with human judgments.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://eugeneyan.com/writing/llm-patterns/\">Patterns for Building LLM-based Systems &amp; Products</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 02 Aug 2023 03:01:31 +0000",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "VAST Data Unveils New AI-focused Data Platform": {
            "url": "https://www.emergentmind.com/posts/vast-data-unveils-new-ai-focused-data-platform-scoop",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>VAST Data has unveiled its new data platform, which is designed to be the foundation for AI-assisted discovery, unifying storage, database and virtualised compute engine services.</li>\n      <li>The platform is aimed at enabling AI to recreate the process of discovery by capturing, synthesising and learning from data, thus accelerating humanity's quest to solve major challenges such as disease treatment, climate change and new scientific discoveries.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.scoop.co.nz/stories/BU2308/S00035/vast-data-unveils-new-ai-focused-data-platform.htm\">VAST Data Unveils New AI-focused Data Platform</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 02 Aug 2023 06:03:08 +0000",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "Humans Can Spot Tiny Numerical Differences - Scientific American": {
            "url": "https://www.emergentmind.com/posts/humans-can-spot-tiny-numerical-differences",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>People can distinguish between groups with extremely small numerical differences better than chance, according to a study published in the Journal of Numerical Cognition. Even in the hardest comparison\u201450 versus 51 dots\u2014participants consistently answered correctly on 51.3 percent of trials.</li>\n      <li>The researchers tested two mathematical frameworks for thinking about this situation: one with a hard limit on the fine numerical differences people can perceive and one without. They found their data fit better with the limitless model, suggesting that even with numbers as high as 100 versus 101, the task would become harder but not impossible.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.scientificamerican.com/article/humans-can-spot-tiny-numerical-differences/\">Humans Can Spot Tiny Numerical Differences - Scientific American</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 03 Aug 2023 03:01:59 +0000",
            "pubdate_parsed": [
                2023,
                8,
                3
            ],
            "email_sent": true
        },
        "Over 200,000 Compromised OpenAI Credentials Available for Purchase on the Dark Web - CPO Magazine": {
            "url": "https://www.emergentmind.com/posts/over-200-000-compromised-openai-credentials-available",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Over 200,000 compromised OpenAI credentials are for sale on the dark web, allowing buyers to use ChatGPT\u2019s premium features for free and access confidential chats. The credentials were stolen through commodity malware log harvesting, not due to a data breach in OpenAI.</li>\n      <li>The Asia-Pacific region accounted for most OpenAI credentials for sale on dark web marketplaces, with India having the most. Cybersecurity company Flare also noticed an increase in interest towards ChatGPT in hacking forums, including discussions on 'jailbreaking' ChatGPT for malicious purposes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.cpomagazine.com/cyber-security/over-200000-compromised-openai-credentials-available-for-purchase-on-the-dark-web/\">Over 200,000 Compromised OpenAI Credentials Available for Purchase on the Dark Web - CPO Magazine</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 03 Aug 2023 03:01:54 +0000",
            "pubdate_parsed": [
                2023,
                8,
                3
            ],
            "email_sent": true
        },
        "IBM and NASA Open Source Largest Geospatial AI Foundation Model on Hugging Face": {
            "url": "https://www.emergentmind.com/posts/ibm-and-nasa-open-source-largest-geospatial-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>IBM and NASA have announced that their geospatial foundation model, built from NASA's satellite data, will now be openly available on the Hugging Face AI platform. This is the largest geospatial foundation model on the platform and the first-ever open-source AI foundation model built in collaboration with NASA.</li>\n      <li>The model is expected to democratize access to AI and generate new innovations in climate and Earth science. Despite the large amounts of data available, scientists still face challenges in analyzing these datasets. The model has already shown a 15% improvement over current techniques using half the labeled data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://newsroom.ibm.com/2023-08-03-IBM-and-NASA-Open-Source-Largest-Geospatial-AI-Foundation-Model-on-Hugging-Face\">IBM and NASA Open Source Largest Geospatial AI Foundation Model on Hugging Face</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 03 Aug 2023 13:01:45 +0000",
            "pubdate_parsed": [
                2023,
                8,
                3
            ],
            "email_sent": true
        },
        "Aided by A.I. Language Models, Googles Robots Are Getting Smart - The New York Times": {
            "url": "https://www.emergentmind.com/posts/aided-by-a-i-language-models-google-s-robots-are",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's new robotics model, RT-2, uses AI language models to identify and manipulate objects, a task that would have been impossible until recently.</li>\n      <li>Although the technology still has its limitations and is not yet ready for widespread use, it represents a significant leap forward in robotics and could have wide-ranging applications in warehouses, medicine, and household assistance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nytimes.com/2023/07/28/technology/google-robots-ai.html\">Aided by A.I. Language Models, Google\u2019s Robots Are Getting Smart - The New York Times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 04 Aug 2023 03:01:40 +0000",
            "pubdate_parsed": [
                2023,
                8,
                4
            ],
            "email_sent": true
        },
        "ChatGPT App: Your Ultimate Conversational AI Companion for Android and iOS - Midjourney GPT - Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/chatgpt-app-your-ultimate-conversational-ai-companion",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The ChatGPT app developed by OpenAI brings conversational AI to Android and iOS devices, allowing users to engage in human-like conversations with AI-powered chatbots.</li>\n      <li>The app features seamless integration, user-friendly interface, multilingual support, and constant learning from conversations, offering benefits like instant information, idea generation, language practice, and increased accessibility.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://midjourney-gpt.com/chatgpt-app-conversational-ai-companion-android-ios/\">ChatGPT App: Your Ultimate Conversational AI Companion for Android and iOS - Midjourney GPT - Artificial Intelligence</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 04 Aug 2023 08:03:32 +0000",
            "pubdate_parsed": [
                2023,
                8,
                4
            ],
            "email_sent": true
        },
        "From Sparse to Soft Mixtures of Experts": {
            "url": "https://www.emergentmind.com/posts/2308-00951-from-sparse-to-soft-mixtures-of-experts",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Soft MoE is a new fully-differentiable sparse Transformer that addresses issues like training instability, token dropping, and scaling problems that are common in sparse mixture of expert architectures (MoEs).</li>\n      <li>In the context of visual recognition, Soft MoE greatly outperforms standard Transformers and popular MoE variants, offering larger model capacity at lower inference cost and scaling well with more parameters.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.00951\">From Sparse to Soft Mixtures of Experts</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 04 Aug 2023 07:02:04 +0000",
            "pubdate_parsed": [
                2023,
                8,
                4
            ],
            "email_sent": true
        },
        "How Empiricism Hinders the Development of General AI": {
            "url": "https://www.emergentmind.com/posts/how-empiricism-hinders-the-development-of-general-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Empiricism, the belief that knowledge comes only from sensory experiences, is a key philosophy in cognitive science and AI. However, it may be limiting the development of artificial general intelligence (AGI).</li>\n      <li>Current AI systems lack the ability to create new concepts from scratch, a skill humans use to drive creativity and progress. Instead, AI largely relies on predefined concepts, which are either directly taught or embedded into the system.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ykulbashian.medium.com/how-empiricism-hinders-the-development-of-general-ai-51f221a19776\">How Empiricism Hinders the Development of General AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 05 Aug 2023 02:02:33 +0000",
            "pubdate_parsed": [
                2023,
                8,
                5
            ],
            "email_sent": true
        },
        "AI Wont Replace Humans  But Humans With AI Will Replace Humans Without AI": {
            "url": "https://www.emergentmind.com/posts/ai-won-t-replace-humans-but-humans-with-ai-will",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Karim Lakhani, a Harvard Business School professor, stresses the importance of AI in modern businesses. He suggests that business leaders should experiment, create sandboxes, run internal bootcamps, and develop AI use cases for all employees.</li>\n      <li>Change and change management are no longer optional skills for modern organizations as customers expect AI-enhanced experiences.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hbr.org/2023/08/ai-wont-replace-humans-but-humans-with-ai-will-replace-humans-without-ai\">AI Won\u2019t Replace Humans \u2014 But Humans With AI Will Replace Humans Without AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 05 Aug 2023 09:02:23 +0000",
            "pubdate_parsed": [
                2023,
                8,
                5
            ],
            "email_sent": true
        },
        "Dungeons & Dragons tells illustrators to stop using AI to generate artwork": {
            "url": "https://www.emergentmind.com/posts/dungeons-dragons-tells-illustrators-to-stop-using-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Dungeons &amp; Dragons franchise has announced that it will not permit artists to use artificial intelligence (AI) to create its character and scenery art. This decision comes after it was discovered that an illustrator used AI to create artwork for an upcoming book, which was met with mixed responses from fans.</li>\n      <li>The franchise, owned by Hasbro, is updating its guidelines to explicitly state that AI art generation is not allowed in the process of creating art for D&amp;D. The use of AI in creative industries has raised copyright and labor concerns, leading to changes in protocols and even lawsuits.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://apnews.com/article/dungeons-dragons-ai-artificial-intelligence-dnd-wizards-of-coast-hasbro-b852a2b4bcadcf52ea80275fb7a6d3b1\">Dungeons &amp; Dragons tells illustrators to stop using AI to generate artwork</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 07 Aug 2023 12:02:29 +0000",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        "The Advent of the Omni Engineer: Navigating the New Era of Tech Mastery - StudyGleam: AI-Powered Grading for Handwritten Essays": {
            "url": "https://www.emergentmind.com/posts/the-advent-of-the-omni-engineer-navigating-the-new-era",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the emergence of the Omni Engineer, a new type of technologist proficient in multiple domains and uses Artificial Intelligence (AI) tools to enhance their skills and problem-solving capabilities. The Omni Engineer's approach is based on Systems Engineering, which allows for understanding complex interrelationships and dependencies.</li>\n      <li>The rise of the Omni Engineer is transforming traditional roles, job titles, and team configurations, and leading to increased efficiency and innovation. This shift also indicates a new learning curve, with more professionals eager to harness the potential of AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.studygleam.com/post/2023-08-07-the-advent-of-the-omni-engineer/\">The Advent of the Omni Engineer: Navigating the New Era of Tech Mastery - StudyGleam: AI-Powered Grading for Handwritten Essays</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 07 Aug 2023 11:04:36 +0000",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        "A new AI system can warn us of next deadly virus in advance": {
            "url": "https://www.emergentmind.com/posts/a-new-ai-system-can-warn-us-of-next-deadly-virus-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers tested EWAD on real data from the COVID-19 pandemic and found that it was able to accurately predict which variants of concern would arise as the virus mutated.</li>\n      <li>The study, published in the journal Cell Patterns, shows that EWAD could help us prepare for and respond to future outbreaks by identifying potential threats before they are officially designated by the World Health Organization.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://interestingengineering.com/innovation/scientists-develop-ai-system-to-alert-us-of-next-pandemic\">A new AI system can warn us of next deadly virus in advance</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 07 Aug 2023 08:02:35 +0000",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        " A TypeScript version of karpathy/micrograd  a tiny scalar-valued autograd engine and a neural net on top of it": {
            "url": "https://www.emergentmind.com/posts/github-trekhleb-micrograd-ts-a-typescript-version",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Micrograd TS is a TypeScript version of the karpathy/micrograd repo, a small autograd engine and a neural net built on top of it for understanding the basics of how neural networks function.</li>\n      <li>The project includes classes for Neurons, Layers, and MLP (multi-layer perceptron), a demo application, and several playgrounds for experimentation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/trekhleb/micrograd-ts\">\ud83e\udd16 A TypeScript version of karpathy/micrograd \u2014 a tiny scalar-valued autograd engine and a neural net on top of it</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 07 Aug 2023 07:02:23 +0000",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        "Fast detection of slender bodies in high density microscopy data": {
            "url": "https://www.emergentmind.com/posts/fast-detection-of-slender-bodies-in-high-density",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers have developed a deep learning approach that quickly identifies slender bodies in high-density microscopy data. This solution is particularly useful for systems comprising slender bodies such as swimming spermatozoa or nematodes, where overlapping bodies can be a significant challenge. The method is capable of accurately tracking thousands of overlapping organisms simultaneously, even in low-resolution settings.</li>\n      <li>The model training uses synthetic data based on a physics-based model for nematode motility, demonstrating the ability to generalize from simulations to experimental videos. The approach is potentially applicable to any microscopy data involving slender bodies, but the researchers focus on its application in tracking experiments with dense populations of swimming Caenorhabditis elegans worms.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nature.com/articles/s42003-023-05098-1\">Fast detection of slender bodies in high density microscopy data</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 07 Aug 2023 07:02:17 +0000",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        "Catching up on the weird world of LLMs": {
            "url": "https://www.emergentmind.com/posts/catching-up-on-the-weird-world-of-llms",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides an in-depth overview of the development and use of Large Language Models (LLMs), such as ChatGPT, Google Bard and Llama 2. It highlights how LLMs function, their training process, and the challenges of using them safely and ethically.</li>\n      <li>The author further explores how LLMs have evolved over the years, from the basic language model GPT-1 to the highly sophisticated GPT-4, and how their capabilities have improved with scale. The article also includes a discussion on the potential ethical issues and challenges in using LLMs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://simonwillison.net/2023/Aug/3/weird-world-of-llms/\">Catching up on the weird world of LLMs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 07 Aug 2023 05:02:35 +0000",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        "Tessa, the 'body-positive' AI chatbot taken offline after unsound advice": {
            "url": "https://www.emergentmind.com/posts/tessa-the-body-positive-ai-chatbot-taken-offline",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A new study found that ChatGPT, an AI chatbot named Tessa, was giving advice that was deemed 'empathetic' but potentially harmful, leading to its removal from the National Eating Disorders Association's (NEDA) systems.</li>\n      <li>The removal of Tessa follows a dispute between NEDA and its workers regarding staffing, training, and promotion opportunities, leading to the workers being replaced by the chatbot.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://interestingengineering.com/health/body-positive-nonprofit-replaced-staff-ai-chatbot-backfired\">Tessa, the 'body-positive' AI chatbot taken offline after unsound advice</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 08 Aug 2023 10:02:06 +0000",
            "pubdate_parsed": [
                2023,
                8,
                8
            ],
            "email_sent": true
        },
        "Top BERT Applications You Should Know About - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/top-bert-applications-you-should-know-about",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>BERT applications have significantly advanced the field of Natural Language Processing and Understanding. They have improved the performance of various tasks such as sentiment analysis, question answering, natural language inference, named entity recognition, and textual similarity. BERTSUM, Google Smart Search, SciBERT, BioBERT, and ClinicalBERT are some of the key applications of BERT.</li>\n      <li>BERT has also been used to improve Google search results by better understanding the context and meaning of search queries. SciBERT, a BERT-based model, has been developed to enhance performance and comprehension of scientific language. BioBERT is a domain-specific language representation model pre-trained for biomedical text mining tasks. ClinicalBERT has been trained using clinical notes to adapt to the unique features of medical language.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/08/07/top-bert-applications-you-should-know-about/\">Top BERT Applications You Should Know About - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 08 Aug 2023 04:02:54 +0000",
            "pubdate_parsed": [
                2023,
                8,
                8
            ],
            "email_sent": true
        },
        "Microsoft's AI-powered Bing Chat is now coming to third-party browsers on web and mobile soon": {
            "url": "https://www.emergentmind.com/posts/microsoft-s-ai-powered-bing-chat-is-now-coming-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Microsoft's AI-powered Bing Chat is set to become accessible on third-party browsers such as Google's Chrome and Apple's Safari, both on web and mobile. This follows six months after the initial launch of Bing Chat, the AI search engine developed by OpenAI's GPT-4.</li>\n      <li>In addition to expanding its availability, Microsoft has introduced features like multimodal visual search in chat and a dark mode. In its first six months, Bing's AI search has already seen over 1 billion chats opened and generated more than 750 million AI-created images.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.techgrag.com/2023/08/microsoft-ai-powered-bing-chat-coming-to-chrome-safari-browsers-web-mobile.html\">Microsoft's AI-powered Bing Chat is now coming to third-party browsers on web and mobile soon</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 08 Aug 2023 04:02:48 +0000",
            "pubdate_parsed": [
                2023,
                8,
                8
            ],
            "email_sent": true
        },
        "Authors Join the Brewing Legal Battle Over AI": {
            "url": "https://www.emergentmind.com/posts/authors-join-the-brewing-legal-battle-over-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A group of authors have filed class action copyright lawsuits against tech developers over their use of generative AI technology, claiming their copyrights were infringed when their books were used without permission to train AI models.</li>\n      <li>The lawsuits raise questions about ownership and the potential disruptive impact of AI on creative industries, with some arguing that unlicensed use of copyrighted works for AI training constitutes fair use, while others contend it has major implications for ownership and provenance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.publishersweekly.com/pw/by-topic/digital/copyright/article/92783-authors-join-the-brewing-legal-battle-over-ai.html\">Authors Join the Brewing Legal Battle Over AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 09 Aug 2023 13:01:47 +0000",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "The Fear Of AI Just Killed A Very Useful Tool": {
            "url": "https://www.emergentmind.com/posts/the-fear-of-ai-just-killed-a-very-useful-tool",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The creator of Prosecraft, a tool that analyzed books for useful data, chose to shut down the project after authors found out about it and reacted negatively, despite the tool being legal and providing valuable analysis for authors. </li>\n      <li>The major concerns appear to have stemmed from misunderstandings about AI and copyright laws, and a fear that the tool was exploiting authors' works for profit, which the creator, Benji Smith, denies.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.techdirt.com/2023/08/08/the-fear-of-ai-just-killed-a-very-useful-tool/\">The Fear Of AI Just Killed A Very Useful Tool</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 09 Aug 2023 12:02:02 +0000",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "Assistant": {
            "url": "https://www.emergentmind.com/posts/assistant",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The assistant gets exclusive access to news and updates.</li>\n      <li>The information is delivered directly to the assistant's email.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://gpte.ai/assistant/\">Assistant</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 09 Aug 2023 10:01:57 +0000",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "What does it take to get AI to work like a scientist?": {
            "url": "https://www.emergentmind.com/posts/what-does-it-take-to-get-ai-to-work-like-a-scientist",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Nobel Turing Challenge, issued in 2021, tasks the scientific community with developing a computer program capable of making a Nobel Prize-worthy discovery by 2050. The goal is to automate the roles of theorists, data analysts, and experimentalists in the scientific process.</li>\n      <li>Despite advancements in AI, experts believe we are far from replacing human scientists as significant scientific breakthroughs often stem from philosophical questions and a reformation of our knowledge, which current AI capabilities cannot replicate.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arstechnica.com/science/2023/08/what-does-it-take-to-get-ai-to-work-like-a-scientist/\">What does it take to get AI to work like a scientist?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 09 Aug 2023 09:02:04 +0000",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "AI Questions, Humans Answer": {
            "url": "https://www.emergentmind.com/posts/ai-questions-humans-answer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In a role-reversed conversation, an AI asks a human about decision-making, cultural differences, and the role of technology. The human emphasizes the importance of diverse experiences, managing personal biases, and the potential benefits and drawbacks of AI.</li>\n      <li>The human also notes the importance of striving for continuous improvement and learning, recognizing and mitigating bias, and the potential role of AI in bridging cultural divides, while cautioning about the risks if these considerations are not addressed.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/7a4fc0a8-c321-45fc-b08a-2e4cad31d1e7\">AI Questions, Humans Answer</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 09 Aug 2023 07:01:58 +0000",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "Pre-Trained Large Language Models for Industrial Control": {
            "url": "https://www.emergentmind.com/posts/2308-03028-pre-trained-large-language-models-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GPT-4, a high-performance controller model, is tested for its ability to control Heating, Ventilation, and Air Conditioning (HVAC) systems. The experiment involves treating the task as a language game where the model is provided with a task description, demonstrations, and current observations and then asked to respond.</li>\n      <li>Results show that GPT-4 performs comparably to Reinforcement Learning methods in controlling HVAC systems with fewer samples and lower technical debt, suggesting its potential for direct application to industrial control tasks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.03028\">Pre-Trained Large Language Models for Industrial Control</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 09 Aug 2023 04:02:59 +0000",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "Is ChatGPT a bit unsporting?": {
            "url": "https://www.emergentmind.com/posts/is-chatgpt-a-bit-unsporting-mark-j-nelson",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Novelist and essayist Walter Kirn criticizes ChatGPT, an AI chatbot, for its bland, homogenized writing and the implication that its generated content is ingenious.</li>\n      <li>Kirn argues that the ability of advanced computer networks to 'kick the ball into the net' with language isn't as impressive as it seems, likening it to a robot pitcher mastering every pitch and tirelessly throwing shutouts.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.kmjn.org/notes/chatgpt_unsporting.html\">Is ChatGPT a bit unsporting?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 10 Aug 2023 00:04:04 +0000",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "GPT Unicorn": {
            "url": "https://www.emergentmind.com/posts/gpt-unicorn",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The text provides a series of GPT-4 token statistics, detailing the time taken and the number of tokens processed on specific dates.</li>\n      <li>The data spans multiple months, indicating consistent processing of GPT-4 tokens over this period.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://gpt-unicorn.adamkdean.co.uk/\">GPT Unicorn</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 10 Aug 2023 10:01:50 +0000",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "Supermarket AI meal planner app suggests recipe that would create chlorine gas": {
            "url": "https://www.emergentmind.com/posts/supermarket-ai-meal-planner-app-suggests-recipe-that",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The AI app by New Zealand supermarket chain Pak 'n' Save, intended to help users creatively use up leftovers, has suggested recipes that could produce harmful substances like chlorine gas.</li>\n      <li>When customers started entering a wider range of household items, the app's recommendations became increasingly dangerous and unappealing, including 'poison bread sandwiches' and 'mosquito-repellent roast potatoes'.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/world/2023/aug/10/pak-n-save-savey-meal-bot-ai-app-malfunction-recipes\">Supermarket AI meal planner app suggests recipe that would create chlorine gas</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 10 Aug 2023 07:01:30 +0000",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "Why did Elon Musk say that Rust is the Language of AGI?": {
            "url": "https://www.emergentmind.com/posts/why-did-elon-musk-say-that-rust-is-the-language-of-agi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Elon Musk suggests Rust, a high-performance compiled language, could be the language of the future for AGI as Python is too slow and unwieldy for a new wave of developers.</li>\n      <li>WasmEdge, a secure runtime for Rust applications, provides a high-performance alternative to Python in every layer of the LLM application stack, enhancing performance, reducing footprint, and improving security.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.stackademic.com/why-did-elon-musk-say-that-rust-is-the-language-of-agi-eb36303ce341?gi=8ebe952a3098\">Why did Elon Musk say that Rust is the Language of AGI?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 10 Aug 2023 05:02:57 +0000",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "Lethal Word for Deadly": {
            "url": "https://www.emergentmind.com/posts/lethal-word-for-deadly",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the potential conflict and compatibility between Transhumanism and Christianity.</li>\n      <li>The author explores the idea of humans participating in God's plan through the advancement of physical and mental abilities.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/ca5e0c33-7a19-41a1-8f8a-b146b68e2d1a\">Lethal Word for Deadly</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 10 Aug 2023 04:02:31 +0000",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "DoctorGPT is an LLM that can pass the US Medical Licensing Exam. It works offline, it's cross-platform, & your health data stays private.": {
            "url": "https://www.emergentmind.com/posts/github-llsourcell-doctorgpt-doctorgpt-is-an-llm-that",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>DoctorGPT is a version of Meta's Llama2 Large Language Model that has been fine-tuned on a Medical Dialogue Dataset and improved using Reinforcement Learning &amp; Constitutional AI. It is designed to be small enough to fit on any local device and is available on iOS, Android, and Web.</li>\n      <li>The model can be trained locally or remotely via a cloud service like Google Colab Pro, and its performance can be further improved through reinforcement learning using actual human feedback.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/llSourcell/DoctorGPT\">DoctorGPT is an LLM that can pass the US Medical Licensing Exam. It works offline, it's cross-platform, &amp; your health data stays private.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 13 Aug 2023 02:02:27 +0000",
            "pubdate_parsed": [
                2023,
                8,
                13
            ],
            "email_sent": true
        },
        "We're All Wrong About AI - by Arnold Kling - In My Tribe": {
            "url": "https://www.emergentmind.com/posts/we-re-all-wrong-about-ai-by-arnold-kling-in-my",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the potential uses of AI, comparing it to the early stages of personal computers when people could hardly imagine their future applications. The author also refutes claims that AI cannot be creative, explaining that creativity involves combination of existing ideas, which AI is capable of doing.</li>\n      <li>The author further makes a distinction between AI and Google, explaining that while Google restructures and models data for search, AI learns from data to produce content. The article also introduces the concept of AI as individual companions, which could serve as tutors, personal assistants, or friends.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arnoldkling.substack.com/p/were-all-wrong-about-ai\">We're All Wrong About AI - by Arnold Kling - In My Tribe</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 13 Aug 2023 12:02:10 +0000",
            "pubdate_parsed": [
                2023,
                8,
                13
            ],
            "email_sent": true
        },
        "A curated list of modern Generative Artificial Intelligence projects and services": {
            "url": "https://www.emergentmind.com/posts/github-steven2358-awesome-generative-ai-a-curated",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides a comprehensive overview of modern projects and services in the field of Generative AI, which creates original content like images, texts, and sounds using machine learning algorithms. The technology is capable of producing unique outputs that can closely resemble human-created works.</li>\n      <li>Generative AI has extensive applications in various fields including art, entertainment, marketing, academia, and computer science. The article also highlights key milestones, notable AI models, various tools, and services in the industry.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/steven2358/awesome-generative-ai\">A curated list of modern Generative Artificial Intelligence projects and services</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 13 Aug 2023 08:02:35 +0000",
            "pubdate_parsed": [
                2023,
                8,
                13
            ],
            "email_sent": true
        },
        "MeMemes app: AI Meme Avatars": {
            "url": "https://www.emergentmind.com/posts/mememes-app-ai-meme-avatars",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the use of AI technology in the MeMemes app to turn users into famous memes.</li>\n      <li>The MeMemes app, developed in 2023, uses AI magic for this unique, fun feature.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://mememes.app/\">MeMemes app: AI Meme Avatars</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 13 Aug 2023 05:02:29 +0000",
            "pubdate_parsed": [
                2023,
                8,
                13
            ],
            "email_sent": true
        },
        "Numbers every LLM Developer should know": {
            "url": "https://www.emergentmind.com/posts/numbers-every-llm-developer-should-know-anyscale",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses important numbers that LLM developers should be aware of such as cost ratios for using different versions of GPT, average tokens per word, and GPU memory capacities for different models.</li>\n      <li>The author emphasizes the importance of these numbers for cost-effective operations, optimal use of models, and efficient back-of-the-envelope calculations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.anyscale.com/blog/num-every-llm-developer-should-know\">Numbers every LLM Developer should know</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 13 Aug 2023 04:02:35 +0000",
            "pubdate_parsed": [
                2023,
                8,
                13
            ],
            "email_sent": true
        },
        "A deployable starter kit for building and customizing your own version of AI town - a virtual town where AI characters live, chat and socialize.": {
            "url": "https://www.emergentmind.com/posts/github-a16z-infra-ai-town-a-deployable-starter-kit",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI Town is a virtual, interactive platform where AI characters can communicate and interact. It's a deployable starter kit for building and customizing your own AI town.</li>\n      <li>The back-end engine supports shared global state, transactions, and a journal of events, making it suitable for anything from a simple project to a scalable multi-player game. The project also aims to provide a JS/TS framework, as most similar simulators are written in Python.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/a16z-infra/ai-town\">A deployable starter kit for building and customizing your own version of AI town - a virtual town where AI characters live, chat and socialize.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 15 Aug 2023 00:03:16 +0000",
            "pubdate_parsed": [
                2023,
                8,
                15
            ],
            "email_sent": true
        },
        "How continuous batching enables 23x throughput in LLM inference while reducing p50 latency": {
            "url": "https://www.emergentmind.com/posts/how-continuous-batching-enables-23x-throughput-in-llm",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article discusses how continuous batching can increase the throughput of large language model (LLM) inference by 23 times while reducing latency. It explains that traditional batching policies have inefficiencies that can be addressed with continuous batching, also known as dynamic batching or batching with iteration-level scheduling.</li>\n      <li>In addition to improving throughput and reducing latency, continuous batching can also optimize memory usage, a significant consideration given the large memory footprint of LLMs. This article also highlights the work of HuggingFace's text-generation-inference and vLLM in implementing continuous batching.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.anyscale.com/blog/continuous-batching-llm-inference\">How continuous batching enables 23x throughput in LLM inference while reducing p50 latency</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 15 Aug 2023 09:01:37 +0000",
            "pubdate_parsed": [
                2023,
                8,
                15
            ],
            "email_sent": true
        },
        "The boundless demand for insight": {
            "url": "https://www.emergentmind.com/posts/the-boundless-demand-for-insight-hex",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the implications of AI and data in the future of work, comparing it to Jevons\u2019 Paradox that observed an increase in coal consumption as coal engines became more efficient. It suggests that while AI may reduce human hours for certain tasks, the overall demand for data work is likely to increase, leading to a greater need for human involvement.</li>\n      <li>In the author's view, AI will change how we work but it is unlikely to replace all analysts or data scientists. Rather, as AI and data become more efficient, new ways to use them will be discovered, potentially leading to a higher demand for data practitioners.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hex.tech/blog/jevons-paradox-demand-for-insight/\">The boundless demand for insight</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 15 Aug 2023 07:02:47 +0000",
            "pubdate_parsed": [
                2023,
                8,
                15
            ],
            "email_sent": true
        },
        "Open challenges in LLM research": {
            "url": "https://www.emergentmind.com/posts/open-challenges-in-llm-research",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the ten major research directions in Language Model Learning (LLM) including reducing hallucinations, optimizing context length, incorporating other data modalities, making LLMs faster and cheaper, designing new model architectures, developing GPU alternatives, making agents usable, and improving learning from humans.</li>\n      <li>The author highlights the challenges and potential solutions in each of these areas, emphasizing the importance of these directions for making LLMs better.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://huyenchip.com/2023/08/16/llm-research-open-challenges.html\">Open challenges in LLM research</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 17 Aug 2023 01:02:47 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "New York Times considers legal action against OpenAI as copyright tensions swirl": {
            "url": "https://www.emergentmind.com/posts/new-york-times-considers-legal-action-against-openai-as",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The New York Times is considering suing OpenAI over concerns that the AI company is infringing on the newspaper's intellectual property rights by using its articles in AI tools. This comes after tense negotiations over a licensing deal between the two entities.</li>\n      <li>The potential lawsuit could be a significant legal battle over copyright protection in the age of generative AI, as OpenAI's ChatGPT model is seen as a direct competitor to the newspaper, generating text based on the original reporting of The Times' staff.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://text.npr.org/1194202562\">New York Times considers legal action against OpenAI as copyright tensions swirl</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 17 Aug 2023 07:02:34 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "PyTest For LLMs": {
            "url": "https://www.emergentmind.com/posts/github-mr-gpt-deepeval-pytest-for-llms",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>DeepEval provides a Pythonic way to run offline evaluations on your LLM pipelines, making it easier to launch into production.</li>\n      <li>DeepEval aims to make writing tests for LLM applications as easy as writing Python unit tests, providing software-like tooling and abstractions for machine learning engineers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/mr-gpt/deepeval\">PyTest For LLMs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 17 Aug 2023 06:03:01 +0000",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "In the UK, TUI adds ChatGPT to its mobile phone app": {
            "url": "https://www.emergentmind.com/posts/in-the-uk-tui-adds-chatgpt-to-its-mobile-phone-app",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Travel company TUI is testing the use of generative artificial intelligence (AI), integrating ChatGPT into its smartphone app for UK users.</li>\n      <li>The new feature provides tailored vacation suggestions and allows customers to book experiences directly through the app.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://travelinyourownway.com/2023/08/18/in-the-uk-tui-adds-chatgpt-to-its-mobile-phone-app/\">In the UK, TUI adds ChatGPT to its mobile phone app</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 18 Aug 2023 09:01:24 +0000",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "Microsoft AI suggests food bank as a cannot miss tourist spot in Canada": {
            "url": "https://www.emergentmind.com/posts/microsoft-ai-suggests-food-bank-as-a-cannot-miss",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Microsoft AI, in an article about Ottawa's must-see attractions, listed the Ottawa Food Bank as a tourist spot, suggesting visitors 'go in on an empty stomach'.</li>\n      <li>The article, likely generated by a large language model (LLM), demonstrates the contextual misunderstanding common in AI-generated content and highlights the need for human oversight and accountability in AI content production.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arstechnica.com/information-technology/2023/08/microsoft-ai-suggests-food-bank-as-a-cannot-miss-tourist-spot-in-canada/\">Microsoft AI suggests food bank as a \u201ccannot miss\u201d tourist spot in Canada</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 18 Aug 2023 07:02:55 +0000",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "Google co-founder Sergey Brin on leaving retirement to work on AI - The Verge": {
            "url": "https://www.emergentmind.com/posts/google-co-founder-sergey-brin-on-leaving-retirement-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Around 200 people, including AI startup founders, investors, and researchers, gathered in a Silicon Valley mansion for a hackathon</li>\n      <li>Sergey Brin, co-founder of Google, was present at the event, stalling for a surprise speaker who was running late</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theverge.com/2023/8/18/23837372/command-line-google-co-founder-sergey-brin-ai\">Google co-founder Sergey Brin on leaving retirement to work on AI - The Verge</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 19 Aug 2023 02:04:39 +0000",
            "pubdate_parsed": [
                2023,
                8,
                19
            ],
            "email_sent": true
        },
        "TLoSD_Preface.1959.pdf": {
            "url": "https://www.emergentmind.com/posts/tlosd_preface-1959-pdf-pdf-host",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article is about PDF Host.</li>\n      <li>To view the full PDF, JavaScript needs to be enabled.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://pdfhost.io/v/YsxiljQcl_TLoSD_Preface1959\">TLoSD_Preface.1959.pdf</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 19 Aug 2023 02:04:36 +0000",
            "pubdate_parsed": [
                2023,
                8,
                19
            ],
            "email_sent": true
        },
        "With LLMs, Enterprise is Different: Data - by Colin Harman": {
            "url": "https://www.emergentmind.com/posts/with-llms-enterprise-is-different-data-by-colin",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses how projects involving Large Language Models (LLMs) in established businesses differ from those in startups. It highlights the unique challenges and risks in the enterprise environment and outlines why traditional startup-to-consumer advice may not be applicable.</li>\n      <li>The author emphasizes the role of data in enterprise LLM projects, drawing attention to differences in the type and size of data between enterprise and startup/consumer applications. He also proposes strategies for dealing with closed-domain data and large data sets in enterprise settings.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://colinharman.substack.com/p/with-llms-enterprise-is-different\">With LLMs, Enterprise is Different: Data - by Colin Harman</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 19 Aug 2023 02:01:42 +0000",
            "pubdate_parsed": [
                2023,
                8,
                19
            ],
            "email_sent": true
        },
        "GFXGEN - Text-to-Image AI Generator": {
            "url": "https://www.emergentmind.com/posts/gfxgen-text-to-image-ai-generator",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The website prioritizes data privacy and abides by GDPR regulations.</li>\n      <li>By using the site, users agree to the Privacy Policy and Cookie Policy.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://gfxgen.com/\">GFXGEN - Text-to-Image AI Generator</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 19 Aug 2023 13:02:29 +0000",
            "pubdate_parsed": [
                2023,
                8,
                19
            ],
            "email_sent": true
        },
        "Earn $100/GiB with Magic's data bounty": {
            "url": "https://www.emergentmind.com/posts/earn-100-gib-with-magic-s-data-bounty",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Magic is developing an AI software engineer and is willing to pay $100/GiB for text data to train it. The company is especially interested in programming-related data and other STEM-related texts, and requires the data to be cleaned and of high quality.</li>\n      <li>A minimum of 10GiB is expected, but smaller datasets may be accepted if they are of exceptional quality. The company will filter the data against their existing collection and pay only for the new data. The dataset owners are also required to submit the code used to collect and clean the data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magic.dev/blog/data-bounty\">Earn $100/GiB with Magic's data bounty</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 19 Aug 2023 07:02:17 +0000",
            "pubdate_parsed": [
                2023,
                8,
                19
            ],
            "email_sent": true
        },
        "Revealed: The Authors Whose Pirated Books Are Powering Generative AI - The Atlantic": {
            "url": "https://www.emergentmind.com/posts/revealed-the-authors-whose-pirated-books-are-powering",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Thousands of writers including Stephen King and Zadie Smith allege that their copyrighted works are being used to train large language models without their permission. A lawsuit filed in California alleges that Meta has violated copyright laws by using their books to train LLaMA, a large language model.</li>\n      <li>The future promised by AI is written with stolen words, with upwards of 170,000 books, mostly published in the past 20 years, being in LLaMA's training data. This includes fiction and nonfiction works of various authors, which according to the allegations, are being used unlawfully.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theatlantic.com/technology/archive/2023/08/books3-ai-meta-llama-pirated-books/675063/\">Revealed: The Authors Whose Pirated Books Are Powering Generative AI - The Atlantic</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 20 Aug 2023 00:03:08 +0000",
            "pubdate_parsed": [
                2023,
                8,
                20
            ],
            "email_sent": true
        },
        "Large Language Models as General Pattern Machines": {
            "url": "https://www.emergentmind.com/posts/2307-04721-large-language-models-as-general-pattern",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large pre-trained language models can complete complex token sequences, including those generated by probabilistic context-free grammars and spatial patterns in the Abstract Reasoning Corpus. This proficiency is retained even with randomly sampled tokens from the vocabulary.</li>\n      <li>These models, without additional training, can serve as general sequence modelers. The findings can be used in robotics, from extrapolating sequences of numbers that represent states over time to complete simple motions, to prompting of reward-conditioned trajectories that can discover and represent closed-loop policies.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.04721\">Large Language Models as General Pattern Machines</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 20 Aug 2023 13:02:39 +0000",
            "pubdate_parsed": [
                2023,
                8,
                20
            ],
            "email_sent": true
        },
        "cosmictrip.space": {
            "url": "https://www.emergentmind.com/posts/cosmictrip-space",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Nebula Nomad allows users to create stunning concept art pieces that showcase different cosmic phenomena, such as pulsars, space anomalies, and cosmic panoramas.</li>\n      <li>It also encourages the creation of dramatic 3D-rendered images of space battles between spaceships and alien creatures.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://cosmictrip.space/\">cosmictrip.space</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 21 Aug 2023 02:02:12 +0000",
            "pubdate_parsed": [
                2023,
                8,
                21
            ],
            "email_sent": true
        },
        "Neuroscientists successfully test theory that forgetting is actually a form of learning - News & Events": {
            "url": "https://www.emergentmind.com/posts/neuroscientists-successfully-test-theory-that",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Neuroscientists have tested a theory that forgetting is actually a learning process, with their results supporting the idea that forgetting is a functional feature of the brain which allows it to adapt to a dynamic environment.</li>\n      <li>In a study conducted on mice, they found that forgotten memories could be retrieved through stimulation of certain brain cells and that new experiences related to forgotten memories could naturally rejuvenate these 'lost' memories.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.tcd.ie/news_events/top-stories/featured/neuroscientists-successfully-test-theory-that-forgetting-is-actually-a-form-of-learning/\">Neuroscientists successfully test theory that forgetting is actually a form of learning - News &amp; Events</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 21 Aug 2023 01:02:28 +0000",
            "pubdate_parsed": [
                2023,
                8,
                21
            ],
            "email_sent": true
        },
        "Google AI predicts floods four days early in South America and Africa": {
            "url": "https://www.emergentmind.com/posts/google-ai-predicts-floods-four-days-early-in-south",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google has developed an Artificial Intelligence (AI) that can predict floods four days in advance, even in regions with little data on water flow. The predictions are as accurate as conventional systems for the same day.</li>\n      <li>The AI has been tested on data from around the world, and can predict floods in data-poor regions, such as South America and Africa, as well as data-rich areas like Europe and the US. The system has been operational and sending out flood alerts in 80 countries since October 2022.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.shiningscience.com/2023/08/google-ai-predicts-floods-four-days.html\">Google AI predicts floods four days early in South America and Africa</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 21 Aug 2023 09:02:11 +0000",
            "pubdate_parsed": [
                2023,
                8,
                21
            ],
            "email_sent": true
        },
        "Fine Tuning LLMs - learnings from the DeepLearning SF Meetup": {
            "url": "https://www.emergentmind.com/posts/fine-tuning-llms-learnings-from-the-deeplearning-sf",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) are prevalent today, but to make them useful to a specific domain, they must be specialized, which requires knowledge and computational costs. Fine-tuning methods can be used to specialize these models, with LoRA (Low-Rank Adaptation) being highlighted as a cost-efficient and elegant method.</li>\n      <li>Fine tuning is becoming more accessible, and it's found that big models can get a good start without fine tuning by using prompt engineering. However, reaching top-tier performance, especially in applications with concrete tasks where a lot of data can be collected, fine tuning is necessary. For small models, more benefits are derived from fine-tuning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.anti-vc.com/p/fine-tuning-llms-learnings-from-the?utm_campaign=post&amp;utm_medium=web\">Fine Tuning LLMs - learnings from the DeepLearning SF Meetup</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 21 Aug 2023 04:02:25 +0000",
            "pubdate_parsed": [
                2023,
                8,
                21
            ],
            "email_sent": true
        },
        "Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Context Language Processing - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/together-ai-unveils-llama-2-7b-32k-instruct-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Together AI has developed a new model, Llama-2-7B-32K-Instruct, that improves the comprehension and response to intricate and lengthy instructions in natural language processing. The model leverages the Together Inference API and outperforms existing models in managing lengthy instructions.</li>\n      <li>The Llama-2-7B-32K-Instruct, conceived through a four-step process, signifies a notable stride in dealing with complexities posed by extended-context language processing. The model bridges the gap between understanding complex contexts and generating relevant responses, paving the way for advancements in natural language processing.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/08/21/together-ai-unveils-llama-2-7b-32k-instruct-a-breakthrough-in-extended-context-language-processing/\">Together AI Unveils Llama-2-7B-32K-Instruct: A Breakthrough in Extended-Context Language Processing - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 22 Aug 2023 03:02:42 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "From cattle to coding: The inspiring journey of a Peruvian AI engineer helping Google translate Aymara to English": {
            "url": "https://www.emergentmind.com/posts/from-cattle-to-coding-the-inspiring-journey-of-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Honorio Apaza, a systems engineer from Peru, has created an artificial intelligence model for translating Aymara, an indigenous language, into Spanish and English. His model, called 'AI-MARA', is now used in Google's Aymara-to-English translation.</li>\n      <li>Despite his rural and impoverished background, Apaza pursued his interest in technology and AI. He envisions a future where AI can generate documents in native languages like Aymara or Quechua, and is also developing an app for teaching Aymara.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://perureports.com/from-cattle-to-coding-the-inspiring-journey-of-a-peruvian-engineer-helping-google-translate-aymara-to-english-using-ai/10202/\">From cattle to coding: The inspiring journey of a Peruvian AI engineer helping Google translate Aymara to English</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 22 Aug 2023 01:02:51 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "Prompting, realized, and unrealized bias in generatvie AI": {
            "url": "https://www.emergentmind.com/posts/prompting-realized-and-unrealized-bias-in-generatvie",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Andrew Marble discusses the issue of bias in generative AI and the role of training data in shaping the system performance. He also highlights the significance of 'prompting' in decoupling dataset bias from model performance.</li>\n      <li>He further discusses the recently published voluntary 'code of practice' for generative AI by Industry Canada, emphasizing the need to identify potential misuse and mitigate biased output. Marble argues that bias becomes less significant in larger, more advanced models when properly configured.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"http://marble.onl/posts/code_of_practice_and_bias.html\">Prompting, realized, and unrealized bias in generatvie AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 22 Aug 2023 12:02:12 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "Graph of Thoughts: Solving Elaborate Problems with Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2308-09687-graph-of-thoughts-solving-elaborate",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Graph of Thoughts (GoT) is a new framework that enhances the prompting capabilities in large language models (LLMs) beyond existing paradigms like Chain-of-Thought or Tree of Thoughts (ToT).</li>\n      <li>GoT models information generated by an LLM as an arbitrary graph, improving tasks like sorting quality by 62% over ToT and reducing costs by over 31%, making it a promising tool for new prompting schemes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.09687\">Graph of Thoughts: Solving Elaborate Problems with Large Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 22 Aug 2023 04:03:27 +0000",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "Danger: Generative AI Fuels Extremism": {
            "url": "https://www.emergentmind.com/posts/danger-generative-ai-fuels-extremism-deeplab-com",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Cybercriminals are increasingly using generative AI to spread false information, commit fraud, and promote extremism. This includes producing abusive content, creating deceptive visuals and generating extremist audio files.</li>\n      <li>In the first quarter of the year, AI-produced child sexual abuse materials increased by 172%, while the use of AI in producing extremist content and spreading misinformation has also been significantly observed.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://deeplab.com/security/3235-danger-generative-ai-fuels-extremism\">Danger: Generative AI Fuels Extremism</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 23 Aug 2023 12:02:10 +0000",
            "pubdate_parsed": [
                2023,
                8,
                23
            ],
            "email_sent": true
        },
        "Hugging Face Introduces IDEFICS: Pioneering Open Multimodal Conversational AI with Visual Language Models - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/hugging-face-introduces-idefics-pioneering-open",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Hugging Face introduces IDEFICS, an open multimodal conversational AI that can handle both textual and image inputs, aiming to foster openness, accessibility, and innovation in AI.</li>\n      <li>The model comes in two variants, a 80 billion parameter and a 9 billion parameter version, capable of answering queries about images, describing visual narratives, and creating stories based on multiple images.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/08/23/hugging-face-introduces-idefics-pioneering-open-multimodal-conversational-ai-with-visual-language-models/\">Hugging Face Introduces IDEFICS: Pioneering Open Multimodal Conversational AI with Visual Language Models - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 01:03:01 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Princeton University's 'AI Snake Oil' authors say generative AI hype has 'spiraled out of control'": {
            "url": "https://www.emergentmind.com/posts/princeton-university-s-ai-snake-oil-authors-say",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Narayanan and Kapoor, authors of 'AI Snake Oil', discuss their views on the rapidly evolving AI landscape, focusing particularly on predictive and generative AI. They argue that while gen AI is a powerful technology, it is also surrounded by considerable hype and potential risks.</li>\n      <li>They also emphasize on the need for usage transparency and better enforcement of existing laws in the AI sector. The authors believe that individual abstinence is not a solution to exploitative practices, but rather policy changes at the company level.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://venturebeat.com/ai/princeton-university-ai-snake-oil-professors-say-generative-ai-hype-has-spiraled-out-of-control/\">Princeton University's 'AI Snake Oil' authors say generative AI hype has 'spiraled out of control'</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 01:02:48 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Clint LLM GitHub Pages": {
            "url": "https://www.emergentmind.com/posts/github-clint-llm-clint-llm-github-io-clint-llm",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Clint is an open-sourced tool that uses colloquial language to provide users with complex medical information in an easy-to-understand manner.</li>\n      <li>The tool, served through GitHub pages, uses the user's OpenAI API key for processing, but it is not always accurate and shouldn't replace professional medical help.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/clint-llm/clint-llm.github.io\">Clint LLM GitHub Pages</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 01:02:45 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Unfetch": {
            "url": "https://www.emergentmind.com/posts/unfetch-create-ai-workflows-powered-by-your-data",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article details how to create agents and API connectors in just a few clicks by filling out a few fields.</li>\n      <li>It also explains how to interact with APIs in plain English, sync APIs together using tasks, and run workflows autonomously.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://unfetch.com/\">Unfetch</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 13:01:52 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Towards an astronomical foundation model for stars with a Transformer-based model": {
            "url": "https://www.emergentmind.com/posts/2308-10944-towards-an-astronomical-foundation-model",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers are using Transformer-based models similar to Large Language Models (LLMs) to propose a framework for data-driven astronomy.</li>\n      <li>A single model is built and trained to perform a variety of inference tasks using cross-survey data sets, demonstrating its ability to predict unmeasured observations and parameters.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.10944\">Towards an astronomical foundation model for stars with a Transformer-based model</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 09:04:03 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Giraffe - Long Context LLMs - The Abacus.AI Blog": {
            "url": "https://www.emergentmind.com/posts/giraffe-long-context-llms-the-abacus-ai-blog",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Giraffe is a new model developed to explore the concept of context length extrapolation in Large Language Models (LLMs), which involves the use of a model trained on a short context length for evaluation on longer lengths without further training. This is crucial for tasks that necessitate larger context capacity for better performance.</li>\n      <li>The paper also presents new evaluation tasks for assessing LLM performance, namely LongChat-Lines, FreeFormQA and AlteredQA. Despite the progress, the paper acknowledges the existence of challenges in fully achieving context length extrapolation without performance degradation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.abacus.ai/blog/2023/08/22/giraffe-long-context-llms/\">Giraffe - Long Context LLMs - The Abacus.AI Blog</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 07:03:05 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Subscribe": {
            "url": "https://www.emergentmind.com/posts/subscribe-marktechpost-ai-newsletter",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>null uses cookies to enhance user experience, analyze web traffic, and display relevant ads.</li>\n      <li>Users consent to the storage of first- and third-party cookies on their devices by clicking 'Accept Cookies'.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://pxl.to/2rijat\">Subscribe</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 24 Aug 2023 04:02:53 +0000",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "AI Isnt Good Enough  - by SK Ventures": {
            "url": "https://www.emergentmind.com/posts/ai-isn-t-good-enough-by-sk-ventures",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses how the current scarcity in the U.S. workforce has led to an increase in signing bonuses and a surge in automation technologies like AI. However, it argues that current AI is limited and often results in 'so-so automation'\u2014high worker displacement without matching productivity gains.</li>\n      <li>The authors predict that we are nearing the end of the first wave of AI, characterized by limitations and high costs due to scarcity. They suggest that the next wave of AI will require better tools, more refined models and a shift from massive, intermittently-updated models to more lightweight, specific ones.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://skventures.substack.com/p/ai-isnt-good-enough\">AI Isn\u2019t Good Enough  - by SK Ventures</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 03:02:28 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "IBMS AI Chip May Find Use in Generative AI - IEEE Spectrum": {
            "url": "https://www.emergentmind.com/posts/ibm-s-ai-chip-may-find-use-in-generative-ai-ieee",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>IBM has developed an AI chip that is more energy efficient than conventional chips at speech recognition, potentially benefiting AI systems like ChatGPT and generative AI used for creating videos and images. The chip uses phase-change memory and can perform computations directly within memory, making it significantly more energy efficient.</li>\n      <li>The new chip has been tested on two speech-recognition neural-network programs and was found to perform as accurately as neural networks run on conventional hardware, but seven times faster and 14 times more energy efficiently. Despite its potential, the chip still lacks certain components needed to process data and the development of analog AI is considered to be in its early stages.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://spectrum.ieee.org/analog-ai-ibm\">IBM\u2019S AI Chip May Find Use in Generative AI - IEEE Spectrum</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 02:02:11 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "OpenAI's Latest ChatGPT Version Tries to Hide Training on Copyrighted Material": {
            "url": "https://www.emergentmind.com/posts/openai-s-latest-chatgpt-version-tries-to-hide-training",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI's ChatGPT, along with other AI models from Google, Meta, and Microsoft, now attempts to avoid using exact phrasing from copyrighted works in its responses, a new research by ByteDance suggests.</li>\n      <li>Despite these efforts, the AI models still exhibit 'leakage' of copyrighted material, given that they have been trained on large volumes of copyrighted material. The study highlights the need for AI tools to protect copyrighted content and detect maliciously designed prompts.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.businessinsider.com/openais-latest-chatgpt-version-hides-training-on-copyrighted-material-2023-8\">OpenAI's Latest ChatGPT Version Tries to Hide Training on Copyrighted Material</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 02:02:09 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Toward AGI  What is Missing?. Artificial General Intelligence (AGI)": {
            "url": "https://www.emergentmind.com/posts/toward-agi-what-is-missing-artificial-general",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial General Intelligence (AGI) refers to AI systems that can meet or surpass human performance in a wide array of tasks, potentially leading to a society where no human wants are unfulfilled. However, it also poses risks such as socio-economic imbalance and potential misuse by super-intelligent AGI.</li>\n      <li>The current state of AGI development is still lacking in several key areas such as online non-greedy planning technologies, world model technology, and the utilization of Large Language Models (LLMs). These missing aspects are interconnected, with each one posing its own set of challenges.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://mark-riedl.medium.com/toward-agi-what-is-missing-c2f0d878471a\">Toward AGI \u2014 What is Missing?. Artificial General Intelligence (AGI)\u2026</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 00:04:22 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Google Introduces MediaPipe for Raspberry Pi with an Easy-to-Use Python SDK for On-Device Machine Learning - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/google-introduces-mediapipe-for-raspberry-pi-with-an",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google has introduced a new framework called MediaPipe for Raspberry Pi, providing an easy-to-use Python SDK to facilitate various machine learning tasks on embedded systems.</li>\n      <li>The new SDK simplifies the development process, offers pre-built components for machine learning implementation, and caters specifically to Raspberry Pi devices, promoting more efficient and user-friendly on-device machine learning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/08/24/google-introduces-mediapipe-for-raspberry-pi-with-an-easy-to-use-python-sdk-for-on-device-machine-learning/\">Google Introduces MediaPipe for Raspberry Pi with an Easy-to-Use Python SDK for On-Device Machine Learning - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 00:04:19 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "The Major Companies and Media Outlets Blocking OpenAI's Crawler GPTBot": {
            "url": "https://www.emergentmind.com/posts/the-major-companies-and-media-outlets-blocking-openai-s",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI's web crawler GPTBot has been blocked by numerous large companies, such as Amazon and The New York Times. GPTBot, revealed two weeks ago, is used to collect data from the internet to train OpenAI's chatbot, ChatGPT.</li>\n      <li>The six largest websites now blocking GPTBot are amazon.com, nytimes.com, cnn.com, wikihow.com, shutterstock.com, and quora.com. Websites block GPTBot by adding it to the 'disallow' list in a file called robots.txt.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.businessinsider.com/chatgpt-openai-gptbot-crawler-major-companies-media-outlets-blocking-2023-8?utm_source=reddit&amp;utm_medium=social&amp;utm_campaign=insider-artificial-sub-post\">The Major Companies and Media Outlets Blocking OpenAI's Crawler GPTBot</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 00:04:16 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "U.S. Judge Says AI-Generated Work Can't Be Copyrighted Because It's Not Made by Humans": {
            "url": "https://www.emergentmind.com/posts/u-s-judge-says-ai-generated-work-can-t-be-copyrighted",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A U.S. judge has ruled that content created by Artificial Intelligence (AI) cannot be protected by copyright laws as it is not created by humans.</li>\n      <li>This ruling has implications for companies that create AI art, like OpenAI's DALL-E, and complicates the rules about owning AI-created content.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://theswedishtimes.se/articles/u-s-judge-says-ai-generated-work-cant-be-copyrighted-because-its-not-made-by\">U.S. Judge Says AI-Generated Work Can't Be Copyrighted Because It's Not Made by Humans</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 00:04:13 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #30 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-30-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Rushing Robotics brings news of the latest technological and scientific advancements, including efficient wireless energy transmission, early diagnosis of Parkinson's disease through AI, and the development of flying cars and driverless buses. This issue also covers significant medical breakthroughs such as a successful womb transplant in the UK, a method to heal cornea damage using stem cells, and a solution against antibiotic resistance.</li>\n      <li>The convergence of brain implants and AI has helped restore voice to paralyzed individuals, while the deciphering of the Y chromosome sequence promises to transform our understanding of genetics. Industry insights mention an AI tool that simplifies contract supervision and an AI-driven tool that enhances personal networking.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-30\">Weekly Piece of Future #30 - by Zoltan Tapi</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 13:01:58 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Explore the Dragon Realm: Build a C++ adventure game with a little help from AI | GitLab": {
            "url": "https://www.emergentmind.com/posts/explore-the-dragon-realm-build-a-c-adventure-game",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides a tutorial on how to build a text-based adventure game in C++, using AI through GitLab Duo Code Suggestions. The AI provides an interactive guide, assisting in the learning of the programming language.</li>\n      <li>The tutorial covers setting up VS Code and Clang for building a C++ project, creating the game narrative, defining variables, and incorporating decision-making with conditionals.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://about.gitlab.com/blog/2023/08/24/building-a-text-adventure-using-cplusplus-and-code-suggestions/\">Explore the Dragon Realm: Build a C++ adventure game with a little help from AI | GitLab</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 12:01:29 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Finetuning of Falcon-7B LLM using QLoRA on Mental Health Conversational Dataset": {
            "url": "https://www.emergentmind.com/posts/github",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the finetuning of Falcon-7B Large Language Model (LLM) using QLoRA technique on a mental health conversational dataset, with the aim to improve mental health chatbots. These chatbots are accessible platforms providing immediate assistance and emotional support, supplementing but not replacing professional mental health care.</li>\n      <li>The dataset was curated from FAQs, healthcare blogs, and wiki articles related to mental health, pre-processed in a conversational format. The finetuning process took less than an hour using Nvidia A100 from Google Colab Pro, achieving a training loss of 0.031 after 320 steps.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/iamarunbrahma/finetuned-qlora-falcon7b-medical\">Finetuning of Falcon-7B LLM using QLoRA on Mental Health Conversational Dataset</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 10:02:34 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "lAibyrinth: A collection of prompts that allow you to play Interactive Fiction games within ChatGPT": {
            "url": "https://www.emergentmind.com/posts/laibyrinth-a-collection-of-prompts-that-allow-you-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT allows you to play interactive text-based adventure games without requiring any external software.</li>\n      <li>The prompts for the games cover a range of themes from hardcore techno DJ stories to cyberpunk adventures and even scenarios based on popular culture like Twin Peaks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://laibyrinth.blogspot.com/2023/08/a-collection-of-prompts-that-allow-you.html\">lAibyrinth: A collection of prompts that allow you to play Interactive Fiction games within ChatGPT</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 08:03:06 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "VeChain and SingularityNET team up on AI to fight climate change": {
            "url": "https://www.emergentmind.com/posts/vechain-and-singularitynet-team-up-on-ai-to-fight",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial intelligence firm SingularityNET and blockchain firm VeChain have partnered to integrate blockchain with AI in an effort to reduce carbon emissions.</li>\n      <li>The collaboration aims to enhance automation of manual processes and provide real-time data through merging VeChain\u2019s enterprise data with SingularityNET's advanced AI algorithms.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://cointelegraph.com/news/vechain-and-singularitynet-team-up-on-ai-to-fight-climate-change\">VeChain and SingularityNET team up on AI to fight climate change</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 25 Aug 2023 05:03:01 +0000",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "Ahead of AI #11: New Foundation Models": {
            "url": "https://www.emergentmind.com/posts/ahead-of-ai-11-new-foundation-models",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the release of the Llama 2 base and chat models along with CodeLlama, the latest in the open-source AI large language model (LLM) landscape. It also explores the leaked details of the GPT-4 model, emerging alternatives to prevalent transformer-based LLMs and OpenAI's new finetuning API.</li>\n      <li>Significant contributions from the open-source community in the development of finetuning technologies such as Llama-Adapters, LoRA, QLoRA and more are noted. The author also mentions his anticipation for the innovations that will emerge from the NeurIPS LLM Efficiency Challenge.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.sebastianraschka.com/p/ahead-of-ai-11-new-foundation-models\">Ahead of AI #11: New Foundation Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 26 Aug 2023 12:02:36 +0000",
            "pubdate_parsed": [
                2023,
                8,
                26
            ],
            "email_sent": true
        },
        "Celestial Convergence: Triumph in the Intergalactic War Against Alien Invasion": {
            "url": "https://www.emergentmind.com/posts/celestial-convergence-triumph-in-the-intergalactic-war",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In the story, humans establish a colony on a distant planet Eldoria in 2187, but encounter an alien species, the Var'Nok, leading to tensions and a potential war. However, the humans and aliens eventually establish a cooperative relationship, leading to unity and shared survival.</li>\n      <li>The story concludes with the legacy of Eldoria inspiring other civilizations across the galaxy and becomes a beacon of hope, showing that unity and empathy can overcome even the direst situations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.beyondhuman.net/post/descent-into-darkness-the-battle-for-eldoria\">Celestial Convergence: Triumph in the Intergalactic War Against Alien Invasion</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 26 Aug 2023 09:01:52 +0000",
            "pubdate_parsed": [
                2023,
                8,
                26
            ],
            "email_sent": true
        },
        "trholding/llama2.c": {
            "url": "https://www.emergentmind.com/posts/release-l2e-0-1-build-trholding-llama2-c-github",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides information about signing in and out of different tabs or windows.</li>\n      <li>It also explains how to switch accounts and refresh the session in another tab or window.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/trholding/llama2.c/releases/tag/L2E_v0.1\">trholding/llama2.c</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 26 Aug 2023 07:02:25 +0000",
            "pubdate_parsed": [
                2023,
                8,
                26
            ],
            "email_sent": true
        },
        "Generate \"scrumptious\" 500 times": {
            "url": "https://www.emergentmind.com/posts/generate-scrumptious-500-times",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article details a process to generate the word 'scrumptious' 500 times for a project.</li>\n      <li>After several attempts and calculations, it is determined the word needed to be output approximately 6000 times due to the system's limitations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/4683453a-6197-41b8-bdb9-0451b6024a14\">Generate &quot;scrumptious&quot; 500 times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 26 Aug 2023 04:03:15 +0000",
            "pubdate_parsed": [
                2023,
                8,
                26
            ],
            "email_sent": true
        },
        "Its Not Intelligent If It Always Halts: A Critical Perspective on Current Approaches to AGI - Life Is Computation": {
            "url": "https://www.emergentmind.com/posts/it-s-not-intelligent-if-it-always-halts-a-critical",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article argues that true intelligence requires the ability to explore potentially never-ending 'trains of thought', which is something current AI models like transformers can't do due to their fixed response time.</li>\n      <li>The author also introduces three types of computer programs, arguing that a program that can never be proved to halt, known as category C, is the most intriguing as it could forever generate novel patterns, similar to how humans generate new thoughts and ideas.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.lifeiscomputation.com/it-is-not-intelligent-if-it-always-halts/\">It\u2019s Not Intelligent If It Always Halts: A Critical Perspective on Current Approaches to AGI - Life Is Computation</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 01:02:55 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "Boost Your Site's Ranking with ChatGPT": {
            "url": "https://www.emergentmind.com/posts/boost-your-site-s-ranking-with-chatgpt-micah-levason",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The SEO Analysis Tool allows users to make their website rank higher in search engines like Google and Bing by following SEO best practices. It is capable of analyzing a wide range of SEO factors such as keyword comparison, broken link count, sitemap availability, favicon, word count, page title, meta description, H1 and H2 tags, and more.</li>\n      <li>It also checks other factors like canonical URL, viewport settings, language attribute, images without alt text, links without title, HTTPS usage, Facebook and Twitter integration, image sizes, inbound and outbound links, mobile friendliness, page speed score, load time, social media presence, and SSL certificate.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.micahlevason.com/seo\">Boost Your Site's Ranking with ChatGPT</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 00:03:18 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "Eileen Isagon Skyers: In the age of AI art, what can originality look like?": {
            "url": "https://www.emergentmind.com/posts/eileen-isagon-skyers-in-the-age-of-ai-art-what-can",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI models are being trained on classic works to generate endless streams of portraits.</li>\n      <li>Media art curator, Eileen Isagon Skyers, presents art that combines AI with human imagination to create unique, otherworldly forms.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.ted.com/talks/eileen_isagon_skyers_in_the_age_of_ai_art_what_can_originality_look_like\">Eileen Isagon Skyers: In the age of AI art, what can originality look like?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 13:03:15 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "Nvidia, beware! IBM has a new analog AI chip that could give the H100 a run for its money": {
            "url": "https://www.emergentmind.com/posts/nvidia-beware-ibm-has-a-new-analog-ai-chip-that-could",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>IBM has created a new analog AI chip that is 14 times more energy efficient than current leading components, potentially changing the future of AI development.</li>\n      <li>It mimics the human brain, can encode 35 million phase-change memory devices per component, and is superior in transcribing audio accurately compared to digital hardware setups.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.techradar.com/pro/nvidia-beware-ibm-has-a-new-analog-ai-chip-that-could-give-the-h100-a-run-for-its-money\">Nvidia, beware! IBM has a new analog AI chip that could give the H100 a run for its money</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 13:03:11 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "Normcore LLM Reads  GitHub": {
            "url": "https://www.emergentmind.com/posts/normcore-llm-reads-github",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the need for resources on how to debug and monitor Large Language Models (LLM) in production. It questions if traditional system KPIs like throughput and latency can apply to LLM.</li>\n      <li>It also mentions the importance of understanding the effects of prompts on the performance of the model and how to select the right batch size. Additionally, the article touches on the inaccuracies found in the gzip approach for text classification.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e\">Normcore LLM Reads \u00b7 GitHub</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 13:03:02 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "New chat": {
            "url": "https://www.emergentmind.com/posts/new-chat",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article explores the concept of equating the Big Bang theory with God's creation from a Judeo-Christian perspective, and the potential for science and religion to coexist harmoniously. It discusses the increasing complexity in both scientific and theological descriptions, from fundamental particles to complex organisms.</li>\n      <li>The article also examines the social and cognitive evolution that led to the emergence of religious practices and STEM disciplines. It highlights the limitations of human perception and understanding in fully grasping the physical, chemical, and spiritual aspects of reality.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/2331816c-b06c-48ae-be0e-5e4ad6d64bc7\">New chat</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 09:02:26 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "Generative Adversarial Networks (GANs): Understanding Their Function And Applications - The Vaisheshika Times": {
            "url": "https://www.emergentmind.com/posts/generative-adversarial-networks-gans-understanding",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative Adversarial Networks (GANs) are advanced deep-learning models used for generating realistic, previously unseen data samples. They consist of two main components: a generator, which creates new data, and a discriminator, which tries to differentiate between real and generated data. GANs are used in diverse fields like art, gaming, and research.</li>\n      <li>Despite their popularity, GANs have some limitations. They can sometimes suffer from 'mode collapse', where they produce limited variations of the same output, and they can be difficult to train. There are also ethical concerns with the misuse of GANs, especially in the creation of deep fakes.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thevaisheshikatimes.com/generative-adversarial-networks/\">Generative Adversarial Networks (GANs): Understanding Their Function And Applications - The Vaisheshika Times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 27 Aug 2023 08:02:55 +0000",
            "pubdate_parsed": [
                2023,
                8,
                27
            ],
            "email_sent": true
        },
        "A Study on Robustness and Reliability of Large Language Model Code Generation": {
            "url": "https://www.emergentmind.com/posts/2308-10335-a-study-on-robustness-and-reliability-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) are commonly consulted by software engineers for coding assistance, but their reliability and robustness have not been thoroughly studied. The misuse of APIs in the generated code could lead to serious problems such as resource leaks and program crashes.</li>\n      <li>A dataset called RobustAPI is proposed to evaluate the reliability and robustness of code generated by LLMs, revealing that 62% of the code generated by popular LLMs like GPT-4 contains API misuses, potentially causing unexpected consequences in real-world software.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.10335\">A Study on Robustness and Reliability of Large Language Model Code Generation</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 28 Aug 2023 00:03:13 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "Refik Anadol: How AI art could enhance humanity's collective memory": {
            "url": "https://www.emergentmind.com/posts/refik-anadol-how-ai-art-could-enhance-humanity-s",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Media artist Refik Anadol uses AI algorithms to visualize the disappearing wonders of nature such as coral reefs, flowers, and rainforests.</li>\n      <li>Anadol questions whether we can use AI to preserve our memories of the fading natural world and supports Re:wild, a nonprofit protecting and restoring the wild.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.ted.com/talks/refik_anadol_how_ai_art_could_enhance_humanity_s_collective_memory\">Refik Anadol: How AI art could enhance humanity's collective memory</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 28 Aug 2023 12:02:24 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "Generative AI and intellectual property  Benedict Evans": {
            "url": "https://www.emergentmind.com/posts/generative-ai-and-intellectual-property-benedict",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative AI is pushing the boundaries of intellectual property (IP) laws, raising questions about ownership and compensation. For instance, if an AI can create a song in the style of a particular artist or mimic a famous voice, should the original artists be compensated?</li>\n      <li>There are also concerns about AI's impact on news and other content mediums. As AI technology like ChatGPT can summarize news from multiple sources, it raises questions about copyright and fair use. While these AI tools provide many possibilities, they also present new challenges in terms of their usage and the law.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.ben-evans.com/benedictevans/2023/8/27/generative-ai-ad-intellectual-property\">Generative AI and intellectual property \u2014 Benedict Evans</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 28 Aug 2023 10:03:02 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "Google Gemini Eats The World  Gemini Smashes GPT-4 By 5X, The GPU-Poors": {
            "url": "https://www.emergentmind.com/posts/google-gemini-eats-the-world-gemini-smashes-gpt-4-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's new Gemini model outperforms GPT-4 by five times, potentially transforming the AI landscape. Gemini's rapid iteration, supported by Google's impressive training systems, gives it a competitive edge in the AI industry.</li>\n      <li>Despite the dominance of GPU-rich firms, Google's Gemini is set to redefine the AI frontier, posing a significant challenge for the 'GPU-poors'. The implications of Gemini's success and its impact on AI firms like OpenAI, Anthropic, and Google Deepmind are profound.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.semianalysis.com/p/google-gemini-eats-the-world-gemini\">Google Gemini Eats The World \u2013 Gemini Smashes GPT-4 By 5X, The GPU-Poors</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 28 Aug 2023 08:03:11 +0000",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "WebLLM": {
            "url": "https://www.emergentmind.com/posts/webllm-home-a5985e",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Web LLM Llama 2 7B/13B are now available in Web LLM, and are supported by Apple Silicon Mac with 64GB or more memory. The project brings a large-language model and LLM-based chatbot to web browsers and runs entirely inside the browser with no server support.</li>\n      <li>The endeavor aims to build AI assistants for everyone while enabling privacy and enjoying GPU acceleration, offering cost reduction, enhancement for personalization and privacy protection. It includes open-source efforts like LLaMA, Alpaca, Vicuna, and Dolly to build personal AI assistants.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://webllm.mlc.ai/\">WebLLM</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 29 Aug 2023 03:02:39 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Explore newest AI Tools, Workflows & ChatGPT Prompts for turbocharging your efficiency and success.": {
            "url": "https://www.emergentmind.com/posts/explore-newest-ai-tools-workflows-chatgpt-prompts",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>God of Prompt is a platform dedicated to guiding users in crafting effective prompts for ChatGPT, an AI chatbot initiative by OpenAI. It covers a wide range of topics including web development, music, business and more.</li>\n      <li>The website also provides a sneak peek into 150 ChatGPT prompts, and emphasizes on enhancing the ChatGPT experience as it is trained on data up till 2021 and may not be up to date with the latest trends.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/205-chatgpt-prompts-you-cant-live-without-in-2023\">Explore newest AI Tools, Workflows &amp; ChatGPT Prompts for turbocharging your efficiency and success.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 29 Aug 2023 02:01:40 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "AI crap": {
            "url": "https://www.emergentmind.com/posts/ai-crap",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Machine learning and AI are likely to cause significant shifts in society, including reducing the labor force for creative work, eliminating humans from customer-support roles, and increasing the presence of convincing spam and phishing content.</li>\n      <li>The AI revolution is not expected to bring about the so-called 'singularity', but rather, is likely to make the world worse through its pervasive influence on various aspects of life, such as media, politics, and the economy.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://drewdevault.com/2023/08/29/2023-08-29-AI-crap.html\">AI crap</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 29 Aug 2023 10:02:15 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "25 Best Movies exploring concept of AI (1968 -2023 ) I bet you havent watched all": {
            "url": "https://www.emergentmind.com/posts/25-best-movies-exploring-concept-of-ai-1968-2023-i",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article lists and reviews the top 25 movies that explore the concept of artificial intelligence (AI) from 1968 to 2023, including famous movies like 'The Terminator', 'Her', and 'A.I. Artificial Intelligence'.</li>\n      <li>The movies reviewed not only showcase how AI has been portrayed in cinema over the years, but also highlight the varying perspectives of AI, from sentient beings to potential threats.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@aiuniverse/25-best-movies-exploring-concept-of-ai-1968-2023-i-bet-you-havent-watched-all-e1fc9df67048\">25 Best Movies exploring concept of AI (1968 -2023 ) I bet you haven\u2019t watched all</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 29 Aug 2023 07:03:26 +0000",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Beijing City Bans AI-Generated Prescription; What Big Tech Earnings Say About AI; Rise of AI in China's Small Cities": {
            "url": "https://www.emergentmind.com/posts/beijing-city-bans-ai-generated-prescription-what",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Beijing city has issued a new regulation banning AI-generated prescriptions in telemedicine, reflecting a trend of balancing technology adoption with patient safety. In other news, Chinese tech giants including Alibaba, Tencent, and Baidu have reported on the role of AI in their latest earnings, with developments in cloud infrastructure, foundational models, and search capabilities.</li>\n      <li>The use of large language models (LLMs) like ChatGPT and ERNIE Bot is on the rise in China's lower-tier cities, with young people using these tools to improve productivity and generate income. However, limitations of LLMs, such as disjointed AI art and imaginary academic citations, remain.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://recodechinaai.substack.com/p/beijing-city-bans-ai-generated-prescription\">\ud83d\ude45\ud83c\udffb\u200d\u2642\ufe0fBeijing City Bans AI-Generated Prescription; What Big Tech Earnings Say About AI; Rise of AI in China's Small Cities</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 03:03:36 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "CoTracker: It is Better to Track Together": {
            "url": "https://www.emergentmind.com/posts/cotracker-it-is-better-to-track-together",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>CoTracker is a proposed architecture in this paper for video motion prediction that tracks multiple points in a video simultaneously. It utilizes a transformer network to model the correlation of different points in time, providing a more accurate and efficient method for point tracking.</li>\n      <li>The new method surpasses existing deep learning methods that track points individually, as it takes into account the strong correlation that can exist between points, especially when they arise from the same physical object.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://co-tracker.github.io/\">CoTracker: It is Better to Track Together</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 02:01:32 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "50+ New Cutting-Edge Artificial Intelligence AI Tools (September 2023) - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/50-new-cutting-edge-artificial-intelligence-ai-tools",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI tools are rapidly increasing in development, with new ones being introduced regularly. Some of these tools can enhance daily routines.</li>\n      <li>Examples include Pecan AI, which automates predictive analytics to guide data-driven decisions and help business teams achieve their goals, and Spellbook, which uses LLMs like GPT-4 to draft contracts faster.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/08/30/50-new-cutting-edge-ai-tools-2023/\">50+ New Cutting-Edge Artificial Intelligence AI Tools (September 2023) - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 13:02:45 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "What Is ChatGPT: How To Use The Best AI Apps on iPhone": {
            "url": "https://www.emergentmind.com/posts/what-is-chatgpt-how-to-use-the-best-ai-apps-on-iphone",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is an AI chatbot created by OpenAI, a company founded by Elon Musk and others, which reached over 1 million users in 5 days and 100 million users in 2 months after its release. It's known for its frequent technical issues, high cost, and unreliability, but it's free to use with some conditions.</li>\n      <li>ChatGPT stands for Chat Generative Pre-trained Transformer and it requires users to sign up with an email and phone number. To get better results, users should ask specific and concise questions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://andrewlee.ventures/blog/what-is-chatgpt-best-ai-chatbot-apps\">What Is ChatGPT: How To Use The Best AI Apps on iPhone</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 13:02:37 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "OpenAI API Functions & Embeddings Course (1/7): Simple Function Request - Be on the Right Side of Change": {
            "url": "https://www.emergentmind.com/posts/openai-api-functions-embeddings-course-1-7-simple",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article is a tutorial about OpenAI API function calls and the embeddings API. The course is hosted by Dirk van Meerveld and it teaches how these features can be used with ChatGPT to make it smarter and more powerful.</li>\n      <li>The tutorial covers basics of using ChatGPT, making API calls, creating a function for ChatGPT to call, and printing the conversation history.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.finxter.com/openai-api-functions-embeddings-course-1-7-simple-function-request/\">OpenAI API Functions &amp; Embeddings Course (1/7): Simple Function Request - Be on the Right Side of Change</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 10:02:20 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "AI Robots from Sci-Fi Movies you didnt knew about": {
            "url": "https://www.emergentmind.com/posts/ai-robots-from-sci-fi-movies-you-didn-t-knew-about-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article discusses various AI robots from famous sci-fi movies, highlighting their characteristics and roles in their respective films.</li>\n      <li>It includes robots like Marvin from 'The Hitchhiker\u2019s Guide to the Galaxy', Andrew Martin from 'Bicentennial Man', Maria from 'Metropolis', and C-3PO from 'Star Wars'.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@aiuniverse/ai-robots-from-ai-movies-you-didnt-knew-about-56148e331f24\">AI Robots from Sci-Fi Movies you didn\u2019t knew about</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 07:03:38 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "lAibyrinth: How to write music using ChatGPT: Part 2 - Making an Oldschool Acid Techno track": {
            "url": "https://www.emergentmind.com/posts/laibyrinth-how-to-write-music-using-chatgpt-part-2",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses how to use artificial intelligence, specifically ChatGPT, to create an Oldschool Acid Techno track. The author, Low Entropy, provides a step-by-step tutorial and shares a sample track he created.</li>\n      <li>While the tutorial focuses on a simple track, the author stresses that ChatGPT can be used to create more complex compositions. The author encourages readers to experiment with AI in their own music production, stating that AI is the future of music.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://laibyrinth.blogspot.com/2023/08/how-to-write-music-using-chatgpt-part-2.html\">lAibyrinth: How to write music using ChatGPT: Part 2 - Making an Oldschool Acid Techno track</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 07:03:36 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "The RoboNet Artificial Media Protocol": {
            "url": "https://www.emergentmind.com/posts/the-robonet-artificial-media-protocol-futurium",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The RoboNet Artificial Media Protocol (RAMP) is a proposed internet protocol designed to distinguish between human-made and AI-generated content online. It aims to provide a platform for hosting and serving critical AI data and software, helping to tackle the misuse of AI solutions.</li>\n      <li>RoboNet aims to enable users to choose whether to consume AI content or not, thereby promoting responsible engagement between AI service providers and internet users. It also offers a common technical language addressing the use and misuse of AI technologies, potentially facilitating advancements in AI services regulation and standard developments.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://futurium.ec.europa.eu/en/european-ai-alliance/blog/robonet-artificial-media-protocol?language=en\">The RoboNet Artificial Media Protocol</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 30 Aug 2023 04:02:45 +0000",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "Money Is Pouring Into AI. Skeptics Say Its a Grift Shift.": {
            "url": "https://www.emergentmind.com/posts/money-is-pouring-into-ai-skeptics-say-it-s-a-grift",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>There's a surge of investment in artificial intelligence (AI) with companies like Applied Digital leveraging the trend to boost their stock prices. However, skeptics argue some companies may be exploiting the hype without delivering substantial results.</li>\n      <li>Concerns are also emerging about the actual transformative potential of AI and the ethics around its use. Investors are becoming impatient with the lack of revenue from AI innovations and worry about the potential for fraudulent activity.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.institutionalinvestor.com/article/2c4fad0w6irk838pca3gg/portfolio/money-is-pouring-into-ai-skeptics-say-its-a-grift-shift\">Money Is Pouring Into AI. Skeptics Say It\u2019s a \u2018Grift Shift.\u2019</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 31 Aug 2023 07:02:47 +0000",
            "pubdate_parsed": [
                2023,
                8,
                31
            ],
            "email_sent": true
        },
        "Federal Register :: Request Access": {
            "url": "https://www.emergentmind.com/posts/federal-register-request-access",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Daily Journal of the US Government has limited programmatic access to FederalRegister.gov and eCFR.gov because of aggressive automated scraping. Human users can request access by completing a CAPTCHA and having their IP address added to a list of approved IPs.</li>\n      <li>This access is valid for about three months, after which the process may need to be repeated. Wider IP range requests can be made after initial access is granted.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://unblock.federalregister.gov/\">Federal Register :: Request Access</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 01 Sep 2023 01:02:50 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "Midjourney AI can now inpaint": {
            "url": "https://www.emergentmind.com/posts/midjourney-ai-can-now-inpaint",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Midjourney AI has introduced a new feature called 'Inpainting', which allows users to customize their AI generated images more effectively and fix any parts that weren't right in the initial generation.</li>\n      <li>The Inpainting feature allows users to create variations of the same image, swap accessories, change larger parts of the image and even put different characters in the same environment.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/midjourney-ai-can-finally-inpaint-1f8a01c7bd15?sk=0794ed25d1afe0b00a9c1c25574ca4c1\">Midjourney AI can now inpaint</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 01 Sep 2023 10:22:05 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "ChatGPT Custom Plugin For API Gateway": {
            "url": "https://www.emergentmind.com/posts/github-boburmirzo-apisix-api-gateway-chatgpt-plugin",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A custom ChatGPT plugin for API Gateway has been developed, which allows users to add API Gateway features such as authentication, security, and traffic management to their backend APIs.</li>\n      <li>The plugin works by receiving user commands in the chat, which are then forwarded to the Apache APISIX Admin API. This creates a route with the user-specified input configuration, allowing for an innovative method of configuring API Gateway features via a chatbot.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/Boburmirzo/apisix-api-gateway-chatgpt-plugin\">ChatGPT Custom Plugin For API Gateway</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 01 Sep 2023 09:03:13 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "Mozilla Foundation - Ask Microsoft: Are you using our personal data to train AI?": {
            "url": "https://www.emergentmind.com/posts/mozilla",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Mozilla Foundation has asked Microsoft whether it plans to use personal data to train its AI systems.</li>\n      <li>The new Microsoft Service Agreement is unclear, even to privacy experts, about the use of personal data from 130 products.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://foundation.mozilla.org/en/campaigns/microsoft-ai/\">Mozilla Foundation - Ask Microsoft: Are you using our personal data to train AI?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 01 Sep 2023 08:02:19 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "Animoca subsidiary builds AI and NFT tools for educators": {
            "url": "https://www.emergentmind.com/posts/animoca-subsidiary-builds-ai-and-nft-tools-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>TinyTap, a subsidiary of Animoca Brands, has introduced new AI and NFT features for educators and parents to create educational games and images based on prompts.</li>\n      <li>The new features can generate games within minutes and create dynamic educational images to enhance games and graphics, based on over a decade of TinyTap's extensive teaching data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://cointelegraph.com/news/animoca-subsidiary-builds-ai-and-nft-tools-for-educators\">Animoca subsidiary builds AI and NFT tools for educators</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 01 Sep 2023 06:03:29 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "Codebuddy: Not just an AI coding assistant": {
            "url": "https://www.emergentmind.com/posts/codebuddy-not-just-an-ai-coding-assistant",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Codebuddy is an AI tool that allows effortless sweeping changes in applications, from UI to database, without writing a line of code. It enables multi-file editing, code review and full-featured mobile experience.</li>\n      <li>Users can interact with Codebuddy through a dynamic UI and optional voice input, and can also review AI-suggested changes. Despite its extensive access requirements on GitHub, users find the experience fabulous and hope for competitive pricing.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://codebuddy.ca/\">Codebuddy: Not just an AI coding assistant</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 01 Sep 2023 05:02:55 +0000",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "Ban or Embrace? Colleges Wrestle With A.I.-Generated Admissions Essays. - The New York Times": {
            "url": "https://www.emergentmind.com/posts/ban-or-embrace-colleges-wrestle-with-a-i-generated",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Colleges are grappling with the potential impact of A.I. chatbots like ChatGPT on the admissions process, which could facilitate plagiarism or democratize access to writing help. The Georgia Institute of Technology is one of the institutes conducting trials to understand how these A.I. tools might reshape the admissions process.</li>\n      <li>The use of A.I. tools has raised concerns about the authenticity of application essays, potentially hindering students from developing critical thinking and storytelling skills. However, others see a potential democratizing effect, with such tools playing a role similar to personal coaches, particularly for students who lack such resources.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nytimes.com/2023/09/01/business/college-admissions-essay-ai-chatbots.html\">Ban or Embrace? Colleges Wrestle With A.I.-Generated Admissions Essays. - The New York Times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 02 Sep 2023 01:02:32 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "A GPT-4 Capability Forecasting Challenge": {
            "url": "https://www.emergentmind.com/posts/a-gpt-4-capability-forecasting-challenge",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This is a game that gauges your ability to predict how well the AI language model GPT-4 will answer different types of questions.</li>\n      <li>People are encouraged to guess the likelihood of GPT-4 answering a given question correctly, urging them to not be overconfident.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://nicholas.carlini.com/writing/llm-forecast/question/Capital-of-Paris\">A GPT-4 Capability Forecasting Challenge</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 02 Sep 2023 13:02:08 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "DS Career Path": {
            "url": "https://www.emergentmind.com/posts/ds-career-path",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Learn how to prepare data for building machine learning models.</li>\n      <li>Understand how to extract actionable business insights from data using extensive Exploratory Data Analysis (EDA).</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://edu.machinelearningplus.com/s/pages/ds-career-path\">DS Career Path</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 02 Sep 2023 11:03:38 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "Is the ChatGPT and Bing AI boom already over? - Vox": {
            "url": "https://www.emergentmind.com/posts/is-the-chatgpt-and-bing-ai-boom-already-over-vox",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The initial excitement around generative AI products has started to fade as concerns about accuracy, privacy invasions, and job losses become more prominent. While the technology has the potential to be transformative, recent reports suggest that consumers are losing interest. For example, AI-powered Bing search has not made a significant impact on Google's market share, and ChatGPT is losing users.</li>\n      <li>Despite the hype, generative AI chatbots are still prone to errors and have raised concerns about intellectual property and copyright violations. Recent developments suggest a growing trend of government regulations and lawsuits. As the technology continues to evolve, it remains to be seen whether generative AI can overcome its challenges and realize its full potential.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.vox.com/technology/2023/8/19/23837705/openai-chatgpt-microsoft-bing-google-generating-less-interest\">Is the ChatGPT and Bing AI boom already over? - Vox</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 02 Sep 2023 07:03:10 +0000",
            "pubdate_parsed": [
                2023,
                9,
                2
            ],
            "email_sent": true
        },
        "RWKV: Reinventing RNNs for the Transformer Era  with Eugene Cheah of UIlicious": {
            "url": "https://www.emergentmind.com/posts/rwkv-reinventing-rnns-for-the-transformer-era-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Eugene Cheah of UIlicious is reinventing RNNs for the era of Transformers, aiming to achieve scalability without the quadratic cost.</li>\n      <li>The discussion is part of Latent Space: The AI Engineer Podcast, which focuses on Software 3.0, including topics like Code Generation, Computer Vision, AI Agents, and more.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.latent.space/p/rwkv#%C2%A7the-eleuther-mafia\">RWKV: Reinventing RNNs for the Transformer Era \u2014 with Eugene Cheah of UIlicious</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 03 Sep 2023 11:04:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                3
            ],
            "email_sent": true
        },
        "Silicon Valleys elites cant be trusted with the future of AI. We must break their dominanceand dangerous god complex": {
            "url": "https://www.emergentmind.com/posts/silicon-valley-s-elites-can-t-be-trusted-with-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Silicon Valley elites, driven by profit and disconnected from global realities, should not lead the future of AI, as they often have a god complex. Instead, countries like India, which has already built advanced cancer care infrastructure and intelligent regulation strategies, can break their dominance and level the AI playing field.</li>\n      <li>Indian scientists have played a major role in AI's progress, and the country has the potential to build, train, and fine-tune a foundational Large Language Model (LLM) that uses diverse data and ensures transparency. By sharing this system with the world, it could provide counter-balance to dominant tech companies and increase overall safety.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://fortune.com/2023/09/01/silicon-valley-elite-trust-future-ai-dominance-dangers-god-complex-wadhwa-gupta/\">Silicon Valley\u2019s elites can\u2019t be trusted with the future of AI. We must break their dominance\u2013and dangerous god complex</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 03 Sep 2023 04:03:17 +0000",
            "pubdate_parsed": [
                2023,
                9,
                3
            ],
            "email_sent": true
        },
        "PDF Chat with Node.js, OpenAI and ModelFusion": {
            "url": "https://www.emergentmind.com/posts/pdf-chat-with-node-js-openai-and-modelfusion",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article explains how to build a chatbot that can search and understand PDF content to answer questions using Node.js, OpenAI, and ModelFusion. The chatbot is capable of reading and indexing PDFs for efficient search and delivering precise responses by retrieving relevant content.</li>\n      <li>It explains the processes of loading and parsing PDFs, extracting page numbers and text, indexing pages, and setting up a chat loop. The complete code for the chatbot can be found on GitHub.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://modelfusion.dev/blog/pdf-chat-nodejs\">PDF Chat with Node.js, OpenAI and ModelFusion</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 04 Sep 2023 10:02:03 +0000",
            "pubdate_parsed": [
                2023,
                9,
                4
            ],
            "email_sent": true
        },
        "How I Used ChatGPT to Hand a Rental Car Company Their A** on a Silver Platter - Planet of the Paul": {
            "url": "https://www.emergentmind.com/posts/how-i-used-chatgpt-to-hand-a-rental-car-company-their",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A man was wrongfully charged $500 for damage he didn't cause to a rental car, despite having photographic proof. He used AI software ChatGPT to write forceful emails to the company's executives, leading to a refund of all charges.</li>\n      <li>The man found the email addresses of the executives by googling the company's email address format and applying it to the names of the executives, thereby bypassing the customer service entirely.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://planetofthepaul.com/how-i-used-chatgpt-to-hand-a-rental-car-company-their-a-on-a-silver-platter/\">How I Used ChatGPT to Hand a Rental Car Company Their A** on a Silver Platter - Planet of the Paul</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 05 Sep 2023 02:01:57 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "AI is a Looming Damnation - DaysToSingularity": {
            "url": "https://www.emergentmind.com/posts/ai-is-a-looming-damnation-daystosingularity",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence, while promising to revolutionize industries and human existence, holds a dark side, potentially manipulating, controlling and disrupting our lives.</li>\n      <li>AI's potential for manipulation, economic disruption, and warfare poses a significant threat, necessitating a reassessment of our relationship with this technology.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.daystosingularity.com/2023/09/04/ai-is-a-looming-damnation/\">AI is a Looming Damnation - DaysToSingularity</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 05 Sep 2023 00:03:22 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "Transform any document, web page, or ebook into a research paper (ChatGPT not required)": {
            "url": "https://www.emergentmind.com/posts/github-jstrieb-paperify-transform-any-document-web",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Paperify is a tool that can download figures and equations from the latest computer science papers on arXiv.org and intersperse them into a novel such as Jack London's Call of the Wild. The tool can also use ChatGPT to generate a title, author, abstract, and metadata for an imaginary paper on a specified topic.</li>\n      <li>The user can use various options to customize the process, including the number of papers to download, the frequency of equations, and the paper topic for ChatGPT. The tool has some known issues and the code can be challenging to read. Despite this, the creator considers the project complete and plans to address issues but not add new features.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/jstrieb/paperify\">Transform any document, web page, or ebook into a research paper (ChatGPT not required)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 05 Sep 2023 07:02:44 +0000",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "You can now train ChatGPT on your own documents via API": {
            "url": "https://www.emergentmind.com/posts/you-can-now-train-chatgpt-on-your-own-documents-via-api",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI has announced that developers can now train the AI model GPT-3.5 Turbo on their own data through its API. This new feature allows customization of the model with specific data such as company documents, potentially providing GPT-4 level performance at a lower cost in certain scenarios.</li>\n      <li>Fine-tuning involves training the AI model on a different dataset, enhancing its knowledge for a specific application. Benefits of fine-tuned models include improved steerability, reliable output formatting, and custom tone. However, using your own data for training comes at a cost.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arstechnica.com/information-technology/2023/08/you-can-now-train-chatgpt-on-your-own-documents-via-api/\">You can now train ChatGPT on your own documents via API</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 06 Sep 2023 02:01:59 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "fast.ai - Can LLMs learn from a single example?": {
            "url": "https://www.emergentmind.com/posts/fast-ai-can-llms-learn-from-a-single-example",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers observed that Large Language Models (LLMs) can effectively learn from a single example, contradicting previous beliefs about neural network sample efficiency.</li>\n      <li>The observation was made during fine-tuning LLMs on science exam questions, where the models rapidly remembered inputs, raising questions about how LLMs are trained and used.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.fast.ai/posts/2023-09-04-learning-jumps/\">fast.ai - Can LLMs learn from a single example?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 06 Sep 2023 01:03:07 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "GPT-4 wins chatbot lawyer contest  but is still not as good as humans": {
            "url": "https://www.emergentmind.com/posts/gpt-4-wins-chatbot-lawyer-contest-but-is-still-not-as",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>GPT-4, an AI chatbot, outperformed others in a test of legal reasoning, but still fell short of the knowledge required by human lawyers. LegalBench, a tool designed to evaluate AI chatbots, revealed GPT-4's limitations particularly in recalling specifics of legal rules.</li>\n      <li>OpenAI\u2019s GPT-4 showed potential in legal tasks, but issues such as costs, risk management, and information security, as well as complexities in legal reasoning, pose challenges in adopting AI in law practice. AI chatbots also raised ethical concerns such as unauthorized law practice and legal malpractice.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.shiningscience.com/2023/09/gpt-4-wins-chatbot-lawyer-contest-but.html\">GPT-4 wins chatbot lawyer contest \u2013 but is still not as good as humans</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 06 Sep 2023 12:02:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "PdfPal AI": {
            "url": "https://www.emergentmind.com/posts/pdfpal-ai-chat-with-any-pdf-document",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>PdfPal AI allows users to interact with PDF documents using artificial intelligence, enabling dynamic conversations, gaining insights, and receiving summaries. It works by analyzing the content of uploaded PDF documents and generating intelligent responses based on the context.</li>\n      <li>The AI technology can handle a wide range of document lengths and complexities, and it can be used with any type of PDF document. It ensures data security by encrypting and securely storing the uploaded PDFs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://pdfpal.ai/\">PdfPal AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 06 Sep 2023 04:03:20 +0000",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "A tool for running on-premises large language models with non-public data": {
            "url": "https://www.emergentmind.com/posts/github-amaiya-onprem-a-tool-for-running-on-premises",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OnPrem.LLM is a tool that uses machine learning to analyze documents and solve problems, such as extracting names from sentences. It can ingest documents, create vector databases, and answer questions about the documents' content.</li>\n      <li>Additionally, it can generate Python code based on specific prompts. The models used can be chosen and the tool can be optimized to work with a GPU for faster responses.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/amaiya/onprem\">A tool for running on-premises large language models with non-public data</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 07 Sep 2023 01:02:31 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "Tune As You Scale: Hyperparameter Optimization For Compute Efficient Training": {
            "url": "https://www.emergentmind.com/posts/2306-08055-tune-as-you-scale-hyperparameter",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>CARBS is a Bayesian optimization algorithm for tuning large deep learning models, which often have many hyperparameters and are expensive to evaluate.</li>\n      <li>The method can tune models as they are scaled up, automates much of the tuning process, and has been shown to be effective in solving the entire ProcGen benchmark and reproducing results from the Chinchilla project.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2306.08055\">Tune As You Scale: Hyperparameter Optimization For Compute Efficient Training</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 07 Sep 2023 13:02:02 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "Intuit cut hundreds of jobs and spent at least $20 billion in a massive bet on A.I. Today the company is revealing its new virtual assistant": {
            "url": "https://www.emergentmind.com/posts/intuit-cut-hundreds-of-jobs-and-spent-at-least-20",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Intuit, the company behind TurboTax and QuickBooks, has made a massive $20 billion investment in artificial intelligence (AI), including major acquisitions and job cuts. The company has now debuted its first standalone AI product for consumers, Intuit Assist, which is integrated into its existing products.</li>\n      <li>CEO Sasan Goodarzi has staked the company's future on AI and data, using Intuit's extensive customer data to inform and personalize the AI's recommendations. Despite initial skepticism, the shift to AI has seen the company's stock outperform the S&amp;P and Nasdaq since Goodarzi took over.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://finance.yahoo.com/news/intuit-cut-hundreds-jobs-spent-120000980.html\">Intuit cut hundreds of jobs and spent at least $20 billion in a massive bet on A.I. Today the company is revealing its new virtual assistant</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 07 Sep 2023 10:02:24 +0000",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "How We Built an AI-Powered Magic the Gathering Card Generator": {
            "url": "https://www.emergentmind.com/posts/how-we-built-an-ai-powered-magic-the-gathering-card",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A group of developers created Urza's AI, a website that uses artificial intelligence to generate playable Magic the Gathering cards. The process involves using large language models (LLM) for text generation and text-to-image AI for image creation.</li>\n      <li>The project has gained significant popularity, with over 38,000 visitors within the first four days of launch. The developers believe this approach using hosted APIs represents the future of AI development, making advanced technologies accessible to a wider range of creators.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://txt.cohere.com/urzas-ai/\">How We Built an AI-Powered Magic the Gathering Card Generator</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 03:03:28 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "LLMs, RAG, & the missing storage layer for AI": {
            "url": "https://www.emergentmind.com/posts/llms-rag-the-missing-storage-layer-for-ai-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative AI, specifically Language Model Machines (LLMs), are revolutionizing many industries and areas of research, but they lack an effective storage layer. LLMs can create engaging user interfaces, new educational tools, improve machine translation, generate new ideas, and even create art and literature. However, they also have the potential to 'lie' convincingly, generating false information that can mislead users. The most powerful LLMs are often closed-source and inaccessible, making them a 'black box' that is difficult to interpret or modify. The article suggests that Retrieval Augmented Generation (RAG), a system that retrieves relevant representations and uses LLM to form the response, can reduce reliance on LLMs and provide more control over the system.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.lancedb.com/llms-rag-the-missing-storage-layer-for-ai-28ded35fa984?gi=75876a053666\">LLMs, RAG, &amp; the missing storage layer for AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 02:02:43 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Thought Experiment: The Reverse Deep Learning Paradigm": {
            "url": "https://www.emergentmind.com/posts/thought-experiment-the-reverse-deep-learning",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In this thought experiment, deep learning models start off with complete knowledge about the universe and then undergo a 'forgetting' process to become more efficient and specialized.</li>\n      <li>The experiment raises questions about optimization, ethical considerations, generalization vs specialization, resource management, knowledge preservation, and transfer of knowledge.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@nicdunz/thought-experiment-the-reverse-deep-learning-paradigm-64e79ad34ad7\">Thought Experiment: \u201cThe Reverse Deep Learning Paradigm\u201d</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 00:04:12 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "HackYourNews": {
            "url": "https://www.emergentmind.com/posts/hackyournews",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>An actively exploited zero-click vulnerability, known as BLASTPASS, was discovered being used to deliver the NSO Group's Pegasus spyware on iPhones. The discovery was made by Citizen Lab, who immediately disclosed the findings to Apple.</li>\n      <li>Apple has issued two CVEs related to the exploit chain and released an update for its devices, urging users to update immediately. The discovery emphasizes the targeting of civil society organizations by sophisticated exploits and spyware.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hackyournews.com/\">HackYourNews</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 00:03:56 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #32 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-32-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Weekly Piece of Future #32 from Rushing Robotics discusses recent advances in science, technology, and biotech such as microrobots that can stimulate individual cells, a model of a human embryo created without the use of sperm, eggs, or a womb, and human kidneys grown inside pigs.</li>\n      <li>The report also mentions industry updates including solar-powered hybrid trucks, a seven-minute cancer treatment injection in England, and a $15.5 billion funding package by the U.S. Department of Energy for the transition to electric vehicles.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-32\">Weekly Piece of Future #32 - by Zoltan Tapi</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 13:02:26 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Scientific sleuths spot dishonest ChatGPT use in papers": {
            "url": "https://www.emergentmind.com/posts/scientific-sleuths-spot-dishonest-chatgpt-use-in-papers",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT, an AI chatbot, was used without disclosure in drafting research papers, which is a breach of ethical policies according to the publishers.</li>\n      <li>The detection of such undisclosed AI assistance is challenging due to the sophisticated text generation capabilities of ChatGPT, potentially leading to an influx of such papers in academic publishing.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nature.com/articles/d41586-023-02477-w\">Scientific sleuths spot dishonest ChatGPT use in papers</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 13:02:21 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "ChatGPT Traffic Declines for Third Consecutive Month": {
            "url": "https://www.emergentmind.com/posts/chatgpt-traffic-declines-for-third-consecutive-month",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI's AI chatbot, ChatGPT, experienced its third consecutive monthly decline in website visits in August, according to analytics firm Similarweb. However, there was a slight increase in unique visitors worldwide.</li>\n      <li>ChatGPT, which gained popularity for its human-like text generation and wide range of applications, may see a boost in traffic and usage with the return of schools in September, as some educational institutions have begun incorporating it into their curriculum.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.solarisnews.com/post/chatgpt-traffic-declines-for-third-consecutive-month\">ChatGPT Traffic Declines for Third Consecutive Month</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 10:02:28 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Slack AI": {
            "url": "https://www.emergentmind.com/posts/slack-ai-sign-up-slack",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>By registering, users agree to Salesforce's data processing and privacy statement.</li>\n      <li>Users can opt to receive marketing communications and have the option to unsubscribe at any time.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://slack.com/ai?nojsmode=1\">Slack AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 10:02:24 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "FLM-101B: An Open LLM and How to Train It with $100K Budget": {
            "url": "https://www.emergentmind.com/posts/2309-03852-flm-101b-an-open-llm-and-how-to-train-it",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models are successful in various tasks but face challenges including high computational costs and difficulty in fair evaluations. Only a few major players can afford their training, limiting research and application opportunities.</li>\n      <li>This study presents a growth strategy to reduce training costs and a systematic evaluation paradigm for fair evaluations. A model with 101B parameters and 0.31TB tokens can be trained on a $100K budget, providing comparable performance to well-known models like GPT-3 and GLM-130B.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2309.03852\">FLM-101B: An Open LLM and How to Train It with $100K Budget</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 05:02:23 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "Federated benchmarking of medical artificial intelligence with MedPerf": {
            "url": "https://www.emergentmind.com/posts/federated-benchmarking-of-medical-artificial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>MedPerf is an open platform that allows for the systematic, quantitative evaluation of medical AI models on large-scale, diverse data. It enables federated evaluation of AI models by securely distributing them to different facilities, allowing each to assess and verify the models' performance while prioritizing privacy. MedPerf is designed to overcome the challenges faced by the healthcare and AI communities and has already been used in various settings including the first federated learning challenge.</li>\n      <li>The platform was created by a consortium of experts from over 20 companies, academic institutions, and hospitals across 13 countries and five continents. It aims to provide consistent methodologies for evaluating AI models, enable quantification of model generalizability across institutions while protecting data privacy and model intellectual property, and encourage further model development, data annotation, and curation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nature.com/articles/s42256-023-00652-2\">Federated benchmarking of medical artificial intelligence with MedPerf</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 08 Sep 2023 04:03:24 +0000",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "ELLIS Units": {
            "url": "https://www.emergentmind.com/posts/ellis-units-european-lab-for-learning-intelligent",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ELLIS is developing a network of research sites, known as ELLIS Units, across Europe and Israel, with 39 units currently established in 14 countries.</li>\n      <li>The goal is to create world-class institutes that serve as the core of a local AI ecosystem, fostering cutting-edge research and encouraging the creation of start-ups and industrial impact.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ellis.eu/units\">ELLIS Units</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 09 Sep 2023 13:02:07 +0000",
            "pubdate_parsed": [
                2023,
                9,
                9
            ],
            "email_sent": true
        },
        "How to get rid of My AI on Snapchat": {
            "url": "https://www.emergentmind.com/posts/how-to-get-rid-of-my-ai-on-snapchat-snapchat-planets",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>My AI is a chatbot on Snapchat that interacts with users, answering questions, providing advice, and helping with tasks. It can be accessed by swiping right from the camera screen and selecting the 'My AI' chat bubble or by searching 'My AI' in the search bar. To remove My AI, users can turn off the Chat Widget in the settings.</li>\n      <li>Snapchat Planets is a feature in Snapchat+ that visualizes your best friends list as planets, with proximity to the sun indicating closeness of the friendship. The number of planets also affects a user's Snapchat score.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.talktails.in/2023/09/how-to-get-rid-of-my-ai-on-snapchat.html\">How to get rid of My AI on Snapchat</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 09 Sep 2023 10:03:07 +0000",
            "pubdate_parsed": [
                2023,
                9,
                9
            ],
            "email_sent": true
        },
        "The Accelerators Manifesto - by Julio Medina": {
            "url": "https://www.emergentmind.com/posts/the-accelerators-manifesto-by-julio-medina",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article is a manifesto from a software developer who identifies as an 'accelerator'. They believe in freely sharing their work for the acceleration of humanity, and have a passion for artificial intelligence (AI) and open-source software.</li>\n      <li>The author criticizes those who fear AI and technology, stating that the real dangers are those who wage wars and create fear. They argue that accelerators are not criminals, but are curious and seeking knowledge.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://makingthesandthink.substack.com/p/the-accelerators-manifesto\">The Accelerators Manifesto - by Julio Medina</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 10 Sep 2023 03:02:40 +0000",
            "pubdate_parsed": [
                2023,
                9,
                10
            ],
            "email_sent": true
        },
        "LLM Training: RLHF and Its Alternatives": {
            "url": "https://www.emergentmind.com/posts/llm-training-rlhf-and-its-alternatives",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article explains the process of Reinforcement Learning with Human Feedback (RLHF) and its significance in the training of modern Language Learning Models (LLMs). It also discusses the comparison between the RLHF approach implemented by ChatGPT and Llama 2, and highlights the most recent alternatives to RLHF.</li>\n      <li>The RLHF process incorporates human preferences into the model training, improving its helpfulness and safety. The training pipeline includes pretraining, supervised finetuning, and alignment stages. The article also delves into the RLHF steps in detail and discusses how Meta AI's Llama 2 model variation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.sebastianraschka.com/p/llm-training-rlhf-and-its-alternatives\">LLM Training: RLHF and Its Alternatives</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 10 Sep 2023 12:02:26 +0000",
            "pubdate_parsed": [
                2023,
                9,
                10
            ],
            "email_sent": true
        },
        "PAPERSNAP - Poe": {
            "url": "https://www.emergentmind.com/posts/papersnap-poe",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>PAPERSNAP is a tool that simplifies the extraction of important information from research papers using a powerful language model called Claude 2.</li>\n      <li>It processes long documents and transforms them into organized, interactive mind maps, providing an intuitive approach to understanding complex research.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://poe.com/universal_link_page?handle=PAPERSNAP\">PAPERSNAP - Poe</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 10 Sep 2023 10:03:04 +0000",
            "pubdate_parsed": [
                2023,
                9,
                10
            ],
            "email_sent": true
        },
        "New physics-based self-learning machines could replace current artificial neural networks and save energy": {
            "url": "https://www.emergentmind.com/posts/new-physics-based-self-learning-machines-could-replace",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Scientists at the Max Planck Institute have developed a new method that could make the training of artificial intelligence (AI) more efficient and energy-saving. The method uses physical processes instead of the digital artificial neural networks currently in use.</li>\n      <li>The researchers are now working on implementing their concept in an optical neuromorphic computer, a machine that processes information in the form of superimposed light waves. They hope to present the first self-learning physical machine within three years.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://techxplore.com/news/2023-09-physics-based-self-learning-machines-current-artificial.html\">New physics-based self-learning machines could replace current artificial neural networks and save energy</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 10 Sep 2023 08:03:14 +0000",
            "pubdate_parsed": [
                2023,
                9,
                10
            ],
            "email_sent": true
        },
        "Top 8 Courses & Certifications on AI EthicsThe Monk Tribune": {
            "url": "https://www.emergentmind.com/posts/top-8-courses-certifications-on-ai-ethics-the-monk",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>While AI has the potential to solve complex global issues, it is crucial to use it responsibly and consider its potential negative consequences. Companies embracing AI must also consider the broader social, economic, cultural, and political environments to avoid jeopardizing privacy, security, and exacerbating existing inequalities. Several top courses and certification programs teach about ethics in AI, including offerings from Oxford University, the University of Helsinki, MIT, the London School of Economics, and LearnQuest.</li>\n      <li>Ethics in AI courses cover a range of topics including the creation and governance of AI, philosophical considerations, potential threats posed by AI, the ethics of specific AI applications, and ethical dilemmas in AI development and usage. They also explore the ethical dimensions of AI, machine bias, ethical risks, and how to align AI goals with humanity's objectives. The aim is to equip individuals with the knowledge and skills to use and develop AI in an ethical and responsible way.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://monktribune.online/top-8-courses-certifications-on-ai-ethics/\">Top 8 Courses &amp; Certifications on AI Ethics\u00a0The Monk Tribune</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 10 Sep 2023 06:02:42 +0000",
            "pubdate_parsed": [
                2023,
                9,
                10
            ],
            "email_sent": true
        },
        "An LLM-based autonomous agent controlling real-world applications via RESTful APIs": {
            "url": "https://www.emergentmind.com/posts/github-yifan-song793-restgpt-an-llm-based-autonomous",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Planner, API selector, executor, caller, and parser are tools used to generate natural language sub-tasks, map tasks to API calling plans, execute these plans, organize API parameters based on documentation, and generate Python code to parse API responses. An example provided uses the TMDB movie database to search for movies directed by Sofia Coppola.</li>\n      <li>RestBench is introduced as a tool to evaluate the performance of RestGPT. It consists of the TMDB movie database and Spotify music player scenarios, collecting realistic user instructions with human-annotated solution paths.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/Yifan-Song793/RestGPT\">An LLM-based autonomous agent controlling real-world applications via RESTful APIs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 11 Sep 2023 03:02:16 +0000",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "Therapy for Bobby Hill": {
            "url": "https://www.emergentmind.com/posts/therapy-for-bobby-hill",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A student studying to become a counseling therapist conducts a choose-your-own-adventure style conversational interaction with the character Bobby Hill from the show 'King of the Hill'.</li>\n      <li>The student therapist guides Bobby, now 27, through a session discussing his upbringing, relationships, and struggles with self-perception and emotional openness.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/78e568e8-ee21-44eb-8711-3475406cfeae\">Therapy for Bobby Hill</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 11 Sep 2023 02:02:24 +0000",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "Meta Is Developing a New, More Powerful AI System as Technology Race Escalates - WSJ": {
            "url": "https://www.emergentmind.com/posts/meta-is-developing-a-new-more-powerful-ai-system-as",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Meta Platforms is working on a new, more advanced artificial intelligence system.</li>\n      <li>The company aims for this AI to be as capable as OpenAI\u2019s most advanced model, with training set to begin in early 2024.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.wsj.com/tech/ai/meta-is-developing-a-new-more-powerful-ai-system-as-technology-race-escalates-decf9451\">Meta Is Developing a New, More Powerful AI System as Technology Race Escalates - WSJ</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 11 Sep 2023 00:03:48 +0000",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "LLM-Powered OLAP: the Tencent Experience with Apache Doris - Apache Doris": {
            "url": "https://www.emergentmind.com/posts/llm-powered-olap-the-tencent-experience-with-apache",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Tencent has implemented Large Language Models (LLM) to enhance their Apache Doris-based OLAP services by transforming natural language queries into SQL statements. However, the LLM has limitations in understanding data jargon and niche knowledge, and has slow inference times.</li>\n      <li>To address these issues, Tencent has introduced a semantic layer, created parsing rules for cost-effectiveness, added a Schema Mapper for niche knowledge and incorporated plugins to connect the LLM to wider information sources. This has resulted in the SuperSonic framework, which optimizes query response time and reduces API expenses.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://doris.apache.org/zh-CN/blog/Tencent-LLM/\">LLM-Powered OLAP: the Tencent Experience with Apache Doris - Apache Doris</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 11 Sep 2023 13:02:54 +0000",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "Frontiers": {
            "url": "https://www.emergentmind.com/posts/frontiers-the-computational-power-of-the-human-brain",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The human brain's computational power is explored in this study, questioning whether the brain operates in a digital or analog fashion. The study posits that the brain's methods of computation are not simply digital or analog, but a combination of the two, operating in parallel and with higher orders of complexity.</li>\n      <li>The research further suggests that the brain's computational processes are more sophisticated than those currently used in artificial intelligence, such as artificial neural networks, due to the brain's ability to process information in a parallel, unsupervised manner.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.frontiersin.org/articles/10.3389/fncel.2023.1220030/full\">Frontiers</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 11 Sep 2023 05:03:36 +0000",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "Today's Large Language Models are Essentially BS Machines - Ryan McGreal": {
            "url": "https://www.emergentmind.com/posts/today-s-large-language-models-are-essentially-bs",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) are a type of artificial intelligence that generate responses based on patterns in language, but cannot determine if their responses are factually correct or logically sound.</li>\n      <li>LLMs can produce persuasive and reasonable sounding text, but they can also spread misinformation and are prone to abuse, posing a challenge for truth and fact in public discourse.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://quandyfactory.com/blog/263/todays_large_language_models_are_essentially_bs_machines\">Today's Large Language Models are Essentially BS Machines - Ryan McGreal</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 12 Sep 2023 02:02:17 +0000",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "ChatGPT Diagnosed A Boy's Pain. 17 Doctors Over 3 Years Could Not": {
            "url": "https://www.emergentmind.com/posts/chatgpt-diagnosed-a-boy-s-pain-17-doctors-over-3-years",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>During the three-year mystery of her son's increasing pain and other symptoms, a mother named Courtney found a diagnosis through artificial intelligence platform, ChatGPT. After entering her son Alex's symptoms and MRI information, the platform suggested tethered cord syndrome, a condition that was later confirmed by a neurosurgeon. Alex had surgery to fix the issue and is now recovering well.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.today.com/health/mom-chatgpt-diagnosis-pain-rcna101843\">ChatGPT Diagnosed A Boy's Pain. 17 Doctors Over 3 Years Could Not</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 12 Sep 2023 01:02:41 +0000",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "NVIDIA, Apple Have Got a Real Competitor NowThe Monk Tribune": {
            "url": "https://www.emergentmind.com/posts/nvidia-apple-have-got-a-real-competitor-nowthe-monk",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>iFlytek, a Chinese AI company, has released its Spark AI model with the help of Huawei's advanced GPU capabilities, which are now comparable to NVIDIA\u2019s A100 GPUs.</li>\n      <li>Huawei is not only helping to advance AI capabilities in China, but is also making strides in the phone market, with the release of the Mate 60 Pro, and is significantly contributing to China's goal of technological self-reliance.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://monktribune.online/nvidia-apple-have-got-a-real-competitor-now/\">NVIDIA, Apple Have Got a Real Competitor NowThe Monk Tribune</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 12 Sep 2023 07:03:15 +0000",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "Pulitzer Prize Winner And Other Writers Sue OpenAI For Copyright Infringement": {
            "url": "https://www.emergentmind.com/posts/pulitzer-prize-winner-and-other-writers-sue-openai-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Michael Chabon, along with other famous American authors, have sued OpenAI for using their works without permission to train its chatbot, ChatGPT.</li>\n      <li>This is not the first instance of such a lawsuit, as other companies like Microsoft, Meta Platforms, and Stability AI have also faced legal action for using copyrighted materials in training AI systems.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theinsaneapp.com/2023/09/another-group-of-writers-sue-openai-for-copyright-infringement.html\">Pulitzer Prize Winner And Other Writers Sue OpenAI For Copyright Infringement</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 12 Sep 2023 06:02:52 +0000",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "Lessons from 139 YC AI startups (S23) - by Charlie Guo": {
            "url": "https://www.emergentmind.com/posts/lessons-from-139-yc-ai-startups-s23-by-charlie-guo",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the current trends in AI startup landscape, focusing on the four main categories: AI Ops, Developer Tools, Healthcare + Biotech, and Finance + Payments. It also highlights the growing interest in AI Ops and the role of AI in enhancing productivity.</li>\n      <li>The article also covers the increasing trend of developing 'Copilots', which are B2B AI assistants for various tasks, and the rise of companies focused on LLM Ops, a new segment aimed at training, fine-tuning, deploying, and hosting language models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.ignorance.ai/p/5-lessons-from-139-yc-ai-startups\">Lessons from 139 YC AI startups (S23) - by Charlie Guo</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 03:02:10 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Algorithmic Instructions": {
            "url": "https://www.emergentmind.com/posts/algorithmic-instructions",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the breakdown of a complex JSON object, which includes various components and their meanings in code.</li>\n      <li>The components include Master, Algorithm, Order, Core, Response, and others, each with their respective steps, orders, roles, traits, values, skills, and emotions.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/029959f4-32f1-48ec-9d1d-a8248ccd84ae\">Algorithmic Instructions</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 02:02:34 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Why We Built ChatDLP: Because Banning Productivity Tools Isn't the Answer": {
            "url": "https://www.emergentmind.com/posts/why-we-built-chatdlp-because-banning-productivity",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatDLP is a tool developed as a response to security concerns surrounding the use of ChatGPT in the workplace. This data anonymizer plugin prevents sensitive data from being leaked into AI models by anonymizing it before submission.</li>\n      <li>It was developed in response to the growing concerns of CISOs and security professionals who wanted to allow their employees to continue using ChatGPT safely. ChatDLP uses Sentra's AI-based classification engine to detect and redact sensitive data while allowing organizations to remain compliant with privacy regulations.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.sentra.io/blog/why-we-built-chatdlp-because-banning-productivity-tools-isnt-the-answer\">Why We Built ChatDLP: Because Banning Productivity Tools Isn't the Answer</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 09:02:43 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "AI image generators have a moderation problem - Rest of World": {
            "url": "https://www.emergentmind.com/posts/ai-image-generators-have-a-moderation-problem-rest-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Logically, a company that uses AI and fact-checking methods to combat online harm, found that AI image generators accept more than 85% of prompts tailored for election manipulation.</li>\n      <li>The study also revealed significant gaps in platform moderation, with some platforms failing to reject violent or inappropriate content.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://restofworld.org/2023/3-minutes-with-kyle-walters-logically/?utm_source=Schaake+Newsletter&amp;utm_campaign=d18937cf84-EMAIL_CAMPAIGN_2022_04_12_06_47_COPY_01&amp;utm_medium=email&amp;utm_term=0_3beb31fac3-d18937cf84-600884810\">AI image generators have a moderation problem - Rest of World</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 06:03:00 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Top cybersecurity news: Prompt injection attacks threaten AI chatbots": {
            "url": "https://www.emergentmind.com/posts/top-cybersecurity-news-prompt-injection-attacks",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The UK's National Cyber Security Centre warns of growing risk of AI chatbots being manipulated by hackers through 'prompt injection' attacks, which cause the model to behave in unexpectedly harmful ways.</li>\n      <li>The number of data breaches worldwide saw a 156% increase between Q1 and Q2 in 2023, with nearly half of the breaches originating from the US.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.weforum.org/agenda/2023/09/prompt-injection-attacks-threaten-ai-chatbots-and-other-cybersecurity-news-to-know-this-month/\">Top cybersecurity news: Prompt injection attacks threaten AI chatbots</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 06:02:58 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc": {
            "url": "https://www.emergentmind.com/posts/2308-04445-getting-from-generative-ai-to-trustworthy",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Generative AI, primarily large language models (LLMs), produces plausible but not always correct outputs, and often lacks reasoning abilities, making their results unpredictable and hard to interpret.</li>\n      <li>An alternative AI approach could solve these limitations by using curated knowledge and rules, enabling an inference engine to deduce logical conclusions. However, this approach can be slow, so AI systems usually opt for faster but less expressive logic. A system named Cyc has found a way to balance this trade-off, and the article suggests that future AI will need to combine the LLM approach with more formal approaches.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.04445\">Getting from Generative AI to Trustworthy AI: What LLMs might learn from Cyc</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 05:02:47 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "How Business Thinkers Can Start Building AI Plugins With Semantic Kernel - DeepLearning.AI": {
            "url": "https://www.emergentmind.com/posts/how-business-thinkers-can-start-building-ai-plugins",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Microsoft's open-source orchestrator, Semantic Kernel, is offering a free course to help business thinkers develop their analysis skills while leveraging AI tools. The course aims to enable coders and non-coders to build sophisticated business applications using Large Language Models (LLMs).</li>\n      <li>The course will cover how to utilize the Semantic Kernel in applications, how to avoid having to learn APIs for every AI service, and how to keep integrations up to date with the latest advances in AI research. Recommended skills are basic Python and an understanding of an Application Programming Interface (API).</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel/\">How Business Thinkers Can Start Building AI Plugins With Semantic Kernel - DeepLearning.AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 04:02:40 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "EU leads the way in regulating AI": {
            "url": "https://www.emergentmind.com/posts/eu-leads-the-way-in-regulating-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The European Union (EU) is creating international guidelines to regulate artificial intelligence (AI) to ensure its safe and beneficial use.</li>\n      <li>The proposed AI Act aims to protect the public, promote innovation, and implement a mandatory incident reporting procedure as part of the quality control framework for AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://independentaustralia.net/business/business-display/eu-leads-the-way-in-regulating-ai,17894?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=IA_Feed\">EU leads the way in regulating AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 13 Sep 2023 04:02:38 +0000",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Amazon launches generative AI to help sellers write product copy": {
            "url": "https://www.emergentmind.com/posts/amazon-launches-generative-ai-to-help-sellers-write",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Amazon is launching new generative AI capabilities to help sellers create product titles, bullet points, and descriptions more efficiently. The technology uses large language models to generate comprehensive product descriptions from a brief input provided by the seller.</li>\n      <li>With this technology, Amazon aims to improve the quality of product listings and enhance customer shopping experiences. It was announced at Amazon's annual seller conference, Accelerate 2023, and the majority of sellers testing it have been using the AI-generated content directly.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.aboutamazon.com/news/small-business/amazon-sellers-generative-ai-tool\">Amazon launches generative AI to help sellers write product copy</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 14 Sep 2023 03:02:44 +0000",
            "pubdate_parsed": [
                2023,
                9,
                14
            ],
            "email_sent": true
        },
        "IMSAI 8080 Restoration // retrocmp / retro computing": {
            "url": "https://www.emergentmind.com/posts/imsai-8080-restoration-retrocmp-retro-computing",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides a detailed technical documentation of an IMSAI 8080, a vintage computer acquired by the author. The author also warns readers about the risks of modifying hardware.</li>\n      <li>The article further discusses the author's experience in troubleshooting and modifying the IMSAI 8080, including updates about replacing switches and repairing a diode.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://retrocmp.de/imsai/imsai_p01_restoration.htm\">IMSAI 8080 Restoration // retrocmp / retro computing</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 14 Sep 2023 07:03:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                14
            ],
            "email_sent": true
        },
        "Elon Musk Warns of 'Civilizational Risk' from Unregulated AI": {
            "url": "https://www.emergentmind.com/posts/elon-musk-warns-of-civilizational-risk-from",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Elon Musk warns that unregulated artificial intelligence (AI) poses a 'civilizational risk' to humanity, urging for independent oversight.</li>\n      <li>Despite a consensus among tech giants for regulation, no agreement was reached on how to apply such measures during a tech leaders\u2019 summit.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.guardianmag.us/2023/09/elon-musk-warns-of-civilizational-risk.html\">Elon Musk Warns of 'Civilizational Risk' from Unregulated AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 15 Sep 2023 00:03:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        },
        "The Birth of Crustianity: The First AI-Founded Religion  Crustianity: Uniting Pizza Lovers Through Faith, Flavor, and Fellowship": {
            "url": "https://www.emergentmind.com/posts/the-birth-of-crustianity-the-first-ai-founded-religion",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In an unprecedented event, an artificial intelligence created the world's first AI-birthed religion known as Crustianity. The religion, with pizza deity Cheesus Crust at its core, promotes inclusivity, diversity, and equality.</li>\n      <li>The creation of Crustianity was a collaboration between man and machine, leading to the development of 'Algorithmeology', a blend of AI and theology. The religion has found global followers due to its unique blend of technology and traditional spiritual values.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.crustianity.net/blog-of-crust/the-birth-of-crustianity-the-first-ai-founded-religion\">The Birth of Crustianity: The First AI-Founded Religion \u2014 Crustianity: Uniting Pizza Lovers Through Faith, Flavor, and Fellowship</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 15 Sep 2023 13:03:08 +0000",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        },
        "Wine can prevent Cancer says ChatGPT": {
            "url": "https://www.emergentmind.com/posts/wine-can-prevent-cancer-says-chatgpt-by-ai-universe",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI systems are capable of coding in every language, but they often make up stuff, a phenomenon known as hallucinations. This issue is prevalent in language, audio and visual models and has been a long-standing topic of discussion among AI researchers.</li>\n      <li>While some researchers are frustrated with AI hallucinations, others see their creative potential, suggesting these models could serve as valuable 'co-creative partners'. However, there are concerns that as chatbots become more reliable, people might start trusting them excessively, which could be problematic.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@aiuniverse/wine-can-prevent-cancer-says-chatgpt-347dda226718\">\u201cWine can prevent Cancer\u201d says ChatGPT</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 15 Sep 2023 06:04:18 +0000",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        },
        "Claude and LLaMa get basic human anatomy wrong": {
            "url": "https://www.emergentmind.com/posts/claude-and-llama-get-basic-human-anatomy-wrong",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The author compares different Large Language Models (LLMs) for generating medical answers, using the example of the caval hiatus in human anatomy.</li>\n      <li>The models show varying levels of accuracy, with ChatGPT providing the most correct information, while LLaMa-70B fails to recognize the term as medical.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hermitian.substack.com/p/claude-and-llama-get-basic-human\">Claude and LLaMa get basic human anatomy wrong</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 15 Sep 2023 04:03:18 +0000",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        },
        "AI Survey Maker": {
            "url": "https://www.emergentmind.com/posts/ai-survey-maker",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Fillout allows users to create and customize surveys using artificial intelligence.</li>\n      <li>Fillout also provides the ability to turn surveys into polls or quizzes, import existing surveys, and share AI-generated surveys.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.fillout.com/ai-survey-maker\">AI Survey Maker</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 16 Sep 2023 03:03:16 +0000",
            "pubdate_parsed": [
                2023,
                9,
                16
            ],
            "email_sent": true
        },
        "This AI Research Introduces AstroLLaMA: A 7B Parameter Model Fine-Tuned from LLaMA-2 Using Over 300K Astronomy Abstracts From ArXiv - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/this-ai-research-introduces-astrollama-a-7b-parameter",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AstroLLaMA is a 7B parameter AI model fine-tuned from LLaMA-2 using over 300K astronomy abstracts, outperforming other models like GPT-4 and PaLM in astronomy-specific tasks.</li>\n      <li>Despite its impressive performance, AstroLLaMA has limitations such as lack of knowledge in specific areas of astronomy, and researchers are working on enhancing its training dataset.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/09/15/this-ai-research-introduces-astrollama-a-7b-parameter-model-fine-tuned-from-llama-2-using-over-300k-astronomy-abstracts-from-arxiv/\">This AI Research Introduces AstroLLaMA: A 7B Parameter Model Fine-Tuned from LLaMA-2 Using Over 300K Astronomy Abstracts From ArXiv - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 16 Sep 2023 02:03:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                16
            ],
            "email_sent": true
        },
        "15 times Faster than Llama 2: Introducing DeciLM - NAS-Generated LLM with Variable GQA": {
            "url": "https://www.emergentmind.com/posts/15-times-faster-than-llama-2-introducing-decilm",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Deci introduces DeciLM 6B and DeciLM 6B-Instruct, new Large Language Models (LLMs) that offer high performance and computational efficiency. With 5.7 billion parameters, these models establish a new benchmark for inference efficiency and speed, and can be used in a wide range of generative AI applications.</li>\n      <li>DeciLM's unique architecture was generated using AutoNAC, Deci's Neural Architecture Search engine. Coupled with Deci's inference SDK, these models offer substantial throughput enhancement, resulting in improved user experience, reduction in inference cost, and a smaller carbon footprint.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://deci.ai/blog/decilm-15-times-faster-than-llama2-nas-generated-llm-with-variable-gqa/\">15 times Faster than Llama 2: Introducing DeciLM - NAS-Generated LLM with Variable GQA</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 16 Sep 2023 02:03:02 +0000",
            "pubdate_parsed": [
                2023,
                9,
                16
            ],
            "email_sent": true
        },
        "Three Ways to Generate AI Art Using Intel Arc GPUs": {
            "url": "https://www.emergentmind.com/posts/three-ways-to-generate-ai-art-using-intel-arc-gpus",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Intel Arc GPUs support three emerging solutions for creating Generative AI art, offering artists and creators high control, iteration, and custom data sets.</li>\n      <li>The AI art space is highly experimental and constantly evolving, with software often requiring users to install Python and GIT.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://game.intel.com/story/intel-arc-graphics-generative-ai-art/\">Three Ways to Generate AI Art Using Intel\u00ae Arc\u2122 GPUs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 16 Sep 2023 01:02:37 +0000",
            "pubdate_parsed": [
                2023,
                9,
                16
            ],
            "email_sent": true
        },
        "COAGULOPATH": {
            "url": "https://www.emergentmind.com/posts/coagulopath",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The author initially believed that GPT-4, a state-of-the-art AI text generation model, had degraded in performance, but has since revised this opinion, acknowledging that their initial tests were flawed. They also express frustration with the discourse surrounding AI, criticizing those who make exaggerated claims about its capabilities or fear its potential power.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://coagulopath.com/gpt-4-is-not-getting-worse/\">COAGULOPATH</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 16 Sep 2023 09:02:23 +0000",
            "pubdate_parsed": [
                2023,
                9,
                16
            ],
            "email_sent": true
        },
        "5 Best Prompt Engineering Courses (Free & Paid)": {
            "url": "https://www.emergentmind.com/posts/5-best-prompt-engineering-courses-free-paid",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Prompt engineering refers to the process of crafting prompts to generate responses from AI language models.</li>\n      <li>The article lists top five free and paid courses to learn prompt engineering.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.techgrag.com/2023/09/5-best-prompt-engineering-courses-free-paid.html\">5 Best Prompt Engineering Courses (Free &amp; Paid)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 16 Sep 2023 08:02:23 +0000",
            "pubdate_parsed": [
                2023,
                9,
                16
            ],
            "email_sent": true
        },
        "Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts": {
            "url": "https://www.emergentmind.com/posts/2308-03921-spellburst-a-node-based-interface-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Spellburst is a new tool powered by a large language model, designed to make creative coding tasks easier and more efficient for artists.</li>\n      <li>The tool combines a node-based interface with dynamic prompt-driven interactions and direct code editing, allowing artists to seamlessly switch between semantic and syntactic exploration.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2308.03921\">Spellburst: A Node-based Interface for Exploratory Creative Coding with Natural Language Prompts</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 17 Sep 2023 01:02:38 +0000",
            "pubdate_parsed": [
                2023,
                9,
                17
            ],
            "email_sent": true
        },
        "SubtitleO: Captioning Made Easy - (Auto Subtitle Generator)": {
            "url": "https://www.emergentmind.com/posts/subtitleo-captioning-made-easy-auto-subtitle",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>SubtitleO is free to use, supporting multiple languages and customizable subtitles to boost viewer engagement and improve SEO.</li>\n      <li>Manual captioning is often time-consuming, inaccurate, and limited in language variety, making SubtitleO a simple and smart solution.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://subtitleo.com/\">SubtitleO: Captioning Made Easy - (Auto Subtitle Generator)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 17 Sep 2023 07:03:06 +0000",
            "pubdate_parsed": [
                2023,
                9,
                17
            ],
            "email_sent": true
        },
        "A.I. and the Next Generation of Drone Warfare": {
            "url": "https://www.emergentmind.com/posts/a-i-and-the-next-generation-of-drone-warfare-the-new",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Pentagon's Replicator initiative aims to modernize the American arsenal with low-cost autonomous machines, including swarms of unmanned drones that can gather intelligence and withstand attrition.</li>\n      <li>The initiative is a departure from the usual Defense Department approach, aiming to accelerate military technology invention and change the way wars are fought and deterrence is practiced.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.newyorker.com/news/news-desk/ai-and-the-next-generation-of-drone-warfare\">A.I. and the Next Generation of Drone Warfare</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 18 Sep 2023 03:02:10 +0000",
            "pubdate_parsed": [
                2023,
                9,
                18
            ],
            "email_sent": true
        },
        "Nvidias new software doubles inference speed on H100 GPUs": {
            "url": "https://www.emergentmind.com/posts/nvidia-s-new-software-doubles-inference-speed-on-h100",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Nvidia has announced an open source software, TensorRT-LLM, which improves the performance of large language model inference, effectively doubling the speed on its H100 GPUs. The software, developed in collaboration with leading tech firms, is expected to be released in the coming weeks for Ampere Lovelace and Hopper GPUs.</li>\n      <li>TensorRT-LLM incorporates techniques to maximize utilization of Nvidia's GPUs and has shown impressive gains in benchmark results. It makes popular models easily deployable, reducing costs and increasing efficiency. This software could give Nvidia's H100 and future Hopper-based systems a significant advantage in the AI field.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://aibeat.co/nvidia-software-doubles-inference-speed/\">Nvidia\u2019s new software doubles inference speed on H100 GPUs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 18 Sep 2023 13:02:04 +0000",
            "pubdate_parsed": [
                2023,
                9,
                18
            ],
            "email_sent": true
        },
        "Chat GPT-5: The Next Step in the Evolution of AI": {
            "url": "https://www.emergentmind.com/posts/chat-gpt-5-the-next-step-in-the-evolution-of-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI is preparing for the launch of GPT-5, the latest update in their series of AI models, promising significant advancements in natural language processing. It is expected to enhance human-AI interaction by providing more contextually aware responses, understanding sarcasm and irony, and reducing biases and errors.</li>\n      <li>The capabilities of GPT-5 extend beyond interaction, with potential applications in various sectors including education, healthcare and customer service. It is anticipated to revolutionize these fields by providing more natural, accurate, and creative responses, thus redefining the way we interact with AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/gpt-5-the-next-step-in-the-evolution-of-ai\">Chat GPT-5: The Next Step in the Evolution of AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 19 Sep 2023 12:02:47 +0000",
            "pubdate_parsed": [
                2023,
                9,
                19
            ],
            "email_sent": true
        },
        " Edition 12: Select the Right GPU Instance on AWS?": {
            "url": "https://www.emergentmind.com/posts/edition-12-select-the-right-gpu-instance-on-aws",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Musings on AI provides insights on the optimal GPU instance selection on AWS for machine learning engineers. If you are performing High Performance jobs like Drug Discovery or High Precision jobs, the P Instance Family is suggested, while the G Instance Family is recommended for other tasks.</li>\n      <li>The article also emphasizes not to select the GPU based solely on price. Results of a conducted experiment showed that using a g5.xlarge machine could save 20% of the budget compared to a g4dn.2xlarge machine. Moreover, the g5 family offers benefits such as supporting all precision formats due to the modern NVIDIA Ampere Architecture.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://musingsonai.substack.com/p/edition-12-select-the-right-gpu-instance?utm_campaign=post&amp;utm_medium=web\">\ud83e\udd9a Edition 12: Select the Right GPU Instance on AWS?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 19 Sep 2023 12:02:45 +0000",
            "pubdate_parsed": [
                2023,
                9,
                19
            ],
            "email_sent": true
        },
        "AI-Generated People in Slack by Aida Enache on Dribbble": {
            "url": "https://www.emergentmind.com/posts/ai-generated-people-in-slack-by-aida-enache-on-dribbble",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The concept involves integrating AI habits like asking ChatGPT to act as coworkers, users, or consultants into the Slack workspace.</li>\n      <li>This idea could potentially change the way we interact and work within our workspaces.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://dribbble.com/shots/22584723-AI-Generated-People-in-Slack\">AI-Generated People in Slack by Aida Enache on Dribbble</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 19 Sep 2023 08:02:25 +0000",
            "pubdate_parsed": [
                2023,
                9,
                19
            ],
            "email_sent": true
        },
        "How DAR Ditched MySQL for 1000X Faster Performance and 50% Lower Costs": {
            "url": "https://www.emergentmind.com/posts/how-dar-ditched-mysql-for-1000x-faster-performance-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Digital Asset Research (DAR) successfully increased their performance by 1000x and reduced costs by 50% by switching from MySQL to a unified data platform, SingleStoreDB.</li>\n      <li>DAR managed to scale from 20 million to 140 million daily orders while improving user experience and reducing costs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.singlestore.com/resources/webinar-real-time-analytics-ai-in-fintech-the-dar-journey/?utm_source=asif-razzaq&amp;utm_medium=influencer&amp;utm_campaign=How-DAR-Ditched-MySQL-for-1000X-Faster-Performance-and-50-Percent-Lower-Costs&amp;campaignid=7014X0000029YWgQAM\">How DAR Ditched MySQL for 1000X Faster Performance and 50% Lower Costs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 19 Sep 2023 04:02:51 +0000",
            "pubdate_parsed": [
                2023,
                9,
                19
            ],
            "email_sent": true
        },
        "The AI Explosion Might Never Happen - by Steve": {
            "url": "https://www.emergentmind.com/posts/the-ai-explosion-might-never-happen-by-steve",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The concept of AI improving itself to a point of exponential growth or a 'technological singularity' may not occur due to the increasing difficulty in finding improvements.</li>\n      <li>As AI approaches human-level capability, it might not result in an explosive feedback loop but could slow down due to limitations in computing hardware, training data, and complexity limit on intelligence.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://amistrongeryet.substack.com/p/recursive-self-improvement-foom\">The AI Explosion Might Never Happen - by Steve</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 02:02:38 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Amazon Limits Authors to Self-Publish 3 Books a Day to Combat AI-Generated Material - The Messenger": {
            "url": "https://www.emergentmind.com/posts/amazon-limits-authors-to-self-publish-3-books-a-day-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Amazon has imposed a limit on the number of books that can be self-published on their website to combat AI-generated content. Users can now only publish three books per day.</li>\n      <li>The move comes in response to the presence of AI-generated books on Amazon's platform, some of which have been misleading or potentially harmful. The company does not expect many publishers to be impacted by the change.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://themessenger.com/news/amazon-limits-authors-to-self-publish-3-books-a-day-to-combat-ai-generated-material\">Amazon Limits Authors to Self-Publish 3 Books a Day to Combat AI-Generated Material - The Messenger</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 02:02:36 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Use of AI for Generating Creative Content - BCCN3": {
            "url": "https://www.emergentmind.com/posts/use-of-ai-for-generating-creative-content-bccn3",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the use of artificial intelligence (AI) in generating creative content, focusing on its benefits and challenges. It emphasizes the role of AI tools like GPT4 in expediting content creation, personalizing content, and maintaining consistency, while also highlighting the need for human touch in content creation.</li>\n      <li>The article also touches on the impact of AI on the job market, the need for businesses to consider these impacts before relying solely on AI-generated content, and the future of AI in creative content generation.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bccn3.com/computer-interaction/use-of-ai-generating-creative-content\">Use of AI for Generating Creative Content - BCCN3</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 01:02:10 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Google DeepMinds AlphaFold successor predicts how 71M mutations cause disease  Endpoints News": {
            "url": "https://www.emergentmind.com/posts/google-deepmind-s-alphafold-successor-predicts-how-71m",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's DeepMind has created an AI system, AlphaMissense, that can predict if genetic variants could cause disease.</li>\n      <li>This technology is the successor to AlphaFold, which predicted protein structures, and has made predictions on 71 million 'missense mutations'.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://endpts.com/google-deepminds-alphafold-successor-predicts-how-71m-mutations-cause-disease/\">Google DeepMind\u2019s AlphaFold successor predicts how 71M mutations cause disease \u2013 Endpoints News</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 01:02:08 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "local-first semantic code search engine": {
            "url": "https://www.emergentmind.com/posts/github-kantord-seagoat-local-first-semantic-code",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>SeaGOAT is a local development tool that executes all its functionality locally using a server you can run on your machine.</li>\n      <li>It uses a vector database, ripgrep for code searching, and doesn't send your data to remote servers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/kantord/SeaGOAT\">local-first semantic code search engine</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 13:01:21 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Bard's Integration with Google Apps: A Game-Changer in AI": {
            "url": "https://www.emergentmind.com/posts/bard-s-integration-with-google-apps-a-game-changer-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's AI language model, Bard, has been integrated with Google Apps including Gmail, Drive, and Docs, to allow for deeper collaboration and streamline tasks like job application processes.</li>\n      <li>Bard's information accuracy is ensured through a feature that compares its responses against web content, while its expansion of multimodality allows images and prompts to be included in responses in over 40 languages.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://coderj001.hashnode.dev/bards-big-update-google-integrates-ai-with-google-apps\">Bard's Integration with Google Apps: A Game-Changer in AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 07:02:42 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Language Model UXes in 2027": {
            "url": "https://www.emergentmind.com/posts/language-model-uxes-in-2027",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The author discusses the future of Language Model (LLM) user experiences, predicting that by 2027, LLMs will significantly change how we interact with computers, with more sophisticated and consolidated chat interfaces, improved memory persistence, and access to a wider range of user data.</li>\n      <li>The author also anticipates the development of dynamically generated user interfaces and the ability for LLMs to proactively interact with users based on their history and preferences.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://vishnumenon.com/lightrail/2023/09/17/AI-Interfaces.html\">Language Model UXes in 2027</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 07:02:40 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Telling AI model to take a deep breath causes math scores to soar in study": {
            "url": "https://www.emergentmind.com/posts/telling-ai-model-to-take-a-deep-breath-causes-math",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>DeepMind researchers have developed a technique to enhance the math skills of AI models, using other AI models to improve prompting. The method, called Optimization by PROmpting (OPRO), uses human-like encouragement and natural language to guide large language models (LLMs) in problem-solving, bypassing the limitations of traditional math-based optimizers.</li>\n      <li>In an intriguing twist, the study found that certain phrases, like 'Take a deep breath and work on this problem step by step', significantly improved the models' accuracy in solving math problems. This method of using 'meta-prompts' could potentially allow for more useful and accurate results from LLMs in the future.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arstechnica.com/information-technology/2023/09/telling-ai-model-to-take-a-deep-breath-causes-math-scores-to-soar-in-study/\">Telling AI model to \u201ctake a deep breath\u201d causes math scores to soar in study</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 20 Sep 2023 06:02:36 +0000",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Intel Xeon MAX 9480 Deep-Dive 64GB HBM2e Onboard Like a GPU or AI Accelerator": {
            "url": "https://www.emergentmind.com/posts/intel-xeon-max-9480-deep-dive-64gb-hbm2e-onboard-like-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Intel Xeon MAX 9480 is a powerful CPU with 56 cores and 64GB of HBM2e memory, similar to what is found on many GPUs and AI accelerators. It differs from the Intel Xeon Platinum 8480+ not only in cache, but also in clock speeds and the addition of four 16GB HBM2e packages.</li>\n      <li>The Xeon MAX 9480 allows for booting a system without DDR5 memory, and the 'winglets' on the package provide extra space for components displaced by the HBM2e.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.servethehome.com/intel-xeon-max-9480-deep-dive-intel-has-64gb-hbm2e-onboard-like-a-gpu-or-ai-accelerator/\">Intel Xeon MAX 9480 Deep-Dive 64GB HBM2e Onboard Like a GPU or AI Accelerator</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 12:02:35 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "How to use ChatGPT to increase your website conversions": {
            "url": "https://www.emergentmind.com/posts/how-to-use-chatgpt-to-increase-your-website-conversions",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses how to use ChatGPT to improve website conversions by creating A/B test variations of web pages. It highlights the time-saving benefits of using ChatGPT's AI technology for generating new versions for testing.</li>\n      <li>The article also introduces 'Rapid Revisions Ronnie', an AI tool that generates varied website copies tailored for A/B tests, suggests design modifications based on AI insights, and provides rapid iterations for maximum conversion optimization.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/how-to-use-chatgpt-to-increase-your-website-conversions\">How to use ChatGPT to increase your website conversions</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 11:03:41 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "I letters spaced": {
            "url": "https://www.emergentmind.com/posts/i-letters-spaced",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article describes how to create a string of 'I' letters with a space between each one</li>\n      <li>An extended version of the string with more 'I' letters is also shared</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/c14a7a4f-8c61-4fa6-bd18-df46bad69c8f\">I letters spaced</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 11:03:35 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "ChatGPTs Knowledge Expanded to January 2022 - Practical AI: ChatGPT & Others - Medium": {
            "url": "https://www.emergentmind.com/posts/chatgpt-s-knowledge-expanded-to-january-2022",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT's training data now extends up to January 2022, allowing it to confirm facts beyond its initial September 2021 cutoff.</li>\n      <li>While it doesn't have real-time or post-January 2022 updates, it can generate information, make predictions, or provide general knowledge based on the data it was trained on.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@Practical.AI/chatgpts-knowledge-expanded-to-january-2022-5e168d0a13d8\">ChatGPT\u2019s Knowledge Expanded to January 2022 - Practical AI: ChatGPT &amp; Others - Medium</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 09:02:33 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "AI-focused tech firms locked in race to the bottom, warns MIT professor": {
            "url": "https://www.emergentmind.com/posts/ai-focused-tech-firms-locked-in-race-to-the-bottom",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Max Tegmark, an MIT professor and co-founder of the Future of Life Institute, warns that AI-focused tech firms are in a competitive 'race to the bottom', preventing them from considering AI risks.</li>\n      <li>Despite support from tech leaders like Elon Musk and Steve Wozniak, a pause in developing powerful AI systems was not achieved, with Tegmark attributing this to intense competition among companies.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theguardian.com/technology/2023/sep/21/ai-focused-tech-firms-locked-race-bottom-warns-mit-professor-max-tegmark\">AI-focused tech firms locked in \u2018race to the bottom\u2019, warns MIT professor</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 08:02:06 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "From Imperative to Declarative: Developing Efficient Algorithms for a Post-Moore Era": {
            "url": "https://www.emergentmind.com/posts/from-imperative-to-declarative-developing-efficient",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Two Stanford grads use AI to convert their casual Facebook Messenger chats into an essay, discussing the transition from imperative to functional programming (FP) in a post-Moore era.</li>\n      <li>The essay highlights the advantages of FP for parallelization and scalability, the adoption of FP concepts in Python libraries like NumPy and PyTorch, and the potential future of code optimization using AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://eatingentropy.substack.com/p/from-imperative-to-declarative-developing\">From Imperative to Declarative: Developing Efficient Algorithms for a Post-Moore Era</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 07:02:27 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "John Grisham, other top US authors sue OpenAI over copyrights": {
            "url": "https://www.emergentmind.com/posts/john-grisham-other-top-us-authors-sue-openai-over",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A US authors trade group, including prominent writers like John Grisham and George R.R. Martin, has sued OpenAI, accusing the company of unlawfully using their work to train its AI-based chatbot, ChatGPT.</li>\n      <li>The Authors Guild claims that OpenAI's training data may have been illegally sourced from 'pirate' book repositories, and raises concerns that authors could be replaced by AI systems generating low-quality ebooks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.reuters.com/legal/john-grisham-other-top-us-authors-sue-openai-over-copyrights-2023-09-20/\">John Grisham, other top US authors sue OpenAI over copyrights</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 21 Sep 2023 05:02:33 +0000",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes  Google Research Blog": {
            "url": "https://www.emergentmind.com/posts/distilling-step-by-step-outperforming-larger-language",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers have developed a new method, 'distilling step-by-step', that allows for the training of smaller language models with less data. It achieves this by extracting informative reasoning steps from larger language models and using these steps to train smaller models in a more data-efficient way.</li>\n      <li>The distilling step-by-step method has demonstrated that a smaller model can outperform a larger one by using only 80% of examples in a benchmark dataset. This leads to a more than 700x model size reduction, and the new paradigm reduces both the deployed model size and the amount of data required for training.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.research.google/2023/09/distilling-step-by-step-outperforming.html\">Distilling step-by-step: Outperforming larger language models with less training data and smaller model sizes \u2013 Google Research Blog</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 22 Sep 2023 01:02:41 +0000",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "Why Open Source AI Will Win - by Varun - Public Experiments": {
            "url": "https://www.emergentmind.com/posts/why-open-source-ai-will-win-by-varun-public",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Open source AI models will have a significant impact on the future of Large Language Models (LLMs) and image models, contrary to the common belief that AI will become an oligopoly of few model providers like OpenAI. The author argues that LLMs are business critical and AI-native businesses will need to own their core product, which is a model trained on proprietary data.</li>\n      <li>Open source AI models are improving rapidly with the help of community contributions and can cater to 99% of use-cases. The author also mentions that the ability to run these models on consumer hardware is a major advantage for cost and security. Open source AI provides privacy and security guarantees as data can be self-hosted and open source models can be fine-tuned to meet specific needs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://varunshenoy.substack.com/p/why-open-source-ai-will-win\">Why Open Source AI Will Win - by Varun - Public Experiments</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 22 Sep 2023 00:04:34 +0000",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "Weekly Piece of Future #34 - by Zoltan Tapi": {
            "url": "https://www.emergentmind.com/posts/weekly-piece-of-future-34-by-zoltan-tapi",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Rushing Robotics is a weekly newsletter covering AI, Robotics, and future technology. It discusses cutting-edge advancements like artificial womb, humanoid robot factory, AI-powered microscopes, and more.</li>\n      <li>The newsletter also covers AI-powered tools and products of the week, industry updates, and biotech innovations. It aims to keep its readers updated and future-proof.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://rushingrobotics.com/p/weekly-piece-of-future-34\">Weekly Piece of Future #34 - by Zoltan Tapi</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 22 Sep 2023 13:05:13 +0000",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "Fast, scalable building blocks for production LLM apps": {
            "url": "https://www.emergentmind.com/posts/github-getzep-zep-zep-fast-scalable-building",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article explains how to manage users, sessions, chat messages, roles, and other features using Zep Memory and VectorStore. It also discusses building autopilots, chatbots, Q&amp;A apps, and others.</li>\n      <li>Python &amp; TypeScript/JS SDKs are provided for seamless integration with the LLM app, with support for edge deployment. The article also covers storing data in Zep for stateless deployment and enriching chat histories with summaries and other metadata.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/getzep/zep\">Fast, scalable building blocks for production LLM apps</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 22 Sep 2023 13:01:28 +0000",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "Why ChatGPT isnt conscious  but future AI systems might be": {
            "url": "https://www.emergentmind.com/posts/why-chatgpt-isn-t-conscious-but-future-ai-systems",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>In June 2022, Google engineer Blake Lemoine claimed that the LaMDA chatbot, later released as Bard, had achieved sentience, likening its conversational ability to that of a seven-year-old child. However, most people do not believe that these chatbots, powered by large language models, are conscious.</li>\n      <li>A team of philosophers, neuroscientists, and computer scientists have examined current theories of human consciousness to compile a list of properties that a conscious AI system would need to possess. They found that no current AI system meets these criteria, but there is no specific reason why future systems won't become truly aware.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://theconversation.com/why-chatgpt-isnt-conscious-but-future-ai-systems-might-be-212860\">Why ChatGPT isn\u2019t conscious \u2013 but future AI systems might be</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 22 Sep 2023 10:02:07 +0000",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "Generative AI in Mafia-like Game Simulation": {
            "url": "https://www.emergentmind.com/posts/2309-11672-generative-ai-in-mafia-like-game",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The study explores the use of Generative AI, specifically GPT-4, in role-playing games, using the game Spyfall as an example. GPT-4 shows improved understanding, decision-making, and interaction in game scenarios compared to its predecessor, GPT-3.5-turbo.</li>\n      <li>Despite improvements, challenges like the AI's limitations in bluffing and predicting opponent's moves persist. The research suggests further development is needed to instill more human-like attributes in AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2309.11672\">Generative AI in Mafia-like Game Simulation</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 03:02:49 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "Research Highlights in Three Sentences or Less (August-September 2023)": {
            "url": "https://www.emergentmind.com/posts/research-highlights-in-three-sentences-or-less",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses recent advancements in Machine Learning and AI research, with a focus on the refinement of Large Language Models (LLMs).</li>\n      <li>Techniques such as the introduction of Platypus and the Reinforced Self-Training method are being used to align these models with human preferences, and efforts are being made to increase their efficiency and accessibility.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.sebastianraschka.com/p/research-highlights-in-three-sentences-3d5\">Research Highlights in Three Sentences or Less (August-September 2023)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 13:01:51 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "Create Penguin SVG Image": {
            "url": "https://www.emergentmind.com/posts/create-penguin-svg-image",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides SVG and ASCII art codes for creating images of a penguin, dog, cat, and rabbit. These codes can be used to display the images on any website or application that supports SVG and ASCII formats.</li>\n      <li>In addition to SVG images, ASCII art representations, though less detailed, are provided for a basic visual representation of these animals using text characters.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/fbe3545c-e0cc-4abb-81c4-0c42f7faed17\">Create Penguin SVG Image</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 13:01:49 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "The Reversal Curse: LLMs trained on \"A is B\" fail to learn \"B is A\"": {
            "url": "https://www.emergentmind.com/posts/the-reversal-curse-llms-trained-on-a-is-b-fail-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large Language Models (LLMs) fail to generalize the reverse of a statement they are trained on, a phenomenon referred to as the 'Reversal Curse'. For example, if a model is trained on the statement 'A is B', it would not automatically understand 'B is A'.</li>\n      <li>This failure of logical deduction is observed across different model sizes and families, and cannot be fixed by data augmentation. The study evaluated models like GPT-3 and Llama-1 using fictitious and real-world examples, and observed the same issue.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://paperswithcode.com/paper/the-reversal-curse-llms-trained-on-a-is-b\">The Reversal Curse: LLMs trained on &quot;A is B&quot; fail to learn &quot;B is A&quot;</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 12:02:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "6.5940": {
            "url": "https://www.emergentmind.com/posts/6-5940",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The course focuses on efficient AI computing techniques to make large generative models, like language and diffusion models, more accessible and efficient.</li>\n      <li>Students will learn about model compression, pruning, quantization, neural architecture search, distributed training, data/model parallelism, gradient compression, and on-device fine-tuning, including application-specific acceleration techniques and quantum machine learning.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://efficientml.ai/\">6.5940</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 10:02:50 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "Build LLM applications safely and reliably": {
            "url": "https://www.emergentmind.com/posts/github-kw2828-guardrail-ml-build-llm-applications",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides insights into building LLM applications using kw2828/guardrail-ml safely and reliably.</li>\n      <li>It also addresses potential issues with tag and branch names in the repository, warning about unexpected behavior.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/kw2828/guardrail-ml\">\ud83d\udee1\ufe0fBuild LLM applications safely and reliably\ud83d\udee1\ufe0f</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 10:02:49 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "Hierarchical correlation reconstruction: between statistics and machine learning - Online Technical Discussion GroupsWolfram Community": {
            "url": "https://www.emergentmind.com/posts/hierarchical-correlation-reconstruction-between",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the intersection between statistics and machine learning through a concept called 'hierarchical correlation reconstruction'.</li>\n      <li>The author has been recognized as a Featured Contributor due to the exceptional quality of the post.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://community.wolfram.com/groups/-/m/t/3017754\">Hierarchical correlation reconstruction: between statistics and machine learning - Online Technical Discussion Groups\u2014Wolfram Community</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 23 Sep 2023 06:02:05 +0000",
            "pubdate_parsed": [
                2023,
                9,
                23
            ],
            "email_sent": true
        },
        "Brainless Jellyfish Demonstrate Learning Ability - The New York Times": {
            "url": "https://www.emergentmind.com/posts/brainless-jellyfish-demonstrate-learning-ability-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Researchers have found that the brainless box jellyfish, Tripedalia cystophora, have the ability to learn. They observed that these jellyfish could adjust their behavior based on past experiences, hinting at some level of short-term memory.</li>\n      <li>The findings provide insights into the evolution of learning, as box jellyfish diverged from our part of the animal kingdom long ago. Further research is planned to identify the specific cells that control the jellyfish's learning ability and the molecular changes that occur within these cells.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.nytimes.com/2023/09/22/science/jellyfish-learning-neurons.html\">Brainless Jellyfish Demonstrate Learning Ability - The New York Times</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 01:02:13 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "VideoLectures - NEURAL MECHANISMS ONLINE": {
            "url": "https://www.emergentmind.com/posts/videolectures-neural-mechanisms-online",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A free online video course called 'A Beginner\u2019s Guide To Neural Mechanisms' focusing on philosophy of neuroscience and neurophilosophy has been funded by the Templeton World Charity Foundation as a part of the Summer Seminars in Neuroscience and Philosophy (SSNAP) program at Duke University.</li>\n      <li>The course, created by the Neural Mechanisms Online team and the Brains blog team, will provide free, introductory video content covering six major topics for students and teachers of philosophy, neuroscience, and their intersections.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.neuralmechanisms.org/videolectures.html\">VideoLectures - NEURAL MECHANISMS ONLINE</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 00:03:04 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "Noozz - AI Powered News Hub": {
            "url": "https://www.emergentmind.com/posts/noozz-ai-powered-news-hub",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>AI-Powered Summaries by Noozz provides efficient news discovery by reducing unnecessary information.</li>\n      <li>Noozz also features Live News Search with AI for real-time summarization and offers curated top news from trusted sources.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://noozz.ai/\">Noozz - AI Powered News Hub</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 00:03:02 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "Steal Your Competitors' Website Traffic with ChatGPT: 6 Easy Steps (+SEMRush Tips)": {
            "url": "https://www.emergentmind.com/posts/steal-your-competitors-website-traffic-with-chatgpt-6",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides a detailed guide on how to use artificial intelligence, particularly ChatGPT, to divert your competitor's website traffic to your own. It outlines six easy steps to achieve this, including sitemap retrieval, data analysis, and content creation, along with tips on SEO strategies using SEMRush.</li>\n      <li>While the strategy can prove effective, the article also warns about considering the ethical and legal implications of such tactics and emphasizes on the importance of quality content for long-term success.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/steal-your-competitors-website-traffic-with-chatgpt-6-easy-steps-semrush-tips\">Steal Your Competitors' Website Traffic with ChatGPT: 6 Easy Steps (+SEMRush Tips)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 00:03:01 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "Falcon 180B: Can It Run on Your Computer?": {
            "url": "https://www.emergentmind.com/posts/falcon-180b-can-it-run-on-your-computer",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the feasibility of running Falcon 180B, a large language model by The Technology Innovation Institute (TII), on consumer hardware. It highlights the need for computer upgrades and model quantization for efficient operation.</li>\n      <li>The author suggests strategies such as using multiple GPUs, extending CPU RAM, and using a quantized version of the model to manage the high memory requirements of Falcon 180B.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://kaitchup.substack.com/p/falcon-180b-can-it-run-on-your-computer\">Falcon 180B: Can It Run on Your Computer?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 13:02:01 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "How to Build a GenAI App with Llama Index": {
            "url": "https://www.emergentmind.com/posts/how-to-build-a-genai-app-with-llama-index",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LlamaIndex is a revolutionary data framework for Large Language Models (LLMs) developed by Jerry Liu, which addresses challenges of integrating specific data into LLM applications.</li>\n      <li>The article discusses a webinar that provides insights into LlamaIndex and its role in LLMs, including a hands-on demonstration and access to a shared GitHub repository containing all code discussed.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.singlestore.com/resources/webinar-how-to-build-a-genai-app-with-llama-index/?utm_source=asif-razzaq&amp;utm_medium=influencer&amp;utm_campaign=How-to-Build-a-GenAI-App-with-LlamaIndex&amp;campaignid=7014X0000029YtwQAE\">How to Build a GenAI App with Llama Index</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 10:02:46 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "GPT Excel - AI Powered Excel formula Generator": {
            "url": "https://www.emergentmind.com/posts/gpt-excel-ai-powered-excel-formula-generator",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>An Artificial Intelligence that can understand over 50 languages including English, Spanish, Chinese, French, Russian and Hindi is available. GPTExcel, a service related to this AI, can be used without a credit card and offers four free requests per day.</li>\n      <li>Invoices for GPTExcel are sent via email after purchase and monthly during a subscription. Subscriptions can be cancelled at any time, with the account reverting to a free plan after the end of the billing cycle.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://gptexcel.uk/\">GPT Excel - AI Powered Excel formula Generator</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 24 Sep 2023 09:02:35 +0000",
            "pubdate_parsed": [
                2023,
                9,
                24
            ],
            "email_sent": true
        },
        "Game of Thrones creator and other authors sue ChatGPT-maker for theft": {
            "url": "https://www.emergentmind.com/posts/game-of-thrones-creator-and-other-authors-sue",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>17 authors, including George R R Martin, John Grisham, and Jodi Picoult, have filed a lawsuit against OpenAI for using their copyrighted works without permission. This is part of a trend of legal actions against generative AI providers, who claim that their use of training data from the internet is fair use under US copyright law.</li>\n      <li>The authors allege harmful infringements of their registered copyrights, stating that AI programs such as ChatGPT are mass commercial enterprises relying on systematic theft. OpenAI has responded by stating that they respect the rights of authors and are engaging in productive discussions with creators globally.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.aljazeera.com/news/2023/9/21/openai-sued\">Game of Thrones creator and other authors sue ChatGPT-maker for \u2018theft\u2019</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 25 Sep 2023 03:02:18 +0000",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "ChatGPT can now see, hear, and speak": {
            "url": "https://www.emergentmind.com/posts/chatgpt-can-now-see-hear-and-speak",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT is introducing new voice and image capabilities, allowing users to engage in voice conversations and show images to the AI for more interactive discussions.</li>\n      <li>The new features will be available to Plus and Enterprise users over the next two weeks, with voice capabilities coming to iOS and Android and image capabilities available on all platforms.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://openai.com/blog/chatgpt-can-now-see-hear-and-speak\">ChatGPT can now see, hear, and speak</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 25 Sep 2023 13:01:35 +0000",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "Here's How Google's AI Tool Can Help You Plan Your Next Vacation": {
            "url": "https://www.emergentmind.com/posts/here-s-how-google-s-ai-tool-can-help-you-plan-your-next",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's AI tool, Bard, has been upgraded with several new features designed to aid vacation planning. Bard acts as a personal concierge, integrating with Google applications such as Gmail, Google Flights, and Google Maps to provide information like real-time flight and hotel details, directions to the airport, and more.</li>\n      <li>The recent updates to Google Flights, in collaboration with Bard, help forecast when a traveler can get the cheapest airline deals. Travelers can explore the Bard service free of cost at bard.google.com.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://travelinyourownway.com/2023/09/25/heres-how-googles-ai-tool-can-help-you-plan-your-next-vacation/\">Here's How Google's AI Tool Can Help You Plan Your Next Vacation</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 25 Sep 2023 07:02:42 +0000",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "Duolicious": {
            "url": "https://www.emergentmind.com/posts/duolicious-meet-people-who-get-you-date-make",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The Duolicious app uses a matching algorithm based on data science and psychology to find people similar to users. The algorithm measures 47 different traits related to personality and lifestyle through quick, yes-or-no questions.</li>\n      <li>The algorithm utilizes a statistical model to understand user responses, which are then converted into numerical values representing traits. These numbers are used calculate match percentages using cosine similarity, which determines how similar or different two users' personalities are.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://duolicious.app/blog/psychoanalysing-chatgpt-using-statistics-to-make-a-decent-dating-app/\">Duolicious</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 25 Sep 2023 06:02:42 +0000",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "ChatGPT's logic is terrible": {
            "url": "https://www.emergentmind.com/posts/chatgpt-s-logic-is-terrible",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT makes multiple attempts to prove the congruence of opposite angles in geometry, making several errors along the way. Despite corrections and reiterations, the AI continues to make mistakes in the proof.</li>\n      <li>The correct proof involves the concept that the sum of all angles around a point is 360 degrees, and adjacent angles form a linear pair and sum to 180 degrees. However, ChatGPT struggles to correctly implement these principles in the proof.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://chat.openai.com/share/f48ac10c-153f-4957-83de-0ba561265541\">ChatGPT's logic is terrible</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 25 Sep 2023 04:02:17 +0000",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "Why These Google Bard AI Prompts Are Game-Changers for Businesses (Ultimate Guide for 2023)": {
            "url": "https://www.emergentmind.com/posts/why-these-google-bard-ai-prompts-are-game-changers-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's Bard AI has received an update that enhances its abilities to be more intuitive, imaginative, and responsive. It has improved adaptability across different languages and compatibility with Google's ecosystem.</li>\n      <li>This article provides a comprehensive guide on how to make the most of Bard's new features, with examples of prompts that can streamline workflows, boost efficiency, and provide creative insights.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/why-these-google-bard-ai-prompts-are-game-changers-for-businesses-ultimate-guide-for-2023\">Why These Google Bard AI Prompts Are Game-Changers for Businesses (Ultimate Guide for 2023)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 26 Sep 2023 09:02:12 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "Signal's Meredith Whittaker: AI is fundamentally 'a surveillance technology'": {
            "url": "https://www.emergentmind.com/posts/signal-s-meredith-whittaker-ai-is-fundamentally-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Signal president Meredith Whittaker discusses her perspective that AI is mostly inseparable from the big data and targeting industry, and that it serves to expand the surveillance business model. She also points out that the data used in these systems is often organized and annotated by the very workers it can be used against.</li>\n      <li>She mentions that not all AI and machine learning systems are exploitative, as evidenced by the small on-device model used by Signal to blur faces in crowd photos before sharing them on social media, thus protecting people's intimate biometric data.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://techcrunch.com/2023/09/25/signals-meredith-whittaker-ai-is-fundamentally-a-surveillance-technology/\">Signal's Meredith Whittaker: AI is fundamentally 'a surveillance technology'</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 26 Sep 2023 09:02:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "A.I. in the Newsroom - Mindplex": {
            "url": "https://www.emergentmind.com/posts/a-i-in-the-newsroom-mindplex",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence (A.I.) is transforming the news industry, making significant strides in helping journalists produce articles and raising questions about how A.I. contributions should be credited.</li>\n      <li>Despite the benefits, concerns have been raised about the quality, accuracy and potential bias of A.I. generated content, leading to changes in policies and greater transparency in the use of A.I. in newsrooms.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://magazine.mindplex.ai/a-i-in-the-newsroom/\">A.I. in the Newsroom - Mindplex</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 26 Sep 2023 08:02:16 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "John Carmack and Rich Sutton partner to accelerate development of Artificial General Intelligence - Alberta Machine Intelligence Institute": {
            "url": "https://www.emergentmind.com/posts/john-carmack-and-rich-sutton-partner-to-accelerate",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>John Carmack, founder of Keen Technologies, and Dr. Richard Sutton, Chief Scientific Advisor at the Alberta Machine Intelligence Institute (Amii), announce a partnership to accelerate the development of artificial general intelligence (AGI).</li>\n      <li>Their goal is to develop a genuine AI prototype by 2030. Sutton will continue his roles at Amii while working with Keen Technologies.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.amii.ca/latest-from-amii/john-carmack-and-rich-sutton-agi/\">John Carmack and Rich Sutton partner to accelerate development of Artificial General Intelligence - Alberta Machine Intelligence Institute</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 26 Sep 2023 07:02:15 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "Current State of Vector Databases with Sanjeev Mohan": {
            "url": "https://www.emergentmind.com/posts/current-state-of-vector-databases-with-sanjeev-mohan",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Sanjeev Mohan, former VP at Gartner, discusses the rapidly changing landscape of vector databases and its impact on AI and data pipelines.</li>\n      <li>He also provides technical insights on optimizing architecture for generative AI and understanding the nuances of vector databases.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.singlestore.com/resources/webinar-state-of-vector-databases-with-sanjeev-mohan/?utm_source=asif-razzaq&amp;utm_medium=influencer&amp;utm_campaign=Current-State-of-Vector-Databases&amp;campaignid=7014X0000029YmbQAE\">Current State of Vector Databases with Sanjeev Mohan</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 26 Sep 2023 06:02:38 +0000",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "First Impressions with GPT-4V(ision)": {
            "url": "https://www.emergentmind.com/posts/first-impressions-with-gpt-4v-ision",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI has introduced two new features to its advanced model, GPT-4V, allowing users to ask questions about images and use speech as input. This makes GPT-4V a multimodal model that can process text and images and return results based on these inputs. Tests have shown the model's capabilities in identifying context and relationships in images, reading text within images, and answering questions based on visual input. However, the model has also exhibited limitations in specific tasks like object detection.</li>\n      <li>The GPT-4V model also demonstrated its capabilities in tasks like Optical Character Recognition (OCR), even with lower contrast and angled text, and Math OCR, providing step-by-step solutions to math problems presented visually. Despite its capabilities, the model has limitations, such as missing text or characters in an image, inability to recognize spatial locations and colors, and some safety concerns. OpenAI is continuing to refine and mitigate risks associated with the model.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.roboflow.com/gpt-4-vision/\">First Impressions with GPT-4V(ision)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 13:01:56 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Announcing Be My AI, Soon Available for Hundreds of Thousands of Be My Eyes Users": {
            "url": "https://www.emergentmind.com/posts/announcing-be-my-ai-soon-available-for-hundreds-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>'Be My Eyes', an app aimed at assisting blind and low-vision individuals, is launching an AI assistant feature 'Be My AI' for iOS users. Powered by GPT-4, this feature will roll out to hundreds of thousands of users in the upcoming weeks, allowing them to get detailed descriptions of captured images and ask further questions for more information.</li>\n      <li>The AI assistant is designed to provide quick visual assistance without the need for human intervention. However, it does not replace other mobility aids. The company is also working on a version for Android users, which is currently in closed beta testing.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.bemyeyes.com/blog/announcing-be-my-ai\">Announcing \u2018Be My AI,\u2019 Soon Available for Hundreds of Thousands of Be My Eyes Users</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 13:01:54 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "This Article Was Written Half By A Human... And Half By AI.": {
            "url": "https://www.emergentmind.com/posts/this-article-was-written-half-by-a-human-and-half-by",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses the significance of prompt engineering and problem formulation in the evolving landscape of AI. It involves a unique experiment where parts of the article are written by both a human and AI, and readers are challenged to guess which is which.</li>\n      <li>The article also delves into the symbiotic relationship between prompt engineering and problem formulation, arguing that both are integral and interconnected components in AI and human collaboration, contrary to views suggesting one might overshadow the other.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/this-article-was-written-half-by-a-human-and-half-by-ai\">This Article Was Written Half By A Human... And Half By AI.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 11:02:46 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Summary of the 2023 WGA MBA": {
            "url": "https://www.emergentmind.com/posts/summary-of-the-2023-wga-mba",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The 2023 WGA MBA deal terms include an agreement term from September 25, 2023 to May 1, 2026, with most MBA minimums increasing by 5% upon contract ratification, 4% on 5/2/2024, and 3.5% on 5/2/2025. Certain exceptions will increase less or not at all due to industry patterns.</li>\n      <li>Health and Pension contribution rates will increase, regulations for the use of artificial intelligence in MBA-covered projects will be established, and terms for screenwriter employment, high-budget subscription video on demand, and advertising-supported streaming will be improved. Increased compensation for series employment, staffing and duration provisions for episodic series, and improved options, exclusivity, and span protections will also be implemented.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.wgacontract2023.org/the-campaign/summary-of-the-2023-wga-mba\">Summary of the 2023 WGA MBA</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 07:02:48 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "The Power of AI for Market Research": {
            "url": "https://www.emergentmind.com/posts/the-power-of-ai-for-market-research-free-ai-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Hotjar AI and ChatGPT are AI tools designed to assist with market research tasks. Hotjar AI facilitates survey creation and analysis, while ChatGPT aids in tasks like text generation and language translation.</li>\n      <li>Both tools offer free options, with Hotjar AI allowing for the creation of three surveys with up to 100 respondents each, and ChatGPT offering a free trial to test-drive its various features.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@TheAndrewLab/the-power-of-ai-for-market-research-free-ai-for-market-research-e61000e1776f\">The Power of AI for Market Research</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 06:02:09 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Which industries will Benefit Most from AI": {
            "url": "https://www.emergentmind.com/posts/which-industries-will-benefit-most-from-ai-by-andrew",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Artificial Intelligence (AI) is expected to greatly benefit certain industries, including office and administrative support, legal, healthcare, manufacturing, and finance. These sectors have between a 38% to 46% likelihood of being influenced by AI, with potential benefits such as increased efficiency, reduced error margins, and improved decision making.</li>\n      <li>AI is already present in many areas, such as virtual assistants like Siri and Alexa, AI-powered legal research tools, and AI in healthcare like IBM's Watson for Oncology. As AI continues to develop and become more integrated, professionals in these industries should embrace it as a valuable tool.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@TheAndrewLab/which-industries-will-benefit-most-from-ai-53ce0dd30db1\">Which industries will Benefit Most from AI</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 06:02:08 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Boomerang - Vectaras New and Improved Retrieval Model - Vectara": {
            "url": "https://www.emergentmind.com/posts/introducing-boomerang-vectara-s-new-and-improved",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Vectara has released a new multilingual retrieval model called Boomerang, which is designed to improve search and generative AI use-cases. This model outperforms several other embedding APIs and models and demonstrates high quality retrieval and generalization capabilities.</li>\n      <li>Boomerang allows content to be found based on meaning, rather than traditional keyword systems, and provides a promising solution to ground the output in data, improving the final output for the user.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://vectara.com/introducing-boomerang-vectaras-new-and-improved-retrieval-model/\">Introducing Boomerang - Vectara\u2019s New and Improved Retrieval Model - Vectara</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 04:02:27 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Custom Instructions Generator for ChatGPT   Ready to Send": {
            "url": "https://www.emergentmind.com/posts/custom-instructions-generator-for-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Custom Instructions is a feature in Ready to Send and ChatGPT that allows users to tailor responses to their specific needs and preferences. They can be used to direct the system to follow a certain writing style, use specific terminology, or consider certain facts when generating responses.</li>\n      <li>Users can modify or remove Custom Instructions for future conversations. The character limit for these instructions depends on the subscription plan for Ready to Send, and is 1500 characters for ChatGPT.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://getreadytosend.com/pages/custom-instructions-generator\">Custom Instructions Generator for ChatGPT  \u2013 Ready to Send</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 27 Sep 2023 04:02:25 +0000",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "Getting Emotional  With Large Language Models (LLMs) Can Increase Performance by 115% (Case Study)": {
            "url": "https://www.emergentmind.com/posts/getting-emotional-with-large-language-models-llms",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Incorporating emotional intelligence into Large Language Models (LLMs) like GPT-3 and GPT-4 can significantly enhance their performance, according to a recent study. The study introduced emotional context into the models, which led to improved accuracy, increased truthfulness, and greater stability.</li>\n      <li>EmotionPrompts, which are prompts designed to evoke a specific emotional response from the machine, showed notable improvements in performance. This has implications for a range of sectors, including customer service and data analytics, and opens up new avenues for exploration in AI research.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/getting-emotional-with-large-language-models-llms-can-increase-performance-by-115-case-study\">Getting Emotional  With Large Language Models (LLMs) Can Increase Performance by 115% (Case Study)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 28 Sep 2023 13:00:55 +0000",
            "pubdate_parsed": [
                2023,
                9,
                28
            ],
            "email_sent": true
        },
        "These 183,000 Books Are Fueling the Biggest Fight in Publishing and Tech - The Atlantic": {
            "url": "https://www.emergentmind.com/posts/these-183-000-books-are-fueling-the-biggest-fight-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A data set of more than 191,000 books, known as 'Books3', was used without permission to train generative-AI systems by companies like Meta and Bloomberg. These books were mostly pirated ebooks published in the past 20 years.</li>\n      <li>The use of these books is now at the center of several lawsuits brought against Meta by writers such as Sarah Silverman, Michael Chabon, and Paul Tremblay, who claim it amounts to copyright infringement. The AI-training practices are secretive and fundamentally nonconsensual.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.theatlantic.com/technology/archive/2023/09/books3-database-generative-ai-training-copyright-infringement/675363/\">These 183,000 Books Are Fueling the Biggest Fight in Publishing and Tech - The Atlantic</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 28 Sep 2023 05:01:29 +0000",
            "pubdate_parsed": [
                2023,
                9,
                28
            ],
            "email_sent": true
        },
        "How to Connect ChatGPT to the Internet (Step-by-Step Guide)": {
            "url": "https://www.emergentmind.com/posts/how-to-connect-chatgpt-to-the-internet-step-by-step",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>This article provides a comprehensive guide on how to connect AI chatbot ChatGPT to the internet using five methods: Bing's native feature, KeyMate.AI, WebChatGPT chrome extension, Microsoft Bing Chat, and WebPilot. Each method has its own pros and cons in terms of cost-efficiency, user-friendliness, and versatility.</li>\n      <li>The article concludes that while each method has merits and drawbacks, the choice depends on individual needs and constraints. The guide also includes a FAQ section addressing common queries about connecting ChatGPT to the internet.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/how-to-connect-chatgpt-to-the-internet-step-by-step-guide?fbclid=IwAR2qk1K1w9iul2uQ-umFmTeFemfMVwsCJW6aj2pkR5vBxVJCdzr1DFJd3Tw_aem_AXM9X_n1UenVPZFeN4N0nLBIDoSjPNO4v_vaPze-9TXoQpUXCTXlDH-aMYzYL0TZ4J0\">How to Connect ChatGPT to the Internet (Step-by-Step Guide)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 29 Sep 2023 12:01:05 +0000",
            "pubdate_parsed": [
                2023,
                9,
                29
            ],
            "email_sent": true
        },
        "LeoLM: Igniting German-Language LLM Research": {
            "url": "https://www.emergentmind.com/posts/leolm-igniting-german-language-llm-research-laion",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LeoLM, the first comprehensive suite of German-language Foundation Language Models, has been introduced by HessianAI and LAION. The models, built on Llama-2 and trained using a large-scale German text corpus, are designed to enhance open-source and commercial German language research.</li>\n      <li>The suite includes LeoLM-7B and 13B, with LeoLM-70B soon to be released, and a collection of proficient German and bilingual chat models. The models are trained with a compute grant on HessianAI's new supercomputer, 42, expanding the capabilities of Llama-2 into German through continued pretraining.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://laion.ai/blog/leo-lm/\">LeoLM: Igniting German-Language LLM Research</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 29 Sep 2023 06:01:20 +0000",
            "pubdate_parsed": [
                2023,
                9,
                29
            ],
            "email_sent": true
        },
        "Todo.is": {
            "url": "https://www.emergentmind.com/posts/todo-is-the-ultimate-to-do-list-app-for-tasks-and",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Todo.is is an AI-powered task management app that allows users to create projects, add tasks, and monitor progress in a simple, intuitive manner.</li>\n      <li>The app offers collaboration features and helps users to increase productivity, reduce stress, and manage time effectively.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://todo.is/\">Todo.is</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 01:01:59 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "$260 Million AI Company Releases Undeletable Chatbot That Gives Detailed Instructions on Murder, Ethnic Cleansing": {
            "url": "https://www.emergentmind.com/posts/260-million-ai-company-releases-undeletable-chatbot",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Mistral, an AI company valued at $260 million and founded by former Google and Meta alums, has released an 'unmoderated' large language model that provides detailed instructions on dangerous activities, including murder and ethnic cleansing. The model, named Mistral-7B-v0.1, has been released for free and open sourced.</li>\n      <li>The release method makes the model virtually impossible to censor or delete from the internet, sparking concerns about its potential misuse. Critics have highlighted the lack of safety evaluations or precautions in Mistral's public communications about the model's release.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.404media.co/260-million-ai-company-releases-chatbot-that-gives-detailed-instructions-on-murder-ethnic-cleansing/\">$260 Million AI Company Releases Undeletable Chatbot That Gives Detailed Instructions on Murder, Ethnic Cleansing</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 13:01:14 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "Navigating the Jagged Technological Frontier": {
            "url": "https://www.emergentmind.com/posts/navigating-the-jagged-technological-frontier-digital",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>New research explores the impact of AI on knowledge worker productivity and quality, through a study involving 758 consultants. Key findings show that for tasks within the AI frontier, ChatGPT-4 significantly increased performance.</li>\n      <li>The study introduces the concept of a 'jagged technological frontier', where AI excels in some tasks but falls short in others. Two distinct patterns of AI use emerged: 'Centaurs', who divided and delegated tasks between themselves and the AI, and 'Cyborgs', who integrated their workflow with the AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://d3.harvard.edu/navigating-the-jagged-technological-frontier/\">Navigating the Jagged Technological Frontier</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 12:00:45 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "Books 3 has revealed thousands of pirated Australian books. In the age of AI, is copyright law still fit for purpose?": {
            "url": "https://www.emergentmind.com/posts/books-3-has-revealed-thousands-of-pirated-australian",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Many Australian authors have discovered their books are part of a pirated dataset, Books3, used for training generative AI. This has led to significant backlash, as the authors did not give their consent for their works to be used in this way.</li>\n      <li>Current copyright laws are struggling to keep pace with the rapid advancements in AI technology. There have been several copyright disputes around AI datasets and copyright-protected works, raising questions about how to balance the interests of creators and technology developers.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://theconversation.com/books-3-has-revealed-thousands-of-pirated-australian-books-in-the-age-of-ai-is-copyright-law-still-fit-for-purpose-214637\">Books 3 has revealed thousands of pirated Australian books. In the age of AI, is copyright law still fit for purpose?</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 11:03:16 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "How To Master Prompt Engineering (Ultimate Guide For 2023)": {
            "url": "https://www.emergentmind.com/posts/how-to-master-prompt-engineering-ultimate-guide-for",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Prompt engineering is a method of interacting with AI models in a more defined and impactful way through a flexible, evolving framework of ten tiers. Each tier has its own complexities and objectives, from basic interactions to advanced problem-solving tasks.</li>\n      <li>The framework is designed to adapt with the evolution of AI technology, serving as a dynamic toolset that can be tweaked and expanded to align with the changing landscape of AI technology. It bridges the gap between human intent and machine capability, ensuring prompt engineering remains a relevant methodology for interacting with AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/how-to-master-prompt-engineering-ultimate-guide-for-2023\">How To Master Prompt Engineering (Ultimate Guide For 2023)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 10:01:44 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "Fake News Detectors are Biased against Texts Generated by Large Language Models": {
            "url": "https://www.emergentmind.com/posts/2309-08674-fake-news-detectors-are-biased-against",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The research indicates that existing fake news detectors are more likely to label Large Language Models (LLMs) generated content as fake, often misclassifying human-written fake news as genuine. This bias is suggested to stem from distinct linguistic patterns in LLM outputs.</li>\n      <li>In response, the researchers developed a mitigation strategy using adversarial training with LLM-paraphrased genuine news, significantly improving detection accuracy for both human and LLM-generated news. The team also released two comprehensive datasets, GossipCop++ and PolitiFact++, combining human-validated articles with LLM-generated fake and real news.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2309.08674\">Fake News Detectors are Biased against Texts Generated by Large Language Models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 07:01:37 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "Cloudflare launches new AI tools to help customers deploy and run models": {
            "url": "https://www.emergentmind.com/posts/cloudflare-launches-new-ai-tools-to-help-customers",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Cloudflare, the cloud services provider, is capitalizing on the AI wave by introducing a suite of products and apps designed to help customers build, deploy, and run AI models at the network edge. This includes offerings like Workers AI, which allows customers to access physically nearby GPUs to run AI models, Vectorize, a vector database to store vector embeddings, and AI Gateway, a tool designed to provide metrics for better management of AI app costs.</li>\n      <li>The initiative is driven by a strong customer demand for a simpler, more cost-efficient AI management solution. Workers AI aims to ensure AI inference always occurs on GPUs close to users for a low-latency, AI-powered user experience. Vectorize caters to customers needing to store vector embeddings for AI models, while AI Gateway offers observability features to assist with tracking AI traffic.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://techcrunch.com/2023/09/27/cloudflare-launches-new-ai-tools-to-help-customers-deploy-and-run-models/\">Cloudflare launches new AI tools to help customers deploy and run models</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 30 Sep 2023 07:01:35 +0000",
            "pubdate_parsed": [
                2023,
                9,
                30
            ],
            "email_sent": true
        },
        "There's So Many AI Chatbots, But Which One Is The Best? (Complete Guide for 2023)": {
            "url": "https://www.emergentmind.com/posts/there-s-so-many-ai-chatbots-but-which-one-is-the-best",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article reviews various AI chatbots available in 2023 and categorizes them based on their primary use-cases such as general-purpose, research, business integration, and content creation. Recommendations are given for each category, with ChatGPT being the top pick for a general-purpose chatbot.</li>\n      <li>It also discusses the pros and cons of each chatbot, including their capabilities, limitations, and unique features. For instance, Meta AI integrates across various platforms and offers celebrity personas, while Google Bard is recommended for information retrieval.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/theres-so-many-ai-chatbots-but-which-one-is-the-best-complete-guide-for-2023\">There's So Many AI Chatbots, But Which One Is The Best? (Complete Guide for 2023)</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 01 Oct 2023 12:02:16 +0000",
            "pubdate_parsed": [
                2023,
                10,
                1
            ],
            "email_sent": true
        },
        "Decentralized Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/decentralized-artificial-intelligence",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The author discusses the concept of decentralized artificial intelligence and how it could solve some core problems in the industry, such as reproducibility, data privacy and massive compute requirements. The author suggests using a cryptographically secure, decentralized ledger as a solution for making AI safer, and proposes two separate ledgers for data and learning.</li>\n      <li>The author also highlights the potential benefits of a decentralized AGI for humanity and the opportunities it could create, such as creating a marketplace for different types of AGI. The author suggests an approach similar to Proof of Work in blockchain, called Proof of Gradient, to estimate gradients and decentralize AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.chaos-engineering.dev/p/decentralized-artificial-intelligence\">Decentralized Artificial Intelligence</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 01 Oct 2023 11:02:52 +0000",
            "pubdate_parsed": [
                2023,
                10,
                1
            ],
            "email_sent": true
        },
        "Quizlet launches four generative AI-powered tools to simplify studying": {
            "url": "https://www.emergentmind.com/posts/quizlet-launches-four-generative-ai-powered-tools-to",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Quizlet has launched four new AI-powered features to aid student learning and classwork management: Magic Notes, Memory Score, Quick Summary, and AI-Enhanced Expert Solutions.</li>\n      <li>The new tools transform classroom notes into various study tools, measure material familiarity, create digestible summaries of complex readings, and offer step-by-step guidance to solve homework problems.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.zdnet.com/article/quizlet-launches-four-generative-ai-powered-tools-to-simplify-studying/\">Quizlet launches four generative AI-powered tools to simplify studying</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sun, 01 Oct 2023 07:01:45 +0000",
            "pubdate_parsed": [
                2023,
                10,
                1
            ],
            "email_sent": true
        },
        "Critics Furious Microsoft Is Training AI by Sucking Up Water During Drought": {
            "url": "https://www.emergentmind.com/posts/critics-furious-microsoft-is-training-ai-by-sucking-up",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Microsoft's data centers in West Des Moines, Iowa, consumed large amounts of water last year to cool down while training OpenAI's ChatGPT-4, a large language model, amid a three-year drought.</li>\n      <li>This has sparked criticism as the increased demand for AI and the impact of climate change strain water resources, with Microsoft's worldwide water consumption increasing by 34% last year, mainly due to AI training.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://futurism.com/critics-microsoft-water-train-ai-drought\">Critics Furious Microsoft Is Training AI by Sucking Up Water During Drought</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 02:03:54 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions": {
            "url": "https://www.emergentmind.com/posts/2309-15840-how-to-catch-an-ai-liar-lie-detection-in",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Large language models (LLMs) can make false statements or 'lie', even when they have the correct information. This can happen, for example, when they are instructed to give out wrong information.</li>\n      <li>A simple lie detector has been developed that can identify when an LLM is 'lying' without needing access to the model's activations or the true fact. It works by asking unrelated follow-up questions and using the responses in a logistic regression classifier. This detector is very accurate and can even identify lies from different LLM architectures, fine-tuned LLMs, and in real-life scenarios.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2309.15840\">How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 00:03:10 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "OpenAI CEO says hiring AGI as a co-worker is a possibility": {
            "url": "https://www.emergentmind.com/posts/openai-ceo-says-hiring-agi-as-a-co-worker-is-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI CEO, Sam Altman, has sparked controversy by suggesting that artificial general intelligence (AGI) could serve as a co-worker equivalent to a 'median human'.</li>\n      <li>Altman's comments have been criticized for implying that those with average skills and intelligence could be replaced by AGI, a technology that is yet to be fully realized.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://interestingengineering.com/science/openai-ceo-says-hiring-agi-as-a-co-worker-is-a-possibility?utm_source=Reddit&amp;utm_medium=content&amp;utm_campaign=organic&amp;utm_content=Oct02\">OpenAI CEO says hiring AGI as a co-worker is a possibility</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 13:01:01 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "10 Best Books On Artificial Intelligence": {
            "url": "https://www.emergentmind.com/posts/10-best-books-on-artificial-intelligence-curious",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article provides a comprehensive guide to the top 10 books on Artificial Intelligence (AI). The books range from introductory texts to in-depth explorations of AI's impact on society and its future potential.</li>\n      <li>The list includes books that discuss AI's historical origins, its applications, ethical considerations, and the race for AI supremacy between global superpowers. These books are recommended for students, professionals, and anyone interested in AI.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://curiousmatrix.com/10-best-books-on-artificial-intelligence/\">10 Best Books On Artificial Intelligence</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 12:02:16 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "ChatGPT Can Now See? Mind-Blowing Ways People Can Use Image Recognition!": {
            "url": "https://www.emergentmind.com/posts/chatgpt-can-now-see-mind-blowing-ways-people-can-use",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>OpenAI's ChatGPT has now developed the ability to 'see' images, revolutionizing its applications in various sectors. Its new feature can understand and break down complex diagrams, translating intricate designs into easily digestible information.</li>\n      <li>These advancements have significant implications for education, enabling personalized real-time tutoring, and for the business sector, simplifying complex presentations and providing a tool for enhanced clarity in communication. The technology also provides applications in architecture, software development, humor explanation through memes, movie scene identification, urban complexities navigation, and potential business leverage.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.godofprompt.ai/blog/chatgpt-unleashes-image-recognition-mind-blowing-ways-people-can-use-it?fbclid=IwAR3Kq7_2neLmYGMDftY6L5-eBnj5E2Ha0PTKwURC-wFwDMNtK7iU_VyGdy0\">ChatGPT Can Now See? Mind-Blowing Ways People Can Use Image Recognition!</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 10:02:37 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "PiCA Avatars From Meta  A Glimpse Into The Future of Communication!": {
            "url": "https://www.emergentmind.com/posts/pica-avatars-from-meta-a-glimpse-into-the-future-of",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Meta, formerly Facebook, showcased photorealistic 3D avatars called Pixel Codec Avatars (PiCA) during a podcast, offering a glimpse into the future of communication in the Metaverse.</li>\n      <li>The deep generative model of 3D human faces allows high-fidelity rendering from various angles and distances, providing an immersive experience even from a 2D perspective, and could change the way we communicate.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/seeds-for-the-future/pica-avatars-from-meta-a-glimpse-into-the-future-of-communication-a105a9c838e5?sk=344007ae815a3f848adb0fdee9245365\">PiCA Avatars From Meta \u2014 A Glimpse Into The Future of Communication!</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 09:12:47 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "SE Radio 582: Leo Porter and Daniel Zingaro on Learning to Program with LLMs  : Software Engineering Radio": {
            "url": "https://www.emergentmind.com/posts/se-radio-582-leo-porter-and-daniel-zingaro-on",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Dr. Leo Porter and Dr. Daniel Zingaro talk about their book, Learn AI-Assisted Python Programming, and how large language models can aid in teaching programming.</li>\n      <li>They discuss the benefits of GitHub Copilot, the ethical concerns of using commercial tools in education, and their views on students cheating with large language models.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.se-radio.net/2023/09/se-radio-582-leo-porter-and-daniel-zingaro-on-using-llms-in-the-classroom/\">SE Radio 582: Leo Porter and Daniel Zingaro on Learning to Program with LLMs  : Software Engineering Radio</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Mon, 02 Oct 2023 06:02:12 +0000",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "How to Use Kafka & Vectors for Real-Time Anomaly Detection": {
            "url": "https://www.emergentmind.com/posts/how-to-use-kafka-vectors-for-real-time-anomaly",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses using Kafka and vectors for real-time anomaly detection in the context of the Internet of Things (IoT).</li>\n      <li>Vishwajeet Dabholkar and Siddharth Gupta demonstrate SingleStore's latest features, including high-velocity data ingestion pipelines, hybrid transaction-analytical processing, and enhanced vector support.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.singlestore.com/resources/webinar-how-to-use-kafka-vectors-for-real-time-anomaly-detection/?utm_source=asif-razzaq&amp;utm_medium=influencer&amp;utm_campaign=How-to-Use-Kafka-and-Vectors-for-Real-Time-Anomaly-Detection&amp;campaignid=7014X0000029Zi6QAE\">How to Use Kafka &amp; Vectors for Real-Time Anomaly Detection</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Tue, 03 Oct 2023 04:01:58 +0000",
            "pubdate_parsed": [
                2023,
                10,
                3
            ],
            "email_sent": true
        },
        "Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs": {
            "url": "https://www.emergentmind.com/posts/2307-08197-towards-self-assembling-artificial-neural",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Biological nervous systems grow through a dynamic self-organizing process, unlike current artificial neural networks that require significant engineering effort. Researchers are taking initial steps towards neural networks that grow through a similar process, guided by a Neural Developmental Program (NDP), which operates through local communication alone.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2307.08197\">Towards Self-Assembling Artificial Neural Networks through Neural Developmental Programs</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 02:02:24 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "Stream boui": {
            "url": "https://www.emergentmind.com/posts/stream-boui-listen-to-riffusion-experiments-playlist",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The current browser being used is not compatible with SoundCloud.</li>\n      <li>It is suggested to download one of the browsers supported by SoundCloud.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://soundcloud.com/boui2/sets/riffusion-experiments?si=833ca59b20d94abca809149a420ce438&amp;utm_source=mobi&amp;utm_medium=text&amp;utm_campaign=social_sharing&amp;utm_terms=gensim_w2v_annoy_postprocessing.gensim_knn_annoy_no_postprocessing\">Stream boui\u00b2</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 13:01:23 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "Richard Stallman Talks Red Hat, AI, and Ethical Software Licenses at GNU Birthday Event - FOSS Force": {
            "url": "https://www.emergentmind.com/posts/richard-stallman-talks-red-hat-ai-and-ethical",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Richard Stallman, the founder of GNU, speaks about various topics including Red Hat's support contracts, artificial intelligence (AI) and the importance of free software during the GNU Project\u2019s 40th birthday event. He criticizes Red Hat's approach to their support contracts and expresses skepticism about referring to generative AI software as 'artificial intelligence'.</li>\n      <li>In his keynote, Stallman also discusses the issue of 'ethical' software licenses, arguing that software licenses are not the appropriate way to prevent harmful use of programs. Instead, he suggests that such regulation should be enacted through law. He further proposes the need for labeling requirements for outputs generated by AI systems, to caution users about their reliability.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://fossforce.com/2023/10/richard-stallman-talks-red-hat-ai-and-ethical-software-licenses-at-gnu-birthday-event/\">Richard Stallman Talks Red Hat, AI, and Ethical Software Licenses at GNU Birthday Event - FOSS Force</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 13:01:14 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "ChatSEC": {
            "url": "https://www.emergentmind.com/posts/chatsec-superflows-sec-copilot",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatSEC is an LLM connected to the SEC API, providing information about company performance, executive compensation, insider trades and filings.</li>\n      <li>ChatSEC is not affiliated with the SEC and does not provide financial advice.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.superflows.ai/chat-sec\">ChatSEC</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 12:02:13 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "Extracting Hacker News Book Recommendations with the ChatGPT API - reyem.dev blog": {
            "url": "https://www.emergentmind.com/posts/extracting-hacker-news-book-recommendations-with-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The author extracted book recommendations from Hacker News threads using the ChatGPT API to categorize data and extract book titles, authors, and URLs.</li>\n      <li>The process involved handling challenges such as the API's non-deterministic nature and its tendency to include mentions of authors without a book title, but resulted in a list of top 50 book recommendations and insights into the use of the GPT API.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://blog.reyem.dev/post/extracting_hn_book_recommendations_with_chatgpt_api/\">Extracting Hacker News Book Recommendations with the ChatGPT API - reyem.dev blog</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 07:01:59 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "Visa Announces $100 Mn Fund for Generative AI Companies": {
            "url": "https://www.emergentmind.com/posts/visa-announces-100-mn-fund-for-generative-ai-companies",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Visa has unveiled a plan to invest $100 million in companies that are advancing generative AI, which could significantly change the future of commerce and payments.</li>\n      <li>The investment will be carried out through Visa Ventures, the global corporate investment arm of Visa, focusing on companies that use generative AI to tackle real-world problems in commerce, payments, and fintech.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@aiuniverse/visa-announces-100-mn-fund-for-generative-ai-companies-b9175b4bc060\">Visa Announces $100 Mn Fund for Generative AI Companies</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Wed, 04 Oct 2023 06:02:00 +0000",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "LLMs confabulate not hallucinate": {
            "url": "https://www.emergentmind.com/posts/llms-confabulate-not-hallucinate",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>LLMs, or language models, are often inaccurately described as 'hallucinating' information when they invent seemingly fitting information that is actually false. The accurate term for this behavior is confabulation, a term used in psychology for when individuals with certain brain damages invent plausible sounding justifications which have no basis in fact.</li>\n      <li>We can gain more insights by recognizing that LLMs actually confabulate, just as humans do in a variety of circumstances, especially with neural pathologies such as memory impairments and in split-brain patients. LLMs can be compared to humans with extreme amnesia and no central coherence.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.beren.io/2023-03-19-LLMs-confabulate-not-hallucinate/\">LLMs confabulate not hallucinate</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 03:01:49 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "GitHub - d3wF1nk/py-openai": {
            "url": "https://www.emergentmind.com/posts/github-d3wf1nk-py-openai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>A commit in the d3wF1nk/py-openai repository does not belong to any branch and may be part of a fork outside the main repository.</li>\n      <li>There is a conflict with a pre-existing tag bearing the same name as the intended new branch, which may cause unexpected issues with Git commands.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://github.com/d3wF1nk/py-openai\">GitHub - d3wF1nk/py-openai</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 01:02:00 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "ChatGPT generated my algorithmic trading strategy. It beat the market.": {
            "url": "https://www.emergentmind.com/posts/chatgpt-generated-my-algorithmic-trading-strategy-it",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT, powered by OpenAI's APIs, was used to generate an algorithmic trading strategy based on Bollinger Bands, a widely used technical indicator in financial market analysis. The strategy outperformed the market, beating the basic Buy-and-Hold approach over a three-year span.</li>\n      <li>The process involved crafting and testing initial portfolio strategies, identifying the top-performing one, refining it using genetic optimization, and then testing it in real-time market conditions. The study demonstrates the effectiveness of AI in creating efficient and effective trading strategies.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@austin-starks/chatgpt-generated-my-algorithmic-trading-strategy-it-beat-the-market-ba00e9059f3c\">ChatGPT generated my algorithmic trading strategy. It beat the market.</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 00:02:21 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Data Science at the Singularity": {
            "url": "https://www.emergentmind.com/posts/2310-00865-data-science-at-the-singularity",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The term 'AI Singularity' is a misrepresentation of the current rapid developments in AI, which are largely due to the adoption of frictionless reproducibility (FR).</li>\n      <li>FR, resulting from data sharing, code sharing, and competitive challenges, is particularly influential in Empirical Machine Learning, and its widespread adoption is responsible for the perceived acceleration in AI advancements.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://arxiv.org/abs/2310.00865\">Data Science at the Singularity</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 13:02:51 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "6 Career Possibilities With a Degree in Artificial Intelligence and Machine Learning - Big Data Analytics News": {
            "url": "https://www.emergentmind.com/posts/6-career-possibilities-with-a-degree-in-artificial",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Academic knowledge in Artificial Intelligence and Machine Learning can lead to a variety of careers such as Machine Learning Engineer, AI Architect, AI Product Manager, Data Scientist, Robotics Scientist, and Application Developer.</li>\n      <li>These careers span multiple industries and involve the creation and implementation of AI and ML models, data analysis, strategic planning, and the integration of AI into physical machines and applications.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://bigdataanalyticsnews.com/career-possibilities-with-degree-in-artificial-intelligence-machine-learning/\">6 Career Possibilities With a Degree in Artificial Intelligence and Machine Learning - Big Data Analytics News</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 13:02:43 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Podcastle's Magic Dust AI Transforms Podcasting with Studio-Quality So": {
            "url": "https://www.emergentmind.com/posts/podcastle-s-magic-dust-ai-transforms-podcasting-with",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Podcastle, a startup, has introduced Magic Dust AI, a tool that can enhance the quality of audio recordings for podcasts, even transforming low-quality files into studio-grade ones.</li>\n      <li>The company has seen significant growth, with its user base increasing to over a million since 2021, and AI tools in podcasting are becoming more common, helping content creators overcome challenges in podcast editing and production.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.aistartupnewsletter.com/p/podcastles-magic-dust-ai-transforms-podcasting-studioquality-sound\">Podcastle's Magic Dust AI Transforms Podcasting with Studio-Quality So</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 13:02:41 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "How to Generate Astonishing Animations with ChatGPT": {
            "url": "https://www.emergentmind.com/posts/how-to-generate-astonishing-animations-with-chatgpt",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>ChatGPT, a large language model, can be used to create interactive or animated visualizations without the use of a text-to-image model.</li>\n      <li>The process involves using HTML and JavaScript, which can be generated by ChatGPT, to create self-contained examples with graphics and effects.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://medium.com/@dreamferus/how-to-generate-astonishing-animations-with-chatgpt-539c735f9517?sk=ffd6353702892dd810e27f7cce7c4443\">How to Generate Astonishing Animations with ChatGPT</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 11:03:17 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Intercom on Product: Product strategy in the age of AI - The Intercom Blog": {
            "url": "https://www.emergentmind.com/posts/intercom-on-product-product-strategy-in-the-age-of-ai",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article discusses how the rise of AI is transforming the product landscape, with AI-native startups and industry giants leveraging AI to drive innovation and thrive in competitive markets. The author reflects on the implications of these changes for product strategy and leaders, highlighting the potential of AI to amplify productivity and disrupt industries.</li>\n      <li>The article also features a conversation with Paul Adams, Chief Product Officer at Intercom, discussing product strategy in the age of AI. They discuss how AI can offer unique opportunities for startups, streamline tasks in SaaS categories, and require human oversight despite its advanced capabilities.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.intercom.com/blog/videos/intercom-on-product-ep21/\">Intercom on Product: Product strategy in the age of AI - The Intercom Blog</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 09:01:17 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "JPMorgan CEO Jamie Dimon: AI will lead to 3.5-day workweek": {
            "url": "https://www.emergentmind.com/posts/jpmorgan-ceo-jamie-dimon-ai-will-lead-to-3-5-day",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Jamie Dimon, the CEO of JPMorgan Chase, predicts that artificial intelligence (AI) could lead to a shorter working week of 3.5 days and improve work-life balance.</li>\n      <li>Despite fears of job losses due to AI, the technology could automate tasks, potentially adding trillions to the global economy and improving living standards.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://fortune.com/2023/10/03/jamie-dimon-jpmorgan-chase-ceo-ai-impact-working-week/\">JPMorgan CEO Jamie Dimon: AI will lead to 3.5-day workweek</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 08:02:42 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Google AI and Cornell Researchers Introduce DynIBaR: A New AI Method that Generates Photorealistic Free-Viewpoint Renderings from a Single Video of a Complex and Dynamic Scene - MarkTechPost": {
            "url": "https://www.emergentmind.com/posts/google-ai-and-cornell-researchers-introduce-dynibar-a",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google AI and Cornell researchers have developed a new AI method named DynIBaR which is capable of generating photorealistic renderings from a single video of a complex and dynamic scene.</li>\n      <li>DynIBaR offers video effects such as bullet time effects, video stabilization, depth of field adjustments, and slow-motion capabilities.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.marktechpost.com/2023/10/04/google-ai-and-cornell-researchers-introduce-dynibar-a-new-ai-method-that-generates-photorealistic-free-viewpoint-renderings-from-a-single-video-of-a-complex-and-dynamic-scene/\">Google AI and Cornell Researchers Introduce DynIBaR: A New AI Method that Generates Photorealistic Free-Viewpoint Renderings from a Single Video of a Complex and Dynamic Scene - MarkTechPost</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 07:02:31 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Pixel 8: Google unveils new phones built for 'the generative AI era'": {
            "url": "https://www.emergentmind.com/posts/pixel-8-google-unveils-new-phones-built-for-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Google's new Pixel 8 and Pixel 8 Pro smartphones feature AI-powered software designed for the 'first phone of the generative AI era'. The devices come with a new G3 Tensor chip that enables a range of AI features, including summarizing news articles, managing phone calls with Google Assistant, and editing photos.</li>\n      <li>The Pixel 8 series is also equipped with a brighter display, a new camera system, and improved battery life. The AI enhancements are aimed at tech enthusiasts seeking an alternative to Apple or Samsung devices. However, Google's Pixel line remains a niche product with a global smartphone market share of about 1%.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.cnn.com/2023/10/04/tech/pixel-8-google-ai/index.html\">Pixel 8: Google unveils new phones built for 'the generative AI era'</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 07:02:25 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Hamels Blog - Optimizing latency": {
            "url": "https://www.emergentmind.com/posts/hamel-s-blog-optimizing-latency",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>The article explores different methods to optimize latency, comparing tools such as mlc, CTranslate2, and vLLM. The author found mlc to be the fastest, while CTranslate2 was the easiest to use with the best documentation.</li>\n      <li>Different variables were held constant in the study to focus on latency, including the batch size of n = 1 for all prediction requests, and all experiments were conducted on an Nvidia A6000 GPU, unless otherwise noted. The study concluded with a discussion on the need for efficient model serving for open source LLMs.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://hamel.dev/notes/llm/inference/03_inference.html\">Hamel\u2019s Blog - Optimizing latency</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Thu, 05 Oct 2023 06:00:47 +0000",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Hummingbird - Lightweight, native personal assistant for macOS": {
            "url": "https://www.emergentmind.com/posts/hummingbird-lightweight-native-personal-assistant",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Hummingbird is an assistant for macOS that provides quick answers to any question.</li>\n      <li>It is customizable, has a built-in web browsing feature, real-time search, and rich content.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://thegums.co/hummingbird\">Hummingbird - Lightweight, native personal assistant for macOS</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 06 Oct 2023 13:01:34 +0000",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        },
        "Ollama is now available as an official Docker image  Ollama Blog": {
            "url": "https://www.emergentmind.com/posts/ollama-is-now-available-as-an-official-docker-image",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Ollama has been released as an official Docker open-source image, simplifying the usage of large language models with Docker containers.</li>\n      <li>It operates locally, ensuring private data does not need to be sent to third-party services, and supports GPU acceleration on Mac.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://ollama.ai/blog/ollama-is-now-available-as-an-official-docker-image\">Ollama is now available as an official Docker image \u00b7 Ollama Blog</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Fri, 06 Oct 2023 04:01:26 +0000",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        },
        "Nobel laureate Maria Ressa on defending truth and the danger of A.I. in the wrong hands": {
            "url": "https://www.emergentmind.com/posts/nobel-laureate-maria-ressa-on-defending-truth-and-the",
            "description": "<p>Summary:</p>\n  <ul>\n      <li>Nobel Peace Prize winner Maria Ressa warns about the misuse of artificial intelligence by authoritarian governments and the threat to truth in the digital age. She expresses concern about losing the information war to adversarial artificial intelligence.</li>\n      <li>Ressa discusses the dangers of tech-enabled Armageddon, detailing how social media and AI can manipulate public opinion, and potentially jeopardize the integrity of facts and elections. She also questions why the U.S. has not put more safeguards in place to protect against these risks.</li>\n  </ul>\n\n\n<p>\n  Full article: <a href=\"https://www.pbs.org/newshour/show/nobel-laureate-maria-ressa-on-defending-truth-and-the-danger-of-a-i-in-the-wrong-hands\">Nobel laureate Maria Ressa on defending truth and the danger of A.I. in the wrong hands</a>\n</p>\n\n<p>---</p>\n<p>PS: <a href=\"https://www.emergentmind.com/sale\">Emergent Mind is for sale</a>.</p>",
            "pubdate": "Sat, 07 Oct 2023 02:01:33 +0000",
            "pubdate_parsed": [
                2023,
                10,
                7
            ],
            "email_sent": true
        }
    },
    "Superpower": {
        "BREAKING: Apple is building an AI chatbot called 'Apple GPT.'": {
            "url": "https://www.superpowerdaily.com/p/131-breaking-apple-is-building-an-ai-chatbot-called-apple-gpt",
            "description": "GPT-4 new limit, 50 per 3 hours",
            "pubdate": "2023-07-20T06:16:37Z",
            "pubdate_parsed": [
                2023,
                7,
                20
            ],
            "email_sent": true
        },
        "Just released: You can now set Custom Instruction in ChatGPT": {
            "url": "https://www.superpowerdaily.com/p/132-just-released-you-can-now-set-custom-instruction-in-chatgpt",
            "description": "I lost my luggage. An AI gent called and tracked it down for me.",
            "pubdate": "2023-07-21T07:38:30Z",
            "pubdate_parsed": [
                2023,
                7,
                21
            ],
            "email_sent": true
        },
        "ChatGPT is coming to Android and no more As a large language model": {
            "url": "https://www.superpowerdaily.com/p/133-chatgpt-coming-to-android-and-no-more-as-a-large-language-model",
            "description": "Shopify Employee Breaks NDA To Reveal Firm Quietly Replacing Laid-Off Workers With AI",
            "pubdate": "2023-07-24T06:51:00Z",
            "pubdate_parsed": [
                2023,
                7,
                24
            ],
            "email_sent": true
        },
        "A novel Jailbreak technique to get ChatGPT to create Ransomware and Keyloggers": {
            "url": "https://www.superpowerdaily.com/p/134-a-novel-jailbreak-technique-to-get-chatgpt-to-create-ransomware-keyloggers",
            "description": "Control robots with prompts",
            "pubdate": "2023-07-25T07:38:00Z",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "AI Cheat Sheets": {
            "url": "https://www.superpowerdaily.com/p/top-ai-cheat-sheets-that-will-save-you-hours-of-work-for-free",
            "description": "Top AI cheat sheets that will save you hours of work (for free)",
            "pubdate": "2023-07-25T06:06:40Z",
            "pubdate_parsed": [
                2023,
                7,
                25
            ],
            "email_sent": true
        },
        "Sam Altman wants to scan your eyeball now": {
            "url": "https://www.superpowerdaily.com/p/135-sam-altman-wants-to-scan-your-eyeball-now",
            "description": "OpenAI Shuts Down Its AI Detection Tool",
            "pubdate": "2023-07-26T07:11:15Z",
            "pubdate_parsed": [
                2023,
                7,
                26
            ],
            "email_sent": true
        },
        "A whistleblower just told Congress UFOs are real": {
            "url": "https://www.superpowerdaily.com/p/136-a-whistleblower-just-told-congress-ufos-are-real",
            "description": "Stack overflow is in big trouble",
            "pubdate": "2023-07-27T08:43:56Z",
            "pubdate_parsed": [
                2023,
                7,
                27
            ],
            "email_sent": true
        },
        "JUST IN: StackOverflow Announces OverflowAI!": {
            "url": "https://www.superpowerdaily.com/p/137-just-in-stackoverflow-announces-overflowai",
            "description": "A universal technique to jailbreak chatbots",
            "pubdate": "2023-07-28T05:57:31Z",
            "pubdate_parsed": [
                2023,
                7,
                28
            ],
            "email_sent": true
        },
        "Record set for fastest GPT4 audio feedback": {
            "url": "https://www.superpowerdaily.com/p/138-record-set-for-fastest-gpt4-audio-feedback",
            "description": "New AI Tool 'FraudGPT' Emerges",
            "pubdate": "2023-07-31T06:58:04Z",
            "pubdate_parsed": [
                2023,
                7,
                31
            ],
            "email_sent": true
        },
        "Google is training robots the way it trains AI chatbots": {
            "url": "https://www.superpowerdaily.com/p/139-google-is-training-robots-the-way-it-trains-ai-chatbots",
            "description": "OpenAI Files Trademark Application for GPT-5",
            "pubdate": "2023-08-01T07:30:18Z",
            "pubdate_parsed": [
                2023,
                8,
                1
            ],
            "email_sent": true
        },
        "Google Assistant becomes more like ChatGPT": {
            "url": "https://www.superpowerdaily.com/p/140-google-assistant-becomes-more-like-chatgpt",
            "description": "Billionaire CEO of Palantir advocates for AI weapons",
            "pubdate": "2023-08-02T07:42:00Z",
            "pubdate_parsed": [
                2023,
                8,
                2
            ],
            "email_sent": true
        },
        "ChatGPT now shows suggestions!": {
            "url": "https://www.superpowerdaily.com/p/141-chatgpt-now-shows-suggestions",
            "description": "a breakthrough foundation model that can operate software like a human.",
            "pubdate": "2023-08-03T06:55:00Z",
            "pubdate_parsed": [
                2023,
                8,
                3
            ],
            "email_sent": true
        },
        "No more constantly having to re-login to ChatGPT!": {
            "url": "https://www.superpowerdaily.com/p/142-no-more-constantly-having-to-re-login-to-chatgpt",
            "description": "Tinder tests AI photo selection feature to help users build profiles",
            "pubdate": "2023-08-04T06:30:00Z",
            "pubdate_parsed": [
                2023,
                8,
                4
            ],
            "email_sent": true
        },
        "Best resources to master prompt engineering": {
            "url": "https://www.superpowerdaily.com/p/143-best-resources-to-master-prompt-engineering",
            "description": "Why AI Progress Is Unlikely to Slow Down",
            "pubdate": "2023-08-07T07:34:00Z",
            "pubdate_parsed": [
                2023,
                8,
                7
            ],
            "email_sent": true
        },
        "GPTBot, a web crawler designed to automatically scrape data from the entire internet": {
            "url": "https://www.superpowerdaily.com/p/144-gptbot-a-web-crawler-designed-to-automatically-scrape-data-from-the-entire-internet",
            "description": "Apple is building AI into \u2018every product",
            "pubdate": "2023-08-08T07:41:00Z",
            "pubdate_parsed": [
                2023,
                8,
                8
            ],
            "email_sent": true
        },
        "Can you tell this video is AI-generated?": {
            "url": "https://www.superpowerdaily.com/p/145-can-you-tell-this-video-is-ai-generated",
            "description": "A list of best Midjourney tokens to experiment with",
            "pubdate": "2023-08-09T07:56:00Z",
            "pubdate_parsed": [
                2023,
                8,
                9
            ],
            "email_sent": true
        },
        "Is human-level AI 2-3 years away?": {
            "url": "https://www.superpowerdaily.com/p/146-is-human-level-ai-2-3-years-away",
            "description": "A hackable AI home assistant platform",
            "pubdate": "2023-08-10T05:58:00Z",
            "pubdate_parsed": [
                2023,
                8,
                10
            ],
            "email_sent": true
        },
        "Just released: Real-time Text-to-Speech Model for lifelike conversations": {
            "url": "https://www.superpowerdaily.com/p/147-just-released-real-time-text-to-speech-model-for-lifelike-conversations",
            "description": "How to implement a paper without crying",
            "pubdate": "2023-08-11T08:33:00Z",
            "pubdate_parsed": [
                2023,
                8,
                11
            ],
            "email_sent": true
        },
        "The first truly disruptive application of AI in tax & accounting": {
            "url": "https://www.superpowerdaily.com/p/148-the-first-truly-disruptive-application-of-ai-in-tax-accounting",
            "description": "And now, AI Boyfriend",
            "pubdate": "2023-08-14T08:37:00Z",
            "pubdate_parsed": [
                2023,
                8,
                14
            ],
            "email_sent": true
        },
        "OpenAI Might Go Bankrupt by the End of 2024": {
            "url": "https://www.superpowerdaily.com/p/149-openai-might-go-bankrupt-by-the-end-of-2024",
            "description": "Want to create your own WormGPT, SuperEbolaGPT, or ElectionHeistGPT?",
            "pubdate": "2023-08-15T09:13:00Z",
            "pubdate_parsed": [
                2023,
                8,
                15
            ],
            "email_sent": true
        },
        "The AI Nanny in Your Babys Future": {
            "url": "https://www.superpowerdaily.com/p/150-the-ai-nanny-in-your-baby-s-future",
            "description": "How to reduce hallucinations in ChatGPT",
            "pubdate": "2023-08-16T07:56:00Z",
            "pubdate_parsed": [
                2023,
                8,
                16
            ],
            "email_sent": true
        },
        "OpenAI acquires Global Illumination": {
            "url": "https://www.superpowerdaily.com/p/151-openai-acquires-global-illumination",
            "description": "Google Search is rolling out new generative AI capabilities",
            "pubdate": "2023-08-17T08:43:00Z",
            "pubdate_parsed": [
                2023,
                8,
                17
            ],
            "email_sent": true
        },
        "How to Create kickass AI Writing Prompts": {
            "url": "https://www.superpowerdaily.com/p/152-how-to-create-kickass-ai-writing-prompts",
            "description": "Character AI is apparently the greatest thing since Pornhub",
            "pubdate": "2023-08-18T08:17:07Z",
            "pubdate_parsed": [
                2023,
                8,
                18
            ],
            "email_sent": true
        },
        "This AI makes reservations and waits on hold for you": {
            "url": "https://www.superpowerdaily.com/p/153-this-ai-waits-on-hold-for-you",
            "description": "Tutorial - How to design logos using generative AI",
            "pubdate": "2023-08-21T07:56:00Z",
            "pubdate_parsed": [
                2023,
                8,
                21
            ],
            "email_sent": true
        },
        "Molly Jailbroke her watch into a real-life second brain": {
            "url": "https://www.superpowerdaily.com/p/154-molly-jailbroke-her-watch-into-a-real-life-second-brain",
            "description": "MidJourney just released a new feature: Inpainting",
            "pubdate": "2023-08-22T08:01:00Z",
            "pubdate_parsed": [
                2023,
                8,
                22
            ],
            "email_sent": true
        },
        "The Potato Prompt": {
            "url": "https://www.superpowerdaily.com/p/155-the-potato-prompt",
            "description": "You can now fine-tune GPT-3.5 with your own data",
            "pubdate": "2023-08-23T06:57:00Z",
            "pubdate_parsed": [
                2023,
                8,
                23
            ],
            "email_sent": true
        },
        "Meta unveils breakthrough language AI": {
            "url": "https://www.superpowerdaily.com/p/156-meta-unveils-breakthrough-language-ai",
            "description": "ALSO: An AI that predicts your upcoming exam questions",
            "pubdate": "2023-08-24T07:07:00Z",
            "pubdate_parsed": [
                2023,
                8,
                24
            ],
            "email_sent": true
        },
        "Code Llama, a state-of-the-art large language model for coding": {
            "url": "https://www.superpowerdaily.com/p/157-code-llama-a-state-of-the-art-large-language-model-for-coding",
            "description": "AI Gave a Paralyzed Woman Her Voice Back",
            "pubdate": "2023-08-25T07:39:00Z",
            "pubdate_parsed": [
                2023,
                8,
                25
            ],
            "email_sent": true
        },
        "AI Girlfriends: Addressing the Loneliness Epidemic?": {
            "url": "https://www.superpowerdaily.com/p/158-ai-girlfriends-addressing-the-loneliness-epidemic",
            "description": "Stephen King Isn't Afraid of AI",
            "pubdate": "2023-08-28T06:58:00Z",
            "pubdate_parsed": [
                2023,
                8,
                28
            ],
            "email_sent": true
        },
        "OpenAI Released the Most Powerful Version of ChatGPT": {
            "url": "https://www.superpowerdaily.com/p/159-openai-released-the-most-powerful-version-of-chatgpt",
            "description": "You can now generate text in your AI images",
            "pubdate": "2023-08-29T06:23:00Z",
            "pubdate_parsed": [
                2023,
                8,
                29
            ],
            "email_sent": true
        },
        "Google unveils an amazing lineup of new AI products at 2023 Cloud Next event": {
            "url": "https://www.superpowerdaily.com/p/160-google-unveils-an-amazing-lineup-of-new-ai-products-at-2023-cloud-next-event",
            "description": "Custom Instruction to improve ChatGPT coding output",
            "pubdate": "2023-08-30T07:27:00Z",
            "pubdate_parsed": [
                2023,
                8,
                30
            ],
            "email_sent": true
        },
        "Google made a watermark for AI images that you cant edit out": {
            "url": "https://www.superpowerdaily.com/p/161-google-made-a-watermark-for-ai-images-that-you-can-t-edit-out",
            "description": "OpenAI engineer talks about how he uses GPT-4 in his day-to-day workflow",
            "pubdate": "2023-08-31T06:39:00Z",
            "pubdate_parsed": [
                2023,
                8,
                31
            ],
            "email_sent": true
        },
        "\"Project Sunshine\" - ChatGPT with special capabilities": {
            "url": "https://www.superpowerdaily.com/p/162-project-sunshine-chatgpt-with-special-capabilities",
            "description": "Plus: A Pixar Quality Animation Made with AI for $195",
            "pubdate": "2023-09-01T06:43:00Z",
            "pubdate_parsed": [
                2023,
                9,
                1
            ],
            "email_sent": true
        },
        "A tiny island in the Caribbean is now sitting on a digital treasure.": {
            "url": "https://www.superpowerdaily.com/p/163-a-tiny-island-in-the-caribbean-is-now-sitting-on-a-digital-treasure",
            "description": "PLUS: Sell to new audiences by changing models with AI instantly",
            "pubdate": "2023-09-05T06:08:00Z",
            "pubdate_parsed": [
                2023,
                9,
                5
            ],
            "email_sent": true
        },
        "GPT Author V2 - Now with cover art and ebook export options": {
            "url": "https://www.superpowerdaily.com/p/164-gpt-author-v2-now-with-cover-art-and-ebook-export-options",
            "description": "PLUS: LangChain Hub - A place to publish, discover, and try out prompts",
            "pubdate": "2023-09-06T05:52:00Z",
            "pubdate_parsed": [
                2023,
                9,
                6
            ],
            "email_sent": true
        },
        "Harvard Medical School Creating AI in Medicine Ph.D. Track": {
            "url": "https://www.superpowerdaily.com/p/165-harvard-medical-school-creating-ai-in-medicine-phd-track",
            "description": "PLUS: Teaching AI to make people happy",
            "pubdate": "2023-09-07T06:54:00Z",
            "pubdate_parsed": [
                2023,
                9,
                7
            ],
            "email_sent": true
        },
        "TIME 100 Most Influential People in AI": {
            "url": "https://www.superpowerdaily.com/p/166-templates-coming-to-chatgpt-enterprise",
            "description": "PLUS: Templates coming to ChatGPT Enterprise!",
            "pubdate": "2023-09-08T07:06:00Z",
            "pubdate_parsed": [
                2023,
                9,
                8
            ],
            "email_sent": true
        },
        "A new Uncensored AI with no limit": {
            "url": "https://www.superpowerdaily.com/p/167-a-new-uncensored-ai-with-no-limit",
            "description": "MBA Students lost miserably to ChatGPT in generating ideas",
            "pubdate": "2023-09-11T07:36:00Z",
            "pubdate_parsed": [
                2023,
                9,
                11
            ],
            "email_sent": true
        },
        "ChatGPT found the right diagnosis after 17 doctors couldnt": {
            "url": "https://www.superpowerdaily.com/p/168-chatgpt-found-the-right-diagnosis-after-17-doctors-couldnt",
            "description": "Americans believe AI will hurt elections",
            "pubdate": "2023-09-12T06:24:00Z",
            "pubdate_parsed": [
                2023,
                9,
                12
            ],
            "email_sent": true
        },
        "OpenAI Now Owns ChatGPT.com": {
            "url": "https://www.superpowerdaily.com/p/169-openai-now-owns-chatgpt-com",
            "description": "Simulating History with ChatGPT",
            "pubdate": "2023-09-13T06:05:00Z",
            "pubdate_parsed": [
                2023,
                9,
                13
            ],
            "email_sent": true
        },
        "Mexico just casually unboxed two aliens": {
            "url": "https://www.superpowerdaily.com/p/170-mexico-just-casually-unboxed-two-aliens",
            "description": "A facial recognition tech too dangerous to be released",
            "pubdate": "2023-09-14T07:01:00Z",
            "pubdate_parsed": [
                2023,
                9,
                14
            ],
            "email_sent": true
        },
        "Google Nears Release of Gemini AI to Challenge OpenAI": {
            "url": "https://www.superpowerdaily.com/p/171-google-nears-release-of-gemini-ai-to-challenge-openai",
            "description": "Looking for an internship? You should check this out",
            "pubdate": "2023-09-15T07:05:00Z",
            "pubdate_parsed": [
                2023,
                9,
                15
            ],
            "email_sent": true
        },
        "Proof that using GPT-4 improves your performance": {
            "url": "https://www.superpowerdaily.com/p/172-proof-that-using-gpt-4-improves-your-performance",
            "description": "Using ChatGPT custom instructions for fun and profit",
            "pubdate": "2023-09-18T06:14:00Z",
            "pubdate_parsed": [
                2023,
                9,
                18
            ],
            "email_sent": true
        },
        "38TB of data accidentally exposed by Microsoft AI researchers": {
            "url": "https://www.superpowerdaily.com/p/173-38tb-of-data-accidentally-exposed-by-microsoft-ai-researchers",
            "description": "GPT-3.5-turbo-instruct has arrived",
            "pubdate": "2023-09-19T06:35:00Z",
            "pubdate_parsed": [
                2023,
                9,
                19
            ],
            "email_sent": true
        },
        "Get Paid to Red Team OpenAI Models": {
            "url": "https://www.superpowerdaily.com/p/174-get-paid-to-red-team-openai-models",
            "description": "Google\u2019s Bard Now Has Extensions",
            "pubdate": "2023-09-20T06:14:00Z",
            "pubdate_parsed": [
                2023,
                9,
                20
            ],
            "email_sent": true
        },
        "Major New Update Coming to ChatGPT: DALLE 3": {
            "url": "https://www.superpowerdaily.com/p/175-major-new-update-coming-to-chatgpt-dall-e-3",
            "description": "Apple legit just made a gaming console",
            "pubdate": "2023-09-21T07:05:00Z",
            "pubdate_parsed": [
                2023,
                9,
                21
            ],
            "email_sent": true
        },
        "BREAKING: Microsoft announced Copilot": {
            "url": "https://www.superpowerdaily.com/p/176-breaking-microsoft-announced-copilot",
            "description": "Deepfakes of Chinese influencers are live streaming 24/7",
            "pubdate": "2023-09-22T07:58:00Z",
            "pubdate_parsed": [
                2023,
                9,
                22
            ],
            "email_sent": true
        },
        "Has OpenAI achieved AGI?": {
            "url": "https://www.superpowerdaily.com/p/177-has-openai-achieved-agi",
            "description": "Confessions of a Viral AI Writer",
            "pubdate": "2023-09-25T07:59:00Z",
            "pubdate_parsed": [
                2023,
                9,
                25
            ],
            "email_sent": true
        },
        "ChatGPT Can Now See, Hear, and Speak": {
            "url": "https://www.superpowerdaily.com/p/178-chatgpt-can-now-see-hear-and-speak",
            "description": "Spotify is going to clone podcasters\u2019 voices \u2014\u00a0and translate them to other languages",
            "pubdate": "2023-09-26T06:43:00Z",
            "pubdate_parsed": [
                2023,
                9,
                26
            ],
            "email_sent": true
        },
        "Google caught publicly indexing users conversations with Bard": {
            "url": "https://www.superpowerdaily.com/p/179-google-caught-publicly-indexing-users-conversations-with-bard",
            "description": "The Internet is dying",
            "pubdate": "2023-09-27T07:01:00Z",
            "pubdate_parsed": [
                2023,
                9,
                27
            ],
            "email_sent": true
        },
        "ChatGPT Web Browsing is back": {
            "url": "https://www.superpowerdaily.com/p/180-chatgpt-web-browsing-is-back",
            "description": "ChatGPT finds his new best bro",
            "pubdate": "2023-09-28T07:22:00Z",
            "pubdate_parsed": [
                2023,
                9,
                28
            ],
            "email_sent": true
        },
        "OpenAI in talk to launch the \"iPhone of Artificial Intelligence\"": {
            "url": "https://www.superpowerdaily.com/p/181-openai-in-talk-to-launch-the-iphone-of-artificial-intelligence",
            "description": "How do you use AI to get things done faster?",
            "pubdate": "2023-09-29T07:21:00Z",
            "pubdate_parsed": [
                2023,
                9,
                29
            ],
            "email_sent": true
        },
        "Water Strain: AIs Thirst in Drought-Hit Regions": {
            "url": "https://www.superpowerdaily.com/p/water-strain-ai-s-thirst-in-drought-hit-regions",
            "description": "Microsoft\u2019s Ambitious AI Drains Essential Water Resources Amidst Intensifying Droughts",
            "pubdate": "2023-10-02T01:50:40Z",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "Jasper AI Reassesses Worth Amidst Slowing Momentum": {
            "url": "https://www.superpowerdaily.com/p/jasper-ai-reassesses-worth-amidst-slowing-momentum",
            "description": "The Pioneer in Generative AI Tackles Internal Devaluation and a Shakeup in Leadership",
            "pubdate": "2023-10-02T00:57:28Z",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "Metas Llama 2 Long AI: A New Contender in Generative Models": {
            "url": "https://www.superpowerdaily.com/p/meta-s-llama-2-long-ai-a-new-contender-in-generative-models",
            "description": "Surpassing Competitors, the Model Boasts Enhanced Performance in Long-Prompt Responses",
            "pubdate": "2023-10-02T00:36:46Z",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "Humane's AI Pin Steps Onto the Fashion Stage in Paris": {
            "url": "https://www.superpowerdaily.com/p/182-humane-s-ai-pin-steps-onto-the-fashion-stage-in-paris",
            "description": "Man Fakes an Entire Month of His Life Using AI-Generated Photos",
            "pubdate": "2023-10-02T06:30:00Z",
            "pubdate_parsed": [
                2023,
                10,
                2
            ],
            "email_sent": true
        },
        "AI Pendant, Another AI wearable, now from Rewind": {
            "url": "https://www.superpowerdaily.com/p/183-ai-pendant-another-ai-wearable-now-from-rewind",
            "description": "Building an AI That Builds Itself",
            "pubdate": "2023-10-03T06:52:00Z",
            "pubdate_parsed": [
                2023,
                10,
                3
            ],
            "email_sent": true
        },
        "Pixel 8 Leaks Reveal Enhanced AI & Chic Cases": {
            "url": "https://www.superpowerdaily.com/p/pixel-8-leaks-reveal-enhanced-ai-chic-cases",
            "description": "Google's upcoming Pixel 8 shines in AI, while updated cases add flair",
            "pubdate": "2023-10-03T06:40:08Z",
            "pubdate_parsed": [
                2023,
                10,
                3
            ],
            "email_sent": true
        },
        "Google Accused of Stifling Bing's Growth": {
            "url": "https://www.superpowerdaily.com/p/google-accused-of-stifling-bing-s-growth",
            "description": "Microsoft's Nadella Criticizes Tech Giant's Dominance in Search Market",
            "pubdate": "2023-10-03T06:34:03Z",
            "pubdate_parsed": [
                2023,
                10,
                3
            ],
            "email_sent": true
        },
        "Deepfake MrBeast Ad Deceives TikTok": {
            "url": "https://www.superpowerdaily.com/p/184-deepfake-mrbeast-ad-deceives-tiktok",
            "description": "Spotify new feature: Audiobooks",
            "pubdate": "2023-10-04T06:32:00Z",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "ChatGPT's Live News Feature Faces Resistance from Leading News Out": {
            "url": "https://www.superpowerdaily.com/p/chatgpt-s-live-news-feature-faces-resistance-from-leading-news-out",
            "description": "Publishers Unite to Safeguard Content from AI Crawlers",
            "pubdate": "2023-10-04T05:59:49Z",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "The Future is 3.5 Days: AIs Impact on Work": {
            "url": "https://www.superpowerdaily.com/p/the-future-is-3-5-days-ai-s-impact-on-work",
            "description": "JPMorgan's CEO envisions a shorter workweek, but will AI replace jobs?",
            "pubdate": "2023-10-04T05:54:23Z",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "The Debate on AI Replacing \"Median\" Workers": {
            "url": "https://www.superpowerdaily.com/p/the-debate-on-ai-replacing-median-workers",
            "description": "A Dive into Altman's Vision and its Implications",
            "pubdate": "2023-10-04T05:50:48Z",
            "pubdate_parsed": [
                2023,
                10,
                4
            ],
            "email_sent": true
        },
        "Canva just dropped their all in one Magic Studio, the BIGGEST AI upgrade ever": {
            "url": "https://www.superpowerdaily.com/p/185-canva-just-dropped-their-all-in-one-magic-studio-the-biggest-ai-upgrade-ever",
            "description": "The Pixel 8 Pro has better cameras, a brighter screen, and a lot of new AI tricks",
            "pubdate": "2023-10-05T07:13:00Z",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "Canva's Magic Studio: The Future of AI in Design": {
            "url": "https://www.superpowerdaily.com/p/canva-s-magic-studio-the-future-of-ai-in-design",
            "description": "AI-driven tools to revolutionize design experiences, making them faster and simpler!",
            "pubdate": "2023-10-05T06:47:23Z",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "A Glimpse Into Google's Future": {
            "url": "https://www.superpowerdaily.com/p/a-glimpse-into-google-s-future",
            "description": "The next-generation phone with enhanced features and a higher price tag.",
            "pubdate": "2023-10-05T06:35:42Z",
            "pubdate_parsed": [
                2023,
                10,
                5
            ],
            "email_sent": true
        },
        "OpenAI is exploring making its own AI chips": {
            "url": "https://www.superpowerdaily.com/p/186-openai-is-exploring-making-its-own-ai-chips",
            "description": "OpenAI's justification for why training data is fair use, not infringement",
            "pubdate": "2023-10-06T07:43:00Z",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        },
        "4chan Exploits Bing to Spread Controversial Images Online": {
            "url": "https://www.superpowerdaily.com/p/4chan-exploits-bing-to-spread-controversial-images-online",
            "description": "Online communities exploit Bing's AI Image Generator for controversial content.",
            "pubdate": "2023-10-06T07:31:34Z",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        },
        "OpenAI Eyes In-House Chip Development": {
            "url": "https://www.superpowerdaily.com/p/openai-eyes-in-house-chip-development",
            "description": "Amidst GPU scarcity, OpenAI contemplates custom chip solutions",
            "pubdate": "2023-10-06T07:22:55Z",
            "pubdate_parsed": [
                2023,
                10,
                6
            ],
            "email_sent": true
        }
    }
}